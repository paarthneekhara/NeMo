[32m[NeMo I 2023-10-13 22:21:45 megatron_gpt_speechllm_sft_2309:108][39m 
    
    ************** Experiment configuration ***********
[32m[NeMo I 2023-10-13 22:21:45 megatron_gpt_speechllm_sft_2309:109][39m 
    name: megatron_sgpt_sft_speechtextpre_220m_1
    restore_from_path: null
    trainer:
      devices: 1
      num_nodes: 1
      accelerator: gpu
      precision: bf16
      logger: false
      enable_checkpointing: false
      use_distributed_sampler: false
      max_epochs: -1
      max_steps: 600000
      log_every_n_steps: 10
      val_check_interval: 1000
      limit_val_batches: 50
      limit_test_batches: 500
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      benchmark: false
      enable_model_summary: false
      num_sanity_val_steps: 0
    exp_manager:
      explicit_log_dir: null
      exp_dir: /datap/misc/gpt_local_eperiments
      name: ${name}
      create_wandb_logger: false
      wandb_logger_kwargs:
        project: null
        name: null
      resume_if_exists: true
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        monitor: val_loss
        save_top_k: 3
        mode: min
        always_save_nemo: false
        save_nemo_on_train_end: false
        filename: megatron_gpt--{val_loss:.2f}-{step}-{consumed_samples}
        model_parallel_size: ${multiply:${model.tensor_model_parallel_size}, ${model.pipeline_model_parallel_size}}
    model:
      micro_batch_size: 4
      global_batch_size: 4
      rampup_batch_size: null
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      virtual_pipeline_model_parallel_size: null
      hidden_dropout: 0.1
      attention_dropout: 0.1
      ffn_dropout: 0.0
      native_amp_init_scale: 4294967296
      native_amp_growth_interval: 1000
      hysteresis: 2
      megatron_amp_O2: false
      resume_from_checkpoint: null
      apex_transformer_log_level: 30
      gradient_as_bucket_view: true
      sync_batch_comm: false
      activations_checkpoint_granularity: null
      activations_checkpoint_method: null
      activations_checkpoint_num_layers: null
      num_micro_batches_with_partial_activation_checkpoints: null
      activations_checkpoint_layers_per_pipeline: null
      sequence_parallel: false
      transformer_engine: false
      use_flash_attention: false
      data:
        train_ds:
        - /datap/misc/manifests/manifests/libritts/train_clean_300_speechlm_ttstasks.json
        validation_ds:
        - /datap/misc/manifests/manifests/libritts/val_clean_300_speechlm_ttstasks.json
        sup_data_path: /datap/misc/librittscodec/codec
        max_seq_length: 512
        sample_rate: 24000
        add_eos: true
        add_bos: false
        decoder_starts_with_pad: false
        add_eos_to_decoder_output: true
        add_sentinel_to_input: true
        ul2_prompt_token: null
        shuffle: true
        num_workers: 4
        pin_memory: true
        speech_offset: 256000
        train_task: tts
      nsys_profile:
        enabled: false
        start_step: 10
        end_step: 10
        ranks:
        - 0
        gen_shape: false
      optim:
        name: distributed_fused_adam
        lr: 1.0e-05
        weight_decay: 0.01
        betas:
        - 0.9
        - 0.98
        sched:
          name: CosineAnnealing
          warmup_steps: 500
          constant_steps: 50000
          min_lr: 1.0e-06
      gc_interval: 0
      task_templates:
      - taskname: squad
        prompt_template: <|VIRTUAL_PROMPT_0|> {context} {question} {answer}
        total_virtual_tokens: 3
        virtual_token_splits:
        - 3
        truncate_field: context
        answer_field: answer
      seq_pattern: delay_parallel
      override_vocab_size: 264192
      output_size: 264192
      embedding_scale: 1.0
      speech_loss_scale: 1.0
      text_size: 256000
      restore_from_path: /datap/misc/Checkpoints/converted_megatron_converted_843m_tp1_pp1.nemo
    
[32m[NeMo I 2023-10-13 22:21:45 exp_manager:639][39m Resuming training from checkpoint: /datap/misc/gpt_local_eperiments/megatron_sgpt_sft_speechtextpre_220m_1/checkpoints/megatron_gpt--val_loss=6.86-step=15000-consumed_samples=60000.0-last.ckpt
[32m[NeMo I 2023-10-13 22:21:45 exp_manager:396][39m Experiments will be logged at /datap/misc/gpt_local_eperiments/megatron_sgpt_sft_speechtextpre_220m_1
[32m[NeMo I 2023-10-13 22:21:45 exp_manager:835][39m TensorboardLogger has been set up
[32m[NeMo I 2023-10-13 22:21:45 megatron_gpt_speechllm_sft_2309:119][39m Restore from {cfg.model.restore_from_path}
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:234][39m Rank 0 has data parallel group: [0]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:237][39m All data parallel group ranks: [[0]]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:238][39m Ranks 0 has data parallel rank: 0
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:246][39m Rank 0 has model parallel group: [0]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:247][39m All model parallel group ranks: [[0]]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:257][39m Rank 0 has tensor model parallel group: [0]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:261][39m All tensor model parallel group ranks: [[0]]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:262][39m Rank 0 has tensor model parallel rank: 0
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:276][39m Rank 0 has pipeline model parallel group: [0]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:288][39m Rank 0 has embedding group: [0]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:294][39m All pipeline model parallel group ranks: [[0]]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:295][39m Rank 0 has pipeline model parallel rank 0
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:296][39m All embedding group ranks: [[0]]
[32m[NeMo I 2023-10-13 22:21:47 megatron_init:297][39m Rank 0 has embedding rank: 0
[32m[NeMo I 2023-10-13 22:21:47 tokenizer_utils:191][39m Getting SentencePiece with model: /tmp/tmp5434gkl0/a184c0997f35446cac66e8e2d63f7853_mt_nlg_plus_multilingual_ja_zh_the_stack_frac_015_256k.model
[32m[NeMo I 2023-10-13 22:21:47 megatron_base_model:312][39m Padded vocab_size: 256000, original vocab_size: 256000, dummy tokens: 0.
[32m[NeMo I 2023-10-13 22:21:49 nlp_overrides:686][39m Model MegatronSpeechGPTSFTModel was successfully restored from /datap/misc/Checkpoints/converted_megatron_converted_843m_tp1_pp1.nemo.
[32m[NeMo I 2023-10-13 22:21:50 megatron_gpt_model:1168][39m Pipeline model parallel rank: 0, Tensor model parallel rank: 0, Number of model parameters on device: 8.40e+08. Total number of model parameters: 8.40e+08.
[32m[NeMo I 2023-10-13 22:21:50 base_prompt_learning_dataset:60][39m Loading and tokenizing dataset ... 
copy_dataset len === 115814
[32m[NeMo I 2023-10-13 22:21:54 t5_speechlm_dataset:222][39m After Process len(self.examples) 76766 115814
[32m[NeMo I 2023-10-13 22:21:54 t5_speechlm_dataset:223][39m Skipped 39048 sentences, sequence length too short or too long even after truncation
build success 19191 ['/datap/misc/manifests/manifests/libritts/train_clean_300_speechlm_ttstasks.json']
[32m[NeMo I 2023-10-13 22:21:54 base_prompt_learning_dataset:60][39m Loading and tokenizing dataset ... 
copy_dataset len === 311
[32m[NeMo I 2023-10-13 22:21:54 t5_speechlm_dataset:222][39m After Process len(self.examples) 203 311
[32m[NeMo I 2023-10-13 22:21:54 t5_speechlm_dataset:223][39m Skipped 108 sentences, sequence length too short or too long even after truncation
build success 50 ['/datap/misc/manifests/manifests/libritts/val_clean_300_speechlm_ttstasks.json']
[32m[NeMo I 2023-10-13 22:21:54 modelPT:728][39m Optimizer config = MegatronDistributedFusedAdam (
    Parameter Group 0
        betas: [0.9, 0.98]
        bias_correction: True
        eps: 1e-08
        lr: 1e-05
        weight_decay: 0.01
    
    Parameter Group 1
        betas: [0.9, 0.98]
        bias_correction: True
        eps: 1e-08
        lr: 1e-05
        weight_decay: 0.0
    )
[32m[NeMo I 2023-10-13 22:21:54 lr_scheduler:910][39m Scheduler "<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7fa7182b39d0>" 
    will be used during training (effective maximum steps = 600000) - 
    Parameters : 
    (warmup_steps: 500
    constant_steps: 50000
    min_lr: 1.0e-06
    max_steps: 600000
    )
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/600000 [00:00<?]Epoch 0: :   0%|          | 0/600000 [00:00<?]loss mask original None

First layer loss:  0.06758953630924225 torch.Size([565, 4]) 6.851992607116699 0.0
Max loss timestep torch.Size([565, 4]) tensor([ 81, 436, 527, 115], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.028799807652831078
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 1 loss 0.08693210035562515
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 2 loss 0.07547976821660995
speech mask sum tensor(480, device='cuda:0') loss mask sum tensor(480, device='cuda:0')
bi 3 loss 0.03135547414422035
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
logits torch.Size([565, 4, 257024]) labels torch.Size([565, 4]) 0 257022
Layer  0  loss:  0.06676534563302994 0.0 6.71134090423584
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([ 79, 436, 527, 150], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.023395901545882225
bi 1 loss 0.07351962476968765
bi 2 loss 0.08000484853982925
bi 3 loss 0.0374232642352581
Layer  1  loss:  0.07216930389404297 0.0 5.290509223937988
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([ 81, 436, 268, 128], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.035266801714897156
bi 1 loss 0.0946953147649765
bi 2 loss 0.07125971466302872
bi 3 loss 0.05686844140291214
Layer  2  loss:  0.06650260835886002 0.0 6.488879680633545
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([108, 436, 268, 166], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.019494302570819855
bi 1 loss 0.0657699778676033
bi 2 loss 0.08393008261919022
bi 3 loss 0.03862681984901428
Layer  3  loss:  0.09621449559926987 0.0 9.288743019104004
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([112, 436, 530, 192], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.0374162383377552
bi 1 loss 0.09350425004959106
bi 2 loss 0.12663888931274414
bi 3 loss 0.03763193264603615
Layer  4  loss:  0.07375872135162354 0.0 5.146410942077637
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([113, 434, 527, 165], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.045538708567619324
bi 1 loss 0.07399182766675949
bi 2 loss 0.09222375601530075
bi 3 loss 0.031116390600800514
Layer  5  loss:  0.09823337942361832 0.0 4.989534378051758
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([ 86, 428, 526, 169], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.03206588700413704
bi 1 loss 0.09234464168548584
bi 2 loss 0.13188131153583527
bi 3 loss 0.03887790068984032
Layer  6  loss:  0.08631445467472076 0.0 9.103154182434082
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([ 82, 436, 526, 191], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.0279471967369318
bi 1 loss 0.09637636691331863
bi 2 loss 0.1058107390999794
bi 3 loss 0.04000381752848625
Logging training audio
Epoch 0: :   3%|▎         | 15001/600000 [00:01<01:04]Epoch 0: :   3%|▎         | 15001/600000 [00:01<01:04, v_num=12, reduced_train_loss=0.628, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=1.630]loss mask original None

First layer loss:  0.11034546792507172 torch.Size([526, 4]) 3.621389627456665 0.0
Max loss timestep torch.Size([526, 4]) tensor([289, 276, 261, 130], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.08681372553110123
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 1 loss 0.11598561704158783
speech mask sum tensor(98, device='cuda:0') loss mask sum tensor(98, device='cuda:0')
bi 2 loss 0.12838752567768097
speech mask sum tensor(411, device='cuda:0') loss mask sum tensor(411, device='cuda:0')
bi 3 loss 0.0812712162733078
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
logits torch.Size([526, 4, 257024]) labels torch.Size([526, 4]) 0 257023
Layer  0  loss:  0.0969022810459137 0.0 4.2290873527526855
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1023
Curr loss timestep torch.Size([526, 4]) tensor([380, 257, 516, 120], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.07572563737630844
bi 1 loss 0.10504060983657837
bi 2 loss 0.11370691657066345
bi 3 loss 0.06398220360279083
Layer  1  loss:  0.10310511291027069 0.0 4.883720397949219
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([287, 276, 283, 123], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.08858270198106766
bi 1 loss 0.0790318101644516
bi 2 loss 0.11875986307859421
bi 3 loss 0.09582646191120148
Layer  2  loss:  0.09875694662332535 0.0 3.0347676277160645
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([286, 275, 495, 156], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.07379704713821411
bi 1 loss 0.07353445887565613
bi 2 loss 0.12901702523231506
bi 3 loss 0.04876013472676277
Layer  3  loss:  0.11588498204946518 0.0 6.128993034362793
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1023
Curr loss timestep torch.Size([526, 4]) tensor([287, 274, 495, 112], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.12466848641633987
bi 1 loss 0.08294741809368134
bi 2 loss 0.1331939399242401
bi 3 loss 0.03989868983626366
Layer  4  loss:  0.09621695429086685 0.0 5.217406272888184
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([289, 275, 360, 126], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.0876355916261673
bi 1 loss 0.05942245572805405
bi 2 loss 0.12063434720039368
bi 3 loss 0.04100703448057175
Layer  5  loss:  0.12652182579040527 0.0 8.15744400024414
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1023
Curr loss timestep torch.Size([526, 4]) tensor([286, 275, 360, 135], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.1127701923251152
bi 1 loss 0.10572092980146408
bi 2 loss 0.15384460985660553
bi 3 loss 0.05212903767824173
Layer  6  loss:  0.10984599590301514 0.0 6.962360382080078
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1023
Curr loss timestep torch.Size([526, 4]) tensor([289, 265, 511, 164], device='cuda:0') tensor(511, device='cuda:0')
bi 0 loss 0.09188514947891235
bi 1 loss 0.09891286492347717
bi 2 loss 0.13069990277290344
bi 3 loss 0.0697074607014656
Epoch 0: :   3%|▎         | 15002/600000 [00:02<01:20, v_num=12, reduced_train_loss=0.628, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=1.630]Epoch 0: :   3%|▎         | 15002/600000 [00:02<01:20, v_num=12, reduced_train_loss=0.858, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.360]loss mask original None

First layer loss:  4.195131301879883 torch.Size([556, 4]) 9.92136001586914 0.0
Max loss timestep torch.Size([556, 4]) tensor([196,  57, 137, 110], device='cuda:0') tensor(137, device='cuda:0')
bi 0 loss 4.278115272521973
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
bi 1 loss 3.6149837970733643
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 2 loss 4.0458574295043945
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 3 loss 4.359980583190918
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
logits torch.Size([556, 4, 257024]) labels torch.Size([556, 4]) 0 257023
Layer  0  loss:  4.665727615356445 0.0 10.573184967041016
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([137,  67, 145, 471], device='cuda:0') tensor(137, device='cuda:0')
bi 0 loss 4.759022235870361
bi 1 loss 4.300861835479736
bi 2 loss 4.461552143096924
bi 3 loss 4.796771049499512
Layer  1  loss:  4.865409851074219 0.0 11.32972240447998
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([201,  82, 137, 490], device='cuda:0') tensor(137, device='cuda:0')
bi 0 loss 5.017177104949951
bi 1 loss 4.486602783203125
bi 2 loss 4.797489643096924
bi 3 loss 4.930050849914551
Layer  2  loss:  5.240809440612793 0.0 10.759050369262695
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([132,  96, 160, 145], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 5.236391067504883
bi 1 loss 4.824893474578857
bi 2 loss 5.104129314422607
bi 3 loss 5.39097261428833
Layer  3  loss:  5.253312110900879 0.0 11.797493934631348
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([211, 151, 287, 300], device='cuda:0') tensor(127, device='cuda:0')
bi 0 loss 5.279333114624023
bi 1 loss 4.815934658050537
bi 2 loss 5.302864074707031
bi 3 loss 5.329535007476807
Layer  4  loss:  5.38988733291626 0.0 11.417065620422363
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([223, 133, 158, 457], device='cuda:0') tensor(141, device='cuda:0')
bi 0 loss 5.2357378005981445
bi 1 loss 4.8272786140441895
bi 2 loss 5.484588623046875
bi 3 loss 5.538081645965576
Layer  5  loss:  5.5144476890563965 0.0 11.72717571258545
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([138, 127, 141, 468], device='cuda:0') tensor(141, device='cuda:0')
bi 0 loss 5.430397987365723
bi 1 loss 4.959006309509277
bi 2 loss 5.514782905578613
bi 3 loss 5.672893524169922
Layer  6  loss:  5.485976219177246 0.0 10.408007621765137
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1020
Curr loss timestep torch.Size([556, 4]) tensor([173,  77, 197, 247], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 5.335813999176025
bi 1 loss 4.9290924072265625
bi 2 loss 5.6356353759765625
bi 3 loss 5.611148357391357
High loss detected
Logging training audio
Epoch 0: :   3%|▎         | 15003/600000 [00:02<01:46, v_num=12, reduced_train_loss=0.858, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.360]Epoch 0: :   3%|▎         | 15003/600000 [00:02<01:46, v_num=12, reduced_train_loss=40.60, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.628]loss mask original None

First layer loss:  0.11408092826604843 torch.Size([547, 4]) 6.379602909088135 0.0
Max loss timestep torch.Size([547, 4]) tensor([321, 338, 268, 505], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.13339866697788239
speech mask sum tensor(428, device='cuda:0') loss mask sum tensor(428, device='cuda:0')
bi 1 loss 0.10534615069627762
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 2 loss 0.061320528388023376
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 3 loss 0.13109613955020905
speech mask sum tensor(487, device='cuda:0') loss mask sum tensor(487, device='cuda:0')
logits torch.Size([547, 4, 257024]) labels torch.Size([547, 4]) 0 257023
Layer  0  loss:  0.12590888142585754 0.0 8.726770401000977
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([399, 520, 195, 444], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.12112641334533691
bi 1 loss 0.14492212235927582
bi 2 loss 0.04784293472766876
bi 3 loss 0.15673409402370453
Layer  1  loss:  0.1345912218093872 0.0 7.837944507598877
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([320, 517, 173, 505], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.1309175193309784
bi 1 loss 0.21585623919963837
bi 2 loss 0.03943062573671341
bi 3 loss 0.1272122859954834
Layer  2  loss:  0.1424981951713562 0.0 11.156595230102539
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([321, 517, 193, 505], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.14849315583705902
bi 1 loss 0.16926482319831848
bi 2 loss 0.0483802892267704
bi 3 loss 0.16647633910179138
Layer  3  loss:  0.14082901179790497 0.0 10.250468254089355
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1021
Curr loss timestep torch.Size([547, 4]) tensor([320, 521, 294, 511], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.15325765311717987
bi 1 loss 0.18800899386405945
bi 2 loss 0.050704050809144974
bi 3 loss 0.1419384777545929
Layer  4  loss:  0.1603405475616455 0.0 9.780876159667969
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([451, 520, 161, 505], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.16679738461971283
bi 1 loss 0.17996786534786224
bi 2 loss 0.06291697174310684
bi 3 loss 0.19092905521392822
Layer  5  loss:  0.14263126254081726 0.0 8.380794525146484
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([451, 520, 129, 524], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.1717713326215744
bi 1 loss 0.1737959235906601
bi 2 loss 0.05315181240439415
bi 3 loss 0.1405889093875885
Layer  6  loss:  0.15348920226097107 0.0 9.986540794372559
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1021
Curr loss timestep torch.Size([547, 4]) tensor([455, 521, 276, 505], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.11852505058050156
bi 1 loss 0.24872387945652008
bi 2 loss 0.04915083944797516
bi 3 loss 0.16804131865501404
Epoch 0: :   3%|▎         | 15004/600000 [00:03<02:01, v_num=12, reduced_train_loss=40.60, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.628]Epoch 0: :   3%|▎         | 15004/600000 [00:03<02:01, v_num=12, reduced_train_loss=1.110, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.366]loss mask original None

First layer loss:  0.06041876599192619 torch.Size([499, 4]) 4.225064277648926 0.0
Max loss timestep torch.Size([499, 4]) tensor([348, 327, 205, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.054044682532548904
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 1 loss 0.041193846613168716
speech mask sum tensor(377, device='cuda:0') loss mask sum tensor(377, device='cuda:0')
bi 2 loss 0.04085470363497734
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 3 loss 0.10002203285694122
speech mask sum tensor(331, device='cuda:0') loss mask sum tensor(331, device='cuda:0')
logits torch.Size([499, 4, 257024]) labels torch.Size([499, 4]) 0 257023
Layer  0  loss:  0.05980653688311577 0.0 8.697015762329102
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([346, 202, 208, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.04888508468866348
bi 1 loss 0.05091378465294838
bi 2 loss 0.03387097641825676
bi 3 loss 0.09548409283161163
Layer  1  loss:  0.05780578404664993 0.0 9.632682800292969
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([346, 379,  79, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.05650972202420235
bi 1 loss 0.04091356694698334
bi 2 loss 0.02810259722173214
bi 3 loss 0.09688927978277206
Layer  2  loss:  0.05567019805312157 0.0 3.4666907787323
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([346, 379,  67, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.05206265673041344
bi 1 loss 0.04594104737043381
bi 2 loss 0.031182749196887016
bi 3 loss 0.08524320274591446
Layer  3  loss:  0.06954449415206909 0.0 7.691898345947266
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([346, 199, 130, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.07003608345985413
bi 1 loss 0.05240582674741745
bi 2 loss 0.03936377912759781
bi 3 loss 0.10770878195762634
Layer  4  loss:  0.06440469622612 0.0 9.365156173706055
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([348, 427, 192, 402], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.05195673927664757
bi 1 loss 0.050711411982774734
bi 2 loss 0.03533094748854637
bi 3 loss 0.10881351679563522
Layer  5  loss:  0.060005832463502884 0.0 6.8159332275390625
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([348, 327, 158, 360], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.08244367688894272
bi 1 loss 0.04387100040912628
bi 2 loss 0.028849542140960693
bi 3 loss 0.07921060174703598
Layer  6  loss:  0.05577956140041351 0.0 2.614370107650757
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([324, 188, 206, 402], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.05485183000564575
bi 1 loss 0.0348280593752861
bi 2 loss 0.033187899738550186
bi 3 loss 0.09468677639961243
Epoch 0: :   3%|▎         | 15005/600000 [00:03<02:16, v_num=12, reduced_train_loss=1.110, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.366]Epoch 0: :   3%|▎         | 15005/600000 [00:03<02:16, v_num=12, reduced_train_loss=0.483, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.345]loss mask original None

First layer loss:  0.08305256068706512 torch.Size([602, 4]) 4.865915298461914 0.0
Max loss timestep torch.Size([602, 4]) tensor([251, 345, 554,  68], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.04177136719226837
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
bi 1 loss 0.0872504860162735
speech mask sum tensor(246, device='cuda:0') loss mask sum tensor(246, device='cuda:0')
bi 2 loss 0.12087693810462952
speech mask sum tensor(414, device='cuda:0') loss mask sum tensor(414, device='cuda:0')
bi 3 loss 0.037523381412029266
speech mask sum tensor(120, device='cuda:0') loss mask sum tensor(120, device='cuda:0')
logits torch.Size([602, 4, 257024]) labels torch.Size([602, 4]) 0 257023
Layer  0  loss:  0.08650583028793335 0.0 6.534627437591553
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1023
Curr loss timestep torch.Size([602, 4]) tensor([388, 333, 356,  87], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.10877687484025955
bi 1 loss 0.06208723783493042
bi 2 loss 0.10324065387248993
bi 3 loss 0.028347769752144814
Layer  1  loss:  0.0803775042295456 0.0 5.638699531555176
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1023
Curr loss timestep torch.Size([602, 4]) tensor([339, 286, 327,  55], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.07357233762741089
bi 1 loss 0.07619751244783401
bi 2 loss 0.09735722839832306
bi 3 loss 0.045791495591402054
Layer  2  loss:  0.07770908623933792 0.0 3.4758434295654297
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1022
Curr loss timestep torch.Size([602, 4]) tensor([272, 329, 335, 134], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.05214868485927582
bi 1 loss 0.06008771434426308
bi 2 loss 0.11738073825836182
bi 3 loss 0.034902650862932205
Layer  3  loss:  0.08101560920476913 0.0 6.573553085327148
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1019
Curr loss timestep torch.Size([602, 4]) tensor([272, 345, 551, 110], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.07607591152191162
bi 1 loss 0.07808545231819153
bi 2 loss 0.09710435569286346
bi 3 loss 0.042712949216365814
Layer  4  loss:  0.08580366522073746 0.0 8.598527908325195
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1022
Curr loss timestep torch.Size([602, 4]) tensor([339, 345, 357,  53], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.08855269849300385
bi 1 loss 0.06668668240308762
bi 2 loss 0.10633067786693573
bi 3 loss 0.04794416204094887
Layer  5  loss:  0.09483476728200912 0.0 5.913615703582764
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1022
Curr loss timestep torch.Size([602, 4]) tensor([272, 345, 356, 144], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.0728035569190979
bi 1 loss 0.06266487389802933
bi 2 loss 0.14348727464675903
bi 3 loss 0.042869336903095245
Layer  6  loss:  0.09765882045030594 0.0 8.173053741455078
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1019
Curr loss timestep torch.Size([602, 4]) tensor([339, 345, 259,  75], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.07257592678070068
bi 1 loss 0.08646407723426819
bi 2 loss 0.1370648443698883
bi 3 loss 0.041511841118335724
Epoch 0: :   3%|▎         | 15006/600000 [00:03<02:33, v_num=12, reduced_train_loss=0.483, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.345]Epoch 0: :   3%|▎         | 15006/600000 [00:03<02:33, v_num=12, reduced_train_loss=0.687, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.405]loss mask original None

First layer loss:  0.06772046536207199 torch.Size([535, 4]) 3.9124691486358643 0.0
Max loss timestep torch.Size([535, 4]) tensor([417, 188, 119, 282], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.08988864719867706
speech mask sum tensor(346, device='cuda:0') loss mask sum tensor(346, device='cuda:0')
bi 1 loss 0.03721414878964424
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 2 loss 0.043320395052433014
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 3 loss 0.06756683439016342
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
logits torch.Size([535, 4, 257024]) labels torch.Size([535, 4]) 0 257022
Layer  0  loss:  0.07304282486438751 0.0 4.5173516273498535
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([414, 104,  74, 252], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.10773849487304688
bi 1 loss 0.038351405411958694
bi 2 loss 0.026479758322238922
bi 3 loss 0.060602277517318726
Layer  1  loss:  0.0918649435043335 0.0 4.683272838592529
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([414,  78, 116, 327], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.12188001722097397
bi 1 loss 0.0427875742316246
bi 2 loss 0.0323447622358799
bi 3 loss 0.1212937980890274
Layer  2  loss:  0.07270034402608871 0.0 3.875786304473877
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([378,  79, 102, 323], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.11092587560415268
bi 1 loss 0.03155163303017616
bi 2 loss 0.042561814188957214
bi 3 loss 0.04802098125219345
Layer  3  loss:  0.08966672420501709 0.0 5.317881107330322
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([435,  98,  93, 351], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.1355464607477188
bi 1 loss 0.03686073422431946
bi 2 loss 0.025662893429398537
bi 3 loss 0.08458411693572998
Layer  4  loss:  0.07834180444478989 0.0 8.991281509399414
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([414, 166, 113, 346], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.12004488706588745
bi 1 loss 0.022539274767041206
bi 2 loss 0.03763518109917641
bi 3 loss 0.07215341925621033
Layer  5  loss:  0.08694365620613098 0.0 6.166342258453369
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([436, 108, 105, 351], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.12132679671049118
bi 1 loss 0.028135886415839195
bi 2 loss 0.03836460039019585
bi 3 loss 0.11031794548034668
Layer  6  loss:  0.06524594873189926 0.0 7.423327445983887
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1021
Curr loss timestep torch.Size([535, 4]) tensor([414,  82, 105, 343], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.09373612701892853
bi 1 loss 0.02360834926366806
bi 2 loss 0.02699161320924759
bi 3 loss 0.07333217561244965
Epoch 0: :   3%|▎         | 15007/600000 [00:04<02:50, v_num=12, reduced_train_loss=0.687, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.405]Epoch 0: :   3%|▎         | 15007/600000 [00:04<02:50, v_num=12, reduced_train_loss=0.626, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.379]loss mask original None

First layer loss:  0.12920919060707092 torch.Size([619, 4]) 8.871321678161621 0.0
Max loss timestep torch.Size([619, 4]) tensor([ 90,  43, 120, 473], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.039691656827926636
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 1 loss 0.01780674234032631
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 2 loss 0.045887600630521774
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
bi 3 loss 0.19355010986328125
speech mask sum tensor(443, device='cuda:0') loss mask sum tensor(443, device='cuda:0')
logits torch.Size([619, 4, 257024]) labels torch.Size([619, 4]) 0 257023
Layer  0  loss:  0.11293869465589523 0.0 8.537820816040039
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([ 97,  25, 145, 470], device='cuda:0') tensor(470, device='cuda:0')
bi 0 loss 0.026652755215764046
bi 1 loss 0.023690801113843918
bi 2 loss 0.0283319354057312
bi 3 loss 0.17375747859477997
Layer  1  loss:  0.13218148052692413 0.0 10.830711364746094
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([162,  31, 127, 470], device='cuda:0') tensor(470, device='cuda:0')
bi 0 loss 0.046941906213760376
bi 1 loss 0.027361426502466202
bi 2 loss 0.042369965463876724
bi 3 loss 0.19692400097846985
Layer  2  loss:  0.13957078754901886 0.0 9.147944450378418
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([130,  58, 176, 470], device='cuda:0') tensor(470, device='cuda:0')
bi 0 loss 0.03423672541975975
bi 1 loss 0.048671603202819824
bi 2 loss 0.02418750338256359
bi 3 loss 0.21535968780517578
Layer  3  loss:  0.1587826907634735 0.0 8.971418380737305
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1021
Curr loss timestep torch.Size([619, 4]) tensor([113,  60, 156, 473], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.049325570464134216
bi 1 loss 0.013469735160470009
bi 2 loss 0.0268452949821949
bi 3 loss 0.24932675063610077
Layer  4  loss:  0.16844403743743896 0.0 9.133885383605957
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1021
Curr loss timestep torch.Size([619, 4]) tensor([131,  45, 122, 473], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.06252758204936981
bi 1 loss 0.0216502845287323
bi 2 loss 0.04500172659754753
bi 3 loss 0.25550106167793274
Layer  5  loss:  0.16717199981212616 0.0 10.908393859863281
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1017
Curr loss timestep torch.Size([619, 4]) tensor([105,  54,  60, 473], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.03154608607292175
bi 1 loss 0.04181276634335518
bi 2 loss 0.030158568173646927
bi 3 loss 0.26195386052131653
Layer  6  loss:  0.14934101700782776 0.0 7.230733394622803
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([150,  64,  99, 470], device='cuda:0') tensor(470, device='cuda:0')
bi 0 loss 0.03269166499376297
bi 1 loss 0.023470746353268623
bi 2 loss 0.026653973385691643
bi 3 loss 0.235245481133461
Epoch 0: :   3%|▎         | 15008/600000 [00:04<03:07, v_num=12, reduced_train_loss=0.626, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.379]Epoch 0: :   3%|▎         | 15008/600000 [00:04<03:07, v_num=12, reduced_train_loss=1.160, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.414]loss mask original None

First layer loss:  0.18911640346050262 torch.Size([642, 4]) 9.295023918151855 0.0
Max loss timestep torch.Size([642, 4]) tensor([205, 393, 397, 267], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.09933719038963318
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 1 loss 0.24274152517318726
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 2 loss 0.2240433692932129
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
bi 3 loss 0.08533277362585068
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
logits torch.Size([642, 4, 257024]) labels torch.Size([642, 4]) 0 257023
Layer  0  loss:  0.1982930302619934 0.0 13.093826293945312
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([303, 393, 279, 267], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.0638207420706749
bi 1 loss 0.26724815368652344
bi 2 loss 0.23857274651527405
bi 3 loss 0.08696611225605011
Layer  1  loss:  0.21052441000938416 0.0 10.921100616455078
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([304, 393, 397, 352], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.07865690439939499
bi 1 loss 0.2945637106895447
bi 2 loss 0.2439747154712677
bi 3 loss 0.0732489675283432
Layer  2  loss:  0.2277725785970688 0.0 7.434780597686768
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1022
Curr loss timestep torch.Size([642, 4]) tensor([260, 371, 394, 352], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.05485120415687561
bi 1 loss 0.31260931491851807
bi 2 loss 0.2631323039531708
bi 3 loss 0.11832215636968613
Layer  3  loss:  0.21828405559062958 0.0 16.12501335144043
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([148, 393, 397, 267], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.06134456768631935
bi 1 loss 0.2549460828304291
bi 2 loss 0.32220444083213806
bi 3 loss 0.10135084390640259
Layer  4  loss:  0.2243192046880722 0.0 8.616470336914062
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1022
Curr loss timestep torch.Size([642, 4]) tensor([304, 393, 395, 264], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.10014107823371887
bi 1 loss 0.30686986446380615
bi 2 loss 0.27285709977149963
bi 3 loss 0.06138673424720764
Layer  5  loss:  0.2582079768180847 0.0 12.612751960754395
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([303, 411, 397, 267], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.08520802110433578
bi 1 loss 0.36736130714416504
bi 2 loss 0.30856895446777344
bi 3 loss 0.07076212763786316
Layer  6  loss:  0.24896514415740967 0.0 13.350103378295898
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([304, 393, 279, 264], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.09396126866340637
bi 1 loss 0.35804063081741333
bi 2 loss 0.2590685784816742
bi 3 loss 0.10865320265293121
Epoch 0: :   3%|▎         | 15009/600000 [00:05<03:25, v_num=12, reduced_train_loss=1.160, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.414]Epoch 0: :   3%|▎         | 15009/600000 [00:05<03:25, v_num=12, reduced_train_loss=1.780, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.429]loss mask original None

First layer loss:  0.1888817399740219 torch.Size([645, 4]) 10.094670295715332 0.0
Max loss timestep torch.Size([645, 4]) tensor([565, 481, 265,  85], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.20341268181800842
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
bi 1 loss 0.1495058834552765
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 2 loss 0.23872250318527222
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 3 loss 0.05205044150352478
speech mask sum tensor(54, device='cuda:0') loss mask sum tensor(54, device='cuda:0')
logits torch.Size([645, 4, 257024]) labels torch.Size([645, 4]) 0 257022
Layer  0  loss:  0.21287080645561218 0.0 9.765674591064453
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1023
Curr loss timestep torch.Size([645, 4]) tensor([569, 481, 265,  78], device='cuda:0') tensor(569, device='cuda:0')
bi 0 loss 0.29024243354797363
bi 1 loss 0.1004309356212616
bi 2 loss 0.18712833523750305
bi 3 loss 0.06952923536300659
Layer  1  loss:  0.20818082988262177 0.0 10.533342361450195
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([570, 361, 323,  61], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.248048797249794
bi 1 loss 0.20024843513965607
bi 2 loss 0.1664731353521347
bi 3 loss 0.05347444489598274
Layer  2  loss:  0.26164770126342773 0.0 7.719874382019043
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([570, 372, 263,  83], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.3319295048713684
bi 1 loss 0.12071503698825836
bi 2 loss 0.30594852566719055
bi 3 loss 0.050554823130369186
Layer  3  loss:  0.2527831196784973 0.0 12.749151229858398
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([565, 447, 263,  53], device='cuda:0') tensor(565, device='cuda:0')
bi 0 loss 0.3304142951965332
bi 1 loss 0.13991780579090118
bi 2 loss 0.2474338263273239
bi 3 loss 0.044653043150901794
Layer  4  loss:  0.27439257502555847 0.0 14.407095909118652
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([565, 424, 264,  70], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.3410528004169464
bi 1 loss 0.16358128190040588
bi 2 loss 0.29721808433532715
bi 3 loss 0.05670734867453575
Layer  5  loss:  0.27705180644989014 0.0 9.724106788635254
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([565, 373, 263,  60], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.3899883031845093
bi 1 loss 0.1414693146944046
bi 2 loss 0.2161455899477005
bi 3 loss 0.04401779547333717
Layer  6  loss:  0.29411131143569946 0.0 16.54800033569336
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([570, 481, 263,  65], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.40466928482055664
bi 1 loss 0.1486227661371231
bi 2 loss 0.25710925459861755
bi 3 loss 0.03825349360704422
Epoch 0: :   3%|▎         | 15010/600000 [00:05<03:49, v_num=12, reduced_train_loss=1.780, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.429]Epoch 0: :   3%|▎         | 15010/600000 [00:05<03:49, v_num=12, reduced_train_loss=1.970, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.573]loss mask original None

First layer loss:  0.17939694225788116 torch.Size([639, 4]) 14.873418807983398 0.0
Max loss timestep torch.Size([639, 4]) tensor([301,  59, 160, 575], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.4953220784664154
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 1 loss 0.02672024443745613
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 2 loss 0.10170397162437439
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 3 loss 0.1991696059703827
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
logits torch.Size([639, 4, 257024]) labels torch.Size([639, 4]) 0 257022
Layer  0  loss:  0.19097431004047394 0.0 11.29133129119873
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1023
Curr loss timestep torch.Size([639, 4]) tensor([298,  67, 271, 589], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.4624374508857727
bi 1 loss 0.06314217299222946
bi 2 loss 0.08271715044975281
bi 3 loss 0.2334427833557129
Layer  1  loss:  0.18756867945194244 0.0 12.654034614562988
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1023
Curr loss timestep torch.Size([639, 4]) tensor([300, 119, 320, 527], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.414328932762146
bi 1 loss 0.018786311149597168
bi 2 loss 0.08037292957305908
bi 3 loss 0.24793703854084015
Layer  2  loss:  0.21313531696796417 0.0 15.392353057861328
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([301, 120, 395, 284], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.632042407989502
bi 1 loss 0.057163305580616
bi 2 loss 0.07818028330802917
bi 3 loss 0.24884766340255737
Layer  3  loss:  0.18823648989200592 0.0 20.383075714111328
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([298, 110, 319, 574], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.6094966530799866
bi 1 loss 0.050188738852739334
bi 2 loss 0.0796654000878334
bi 3 loss 0.20264694094657898
Layer  4  loss:  0.21171675622463226 0.0 16.180648803710938
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([301, 108, 315, 589], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.6971975564956665
bi 1 loss 0.03341245278716087
bi 2 loss 0.0763934999704361
bi 3 loss 0.23920400440692902
Layer  5  loss:  0.21249936521053314 0.0 15.094208717346191
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1023
Curr loss timestep torch.Size([639, 4]) tensor([301, 126, 303, 589], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.5734044909477234
bi 1 loss 0.035676367580890656
bi 2 loss 0.0998779758810997
bi 3 loss 0.250740647315979
Layer  6  loss:  0.21146714687347412 0.0 17.781339645385742
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([309,  61, 363, 589], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.6304647326469421
bi 1 loss 0.031003344804048538
bi 2 loss 0.07324781268835068
bi 3 loss 0.2548697292804718
Epoch 0: :   3%|▎         | 15011/600000 [00:06<04:07, v_num=12, reduced_train_loss=1.970, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.573]Epoch 0: :   3%|▎         | 15011/600000 [00:06<04:07, v_num=12, reduced_train_loss=1.590, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.429]loss mask original None

First layer loss:  0.1826462745666504 torch.Size([623, 4]) 16.581924438476562 0.0
Max loss timestep torch.Size([623, 4]) tensor([365, 329, 513, 198], device='cuda:0') tensor(513, device='cuda:0')
bi 0 loss 0.08493851870298386
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 1 loss 0.24306313693523407
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 2 loss 0.23209945857524872
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
bi 3 loss 0.04513315483927727
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
logits torch.Size([623, 4, 257024]) labels torch.Size([623, 4]) 0 257022
Layer  0  loss:  0.1897953599691391 0.0 10.703807830810547
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([362, 328, 514, 113], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.17267608642578125
bi 1 loss 0.25632530450820923
bi 2 loss 0.19464488327503204
bi 3 loss 0.08223312348127365
Layer  1  loss:  0.243526428937912 0.0 14.119634628295898
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([262, 329, 406, 256], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.32717862725257874
bi 1 loss 0.2603089511394501
bi 2 loss 0.25851917266845703
bi 3 loss 0.0970548689365387
Layer  2  loss:  0.2537585198879242 0.0 12.447226524353027
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([263, 328, 560, 208], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.365195631980896
bi 1 loss 0.30467936396598816
bi 2 loss 0.2511798143386841
bi 3 loss 0.06984705477952957
Layer  3  loss:  0.27047446370124817 0.0 16.77146339416504
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([263, 328, 513, 151], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.29866644740104675
bi 1 loss 0.3166513741016388
bi 2 loss 0.3082914650440216
bi 3 loss 0.06783641874790192
Layer  4  loss:  0.2815541625022888 0.0 14.601536750793457
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([262, 328, 560, 137], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.39560091495513916
bi 1 loss 0.2963162064552307
bi 2 loss 0.3166680634021759
bi 3 loss 0.057086024433374405
Layer  5  loss:  0.25716376304626465 0.0 13.156784057617188
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([263, 329, 408, 257], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.34975484013557434
bi 1 loss 0.3064210116863251
bi 2 loss 0.2762258052825928
bi 3 loss 0.037352077662944794
Layer  6  loss:  0.2534343898296356 0.0 14.97590160369873
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([263, 562, 515, 257], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.38571134209632874
bi 1 loss 0.32059741020202637
bi 2 loss 0.23803077638149261
bi 3 loss 0.056152891367673874
Epoch 0: :   3%|▎         | 15012/600000 [00:06<04:25, v_num=12, reduced_train_loss=1.590, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.429]Epoch 0: :   3%|▎         | 15012/600000 [00:06<04:25, v_num=12, reduced_train_loss=1.930, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.411]loss mask original None

First layer loss:  0.1901782602071762 torch.Size([617, 4]) 8.909913063049316 0.0
Max loss timestep torch.Size([617, 4]) tensor([304,  43, 589, 321], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.31821408867836
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 1 loss 0.052862461656332016
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 2 loss 0.16107496619224548
speech mask sum tensor(431, device='cuda:0') loss mask sum tensor(431, device='cuda:0')
bi 3 loss 0.18393558263778687
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
logits torch.Size([617, 4, 257024]) labels torch.Size([617, 4]) 0 257022
Layer  0  loss:  0.2367994636297226 0.0 10.82611083984375
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([304,  34, 585, 276], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.4591020941734314
bi 1 loss 0.036674994975328445
bi 2 loss 0.21153992414474487
bi 3 loss 0.14718598127365112
Layer  1  loss:  0.20731167495250702 0.0 12.711136817932129
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([304,  35, 589, 274], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.31009548902511597
bi 1 loss 0.025345131754875183
bi 2 loss 0.2045699506998062
bi 3 loss 0.17234501242637634
Layer  2  loss:  0.25595828890800476 0.0 15.898544311523438
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([304,  49, 589, 276], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.4257384240627289
bi 1 loss 0.03861435502767563
bi 2 loss 0.24508103728294373
bi 3 loss 0.18703879415988922
Layer  3  loss:  0.21438618004322052 0.0 12.343923568725586
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([368,  52, 589, 276], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.3497565984725952
bi 1 loss 0.03684603422880173
bi 2 loss 0.1950061172246933
bi 3 loss 0.18881885707378387
Layer  4  loss:  0.21964454650878906 0.0 14.66639518737793
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([305,  41, 589, 276], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.2956925928592682
bi 1 loss 0.03317329287528992
bi 2 loss 0.22595886886119843
bi 3 loss 0.18925973773002625
Layer  5  loss:  0.23205843567848206 0.0 11.875947952270508
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([305,  49, 585, 276], device='cuda:0') tensor(585, device='cuda:0')
bi 0 loss 0.31101834774017334
bi 1 loss 0.10565837472677231
bi 2 loss 0.21734508872032166
bi 3 loss 0.23366479575634003
Layer  6  loss:  0.2129627913236618 0.0 14.218793869018555
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([369,  38, 589, 274], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.3225531280040741
bi 1 loss 0.08627089858055115
bi 2 loss 0.206658735871315
bi 3 loss 0.16206997632980347
Epoch 0: :   3%|▎         | 15013/600000 [00:07<04:42, v_num=12, reduced_train_loss=1.930, global_step=1.5e+4, consumed_samples=6e+4, train_step_timing in s=0.411]Epoch 0: :   3%|▎         | 15013/600000 [00:07<04:42, v_num=12, reduced_train_loss=1.770, global_step=1.5e+4, consumed_samples=60052.0, train_step_timing in s=0.410]loss mask original None

First layer loss:  0.05020187050104141 torch.Size([447, 4]) 6.738804817199707 0.0
Max loss timestep torch.Size([447, 4]) tensor([117, 126, 146, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.028944116085767746
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 1 loss 0.09271886199712753
speech mask sum tensor(110, device='cuda:0') loss mask sum tensor(110, device='cuda:0')
bi 2 loss 0.050588786602020264
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
bi 3 loss 0.045117102563381195
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
logits torch.Size([447, 4, 257024]) labels torch.Size([447, 4]) 0 257022
Layer  0  loss:  0.03451112285256386 0.0 4.7163166999816895
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([154, 176, 191, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.031073041260242462
bi 1 loss 0.0290081724524498
bi 2 loss 0.021332189440727234
bi 3 loss 0.039853259921073914
Layer  1  loss:  0.035953816026449203 0.0 4.731287956237793
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([154, 198, 195, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.03287172690033913
bi 1 loss 0.044018086045980453
bi 2 loss 0.02063586376607418
bi 3 loss 0.03768797591328621
Layer  2  loss:  0.038088489323854446 0.0 3.050323486328125
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([129, 195, 160, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.02826046198606491
bi 1 loss 0.04283208027482033
bi 2 loss 0.028844643384218216
bi 3 loss 0.04188204184174538
Layer  3  loss:  0.04212077707052231 0.0 7.240386486053467
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([208, 157, 178, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.022586561739444733
bi 1 loss 0.022004010155797005
bi 2 loss 0.02105032280087471
bi 3 loss 0.058698203414678574
Layer  4  loss:  0.046024974435567856 0.0 7.82681131362915
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([211, 190, 140, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.021936539560556412
bi 1 loss 0.04552631080150604
bi 2 loss 0.025147704407572746
bi 3 loss 0.0584651380777359
Layer  5  loss:  0.05808311700820923 0.0 14.043299674987793
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([190, 168, 177, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.04416472092270851
bi 1 loss 0.037749361246824265
bi 2 loss 0.02183360420167446
bi 3 loss 0.07579205930233002
Layer  6  loss:  0.04480651766061783 0.0 10.958588600158691
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([129, 201, 144, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.03401893749833107
bi 1 loss 0.03287241607904434
bi 2 loss 0.01700972393155098
bi 3 loss 0.05737169459462166
Epoch 0: :   3%|▎         | 15014/600000 [00:07<04:56, v_num=12, reduced_train_loss=1.770, global_step=1.5e+4, consumed_samples=60052.0, train_step_timing in s=0.410]Epoch 0: :   3%|▎         | 15014/600000 [00:07<04:56, v_num=12, reduced_train_loss=0.350, global_step=1.5e+4, consumed_samples=60056.0, train_step_timing in s=0.319]loss mask original None

First layer loss:  0.07240140438079834 torch.Size([531, 4]) 8.160311698913574 0.0
Max loss timestep torch.Size([531, 4]) tensor([102, 260, 108, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.009716736152768135
speech mask sum tensor(53, device='cuda:0') loss mask sum tensor(53, device='cuda:0')
bi 1 loss 0.042167261242866516
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 2 loss 0.019989460706710815
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.13863347470760345
speech mask sum tensor(273, device='cuda:0') loss mask sum tensor(273, device='cuda:0')
logits torch.Size([531, 4, 257024]) labels torch.Size([531, 4]) 0 257023
Layer  0  loss:  0.07571779936552048 0.0 10.044251441955566
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1023
Curr loss timestep torch.Size([531, 4]) tensor([103, 221, 145, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.010881293565034866
bi 1 loss 0.03836360573768616
bi 2 loss 0.02194868214428425
bi 3 loss 0.14998863637447357
Layer  1  loss:  0.11006023734807968 0.0 14.982529640197754
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1021
Curr loss timestep torch.Size([531, 4]) tensor([104, 142, 141, 286], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.03374407812952995
bi 1 loss 0.05282953754067421
bi 2 loss 0.03178419917821884
bi 3 loss 0.2174728512763977
Layer  2  loss:  0.09317046403884888 0.0 15.329097747802734
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1023
Curr loss timestep torch.Size([531, 4]) tensor([101, 255, 119, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.01877528801560402
bi 1 loss 0.03989478200674057
bi 2 loss 0.026334315538406372
bi 3 loss 0.191005676984787
Layer  3  loss:  0.10535053163766861 0.0 12.196972846984863
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1017
Curr loss timestep torch.Size([531, 4]) tensor([106, 268, 126, 286], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.024055946618318558
bi 1 loss 0.05005936697125435
bi 2 loss 0.02265910431742668
bi 3 loss 0.21387964487075806
Layer  4  loss:  0.09654811769723892 0.0 16.169937133789062
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1023
Curr loss timestep torch.Size([531, 4]) tensor([108, 304, 114, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.018607473000884056
bi 1 loss 0.04597318544983864
bi 2 loss 0.021862300112843513
bi 3 loss 0.196072056889534
Layer  5  loss:  0.12180142849683762 0.0 13.1090669631958
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1018
Curr loss timestep torch.Size([531, 4]) tensor([ 97, 266,  96, 286], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.033464979380369186
bi 1 loss 0.07426479458808899
bi 2 loss 0.02526729926466942
bi 3 loss 0.23052482306957245
Layer  6  loss:  0.08770528435707092 0.0 17.172008514404297
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1023
Curr loss timestep torch.Size([531, 4]) tensor([101, 283, 115, 286], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.01981404982507229
bi 1 loss 0.054179247468709946
bi 2 loss 0.014816319569945335
bi 3 loss 0.167705699801445
Epoch 0: :   3%|▎         | 15015/600000 [00:08<05:12, v_num=12, reduced_train_loss=0.350, global_step=1.5e+4, consumed_samples=60056.0, train_step_timing in s=0.319]Epoch 0: :   3%|▎         | 15015/600000 [00:08<05:12, v_num=12, reduced_train_loss=0.763, global_step=1.5e+4, consumed_samples=60060.0, train_step_timing in s=0.361]loss mask original None

First layer loss:  0.0437004528939724 torch.Size([454, 4]) 2.623875141143799 0.0
Max loss timestep torch.Size([454, 4]) tensor([268, 324, 315, 140], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.026143360882997513
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 1 loss 0.052645668387413025
speech mask sum tensor(386, device='cuda:0') loss mask sum tensor(386, device='cuda:0')
bi 2 loss 0.05068032816052437
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 3 loss 0.01774132438004017
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
logits torch.Size([454, 4, 257024]) labels torch.Size([454, 4]) 0 257022
Layer  0  loss:  0.04435617849230766 0.0 1.9130288362503052
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([253, 425, 396, 130], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.024308515712618828
bi 1 loss 0.04736137390136719
bi 2 loss 0.05939644202589989
bi 3 loss 0.020039400085806847
Layer  1  loss:  0.05096418410539627 0.0 1.828042984008789
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([150, 338, 396,  84], device='cuda:0') tensor(150, device='cuda:0')
bi 0 loss 0.03730485588312149
bi 1 loss 0.05165215581655502
bi 2 loss 0.06664113700389862
bi 3 loss 0.022834213450551033
Layer  2  loss:  0.03889860585331917 0.0 1.4707744121551514
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([159, 260, 396,  71], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.02262275293469429
bi 1 loss 0.04571503400802612
bi 2 loss 0.045556243509054184
bi 3 loss 0.01979116164147854
Layer  3  loss:  0.04555066302418709 0.0 1.6135283708572388
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([266, 431, 389,  95], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.05390165001153946
bi 1 loss 0.0471157468855381
bi 2 loss 0.04468114301562309
bi 3 loss 0.028569873422384262
Layer  4  loss:  0.04640847072005272 0.0 2.0506796836853027
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([148, 160, 396,  91], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 0.0506368912756443
bi 1 loss 0.044310376048088074
bi 2 loss 0.0551455058157444
bi 3 loss 0.020487435162067413
Layer  5  loss:  0.04104197025299072 0.0 1.1328204870224
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([251, 426, 359, 114], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 0.026028243824839592
bi 1 loss 0.047234002500772476
bi 2 loss 0.05010369420051575
bi 3 loss 0.014815782196819782
Layer  6  loss:  0.04649735987186432 0.0 1.798119306564331
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1021
Curr loss timestep torch.Size([454, 4]) tensor([247, 338, 328,  83], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.03647446259856224
bi 1 loss 0.05455804616212845
bi 2 loss 0.049279842525720596
bi 3 loss 0.024295443668961525
Epoch 0: :   3%|▎         | 15016/600000 [00:08<05:25, v_num=12, reduced_train_loss=0.763, global_step=1.5e+4, consumed_samples=60060.0, train_step_timing in s=0.361]Epoch 0: :   3%|▎         | 15016/600000 [00:08<05:25, v_num=12, reduced_train_loss=0.357, global_step=1.5e+4, consumed_samples=60064.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.12999719381332397 torch.Size([566, 4]) 13.537659645080566 0.0
Max loss timestep torch.Size([566, 4]) tensor([264, 224, 496, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.08480115234851837
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 1 loss 0.11414133757352829
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 2 loss 0.07640901207923889
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 3 loss 0.22494538128376007
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
logits torch.Size([566, 4, 257024]) labels torch.Size([566, 4]) 0 257022
Layer  0  loss:  0.15826982259750366 0.0 8.817119598388672
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([297, 252, 305, 530], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.11659126728773117
bi 1 loss 0.11597011983394623
bi 2 loss 0.12269187718629837
bi 3 loss 0.23883415758609772
Layer  1  loss:  0.16051802039146423 0.0 15.98134708404541
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([331, 207, 305, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.11292064934968948
bi 1 loss 0.05349796265363693
bi 2 loss 0.10349220037460327
bi 3 loss 0.2884557545185089
Layer  2  loss:  0.15837587416172028 0.0 11.408257484436035
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([274, 194, 495, 471], device='cuda:0') tensor(471, device='cuda:0')
bi 0 loss 0.11534103751182556
bi 1 loss 0.04929323121905327
bi 2 loss 0.11442805081605911
bi 3 loss 0.26932650804519653
Layer  3  loss:  0.1604008674621582 0.0 11.469695091247559
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([356, 168, 304, 542], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.08542146533727646
bi 1 loss 0.03310007229447365
bi 2 loss 0.13018757104873657
bi 3 loss 0.2833107113838196
Layer  4  loss:  0.14798451960086823 0.0 17.119138717651367
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([348, 180, 496, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.07469955831766129
bi 1 loss 0.06136692687869072
bi 2 loss 0.11485562473535538
bi 3 loss 0.2606867849826813
Layer  5  loss:  0.16826660931110382 0.0 13.56252384185791
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([331, 228, 496, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.08873031288385391
bi 1 loss 0.043636810034513474
bi 2 loss 0.11346959322690964
bi 3 loss 0.32074299454689026
Layer  6  loss:  0.1578052043914795 0.0 11.314722061157227
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([331, 205, 305, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.07629481703042984
bi 1 loss 0.05192232504487038
bi 2 loss 0.09241808950901031
bi 3 loss 0.3177090883255005
Epoch 0: :   3%|▎         | 15017/600000 [00:08<05:42, v_num=12, reduced_train_loss=0.357, global_step=1.5e+4, consumed_samples=60064.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15017/600000 [00:08<05:42, v_num=12, reduced_train_loss=1.240, global_step=1.5e+4, consumed_samples=60068.0, train_step_timing in s=0.386]loss mask original None

First layer loss:  0.1875595599412918 torch.Size([669, 4]) 8.80748176574707 0.0
Max loss timestep torch.Size([669, 4]) tensor([617, 121, 147, 581], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 0.22485744953155518
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
bi 1 loss 0.6003339886665344
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
bi 2 loss 0.06113894283771515
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 3 loss 0.11202341318130493
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
logits torch.Size([669, 4, 257024]) labels torch.Size([669, 4]) 0 257023
Layer  0  loss:  0.18094654381275177 0.0 6.991726875305176
logits torch.Size([669, 4, 1024]) labels torch.Size([669, 4]) 0 1023
Curr loss timestep torch.Size([669, 4]) tensor([577,  72, 249, 585], device='cuda:0') tensor(577, device='cuda:0')
bi 0 loss 0.2721303403377533
bi 1 loss 0.0755247101187706
bi 2 loss 0.060451094061136246
bi 3 loss 0.17575514316558838
Layer  1  loss:  0.19025850296020508 0.0 10.72949504852295
logits torch.Size([669, 4, 1024]) labels torch.Size([669, 4]) 0 1023
Curr loss timestep torch.Size([669, 4]) tensor([575, 102, 249, 585], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.2622445821762085
bi 1 loss 0.14310938119888306
bi 2 loss 0.062080979347229004
bi 3 loss 0.1940481811761856
Layer  2  loss:  0.1937679648399353 0.0 6.734232425689697
logits torch.Size([669, 4, 1024]) labels torch.Size([669, 4]) 0 1022
Curr loss timestep torch.Size([669, 4]) tensor([617,  71, 274, 598], device='cuda:0') tensor(617, device='cuda:0')
bi 0 loss 0.3130922019481659
bi 1 loss 0.18369634449481964
bi 2 loss 0.07340802997350693
bi 3 loss 0.13641174137592316
Layer  3  loss:  0.20582473278045654 0.0 10.60836124420166
logits torch.Size([669, 4, 1024]) labels torch.Size([669, 4]) 0 1021
Curr loss timestep torch.Size([669, 4]) tensor([617, 105, 178, 542], device='cuda:0') tensor(617, device='cuda:0')
bi 0 loss 0.3300447463989258
bi 1 loss 0.06676243990659714
bi 2 loss 0.07394110411405563
bi 3 loss 0.18122529983520508
Layer  4  loss:  0.20233483612537384 0.0 9.797213554382324
logits torch.Size([669, 4, 1024]) labels torch.Size([669, 4]) 0 1020
Curr loss timestep torch.Size([669, 4]) tensor([575, 111, 249, 543], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.33200016617774963
bi 1 loss 0.08535631000995636
bi 2 loss 0.08037064224481583
bi 3 loss 0.16171497106552124
Layer  5  loss:  0.20026880502700806 0.0 11.146685600280762
logits torch.Size([669, 4, 1024]) labels torch.Size([669, 4]) 0 1022
Curr loss timestep torch.Size([669, 4]) tensor([617, 107, 150, 581], device='cuda:0') tensor(107, device='cuda:0')
bi 0 loss 0.2853291928768158
bi 1 loss 0.18007993698120117
bi 2 loss 0.08347482979297638
bi 3 loss 0.17835140228271484
Layer  6  loss:  0.20560665428638458 0.0 12.180885314941406
logits torch.Size([669, 4, 1024]) labels torch.Size([669, 4]) 0 1022
Curr loss timestep torch.Size([669, 4]) tensor([575, 126, 246, 581], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.3037331700325012
bi 1 loss 0.07188646495342255
bi 2 loss 0.05657211318612099
bi 3 loss 0.21487100422382355
Epoch 0: :   3%|▎         | 15018/600000 [00:09<06:01, v_num=12, reduced_train_loss=1.240, global_step=1.5e+4, consumed_samples=60068.0, train_step_timing in s=0.386]Epoch 0: :   3%|▎         | 15018/600000 [00:09<06:01, v_num=12, reduced_train_loss=1.570, global_step=1.5e+4, consumed_samples=60072.0, train_step_timing in s=0.449]loss mask original None

First layer loss:  0.07771012932062149 torch.Size([547, 4]) 2.8077187538146973 0.0
Max loss timestep torch.Size([547, 4]) tensor([ 65, 535, 408, 251], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.039166320115327835
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 1 loss 0.08431673794984818
speech mask sum tensor(357, device='cuda:0') loss mask sum tensor(357, device='cuda:0')
bi 2 loss 0.12789717316627502
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 3 loss 0.041877713054418564
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
logits torch.Size([547, 4, 257024]) labels torch.Size([547, 4]) 0 257023
Layer  0  loss:  0.08468567579984665 0.0 3.314800500869751
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([100, 538, 398, 244], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.021778317168354988
bi 1 loss 0.10560394078493118
bi 2 loss 0.12308661639690399
bi 3 loss 0.04541277140378952
Layer  1  loss:  0.08652757853269577 0.0 4.724599838256836
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([ 87, 538, 342, 250], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.028963960707187653
bi 1 loss 0.09867726266384125
bi 2 loss 0.1531716138124466
bi 3 loss 0.035734277218580246
Layer  2  loss:  0.07864531874656677 0.0 2.8028173446655273
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([ 49, 538, 309, 145], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.041241664439439774
bi 1 loss 0.08898083865642548
bi 2 loss 0.10565411299467087
bi 3 loss 0.0565279982984066
Layer  3  loss:  0.08548299223184586 0.0 6.051764488220215
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([109, 538, 345, 170], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.07188964635133743
bi 1 loss 0.09663433581590652
bi 2 loss 0.11311549693346024
bi 3 loss 0.038114871829748154
Layer  4  loss:  0.08347555994987488 0.0 4.3856892585754395
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1021
Curr loss timestep torch.Size([547, 4]) tensor([139, 538, 405, 180], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.041082583367824554
bi 1 loss 0.10380610078573227
bi 2 loss 0.11136718839406967
bi 3 loss 0.03785429894924164
Layer  5  loss:  0.07575021684169769 0.0 4.139703273773193
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([136, 538, 405, 186], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.03652109578251839
bi 1 loss 0.08233051747083664
bi 2 loss 0.11926093697547913
bi 3 loss 0.04781891778111458
Layer  6  loss:  0.07960792630910873 0.0 5.367667198181152
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([ 76, 538, 408, 190], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.023938452824950218
bi 1 loss 0.09162897616624832
bi 2 loss 0.12410274893045425
bi 3 loss 0.05122670158743858
Epoch 0: :   3%|▎         | 15019/600000 [00:09<06:16, v_num=12, reduced_train_loss=1.570, global_step=1.5e+4, consumed_samples=60072.0, train_step_timing in s=0.449]Epoch 0: :   3%|▎         | 15019/600000 [00:09<06:16, v_num=12, reduced_train_loss=0.652, global_step=1.5e+4, consumed_samples=60076.0, train_step_timing in s=0.366]loss mask original None

First layer loss:  0.12215884029865265 torch.Size([595, 4]) 12.596990585327148 0.0
Max loss timestep torch.Size([595, 4]) tensor([478, 152, 532, 317], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.14522771537303925
speech mask sum tensor(474, device='cuda:0') loss mask sum tensor(474, device='cuda:0')
bi 1 loss 0.0838688388466835
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 2 loss 0.09870503097772598
speech mask sum tensor(407, device='cuda:0') loss mask sum tensor(407, device='cuda:0')
bi 3 loss 0.15075956284999847
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
logits torch.Size([595, 4, 257024]) labels torch.Size([595, 4]) 0 257023
Layer  0  loss:  0.16203653812408447 0.0 22.687685012817383
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([307, 283, 573, 314], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.20656625926494598
bi 1 loss 0.06418471783399582
bi 2 loss 0.12749719619750977
bi 3 loss 0.22134733200073242
Layer  1  loss:  0.17947448790073395 0.0 17.173059463500977
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1022
Curr loss timestep torch.Size([595, 4]) tensor([335, 214, 392, 316], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.2324414700269699
bi 1 loss 0.051831360906362534
bi 2 loss 0.17267563939094543
bi 3 loss 0.2050970494747162
Layer  2  loss:  0.1956779658794403 0.0 17.953447341918945
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([457, 255, 392, 314], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.2024238109588623
bi 1 loss 0.06868691742420197
bi 2 loss 0.22560985386371613
bi 3 loss 0.24811962246894836
Layer  3  loss:  0.1832338571548462 0.0 16.070884704589844
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([457, 285, 393, 314], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.20755231380462646
bi 1 loss 0.06521102041006088
bi 2 loss 0.19025593996047974
bi 3 loss 0.23161272704601288
Layer  4  loss:  0.18415118753910065 0.0 12.062697410583496
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([307, 283, 393, 314], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.2265995889902115
bi 1 loss 0.06589419394731522
bi 2 loss 0.19317178428173065
bi 3 loss 0.19570298492908478
Layer  5  loss:  0.18129508197307587 0.0 15.482251167297363
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([307, 284, 392, 317], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.17114302515983582
bi 1 loss 0.06428848206996918
bi 2 loss 0.23210057616233826
bi 3 loss 0.2229396551847458
Layer  6  loss:  0.1791328638792038 0.0 20.689584732055664
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([307, 283, 390, 317], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.20082910358905792
bi 1 loss 0.0484975129365921
bi 2 loss 0.19445110857486725
bi 3 loss 0.23033387959003448
Epoch 0: :   3%|▎         | 15020/600000 [00:10<06:33, v_num=12, reduced_train_loss=0.652, global_step=1.5e+4, consumed_samples=60076.0, train_step_timing in s=0.366]Epoch 0: :   3%|▎         | 15020/600000 [00:10<06:34, v_num=12, reduced_train_loss=1.390, global_step=1.5e+4, consumed_samples=60080.0, train_step_timing in s=0.401]loss mask original None

First layer loss:  0.11129968613386154 torch.Size([498, 4]) 12.096094131469727 0.0
Max loss timestep torch.Size([498, 4]) tensor([278,  96, 344, 366], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.14884915947914124
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 1 loss 0.03213449567556381
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 2 loss 0.09796339273452759
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 3 loss 0.1502288281917572
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
logits torch.Size([498, 4, 257024]) labels torch.Size([498, 4]) 0 257019
Layer  0  loss:  0.11199425160884857 0.0 12.720907211303711
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([279, 246, 344, 366], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.1516665518283844
bi 1 loss 0.04382376745343208
bi 2 loss 0.11355239152908325
bi 3 loss 0.11782018095254898
Layer  1  loss:  0.11168988794088364 0.0 12.93917179107666
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([279, 224, 344, 366], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.15547534823417664
bi 1 loss 0.038739051669836044
bi 2 loss 0.10256308317184448
bi 3 loss 0.13261719048023224
Layer  2  loss:  0.09569282829761505 0.0 9.573160171508789
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1022
Curr loss timestep torch.Size([498, 4]) tensor([280, 237, 344, 366], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.09382952749729156
bi 1 loss 0.028171535581350327
bi 2 loss 0.12471721321344376
bi 3 loss 0.10603633522987366
Layer  3  loss:  0.1217070147395134 0.0 9.158679962158203
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1021
Curr loss timestep torch.Size([498, 4]) tensor([280, 170, 313, 366], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.14473077654838562
bi 1 loss 0.038259245455265045
bi 2 loss 0.1460149586200714
bi 3 loss 0.12366349995136261
Layer  4  loss:  0.10907282680273056 0.0 10.477198600769043
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([279, 207, 344, 366], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.1320784091949463
bi 1 loss 0.039436228573322296
bi 2 loss 0.12157686799764633
bi 3 loss 0.1181478500366211
Layer  5  loss:  0.1135985404253006 0.0 12.708610534667969
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1018
Curr loss timestep torch.Size([498, 4]) tensor([279, 151, 344, 366], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.13614048063755035
bi 1 loss 0.0358203761279583
bi 2 loss 0.11893826723098755
bi 3 loss 0.14016380906105042
Layer  6  loss:  0.12803980708122253 0.0 16.658920288085938
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1022
Curr loss timestep torch.Size([498, 4]) tensor([278, 247, 344, 366], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.15561063587665558
bi 1 loss 0.05519435182213783
bi 2 loss 0.13961443305015564
bi 3 loss 0.1358928233385086
Epoch 0: :   3%|▎         | 15021/600000 [00:10<06:48, v_num=12, reduced_train_loss=1.390, global_step=1.5e+4, consumed_samples=60080.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15021/600000 [00:10<06:48, v_num=12, reduced_train_loss=0.903, global_step=1.5e+4, consumed_samples=60084.0, train_step_timing in s=0.344]loss mask original None

First layer loss:  3.999680519104004 torch.Size([536, 4]) 15.059981346130371 0.0
Max loss timestep torch.Size([536, 4]) tensor([436, 424,  62, 169], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 3.762481689453125
speech mask sum tensor(368, device='cuda:0') loss mask sum tensor(368, device='cuda:0')
bi 1 loss 4.308262348175049
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 2 loss 3.325808048248291
speech mask sum tensor(76, device='cuda:0') loss mask sum tensor(76, device='cuda:0')
bi 3 loss 4.061868190765381
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
logits torch.Size([536, 4, 257024]) labels torch.Size([536, 4]) 0 257023
Layer  0  loss:  4.639288902282715 0.0 10.542267799377441
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1023
Curr loss timestep torch.Size([536, 4]) tensor([194, 180,  79, 259], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.609720706939697
bi 1 loss 4.871140003204346
bi 2 loss 3.5820658206939697
bi 3 loss 4.641298294067383
Layer  1  loss:  4.8351216316223145 0.0 9.661130905151367
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1022
Curr loss timestep torch.Size([536, 4]) tensor([449, 314,  82, 343], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 4.734256744384766
bi 1 loss 4.947424411773682
bi 2 loss 3.8296220302581787
bi 3 loss 5.077719211578369
Layer  2  loss:  5.048129081726074 0.0 9.737783432006836
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1022
Curr loss timestep torch.Size([536, 4]) tensor([447, 165,  97, 225], device='cuda:0') tensor(172, device='cuda:0')
bi 0 loss 4.977252960205078
bi 1 loss 5.223216533660889
bi 2 loss 3.964111804962158
bi 3 loss 5.187532424926758
Layer  3  loss:  5.202730655670166 0.0 10.487909317016602
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1021
Curr loss timestep torch.Size([536, 4]) tensor([195, 461,  84, 151], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 5.131941318511963
bi 1 loss 5.374612331390381
bi 2 loss 4.080821514129639
bi 3 loss 5.356423854827881
Layer  4  loss:  5.306909561157227 0.0 10.204253196716309
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1023
Curr loss timestep torch.Size([536, 4]) tensor([492, 206,  95, 166], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 5.230109691619873
bi 1 loss 5.411471366882324
bi 2 loss 4.282466888427734
bi 3 loss 5.534215450286865
Layer  5  loss:  5.423398971557617 0.0 10.410028457641602
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1023
Curr loss timestep torch.Size([536, 4]) tensor([337, 190,  91, 245], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 5.319628715515137
bi 1 loss 5.53779935836792
bi 2 loss 4.36613130569458
bi 3 loss 5.680574893951416
Layer  6  loss:  5.467495918273926 0.0 9.991264343261719
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1022
Curr loss timestep torch.Size([536, 4]) tensor([184, 422,  84, 346], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 5.401185512542725
bi 1 loss 5.5189924240112305
bi 2 loss 4.454352378845215
bi 3 loss 5.750652313232422
Epoch 0: :   3%|▎         | 15022/600000 [00:10<07:03, v_num=12, reduced_train_loss=0.903, global_step=1.5e+4, consumed_samples=60084.0, train_step_timing in s=0.344]Epoch 0: :   3%|▎         | 15022/600000 [00:10<07:03, v_num=12, reduced_train_loss=39.90, global_step=1.5e+4, consumed_samples=60088.0, train_step_timing in s=0.343]loss mask original None

First layer loss:  0.13406193256378174 torch.Size([463, 4]) 6.502573013305664 0.0
Max loss timestep torch.Size([463, 4]) tensor([307, 341, 260, 389], device='cuda:0') tensor(389, device='cuda:0')
bi 0 loss 0.13136735558509827
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 1 loss 0.1212267205119133
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 2 loss 0.14449404180049896
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 3 loss 0.1386292725801468
speech mask sum tensor(284, device='cuda:0') loss mask sum tensor(284, device='cuda:0')
logits torch.Size([463, 4, 257024]) labels torch.Size([463, 4]) 0 257022
Layer  0  loss:  0.1528516560792923 0.0 11.033037185668945
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([309, 341, 433, 283], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.18122655153274536
bi 1 loss 0.11814550310373306
bi 2 loss 0.1627717912197113
bi 3 loss 0.1687726080417633
Layer  1  loss:  0.19256550073623657 0.0 15.883285522460938
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([309, 316, 326, 413], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.18464481830596924
bi 1 loss 0.12127448618412018
bi 2 loss 0.2165442556142807
bi 3 loss 0.24728092551231384
Layer  2  loss:  0.17562110722064972 0.0 8.710302352905273
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([309, 340, 433, 411], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.14569100737571716
bi 1 loss 0.13293153047561646
bi 2 loss 0.17607305943965912
bi 3 loss 0.23117521405220032
Layer  3  loss:  0.18331803381443024 0.0 12.897050857543945
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([309, 317, 264, 413], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.14259563386440277
bi 1 loss 0.1454206109046936
bi 2 loss 0.1634577512741089
bi 3 loss 0.25718754529953003
Layer  4  loss:  0.16460400819778442 0.0 7.602530479431152
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([309, 340, 264, 284], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.20833225548267365
bi 1 loss 0.1215096041560173
bi 2 loss 0.15769101679325104
bi 3 loss 0.19925974309444427
Layer  5  loss:  0.18635757267475128 0.0 9.448241233825684
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([307, 387, 264, 283], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.16122175753116608
bi 1 loss 0.13455496728420258
bi 2 loss 0.17063112556934357
bi 3 loss 0.26483669877052307
Layer  6  loss:  0.18032467365264893 0.0 9.041049003601074
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([309, 372, 328, 389], device='cuda:0') tensor(389, device='cuda:0')
bi 0 loss 0.16000299155712128
bi 1 loss 0.1636812388896942
bi 2 loss 0.12289861589670181
bi 3 loss 0.2596616744995117
Epoch 0: :   3%|▎         | 15023/600000 [00:11<07:17, v_num=12, reduced_train_loss=39.90, global_step=1.5e+4, consumed_samples=60088.0, train_step_timing in s=0.343]Epoch 0: :   3%|▎         | 15023/600000 [00:11<07:17, v_num=12, reduced_train_loss=1.370, global_step=1.5e+4, consumed_samples=60092.0, train_step_timing in s=0.323]loss mask original None

First layer loss:  0.2699960768222809 torch.Size([805, 4]) 16.859851837158203 0.0
Max loss timestep torch.Size([805, 4]) tensor([577, 121, 463,  96], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.21375426650047302
speech mask sum tensor(482, device='cuda:0') loss mask sum tensor(482, device='cuda:0')
bi 1 loss 0.021180668845772743
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 2 loss 0.4161873161792755
speech mask sum tensor(461, device='cuda:0') loss mask sum tensor(461, device='cuda:0')
bi 3 loss 0.01857953518629074
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
logits torch.Size([805, 4, 257024]) labels torch.Size([805, 4]) 0 257023
Layer  0  loss:  0.2948918640613556 0.0 10.2211332321167
logits torch.Size([805, 4, 1024]) labels torch.Size([805, 4]) 0 1023
Curr loss timestep torch.Size([805, 4]) tensor([320,  77, 618, 103], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.2830917537212372
bi 1 loss 0.05809512734413147
bi 2 loss 0.3930642306804657
bi 3 loss 0.041480161249637604
Layer  1  loss:  0.3131644129753113 0.0 15.007305145263672
logits torch.Size([805, 4, 1024]) labels torch.Size([805, 4]) 0 1023
Curr loss timestep torch.Size([805, 4]) tensor([406,  79, 632, 130], device='cuda:0') tensor(632, device='cuda:0')
bi 0 loss 0.29373404383659363
bi 1 loss 0.013011422008275986
bi 2 loss 0.4349874258041382
bi 3 loss 0.03059401921927929
Layer  2  loss:  0.35825276374816895 0.0 13.431031227111816
logits torch.Size([805, 4, 1024]) labels torch.Size([805, 4]) 0 1022
Curr loss timestep torch.Size([805, 4]) tensor([323, 124, 632,  93], device='cuda:0') tensor(632, device='cuda:0')
bi 0 loss 0.2840419113636017
bi 1 loss 0.07124824821949005
bi 2 loss 0.5301004648208618
bi 3 loss 0.10292123258113861
Layer  3  loss:  0.36069366335868835 0.0 14.132085800170898
logits torch.Size([805, 4, 1024]) labels torch.Size([805, 4]) 0 1023
Curr loss timestep torch.Size([805, 4]) tensor([406, 108, 632, 131], device='cuda:0') tensor(632, device='cuda:0')
bi 0 loss 0.2801596224308014
bi 1 loss 0.06369397789239883
bi 2 loss 0.551069438457489
bi 3 loss 0.05071871355175972
Layer  4  loss:  0.34625568985939026 0.0 12.873517036437988
logits torch.Size([805, 4, 1024]) labels torch.Size([805, 4]) 0 1023
Curr loss timestep torch.Size([805, 4]) tensor([557, 101, 632, 131], device='cuda:0') tensor(632, device='cuda:0')
bi 0 loss 0.29493245482444763
bi 1 loss 0.029649293050169945
bi 2 loss 0.5029648542404175
bi 3 loss 0.06951695680618286
Layer  5  loss:  0.36105799674987793 0.0 15.41796588897705
logits torch.Size([805, 4, 1024]) labels torch.Size([805, 4]) 0 1023
Curr loss timestep torch.Size([805, 4]) tensor([585,  86, 361, 135], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.28747498989105225
bi 1 loss 0.020979078486561775
bi 2 loss 0.5527030229568481
bi 3 loss 0.04248931258916855
Layer  6  loss:  0.3357335329055786 0.0 11.071752548217773
logits torch.Size([805, 4, 1024]) labels torch.Size([805, 4]) 0 1021
Curr loss timestep torch.Size([805, 4]) tensor([557, 106, 618, 119], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.28184521198272705
bi 1 loss 0.013881010003387928
bi 2 loss 0.49311017990112305
bi 3 loss 0.07413121312856674
Epoch 0: :   3%|▎         | 15024/600000 [00:11<07:39, v_num=12, reduced_train_loss=1.370, global_step=1.5e+4, consumed_samples=60092.0, train_step_timing in s=0.323]Epoch 0: :   3%|▎         | 15024/600000 [00:11<07:40, v_num=12, reduced_train_loss=2.640, global_step=1.5e+4, consumed_samples=60096.0, train_step_timing in s=0.538]loss mask original None

First layer loss:  3.4154930114746094 torch.Size([356, 4]) 11.054917335510254 0.0
Max loss timestep torch.Size([356, 4]) tensor([106, 305, 150, 181], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 3.030355930328369
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 1 loss 3.6466898918151855
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 3.027310848236084
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
bi 3 loss 3.8182761669158936
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
logits torch.Size([356, 4, 257024]) labels torch.Size([356, 4]) 0 257022
Layer  0  loss:  3.935924768447876 0.0 9.452693939208984
logits torch.Size([356, 4, 1024]) labels torch.Size([356, 4]) 0 1023
Curr loss timestep torch.Size([356, 4]) tensor([ 97, 269, 150, 307], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 3.5699303150177
bi 1 loss 4.362534046173096
bi 2 loss 3.5327444076538086
bi 3 loss 4.238369941711426
Layer  1  loss:  4.303753852844238 0.0 10.357748031616211
logits torch.Size([356, 4, 1024]) labels torch.Size([356, 4]) 0 1022
Curr loss timestep torch.Size([356, 4]) tensor([107, 235, 170, 216], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 3.6961212158203125
bi 1 loss 4.940714359283447
bi 2 loss 3.8912384510040283
bi 3 loss 4.591576099395752
Layer  2  loss:  4.436657905578613 0.0 10.81381607055664
logits torch.Size([356, 4, 1024]) labels torch.Size([356, 4]) 0 1022
Curr loss timestep torch.Size([356, 4]) tensor([111, 329, 170, 238], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 3.6397435665130615
bi 1 loss 4.862555503845215
bi 2 loss 3.9842426776885986
bi 3 loss 4.952618598937988
Layer  3  loss:  4.609206676483154 0.0 10.173510551452637
logits torch.Size([356, 4, 1024]) labels torch.Size([356, 4]) 0 1022
Curr loss timestep torch.Size([356, 4]) tensor([106, 294, 197, 214], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 4.190679550170898
bi 1 loss 5.038949489593506
bi 2 loss 4.160796642303467
bi 3 loss 4.974642753601074
Layer  4  loss:  4.7074785232543945 0.0 10.287482261657715
logits torch.Size([356, 4, 1024]) labels torch.Size([356, 4]) 0 1021
Curr loss timestep torch.Size([356, 4]) tensor([ 93, 334, 288, 108], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 4.091616630554199
bi 1 loss 5.171209812164307
bi 2 loss 4.311310291290283
bi 3 loss 5.077898025512695
Layer  5  loss:  4.811886787414551 0.0 9.30317211151123
logits torch.Size([356, 4, 1024]) labels torch.Size([356, 4]) 0 1022
Curr loss timestep torch.Size([356, 4]) tensor([102, 232, 233, 306], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 4.572533130645752
bi 1 loss 5.333187580108643
bi 2 loss 4.393946647644043
bi 3 loss 5.028306007385254
Layer  6  loss:  4.812568187713623 0.0 10.57577133178711
logits torch.Size([356, 4, 1024]) labels torch.Size([356, 4]) 0 1023
Curr loss timestep torch.Size([356, 4]) tensor([118, 334, 221, 285], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 4.515684604644775
bi 1 loss 5.235005855560303
bi 2 loss 4.4318461418151855
bi 3 loss 5.068753242492676
Epoch 0: :   3%|▎         | 15025/600000 [00:12<07:51, v_num=12, reduced_train_loss=2.640, global_step=1.5e+4, consumed_samples=60096.0, train_step_timing in s=0.538]Epoch 0: :   3%|▎         | 15025/600000 [00:12<07:51, v_num=12, reduced_train_loss=35.00, global_step=1.5e+4, consumed_samples=60100.0, train_step_timing in s=0.270]loss mask original None

First layer loss:  0.15958541631698608 torch.Size([661, 4]) 11.49521541595459 0.0
Max loss timestep torch.Size([661, 4]) tensor([292, 276, 500, 285], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.15399645268917084
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 1 loss 0.09215214103460312
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 2 loss 0.263120174407959
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 3 loss 0.08296820521354675
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
logits torch.Size([661, 4, 257024]) labels torch.Size([661, 4]) 0 257023
Layer  0  loss:  0.2004692256450653 0.0 11.125310897827148
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([316, 259, 499, 402], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.25391504168510437
bi 1 loss 0.154997780919075
bi 2 loss 0.25662529468536377
bi 3 loss 0.1089087724685669
Layer  1  loss:  0.20166046917438507 0.0 15.900715827941895
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1022
Curr loss timestep torch.Size([661, 4]) tensor([335, 259, 498, 397], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.208866149187088
bi 1 loss 0.13987262547016144
bi 2 loss 0.31712499260902405
bi 3 loss 0.090840183198452
Layer  2  loss:  0.24543830752372742 0.0 12.368178367614746
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1022
Curr loss timestep torch.Size([661, 4]) tensor([293, 259, 561, 310], device='cuda:0') tensor(561, device='cuda:0')
bi 0 loss 0.26221564412117004
bi 1 loss 0.142654687166214
bi 2 loss 0.3766877055168152
bi 3 loss 0.13893303275108337
Layer  3  loss:  0.210150808095932 0.0 11.344442367553711
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([388, 259, 500, 397], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.19386768341064453
bi 1 loss 0.1298850178718567
bi 2 loss 0.3488104045391083
bi 3 loss 0.10781769454479218
Layer  4  loss:  0.2263454645872116 0.0 14.494555473327637
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1022
Curr loss timestep torch.Size([661, 4]) tensor([316, 259, 499, 310], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.24078375101089478
bi 1 loss 0.1393996775150299
bi 2 loss 0.3598146140575409
bi 3 loss 0.10546968877315521
Layer  5  loss:  0.24505826830863953 0.0 20.360132217407227
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([316, 259, 498, 391], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.21869906783103943
bi 1 loss 0.14757774770259857
bi 2 loss 0.42763423919677734
bi 3 loss 0.10822057723999023
Layer  6  loss:  0.25417643785476685 0.0 15.469329833984375
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1022
Curr loss timestep torch.Size([661, 4]) tensor([316, 316, 500, 402], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.2667864263057709
bi 1 loss 0.14695416390895844
bi 2 loss 0.39174264669418335
bi 3 loss 0.1471889168024063
Epoch 0: :   3%|▎         | 15026/600000 [00:12<08:10, v_num=12, reduced_train_loss=35.00, global_step=1.5e+4, consumed_samples=60100.0, train_step_timing in s=0.270]Epoch 0: :   3%|▎         | 15026/600000 [00:12<08:10, v_num=12, reduced_train_loss=1.740, global_step=1.5e+4, consumed_samples=60104.0, train_step_timing in s=0.446]loss mask original None

First layer loss:  3.6210172176361084 torch.Size([496, 4]) 10.944982528686523 0.0
Max loss timestep torch.Size([496, 4]) tensor([155, 250,  60, 280], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.375088214874268
speech mask sum tensor(225, device='cuda:0') loss mask sum tensor(225, device='cuda:0')
bi 1 loss 2.5671586990356445
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 2 loss 3.918410539627075
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 3 loss 3.9193174839019775
speech mask sum tensor(386, device='cuda:0') loss mask sum tensor(386, device='cuda:0')
logits torch.Size([496, 4, 257024]) labels torch.Size([496, 4]) 0 257022
Layer  0  loss:  4.099970817565918 0.0 10.318135261535645
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1023
Curr loss timestep torch.Size([496, 4]) tensor([271, 278,  84, 462], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 5.071340560913086
bi 1 loss 2.989413022994995
bi 2 loss 4.045478343963623
bi 3 loss 4.496201992034912
Layer  1  loss:  4.434246063232422 0.0 10.348997116088867
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1021
Curr loss timestep torch.Size([496, 4]) tensor([125, 293, 195, 473], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 5.167446613311768
bi 1 loss 3.2591845989227295
bi 2 loss 4.536612510681152
bi 3 loss 4.944779872894287
Layer  2  loss:  4.695931434631348 0.0 10.832883834838867
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1022
Curr loss timestep torch.Size([496, 4]) tensor([109, 149, 126, 469], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 5.551976680755615
bi 1 loss 3.419417381286621
bi 2 loss 4.77581262588501
bi 3 loss 5.231578350067139
Layer  3  loss:  4.816504001617432 0.0 10.95555305480957
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1023
Curr loss timestep torch.Size([496, 4]) tensor([ 71, 236, 161, 129], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 5.643531799316406
bi 1 loss 3.556678295135498
bi 2 loss 4.877823829650879
bi 3 loss 5.36434268951416
Layer  4  loss:  4.946088790893555 0.0 10.294906616210938
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1022
Curr loss timestep torch.Size([496, 4]) tensor([225, 293,  75, 216], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 5.821726322174072
bi 1 loss 3.534327745437622
bi 2 loss 5.031212329864502
bi 3 loss 5.581553936004639
Layer  5  loss:  5.014161586761475 0.0 10.39632797241211
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1020
Curr loss timestep torch.Size([496, 4]) tensor([152, 398, 109, 178], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 5.843774318695068
bi 1 loss 3.6490933895111084
bi 2 loss 5.263571739196777
bi 3 loss 5.554572582244873
Layer  6  loss:  5.058129787445068 0.0 9.879264831542969
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1023
Curr loss timestep torch.Size([496, 4]) tensor([ 91, 154, 202, 215], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 5.944328308105469
bi 1 loss 3.5806877613067627
bi 2 loss 5.232027530670166
bi 3 loss 5.698123455047607
Epoch 0: :   3%|▎         | 15027/600000 [00:12<08:24, v_num=12, reduced_train_loss=1.740, global_step=1.5e+4, consumed_samples=60104.0, train_step_timing in s=0.446]Epoch 0: :   3%|▎         | 15027/600000 [00:12<08:24, v_num=12, reduced_train_loss=36.70, global_step=1.5e+4, consumed_samples=60108.0, train_step_timing in s=0.325]loss mask original None

First layer loss:  0.13163501024246216 torch.Size([699, 4]) 11.026286125183105 0.0
Max loss timestep torch.Size([699, 4]) tensor([372,  30, 259,  35], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.10399946570396423
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 1 loss 0.026691865175962448
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 2 loss 0.4211776852607727
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
bi 3 loss 0.1019451692700386
speech mask sum tensor(63, device='cuda:0') loss mask sum tensor(63, device='cuda:0')
logits torch.Size([699, 4, 257024]) labels torch.Size([699, 4]) 0 257023
Layer  0  loss:  0.14691609144210815 0.0 15.751190185546875
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1023
Curr loss timestep torch.Size([699, 4]) tensor([561,  32, 260,  68], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.10968872159719467
bi 1 loss 0.009448446333408356
bi 2 loss 0.6242412328720093
bi 3 loss 0.01484458614140749
Layer  1  loss:  0.1678699404001236 0.0 11.782195091247559
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1022
Curr loss timestep torch.Size([699, 4]) tensor([686,  37, 276,  66], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.14213110506534576
bi 1 loss 0.0050399708561599255
bi 2 loss 0.5825840830802917
bi 3 loss 0.04969600960612297
Layer  2  loss:  0.1771520972251892 0.0 12.627401351928711
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1022
Curr loss timestep torch.Size([699, 4]) tensor([686,  46, 260,  72], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.14805500209331512
bi 1 loss 0.019856587052345276
bi 2 loss 0.6348106861114502
bi 3 loss 0.03152269124984741
Layer  3  loss:  0.16920097172260284 0.0 11.260336875915527
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1017
Curr loss timestep torch.Size([699, 4]) tensor([686,  28, 260,  74], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.1631452441215515
bi 1 loss 0.056460995227098465
bi 2 loss 0.3931208848953247
bi 3 loss 0.07802295684814453
Layer  4  loss:  0.15296275913715363 0.0 11.537101745605469
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1020
Curr loss timestep torch.Size([699, 4]) tensor([372,  27, 260,  76], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.1524825096130371
bi 1 loss 0.016194362193346024
bi 2 loss 0.3846071660518646
bi 3 loss 0.04004589840769768
Layer  5  loss:  0.17556659877300262 0.0 14.150010108947754
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1022
Curr loss timestep torch.Size([699, 4]) tensor([536,  47, 260,  63], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.1675921231508255
bi 1 loss 0.04182782769203186
bi 2 loss 0.47411128878593445
bi 3 loss 0.03891133889555931
Layer  6  loss:  0.18022173643112183 0.0 16.110790252685547
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1019
Curr loss timestep torch.Size([699, 4]) tensor([536,  39, 259,  52], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.15242058038711548
bi 1 loss 0.047137755900621414
bi 2 loss 0.6224706172943115
bi 3 loss 0.02100502885878086
Epoch 0: :   3%|▎         | 15028/600000 [00:13<08:44, v_num=12, reduced_train_loss=36.70, global_step=1.5e+4, consumed_samples=60108.0, train_step_timing in s=0.325]Epoch 0: :   3%|▎         | 15028/600000 [00:13<08:44, v_num=12, reduced_train_loss=1.300, global_step=1.5e+4, consumed_samples=60112.0, train_step_timing in s=0.470]loss mask original None

First layer loss:  0.05997808650135994 torch.Size([538, 4]) 5.567953586578369 0.0
Max loss timestep torch.Size([538, 4]) tensor([275, 193,  85, 454], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.0511409230530262
speech mask sum tensor(312, device='cuda:0') loss mask sum tensor(312, device='cuda:0')
bi 1 loss 0.04996674135327339
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 2 loss 0.02399572543799877
speech mask sum tensor(77, device='cuda:0') loss mask sum tensor(77, device='cuda:0')
bi 3 loss 0.07434181869029999
speech mask sum tensor(442, device='cuda:0') loss mask sum tensor(442, device='cuda:0')
logits torch.Size([538, 4, 257024]) labels torch.Size([538, 4]) 0 257022
Layer  0  loss:  0.07769782096147537 0.0 9.250948905944824
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([293, 163,  91, 457], device='cuda:0') tensor(457, device='cuda:0')
bi 0 loss 0.048931367695331573
bi 1 loss 0.043808914721012115
bi 2 loss 0.056508440524339676
bi 3 loss 0.10798200219869614
Layer  1  loss:  0.07417870312929153 0.0 4.74058198928833
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([ 79, 158, 119, 457], device='cuda:0') tensor(457, device='cuda:0')
bi 0 loss 0.07387146353721619
bi 1 loss 0.06545478850603104
bi 2 loss 0.044081080704927444
bi 3 loss 0.08125730603933334
Layer  2  loss:  0.10188669711351395 0.0 8.207389831542969
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1022
Curr loss timestep torch.Size([538, 4]) tensor([ 93, 206, 109, 454], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.06853557378053665
bi 1 loss 0.1180335283279419
bi 2 loss 0.040879473090171814
bi 3 loss 0.13306108117103577
Layer  3  loss:  0.06857993453741074 0.0 2.9771804809570312
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([275, 168,  76, 454], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.060586117208004
bi 1 loss 0.04894870147109032
bi 2 loss 0.04687799513339996
bi 3 loss 0.08164527267217636
Layer  4  loss:  0.07751982659101486 0.0 7.354864597320557
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1022
Curr loss timestep torch.Size([538, 4]) tensor([275, 182,  94, 454], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.079535111784935
bi 1 loss 0.021199477836489677
bi 2 loss 0.027920091524720192
bi 3 loss 0.09518653899431229
Layer  5  loss:  0.08648589998483658 0.0 7.884875774383545
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1022
Curr loss timestep torch.Size([538, 4]) tensor([316, 176,  97, 457], device='cuda:0') tensor(457, device='cuda:0')
bi 0 loss 0.056815311312675476
bi 1 loss 0.051104191690683365
bi 2 loss 0.047776736319065094
bi 3 loss 0.12073731422424316
Layer  6  loss:  0.10478979349136353 0.0 15.851449012756348
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([275, 192,  97, 454], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.09365755319595337
bi 1 loss 0.034120142459869385
bi 2 loss 0.04962398484349251
bi 3 loss 0.13536882400512695
Epoch 0: :   3%|▎         | 15029/600000 [00:13<09:00, v_num=12, reduced_train_loss=1.300, global_step=1.5e+4, consumed_samples=60112.0, train_step_timing in s=0.470]Epoch 0: :   3%|▎         | 15029/600000 [00:13<09:00, v_num=12, reduced_train_loss=0.651, global_step=1.5e+4, consumed_samples=60116.0, train_step_timing in s=0.366]loss mask original None

First layer loss:  0.1393100917339325 torch.Size([621, 4]) 9.130229949951172 0.0
Max loss timestep torch.Size([621, 4]) tensor([387, 551, 259, 585], device='cuda:0') tensor(585, device='cuda:0')
bi 0 loss 0.10394791513681412
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
bi 1 loss 0.14784151315689087
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 2 loss 0.09610500186681747
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 3 loss 0.17878466844558716
speech mask sum tensor(501, device='cuda:0') loss mask sum tensor(501, device='cuda:0')
logits torch.Size([621, 4, 257024]) labels torch.Size([621, 4]) 0 257022
Layer  0  loss:  0.1587064117193222 0.0 7.352668285369873
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([388, 463, 264, 274], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.1669042557477951
bi 1 loss 0.11973834037780762
bi 2 loss 0.15434692800045013
bi 3 loss 0.1814633011817932
Layer  1  loss:  0.1718633770942688 0.0 10.7838716506958
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([291, 464, 278, 605], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.1647437959909439
bi 1 loss 0.13087977468967438
bi 2 loss 0.11688835173845291
bi 3 loss 0.2293236404657364
Layer  2  loss:  0.18572013080120087 0.0 14.168219566345215
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([388, 551, 279, 606], device='cuda:0') tensor(606, device='cuda:0')
bi 0 loss 0.2025677114725113
bi 1 loss 0.1777646839618683
bi 2 loss 0.08175845444202423
bi 3 loss 0.22282283008098602
Layer  3  loss:  0.19436991214752197 0.0 16.77574920654297
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([387, 463, 278, 274], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.26646873354911804
bi 1 loss 0.10895424336194992
bi 2 loss 0.08146354556083679
bi 3 loss 0.24712498486042023
Layer  4  loss:  0.16044357419013977 0.0 11.535055160522461
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([387, 463, 279, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.14410832524299622
bi 1 loss 0.09975096583366394
bi 2 loss 0.14679288864135742
bi 3 loss 0.22100849449634552
Layer  5  loss:  0.1772262156009674 0.0 10.620443344116211
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([387, 463, 278, 603], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.14769628643989563
bi 1 loss 0.12788954377174377
bi 2 loss 0.13672299683094025
bi 3 loss 0.2514110505580902
Layer  6  loss:  0.18452781438827515 0.0 13.40652084350586
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([386, 468, 278, 605], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.2110544592142105
bi 1 loss 0.1071016788482666
bi 2 loss 0.09988411515951157
bi 3 loss 0.2543926239013672
Epoch 0: :   3%|▎         | 15030/600000 [00:14<09:17, v_num=12, reduced_train_loss=0.651, global_step=1.5e+4, consumed_samples=60116.0, train_step_timing in s=0.366]Epoch 0: :   3%|▎         | 15030/600000 [00:14<09:17, v_num=12, reduced_train_loss=1.370, global_step=1.5e+4, consumed_samples=60120.0, train_step_timing in s=0.413]loss mask original None

First layer loss:  3.7814972400665283 torch.Size([404, 4]) 10.800298690795898 0.0
Max loss timestep torch.Size([404, 4]) tensor([255, 201, 264, 172], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 3.3008179664611816
speech mask sum tensor(93, device='cuda:0') loss mask sum tensor(93, device='cuda:0')
bi 1 loss 3.686340093612671
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 2 loss 3.678520679473877
speech mask sum tensor(320, device='cuda:0') loss mask sum tensor(320, device='cuda:0')
bi 3 loss 4.144819736480713
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
logits torch.Size([404, 4, 257024]) labels torch.Size([404, 4]) 0 257023
Layer  0  loss:  4.451694011688232 0.0 11.409405708312988
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([276, 217,  86, 255], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 3.894289016723633
bi 1 loss 4.419281482696533
bi 2 loss 4.351101875305176
bi 3 loss 4.781080722808838
Layer  1  loss:  4.695324897766113 0.0 10.321464538574219
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([294, 178, 133, 326], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.035897731781006
bi 1 loss 4.590306282043457
bi 2 loss 4.723782062530518
bi 3 loss 4.976718425750732
Layer  2  loss:  5.074258327484131 0.0 11.615865707397461
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([245, 102, 210, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 4.487400054931641
bi 1 loss 4.912569522857666
bi 2 loss 5.180736541748047
bi 3 loss 5.293588638305664
Layer  3  loss:  5.184721946716309 0.0 9.806336402893066
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([256, 187, 222, 189], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 4.600622177124023
bi 1 loss 5.092353820800781
bi 2 loss 5.332596302032471
bi 3 loss 5.293189525604248
Layer  4  loss:  5.234438896179199 0.0 9.68514633178711
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([298, 270, 337, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.729837894439697
bi 1 loss 5.123777389526367
bi 2 loss 5.280278205871582
bi 3 loss 5.44964075088501
Layer  5  loss:  5.335147857666016 0.0 10.095636367797852
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([260, 275,  93, 130], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 4.620912075042725
bi 1 loss 5.243957042694092
bi 2 loss 5.367674350738525
bi 3 loss 5.617599010467529
Layer  6  loss:  5.415210247039795 0.0 9.562518119812012
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([249, 236, 155, 309], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.710982322692871
bi 1 loss 5.361900329589844
bi 2 loss 5.474471092224121
bi 3 loss 5.629556179046631
Epoch 0: :   3%|▎         | 15031/600000 [00:14<09:30, v_num=12, reduced_train_loss=1.370, global_step=1.5e+4, consumed_samples=60120.0, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15031/600000 [00:14<09:30, v_num=12, reduced_train_loss=39.20, global_step=1.5e+4, consumed_samples=60124.0, train_step_timing in s=0.289]loss mask original None

First layer loss:  0.2089814394712448 torch.Size([637, 4]) 12.626337051391602 0.0
Max loss timestep torch.Size([637, 4]) tensor([592, 320, 412, 321], device='cuda:0') tensor(592, device='cuda:0')
bi 0 loss 0.3750109374523163
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 1 loss 0.06563750654459
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 2 loss 0.18451958894729614
speech mask sum tensor(432, device='cuda:0') loss mask sum tensor(432, device='cuda:0')
bi 3 loss 0.15146282315254211
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
logits torch.Size([637, 4, 257024]) labels torch.Size([637, 4]) 0 257023
Layer  0  loss:  0.19668519496917725 0.0 11.07841682434082
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([593, 320, 451, 267], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.34183767437934875
bi 1 loss 0.07588805258274078
bi 2 loss 0.1813419908285141
bi 3 loss 0.13538922369480133
Layer  1  loss:  0.21993570029735565 0.0 14.815069198608398
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([593, 320, 412, 321], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.42464372515678406
bi 1 loss 0.10008223354816437
bi 2 loss 0.1777353584766388
bi 3 loss 0.12756510078907013
Layer  2  loss:  0.2108514904975891 0.0 16.626697540283203
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1022
Curr loss timestep torch.Size([637, 4]) tensor([592, 320, 411, 320], device='cuda:0') tensor(592, device='cuda:0')
bi 0 loss 0.36761143803596497
bi 1 loss 0.05939851328730583
bi 2 loss 0.1947978287935257
bi 3 loss 0.157792329788208
Layer  3  loss:  0.1997510939836502 0.0 17.078458786010742
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1021
Curr loss timestep torch.Size([637, 4]) tensor([592, 319, 327, 321], device='cuda:0') tensor(592, device='cuda:0')
bi 0 loss 0.40387123823165894
bi 1 loss 0.06655806303024292
bi 2 loss 0.13231118023395538
bi 3 loss 0.1503664255142212
Layer  4  loss:  0.24753469228744507 0.0 12.472415924072266
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([592, 319, 412, 321], device='cuda:0') tensor(592, device='cuda:0')
bi 0 loss 0.4200274646282196
bi 1 loss 0.11736884713172913
bi 2 loss 0.2222023755311966
bi 3 loss 0.17531682550907135
Layer  5  loss:  0.23713047802448273 0.0 13.923971176147461
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([525, 266, 409, 267], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.4165300130844116
bi 1 loss 0.07223492115736008
bi 2 loss 0.1834038347005844
bi 3 loss 0.2178514003753662
Layer  6  loss:  0.22016975283622742 0.0 12.197903633117676
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([593, 320, 267, 321], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.38329795002937317
bi 1 loss 0.09906500577926636
bi 2 loss 0.1914651095867157
bi 3 loss 0.15686987340450287
Epoch 0: :   3%|▎         | 15032/600000 [00:15<09:48, v_num=12, reduced_train_loss=39.20, global_step=1.5e+4, consumed_samples=60124.0, train_step_timing in s=0.289]Epoch 0: :   3%|▎         | 15032/600000 [00:15<09:48, v_num=12, reduced_train_loss=1.740, global_step=1.5e+4, consumed_samples=60128.0, train_step_timing in s=0.429]loss mask original None

First layer loss:  3.78983998298645 torch.Size([464, 4]) 11.40550708770752 0.0
Max loss timestep torch.Size([464, 4]) tensor([373, 123, 125, 260], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 3.217271566390991
speech mask sum tensor(324, device='cuda:0') loss mask sum tensor(324, device='cuda:0')
bi 1 loss 3.95660662651062
speech mask sum tensor(185, device='cuda:0') loss mask sum tensor(185, device='cuda:0')
bi 2 loss 4.323633670806885
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
bi 3 loss 3.7269937992095947
speech mask sum tensor(308, device='cuda:0') loss mask sum tensor(308, device='cuda:0')
logits torch.Size([464, 4, 257024]) labels torch.Size([464, 4]) 0 257023
Layer  0  loss:  4.171469211578369 0.0 11.300782203674316
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1023
Curr loss timestep torch.Size([464, 4]) tensor([135, 239, 308, 293], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 3.6087770462036133
bi 1 loss 4.258591175079346
bi 2 loss 4.495712757110596
bi 3 loss 4.367870330810547
Layer  1  loss:  4.670372009277344 0.0 10.421403884887695
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1022
Curr loss timestep torch.Size([464, 4]) tensor([345, 164, 178, 385], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 4.228150367736816
bi 1 loss 4.614208698272705
bi 2 loss 4.858656883239746
bi 3 loss 4.9700117111206055
Layer  2  loss:  4.9497175216674805 0.0 10.25490951538086
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1022
Curr loss timestep torch.Size([464, 4]) tensor([122, 244,  95, 347], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 4.477285385131836
bi 1 loss 4.919330596923828
bi 2 loss 5.142378330230713
bi 3 loss 5.261022567749023
Layer  3  loss:  5.063005447387695 0.0 10.316251754760742
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1022
Curr loss timestep torch.Size([464, 4]) tensor([362, 219, 161, 259], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 4.590975761413574
bi 1 loss 5.102951526641846
bi 2 loss 5.159701824188232
bi 3 loss 5.43321418762207
Layer  4  loss:  5.143163204193115 0.0 10.49368667602539
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1022
Curr loss timestep torch.Size([464, 4]) tensor([277, 213, 366, 187], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 4.710390567779541
bi 1 loss 5.157253742218018
bi 2 loss 5.274207592010498
bi 3 loss 5.451251983642578
Layer  5  loss:  5.2587409019470215 0.0 10.17944622039795
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1022
Curr loss timestep torch.Size([464, 4]) tensor([306, 143, 111, 237], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 4.809615612030029
bi 1 loss 5.312130928039551
bi 2 loss 5.369466781616211
bi 3 loss 5.5819315910339355
Layer  6  loss:  5.335949897766113 0.0 10.572107315063477
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1023
Curr loss timestep torch.Size([464, 4]) tensor([335, 222, 302, 402], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 4.872040271759033
bi 1 loss 5.361906051635742
bi 2 loss 5.615518093109131
bi 3 loss 5.5124616622924805
Epoch 0: :   3%|▎         | 15033/600000 [00:15<10:01, v_num=12, reduced_train_loss=1.740, global_step=1.5e+4, consumed_samples=60128.0, train_step_timing in s=0.429]Epoch 0: :   3%|▎         | 15033/600000 [00:15<10:02, v_num=12, reduced_train_loss=38.40, global_step=1.5e+4, consumed_samples=60132.0, train_step_timing in s=0.314]loss mask original None

First layer loss:  0.10896856337785721 torch.Size([579, 4]) 7.20496129989624 0.0
Max loss timestep torch.Size([579, 4]) tensor([512, 112, 283, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.1798628270626068
speech mask sum tensor(405, device='cuda:0') loss mask sum tensor(405, device='cuda:0')
bi 1 loss 0.030900010839104652
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 2 loss 0.06852448731660843
speech mask sum tensor(207, device='cuda:0') loss mask sum tensor(207, device='cuda:0')
bi 3 loss 0.07791665941476822
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
logits torch.Size([579, 4, 257024]) labels torch.Size([579, 4]) 0 257023
Layer  0  loss:  0.11653541773557663 0.0 12.579723358154297
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([351, 133, 279, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.1249072253704071
bi 1 loss 0.047871388494968414
bi 2 loss 0.04769263416528702
bi 3 loss 0.1646830439567566
Layer  1  loss:  0.11361285299062729 0.0 13.664259910583496
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([535, 157, 298, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.13875919580459595
bi 1 loss 0.05246584862470627
bi 2 loss 0.06876174360513687
bi 3 loss 0.1287439465522766
Layer  2  loss:  0.14014233648777008 0.0 11.831280708312988
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([341, 109, 300, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.17683731019496918
bi 1 loss 0.046201396733522415
bi 2 loss 0.0742173120379448
bi 3 loss 0.16382890939712524
Layer  3  loss:  0.12316776812076569 0.0 14.595504760742188
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1020
Curr loss timestep torch.Size([579, 4]) tensor([511, 106, 298, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.14860522747039795
bi 1 loss 0.06276515871286392
bi 2 loss 0.07467205077409744
bi 3 loss 0.13975654542446136
Layer  4  loss:  0.12060729414224625 0.0 11.908804893493652
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([511, 170, 298, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.14102905988693237
bi 1 loss 0.050431862473487854
bi 2 loss 0.0812365785241127
bi 3 loss 0.14036592841148376
Layer  5  loss:  0.1521070897579193 0.0 11.796845436096191
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([512, 170, 300, 262], device='cuda:0') tensor(512, device='cuda:0')
bi 0 loss 0.20864419639110565
bi 1 loss 0.04219291731715202
bi 2 loss 0.08310477435588837
bi 3 loss 0.16094329953193665
Layer  6  loss:  0.12509191036224365 0.0 9.78891372680664
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([511, 173, 298, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.1490054428577423
bi 1 loss 0.039992958307266235
bi 2 loss 0.07733338326215744
bi 3 loss 0.14996546506881714
Epoch 0: :   3%|▎         | 15034/600000 [00:15<10:18, v_num=12, reduced_train_loss=38.40, global_step=1.5e+4, consumed_samples=60132.0, train_step_timing in s=0.314]Epoch 0: :   3%|▎         | 15034/600000 [00:15<10:18, v_num=12, reduced_train_loss=1.000, global_step=1.5e+4, consumed_samples=60136.0, train_step_timing in s=0.390]loss mask original None

First layer loss:  3.6160190105438232 torch.Size([552, 4]) 12.670673370361328 0.0
Max loss timestep torch.Size([552, 4]) tensor([150, 176, 231, 436], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 3.580317974090576
speech mask sum tensor(474, device='cuda:0') loss mask sum tensor(474, device='cuda:0')
bi 1 loss 2.523022174835205
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 2 loss 4.154177188873291
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 3 loss 3.6530747413635254
speech mask sum tensor(372, device='cuda:0') loss mask sum tensor(372, device='cuda:0')
logits torch.Size([552, 4, 257024]) labels torch.Size([552, 4]) 0 257023
Layer  0  loss:  4.198096752166748 0.0 10.951141357421875
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([388, 183, 209, 238], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.206943988800049
bi 1 loss 3.648094654083252
bi 2 loss 4.3727335929870605
bi 3 loss 4.220839500427246
Layer  1  loss:  4.4504194259643555 0.0 10.375128746032715
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([517, 164, 257, 455], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.46788215637207
bi 1 loss 3.7724087238311768
bi 2 loss 4.693345546722412
bi 3 loss 4.459103584289551
Layer  2  loss:  4.716272830963135 0.0 10.336957931518555
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([419, 152, 256, 472], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.792107582092285
bi 1 loss 4.0025811195373535
bi 2 loss 4.983884334564209
bi 3 loss 4.647471904754639
Layer  3  loss:  4.846273899078369 0.0 10.670045852661133
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1019
Curr loss timestep torch.Size([552, 4]) tensor([184, 172, 222, 466], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.852880477905273
bi 1 loss 4.11488676071167
bi 2 loss 5.256658554077148
bi 3 loss 4.812211036682129
Layer  4  loss:  5.001199722290039 0.0 11.689627647399902
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([141, 164, 243, 329], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.91373348236084
bi 1 loss 4.2676191329956055
bi 2 loss 5.589244842529297
bi 3 loss 5.016735076904297
Layer  5  loss:  5.057577610015869 0.0 11.853809356689453
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([452, 182, 299, 311], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 5.081465721130371
bi 1 loss 4.195407390594482
bi 2 loss 5.381082057952881
bi 3 loss 5.060671329498291
Layer  6  loss:  5.047064781188965 0.0 10.801740646362305
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([427, 163, 284, 415], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.990885257720947
bi 1 loss 4.510618209838867
bi 2 loss 5.438115119934082
bi 3 loss 5.064014911651611
Epoch 0: :   3%|▎         | 15035/600000 [00:16<10:33, v_num=12, reduced_train_loss=1.000, global_step=1.5e+4, consumed_samples=60136.0, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15035/600000 [00:16<10:33, v_num=12, reduced_train_loss=36.90, global_step=1.5e+4, consumed_samples=60140.0, train_step_timing in s=0.343]loss mask original None

First layer loss:  0.2596564292907715 torch.Size([617, 4]) 12.569380760192871 0.0
Max loss timestep torch.Size([617, 4]) tensor([400, 518, 566, 108], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.18823741376399994
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 1 loss 0.3498978018760681
speech mask sum tensor(428, device='cuda:0') loss mask sum tensor(428, device='cuda:0')
bi 2 loss 0.31358399987220764
speech mask sum tensor(445, device='cuda:0') loss mask sum tensor(445, device='cuda:0')
bi 3 loss 0.05064279958605766
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
logits torch.Size([617, 4, 257024]) labels torch.Size([617, 4]) 0 257023
Layer  0  loss:  0.2787835896015167 0.0 12.477846145629883
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([492, 586, 372, 116], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.2967149615287781
bi 1 loss 0.37931495904922485
bi 2 loss 0.2500426769256592
bi 3 loss 0.05439262092113495
Layer  1  loss:  0.34947922825813293 0.0 14.531472206115723
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([492, 577, 372, 172], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.34712347388267517
bi 1 loss 0.44778019189834595
bi 2 loss 0.36424073576927185
bi 3 loss 0.06200593337416649
Layer  2  loss:  0.3704017996788025 0.0 15.51386547088623
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([287, 309, 551,  99], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.42461979389190674
bi 1 loss 0.39411020278930664
bi 2 loss 0.4139258861541748
bi 3 loss 0.06489171087741852
Layer  3  loss:  0.3682679831981659 0.0 13.895553588867188
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([286, 521, 566, 168], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.4165736734867096
bi 1 loss 0.42870408296585083
bi 2 loss 0.39265382289886475
bi 3 loss 0.03329279273748398
Layer  4  loss:  0.3537292182445526 0.0 16.56818199157715
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([492, 521, 551,  41], device='cuda:0') tensor(551, device='cuda:0')
bi 0 loss 0.36369389295578003
bi 1 loss 0.4767182469367981
bi 2 loss 0.3409571349620819
bi 3 loss 0.04739227518439293
Layer  5  loss:  0.38812997937202454 0.0 17.789194107055664
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([492, 518, 551, 114], device='cuda:0') tensor(551, device='cuda:0')
bi 0 loss 0.4332636892795563
bi 1 loss 0.4477226138114929
bi 2 loss 0.4148101210594177
bi 3 loss 0.05665073171257973
Layer  6  loss:  0.3759967088699341 0.0 15.520051956176758
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([287, 518, 372, 145], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.41045376658439636
bi 1 loss 0.4110146760940552
bi 2 loss 0.4248940050601959
bi 3 loss 0.07346854358911514
Epoch 0: :   3%|▎         | 15036/600000 [00:16<10:51, v_num=12, reduced_train_loss=36.90, global_step=1.5e+4, consumed_samples=60140.0, train_step_timing in s=0.343]Epoch 0: :   3%|▎         | 15036/600000 [00:16<10:51, v_num=12, reduced_train_loss=2.740, global_step=1.5e+4, consumed_samples=60144.0, train_step_timing in s=0.422]loss mask original None

First layer loss:  3.661123275756836 torch.Size([716, 4]) 10.84736156463623 0.0
Max loss timestep torch.Size([716, 4]) tensor([196, 231, 579, 277], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 3.597214460372925
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 1 loss 3.933943271636963
speech mask sum tensor(90, device='cuda:0') loss mask sum tensor(90, device='cuda:0')
bi 2 loss 4.059284210205078
speech mask sum tensor(389, device='cuda:0') loss mask sum tensor(389, device='cuda:0')
bi 3 loss 3.2401366233825684
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
logits torch.Size([716, 4, 257024]) labels torch.Size([716, 4]) 0 257022
Layer  0  loss:  4.284510135650635 0.0 9.896827697753906
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([192, 198, 628, 141], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.041598796844482
bi 1 loss 4.146601676940918
bi 2 loss 4.645630836486816
bi 3 loss 4.019237041473389
Layer  1  loss:  4.619058132171631 0.0 10.952400207519531
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([176, 201, 351, 322], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.591279983520508
bi 1 loss 4.446073532104492
bi 2 loss 4.859292984008789
bi 3 loss 4.436341762542725
Layer  2  loss:  4.747771739959717 0.0 9.816341400146484
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([199, 194, 449, 159], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.832335472106934
bi 1 loss 4.747600078582764
bi 2 loss 5.026697158813477
bi 3 loss 4.471280574798584
Layer  3  loss:  4.873961925506592 0.0 9.694798469543457
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([199, 203, 666, 317], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.922091484069824
bi 1 loss 4.997251987457275
bi 2 loss 5.201645374298096
bi 3 loss 4.531489372253418
Layer  4  loss:  5.001935005187988 0.0 10.556314468383789
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([164, 215, 421, 445], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 5.24186897277832
bi 1 loss 4.944892406463623
bi 2 loss 5.399094581604004
bi 3 loss 4.599245071411133
Layer  5  loss:  5.077692985534668 0.0 11.011543273925781
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([166, 196, 564, 436], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 5.186511516571045
bi 1 loss 5.15572452545166
bi 2 loss 5.380009651184082
bi 3 loss 4.75799036026001
Layer  6  loss:  5.079523086547852 0.0 9.462567329406738
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([205, 238, 420, 211], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 5.3615336418151855
bi 1 loss 5.151334285736084
bi 2 loss 5.427675247192383
bi 3 loss 4.687324523925781
Epoch 0: :   3%|▎         | 15037/600000 [00:17<11:08, v_num=12, reduced_train_loss=2.740, global_step=1.5e+4, consumed_samples=60144.0, train_step_timing in s=0.422]Epoch 0: :   3%|▎         | 15037/600000 [00:17<11:08, v_num=12, reduced_train_loss=37.30, global_step=1.5e+4, consumed_samples=60148.0, train_step_timing in s=0.421]loss mask original None

First layer loss:  0.1599302738904953 torch.Size([655, 4]) 10.649523735046387 0.0
Max loss timestep torch.Size([655, 4]) tensor([326,  86, 198, 578], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.20148825645446777
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 1 loss 0.06439373642206192
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 2 loss 0.04771072044968605
speech mask sum tensor(98, device='cuda:0') loss mask sum tensor(98, device='cuda:0')
bi 3 loss 0.19235636293888092
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
logits torch.Size([655, 4, 257024]) labels torch.Size([655, 4]) 0 257023
Layer  0  loss:  0.16341544687747955 0.0 13.46895980834961
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([434, 146, 202, 607], device='cuda:0') tensor(607, device='cuda:0')
bi 0 loss 0.20540964603424072
bi 1 loss 0.05806470289826393
bi 2 loss 0.04300661385059357
bi 3 loss 0.200826957821846
Layer  1  loss:  0.21970239281654358 0.0 16.35337257385254
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([434, 131, 152, 600], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.34528693556785583
bi 1 loss 0.04130664840340614
bi 2 loss 0.031426869332790375
bi 3 loss 0.24183134734630585
Layer  2  loss:  0.19513460993766785 0.0 11.452244758605957
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([386, 161, 162, 601], device='cuda:0') tensor(601, device='cuda:0')
bi 0 loss 0.3077578842639923
bi 1 loss 0.05100065469741821
bi 2 loss 0.02160595916211605
bi 3 loss 0.21148104965686798
Layer  3  loss:  0.18140384554862976 0.0 11.2869291305542
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([295, 129, 198, 600], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.2658407986164093
bi 1 loss 0.03465568646788597
bi 2 loss 0.0435524582862854
bi 3 loss 0.2075861394405365
Layer  4  loss:  0.19808025658130646 0.0 10.88323974609375
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([434, 157, 140, 600], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.32613107562065125
bi 1 loss 0.05778181180357933
bi 2 loss 0.05558197200298309
bi 3 loss 0.19411598145961761
Layer  5  loss:  0.20263174176216125 0.0 12.005879402160645
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([434, 117, 204, 600], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.31161874532699585
bi 1 loss 0.0603201799094677
bi 2 loss 0.04644203186035156
bi 3 loss 0.2160147875547409
Layer  6  loss:  0.2177252620458603 0.0 14.250848770141602
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([272, 115, 199, 600], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.3263710141181946
bi 1 loss 0.04600853472948074
bi 2 loss 0.07185089588165283
bi 3 loss 0.23737357556819916
Epoch 0: :   3%|▎         | 15038/600000 [00:17<11:27, v_num=12, reduced_train_loss=37.30, global_step=1.5e+4, consumed_samples=60148.0, train_step_timing in s=0.421]Epoch 0: :   3%|▎         | 15038/600000 [00:17<11:27, v_num=12, reduced_train_loss=1.540, global_step=1.5e+4, consumed_samples=60152.0, train_step_timing in s=0.437]loss mask original None

First layer loss:  0.05507615953683853 torch.Size([603, 4]) 4.3968281745910645 0.0
Max loss timestep torch.Size([603, 4]) tensor([220, 558, 170, 166], device='cuda:0') tensor(558, device='cuda:0')
bi 0 loss 0.03579389303922653
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 1 loss 0.06874669343233109
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
bi 2 loss 0.04309644177556038
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 3 loss 0.02575378678739071
speech mask sum tensor(56, device='cuda:0') loss mask sum tensor(56, device='cuda:0')
logits torch.Size([603, 4, 257024]) labels torch.Size([603, 4]) 0 257022
Layer  0  loss:  0.07491940259933472 0.0 5.9506049156188965
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([186, 576, 170, 155], device='cuda:0') tensor(576, device='cuda:0')
bi 0 loss 0.04661111906170845
bi 1 loss 0.09563737362623215
bi 2 loss 0.05649329721927643
bi 3 loss 0.027177652344107628
Layer  1  loss:  0.09317733347415924 0.0 11.985116958618164
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([269, 558, 155, 175], device='cuda:0') tensor(558, device='cuda:0')
bi 0 loss 0.04455021396279335
bi 1 loss 0.12823379039764404
bi 2 loss 0.04335584491491318
bi 3 loss 0.038594234734773636
Layer  2  loss:  0.0811237096786499 0.0 4.40656852722168
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([277, 562, 133, 159], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.025989938527345657
bi 1 loss 0.12097463011741638
bi 2 loss 0.021829675883054733
bi 3 loss 0.021826444193720818
Layer  3  loss:  0.09080718457698822 0.0 4.641889572143555
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1020
Curr loss timestep torch.Size([603, 4]) tensor([268, 374, 179, 163], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.04664533957839012
bi 1 loss 0.12714290618896484
bi 2 loss 0.023971887305378914
bi 3 loss 0.0283794142305851
Layer  4  loss:  0.0791950672864914 0.0 5.990985870361328
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1020
Curr loss timestep torch.Size([603, 4]) tensor([266, 583, 176, 152], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.031377360224723816
bi 1 loss 0.11517337709665298
bi 2 loss 0.02387142926454544
bi 3 loss 0.020101573318243027
Layer  5  loss:  0.09573644399642944 0.0 6.191019058227539
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([102, 576, 155, 164], device='cuda:0') tensor(576, device='cuda:0')
bi 0 loss 0.03249993920326233
bi 1 loss 0.13990671932697296
bi 2 loss 0.03153163194656372
bi 3 loss 0.03658687323331833
Layer  6  loss:  0.08820100128650665 0.0 6.578949928283691
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([171, 558, 141, 154], device='cuda:0') tensor(558, device='cuda:0')
bi 0 loss 0.038378987461328506
bi 1 loss 0.1270834505558014
bi 2 loss 0.026994792744517326
bi 3 loss 0.018719764426350594
Epoch 0: :   3%|▎         | 15039/600000 [00:18<11:44, v_num=12, reduced_train_loss=1.540, global_step=1.5e+4, consumed_samples=60152.0, train_step_timing in s=0.437]Epoch 0: :   3%|▎         | 15039/600000 [00:18<11:44, v_num=12, reduced_train_loss=0.658, global_step=1.5e+4, consumed_samples=60156.0, train_step_timing in s=0.407]loss mask original None

First layer loss:  0.09623196721076965 torch.Size([574, 4]) 15.02513599395752 0.0
Max loss timestep torch.Size([574, 4]) tensor([290, 279, 335, 331], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.04316383972764015
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 1 loss 0.06185855716466904
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 2 loss 0.05294591560959816
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 3 loss 0.16416533291339874
speech mask sum tensor(428, device='cuda:0') loss mask sum tensor(428, device='cuda:0')
logits torch.Size([574, 4, 257024]) labels torch.Size([574, 4]) 0 257023
Layer  0  loss:  0.12445823848247528 0.0 14.7267427444458
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1023
Curr loss timestep torch.Size([574, 4]) tensor([295, 279, 300, 331], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.05956511199474335
bi 1 loss 0.10320716351270676
bi 2 loss 0.06134028360247612
bi 3 loss 0.20555035769939423
Layer  1  loss:  0.09844610095024109 0.0 7.127859115600586
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1022
Curr loss timestep torch.Size([574, 4]) tensor([296, 279, 323, 333], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.04824909567832947
bi 1 loss 0.0816916972398758
bi 2 loss 0.05145815759897232
bi 3 loss 0.1603042036294937
Layer  2  loss:  0.12356708198785782 0.0 13.836663246154785
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1023
Curr loss timestep torch.Size([574, 4]) tensor([297, 279, 482, 331], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.08005044609308243
bi 1 loss 0.08105550706386566
bi 2 loss 0.06575118750333786
bi 3 loss 0.19633686542510986
Layer  3  loss:  0.12021861970424652 0.0 12.991459846496582
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1018
Curr loss timestep torch.Size([574, 4]) tensor([297, 279, 301, 330], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.06751277297735214
bi 1 loss 0.09424098581075668
bi 2 loss 0.0653514713048935
bi 3 loss 0.19112537801265717
Layer  4  loss:  0.11274828761816025 0.0 7.650297164916992
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1022
Curr loss timestep torch.Size([574, 4]) tensor([297, 279, 336, 331], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.08148378133773804
bi 1 loss 0.13398416340351105
bi 2 loss 0.060219984501600266
bi 3 loss 0.15240058302879333
Layer  5  loss:  0.13463139533996582 0.0 17.61343765258789
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1023
Curr loss timestep torch.Size([574, 4]) tensor([297, 279, 457, 331], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.08093209564685822
bi 1 loss 0.12270456552505493
bi 2 loss 0.046510837972164154
bi 3 loss 0.21891559660434723
Layer  6  loss:  0.11882585287094116 0.0 11.281280517578125
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1022
Curr loss timestep torch.Size([574, 4]) tensor([297, 279, 312, 333], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.0692773386836052
bi 1 loss 0.08537326753139496
bi 2 loss 0.04875783622264862
bi 3 loss 0.19860514998435974
Epoch 0: :   3%|▎         | 15040/600000 [00:18<12:01, v_num=12, reduced_train_loss=0.658, global_step=1.5e+4, consumed_samples=60156.0, train_step_timing in s=0.407]Epoch 0: :   3%|▎         | 15040/600000 [00:18<12:01, v_num=12, reduced_train_loss=0.929, global_step=1.5e+4, consumed_samples=60160.0, train_step_timing in s=0.390]loss mask original None

First layer loss:  0.0291566364467144 torch.Size([359, 4]) 1.6665606498718262 0.0
Max loss timestep torch.Size([359, 4]) tensor([304, 253, 261, 172], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.031531937420368195
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
bi 1 loss 0.01878054067492485
speech mask sum tensor(171, device='cuda:0') loss mask sum tensor(171, device='cuda:0')
bi 2 loss 0.05550345033407211
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 3 loss 0.017822638154029846
speech mask sum tensor(269, device='cuda:0') loss mask sum tensor(269, device='cuda:0')
logits torch.Size([359, 4, 257024]) labels torch.Size([359, 4]) 0 257023
Layer  0  loss:  0.024693377315998077 0.0 0.8666061758995056
logits torch.Size([359, 4, 1024]) labels torch.Size([359, 4]) 0 1023
Curr loss timestep torch.Size([359, 4]) tensor([251, 324, 260, 117], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.030259033665060997
bi 1 loss 0.020913397893309593
bi 2 loss 0.033073823899030685
bi 3 loss 0.018603559583425522
Layer  1  loss:  0.02986038848757744 0.0 1.7838605642318726
logits torch.Size([359, 4, 1024]) labels torch.Size([359, 4]) 0 1023
Curr loss timestep torch.Size([359, 4]) tensor([270, 245, 278,  98], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.028480440378189087
bi 1 loss 0.030141456052660942
bi 2 loss 0.04433966055512428
bi 3 loss 0.02138533815741539
Layer  2  loss:  0.03409569337964058 0.0 7.329665660858154
logits torch.Size([359, 4, 1024]) labels torch.Size([359, 4]) 0 1022
Curr loss timestep torch.Size([359, 4]) tensor([195, 320, 260, 208], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.02882547490298748
bi 1 loss 0.01769864745438099
bi 2 loss 0.07731851935386658
bi 3 loss 0.02042056806385517
Layer  3  loss:  0.029745956882834435 0.0 3.301697015762329
logits torch.Size([359, 4, 1024]) labels torch.Size([359, 4]) 0 1021
Curr loss timestep torch.Size([359, 4]) tensor([261, 343, 260, 284], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.03231269121170044
bi 1 loss 0.018243808299303055
bi 2 loss 0.048586804419755936
bi 3 loss 0.02373240329325199
Layer  4  loss:  0.027974043041467667 0.0 4.784496784210205
logits torch.Size([359, 4, 1024]) labels torch.Size([359, 4]) 0 1022
Curr loss timestep torch.Size([359, 4]) tensor([197, 293, 260, 199], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.02771395817399025
bi 1 loss 0.018478794023394585
bi 2 loss 0.04930293560028076
bi 3 loss 0.02076094225049019
Layer  5  loss:  0.027137748897075653 0.0 1.3061761856079102
logits torch.Size([359, 4, 1024]) labels torch.Size([359, 4]) 0 1022
Curr loss timestep torch.Size([359, 4]) tensor([286, 319, 296, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.029875673353672028
bi 1 loss 0.02208176627755165
bi 2 loss 0.038485195487737656
bi 3 loss 0.021634915843605995
Layer  6  loss:  0.03559041768312454 0.0 2.887681007385254
logits torch.Size([359, 4, 1024]) labels torch.Size([359, 4]) 0 1019
Curr loss timestep torch.Size([359, 4]) tensor([258, 235, 259, 281], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.03411182016134262
bi 1 loss 0.02252160757780075
bi 2 loss 0.06762861460447311
bi 3 loss 0.02462748810648918
Epoch 0: :   3%|▎         | 15041/600000 [00:18<12:13, v_num=12, reduced_train_loss=0.929, global_step=1.5e+4, consumed_samples=60160.0, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15041/600000 [00:18<12:13, v_num=12, reduced_train_loss=0.238, global_step=1.5e+4, consumed_samples=60164.0, train_step_timing in s=0.274]loss mask original None

First layer loss:  0.28277480602264404 torch.Size([699, 4]) 12.660379409790039 0.0
Max loss timestep torch.Size([699, 4]) tensor([514, 637, 276, 538], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.3431914448738098
speech mask sum tensor(393, device='cuda:0') loss mask sum tensor(393, device='cuda:0')
bi 1 loss 0.3132895827293396
speech mask sum tensor(483, device='cuda:0') loss mask sum tensor(483, device='cuda:0')
bi 2 loss 0.24364551901817322
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 3 loss 0.2123173475265503
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
logits torch.Size([699, 4, 257024]) labels torch.Size([699, 4]) 0 257022
Layer  0  loss:  0.32217323780059814 0.0 16.234756469726562
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1023
Curr loss timestep torch.Size([699, 4]) tensor([517, 665, 276, 538], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.3916672170162201
bi 1 loss 0.36769694089889526
bi 2 loss 0.31799089908599854
bi 3 loss 0.2080719769001007
Layer  1  loss:  0.3211902678012848 0.0 14.193111419677734
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1023
Curr loss timestep torch.Size([699, 4]) tensor([544, 665, 276, 537], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.4176256060600281
bi 1 loss 0.3585532307624817
bi 2 loss 0.21593284606933594
bi 3 loss 0.2438582330942154
Layer  2  loss:  0.36471831798553467 0.0 14.251776695251465
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1022
Curr loss timestep torch.Size([699, 4]) tensor([517, 508, 325, 530], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.43095168471336365
bi 1 loss 0.39101704955101013
bi 2 loss 0.2996251881122589
bi 3 loss 0.3071439266204834
Layer  3  loss:  0.3925648629665375 0.0 21.26614761352539
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1022
Curr loss timestep torch.Size([699, 4]) tensor([514, 567, 276, 525], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.3930681049823761
bi 1 loss 0.4325428903102875
bi 2 loss 0.3862690329551697
bi 3 loss 0.3498241603374481
Layer  4  loss:  0.4066171646118164 0.0 14.100757598876953
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1023
Curr loss timestep torch.Size([699, 4]) tensor([517, 637, 276, 525], device='cuda:0') tensor(637, device='cuda:0')
bi 0 loss 0.44617760181427
bi 1 loss 0.40265321731567383
bi 2 loss 0.34227365255355835
bi 3 loss 0.407850444316864
Layer  5  loss:  0.42110443115234375 0.0 18.776020050048828
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1022
Curr loss timestep torch.Size([699, 4]) tensor([517, 637, 325, 565], device='cuda:0') tensor(637, device='cuda:0')
bi 0 loss 0.45378729701042175
bi 1 loss 0.48120465874671936
bi 2 loss 0.34556493163108826
bi 3 loss 0.3615429997444153
Layer  6  loss:  0.3886853754520416 0.0 16.216135025024414
logits torch.Size([699, 4, 1024]) labels torch.Size([699, 4]) 0 1019
Curr loss timestep torch.Size([699, 4]) tensor([585, 637, 276, 525], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.3818257749080658
bi 1 loss 0.42605510354042053
bi 2 loss 0.36550408601760864
bi 3 loss 0.3645017147064209
Epoch 0: :   3%|▎         | 15042/600000 [00:19<12:32, v_num=12, reduced_train_loss=0.238, global_step=1.5e+4, consumed_samples=60164.0, train_step_timing in s=0.274]Epoch 0: :   3%|▎         | 15042/600000 [00:19<12:32, v_num=12, reduced_train_loss=2.900, global_step=1.5e+4, consumed_samples=60168.0, train_step_timing in s=0.469]loss mask original None

First layer loss:  0.08109811693429947 torch.Size([510, 4]) 5.844614028930664 0.0
Max loss timestep torch.Size([510, 4]) tensor([312, 257, 376, 351], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.06854714453220367
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 1 loss 0.11034884303808212
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 2 loss 0.11027674376964569
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 3 loss 0.05391833931207657
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
logits torch.Size([510, 4, 257024]) labels torch.Size([510, 4]) 0 257022
Layer  0  loss:  0.09193005412817001 0.0 4.100224018096924
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([315, 306, 498, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.07502495497465134
bi 1 loss 0.09218741953372955
bi 2 loss 0.1366763859987259
bi 3 loss 0.07611697167158127
Layer  1  loss:  0.08487606793642044 0.0 6.694652080535889
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([313, 306, 369, 352], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.125896617770195
bi 1 loss 0.07362810522317886
bi 2 loss 0.08099957555532455
bi 3 loss 0.062099456787109375
Layer  2  loss:  0.10185270011425018 0.0 11.553226470947266
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([313, 312, 403, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.1278543770313263
bi 1 loss 0.07154013961553574
bi 2 loss 0.07838526368141174
bi 3 loss 0.11541422456502914
Layer  3  loss:  0.07924986630678177 0.0 5.677478313446045
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([312, 290, 378, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.07504437118768692
bi 1 loss 0.05500258505344391
bi 2 loss 0.10551407188177109
bi 3 loss 0.08062952011823654
Layer  4  loss:  0.0960729792714119 0.0 5.331375598907471
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([313, 270, 358, 351], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.1156817078590393
bi 1 loss 0.08887068927288055
bi 2 loss 0.09409256279468536
bi 3 loss 0.08640190958976746
Layer  5  loss:  0.11096698045730591 0.0 6.3872761726379395
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([312, 307, 469, 351], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.14338602125644684
bi 1 loss 0.09245646744966507
bi 2 loss 0.12648363411426544
bi 3 loss 0.08692166209220886
Layer  6  loss:  0.11276684701442719 0.0 10.848143577575684
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1019
Curr loss timestep torch.Size([510, 4]) tensor([315, 299, 391, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.11953703314065933
bi 1 loss 0.08851056545972824
bi 2 loss 0.1203426644206047
bi 3 loss 0.11760929226875305
Epoch 0: :   3%|▎         | 15043/600000 [00:19<12:47, v_num=12, reduced_train_loss=2.900, global_step=1.5e+4, consumed_samples=60168.0, train_step_timing in s=0.469]Epoch 0: :   3%|▎         | 15043/600000 [00:19<12:47, v_num=12, reduced_train_loss=0.759, global_step=1.5e+4, consumed_samples=60172.0, train_step_timing in s=0.350]loss mask original None

First layer loss:  3.785001754760742 torch.Size([436, 4]) 11.430827140808105 0.0
Max loss timestep torch.Size([436, 4]) tensor([184, 320, 257, 177], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 3.7726175785064697
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
bi 1 loss 3.5847465991973877
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 2 loss 3.8378493785858154
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 3 loss 3.8733441829681396
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
logits torch.Size([436, 4, 257024]) labels torch.Size([436, 4]) 0 257022
Layer  0  loss:  4.383306503295898 0.0 10.999695777893066
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([198, 288, 214, 124], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 4.467354774475098
bi 1 loss 4.327207565307617
bi 2 loss 4.085755825042725
bi 3 loss 4.473602294921875
Layer  1  loss:  4.762579917907715 0.0 10.011113166809082
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([121, 347, 232, 147], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 4.4285078048706055
bi 1 loss 4.7993388175964355
bi 2 loss 4.834826469421387
bi 3 loss 4.930308818817139
Layer  2  loss:  4.916405200958252 0.0 10.154277801513672
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([222, 319, 245, 250], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 4.89878511428833
bi 1 loss 5.006178379058838
bi 2 loss 4.841609954833984
bi 3 loss 4.9115891456604
Layer  3  loss:  5.165200233459473 0.0 10.087419509887695
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([153, 410, 261, 110], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 5.351437091827393
bi 1 loss 5.125396728515625
bi 2 loss 4.885045528411865
bi 3 loss 5.174910068511963
Layer  4  loss:  5.297301292419434 0.0 9.673810005187988
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([185, 397, 266, 350], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 5.365603923797607
bi 1 loss 5.275857448577881
bi 2 loss 5.286052703857422
bi 3 loss 5.268660545349121
Layer  5  loss:  5.35759973526001 0.0 9.529708862304688
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([246, 377, 235, 415], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 5.555094242095947
bi 1 loss 5.2872114181518555
bi 2 loss 5.12023401260376
bi 3 loss 5.358835697174072
Layer  6  loss:  5.413300514221191 0.0 10.63497543334961
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([ 85, 363, 246, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 5.428366184234619
bi 1 loss 5.4756855964660645
bi 2 loss 5.314309597015381
bi 3 loss 5.410745620727539
Epoch 0: :   3%|▎         | 15044/600000 [00:20<13:00, v_num=12, reduced_train_loss=0.759, global_step=1.5e+4, consumed_samples=60172.0, train_step_timing in s=0.350]Epoch 0: :   3%|▎         | 15044/600000 [00:20<13:00, v_num=12, reduced_train_loss=39.10, global_step=1.5e+4, consumed_samples=60176.0, train_step_timing in s=0.302]loss mask original None

First layer loss:  3.821214199066162 torch.Size([468, 4]) 11.740078926086426 0.0
Max loss timestep torch.Size([468, 4]) tensor([404, 198, 223, 297], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 4.283390998840332
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
bi 1 loss 4.1017351150512695
speech mask sum tensor(414, device='cuda:0') loss mask sum tensor(414, device='cuda:0')
bi 2 loss 3.345852851867676
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 3 loss 3.201774835586548
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
logits torch.Size([468, 4, 257024]) labels torch.Size([468, 4]) 0 257023
Layer  0  loss:  4.332362651824951 0.0 10.863262176513672
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([393, 229, 191, 377], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 4.6565937995910645
bi 1 loss 4.692018508911133
bi 2 loss 3.9708499908447266
bi 3 loss 3.6303741931915283
Layer  1  loss:  4.502964496612549 0.0 10.56264591217041
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([215, 401, 304, 441], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 4.962137222290039
bi 1 loss 4.725329875946045
bi 2 loss 4.127560615539551
bi 3 loss 3.900085687637329
Layer  2  loss:  4.729862213134766 0.0 11.041316986083984
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([314, 358, 194, 328], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 5.038878440856934
bi 1 loss 5.0244221687316895
bi 2 loss 4.2024126052856445
bi 3 loss 4.315398693084717
Layer  3  loss:  4.895047664642334 0.0 10.82563591003418
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([306, 170, 191, 444], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 5.222115516662598
bi 1 loss 5.204216003417969
bi 2 loss 4.439691066741943
bi 3 loss 4.3666462898254395
Layer  4  loss:  4.91648530960083 0.0 10.172978401184082
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([314, 103, 183, 452], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 5.120579719543457
bi 1 loss 5.230907440185547
bi 2 loss 4.4829936027526855
bi 3 loss 4.505069732666016
Layer  5  loss:  5.088324069976807 0.0 10.006213188171387
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([204, 371, 237, 453], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 5.22659158706665
bi 1 loss 5.416219234466553
bi 2 loss 4.631916522979736
bi 3 loss 4.752098560333252
Layer  6  loss:  5.104620933532715 0.0 9.786596298217773
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([323, 215, 170, 283], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 5.28572940826416
bi 1 loss 5.460498809814453
bi 2 loss 4.670429706573486
bi 3 loss 4.646610260009766
Epoch 0: :   3%|▎         | 15045/600000 [00:20<13:14, v_num=12, reduced_train_loss=39.10, global_step=1.5e+4, consumed_samples=60176.0, train_step_timing in s=0.302]Epoch 0: :   3%|▎         | 15045/600000 [00:20<13:14, v_num=12, reduced_train_loss=37.40, global_step=1.5e+4, consumed_samples=60180.0, train_step_timing in s=0.316]loss mask original None

First layer loss:  0.07932234555482864 torch.Size([519, 4]) 5.390843391418457 0.0
Max loss timestep torch.Size([519, 4]) tensor([266, 268, 354, 274], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.10501463711261749
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 1 loss 0.052453141659498215
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 2 loss 0.07896297425031662
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
bi 3 loss 0.07521723955869675
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
logits torch.Size([519, 4, 257024]) labels torch.Size([519, 4]) 0 257022
Layer  0  loss:  0.10166186094284058 0.0 10.943025588989258
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([266, 209, 273, 440], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.1624642163515091
bi 1 loss 0.025865448638796806
bi 2 loss 0.08582282811403275
bi 3 loss 0.11344478279352188
Layer  1  loss:  0.09405442327260971 0.0 9.881335258483887
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([267, 267, 273, 274], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.17466355860233307
bi 1 loss 0.06644731014966965
bi 2 loss 0.077692911028862
bi 3 loss 0.08441227674484253
Layer  2  loss:  0.09610635787248611 0.0 9.140595436096191
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([267, 200, 296, 274], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.16592468321323395
bi 1 loss 0.052993033081293106
bi 2 loss 0.073976069688797
bi 3 loss 0.1025962308049202
Layer  3  loss:  0.12190155684947968 0.0 10.248908996582031
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([269, 264, 354, 274], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.22542288899421692
bi 1 loss 0.0483810193836689
bi 2 loss 0.11911572515964508
bi 3 loss 0.09762853384017944
Layer  4  loss:  0.08642325550317764 0.0 7.404109954833984
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([267, 272, 354, 274], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.15065565705299377
bi 1 loss 0.022818978875875473
bi 2 loss 0.0655733048915863
bi 3 loss 0.09943757206201553
Layer  5  loss:  0.08931630104780197 0.0 7.9545769691467285
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([267, 231, 488, 302], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.14296680688858032
bi 1 loss 0.02778310887515545
bi 2 loss 0.08154796808958054
bi 3 loss 0.09073121845722198
Layer  6  loss:  0.11798180639743805 0.0 11.691635131835938
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([266, 272, 260, 274], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.18915775418281555
bi 1 loss 0.04256046563386917
bi 2 loss 0.09662614017724991
bi 3 loss 0.13161005079746246
Epoch 0: :   3%|▎         | 15046/600000 [00:20<13:29, v_num=12, reduced_train_loss=37.40, global_step=1.5e+4, consumed_samples=60180.0, train_step_timing in s=0.316]Epoch 0: :   3%|▎         | 15046/600000 [00:20<13:29, v_num=12, reduced_train_loss=0.787, global_step=1.5e+4, consumed_samples=60184.0, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.11294601857662201 torch.Size([586, 4]) 7.768274784088135 0.0
Max loss timestep torch.Size([586, 4]) tensor([560, 307, 100, 172], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.16537705063819885
speech mask sum tensor(504, device='cuda:0') loss mask sum tensor(504, device='cuda:0')
bi 1 loss 0.09867142140865326
speech mask sum tensor(107, device='cuda:0') loss mask sum tensor(107, device='cuda:0')
bi 2 loss 0.033564645797014236
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
bi 3 loss 0.03530341386795044
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
logits torch.Size([586, 4, 257024]) labels torch.Size([586, 4]) 0 257022
Layer  0  loss:  0.11612561345100403 0.0 8.12028980255127
logits torch.Size([586, 4, 1024]) labels torch.Size([586, 4]) 0 1023
Curr loss timestep torch.Size([586, 4]) tensor([367, 311, 197, 194], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.1746138334274292
bi 1 loss 0.050596609711647034
bi 2 loss 0.03932539373636246
bi 3 loss 0.05160779133439064
Layer  1  loss:  0.15612073242664337 0.0 12.236746788024902
logits torch.Size([586, 4, 1024]) labels torch.Size([586, 4]) 0 1022
Curr loss timestep torch.Size([586, 4]) tensor([560, 268, 203, 284], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.2415034919977188
bi 1 loss 0.09104160219430923
bi 2 loss 0.046569883823394775
bi 3 loss 0.03779973089694977
Layer  2  loss:  0.14003776013851166 0.0 6.81201171875
logits torch.Size([586, 4, 1024]) labels torch.Size([586, 4]) 0 1023
Curr loss timestep torch.Size([586, 4]) tensor([367, 279, 130, 303], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.19492210447788239
bi 1 loss 0.0926770344376564
bi 2 loss 0.06330931186676025
bi 3 loss 0.07460875809192657
Layer  3  loss:  0.13474494218826294 0.0 11.887640953063965
logits torch.Size([586, 4, 1024]) labels torch.Size([586, 4]) 0 1022
Curr loss timestep torch.Size([586, 4]) tensor([367, 318, 164, 264], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.20536771416664124
bi 1 loss 0.06397107243537903
bi 2 loss 0.03312753885984421
bi 3 loss 0.06052394211292267
Layer  4  loss:  0.1611408293247223 0.0 11.959134101867676
logits torch.Size([586, 4, 1024]) labels torch.Size([586, 4]) 0 1022
Curr loss timestep torch.Size([586, 4]) tensor([560, 301, 161, 275], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.24640920758247375
bi 1 loss 0.0887451320886612
bi 2 loss 0.05720114707946777
bi 3 loss 0.042298927903175354
Layer  5  loss:  0.1382283866405487 0.0 12.365357398986816
logits torch.Size([586, 4, 1024]) labels torch.Size([586, 4]) 0 1023
Curr loss timestep torch.Size([586, 4]) tensor([560, 305, 150, 264], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.20370544493198395
bi 1 loss 0.054512396454811096
bi 2 loss 0.05981037765741348
bi 3 loss 0.06514160335063934
Layer  6  loss:  0.14765720069408417 0.0 9.889484405517578
logits torch.Size([586, 4, 1024]) labels torch.Size([586, 4]) 0 1023
Curr loss timestep torch.Size([586, 4]) tensor([573, 254, 148, 291], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.21759551763534546
bi 1 loss 0.05935916304588318
bi 2 loss 0.060522835701704025
bi 3 loss 0.0724218487739563
Epoch 0: :   3%|▎         | 15047/600000 [00:21<13:46, v_num=12, reduced_train_loss=0.787, global_step=1.5e+4, consumed_samples=60184.0, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15047/600000 [00:21<13:46, v_num=12, reduced_train_loss=1.110, global_step=1.5e+4, consumed_samples=60188.0, train_step_timing in s=0.393]loss mask original None

First layer loss:  3.919356107711792 torch.Size([680, 4]) 11.188079833984375 0.0
Max loss timestep torch.Size([680, 4]) tensor([231, 247, 279, 474], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 4.183155059814453
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
bi 1 loss 3.4609341621398926
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 2 loss 3.233624219894409
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 3 loss 4.035356521606445
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
logits torch.Size([680, 4, 257024]) labels torch.Size([680, 4]) 0 257023
Layer  0  loss:  4.356939792633057 0.0 10.034679412841797
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([511, 234, 190, 510], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 4.516360759735107
bi 1 loss 4.0676727294921875
bi 2 loss 4.016735076904297
bi 3 loss 4.401806354522705
Layer  1  loss:  4.814058303833008 0.0 11.447360038757324
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([526, 184, 285, 260], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 5.067792892456055
bi 1 loss 4.656557559967041
bi 2 loss 4.189353942871094
bi 3 loss 4.812335968017578
Layer  2  loss:  5.0819783210754395 0.0 12.197108268737793
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([305, 193, 259, 572], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 5.10578727722168
bi 1 loss 5.071846008300781
bi 2 loss 4.584329128265381
bi 3 loss 5.254880905151367
Layer  3  loss:  5.217846393585205 0.0 10.173236846923828
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([544, 194, 279, 269], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 5.217408180236816
bi 1 loss 5.00254487991333
bi 2 loss 4.778265953063965
bi 3 loss 5.468811511993408
Layer  4  loss:  5.3148512840271 0.0 9.453807830810547
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([441, 198, 274, 281], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 5.362498760223389
bi 1 loss 4.983339309692383
bi 2 loss 4.8262224197387695
bi 3 loss 5.568193435668945
Layer  5  loss:  5.423699378967285 0.0 9.717401504516602
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([453, 197, 298, 525], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 5.56140661239624
bi 1 loss 5.219027996063232
bi 2 loss 4.858797073364258
bi 3 loss 5.55444860458374
Layer  6  loss:  5.531780242919922 0.0 10.5211820602417
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([550, 263, 260, 339], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 5.71300745010376
bi 1 loss 5.224598407745361
bi 2 loss 4.979717254638672
bi 3 loss 5.640973091125488
Epoch 0: :   3%|▎         | 15048/600000 [00:21<14:03, v_num=12, reduced_train_loss=1.110, global_step=1.5e+4, consumed_samples=60188.0, train_step_timing in s=0.393]Epoch 0: :   3%|▎         | 15048/600000 [00:21<14:03, v_num=12, reduced_train_loss=39.70, global_step=1.5e+4, consumed_samples=60192.0, train_step_timing in s=0.400]loss mask original None

First layer loss:  0.14479577541351318 torch.Size([599, 4]) 12.093941688537598 0.0
Max loss timestep torch.Size([599, 4]) tensor([285, 297, 341, 559], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.10625962167978287
speech mask sum tensor(288, device='cuda:0') loss mask sum tensor(288, device='cuda:0')
bi 1 loss 0.2441207319498062
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 2 loss 0.10465191304683685
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 3 loss 0.14723584055900574
speech mask sum tensor(392, device='cuda:0') loss mask sum tensor(392, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257022
Layer  0  loss:  0.17739717662334442 0.0 10.550474166870117
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([285, 297, 313, 462], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.20646531879901886
bi 1 loss 0.14068691432476044
bi 2 loss 0.19003410637378693
bi 3 loss 0.1670738011598587
Layer  1  loss:  0.16316281259059906 0.0 12.054764747619629
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([285, 297, 296, 559], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.13729482889175415
bi 1 loss 0.21735168993473053
bi 2 loss 0.13593508303165436
bi 3 loss 0.1716126948595047
Layer  2  loss:  0.1999969780445099 0.0 8.488029479980469
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([285, 296, 295, 559], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.19106467068195343
bi 1 loss 0.29401537775993347
bi 2 loss 0.17505376040935516
bi 3 loss 0.17334339022636414
Layer  3  loss:  0.20333926379680634 0.0 10.050893783569336
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([283, 297, 335, 559], device='cuda:0') tensor(559, device='cuda:0')
bi 0 loss 0.21671989560127258
bi 1 loss 0.1508515477180481
bi 2 loss 0.1663709431886673
bi 3 loss 0.24606762826442719
Layer  4  loss:  0.20891685783863068 0.0 15.2912015914917
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([285, 297, 320, 559], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.22460198402404785
bi 1 loss 0.2159222960472107
bi 2 loss 0.1978531777858734
bi 3 loss 0.20107059180736542
Layer  5  loss:  0.21488620340824127 0.0 11.617659568786621
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([283, 297, 312, 559], device='cuda:0') tensor(559, device='cuda:0')
bi 0 loss 0.2253093719482422
bi 1 loss 0.20270374417304993
bi 2 loss 0.1786082237958908
bi 3 loss 0.23793959617614746
Layer  6  loss:  0.23604688048362732 0.0 20.016515731811523
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([218, 297, 313, 559], device='cuda:0') tensor(559, device='cuda:0')
bi 0 loss 0.18641799688339233
bi 1 loss 0.22559323906898499
bi 2 loss 0.20991834998130798
bi 3 loss 0.29551926255226135
Epoch 0: :   3%|▎         | 15049/600000 [00:22<14:20, v_num=12, reduced_train_loss=39.70, global_step=1.5e+4, consumed_samples=60192.0, train_step_timing in s=0.400]Epoch 0: :   3%|▎         | 15049/600000 [00:22<14:20, v_num=12, reduced_train_loss=1.550, global_step=1.5e+4, consumed_samples=60196.0, train_step_timing in s=0.404]loss mask original None

First layer loss:  3.25396990776062 torch.Size([544, 4]) 12.087837219238281 0.0
Max loss timestep torch.Size([544, 4]) tensor([166, 331, 212, 104], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 3.0827865600585938
speech mask sum tensor(489, device='cuda:0') loss mask sum tensor(489, device='cuda:0')
bi 1 loss 3.9619505405426025
speech mask sum tensor(282, device='cuda:0') loss mask sum tensor(282, device='cuda:0')
bi 2 loss 3.4519028663635254
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 3 loss 2.8198435306549072
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
logits torch.Size([544, 4, 257024]) labels torch.Size([544, 4]) 0 257023
Layer  0  loss:  3.9330661296844482 0.0 10.729341506958008
logits torch.Size([544, 4, 1024]) labels torch.Size([544, 4]) 0 1023
Curr loss timestep torch.Size([544, 4]) tensor([187, 353, 219, 103], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 3.548860549926758
bi 1 loss 4.622002124786377
bi 2 loss 3.81811785697937
bi 3 loss 3.9426281452178955
Layer  1  loss:  4.417490482330322 0.0 11.236906051635742
logits torch.Size([544, 4, 1024]) labels torch.Size([544, 4]) 0 1023
Curr loss timestep torch.Size([544, 4]) tensor([234, 282, 243,  56], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.013761520385742
bi 1 loss 4.972301959991455
bi 2 loss 4.088954925537109
bi 3 loss 4.639786243438721
Layer  2  loss:  4.653535842895508 0.0 10.931015968322754
logits torch.Size([544, 4, 1024]) labels torch.Size([544, 4]) 0 1023
Curr loss timestep torch.Size([544, 4]) tensor([216, 164, 241, 314], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 4.283979892730713
bi 1 loss 5.218714714050293
bi 2 loss 3.9099347591400146
bi 3 loss 4.921840190887451
Layer  3  loss:  4.748226165771484 0.0 11.077530860900879
logits torch.Size([544, 4, 1024]) labels torch.Size([544, 4]) 0 1021
Curr loss timestep torch.Size([544, 4]) tensor([ 91, 336, 264, 336], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 4.318968296051025
bi 1 loss 5.345550537109375
bi 2 loss 4.393634796142578
bi 3 loss 4.979094982147217
Layer  4  loss:  4.954351425170898 0.0 9.807003021240234
logits torch.Size([544, 4, 1024]) labels torch.Size([544, 4]) 0 1022
Curr loss timestep torch.Size([544, 4]) tensor([313, 285, 257, 118], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 4.560095310211182
bi 1 loss 5.503870964050293
bi 2 loss 4.564473628997803
bi 3 loss 5.182662010192871
Layer  5  loss:  4.974425315856934 0.0 10.512689590454102
logits torch.Size([544, 4, 1024]) labels torch.Size([544, 4]) 0 1023
Curr loss timestep torch.Size([544, 4]) tensor([267, 174, 250, 335], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 4.5146989822387695
bi 1 loss 5.592535495758057
bi 2 loss 4.417835712432861
bi 3 loss 5.288843154907227
Layer  6  loss:  5.010214328765869 0.0 10.391033172607422
logits torch.Size([544, 4, 1024]) labels torch.Size([544, 4]) 0 1022
Curr loss timestep torch.Size([544, 4]) tensor([412, 185, 231, 333], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 4.578782081604004
bi 1 loss 5.747331619262695
bi 2 loss 4.371672630310059
bi 3 loss 5.190557956695557
Epoch 0: :   3%|▎         | 15050/600000 [00:22<14:36, v_num=12, reduced_train_loss=1.550, global_step=1.5e+4, consumed_samples=60196.0, train_step_timing in s=0.404]Epoch 0: :   3%|▎         | 15050/600000 [00:22<14:36, v_num=12, reduced_train_loss=35.90, global_step=1.5e+4, consumed_samples=60200.0, train_step_timing in s=0.376]loss mask original None

First layer loss:  3.959705352783203 torch.Size([488, 4]) 10.384968757629395 0.0
Max loss timestep torch.Size([488, 4]) tensor([236, 228,  83, 191], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 3.816476345062256
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 1 loss 4.067389965057373
speech mask sum tensor(404, device='cuda:0') loss mask sum tensor(404, device='cuda:0')
bi 2 loss 3.5963504314422607
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 4.175478935241699
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257023
Layer  0  loss:  4.357049465179443 0.0 11.424657821655273
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([376, 376, 129, 133], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 4.5001749992370605
bi 1 loss 4.304593086242676
bi 2 loss 4.107728481292725
bi 3 loss 4.471990585327148
Layer  1  loss:  4.662514686584473 0.0 9.873559951782227
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([299, 143, 108, 175], device='cuda:0') tensor(108, device='cuda:0')
bi 0 loss 4.552185535430908
bi 1 loss 4.598851203918457
bi 2 loss 4.605859279632568
bi 3 loss 4.993757247924805
Layer  2  loss:  4.897396087646484 0.0 11.342472076416016
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([259, 105,  97,  75], device='cuda:0') tensor(105, device='cuda:0')
bi 0 loss 4.645078659057617
bi 1 loss 4.914192199707031
bi 2 loss 4.82377290725708
bi 3 loss 5.246855735778809
Layer  3  loss:  5.055893421173096 0.0 10.476810455322266
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([307, 446, 168, 134], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 5.095954418182373
bi 1 loss 5.001003265380859
bi 2 loss 5.1197285652160645
bi 3 loss 5.079531192779541
Layer  4  loss:  5.206029891967773 0.0 10.35262680053711
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([292, 353, 119, 151], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 5.186604976654053
bi 1 loss 5.133233070373535
bi 2 loss 5.161818504333496
bi 3 loss 5.428793430328369
Layer  5  loss:  5.245546817779541 0.0 9.453763961791992
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([285, 270, 103, 164], device='cuda:0') tensor(118, device='cuda:0')
bi 0 loss 5.043060779571533
bi 1 loss 5.196933269500732
bi 2 loss 5.445690631866455
bi 3 loss 5.473521709442139
Layer  6  loss:  5.3053998947143555 0.0 10.287514686584473
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([280, 353, 156, 186], device='cuda:0') tensor(133, device='cuda:0')
bi 0 loss 5.262969493865967
bi 1 loss 5.260876178741455
bi 2 loss 5.4004998207092285
bi 3 loss 5.391170024871826
Epoch 0: :   3%|▎         | 15051/600000 [00:22<14:50, v_num=12, reduced_train_loss=35.90, global_step=1.5e+4, consumed_samples=60200.0, train_step_timing in s=0.376]Epoch 0: :   3%|▎         | 15051/600000 [00:22<14:50, v_num=12, reduced_train_loss=38.70, global_step=1.5e+4, consumed_samples=60204.0, train_step_timing in s=0.336]loss mask original None

First layer loss:  0.1649339199066162 torch.Size([702, 4]) 14.700966835021973 0.0
Max loss timestep torch.Size([702, 4]) tensor([340, 495, 162, 133], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.06066206842660904
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
bi 1 loss 0.2782016694545746
speech mask sum tensor(503, device='cuda:0') loss mask sum tensor(503, device='cuda:0')
bi 2 loss 0.07816579192876816
speech mask sum tensor(264, device='cuda:0') loss mask sum tensor(264, device='cuda:0')
bi 3 loss 0.050220225006341934
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
logits torch.Size([702, 4, 257024]) labels torch.Size([702, 4]) 0 257022
Layer  0  loss:  0.20581212639808655 0.0 12.830185890197754
logits torch.Size([702, 4, 1024]) labels torch.Size([702, 4]) 0 1023
Curr loss timestep torch.Size([702, 4]) tensor([340, 495, 336,  96], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.11376601457595825
bi 1 loss 0.3517167866230011
bi 2 loss 0.05513310059905052
bi 3 loss 0.06387929618358612
Layer  1  loss:  0.20971335470676422 0.0 16.08818244934082
logits torch.Size([702, 4, 1024]) labels torch.Size([702, 4]) 0 1022
Curr loss timestep torch.Size([702, 4]) tensor([294, 495, 308, 121], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.08683225512504578
bi 1 loss 0.37006810307502747
bi 2 loss 0.06059781089425087
bi 3 loss 0.06136404722929001
Layer  2  loss:  0.2611716389656067 0.0 16.390729904174805
logits torch.Size([702, 4, 1024]) labels torch.Size([702, 4]) 0 1023
Curr loss timestep torch.Size([702, 4]) tensor([268, 496, 306, 112], device='cuda:0') tensor(496, device='cuda:0')
bi 0 loss 0.08516794443130493
bi 1 loss 0.4550821781158447
bi 2 loss 0.11525523662567139
bi 3 loss 0.050157174468040466
Layer  3  loss:  0.2265624701976776 0.0 12.156652450561523
logits torch.Size([702, 4, 1024]) labels torch.Size([702, 4]) 0 1022
Curr loss timestep torch.Size([702, 4]) tensor([424, 496, 319, 148], device='cuda:0') tensor(496, device='cuda:0')
bi 0 loss 0.1249336525797844
bi 1 loss 0.3796798586845398
bi 2 loss 0.08274339884519577
bi 3 loss 0.047555841505527496
Layer  4  loss:  0.24690309166908264 0.0 14.666478157043457
logits torch.Size([702, 4, 1024]) labels torch.Size([702, 4]) 0 1021
Curr loss timestep torch.Size([702, 4]) tensor([409, 494, 307, 110], device='cuda:0') tensor(494, device='cuda:0')
bi 0 loss 0.1040845438838005
bi 1 loss 0.43171238899230957
bi 2 loss 0.08184885233640671
bi 3 loss 0.05847018212080002
Layer  5  loss:  0.2441939264535904 0.0 16.27083969116211
logits torch.Size([702, 4, 1024]) labels torch.Size([702, 4]) 0 1023
Curr loss timestep torch.Size([702, 4]) tensor([409, 495, 307,  88], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.11046552658081055
bi 1 loss 0.4024198353290558
bi 2 loss 0.1247769445180893
bi 3 loss 0.046834204345941544
Layer  6  loss:  0.2520819902420044 0.0 14.982089042663574
logits torch.Size([702, 4, 1024]) labels torch.Size([702, 4]) 0 1022
Curr loss timestep torch.Size([702, 4]) tensor([471, 494, 144, 147], device='cuda:0') tensor(494, device='cuda:0')
bi 0 loss 0.09430879354476929
bi 1 loss 0.4551439583301544
bi 2 loss 0.06984367221593857
bi 3 loss 0.049971312284469604
Epoch 0: :   3%|▎         | 15052/600000 [00:23<15:10, v_num=12, reduced_train_loss=38.70, global_step=1.5e+4, consumed_samples=60204.0, train_step_timing in s=0.336]Epoch 0: :   3%|▎         | 15052/600000 [00:23<15:10, v_num=12, reduced_train_loss=1.810, global_step=15051.0, consumed_samples=60208.0, train_step_timing in s=0.469]loss mask original None

First layer loss:  3.7280759811401367 torch.Size([524, 4]) 10.879018783569336 0.0
Max loss timestep torch.Size([524, 4]) tensor([173, 326, 215, 446], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 3.9473114013671875
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
bi 1 loss 2.9415812492370605
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 2 loss 4.349433422088623
speech mask sum tensor(354, device='cuda:0') loss mask sum tensor(354, device='cuda:0')
bi 3 loss 3.4155466556549072
speech mask sum tensor(251, device='cuda:0') loss mask sum tensor(251, device='cuda:0')
logits torch.Size([524, 4, 257024]) labels torch.Size([524, 4]) 0 257023
Layer  0  loss:  4.402230739593506 0.0 13.003095626831055
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([228, 308, 414, 365], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 4.641698837280273
bi 1 loss 4.024806499481201
bi 2 loss 4.7332763671875
bi 3 loss 4.046497344970703
Layer  1  loss:  4.654374599456787 0.0 10.920708656311035
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([324, 364, 421, 404], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 4.7503252029418945
bi 1 loss 4.257928371429443
bi 2 loss 5.0003767013549805
bi 3 loss 4.46787166595459
Layer  2  loss:  4.938557147979736 0.0 10.51623249053955
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([401, 238, 181, 298], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 5.084199905395508
bi 1 loss 4.501587390899658
bi 2 loss 5.201043128967285
bi 3 loss 4.853302955627441
Layer  3  loss:  5.0395636558532715 0.0 10.021295547485352
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1021
Curr loss timestep torch.Size([524, 4]) tensor([262, 246, 124, 376], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 5.206791400909424
bi 1 loss 4.652773380279541
bi 2 loss 5.221459865570068
bi 3 loss 4.989766597747803
Layer  4  loss:  5.30077600479126 0.0 10.613231658935547
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1021
Curr loss timestep torch.Size([524, 4]) tensor([412, 272, 353, 350], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 5.398347854614258
bi 1 loss 4.8526129722595215
bi 2 loss 5.626200199127197
bi 3 loss 5.195559501647949
Layer  5  loss:  5.30771017074585 0.0 11.59554672241211
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([413, 242, 201, 467], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 5.308721542358398
bi 1 loss 4.994258403778076
bi 2 loss 5.5496320724487305
bi 3 loss 5.293750762939453
Layer  6  loss:  5.320181846618652 0.0 10.947103500366211
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([340, 363, 416, 429], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 5.393392562866211
bi 1 loss 4.85345458984375
bi 2 loss 5.596622467041016
bi 3 loss 5.33242130279541
Epoch 0: :   3%|▎         | 15053/600000 [00:23<15:25, v_num=12, reduced_train_loss=1.810, global_step=15051.0, consumed_samples=60208.0, train_step_timing in s=0.469]Epoch 0: :   3%|▎         | 15053/600000 [00:23<15:25, v_num=12, reduced_train_loss=38.70, global_step=15052.0, consumed_samples=60212.0, train_step_timing in s=0.341]loss mask original None

First layer loss:  0.02357594296336174 torch.Size([383, 4]) 1.0922279357910156 0.0
Max loss timestep torch.Size([383, 4]) tensor([323, 194, 106, 146], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.0344051867723465
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 1 loss 0.018787730485200882
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
bi 2 loss 0.020805753767490387
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 3 loss 0.021204961463809013
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
logits torch.Size([383, 4, 257024]) labels torch.Size([383, 4]) 0 257022
Layer  0  loss:  0.016856219619512558 0.0 0.34385156631469727
logits torch.Size([383, 4, 1024]) labels torch.Size([383, 4]) 0 1023
Curr loss timestep torch.Size([383, 4]) tensor([325, 142, 151, 138], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.018170498311519623
bi 1 loss 0.014931531623005867
bi 2 loss 0.018139857798814774
bi 3 loss 0.018040625378489494
Layer  1  loss:  0.023400526493787766 0.0 0.327138215303421
logits torch.Size([383, 4, 1024]) labels torch.Size([383, 4]) 0 1023
Curr loss timestep torch.Size([383, 4]) tensor([267, 278, 107, 157], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.029123976826667786
bi 1 loss 0.020694222301244736
bi 2 loss 0.02258487604558468
bi 3 loss 0.022062567993998528
Layer  2  loss:  0.02385377697646618 0.0 0.9185268878936768
logits torch.Size([383, 4, 1024]) labels torch.Size([383, 4]) 0 1022
Curr loss timestep torch.Size([383, 4]) tensor([343, 328, 151, 139], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.03230069950222969
bi 1 loss 0.02160005085170269
bi 2 loss 0.017817223444581032
bi 3 loss 0.021708810701966286
Layer  3  loss:  0.02120574750006199 0.0 0.574778139591217
logits torch.Size([383, 4, 1024]) labels torch.Size([383, 4]) 0 1023
Curr loss timestep torch.Size([383, 4]) tensor([343, 312, 123,  68], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.029157115146517754
bi 1 loss 0.014409727416932583
bi 2 loss 0.015233979560434818
bi 3 loss 0.02807111106812954
Layer  4  loss:  0.020194703713059425 0.0 0.4117569327354431
logits torch.Size([383, 4, 1024]) labels torch.Size([383, 4]) 0 1021
Curr loss timestep torch.Size([383, 4]) tensor([324, 135, 133,  86], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.02350531704723835
bi 1 loss 0.02003599889576435
bi 2 loss 0.020360970869660378
bi 3 loss 0.01639728434383869
Layer  5  loss:  0.019835693761706352 0.0 0.9998048543930054
logits torch.Size([383, 4, 1024]) labels torch.Size([383, 4]) 0 1022
Curr loss timestep torch.Size([383, 4]) tensor([323, 173,  97,  79], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.026170797646045685
bi 1 loss 0.01930418610572815
bi 2 loss 0.016689671203494072
bi 3 loss 0.015192965045571327
Layer  6  loss:  0.02189633995294571 0.0 0.3217732310295105
logits torch.Size([383, 4, 1024]) labels torch.Size([383, 4]) 0 1021
Curr loss timestep torch.Size([383, 4]) tensor([308, 283, 126, 161], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.028215108439326286
bi 1 loss 0.019144918769598007
bi 2 loss 0.02389376237988472
bi 3 loss 0.018138974905014038
Epoch 0: :   3%|▎         | 15054/600000 [00:24<15:37, v_num=12, reduced_train_loss=38.70, global_step=15052.0, consumed_samples=60212.0, train_step_timing in s=0.341]Epoch 0: :   3%|▎         | 15054/600000 [00:24<15:37, v_num=12, reduced_train_loss=0.171, global_step=15053.0, consumed_samples=60216.0, train_step_timing in s=0.288]loss mask original None

First layer loss:  0.06597515195608139 torch.Size([587, 4]) 3.843088150024414 0.0
Max loss timestep torch.Size([587, 4]) tensor([184, 335, 155, 155], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.04402777552604675
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 1 loss 0.10126014798879623
speech mask sum tensor(354, device='cuda:0') loss mask sum tensor(354, device='cuda:0')
bi 2 loss 0.02014448307454586
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 3 loss 0.016968192532658577
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
logits torch.Size([587, 4, 257024]) labels torch.Size([587, 4]) 0 257022
Layer  0  loss:  0.08675006031990051 0.0 5.229015827178955
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([100, 389, 159, 142], device='cuda:0') tensor(389, device='cuda:0')
bi 0 loss 0.040265146642923355
bi 1 loss 0.1458338052034378
bi 2 loss 0.017258627340197563
bi 3 loss 0.015600701794028282
Layer  1  loss:  0.08209051191806793 0.0 6.6449127197265625
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([196, 493, 157, 156], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.02589370310306549
bi 1 loss 0.1428648978471756
bi 2 loss 0.020626939833164215
bi 3 loss 0.013409055769443512
Layer  2  loss:  0.10525447875261307 0.0 9.923284530639648
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1022
Curr loss timestep torch.Size([587, 4]) tensor([103, 337, 164, 126], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.04259456694126129
bi 1 loss 0.18272292613983154
bi 2 loss 0.013796266168355942
bi 3 loss 0.015980612486600876
Layer  3  loss:  0.08738750964403152 0.0 5.3286943435668945
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([154, 493, 157, 150], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.034735579043626785
bi 1 loss 0.15020814538002014
bi 2 loss 0.017457736656069756
bi 3 loss 0.013341858051717281
Layer  4  loss:  0.0892380028963089 0.0 9.519403457641602
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1022
Curr loss timestep torch.Size([587, 4]) tensor([ 72, 337, 118, 151], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.03116901032626629
bi 1 loss 0.14708355069160461
bi 2 loss 0.022670410573482513
bi 3 loss 0.04387914016842842
Layer  5  loss:  0.10335320234298706 0.0 7.3774261474609375
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([ 65, 493, 125, 133], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.035116564482450485
bi 1 loss 0.1774459034204483
bi 2 loss 0.02263461984694004
bi 3 loss 0.026546142995357513
Layer  6  loss:  0.1054334044456482 0.0 7.570382118225098
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1022
Curr loss timestep torch.Size([587, 4]) tensor([141, 493, 108, 168], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.029696498066186905
bi 1 loss 0.18145786225795746
bi 2 loss 0.02736671082675457
bi 3 loss 0.032394878566265106
Epoch 0: :   3%|▎         | 15055/600000 [00:24<15:54, v_num=12, reduced_train_loss=0.171, global_step=15053.0, consumed_samples=60216.0, train_step_timing in s=0.288]Epoch 0: :   3%|▎         | 15055/600000 [00:24<15:54, v_num=12, reduced_train_loss=0.725, global_step=15054.0, consumed_samples=60220.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  3.362215280532837 torch.Size([496, 4]) 11.477752685546875 0.0
Max loss timestep torch.Size([496, 4]) tensor([309, 125, 406, 173], device='cuda:0') tensor(146, device='cuda:0')
bi 0 loss 3.2528789043426514
speech mask sum tensor(284, device='cuda:0') loss mask sum tensor(284, device='cuda:0')
bi 1 loss 3.0974416732788086
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 2 loss 3.5170657634735107
speech mask sum tensor(395, device='cuda:0') loss mask sum tensor(395, device='cuda:0')
bi 3 loss 3.270808219909668
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
logits torch.Size([496, 4, 257024]) labels torch.Size([496, 4]) 0 257022
Layer  0  loss:  3.9465949535369873 0.0 10.00883674621582
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1023
Curr loss timestep torch.Size([496, 4]) tensor([112, 126, 180, 172], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 3.7837765216827393
bi 1 loss 3.763662338256836
bi 2 loss 4.110240936279297
bi 3 loss 3.9038355350494385
Layer  1  loss:  4.200720310211182 0.0 10.136016845703125
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1023
Curr loss timestep torch.Size([496, 4]) tensor([123, 125, 406, 214], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 4.241981506347656
bi 1 loss 3.811099052429199
bi 2 loss 4.271688938140869
bi 3 loss 4.104885578155518
Layer  2  loss:  4.589968204498291 0.0 11.000520706176758
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1022
Curr loss timestep torch.Size([496, 4]) tensor([259, 138, 180, 211], device='cuda:0') tensor(207, device='cuda:0')
bi 0 loss 4.467579364776611
bi 1 loss 4.339888572692871
bi 2 loss 4.635383605957031
bi 3 loss 4.887217044830322
Layer  3  loss:  4.575220584869385 0.0 9.995555877685547
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1023
Curr loss timestep torch.Size([496, 4]) tensor([325, 144, 304, 200], device='cuda:0') tensor(151, device='cuda:0')
bi 0 loss 4.665539264678955
bi 1 loss 4.246246337890625
bi 2 loss 4.539891242980957
bi 3 loss 4.679627418518066
Layer  4  loss:  4.744894981384277 0.0 10.152276992797852
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1022
Curr loss timestep torch.Size([496, 4]) tensor([361, 145, 325, 177], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 4.753201961517334
bi 1 loss 4.309275150299072
bi 2 loss 4.770570278167725
bi 3 loss 4.908448696136475
Layer  5  loss:  4.828385353088379 0.0 9.40751838684082
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1022
Curr loss timestep torch.Size([496, 4]) tensor([158, 147, 399, 225], device='cuda:0') tensor(157, device='cuda:0')
bi 0 loss 4.841637134552002
bi 1 loss 4.230301380157471
bi 2 loss 4.876431465148926
bi 3 loss 5.005660533905029
Layer  6  loss:  4.80557107925415 0.0 10.955925941467285
logits torch.Size([496, 4, 1024]) labels torch.Size([496, 4]) 0 1023
Curr loss timestep torch.Size([496, 4]) tensor([194, 171, 201, 155], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 4.87063455581665
bi 1 loss 4.548600673675537
bi 2 loss 4.73581075668335
bi 3 loss 5.04146671295166
Epoch 0: :   3%|▎         | 15056/600000 [00:24<16:08, v_num=12, reduced_train_loss=0.725, global_step=15054.0, consumed_samples=60220.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15056/600000 [00:24<16:08, v_num=12, reduced_train_loss=35.10, global_step=15055.0, consumed_samples=60224.0, train_step_timing in s=0.325]loss mask original None

First layer loss:  3.9106030464172363 torch.Size([500, 4]) 10.361055374145508 0.0
Max loss timestep torch.Size([500, 4]) tensor([122, 308, 305, 161], device='cuda:0') tensor(122, device='cuda:0')
bi 0 loss 2.829063892364502
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 1 loss 3.735123634338379
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
bi 2 loss 4.394476413726807
speech mask sum tensor(413, device='cuda:0') loss mask sum tensor(413, device='cuda:0')
bi 3 loss 3.646630048751831
speech mask sum tensor(218, device='cuda:0') loss mask sum tensor(218, device='cuda:0')
logits torch.Size([500, 4, 257024]) labels torch.Size([500, 4]) 0 257023
Layer  0  loss:  4.39949369430542 0.0 10.724206924438477
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([123, 317, 113, 224], device='cuda:0') tensor(120, device='cuda:0')
bi 0 loss 3.394261360168457
bi 1 loss 4.288485050201416
bi 2 loss 4.790956020355225
bi 3 loss 4.195964336395264
Layer  1  loss:  4.669129371643066 0.0 10.191059112548828
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([135, 318, 474, 128], device='cuda:0') tensor(128, device='cuda:0')
bi 0 loss 3.8248801231384277
bi 1 loss 4.481010913848877
bi 2 loss 5.089621543884277
bi 3 loss 4.4493513107299805
Layer  2  loss:  4.860192775726318 0.0 10.801704406738281
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([156, 184, 416, 107], device='cuda:0') tensor(107, device='cuda:0')
bi 0 loss 4.149432182312012
bi 1 loss 4.583186626434326
bi 2 loss 5.320862293243408
bi 3 loss 4.629271984100342
Layer  3  loss:  4.963356971740723 0.0 10.239351272583008
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1021
Curr loss timestep torch.Size([500, 4]) tensor([137, 187, 434, 216], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 4.370359897613525
bi 1 loss 4.650873184204102
bi 2 loss 5.463783264160156
bi 3 loss 4.657904624938965
Layer  4  loss:  5.180543422698975 0.0 10.155853271484375
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([164,  93, 374,  87], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 4.605390548706055
bi 1 loss 4.930830001831055
bi 2 loss 5.625485897064209
bi 3 loss 4.890608310699463
Layer  5  loss:  5.2160162925720215 0.0 10.623625755310059
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([145, 330, 358, 254], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 4.530784606933594
bi 1 loss 4.848690986633301
bi 2 loss 5.73075532913208
bi 3 loss 4.991612911224365
Layer  6  loss:  5.239762783050537 0.0 11.698685646057129
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([144, 251, 449, 136], device='cuda:0') tensor(105, device='cuda:0')
bi 0 loss 4.574394702911377
bi 1 loss 4.938182353973389
bi 2 loss 5.766541481018066
bi 3 loss 4.898250579833984
Epoch 0: :   3%|▎         | 15057/600000 [00:25<16:22, v_num=12, reduced_train_loss=35.10, global_step=15055.0, consumed_samples=60224.0, train_step_timing in s=0.325]Epoch 0: :   3%|▎         | 15057/600000 [00:25<16:22, v_num=12, reduced_train_loss=38.40, global_step=15056.0, consumed_samples=60228.0, train_step_timing in s=0.326]loss mask original None

First layer loss:  0.09142221510410309 torch.Size([502, 4]) 7.439381122589111 0.0
Max loss timestep torch.Size([502, 4]) tensor([346, 452, 277, 274], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.08154825121164322
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 1 loss 0.08027824759483337
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 2 loss 0.1004999428987503
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 3 loss 0.10779688507318497
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
logits torch.Size([502, 4, 257024]) labels torch.Size([502, 4]) 0 257022
Layer  0  loss:  0.10937164723873138 0.0 6.62673807144165
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([343, 474, 285, 274], device='cuda:0') tensor(474, device='cuda:0')
bi 0 loss 0.1586841493844986
bi 1 loss 0.09883371740579605
bi 2 loss 0.11830174922943115
bi 3 loss 0.09609281271696091
Layer  1  loss:  0.08030805736780167 0.0 3.8226449489593506
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([347, 474, 277, 274], device='cuda:0') tensor(474, device='cuda:0')
bi 0 loss 0.09371170401573181
bi 1 loss 0.08706095814704895
bi 2 loss 0.07649172097444534
bi 3 loss 0.06537120044231415
Layer  2  loss:  0.08569270372390747 0.0 5.264896392822266
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1022
Curr loss timestep torch.Size([502, 4]) tensor([265, 474, 277, 274], device='cuda:0') tensor(474, device='cuda:0')
bi 0 loss 0.10860247164964676
bi 1 loss 0.08746400475502014
bi 2 loss 0.08204244822263718
bi 3 loss 0.07457989454269409
Layer  3  loss:  0.07791978120803833 0.0 3.883612632751465
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1021
Curr loss timestep torch.Size([502, 4]) tensor([349, 194, 277, 306], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 0.12410828471183777
bi 1 loss 0.0757887214422226
bi 2 loss 0.05615741387009621
bi 3 loss 0.0774066150188446
Layer  4  loss:  0.08198168873786926 0.0 2.5555543899536133
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([289, 420, 249, 191], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.12071555852890015
bi 1 loss 0.09012439846992493
bi 2 loss 0.07694843411445618
bi 3 loss 0.05337431654334068
Layer  5  loss:  0.1046084463596344 0.0 5.260241508483887
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([343, 474, 277, 274], device='cuda:0') tensor(474, device='cuda:0')
bi 0 loss 0.16408300399780273
bi 1 loss 0.08674826472997665
bi 2 loss 0.11691742390394211
bi 3 loss 0.09617291390895844
Layer  6  loss:  0.10094845294952393 0.0 6.637017250061035
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([332, 474, 277, 296], device='cuda:0') tensor(474, device='cuda:0')
bi 0 loss 0.08217990398406982
bi 1 loss 0.1278613656759262
bi 2 loss 0.0907922089099884
bi 3 loss 0.0722290426492691
Epoch 0: :   3%|▎         | 15058/600000 [00:25<16:37, v_num=12, reduced_train_loss=38.40, global_step=15056.0, consumed_samples=60228.0, train_step_timing in s=0.326]Epoch 0: :   3%|▎         | 15058/600000 [00:25<16:37, v_num=12, reduced_train_loss=0.732, global_step=15057.0, consumed_samples=60232.0, train_step_timing in s=0.346]loss mask original None

First layer loss:  0.015755033120512962 torch.Size([327, 4]) 0.13167710602283478 0.0
Max loss timestep torch.Size([327, 4]) tensor([115, 183, 294, 164], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 0.010546200908720493
speech mask sum tensor(44, device='cuda:0') loss mask sum tensor(44, device='cuda:0')
bi 1 loss 0.017636846750974655
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 2 loss 0.01764063909649849
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 3 loss 0.013003932312130928
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
logits torch.Size([327, 4, 257024]) labels torch.Size([327, 4]) 0 257022
Layer  0  loss:  0.01685403473675251 0.0 0.29549500346183777
logits torch.Size([327, 4, 1024]) labels torch.Size([327, 4]) 0 1023
Curr loss timestep torch.Size([327, 4]) tensor([134, 116, 308, 176], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.014080540277063847
bi 1 loss 0.01720641367137432
bi 2 loss 0.02039445750415325
bi 3 loss 0.013655469752848148
Layer  1  loss:  0.015127195976674557 0.0 0.19870616495609283
logits torch.Size([327, 4, 1024]) labels torch.Size([327, 4]) 0 1023
Curr loss timestep torch.Size([327, 4]) tensor([126, 102, 183, 192], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 0.010279787704348564
bi 1 loss 0.015117441304028034
bi 2 loss 0.01735083758831024
bi 3 loss 0.014274113811552525
Layer  2  loss:  0.015068425796926022 0.0 0.13832613825798035
logits torch.Size([327, 4, 1024]) labels torch.Size([327, 4]) 0 1022
Curr loss timestep torch.Size([327, 4]) tensor([132, 212, 301, 192], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 0.01082532200962305
bi 1 loss 0.015787333250045776
bi 2 loss 0.015075474046170712
bi 3 loss 0.015362197533249855
Layer  3  loss:  0.013678711839020252 0.0 0.14643141627311707
logits torch.Size([327, 4, 1024]) labels torch.Size([327, 4]) 0 1020
Curr loss timestep torch.Size([327, 4]) tensor([121, 179, 269, 197], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 0.00728178583085537
bi 1 loss 0.014728911221027374
bi 2 loss 0.012381582520902157
bi 3 loss 0.015470911748707294
Layer  4  loss:  0.014195585623383522 0.0 0.14011690020561218
logits torch.Size([327, 4, 1024]) labels torch.Size([327, 4]) 0 1022
Curr loss timestep torch.Size([327, 4]) tensor([134, 132, 294, 167], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 0.007949951104819775
bi 1 loss 0.015517660416662693
bi 2 loss 0.016865558922290802
bi 3 loss 0.0116423349827528
Layer  5  loss:  0.014886666089296341 0.0 0.3572370707988739
logits torch.Size([327, 4, 1024]) labels torch.Size([327, 4]) 0 1023
Curr loss timestep torch.Size([327, 4]) tensor([127, 216, 239, 191], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 0.011842682957649231
bi 1 loss 0.014305392280220985
bi 2 loss 0.01550601888448
bi 3 loss 0.01583866775035858
Layer  6  loss:  0.014217555522918701 0.0 0.20400170981884003
logits torch.Size([327, 4, 1024]) labels torch.Size([327, 4]) 0 1022
Curr loss timestep torch.Size([327, 4]) tensor([130, 203, 256, 103], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 0.005554753355681896
bi 1 loss 0.01459672674536705
bi 2 loss 0.014249172993004322
bi 3 loss 0.01614519953727722
Epoch 0: :   3%|▎         | 15059/600000 [00:25<16:48, v_num=12, reduced_train_loss=0.732, global_step=15057.0, consumed_samples=60232.0, train_step_timing in s=0.346]Epoch 0: :   3%|▎         | 15059/600000 [00:25<16:48, v_num=12, reduced_train_loss=0.120, global_step=15058.0, consumed_samples=60236.0, train_step_timing in s=0.258]loss mask original None

First layer loss:  0.011479201726615429 torch.Size([319, 4]) 0.09969592839479446 0.0
Max loss timestep torch.Size([319, 4]) tensor([204, 235,  83, 218], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 0.01215079054236412
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 1 loss 0.011039637960493565
speech mask sum tensor(207, device='cuda:0') loss mask sum tensor(207, device='cuda:0')
bi 2 loss 0.010764694772660732
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.012369269505143166
speech mask sum tensor(108, device='cuda:0') loss mask sum tensor(108, device='cuda:0')
logits torch.Size([319, 4, 257024]) labels torch.Size([319, 4]) 0 257023
Layer  0  loss:  0.01025905180722475 0.0 0.11884115636348724
logits torch.Size([319, 4, 1024]) labels torch.Size([319, 4]) 0 1023
Curr loss timestep torch.Size([319, 4]) tensor([207, 253, 101, 230], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 0.010419289581477642
bi 1 loss 0.010153893381357193
bi 2 loss 0.009302289225161076
bi 3 loss 0.011571300216019154
Layer  1  loss:  0.008639209903776646 0.0 0.09413779526948929
logits torch.Size([319, 4, 1024]) labels torch.Size([319, 4]) 0 1022
Curr loss timestep torch.Size([319, 4]) tensor([179, 114,  77, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.008978812955319881
bi 1 loss 0.0075409747660160065
bi 2 loss 0.007529463153332472
bi 3 loss 0.01181464921683073
Layer  2  loss:  0.011112797074019909 0.0 0.41679030656814575
logits torch.Size([319, 4, 1024]) labels torch.Size([319, 4]) 0 1022
Curr loss timestep torch.Size([319, 4]) tensor([267, 231,  91, 206], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.0154575165361166
bi 1 loss 0.008685773238539696
bi 2 loss 0.00979599915444851
bi 3 loss 0.011450654827058315
Layer  3  loss:  0.010372832417488098 0.0 0.1823393851518631
logits torch.Size([319, 4, 1024]) labels torch.Size([319, 4]) 0 1023
Curr loss timestep torch.Size([319, 4]) tensor([298, 116, 165, 255], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 0.012811286374926567
bi 1 loss 0.00978830736130476
bi 2 loss 0.008563661947846413
bi 3 loss 0.010568184778094292
Layer  4  loss:  0.00898064486682415 0.0 0.1175324022769928
logits torch.Size([319, 4, 1024]) labels torch.Size([319, 4]) 0 1018
Curr loss timestep torch.Size([319, 4]) tensor([287, 230, 177, 274], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 0.011035621166229248
bi 1 loss 0.008958443067967892
bi 2 loss 0.00661334628239274
bi 3 loss 0.009421818889677525
Layer  5  loss:  0.011576316319406033 0.0 0.23308910429477692
logits torch.Size([319, 4, 1024]) labels torch.Size([319, 4]) 0 1023
Curr loss timestep torch.Size([319, 4]) tensor([180, 116, 121, 255], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 0.015290246345102787
bi 1 loss 0.010775630362331867
bi 2 loss 0.008672448806464672
bi 3 loss 0.01190959569066763
Layer  6  loss:  0.010286220349371433 0.0 0.12989920377731323
logits torch.Size([319, 4, 1024]) labels torch.Size([319, 4]) 0 1023
Curr loss timestep torch.Size([319, 4]) tensor([285, 123, 117, 222], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.010682391002774239
bi 1 loss 0.009594745934009552
bi 2 loss 0.010058860294520855
bi 3 loss 0.011368181556463242
Epoch 0: :   3%|▎         | 15060/600000 [00:26<17:00, v_num=12, reduced_train_loss=0.120, global_step=15058.0, consumed_samples=60236.0, train_step_timing in s=0.258]Epoch 0: :   3%|▎         | 15060/600000 [00:26<17:00, v_num=12, reduced_train_loss=0.0827, global_step=15059.0, consumed_samples=60240.0, train_step_timing in s=0.260]loss mask original None

First layer loss:  3.463895320892334 torch.Size([584, 4]) 11.647855758666992 0.0
Max loss timestep torch.Size([584, 4]) tensor([191, 294, 173, 343], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 2.9608187675476074
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 1 loss 3.7455320358276367
speech mask sum tensor(329, device='cuda:0') loss mask sum tensor(329, device='cuda:0')
bi 2 loss 3.0472075939178467
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 3 loss 3.5724101066589355
speech mask sum tensor(476, device='cuda:0') loss mask sum tensor(476, device='cuda:0')
logits torch.Size([584, 4, 257024]) labels torch.Size([584, 4]) 0 257022
Layer  0  loss:  3.8782525062561035 0.0 10.160224914550781
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([265, 208, 312, 462], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 3.3464810848236084
bi 1 loss 4.398443222045898
bi 2 loss 3.4732494354248047
bi 3 loss 3.824802875518799
Layer  1  loss:  4.268531322479248 0.0 11.262348175048828
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1021
Curr loss timestep torch.Size([584, 4]) tensor([251, 387, 209, 467], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 3.827723264694214
bi 1 loss 4.579275131225586
bi 2 loss 3.966385841369629
bi 3 loss 4.293871879577637
Layer  2  loss:  4.498143196105957 0.0 9.684165954589844
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([198, 277, 230, 186], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 3.9859044551849365
bi 1 loss 4.793148517608643
bi 2 loss 4.151173114776611
bi 3 loss 4.571595191955566
Layer  3  loss:  4.615572452545166 0.0 12.094413757324219
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([268, 314, 345, 118], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 4.194551467895508
bi 1 loss 4.959115028381348
bi 2 loss 4.38153600692749
bi 3 loss 4.585347652435303
Layer  4  loss:  4.753854274749756 0.0 10.850851058959961
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([204, 302, 330, 315], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 4.26658296585083
bi 1 loss 5.09298038482666
bi 2 loss 4.496397972106934
bi 3 loss 4.753854274749756
Layer  5  loss:  4.801332950592041 0.0 9.751969337463379
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([201, 353, 224, 411], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.299813270568848
bi 1 loss 5.162171840667725
bi 2 loss 4.47558069229126
bi 3 loss 4.817818641662598
Layer  6  loss:  4.810164928436279 0.0 9.237199783325195
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([215, 390, 313, 326], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 4.319785118103027
bi 1 loss 5.075619220733643
bi 2 loss 4.516335964202881
bi 3 loss 4.876662731170654
Epoch 0: :   3%|▎         | 15061/600000 [00:26<17:15, v_num=12, reduced_train_loss=0.0827, global_step=15059.0, consumed_samples=60240.0, train_step_timing in s=0.260]Epoch 0: :   3%|▎         | 15061/600000 [00:26<17:15, v_num=12, reduced_train_loss=35.10, global_step=15060.0, consumed_samples=60244.0, train_step_timing in s=0.364] loss mask original None

First layer loss:  0.08880205452442169 torch.Size([601, 4]) 6.268961429595947 0.0
Max loss timestep torch.Size([601, 4]) tensor([353, 270,  79, 344], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.0887637808918953
speech mask sum tensor(252, device='cuda:0') loss mask sum tensor(252, device='cuda:0')
bi 1 loss 0.15270857512950897
speech mask sum tensor(168, device='cuda:0') loss mask sum tensor(168, device='cuda:0')
bi 2 loss 0.022470543161034584
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 3 loss 0.08284996449947357
speech mask sum tensor(476, device='cuda:0') loss mask sum tensor(476, device='cuda:0')
logits torch.Size([601, 4, 257024]) labels torch.Size([601, 4]) 0 257022
Layer  0  loss:  0.12515953183174133 0.0 7.366708755493164
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([351, 188,  72, 567], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.1413339525461197
bi 1 loss 0.15763495862483978
bi 2 loss 0.023045038804411888
bi 3 loss 0.13066329061985016
Layer  1  loss:  0.12412016838788986 0.0 9.375445365905762
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([371, 270, 118, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.16449692845344543
bi 1 loss 0.11908873915672302
bi 2 loss 0.02895805798470974
bi 3 loss 0.12831054627895355
Layer  2  loss:  0.10599914193153381 0.0 7.017735481262207
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([351, 270, 112, 344], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.11683415621519089
bi 1 loss 0.1319705694913864
bi 2 loss 0.027889028191566467
bi 3 loss 0.11062409728765488
Layer  3  loss:  0.12968650460243225 0.0 9.015953063964844
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([352, 291,  99, 344], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.13664430379867554
bi 1 loss 0.1185225322842598
bi 2 loss 0.03196929767727852
bi 3 loss 0.15437251329421997
Layer  4  loss:  0.11644859611988068 0.0 8.912665367126465
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([353, 291,  97, 489], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.15565486252307892
bi 1 loss 0.11085902154445648
bi 2 loss 0.0318116620182991
bi 3 loss 0.11882434785366058
Layer  5  loss:  0.1415342390537262 0.0 16.937816619873047
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([353, 270,  86, 568], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.22698988020420074
bi 1 loss 0.12378556281328201
bi 2 loss 0.021171633154153824
bi 3 loss 0.13264791667461395
Layer  6  loss:  0.13133610785007477 0.0 10.271324157714844
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1019
Curr loss timestep torch.Size([601, 4]) tensor([351, 273,  98, 568], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.16917695105075836
bi 1 loss 0.17334964871406555
bi 2 loss 0.01712772436439991
bi 3 loss 0.12502650916576385
Epoch 0: :   3%|▎         | 15062/600000 [00:27<17:33, v_num=12, reduced_train_loss=35.10, global_step=15060.0, consumed_samples=60244.0, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15062/600000 [00:27<17:33, v_num=12, reduced_train_loss=0.963, global_step=15061.0, consumed_samples=60248.0, train_step_timing in s=0.406]loss mask original None

First layer loss:  0.09654413908720016 torch.Size([483, 4]) 6.361502170562744 0.0
Max loss timestep torch.Size([483, 4]) tensor([280, 383, 219, 373], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.10403349995613098
speech mask sum tensor(315, device='cuda:0') loss mask sum tensor(315, device='cuda:0')
bi 1 loss 0.12284787744283676
speech mask sum tensor(360, device='cuda:0') loss mask sum tensor(360, device='cuda:0')
bi 2 loss 0.08926820755004883
speech mask sum tensor(237, device='cuda:0') loss mask sum tensor(237, device='cuda:0')
bi 3 loss 0.063738614320755
speech mask sum tensor(308, device='cuda:0') loss mask sum tensor(308, device='cuda:0')
logits torch.Size([483, 4, 257024]) labels torch.Size([483, 4]) 0 257022
Layer  0  loss:  0.09394100308418274 0.0 7.5652031898498535
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1023
Curr loss timestep torch.Size([483, 4]) tensor([314, 295, 321, 373], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.10409349948167801
bi 1 loss 0.08283665776252747
bi 2 loss 0.0746588408946991
bi 3 loss 0.11137412488460541
Layer  1  loss:  0.08878955990076065 0.0 14.695242881774902
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1022
Curr loss timestep torch.Size([483, 4]) tensor([137, 295, 321, 372], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.08623313158750534
bi 1 loss 0.09710738807916641
bi 2 loss 0.08890246599912643
bi 3 loss 0.08159507066011429
Layer  2  loss:  0.10426464676856995 0.0 8.579741477966309
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1023
Curr loss timestep torch.Size([483, 4]) tensor([267, 297, 275, 423], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.08500640094280243
bi 1 loss 0.10198806971311569
bi 2 loss 0.10780072957277298
bi 3 loss 0.12390054762363434
Layer  3  loss:  0.0881383940577507 0.0 5.547763824462891
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1023
Curr loss timestep torch.Size([483, 4]) tensor([341, 299, 308, 445], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.05791674554347992
bi 1 loss 0.10061582177877426
bi 2 loss 0.08323174715042114
bi 3 loss 0.10823848098516464
Layer  4  loss:  0.11131802201271057 0.0 7.885944366455078
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1022
Curr loss timestep torch.Size([483, 4]) tensor([224, 295, 275, 423], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.12923501431941986
bi 1 loss 0.13415300846099854
bi 2 loss 0.07430191338062286
bi 3 loss 0.09478678554296494
Layer  5  loss:  0.08994384855031967 0.0 5.114908218383789
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1023
Curr loss timestep torch.Size([483, 4]) tensor([280,  51, 319, 423], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.09774047881364822
bi 1 loss 0.07410498708486557
bi 2 loss 0.10734561085700989
bi 3 loss 0.08709264546632767
Layer  6  loss:  0.09269391745328903 0.0 7.268486976623535
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1022
Curr loss timestep torch.Size([483, 4]) tensor([276, 295, 314, 430], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.08569177240133286
bi 1 loss 0.12142814695835114
bi 2 loss 0.06832993030548096
bi 3 loss 0.08501735329627991
Epoch 0: :   3%|▎         | 15063/600000 [00:27<17:47, v_num=12, reduced_train_loss=0.963, global_step=15061.0, consumed_samples=60248.0, train_step_timing in s=0.406]Epoch 0: :   3%|▎         | 15063/600000 [00:27<17:47, v_num=12, reduced_train_loss=0.766, global_step=15062.0, consumed_samples=60252.0, train_step_timing in s=0.335]loss mask original None

First layer loss:  3.6123085021972656 torch.Size([368, 4]) 13.250326156616211 0.0
Max loss timestep torch.Size([368, 4]) tensor([130, 226,  67, 181], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 3.9782609939575195
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 1 loss 3.8946003913879395
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 2 loss 3.6658828258514404
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 3 loss 3.2075107097625732
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
logits torch.Size([368, 4, 257024]) labels torch.Size([368, 4]) 0 257023
Layer  0  loss:  4.05385160446167 0.0 9.975143432617188
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1023
Curr loss timestep torch.Size([368, 4]) tensor([147, 192,  96, 314], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 4.436263561248779
bi 1 loss 3.9092812538146973
bi 2 loss 4.0015459060668945
bi 3 loss 3.9559340476989746
Layer  1  loss:  4.326970100402832 0.0 10.345681190490723
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1023
Curr loss timestep torch.Size([368, 4]) tensor([ 77, 296, 119, 166], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 4.9816412925720215
bi 1 loss 4.419223308563232
bi 2 loss 4.047450065612793
bi 3 loss 4.020473003387451
Layer  2  loss:  4.6383442878723145 0.0 9.071662902832031
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1022
Curr loss timestep torch.Size([368, 4]) tensor([125, 229,  63, 172], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 5.076483726501465
bi 1 loss 4.847280025482178
bi 2 loss 4.330169677734375
bi 3 loss 4.388990879058838
Layer  3  loss:  4.792663097381592 0.0 9.593561172485352
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1018
Curr loss timestep torch.Size([368, 4]) tensor([ 86, 200,  73, 182], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 5.142726898193359
bi 1 loss 4.831204891204834
bi 2 loss 4.395711898803711
bi 3 loss 4.737306118011475
Layer  4  loss:  4.9080305099487305 0.0 10.731834411621094
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1022
Curr loss timestep torch.Size([368, 4]) tensor([174, 208,  83, 197], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 5.298361778259277
bi 1 loss 5.016631126403809
bi 2 loss 4.689736366271973
bi 3 loss 4.712281227111816
Layer  5  loss:  5.015962600708008 0.0 10.810256004333496
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1022
Curr loss timestep torch.Size([368, 4]) tensor([161, 220,  85, 308], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 5.403469085693359
bi 1 loss 5.0157318115234375
bi 2 loss 4.680188179016113
bi 3 loss 4.939505100250244
Layer  6  loss:  4.954751014709473 0.0 10.158512115478516
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1023
Curr loss timestep torch.Size([368, 4]) tensor([136, 291, 105, 204], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 5.225761890411377
bi 1 loss 5.059163570404053
bi 2 loss 4.7597150802612305
bi 3 loss 4.818175315856934
Epoch 0: :   3%|▎         | 15064/600000 [00:27<17:59, v_num=12, reduced_train_loss=0.766, global_step=15062.0, consumed_samples=60252.0, train_step_timing in s=0.335]Epoch 0: :   3%|▎         | 15064/600000 [00:27<17:59, v_num=12, reduced_train_loss=36.30, global_step=15063.0, consumed_samples=60256.0, train_step_timing in s=0.272]loss mask original None

First layer loss:  0.13839346170425415 torch.Size([658, 4]) 6.9872236251831055 0.0
Max loss timestep torch.Size([658, 4]) tensor([228, 533, 498, 386], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.11988060921430588
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 1 loss 0.19275468587875366
speech mask sum tensor(324, device='cuda:0') loss mask sum tensor(324, device='cuda:0')
bi 2 loss 0.1139322817325592
speech mask sum tensor(404, device='cuda:0') loss mask sum tensor(404, device='cuda:0')
bi 3 loss 0.11462072283029556
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
logits torch.Size([658, 4, 257024]) labels torch.Size([658, 4]) 0 257023
Layer  0  loss:  0.1657957285642624 0.0 10.15746784210205
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([238, 416, 322, 389], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.09379639476537704
bi 1 loss 0.22257868945598602
bi 2 loss 0.15052483975887299
bi 3 loss 0.14221152663230896
Layer  1  loss:  0.16718339920043945 0.0 16.875629425048828
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([236, 533, 498, 270], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.050586968660354614
bi 1 loss 0.26668477058410645
bi 2 loss 0.15194134414196014
bi 3 loss 0.10475113987922668
Layer  2  loss:  0.18389344215393066 0.0 17.021635055541992
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([283, 416, 324, 388], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.10322447121143341
bi 1 loss 0.2799767255783081
bi 2 loss 0.14524604380130768
bi 3 loss 0.15045495331287384
Layer  3  loss:  0.1715155988931656 0.0 14.105256080627441
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1020
Curr loss timestep torch.Size([658, 4]) tensor([265, 533, 498, 389], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.0988822728395462
bi 1 loss 0.290576308965683
bi 2 loss 0.11515586823225021
bi 3 loss 0.13432444632053375
Layer  4  loss:  0.17372313141822815 0.0 9.760672569274902
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([269, 417, 322, 388], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.07584354281425476
bi 1 loss 0.27450549602508545
bi 2 loss 0.11776942759752274
bi 3 loss 0.16704966127872467
Layer  5  loss:  0.16025331616401672 0.0 9.697257041931152
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([276, 533, 322, 389], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.06410126388072968
bi 1 loss 0.2773352265357971
bi 2 loss 0.10340482741594315
bi 3 loss 0.13401848077774048
Layer  6  loss:  0.19583173096179962 0.0 10.113669395446777
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([247, 416, 322, 389], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.052470237016677856
bi 1 loss 0.32085156440734863
bi 2 loss 0.1552182137966156
bi 3 loss 0.1498362123966217
Epoch 0: :   3%|▎         | 15065/600000 [00:28<18:18, v_num=12, reduced_train_loss=36.30, global_step=15063.0, consumed_samples=60256.0, train_step_timing in s=0.272]Epoch 0: :   3%|▎         | 15065/600000 [00:28<18:18, v_num=12, reduced_train_loss=1.360, global_step=15064.0, consumed_samples=60260.0, train_step_timing in s=0.445]loss mask original None

First layer loss:  0.11917577683925629 torch.Size([617, 4]) 12.119406700134277 0.0
Max loss timestep torch.Size([617, 4]) tensor([254, 359, 275, 520], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.07244132459163666
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 1 loss 0.07589775323867798
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 2 loss 0.1291869580745697
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 3 loss 0.16188588738441467
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
logits torch.Size([617, 4, 257024]) labels torch.Size([617, 4]) 0 257022
Layer  0  loss:  0.13303729891777039 0.0 12.492071151733398
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([266, 338, 326, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.04321678727865219
bi 1 loss 0.1272793561220169
bi 2 loss 0.12513640522956848
bi 3 loss 0.1866014003753662
Layer  1  loss:  0.16214150190353394 0.0 18.066448211669922
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([250, 265, 326, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.08743325620889664
bi 1 loss 0.110507071018219
bi 2 loss 0.13841848075389862
bi 3 loss 0.24236992001533508
Layer  2  loss:  0.15040676295757294 0.0 12.583913803100586
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([179, 339, 329, 520], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.05979427322745323
bi 1 loss 0.1279173344373703
bi 2 loss 0.10135281831026077
bi 3 loss 0.2363341897726059
Layer  3  loss:  0.18093964457511902 0.0 15.799005508422852
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([155, 359, 329, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.05456901341676712
bi 1 loss 0.1449168473482132
bi 2 loss 0.15725725889205933
bi 3 loss 0.27885058522224426
Layer  4  loss:  0.17576317489147186 0.0 14.97109317779541
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([106, 288, 326, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.06356461346149445
bi 1 loss 0.157538041472435
bi 2 loss 0.15382972359657288
bi 3 loss 0.2554768919944763
Layer  5  loss:  0.1507779061794281 0.0 15.078059196472168
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([288, 356, 326, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.06978906691074371
bi 1 loss 0.14047518372535706
bi 2 loss 0.1206328496336937
bi 3 loss 0.21457010507583618
Layer  6  loss:  0.1568584442138672 0.0 18.351627349853516
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([176, 335, 326, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.06030185893177986
bi 1 loss 0.17142844200134277
bi 2 loss 0.10928899049758911
bi 3 loss 0.2242354452610016
Epoch 0: :   3%|▎         | 15066/600000 [00:28<18:35, v_num=12, reduced_train_loss=1.360, global_step=15064.0, consumed_samples=60260.0, train_step_timing in s=0.445]Epoch 0: :   3%|▎         | 15066/600000 [00:28<18:35, v_num=12, reduced_train_loss=1.230, global_step=15065.0, consumed_samples=60264.0, train_step_timing in s=0.413]loss mask original None

First layer loss:  3.6931488513946533 torch.Size([684, 4]) 11.970260620117188 0.0
Max loss timestep torch.Size([684, 4]) tensor([170, 129, 625, 183], device='cuda:0') tensor(191, device='cuda:0')
bi 0 loss 4.241008281707764
speech mask sum tensor(401, device='cuda:0') loss mask sum tensor(401, device='cuda:0')
bi 1 loss 3.409877061843872
speech mask sum tensor(89, device='cuda:0') loss mask sum tensor(89, device='cuda:0')
bi 2 loss 3.6382453441619873
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
bi 3 loss 2.5228114128112793
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
logits torch.Size([684, 4, 257024]) labels torch.Size([684, 4]) 0 257022
Layer  0  loss:  4.2786335945129395 0.0 11.632251739501953
logits torch.Size([684, 4, 1024]) labels torch.Size([684, 4]) 0 1023
Curr loss timestep torch.Size([684, 4]) tensor([285, 131, 297, 199], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.688502788543701
bi 1 loss 4.463971138000488
bi 2 loss 4.234058380126953
bi 3 loss 3.167916774749756
Layer  1  loss:  4.680747032165527 0.0 10.352043151855469
logits torch.Size([684, 4, 1024]) labels torch.Size([684, 4]) 0 1021
Curr loss timestep torch.Size([684, 4]) tensor([124, 134, 273, 268], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 4.943793296813965
bi 1 loss 4.736865997314453
bi 2 loss 4.804120063781738
bi 3 loss 3.481990337371826
Layer  2  loss:  4.918859958648682 0.0 11.3275785446167
logits torch.Size([684, 4, 1024]) labels torch.Size([684, 4]) 0 1022
Curr loss timestep torch.Size([684, 4]) tensor([404, 170, 611, 263], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 5.184656620025635
bi 1 loss 4.686930179595947
bi 2 loss 5.056981563568115
bi 3 loss 3.8407132625579834
Layer  3  loss:  4.927249908447266 0.0 10.06097412109375
logits torch.Size([684, 4, 1024]) labels torch.Size([684, 4]) 0 1022
Curr loss timestep torch.Size([684, 4]) tensor([272, 156, 635, 260], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 5.201446533203125
bi 1 loss 5.004037380218506
bi 2 loss 5.048399448394775
bi 3 loss 3.692042112350464
Layer  4  loss:  5.106333255767822 0.0 12.130459785461426
logits torch.Size([684, 4, 1024]) labels torch.Size([684, 4]) 0 1022
Curr loss timestep torch.Size([684, 4]) tensor([384, 170, 380, 199], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 5.370586395263672
bi 1 loss 4.893640518188477
bi 2 loss 5.243025302886963
bi 3 loss 4.025478363037109
Layer  5  loss:  5.1669602394104 0.0 9.997024536132812
logits torch.Size([684, 4, 1024]) labels torch.Size([684, 4]) 0 1023
Curr loss timestep torch.Size([684, 4]) tensor([252, 139, 649, 204], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 5.456075191497803
bi 1 loss 4.976166725158691
bi 2 loss 5.247792720794678
bi 3 loss 4.195731163024902
Layer  6  loss:  5.310191631317139 0.0 9.720383644104004
logits torch.Size([684, 4, 1024]) labels torch.Size([684, 4]) 0 1021
Curr loss timestep torch.Size([684, 4]) tensor([438, 148, 286, 308], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 5.528846263885498
bi 1 loss 5.3422746658325195
bi 2 loss 5.47116231918335
bi 3 loss 4.120997428894043
Epoch 0: :   3%|▎         | 15067/600000 [00:29<18:52, v_num=12, reduced_train_loss=1.230, global_step=15065.0, consumed_samples=60264.0, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15067/600000 [00:29<18:52, v_num=12, reduced_train_loss=38.10, global_step=15066.0, consumed_samples=60268.0, train_step_timing in s=0.405]loss mask original None

First layer loss:  0.25313887000083923 torch.Size([649, 4]) 11.260730743408203 0.0
Max loss timestep torch.Size([649, 4]) tensor([315, 310, 605, 226], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.14111346006393433
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 1 loss 0.14516010880470276
speech mask sum tensor(346, device='cuda:0') loss mask sum tensor(346, device='cuda:0')
bi 2 loss 0.42384564876556396
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
bi 3 loss 0.07376960664987564
speech mask sum tensor(49, device='cuda:0') loss mask sum tensor(49, device='cuda:0')
logits torch.Size([649, 4, 257024]) labels torch.Size([649, 4]) 0 257022
Layer  0  loss:  0.2697034776210785 0.0 12.781615257263184
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([316, 496, 551, 228], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.18944187462329865
bi 1 loss 0.1682664453983307
bi 2 loss 0.42339026927948
bi 3 loss 0.016578922048211098
Layer  1  loss:  0.2235235720872879 0.0 12.345667839050293
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([317, 287, 439, 238], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.1489282101392746
bi 1 loss 0.1509164720773697
bi 2 loss 0.3449058532714844
bi 3 loss 0.03667174652218819
Layer  2  loss:  0.27421149611473083 0.0 14.345491409301758
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([316, 272, 530, 234], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.17072919011116028
bi 1 loss 0.15638475120067596
bi 2 loss 0.4545193314552307
bi 3 loss 0.023860860615968704
Layer  3  loss:  0.2814379036426544 0.0 12.302312850952148
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1021
Curr loss timestep torch.Size([649, 4]) tensor([316, 381, 594, 242], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.1862313598394394
bi 1 loss 0.16812823712825775
bi 2 loss 0.4466899633407593
bi 3 loss 0.09172166883945465
Layer  4  loss:  0.26827818155288696 0.0 12.515480041503906
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1020
Curr loss timestep torch.Size([649, 4]) tensor([316, 286, 441, 245], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.19484905898571014
bi 1 loss 0.12455037236213684
bi 2 loss 0.4412626326084137
bi 3 loss 0.09231938421726227
Layer  5  loss:  0.26887398958206177 0.0 12.024075508117676
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1020
Curr loss timestep torch.Size([649, 4]) tensor([317, 380, 530, 233], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.20077863335609436
bi 1 loss 0.14232686161994934
bi 2 loss 0.4323979914188385
bi 3 loss 0.028952501714229584
Layer  6  loss:  0.2994363009929657 0.0 15.102948188781738
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([315, 425, 594, 224], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.20683138072490692
bi 1 loss 0.1536078304052353
bi 2 loss 0.4933692216873169
bi 3 loss 0.05474875867366791
Epoch 0: :   3%|▎         | 15068/600000 [00:29<19:10, v_num=12, reduced_train_loss=38.10, global_step=15066.0, consumed_samples=60268.0, train_step_timing in s=0.405]Epoch 0: :   3%|▎         | 15068/600000 [00:29<19:10, v_num=12, reduced_train_loss=2.140, global_step=15067.0, consumed_samples=60272.0, train_step_timing in s=0.435]loss mask original None

First layer loss:  0.1526535302400589 torch.Size([674, 4]) 6.315243721008301 0.0
Max loss timestep torch.Size([674, 4]) tensor([330, 600, 150, 415], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.13532058894634247
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 1 loss 0.16984975337982178
speech mask sum tensor(417, device='cuda:0') loss mask sum tensor(417, device='cuda:0')
bi 2 loss 0.0309508815407753
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 3 loss 0.19938169419765472
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
logits torch.Size([674, 4, 257024]) labels torch.Size([674, 4]) 0 257022
Layer  0  loss:  0.1703043133020401 0.0 9.689387321472168
logits torch.Size([674, 4, 1024]) labels torch.Size([674, 4]) 0 1023
Curr loss timestep torch.Size([674, 4]) tensor([327, 568, 101, 222], device='cuda:0') tensor(568, device='cuda:0')
bi 0 loss 0.13032154738903046
bi 1 loss 0.22904455661773682
bi 2 loss 0.0474526546895504
bi 3 loss 0.19404318928718567
Layer  1  loss:  0.18305255472660065 0.0 11.893129348754883
logits torch.Size([674, 4, 1024]) labels torch.Size([674, 4]) 0 1023
Curr loss timestep torch.Size([674, 4]) tensor([399, 378,  77, 415], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.12523165345191956
bi 1 loss 0.2634489834308624
bi 2 loss 0.04385552182793617
bi 3 loss 0.207355797290802
Layer  2  loss:  0.21757872402668 0.0 15.114447593688965
logits torch.Size([674, 4, 1024]) labels torch.Size([674, 4]) 0 1022
Curr loss timestep torch.Size([674, 4]) tensor([498, 379,  51, 415], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.15982285141944885
bi 1 loss 0.3373509645462036
bi 2 loss 0.05188516527414322
bi 3 loss 0.20754201710224152
Layer  3  loss:  0.1714567244052887 0.0 8.328975677490234
logits torch.Size([674, 4, 1024]) labels torch.Size([674, 4]) 0 1018
Curr loss timestep torch.Size([674, 4]) tensor([330, 601, 123, 315], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.14213934540748596
bi 1 loss 0.2709702253341675
bi 2 loss 0.02981835976243019
bi 3 loss 0.14510147273540497
Layer  4  loss:  0.19016560912132263 0.0 12.422965049743652
logits torch.Size([674, 4, 1024]) labels torch.Size([674, 4]) 0 1023
Curr loss timestep torch.Size([674, 4]) tensor([501, 600, 125, 414], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.15221112966537476
bi 1 loss 0.2677463889122009
bi 2 loss 0.03096877783536911
bi 3 loss 0.2047291249036789
Layer  5  loss:  0.19119955599308014 0.0 16.193946838378906
logits torch.Size([674, 4, 1024]) labels torch.Size([674, 4]) 0 1022
Curr loss timestep torch.Size([674, 4]) tensor([330, 598, 151, 104], device='cuda:0') tensor(598, device='cuda:0')
bi 0 loss 0.15387892723083496
bi 1 loss 0.28703808784484863
bi 2 loss 0.025959238409996033
bi 3 loss 0.18674078583717346
Layer  6  loss:  0.21009944379329681 0.0 12.13442325592041
logits torch.Size([674, 4, 1024]) labels torch.Size([674, 4]) 0 1023
Curr loss timestep torch.Size([674, 4]) tensor([498, 598, 157, 228], device='cuda:0') tensor(598, device='cuda:0')
bi 0 loss 0.14815224707126617
bi 1 loss 0.3164818584918976
bi 2 loss 0.04595146328210831
bi 3 loss 0.2190631628036499
Epoch 0: :   3%|▎         | 15069/600000 [00:30<19:29, v_num=12, reduced_train_loss=2.140, global_step=15067.0, consumed_samples=60272.0, train_step_timing in s=0.435]Epoch 0: :   3%|▎         | 15069/600000 [00:30<19:29, v_num=12, reduced_train_loss=1.490, global_step=15068.0, consumed_samples=60276.0, train_step_timing in s=0.450]loss mask original None

First layer loss:  0.08467929065227509 torch.Size([567, 4]) 9.005743980407715 0.0
Max loss timestep torch.Size([567, 4]) tensor([243,  77, 317, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.05504310131072998
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 1 loss 0.0717182531952858
speech mask sum tensor(76, device='cuda:0') loss mask sum tensor(76, device='cuda:0')
bi 2 loss 0.08122485131025314
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
bi 3 loss 0.13430200517177582
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
logits torch.Size([567, 4, 257024]) labels torch.Size([567, 4]) 0 257022
Layer  0  loss:  0.11262434720993042 0.0 6.314944744110107
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([263,  75, 556, 259], device='cuda:0') tensor(556, device='cuda:0')
bi 0 loss 0.07177799940109253
bi 1 loss 0.05905473977327347
bi 2 loss 0.1443393975496292
bi 3 loss 0.10200153291225433
Layer  1  loss:  0.10225602984428406 0.0 8.070030212402344
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([304,  94, 316, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.08032835274934769
bi 1 loss 0.03474383428692818
bi 2 loss 0.10798413306474686
bi 3 loss 0.1476871818304062
Layer  2  loss:  0.10647213459014893 0.0 7.566168785095215
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([205, 111, 317, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.08172120153903961
bi 1 loss 0.025438552722334862
bi 2 loss 0.11373058706521988
bi 3 loss 0.1582043468952179
Layer  3  loss:  0.1066436767578125 0.0 5.673184394836426
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([269, 111, 316, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.06268960237503052
bi 1 loss 0.05130535364151001
bi 2 loss 0.13404792547225952
bi 3 loss 0.1120658740401268
Layer  4  loss:  0.10501604527235031 0.0 5.783504009246826
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([210,  77, 556, 261], device='cuda:0') tensor(556, device='cuda:0')
bi 0 loss 0.055034566670656204
bi 1 loss 0.03449869900941849
bi 2 loss 0.1255730390548706
bi 3 loss 0.14377367496490479
Layer  5  loss:  0.10579235851764679 0.0 7.945165157318115
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1022
Curr loss timestep torch.Size([567, 4]) tensor([273, 114, 317, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.06052412837743759
bi 1 loss 0.03333919867873192
bi 2 loss 0.1406242847442627
bi 3 loss 0.10187375545501709
Layer  6  loss:  0.10930650681257248 0.0 7.643542289733887
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1022
Curr loss timestep torch.Size([567, 4]) tensor([314,  97, 447, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.08397167176008224
bi 1 loss 0.05608677119016647
bi 2 loss 0.12036330252885818
bi 3 loss 0.136592298746109
Epoch 0: :   3%|▎         | 15070/600000 [00:30<19:45, v_num=12, reduced_train_loss=1.490, global_step=15068.0, consumed_samples=60276.0, train_step_timing in s=0.450]Epoch 0: :   3%|▎         | 15070/600000 [00:30<19:45, v_num=12, reduced_train_loss=0.833, global_step=15069.0, consumed_samples=60280.0, train_step_timing in s=0.387]loss mask original None

First layer loss:  0.022554323077201843 torch.Size([378, 4]) 2.8301610946655273 0.0
Max loss timestep torch.Size([378, 4]) tensor([165, 323, 121, 181], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 0.01435321755707264
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 1 loss 0.0179793369024992
speech mask sum tensor(332, device='cuda:0') loss mask sum tensor(332, device='cuda:0')
bi 2 loss 0.01341623067855835
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 3 loss 0.06572692096233368
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
logits torch.Size([378, 4, 257024]) labels torch.Size([378, 4]) 0 257023
Layer  0  loss:  0.01551856566220522 0.0 0.20854683220386505
logits torch.Size([378, 4, 1024]) labels torch.Size([378, 4]) 0 1023
Curr loss timestep torch.Size([378, 4]) tensor([238,  85, 147, 193], device='cuda:0') tensor(85, device='cuda:0')
bi 0 loss 0.01595604047179222
bi 1 loss 0.016125265508890152
bi 2 loss 0.012426950968801975
bi 3 loss 0.015664108097553253
Layer  1  loss:  0.014960424974560738 0.0 0.19799396395683289
logits torch.Size([378, 4, 1024]) labels torch.Size([378, 4]) 0 1022
Curr loss timestep torch.Size([378, 4]) tensor([111, 121, 139, 181], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 0.014642882160842419
bi 1 loss 0.0147936400026083
bi 2 loss 0.016258949413895607
bi 3 loss 0.014893154613673687
Layer  2  loss:  0.01674087904393673 0.0 0.26086950302124023
logits torch.Size([378, 4, 1024]) labels torch.Size([378, 4]) 0 1022
Curr loss timestep torch.Size([378, 4]) tensor([115, 139, 121, 154], device='cuda:0') tensor(115, device='cuda:0')
bi 0 loss 0.018930967897176743
bi 1 loss 0.01704215072095394
bi 2 loss 0.015010829083621502
bi 3 loss 0.012661535292863846
Layer  3  loss:  0.01672947406768799 0.0 0.32208728790283203
logits torch.Size([378, 4, 1024]) labels torch.Size([378, 4]) 0 1023
Curr loss timestep torch.Size([378, 4]) tensor([121, 148, 118, 154], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 0.018264614045619965
bi 1 loss 0.015866030007600784
bi 2 loss 0.016633734107017517
bi 3 loss 0.016396667808294296
Layer  4  loss:  0.014983115717768669 0.0 0.3876342177391052
logits torch.Size([378, 4, 1024]) labels torch.Size([378, 4]) 0 1022
Curr loss timestep torch.Size([378, 4]) tensor([ 70, 288, 172, 197], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.014561453834176064
bi 1 loss 0.017086049541831017
bi 2 loss 0.012947078794240952
bi 3 loss 0.010814711451530457
Layer  5  loss:  0.014283915981650352 0.0 0.2631409764289856
logits torch.Size([378, 4, 1024]) labels torch.Size([378, 4]) 0 1023
Curr loss timestep torch.Size([378, 4]) tensor([149, 348, 180, 212], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 0.015644745901226997
bi 1 loss 0.015092370100319386
bi 2 loss 0.013773646205663681
bi 3 loss 0.009040636010468006
Layer  6  loss:  0.015595686621963978 0.0 0.17781658470630646
logits torch.Size([378, 4, 1024]) labels torch.Size([378, 4]) 0 1021
Curr loss timestep torch.Size([378, 4]) tensor([239, 239, 120, 169], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 0.019488852471113205
bi 1 loss 0.013993917964398861
bi 2 loss 0.015651674941182137
bi 3 loss 0.012431270442903042
Epoch 0: :   3%|▎         | 15071/600000 [00:30<19:58, v_num=12, reduced_train_loss=0.833, global_step=15069.0, consumed_samples=60280.0, train_step_timing in s=0.387]Epoch 0: :   3%|▎         | 15071/600000 [00:30<19:58, v_num=12, reduced_train_loss=0.131, global_step=15070.0, consumed_samples=60284.0, train_step_timing in s=0.286]loss mask original None

First layer loss:  3.920933723449707 torch.Size([540, 4]) 9.910504341125488 0.0
Max loss timestep torch.Size([540, 4]) tensor([233, 206, 121, 171], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 3.7763142585754395
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
bi 1 loss 3.9828414916992188
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
bi 2 loss 3.934176206588745
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
bi 3 loss 4.069431304931641
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
logits torch.Size([540, 4, 257024]) labels torch.Size([540, 4]) 0 257023
Layer  0  loss:  4.265115261077881 0.0 10.753738403320312
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([114, 295,  87, 142], device='cuda:0') tensor(207, device='cuda:0')
bi 0 loss 4.466824054718018
bi 1 loss 4.22204065322876
bi 2 loss 3.999983549118042
bi 3 loss 4.646145343780518
Layer  1  loss:  4.837306499481201 0.0 10.491347312927246
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([235, 429, 203, 100], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.820742130279541
bi 1 loss 4.713829040527344
bi 2 loss 4.910952091217041
bi 3 loss 4.957698822021484
Layer  2  loss:  5.11232852935791 0.0 11.341331481933594
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([329, 269,  76, 163], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 5.180504322052002
bi 1 loss 4.995085716247559
bi 2 loss 5.1903862953186035
bi 3 loss 5.012421607971191
Layer  3  loss:  5.178983211517334 0.0 11.293708801269531
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([370, 129, 327, 226], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 5.287586212158203
bi 1 loss 5.089712619781494
bi 2 loss 5.182449817657471
bi 3 loss 5.129896640777588
Layer  4  loss:  5.333931922912598 0.0 10.444076538085938
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([335, 166,  69, 129], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 5.4576849937438965
bi 1 loss 5.253054141998291
bi 2 loss 5.342229843139648
bi 3 loss 5.2171711921691895
Layer  5  loss:  5.407852649688721 0.0 10.839447021484375
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1019
Curr loss timestep torch.Size([540, 4]) tensor([176, 472, 274, 104], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 5.527152061462402
bi 1 loss 5.385453224182129
bi 2 loss 5.34989070892334
bi 3 loss 5.349828243255615
Layer  6  loss:  5.465113162994385 0.0 11.708653450012207
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([176, 398, 521, 224], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 5.692772388458252
bi 1 loss 5.371370315551758
bi 2 loss 5.410070419311523
bi 3 loss 5.318227291107178
Epoch 0: :   3%|▎         | 15072/600000 [00:31<20:13, v_num=12, reduced_train_loss=0.131, global_step=15070.0, consumed_samples=60284.0, train_step_timing in s=0.286]Epoch 0: :   3%|▎         | 15072/600000 [00:31<20:13, v_num=12, reduced_train_loss=39.50, global_step=15071.0, consumed_samples=60288.0, train_step_timing in s=0.344]loss mask original None

First layer loss:  3.8635356426239014 torch.Size([640, 4]) 10.112088203430176 0.0
Max loss timestep torch.Size([640, 4]) tensor([158, 238, 205, 399], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 3.314615488052368
speech mask sum tensor(200, device='cuda:0') loss mask sum tensor(200, device='cuda:0')
bi 1 loss 4.320623397827148
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 2 loss 4.168614387512207
speech mask sum tensor(461, device='cuda:0') loss mask sum tensor(461, device='cuda:0')
bi 3 loss 3.564410448074341
speech mask sum tensor(285, device='cuda:0') loss mask sum tensor(285, device='cuda:0')
logits torch.Size([640, 4, 257024]) labels torch.Size([640, 4]) 0 257023
Layer  0  loss:  4.418177127838135 0.0 11.868345260620117
logits torch.Size([640, 4, 1024]) labels torch.Size([640, 4]) 0 1023
Curr loss timestep torch.Size([640, 4]) tensor([147, 250, 608, 332], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 3.9488320350646973
bi 1 loss 5.0305657386779785
bi 2 loss 4.541199207305908
bi 3 loss 4.292849540710449
Layer  1  loss:  4.734558582305908 0.0 11.576120376586914
logits torch.Size([640, 4, 1024]) labels torch.Size([640, 4]) 0 1022
Curr loss timestep torch.Size([640, 4]) tensor([223, 190, 607, 415], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 4.56729793548584
bi 1 loss 4.900292873382568
bi 2 loss 4.930667400360107
bi 3 loss 4.465519428253174
Layer  2  loss:  4.954024314880371 0.0 9.950881004333496
logits torch.Size([640, 4, 1024]) labels torch.Size([640, 4]) 0 1022
Curr loss timestep torch.Size([640, 4]) tensor([203, 224, 228, 419], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.787158966064453
bi 1 loss 5.326754570007324
bi 2 loss 5.031726837158203
bi 3 loss 4.789802551269531
Layer  3  loss:  5.034018516540527 0.0 10.683409690856934
logits torch.Size([640, 4, 1024]) labels torch.Size([640, 4]) 0 1021
Curr loss timestep torch.Size([640, 4]) tensor([278, 260, 184, 525], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.857977867126465
bi 1 loss 5.301241874694824
bi 2 loss 5.1487579345703125
bi 3 loss 4.860381603240967
Layer  4  loss:  5.132813930511475 0.0 9.906549453735352
logits torch.Size([640, 4, 1024]) labels torch.Size([640, 4]) 0 1022
Curr loss timestep torch.Size([640, 4]) tensor([175, 255, 294, 567], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 4.901866912841797
bi 1 loss 5.461333274841309
bi 2 loss 5.163181781768799
bi 3 loss 5.108587741851807
Layer  5  loss:  5.235138893127441 0.0 10.069880485534668
logits torch.Size([640, 4, 1024]) labels torch.Size([640, 4]) 0 1019
Curr loss timestep torch.Size([640, 4]) tensor([315, 227, 510, 445], device='cuda:0') tensor(208, device='cuda:0')
bi 0 loss 4.928583145141602
bi 1 loss 5.638461112976074
bi 2 loss 5.3099188804626465
bi 3 loss 5.1609015464782715
Layer  6  loss:  5.284106254577637 0.0 10.787877082824707
logits torch.Size([640, 4, 1024]) labels torch.Size([640, 4]) 0 1023
Curr loss timestep torch.Size([640, 4]) tensor([262, 206, 612, 567], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 5.032741069793701
bi 1 loss 5.725522994995117
bi 2 loss 5.2988152503967285
bi 3 loss 5.252399444580078
Epoch 0: :   3%|▎         | 15073/600000 [00:31<20:29, v_num=12, reduced_train_loss=39.50, global_step=15071.0, consumed_samples=60288.0, train_step_timing in s=0.344]Epoch 0: :   3%|▎         | 15073/600000 [00:31<20:29, v_num=12, reduced_train_loss=38.70, global_step=15072.0, consumed_samples=60292.0, train_step_timing in s=0.389]loss mask original None

First layer loss:  0.12884575128555298 torch.Size([566, 4]) 9.792162895202637 0.0
Max loss timestep torch.Size([566, 4]) tensor([223, 378, 365, 347], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.051141589879989624
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 1 loss 0.10139697790145874
speech mask sum tensor(346, device='cuda:0') loss mask sum tensor(346, device='cuda:0')
bi 2 loss 0.12494511157274246
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
bi 3 loss 0.18351905047893524
speech mask sum tensor(363, device='cuda:0') loss mask sum tensor(363, device='cuda:0')
logits torch.Size([566, 4, 257024]) labels torch.Size([566, 4]) 0 257022
Layer  0  loss:  0.14364521205425262 0.0 8.4065580368042
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([263, 378, 316, 452], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.06806158274412155
bi 1 loss 0.10062075406312943
bi 2 loss 0.15516188740730286
bi 3 loss 0.2046680450439453
Layer  1  loss:  0.14722658693790436 0.0 8.479527473449707
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([180, 378, 318, 347], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.06458029896020889
bi 1 loss 0.09430278092622757
bi 2 loss 0.1684006154537201
bi 3 loss 0.2152291238307953
Layer  2  loss:  0.17578040063381195 0.0 10.081888198852539
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([163, 378, 316, 298], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.04350345954298973
bi 1 loss 0.12795230746269226
bi 2 loss 0.16522027552127838
bi 3 loss 0.27187782526016235
Layer  3  loss:  0.18190555274486542 0.0 13.594046592712402
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1021
Curr loss timestep torch.Size([566, 4]) tensor([176, 378, 316, 347], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.03728482127189636
bi 1 loss 0.14183872938156128
bi 2 loss 0.13390901684761047
bi 3 loss 0.2936946451663971
Layer  4  loss:  0.16828137636184692 0.0 10.568827629089355
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([262, 378, 303, 547], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.05590079724788666
bi 1 loss 0.1452386975288391
bi 2 loss 0.12234342843294144
bi 3 loss 0.25179266929626465
Layer  5  loss:  0.1792902946472168 0.0 8.815549850463867
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([227, 323, 315, 452], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.09053400903940201
bi 1 loss 0.09964898973703384
bi 2 loss 0.16271013021469116
bi 3 loss 0.2938793897628784
Layer  6  loss:  0.1422399878501892 0.0 10.44701862335205
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([181, 378, 316, 547], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.039093513041734695
bi 1 loss 0.11184030026197433
bi 2 loss 0.12862056493759155
bi 3 loss 0.21331660449504852
Epoch 0: :   3%|▎         | 15074/600000 [00:32<20:45, v_num=12, reduced_train_loss=38.70, global_step=15072.0, consumed_samples=60292.0, train_step_timing in s=0.389]Epoch 0: :   3%|▎         | 15074/600000 [00:32<20:45, v_num=12, reduced_train_loss=1.270, global_step=15073.0, consumed_samples=60296.0, train_step_timing in s=0.385]loss mask original None

First layer loss:  0.09194090962409973 torch.Size([497, 4]) 10.628829002380371 0.0
Max loss timestep torch.Size([497, 4]) tensor([273, 150, 271, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.07119552791118622
speech mask sum tensor(276, device='cuda:0') loss mask sum tensor(276, device='cuda:0')
bi 1 loss 0.0987199991941452
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 2 loss 0.048354122787714005
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 3 loss 0.12358880043029785
speech mask sum tensor(357, device='cuda:0') loss mask sum tensor(357, device='cuda:0')
logits torch.Size([497, 4, 257024]) labels torch.Size([497, 4]) 0 257023
Layer  0  loss:  0.08862476050853729 0.0 14.50219440460205
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([273, 309, 309, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.06280636787414551
bi 1 loss 0.04232844337821007
bi 2 loss 0.11927875131368637
bi 3 loss 0.12389715760946274
Layer  1  loss:  0.09043744206428528 0.0 11.48203182220459
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([273, 309, 309, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.05293586105108261
bi 1 loss 0.05229802802205086
bi 2 loss 0.1051686629652977
bi 3 loss 0.13684849441051483
Layer  2  loss:  0.08815106749534607 0.0 10.756328582763672
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([273, 156, 309, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.07739733159542084
bi 1 loss 0.04448983445763588
bi 2 loss 0.07643534988164902
bi 3 loss 0.12945397198200226
Layer  3  loss:  0.10055121034383774 0.0 14.69614028930664
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([271, 309, 309, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.07269609719514847
bi 1 loss 0.03597642108798027
bi 2 loss 0.09746097773313522
bi 3 loss 0.16437648236751556
Layer  4  loss:  0.08987951278686523 0.0 12.41545295715332
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([250, 326, 280, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.06992141157388687
bi 1 loss 0.040836967527866364
bi 2 loss 0.09135623276233673
bi 3 loss 0.1356816291809082
Layer  5  loss:  0.10003437846899033 0.0 14.384391784667969
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([271, 309, 309, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.08488669991493225
bi 1 loss 0.04567038640379906
bi 2 loss 0.08787992596626282
bi 3 loss 0.15171000361442566
Layer  6  loss:  0.09533566236495972 0.0 11.706767082214355
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([271, 291, 309, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.09589547663927078
bi 1 loss 0.031887590885162354
bi 2 loss 0.16046777367591858
bi 3 loss 0.10533067584037781
Epoch 0: :   3%|▎         | 15075/600000 [00:32<21:00, v_num=12, reduced_train_loss=1.270, global_step=15073.0, consumed_samples=60296.0, train_step_timing in s=0.385]Epoch 0: :   3%|▎         | 15075/600000 [00:32<21:00, v_num=12, reduced_train_loss=0.745, global_step=15074.0, consumed_samples=60300.0, train_step_timing in s=0.346]loss mask original None

First layer loss:  0.10634433478116989 torch.Size([539, 4]) 8.031774520874023 0.0
Max loss timestep torch.Size([539, 4]) tensor([409, 265, 130, 289], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.12090325355529785
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 1 loss 0.12240654975175858
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 2 loss 0.03497748821973801
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 3 loss 0.09534717351198196
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
logits torch.Size([539, 4, 257024]) labels torch.Size([539, 4]) 0 257023
Layer  0  loss:  0.11622461676597595 0.0 7.313544750213623
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([409, 262, 147, 167], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.1279091089963913
bi 1 loss 0.17128410935401917
bi 2 loss 0.021517837420105934
bi 3 loss 0.10020285099744797
Layer  1  loss:  0.13675856590270996 0.0 5.438661098480225
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([400, 263, 158, 351], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.14260604977607727
bi 1 loss 0.18943049013614655
bi 2 loss 0.02112036570906639
bi 3 loss 0.14029145240783691
Layer  2  loss:  0.13826856017112732 0.0 9.753262519836426
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([409, 265, 143, 289], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.16694191098213196
bi 1 loss 0.14015869796276093
bi 2 loss 0.023636644706130028
bi 3 loss 0.12185075134038925
Layer  3  loss:  0.13743652403354645 0.0 8.378058433532715
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1021
Curr loss timestep torch.Size([539, 4]) tensor([421, 262, 173, 351], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.1793280839920044
bi 1 loss 0.1318439245223999
bi 2 loss 0.042475856840610504
bi 3 loss 0.09243693947792053
Layer  4  loss:  0.15048672258853912 0.0 8.731927871704102
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1021
Curr loss timestep torch.Size([539, 4]) tensor([421, 262, 137, 330], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.14745447039604187
bi 1 loss 0.18944837152957916
bi 2 loss 0.029594074934720993
bi 3 loss 0.17940650880336761
Layer  5  loss:  0.14624901115894318 0.0 6.5654802322387695
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([467, 263, 123, 298], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.1416509449481964
bi 1 loss 0.169733926653862
bi 2 loss 0.023274598643183708
bi 3 loss 0.18626749515533447
Layer  6  loss:  0.1306508183479309 0.0 5.662362575531006
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([409, 262, 157, 298], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.1308959424495697
bi 1 loss 0.1483376920223236
bi 2 loss 0.03236427530646324
bi 3 loss 0.15562841296195984
Epoch 0: :   3%|▎         | 15076/600000 [00:32<21:16, v_num=12, reduced_train_loss=0.745, global_step=15074.0, consumed_samples=60300.0, train_step_timing in s=0.346]Epoch 0: :   3%|▎         | 15076/600000 [00:32<21:16, v_num=12, reduced_train_loss=1.060, global_step=15075.0, consumed_samples=60304.0, train_step_timing in s=0.367]loss mask original None

First layer loss:  3.2903528213500977 torch.Size([364, 4]) 9.543917655944824 0.0
Max loss timestep torch.Size([364, 4]) tensor([ 74, 197, 144, 107], device='cuda:0') tensor(78, device='cuda:0')
bi 0 loss 3.455414295196533
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 1 loss 2.409210443496704
speech mask sum tensor(48, device='cuda:0') loss mask sum tensor(48, device='cuda:0')
bi 2 loss 3.5356664657592773
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 3 loss 2.758899450302124
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
logits torch.Size([364, 4, 257024]) labels torch.Size([364, 4]) 0 257022
Layer  0  loss:  3.861116647720337 0.0 9.928805351257324
logits torch.Size([364, 4, 1024]) labels torch.Size([364, 4]) 0 1023
Curr loss timestep torch.Size([364, 4]) tensor([258, 189, 160,  78], device='cuda:0') tensor(132, device='cuda:0')
bi 0 loss 4.035733699798584
bi 1 loss 3.1099274158477783
bi 2 loss 3.7706594467163086
bi 3 loss 3.844780206680298
Layer  1  loss:  4.200066566467285 0.0 9.843676567077637
logits torch.Size([364, 4, 1024]) labels torch.Size([364, 4]) 0 1022
Curr loss timestep torch.Size([364, 4]) tensor([305, 196,  63,  72], device='cuda:0') tensor(129, device='cuda:0')
bi 0 loss 4.308973789215088
bi 1 loss 3.366514205932617
bi 2 loss 4.346205711364746
bi 3 loss 4.0054521560668945
Layer  2  loss:  4.474474906921387 0.0 9.63159465789795
logits torch.Size([364, 4, 1024]) labels torch.Size([364, 4]) 0 1023
Curr loss timestep torch.Size([364, 4]) tensor([135, 200, 151, 103], device='cuda:0') tensor(129, device='cuda:0')
bi 0 loss 4.5823655128479
bi 1 loss 3.7957849502563477
bi 2 loss 4.598530292510986
bi 3 loss 4.245095252990723
Layer  3  loss:  4.5483269691467285 0.0 10.102601051330566
logits torch.Size([364, 4, 1024]) labels torch.Size([364, 4]) 0 1018
Curr loss timestep torch.Size([364, 4]) tensor([143, 190, 110, 120], device='cuda:0') tensor(115, device='cuda:0')
bi 0 loss 4.612431526184082
bi 1 loss 4.159749507904053
bi 2 loss 4.579494476318359
bi 3 loss 4.48209285736084
Layer  4  loss:  4.698679447174072 0.0 9.627361297607422
logits torch.Size([364, 4, 1024]) labels torch.Size([364, 4]) 0 1016
Curr loss timestep torch.Size([364, 4]) tensor([139, 197, 191, 139], device='cuda:0') tensor(139, device='cuda:0')
bi 0 loss 4.715839862823486
bi 1 loss 4.010160446166992
bi 2 loss 4.829070091247559
bi 3 loss 4.754018306732178
Layer  5  loss:  4.79888391494751 0.0 9.278691291809082
logits torch.Size([364, 4, 1024]) labels torch.Size([364, 4]) 0 1023
Curr loss timestep torch.Size([364, 4]) tensor([346, 201, 175,  95], device='cuda:0') tensor(122, device='cuda:0')
bi 0 loss 4.848140239715576
bi 1 loss 4.136777877807617
bi 2 loss 4.864648818969727
bi 3 loss 4.855522155761719
Layer  6  loss:  4.794994831085205 0.0 9.318307876586914
logits torch.Size([364, 4, 1024]) labels torch.Size([364, 4]) 0 1021
Curr loss timestep torch.Size([364, 4]) tensor([155, 191, 139,  95], device='cuda:0') tensor(93, device='cuda:0')
bi 0 loss 4.753111362457275
bi 1 loss 4.337566375732422
bi 2 loss 5.045176982879639
bi 3 loss 4.704989910125732
Epoch 0: :   3%|▎         | 15077/600000 [00:33<21:28, v_num=12, reduced_train_loss=1.060, global_step=15075.0, consumed_samples=60304.0, train_step_timing in s=0.367]Epoch 0: :   3%|▎         | 15077/600000 [00:33<21:28, v_num=12, reduced_train_loss=34.70, global_step=15076.0, consumed_samples=60308.0, train_step_timing in s=0.273]loss mask original None

First layer loss:  3.262031316757202 torch.Size([436, 4]) 15.570606231689453 0.0
Max loss timestep torch.Size([436, 4]) tensor([179,  52, 309, 126], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 3.353253126144409
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
bi 1 loss 2.8261301517486572
speech mask sum tensor(45, device='cuda:0') loss mask sum tensor(45, device='cuda:0')
bi 2 loss 3.2601704597473145
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
bi 3 loss 3.3426103591918945
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
logits torch.Size([436, 4, 257024]) labels torch.Size([436, 4]) 0 257022
Layer  0  loss:  3.9419779777526855 0.0 9.930488586425781
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([175,  63, 394, 195], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 4.38297700881958
bi 1 loss 3.1281192302703857
bi 2 loss 3.947814464569092
bi 3 loss 3.865412950515747
Layer  1  loss:  4.231391906738281 0.0 9.465895652770996
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([192,  57, 395, 208], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 4.513163089752197
bi 1 loss 3.6175904273986816
bi 2 loss 4.225789546966553
bi 3 loss 4.230282783508301
Layer  2  loss:  4.453433990478516 0.0 9.517539978027344
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([177,  55, 415, 133], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 4.96605920791626
bi 1 loss 3.4491522312164307
bi 2 loss 4.325061321258545
bi 3 loss 4.613643646240234
Layer  3  loss:  4.5188374519348145 0.0 9.340605735778809
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1019
Curr loss timestep torch.Size([436, 4]) tensor([245,  70, 293, 133], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 4.848567962646484
bi 1 loss 3.868412971496582
bi 2 loss 4.328073978424072
bi 3 loss 4.8070068359375
Layer  4  loss:  4.782583236694336 0.0 9.382036209106445
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1021
Curr loss timestep torch.Size([436, 4]) tensor([177,  72, 301, 134], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 5.180979251861572
bi 1 loss 3.723889112472534
bi 2 loss 4.811882972717285
bi 3 loss 4.782909870147705
Layer  5  loss:  4.746802806854248 0.0 9.188078880310059
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([226,  72, 334, 153], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.821725368499756
bi 1 loss 3.917186737060547
bi 2 loss 4.729186058044434
bi 3 loss 5.001059532165527
Layer  6  loss:  4.838718891143799 0.0 9.35545825958252
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([242,  69, 343, 117], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 5.0440874099731445
bi 1 loss 3.761868953704834
bi 2 loss 4.792428016662598
bi 3 loss 5.124131679534912
Epoch 0: :   3%|▎         | 15078/600000 [00:33<21:41, v_num=12, reduced_train_loss=34.70, global_step=15076.0, consumed_samples=60308.0, train_step_timing in s=0.273]Epoch 0: :   3%|▎         | 15078/600000 [00:33<21:41, v_num=12, reduced_train_loss=34.80, global_step=15077.0, consumed_samples=60312.0, train_step_timing in s=0.306]loss mask original None

First layer loss:  0.09720566868782043 torch.Size([509, 4]) 8.982291221618652 0.0
Max loss timestep torch.Size([509, 4]) tensor([353, 122, 225, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.10259722918272018
speech mask sum tensor(293, device='cuda:0') loss mask sum tensor(293, device='cuda:0')
bi 1 loss 0.06367227435112
speech mask sum tensor(138, device='cuda:0') loss mask sum tensor(138, device='cuda:0')
bi 2 loss 0.05571575462818146
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.12360918521881104
speech mask sum tensor(315, device='cuda:0') loss mask sum tensor(315, device='cuda:0')
logits torch.Size([509, 4, 257024]) labels torch.Size([509, 4]) 0 257022
Layer  0  loss:  0.10214313864707947 0.0 8.62575912475586
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([350, 137, 267, 360], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.1170511245727539
bi 1 loss 0.08526427298784256
bi 2 loss 0.05149048939347267
bi 3 loss 0.11609276384115219
Layer  1  loss:  0.08720707893371582 0.0 9.8910551071167
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([350, 174, 252, 278], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.12419600039720535
bi 1 loss 0.036889199167490005
bi 2 loss 0.055222705006599426
bi 3 loss 0.08774085342884064
Layer  2  loss:  0.11400619149208069 0.0 8.298286437988281
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([353,  81, 238, 279], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.1735249012708664
bi 1 loss 0.07683824747800827
bi 2 loss 0.0423533134162426
bi 3 loss 0.10381607711315155
Layer  3  loss:  0.0961717963218689 0.0 10.585400581359863
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1021
Curr loss timestep torch.Size([509, 4]) tensor([350,  94, 268, 265], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.12347004562616348
bi 1 loss 0.05609870329499245
bi 2 loss 0.03718845173716545
bi 3 loss 0.1121165081858635
Layer  4  loss:  0.12236209958791733 0.0 11.504714012145996
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([350, 151, 268, 279], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.15819151699543
bi 1 loss 0.04747414216399193
bi 2 loss 0.08327138423919678
bi 3 loss 0.13760346174240112
Layer  5  loss:  0.10817567259073257 0.0 13.022969245910645
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1020
Curr loss timestep torch.Size([509, 4]) tensor([350, 113, 268, 279], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.16965892910957336
bi 1 loss 0.049916986376047134
bi 2 loss 0.05038059502840042
bi 3 loss 0.09981086105108261
Layer  6  loss:  0.0949578806757927 0.0 7.999350547790527
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1021
Curr loss timestep torch.Size([509, 4]) tensor([350,  88, 265, 380], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.1290302276611328
bi 1 loss 0.06374245136976242
bi 2 loss 0.04510657116770744
bi 3 loss 0.09703929722309113
Epoch 0: :   3%|▎         | 15079/600000 [00:33<21:56, v_num=12, reduced_train_loss=34.80, global_step=15077.0, consumed_samples=60312.0, train_step_timing in s=0.306]Epoch 0: :   3%|▎         | 15079/600000 [00:33<21:56, v_num=12, reduced_train_loss=0.822, global_step=15078.0, consumed_samples=60316.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  3.8152241706848145 torch.Size([560, 4]) 11.449029922485352 0.0
Max loss timestep torch.Size([560, 4]) tensor([364, 268, 120, 225], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 4.073617935180664
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 1 loss 3.720067262649536
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 2 loss 3.7716972827911377
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
bi 3 loss 3.5675153732299805
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
logits torch.Size([560, 4, 257024]) labels torch.Size([560, 4]) 0 257022
Layer  0  loss:  4.459802627563477 0.0 10.996541976928711
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([455, 233, 176, 191], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 4.630101203918457
bi 1 loss 4.353645324707031
bi 2 loss 4.423919677734375
bi 3 loss 4.3912353515625
Layer  1  loss:  4.546448230743408 0.0 9.633659362792969
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([442, 336, 253, 171], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 4.815216541290283
bi 1 loss 4.355411052703857
bi 2 loss 4.539245128631592
bi 3 loss 4.301280498504639
Layer  2  loss:  4.932558536529541 0.0 10.131309509277344
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([457, 366, 166, 220], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 5.070902347564697
bi 1 loss 4.64069938659668
bi 2 loss 5.08214807510376
bi 3 loss 4.57406759262085
Layer  3  loss:  5.071743965148926 0.0 11.065506935119629
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([487, 209, 303, 162], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 5.141453742980957
bi 1 loss 4.757453918457031
bi 2 loss 5.189208984375
bi 3 loss 5.009313583374023
Layer  4  loss:  5.1696577072143555 0.0 10.293973922729492
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([427, 223, 224, 187], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 5.304328441619873
bi 1 loss 4.685999870300293
bi 2 loss 5.317840576171875
bi 3 loss 5.129923343658447
Layer  5  loss:  5.221120834350586 0.0 11.125370025634766
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([493, 229, 274, 193], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 5.366591453552246
bi 1 loss 4.748757362365723
bi 2 loss 5.391599178314209
bi 3 loss 5.0615739822387695
Layer  6  loss:  5.330452919006348 0.0 9.906599998474121
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1020
Curr loss timestep torch.Size([560, 4]) tensor([453, 380, 142, 176], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 5.413278579711914
bi 1 loss 4.985566139221191
bi 2 loss 5.4461493492126465
bi 3 loss 5.294989109039307
Epoch 0: :   3%|▎         | 15080/600000 [00:34<22:11, v_num=12, reduced_train_loss=0.822, global_step=15078.0, consumed_samples=60316.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15080/600000 [00:34<22:11, v_num=12, reduced_train_loss=38.50, global_step=15079.0, consumed_samples=60320.0, train_step_timing in s=0.348]loss mask original None

First layer loss:  0.06507366895675659 torch.Size([341, 4]) 11.657965660095215 0.0
Max loss timestep torch.Size([341, 4]) tensor([306,  87, 152, 195], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.2218320518732071
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 1 loss 0.016212761402130127
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 2 loss 0.010585485957562923
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 3 loss 0.022742634639143944
speech mask sum tensor(126, device='cuda:0') loss mask sum tensor(126, device='cuda:0')
logits torch.Size([341, 4, 257024]) labels torch.Size([341, 4]) 0 257022
Layer  0  loss:  0.05199375003576279 0.0 10.644193649291992
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1023
Curr loss timestep torch.Size([341, 4]) tensor([308,  84, 111, 218], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.16966241598129272
bi 1 loss 0.017338620498776436
bi 2 loss 0.009862679056823254
bi 3 loss 0.02095434069633484
Layer  1  loss:  0.061856769025325775 0.0 11.345731735229492
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1022
Curr loss timestep torch.Size([341, 4]) tensor([306, 178, 258, 152], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.19795076549053192
bi 1 loss 0.016329560428857803
bi 2 loss 0.01669779047369957
bi 3 loss 0.023388756439089775
Layer  2  loss:  0.0731891468167305 0.0 17.078088760375977
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1022
Curr loss timestep torch.Size([341, 4]) tensor([306, 124, 295, 195], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.25219064950942993
bi 1 loss 0.01479819044470787
bi 2 loss 0.013653525151312351
bi 3 loss 0.021374572068452835
Layer  3  loss:  0.06723843514919281 0.0 11.755758285522461
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1017
Curr loss timestep torch.Size([341, 4]) tensor([306, 126, 258, 150], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.2258281111717224
bi 1 loss 0.026034926995635033
bi 2 loss 0.010801702737808228
bi 3 loss 0.018932683393359184
Layer  4  loss:  0.06729644536972046 0.0 11.053210258483887
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1020
Curr loss timestep torch.Size([341, 4]) tensor([306, 120, 108, 194], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.22785308957099915
bi 1 loss 0.019017131999135017
bi 2 loss 0.013791253790259361
bi 3 loss 0.016835326328873634
Layer  5  loss:  0.056833215057849884 0.0 8.585952758789062
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1015
Curr loss timestep torch.Size([341, 4]) tensor([295, 119, 259, 147], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.17307507991790771
bi 1 loss 0.016366805881261826
bi 2 loss 0.019538428634405136
bi 3 loss 0.022678444162011147
Layer  6  loss:  0.06352577358484268 0.0 11.354463577270508
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1019
Curr loss timestep torch.Size([341, 4]) tensor([306, 124, 248, 159], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.19840151071548462
bi 1 loss 0.013125086203217506
bi 2 loss 0.021074671298265457
bi 3 loss 0.02556709013879299
Epoch 0: :   3%|▎         | 15081/600000 [00:34<22:23, v_num=12, reduced_train_loss=38.50, global_step=15079.0, consumed_samples=60320.0, train_step_timing in s=0.348]Epoch 0: :   3%|▎         | 15081/600000 [00:34<22:23, v_num=12, reduced_train_loss=0.507, global_step=15080.0, consumed_samples=60324.0, train_step_timing in s=0.269]loss mask original None

First layer loss:  0.09671950340270996 torch.Size([638, 4]) 5.195930480957031 0.0
Max loss timestep torch.Size([638, 4]) tensor([626, 267,  85, 303], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.1780068278312683
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 1 loss 0.06792965531349182
speech mask sum tensor(299, device='cuda:0') loss mask sum tensor(299, device='cuda:0')
bi 2 loss 0.07568908482789993
speech mask sum tensor(57, device='cuda:0') loss mask sum tensor(57, device='cuda:0')
bi 3 loss 0.06705550104379654
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
logits torch.Size([638, 4, 257024]) labels torch.Size([638, 4]) 0 257022
Layer  0  loss:  0.10589456558227539 0.0 8.884489059448242
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([579, 268,  62, 115], device='cuda:0') tensor(579, device='cuda:0')
bi 0 loss 0.22925080358982086
bi 1 loss 0.06778758019208908
bi 2 loss 0.02709137834608555
bi 3 loss 0.06452743709087372
Layer  1  loss:  0.12446606159210205 0.0 6.338645935058594
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([626, 330,  83, 263], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.27128085494041443
bi 1 loss 0.08137903362512589
bi 2 loss 0.05007271096110344
bi 3 loss 0.0687473937869072
Layer  2  loss:  0.13669303059577942 0.0 6.379236221313477
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([458, 268,  92, 262], device='cuda:0') tensor(458, device='cuda:0')
bi 0 loss 0.2961028814315796
bi 1 loss 0.09206759184598923
bi 2 loss 0.024698326364159584
bi 3 loss 0.08031897246837616
Layer  3  loss:  0.10909698903560638 0.0 5.008602619171143
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([465, 268,  80, 133], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.22620795667171478
bi 1 loss 0.08363252878189087
bi 2 loss 0.05754662677645683
bi 3 loss 0.05335415527224541
Layer  4  loss:  0.12998537719249725 0.0 10.467878341674805
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([626, 267,  86, 335], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.2638351619243622
bi 1 loss 0.09335929155349731
bi 2 loss 0.025516999885439873
bi 3 loss 0.08389481902122498
Layer  5  loss:  0.12215122580528259 0.0 6.700525283813477
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([566, 268,  71, 289], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.2579072415828705
bi 1 loss 0.08593287318944931
bi 2 loss 0.03490406274795532
bi 3 loss 0.07051599025726318
Layer  6  loss:  0.1256607472896576 0.0 7.91883659362793
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([465, 267,  89, 282], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.2521093785762787
bi 1 loss 0.09363649040460587
bi 2 loss 0.026107272133231163
bi 3 loss 0.0794958621263504
Epoch 0: :   3%|▎         | 15082/600000 [00:35<22:41, v_num=12, reduced_train_loss=0.507, global_step=15080.0, consumed_samples=60324.0, train_step_timing in s=0.269]Epoch 0: :   3%|▎         | 15082/600000 [00:35<22:41, v_num=12, reduced_train_loss=0.951, global_step=15081.0, consumed_samples=60328.0, train_step_timing in s=0.430]loss mask original None

First layer loss:  3.6170735359191895 torch.Size([548, 4]) 12.886263847351074 0.0
Max loss timestep torch.Size([548, 4]) tensor([ 51, 149, 198, 399], device='cuda:0') tensor(208, device='cuda:0')
bi 0 loss 3.5693588256835938
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 1 loss 4.027042865753174
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 2 loss 3.30263352394104
speech mask sum tensor(419, device='cuda:0') loss mask sum tensor(419, device='cuda:0')
bi 3 loss 3.8048813343048096
speech mask sum tensor(344, device='cuda:0') loss mask sum tensor(344, device='cuda:0')
logits torch.Size([548, 4, 257024]) labels torch.Size([548, 4]) 0 257023
Layer  0  loss:  4.159402370452881 0.0 11.140528678894043
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([101, 184, 465, 400], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 4.052016735076904
bi 1 loss 4.526646137237549
bi 2 loss 3.6977109909057617
bi 3 loss 4.56663703918457
Layer  1  loss:  4.473837852478027 0.0 10.978391647338867
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([ 55, 162, 438, 273], device='cuda:0') tensor(110, device='cuda:0')
bi 0 loss 4.654748916625977
bi 1 loss 5.009725570678711
bi 2 loss 4.078165531158447
bi 3 loss 4.626379489898682
Layer  2  loss:  4.681251049041748 0.0 10.567023277282715
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([122, 113,  95, 293], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.607464790344238
bi 1 loss 5.078065395355225
bi 2 loss 4.374397277832031
bi 3 loss 4.874506950378418
Layer  3  loss:  4.7745256423950195 0.0 11.346795082092285
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 60, 209, 360, 260], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 4.746002674102783
bi 1 loss 5.190917015075684
bi 2 loss 4.287032604217529
bi 3 loss 5.1639723777771
Layer  4  loss:  4.964150428771973 0.0 10.848491668701172
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1021
Curr loss timestep torch.Size([548, 4]) tensor([ 53, 205, 184, 490], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 5.204489707946777
bi 1 loss 5.023040294647217
bi 2 loss 4.557825088500977
bi 3 loss 5.355575084686279
Layer  5  loss:  5.054978370666504 0.0 10.305549621582031
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([ 92, 188, 235, 259], device='cuda:0') tensor(117, device='cuda:0')
bi 0 loss 5.106631755828857
bi 1 loss 5.16990327835083
bi 2 loss 4.749518871307373
bi 3 loss 5.3524699211120605
Layer  6  loss:  5.041635036468506 0.0 10.975075721740723
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 94, 241, 455, 458], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 5.192346096038818
bi 1 loss 5.149547100067139
bi 2 loss 4.679486274719238
bi 3 loss 5.381528377532959
Epoch 0: :   3%|▎         | 15083/600000 [00:35<22:55, v_num=12, reduced_train_loss=0.951, global_step=15081.0, consumed_samples=60328.0, train_step_timing in s=0.430]Epoch 0: :   3%|▎         | 15083/600000 [00:35<22:55, v_num=12, reduced_train_loss=36.80, global_step=15082.0, consumed_samples=60332.0, train_step_timing in s=0.345]loss mask original None

First layer loss:  3.8956458568573 torch.Size([568, 4]) 12.307465553283691 0.0
Max loss timestep torch.Size([568, 4]) tensor([173, 184, 201, 374], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 3.798921585083008
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 1 loss 4.079273700714111
speech mask sum tensor(433, device='cuda:0') loss mask sum tensor(433, device='cuda:0')
bi 2 loss 4.083730697631836
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 3.6847479343414307
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
logits torch.Size([568, 4, 257024]) labels torch.Size([568, 4]) 0 257023
Layer  0  loss:  4.374447822570801 0.0 11.194883346557617
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([163, 421, 263, 489], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.3850274085998535
bi 1 loss 4.619153022766113
bi 2 loss 4.472637176513672
bi 3 loss 4.098320484161377
Layer  1  loss:  4.756120681762695 0.0 9.939689636230469
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([182, 335, 227, 471], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.721177101135254
bi 1 loss 5.054200172424316
bi 2 loss 4.46613883972168
bi 3 loss 4.558969020843506
Layer  2  loss:  4.870104789733887 0.0 11.042192459106445
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([162, 165, 222, 471], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.801106929779053
bi 1 loss 5.186826705932617
bi 2 loss 4.6185221672058105
bi 3 loss 4.652878761291504
Layer  3  loss:  4.983407974243164 0.0 9.74870491027832
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1020
Curr loss timestep torch.Size([568, 4]) tensor([206, 475, 201, 317], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.953407287597656
bi 1 loss 5.256863117218018
bi 2 loss 4.719998836517334
bi 3 loss 4.801130771636963
Layer  4  loss:  5.237415313720703 0.0 11.270955085754395
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([ 97, 381, 262, 140], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 5.1499457359313965
bi 1 loss 5.368439674377441
bi 2 loss 4.973733425140381
bi 3 loss 5.213809013366699
Layer  5  loss:  5.338151931762695 0.0 10.090347290039062
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([108, 260, 184, 262], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 5.115248680114746
bi 1 loss 5.5525126457214355
bi 2 loss 5.128113746643066
bi 3 loss 5.255798816680908
Layer  6  loss:  5.374209403991699 0.0 9.166696548461914
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([187, 471, 256, 381], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 5.091193199157715
bi 1 loss 5.635725498199463
bi 2 loss 5.1937642097473145
bi 3 loss 5.253922939300537
Epoch 0: :   3%|▎         | 15084/600000 [00:35<23:11, v_num=12, reduced_train_loss=36.80, global_step=15082.0, consumed_samples=60332.0, train_step_timing in s=0.345]Epoch 0: :   3%|▎         | 15084/600000 [00:35<23:11, v_num=12, reduced_train_loss=38.80, global_step=15083.0, consumed_samples=60336.0, train_step_timing in s=0.362]loss mask original None

First layer loss:  0.16069616377353668 torch.Size([559, 4]) 9.914165496826172 0.0
Max loss timestep torch.Size([559, 4]) tensor([400, 517, 355, 383], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.08785837888717651
speech mask sum tensor(293, device='cuda:0') loss mask sum tensor(293, device='cuda:0')
bi 1 loss 0.2023705393075943
speech mask sum tensor(406, device='cuda:0') loss mask sum tensor(406, device='cuda:0')
bi 2 loss 0.09753347188234329
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 3 loss 0.2021893858909607
speech mask sum tensor(376, device='cuda:0') loss mask sum tensor(376, device='cuda:0')
logits torch.Size([559, 4, 257024]) labels torch.Size([559, 4]) 0 257023
Layer  0  loss:  0.1980188935995102 0.0 16.41458511352539
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([400, 512, 355, 295], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.07884131371974945
bi 1 loss 0.2118980586528778
bi 2 loss 0.1268763244152069
bi 3 loss 0.3093920946121216
Layer  1  loss:  0.23590800166130066 0.0 15.906309127807617
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([399, 517, 355, 307], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.11993592977523804
bi 1 loss 0.24243126809597015
bi 2 loss 0.09873145818710327
bi 3 loss 0.38381126523017883
Layer  2  loss:  0.22492912411689758 0.0 18.460987091064453
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([400, 517, 269, 306], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.13996967673301697
bi 1 loss 0.18935728073120117
bi 2 loss 0.1104280948638916
bi 3 loss 0.38344496488571167
Layer  3  loss:  0.22493965923786163 0.0 13.88946533203125
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([400, 517, 355, 309], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.11630808562040329
bi 1 loss 0.22253181040287018
bi 2 loss 0.10989956557750702
bi 3 loss 0.36634576320648193
Layer  4  loss:  0.23275071382522583 0.0 19.475099563598633
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([400, 511, 355, 384], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.12381221354007721
bi 1 loss 0.24213740229606628
bi 2 loss 0.07609409093856812
bi 3 loss 0.3812512457370758
Layer  5  loss:  0.23509089648723602 0.0 16.164690017700195
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([280, 517, 260, 384], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.10537915676832199
bi 1 loss 0.2231532484292984
bi 2 loss 0.13608810305595398
bi 3 loss 0.39566463232040405
Layer  6  loss:  0.2719145119190216 0.0 19.87601089477539
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1020
Curr loss timestep torch.Size([559, 4]) tensor([290, 465, 355, 309], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.12966614961624146
bi 1 loss 0.2539275884628296
bi 2 loss 0.18630914390087128
bi 3 loss 0.44248268008232117
Epoch 0: :   3%|▎         | 15085/600000 [00:36<23:27, v_num=12, reduced_train_loss=38.80, global_step=15083.0, consumed_samples=60336.0, train_step_timing in s=0.362]Epoch 0: :   3%|▎         | 15085/600000 [00:36<23:27, v_num=12, reduced_train_loss=1.780, global_step=15084.0, consumed_samples=60340.0, train_step_timing in s=0.375]loss mask original None

First layer loss:  3.2869713306427 torch.Size([664, 4]) 11.000899314880371 0.0
Max loss timestep torch.Size([664, 4]) tensor([141, 379, 178, 124], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 3.3509223461151123
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 1 loss 3.404958486557007
speech mask sum tensor(365, device='cuda:0') loss mask sum tensor(365, device='cuda:0')
bi 2 loss 3.6327240467071533
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 3 loss 2.834653854370117
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
logits torch.Size([664, 4, 257024]) labels torch.Size([664, 4]) 0 257022
Layer  0  loss:  3.917013168334961 0.0 11.039996147155762
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([210, 349, 263, 295], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 3.690880060195923
bi 1 loss 4.172371864318848
bi 2 loss 4.232354164123535
bi 3 loss 3.458698034286499
Layer  1  loss:  4.222019195556641 0.0 10.406495094299316
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([209, 510, 344,  99], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.467563629150391
bi 1 loss 4.3261237144470215
bi 2 loss 4.686527729034424
bi 3 loss 3.602475643157959
Layer  2  loss:  4.472135543823242 0.0 10.025653839111328
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([172, 419, 329, 272], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 4.616036891937256
bi 1 loss 4.680971145629883
bi 2 loss 4.935170650482178
bi 3 loss 3.768920421600342
Layer  3  loss:  4.561824798583984 0.0 10.98746109008789
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1018
Curr loss timestep torch.Size([664, 4]) tensor([160, 306, 217, 105], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 4.666709899902344
bi 1 loss 4.768188953399658
bi 2 loss 5.104799747467041
bi 3 loss 3.8213939666748047
Layer  4  loss:  4.66071891784668 0.0 10.398140907287598
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([207, 428, 369, 108], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 4.764881134033203
bi 1 loss 4.818371295928955
bi 2 loss 5.186942100524902
bi 3 loss 3.997615098953247
Layer  5  loss:  4.73347806930542 0.0 10.68315315246582
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([179, 447, 242, 342], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 4.89916467666626
bi 1 loss 4.8917951583862305
bi 2 loss 5.1582818031311035
bi 3 loss 4.1145477294921875
Layer  6  loss:  4.75091028213501 0.0 10.457836151123047
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1021
Curr loss timestep torch.Size([664, 4]) tensor([153, 494, 217, 111], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 4.979706764221191
bi 1 loss 4.7707133293151855
bi 2 loss 5.353924751281738
bi 3 loss 4.14571475982666
Epoch 0: :   3%|▎         | 15086/600000 [00:36<23:44, v_num=12, reduced_train_loss=1.780, global_step=15084.0, consumed_samples=60340.0, train_step_timing in s=0.375]Epoch 0: :   3%|▎         | 15086/600000 [00:36<23:44, v_num=12, reduced_train_loss=34.60, global_step=15085.0, consumed_samples=60344.0, train_step_timing in s=0.401]loss mask original None

First layer loss:  0.20688651502132416 torch.Size([585, 4]) 12.75662612915039 0.0
Max loss timestep torch.Size([585, 4]) tensor([280, 350, 560, 530], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.13089922070503235
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 1 loss 0.2174212634563446
speech mask sum tensor(450, device='cuda:0') loss mask sum tensor(450, device='cuda:0')
bi 2 loss 0.194465771317482
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 3 loss 0.24841970205307007
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
logits torch.Size([585, 4, 257024]) labels torch.Size([585, 4]) 0 257022
Layer  0  loss:  0.1765204817056656 0.0 10.457023620605469
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([280, 427, 134, 502], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.2170168161392212
bi 1 loss 0.12694095075130463
bi 2 loss 0.1416006088256836
bi 3 loss 0.27386146783828735
Layer  1  loss:  0.20497791469097137 0.0 14.315985679626465
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([280, 429, 560, 502], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.17684245109558105
bi 1 loss 0.16280348598957062
bi 2 loss 0.2002452313899994
bi 3 loss 0.2820763885974884
Layer  2  loss:  0.2047566920518875 0.0 15.09680461883545
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([280, 428, 560, 502], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.22230683267116547
bi 1 loss 0.19222886860370636
bi 2 loss 0.15716631710529327
bi 3 loss 0.2824607491493225
Layer  3  loss:  0.20101940631866455 0.0 11.432887077331543
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([346, 429, 560, 502], device='cuda:0') tensor(502, device='cuda:0')
bi 0 loss 0.14628538489341736
bi 1 loss 0.14421972632408142
bi 2 loss 0.16350699961185455
bi 3 loss 0.3587028980255127
Layer  4  loss:  0.2193022221326828 0.0 15.142908096313477
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([280, 429, 560, 502], device='cuda:0') tensor(502, device='cuda:0')
bi 0 loss 0.22082698345184326
bi 1 loss 0.18454353511333466
bi 2 loss 0.19255846738815308
bi 3 loss 0.3040885329246521
Layer  5  loss:  0.22829535603523254 0.0 12.377187728881836
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([280, 429, 560, 505], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.14873643219470978
bi 1 loss 0.19909457862377167
bi 2 loss 0.199472114443779
bi 3 loss 0.3486425280570984
Layer  6  loss:  0.20871667563915253 0.0 11.259686470031738
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([267, 429, 560, 502], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.15551318228244781
bi 1 loss 0.14370818436145782
bi 2 loss 0.2083919793367386
bi 3 loss 0.3222053647041321
Epoch 0: :   3%|▎         | 15087/600000 [00:37<24:00, v_num=12, reduced_train_loss=34.60, global_step=15085.0, consumed_samples=60344.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15087/600000 [00:37<24:00, v_num=12, reduced_train_loss=1.650, global_step=15086.0, consumed_samples=60348.0, train_step_timing in s=0.399]loss mask original None

First layer loss:  0.2054654061794281 torch.Size([655, 4]) 12.942902565002441 0.0
Max loss timestep torch.Size([655, 4]) tensor([158, 443, 473, 403], device='cuda:0') tensor(443, device='cuda:0')
bi 0 loss 0.07688494026660919
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 1 loss 0.3485766351222992
speech mask sum tensor(465, device='cuda:0') loss mask sum tensor(465, device='cuda:0')
bi 2 loss 0.07543119788169861
speech mask sum tensor(353, device='cuda:0') loss mask sum tensor(353, device='cuda:0')
bi 3 loss 0.18823212385177612
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
logits torch.Size([655, 4, 257024]) labels torch.Size([655, 4]) 0 257023
Layer  0  loss:  0.28222063183784485 0.0 16.32828712463379
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([162, 443, 303, 304], device='cuda:0') tensor(443, device='cuda:0')
bi 0 loss 0.03661980852484703
bi 1 loss 0.43353599309921265
bi 2 loss 0.19458885490894318
bi 3 loss 0.2493279129266739
Layer  1  loss:  0.2820335030555725 0.0 15.986729621887207
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([131, 578, 303, 305], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.039917491376399994
bi 1 loss 0.44690826535224915
bi 2 loss 0.16731595993041992
bi 3 loss 0.26143527030944824
Layer  2  loss:  0.2959694266319275 0.0 17.336654663085938
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([191, 395, 302, 304], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.04551633819937706
bi 1 loss 0.4994157552719116
bi 2 loss 0.14886076748371124
bi 3 loss 0.25160855054855347
Layer  3  loss:  0.32397153973579407 0.0 18.31647300720215
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([181, 394, 303, 304], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.06017894670367241
bi 1 loss 0.5046294927597046
bi 2 loss 0.19664035737514496
bi 3 loss 0.3030725121498108
Layer  4  loss:  0.2959594130516052 0.0 13.500591278076172
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([187, 394, 473, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.04820530116558075
bi 1 loss 0.4481663405895233
bi 2 loss 0.18555253744125366
bi 3 loss 0.2977377772331238
Layer  5  loss:  0.3047315776348114 0.0 14.771463394165039
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([118, 394, 305, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.05167412385344505
bi 1 loss 0.47631174325942993
bi 2 loss 0.17434528470039368
bi 3 loss 0.3009554445743561
Layer  6  loss:  0.30626481771469116 0.0 15.617876052856445
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([142, 594, 305, 304], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.029727371409535408
bi 1 loss 0.5161857604980469
bi 2 loss 0.16317617893218994
bi 3 loss 0.2573477029800415
Epoch 0: :   3%|▎         | 15088/600000 [00:37<24:19, v_num=12, reduced_train_loss=1.650, global_step=15086.0, consumed_samples=60348.0, train_step_timing in s=0.399]Epoch 0: :   3%|▎         | 15088/600000 [00:37<24:19, v_num=12, reduced_train_loss=2.300, global_step=15087.0, consumed_samples=60352.0, train_step_timing in s=0.451]loss mask original None

First layer loss:  3.4760494232177734 torch.Size([584, 4]) 12.520147323608398 0.0
Max loss timestep torch.Size([584, 4]) tensor([226, 531,  82, 275], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 3.3526270389556885
speech mask sum tensor(300, device='cuda:0') loss mask sum tensor(300, device='cuda:0')
bi 1 loss 3.4565773010253906
speech mask sum tensor(363, device='cuda:0') loss mask sum tensor(363, device='cuda:0')
bi 2 loss 3.707434892654419
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 3.5091049671173096
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
logits torch.Size([584, 4, 257024]) labels torch.Size([584, 4]) 0 257021
Layer  0  loss:  4.040104389190674 0.0 10.0956449508667
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([170, 233,  78, 250], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 4.2660441398620605
bi 1 loss 4.144748210906982
bi 2 loss 4.020691394805908
bi 3 loss 3.7840609550476074
Layer  1  loss:  4.390836715698242 0.0 10.586204528808594
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([411, 524,  89, 372], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 4.260809898376465
bi 1 loss 4.527266979217529
bi 2 loss 4.498879909515381
bi 3 loss 4.329085826873779
Layer  2  loss:  4.71334981918335 0.0 10.61776065826416
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([163, 295, 162, 192], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 4.8144378662109375
bi 1 loss 4.641162872314453
bi 2 loss 5.155129432678223
bi 3 loss 4.557322025299072
Layer  3  loss:  4.884490966796875 0.0 10.743131637573242
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([287, 405, 124, 279], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 4.982567310333252
bi 1 loss 4.885988235473633
bi 2 loss 5.083917140960693
bi 3 loss 4.744317054748535
Layer  4  loss:  5.008213043212891 0.0 9.689058303833008
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([344, 426,  91, 311], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 4.958649635314941
bi 1 loss 5.070701599121094
bi 2 loss 5.00369119644165
bi 3 loss 4.9903154373168945
Layer  5  loss:  5.020867824554443 0.0 10.532796859741211
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([427, 398, 142, 151], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 5.057682514190674
bi 1 loss 5.0003533363342285
bi 2 loss 5.391182899475098
bi 3 loss 4.88972806930542
Layer  6  loss:  5.016802787780762 0.0 10.304889678955078
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([237, 343, 105, 307], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 5.051216125488281
bi 1 loss 5.1165385246276855
bi 2 loss 5.2486443519592285
bi 3 loss 4.824834823608398
Epoch 0: :   3%|▎         | 15089/600000 [00:38<24:34, v_num=12, reduced_train_loss=2.300, global_step=15087.0, consumed_samples=60352.0, train_step_timing in s=0.451]Epoch 0: :   3%|▎         | 15089/600000 [00:38<24:34, v_num=12, reduced_train_loss=36.60, global_step=15088.0, consumed_samples=60356.0, train_step_timing in s=0.364]loss mask original None

First layer loss:  0.188355952501297 torch.Size([653, 4]) 10.460467338562012 0.0
Max loss timestep torch.Size([653, 4]) tensor([407, 323, 332, 607], device='cuda:0') tensor(607, device='cuda:0')
bi 0 loss 0.10666192322969437
speech mask sum tensor(488, device='cuda:0') loss mask sum tensor(488, device='cuda:0')
bi 1 loss 0.11436916887760162
speech mask sum tensor(276, device='cuda:0') loss mask sum tensor(276, device='cuda:0')
bi 2 loss 0.13160440325737
speech mask sum tensor(383, device='cuda:0') loss mask sum tensor(383, device='cuda:0')
bi 3 loss 0.3918865919113159
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
logits torch.Size([653, 4, 257024]) labels torch.Size([653, 4]) 0 257023
Layer  0  loss:  0.2688785195350647 0.0 10.779729843139648
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([553, 323, 333, 354], device='cuda:0') tensor(462, device='cuda:0')
bi 0 loss 0.14995430409908295
bi 1 loss 0.10911213606595993
bi 2 loss 0.31407949328422546
bi 3 loss 0.47934651374816895
Layer  1  loss:  0.2622253894805908 0.0 12.173468589782715
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([554, 322, 332, 594], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.1434592753648758
bi 1 loss 0.1670530140399933
bi 2 loss 0.25348541140556335
bi 3 loss 0.4795277714729309
Layer  2  loss:  0.27187487483024597 0.0 11.727717399597168
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([553, 323, 333, 354], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.1643267422914505
bi 1 loss 0.1379963904619217
bi 2 loss 0.2948634624481201
bi 3 loss 0.47194766998291016
Layer  3  loss:  0.2936587333679199 0.0 15.164338111877441
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1021
Curr loss timestep torch.Size([653, 4]) tensor([553, 322, 332, 606], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.14667673408985138
bi 1 loss 0.17123225331306458
bi 2 loss 0.2566840350627899
bi 3 loss 0.5906269550323486
Layer  4  loss:  0.2936317026615143 0.0 14.279868125915527
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([554, 323, 333, 594], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.18047116696834564
bi 1 loss 0.14724287390708923
bi 2 loss 0.2729073762893677
bi 3 loss 0.5506119728088379
Layer  5  loss:  0.3033955991268158 0.0 18.854846954345703
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([361, 322, 333, 354], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.13174748420715332
bi 1 loss 0.20389123260974884
bi 2 loss 0.36395901441574097
bi 3 loss 0.521836519241333
Layer  6  loss:  0.2836121618747711 0.0 13.969680786132812
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([540, 322, 333, 606], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.16054180264472961
bi 1 loss 0.15508028864860535
bi 2 loss 0.324860543012619
bi 3 loss 0.48146578669548035
Epoch 0: :   3%|▎         | 15090/600000 [00:38<24:53, v_num=12, reduced_train_loss=36.60, global_step=15088.0, consumed_samples=60356.0, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15090/600000 [00:38<24:53, v_num=12, reduced_train_loss=2.170, global_step=15089.0, consumed_samples=60360.0, train_step_timing in s=0.440]loss mask original None

First layer loss:  0.053024522960186005 torch.Size([465, 4]) 4.248711585998535 0.0
Max loss timestep torch.Size([465, 4]) tensor([167, 309, 328, 169], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.024992013350129128
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 1 loss 0.09853459894657135
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 2 loss 0.03714919835329056
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
bi 3 loss 0.047375522553920746
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
logits torch.Size([465, 4, 257024]) labels torch.Size([465, 4]) 0 257022
Layer  0  loss:  0.05221713334321976 0.0 2.6583895683288574
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([124, 431, 305, 240], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.018543079495429993
bi 1 loss 0.07188065350055695
bi 2 loss 0.05249419063329697
bi 3 loss 0.057667072862386703
Layer  1  loss:  0.05931247025728226 0.0 3.226562023162842
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([105, 381, 269, 252], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 0.016123821958899498
bi 1 loss 0.10702760517597198
bi 2 loss 0.04908318445086479
bi 3 loss 0.054362114518880844
Layer  2  loss:  0.07181808352470398 0.0 4.363565444946289
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([128, 317, 303, 284], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.029729729518294334
bi 1 loss 0.14243856072425842
bi 2 loss 0.043765511363744736
bi 3 loss 0.06904392689466476
Layer  3  loss:  0.059253424406051636 0.0 2.5681796073913574
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1020
Curr loss timestep torch.Size([465, 4]) tensor([ 79, 379, 328, 218], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.023805569857358932
bi 1 loss 0.0993904247879982
bi 2 loss 0.04751837998628616
bi 3 loss 0.06102718040347099
Layer  4  loss:  0.0697990134358406 0.0 2.5930333137512207
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([ 84, 380, 276, 160], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.03085251711308956
bi 1 loss 0.11739031225442886
bi 2 loss 0.06355662643909454
bi 3 loss 0.051600974053144455
Layer  5  loss:  0.05755859240889549 0.0 4.0303544998168945
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1019
Curr loss timestep torch.Size([465, 4]) tensor([135, 323, 328, 220], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.03280327469110489
bi 1 loss 0.10579133033752441
bi 2 loss 0.04263928905129433
bi 3 loss 0.041939206421375275
Layer  6  loss:  0.07371868938207626 0.0 5.346116542816162
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([156, 379, 328, 236], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.024133585393428802
bi 1 loss 0.13307107985019684
bi 2 loss 0.07085435837507248
bi 3 loss 0.041281960904598236
Epoch 0: :   3%|▎         | 15091/600000 [00:38<25:07, v_num=12, reduced_train_loss=2.170, global_step=15089.0, consumed_samples=60360.0, train_step_timing in s=0.440]Epoch 0: :   3%|▎         | 15091/600000 [00:38<25:07, v_num=12, reduced_train_loss=0.497, global_step=15090.0, consumed_samples=60364.0, train_step_timing in s=0.329]loss mask original None

First layer loss:  3.553568124771118 torch.Size([616, 4]) 10.8919677734375 0.0
Max loss timestep torch.Size([616, 4]) tensor([289, 160, 404, 210], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 3.9763522148132324
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 1 loss 3.0786845684051514
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
bi 2 loss 3.256209373474121
speech mask sum tensor(465, device='cuda:0') loss mask sum tensor(465, device='cuda:0')
bi 3 loss 3.8380701541900635
speech mask sum tensor(469, device='cuda:0') loss mask sum tensor(469, device='cuda:0')
logits torch.Size([616, 4, 257024]) labels torch.Size([616, 4]) 0 257023
Layer  0  loss:  4.089321613311768 0.0 11.097810745239258
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([183, 182, 277, 394], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 4.557265281677246
bi 1 loss 3.6756067276000977
bi 2 loss 3.704906940460205
bi 3 loss 4.415374279022217
Layer  1  loss:  4.406149864196777 0.0 10.195646286010742
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([177, 256, 464, 488], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 4.976831436157227
bi 1 loss 4.451088905334473
bi 2 loss 3.9052212238311768
bi 3 loss 4.621223449707031
Layer  2  loss:  4.71126127243042 0.0 11.052199363708496
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([248, 242, 399, 320], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 5.3206377029418945
bi 1 loss 4.668208122253418
bi 2 loss 4.167812824249268
bi 3 loss 4.984922409057617
Layer  3  loss:  4.799931049346924 0.0 10.6344633102417
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([232, 193, 223, 187], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 5.4888763427734375
bi 1 loss 4.791982173919678
bi 2 loss 4.2285261154174805
bi 3 loss 5.050797939300537
Layer  4  loss:  4.917527675628662 0.0 10.367634773254395
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([233, 164, 160, 542], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 5.517878532409668
bi 1 loss 4.9017109870910645
bi 2 loss 4.300711631774902
bi 3 loss 5.257478713989258
Layer  5  loss:  4.9914655685424805 0.0 9.582796096801758
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([295, 254, 235, 226], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 5.7427239418029785
bi 1 loss 5.029813289642334
bi 2 loss 4.323439121246338
bi 3 loss 5.291234970092773
Layer  6  loss:  5.059189796447754 0.0 12.556504249572754
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([215, 280, 441, 386], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 5.819233417510986
bi 1 loss 5.082099437713623
bi 2 loss 4.40403413772583
bi 3 loss 5.348156929016113
Epoch 0: :   3%|▎         | 15092/600000 [00:39<25:23, v_num=12, reduced_train_loss=0.497, global_step=15090.0, consumed_samples=60364.0, train_step_timing in s=0.329]Epoch 0: :   3%|▎         | 15092/600000 [00:39<25:23, v_num=12, reduced_train_loss=36.50, global_step=15091.0, consumed_samples=60368.0, train_step_timing in s=0.376]loss mask original None

First layer loss:  3.890385627746582 torch.Size([560, 4]) 11.921807289123535 0.0
Max loss timestep torch.Size([560, 4]) tensor([534, 161, 188, 293], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 4.1587324142456055
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
bi 1 loss 3.9846715927124023
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 2 loss 3.1112043857574463
speech mask sum tensor(212, device='cuda:0') loss mask sum tensor(212, device='cuda:0')
bi 3 loss 4.018887996673584
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
logits torch.Size([560, 4, 257024]) labels torch.Size([560, 4]) 0 257022
Layer  0  loss:  4.528835296630859 0.0 11.216388702392578
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([541, 297, 154, 271], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 4.703014373779297
bi 1 loss 4.389096260070801
bi 2 loss 4.023773193359375
bi 3 loss 4.816965103149414
Layer  1  loss:  4.853014945983887 0.0 11.877030372619629
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([275, 166, 190, 288], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 4.991832256317139
bi 1 loss 4.703061103820801
bi 2 loss 4.551495552062988
bi 3 loss 5.045585632324219
Layer  2  loss:  4.951953887939453 0.0 10.698873519897461
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([470, 326, 211, 366], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 5.153074264526367
bi 1 loss 4.768446445465088
bi 2 loss 4.7051262855529785
bi 3 loss 5.052610397338867
Layer  3  loss:  5.079441070556641 0.0 10.36436939239502
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1019
Curr loss timestep torch.Size([560, 4]) tensor([433, 133, 125, 486], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 5.269925117492676
bi 1 loss 4.917038917541504
bi 2 loss 4.786513328552246
bi 3 loss 5.207917213439941
Layer  4  loss:  5.221831321716309 0.0 10.907424926757812
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([407, 125, 158, 487], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 5.437862873077393
bi 1 loss 5.023568153381348
bi 2 loss 4.831949710845947
bi 3 loss 5.4255828857421875
Layer  5  loss:  5.309723854064941 0.0 11.44404411315918
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([492, 354, 214, 436], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 5.6446146965026855
bi 1 loss 4.969386100769043
bi 2 loss 5.097405433654785
bi 3 loss 5.362419128417969
Layer  6  loss:  5.417410850524902 0.0 11.256820678710938
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([420, 312, 111, 345], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 5.598824977874756
bi 1 loss 5.218919277191162
bi 2 loss 5.186625957489014
bi 3 loss 5.548040390014648
Epoch 0: :   3%|▎         | 15093/600000 [00:39<25:37, v_num=12, reduced_train_loss=36.50, global_step=15091.0, consumed_samples=60368.0, train_step_timing in s=0.376]Epoch 0: :   3%|▎         | 15093/600000 [00:39<25:37, v_num=12, reduced_train_loss=39.30, global_step=15092.0, consumed_samples=60372.0, train_step_timing in s=0.347]loss mask original None

First layer loss:  3.8519840240478516 torch.Size([488, 4]) 10.362419128417969 0.0
Max loss timestep torch.Size([488, 4]) tensor([168, 186, 161, 148], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.171081066131592
speech mask sum tensor(329, device='cuda:0') loss mask sum tensor(329, device='cuda:0')
bi 1 loss 3.20807147026062
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 2 loss 3.3919179439544678
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 3 loss 3.9975802898406982
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257023
Layer  0  loss:  4.469717979431152 0.0 10.799792289733887
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([185, 222, 190, 224], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.972236633300781
bi 1 loss 3.6703178882598877
bi 2 loss 4.03462028503418
bi 3 loss 4.4355034828186035
Layer  1  loss:  4.689849376678467 0.0 10.895758628845215
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([190, 232, 177, 153], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 5.219161033630371
bi 1 loss 3.8914239406585693
bi 2 loss 4.256261825561523
bi 3 loss 4.620288372039795
Layer  2  loss:  4.877660751342773 0.0 10.225911140441895
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([285, 238, 192, 313], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 5.361217021942139
bi 1 loss 3.9174749851226807
bi 2 loss 4.6862006187438965
bi 3 loss 4.794698238372803
Layer  3  loss:  4.989992618560791 0.0 10.333237648010254
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([332, 224, 269, 194], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 5.424556255340576
bi 1 loss 4.114300727844238
bi 2 loss 4.863806247711182
bi 3 loss 4.894095420837402
Layer  4  loss:  5.167255878448486 0.0 10.390861511230469
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([203, 235, 140, 356], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 5.657218933105469
bi 1 loss 4.5872273445129395
bi 2 loss 4.871519088745117
bi 3 loss 4.971495151519775
Layer  5  loss:  5.2590765953063965 0.0 10.308362007141113
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1019
Curr loss timestep torch.Size([488, 4]) tensor([359, 215, 233, 328], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 5.81429386138916
bi 1 loss 4.434809684753418
bi 2 loss 4.98446798324585
bi 3 loss 5.074581623077393
Layer  6  loss:  5.280485153198242 0.0 10.12399673461914
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([238, 236, 219, 250], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 5.737684726715088
bi 1 loss 4.240442752838135
bi 2 loss 5.132355690002441
bi 3 loss 5.240414619445801
Epoch 0: :   3%|▎         | 15094/600000 [00:40<25:51, v_num=12, reduced_train_loss=39.30, global_step=15092.0, consumed_samples=60372.0, train_step_timing in s=0.347]Epoch 0: :   3%|▎         | 15094/600000 [00:40<25:51, v_num=12, reduced_train_loss=38.60, global_step=15093.0, consumed_samples=60376.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.08025176078081131 torch.Size([433, 4]) 10.35124683380127 0.0
Max loss timestep torch.Size([433, 4]) tensor([127, 410, 352, 285], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.037367865443229675
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 1 loss 0.06126898527145386
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 2 loss 0.06911083310842514
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 3 loss 0.12339989840984344
speech mask sum tensor(342, device='cuda:0') loss mask sum tensor(342, device='cuda:0')
logits torch.Size([433, 4, 257024]) labels torch.Size([433, 4]) 0 257023
Layer  0  loss:  0.10056425631046295 0.0 15.445671081542969
logits torch.Size([433, 4, 1024]) labels torch.Size([433, 4]) 0 1023
Curr loss timestep torch.Size([433, 4]) tensor([ 96, 355, 381, 283], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.04290119558572769
bi 1 loss 0.08134030550718307
bi 2 loss 0.08603676408529282
bi 3 loss 0.15427348017692566
Layer  1  loss:  0.10465356707572937 0.0 13.973631858825684
logits torch.Size([433, 4, 1024]) labels torch.Size([433, 4]) 0 1023
Curr loss timestep torch.Size([433, 4]) tensor([196, 335, 380, 285], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.03602670878171921
bi 1 loss 0.052214521914720535
bi 2 loss 0.08604872971773148
bi 3 loss 0.1882343888282776
Layer  2  loss:  0.1061772033572197 0.0 8.00210952758789
logits torch.Size([433, 4, 1024]) labels torch.Size([433, 4]) 0 1023
Curr loss timestep torch.Size([433, 4]) tensor([122, 303, 369, 284], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.05821160599589348
bi 1 loss 0.0927167609333992
bi 2 loss 0.1101941466331482
bi 3 loss 0.13818450272083282
Layer  3  loss:  0.09066417813301086 0.0 12.687830924987793
logits torch.Size([433, 4, 1024]) labels torch.Size([433, 4]) 0 1023
Curr loss timestep torch.Size([433, 4]) tensor([192, 224, 381, 284], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.03201859071850777
bi 1 loss 0.05678800493478775
bi 2 loss 0.08313288539648056
bi 3 loss 0.14940015971660614
Layer  4  loss:  0.09033696353435516 0.0 8.583011627197266
logits torch.Size([433, 4, 1024]) labels torch.Size([433, 4]) 0 1022
Curr loss timestep torch.Size([433, 4]) tensor([117, 247, 381, 284], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.05305696651339531
bi 1 loss 0.07147067040205002
bi 2 loss 0.09743210673332214
bi 3 loss 0.11781645566225052
Layer  5  loss:  0.10064902901649475 0.0 13.713900566101074
logits torch.Size([433, 4, 1024]) labels torch.Size([433, 4]) 0 1018
Curr loss timestep torch.Size([433, 4]) tensor([146, 262, 381, 284], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.05717231705784798
bi 1 loss 0.05323706194758415
bi 2 loss 0.12281633913516998
bi 3 loss 0.1392725110054016
Layer  6  loss:  0.11164428293704987 0.0 15.90821361541748
logits torch.Size([433, 4, 1024]) labels torch.Size([433, 4]) 0 1022
Curr loss timestep torch.Size([433, 4]) tensor([159, 377, 335, 283], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.045878730714321136
bi 1 loss 0.05978865548968315
bi 2 loss 0.07387152314186096
bi 3 loss 0.20646129548549652
Epoch 0: :   3%|▎         | 15095/600000 [00:40<26:05, v_num=12, reduced_train_loss=38.60, global_step=15093.0, consumed_samples=60376.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15095/600000 [00:40<26:05, v_num=12, reduced_train_loss=0.785, global_step=15094.0, consumed_samples=60380.0, train_step_timing in s=0.314]loss mask original None

First layer loss:  3.638413906097412 torch.Size([468, 4]) 11.325376510620117 0.0
Max loss timestep torch.Size([468, 4]) tensor([422, 173,  60, 323], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 3.358274221420288
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 1 loss 3.895510196685791
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 2 loss 3.3148691654205322
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 3 loss 3.853228807449341
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
logits torch.Size([468, 4, 257024]) labels torch.Size([468, 4]) 0 257022
Layer  0  loss:  4.24410343170166 0.0 11.093867301940918
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([256, 396, 130, 366], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 4.1109113693237305
bi 1 loss 4.574524402618408
bi 2 loss 3.8863587379455566
bi 3 loss 4.233199596405029
Layer  1  loss:  4.6847004890441895 0.0 10.55075454711914
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([397, 214, 142, 237], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 4.680234432220459
bi 1 loss 4.831944465637207
bi 2 loss 4.4544358253479
bi 3 loss 4.69831657409668
Layer  2  loss:  4.895813941955566 0.0 10.45939826965332
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([372, 449, 265, 303], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 4.963865280151367
bi 1 loss 4.974079608917236
bi 2 loss 4.671476364135742
bi 3 loss 4.938195705413818
Layer  3  loss:  5.00593900680542 0.0 9.980863571166992
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([383, 239, 171, 268], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 4.986689567565918
bi 1 loss 5.167356491088867
bi 2 loss 4.6219940185546875
bi 3 loss 5.17141580581665
Layer  4  loss:  5.1098809242248535 0.0 10.15874195098877
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([342, 192, 192, 228], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 5.030594825744629
bi 1 loss 5.223609924316406
bi 2 loss 4.8187665939331055
bi 3 loss 5.313525676727295
Layer  5  loss:  5.2025604248046875 0.0 9.343554496765137
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([349,  92, 173, 269], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 5.076084136962891
bi 1 loss 5.271841526031494
bi 2 loss 4.933928489685059
bi 3 loss 5.49933385848999
Layer  6  loss:  5.262861728668213 0.0 10.084059715270996
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1021
Curr loss timestep torch.Size([468, 4]) tensor([318, 235, 270, 244], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 5.135538578033447
bi 1 loss 5.347568035125732
bi 2 loss 5.027104377746582
bi 3 loss 5.502412796020508
Epoch 0: :   3%|▎         | 15096/600000 [00:40<26:18, v_num=12, reduced_train_loss=0.785, global_step=15094.0, consumed_samples=60380.0, train_step_timing in s=0.314]Epoch 0: :   3%|▎         | 15096/600000 [00:40<26:18, v_num=12, reduced_train_loss=38.00, global_step=15095.0, consumed_samples=60384.0, train_step_timing in s=0.317]loss mask original None

First layer loss:  0.0820976123213768 torch.Size([603, 4]) 7.737043857574463 0.0
Max loss timestep torch.Size([603, 4]) tensor([132, 184, 517, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.015654871240258217
speech mask sum tensor(56, device='cuda:0') loss mask sum tensor(56, device='cuda:0')
bi 1 loss 0.02611023560166359
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 2 loss 0.08018352836370468
speech mask sum tensor(503, device='cuda:0') loss mask sum tensor(503, device='cuda:0')
bi 3 loss 0.14057588577270508
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
logits torch.Size([603, 4, 257024]) labels torch.Size([603, 4]) 0 257023
Layer  0  loss:  0.06793839484453201 0.0 3.8821518421173096
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([129, 176, 428, 328], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.031489286571741104
bi 1 loss 0.02713628299534321
bi 2 loss 0.08102178573608398
bi 3 loss 0.07390568405389786
Layer  1  loss:  0.07460349053144455 0.0 6.679015159606934
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([131, 155, 521, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.0186784565448761
bi 1 loss 0.03444678336381912
bi 2 loss 0.07744255661964417
bi 3 loss 0.10891762375831604
Layer  2  loss:  0.07717578113079071 0.0 3.3622443675994873
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([125, 128, 403, 385], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.015333919785916805
bi 1 loss 0.03717496246099472
bi 2 loss 0.09305257350206375
bi 3 loss 0.08269304037094116
Layer  3  loss:  0.0922895148396492 0.0 11.283157348632812
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([133, 151, 403, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.02304057404398918
bi 1 loss 0.04557785019278526
bi 2 loss 0.09973050653934479
bi 3 loss 0.12369454652070999
Layer  4  loss:  0.07622797787189484 0.0 4.329078674316406
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([147, 193, 314, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.03684787079691887
bi 1 loss 0.022820372134447098
bi 2 loss 0.08605828136205673
bi 3 loss 0.09879910945892334
Layer  5  loss:  0.07050090283155441 0.0 4.405602931976318
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([132, 202, 521, 334], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.009406591765582561
bi 1 loss 0.03740903362631798
bi 2 loss 0.08336678147315979
bi 3 loss 0.07825153321027756
Layer  6  loss:  0.07178845256567001 0.0 3.0446860790252686
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([134, 189, 522, 339], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.04470636695623398
bi 1 loss 0.03838536515831947
bi 2 loss 0.08312727510929108
bi 3 loss 0.07450643181800842
Epoch 0: :   3%|▎         | 15097/600000 [00:41<26:35, v_num=12, reduced_train_loss=38.00, global_step=15095.0, consumed_samples=60384.0, train_step_timing in s=0.317]Epoch 0: :   3%|▎         | 15097/600000 [00:41<26:35, v_num=12, reduced_train_loss=0.613, global_step=15096.0, consumed_samples=60388.0, train_step_timing in s=0.407]loss mask original None

First layer loss:  0.11603578925132751 torch.Size([575, 4]) 9.646690368652344 0.0
Max loss timestep torch.Size([575, 4]) tensor([340, 369, 544, 315], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.1234479546546936
speech mask sum tensor(467, device='cuda:0') loss mask sum tensor(467, device='cuda:0')
bi 1 loss 0.10367055982351303
speech mask sum tensor(402, device='cuda:0') loss mask sum tensor(402, device='cuda:0')
bi 2 loss 0.14160609245300293
speech mask sum tensor(454, device='cuda:0') loss mask sum tensor(454, device='cuda:0')
bi 3 loss 0.07611649483442307
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
logits torch.Size([575, 4, 257024]) labels torch.Size([575, 4]) 0 257023
Layer  0  loss:  0.12750840187072754 0.0 10.37510871887207
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([538, 368, 544, 363], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.12445303052663803
bi 1 loss 0.1211656853556633
bi 2 loss 0.15768937766551971
bi 3 loss 0.08906753361225128
Layer  1  loss:  0.1268903911113739 0.0 12.548799514770508
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([531, 368, 544, 363], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.1275438368320465
bi 1 loss 0.1528332233428955
bi 2 loss 0.12631943821907043
bi 3 loss 0.08548733592033386
Layer  2  loss:  0.14157046377658844 0.0 12.207176208496094
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([373, 369, 533, 363], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.14284063875675201
bi 1 loss 0.1322600394487381
bi 2 loss 0.16925695538520813
bi 3 loss 0.10433705151081085
Layer  3  loss:  0.14720088243484497 0.0 14.422890663146973
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([389, 368, 533, 363], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.15245848894119263
bi 1 loss 0.15024520456790924
bi 2 loss 0.16643494367599487
bi 3 loss 0.09814400970935822
Layer  4  loss:  0.12655262649059296 0.0 14.05345630645752
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([532, 369, 533, 363], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.11632832139730453
bi 1 loss 0.14068767428398132
bi 2 loss 0.13280142843723297
bi 3 loss 0.1117522194981575
Layer  5  loss:  0.1275559812784195 0.0 9.610481262207031
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1018
Curr loss timestep torch.Size([575, 4]) tensor([132, 369, 544, 347], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.14541152119636536
bi 1 loss 0.1425582766532898
bi 2 loss 0.1215360015630722
bi 3 loss 0.08156229555606842
Layer  6  loss:  0.13971883058547974 0.0 14.187419891357422
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([265, 368, 533, 289], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.13856063783168793
bi 1 loss 0.15909752249717712
bi 2 loss 0.16944898664951324
bi 3 loss 0.057715434581041336
Epoch 0: :   3%|▎         | 15098/600000 [00:41<26:52, v_num=12, reduced_train_loss=0.613, global_step=15096.0, consumed_samples=60388.0, train_step_timing in s=0.407]Epoch 0: :   3%|▎         | 15098/600000 [00:41<26:52, v_num=12, reduced_train_loss=1.050, global_step=15097.0, consumed_samples=60392.0, train_step_timing in s=0.393]loss mask original None

First layer loss:  3.7040393352508545 torch.Size([320, 4]) 11.242779731750488 0.0
Max loss timestep torch.Size([320, 4]) tensor([177, 116, 200, 107], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 3.8890068531036377
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 1 loss 4.0265302658081055
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
bi 2 loss 2.5655393600463867
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 3 loss 3.3229362964630127
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
logits torch.Size([320, 4, 257024]) labels torch.Size([320, 4]) 0 257023
Layer  0  loss:  4.152839183807373 0.0 10.46621322631836
logits torch.Size([320, 4, 1024]) labels torch.Size([320, 4]) 0 1023
Curr loss timestep torch.Size([320, 4]) tensor([250, 127, 216, 107], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.313719749450684
bi 1 loss 4.377024173736572
bi 2 loss 3.002995252609253
bi 3 loss 4.122241973876953
Layer  1  loss:  4.471722602844238 0.0 9.764768600463867
logits torch.Size([320, 4, 1024]) labels torch.Size([320, 4]) 0 1023
Curr loss timestep torch.Size([320, 4]) tensor([211, 207, 217,  96], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.691746234893799
bi 1 loss 4.755415916442871
bi 2 loss 3.170464277267456
bi 3 loss 4.220534801483154
Layer  2  loss:  4.747745990753174 0.0 9.586499214172363
logits torch.Size([320, 4, 1024]) labels torch.Size([320, 4]) 0 1022
Curr loss timestep torch.Size([320, 4]) tensor([123, 266, 210, 131], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 4.968508720397949
bi 1 loss 5.042483329772949
bi 2 loss 3.2283213138580322
bi 3 loss 4.680965900421143
Layer  3  loss:  4.8334245681762695 0.0 9.217551231384277
logits torch.Size([320, 4, 1024]) labels torch.Size([320, 4]) 0 1022
Curr loss timestep torch.Size([320, 4]) tensor([279, 129, 222,  97], device='cuda:0') tensor(113, device='cuda:0')
bi 0 loss 5.126461982727051
bi 1 loss 4.988908767700195
bi 2 loss 3.4190163612365723
bi 3 loss 4.750721454620361
Layer  4  loss:  5.0198073387146 0.0 9.10993766784668
logits torch.Size([320, 4, 1024]) labels torch.Size([320, 4]) 0 1022
Curr loss timestep torch.Size([320, 4]) tensor([192, 226, 205, 111], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 5.368326187133789
bi 1 loss 5.196385860443115
bi 2 loss 3.5185234546661377
bi 3 loss 4.764190673828125
Layer  5  loss:  5.065250396728516 0.0 9.328142166137695
logits torch.Size([320, 4, 1024]) labels torch.Size([320, 4]) 0 1020
Curr loss timestep torch.Size([320, 4]) tensor([128, 227, 221, 117], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 5.337401866912842
bi 1 loss 5.195816993713379
bi 2 loss 3.693965196609497
bi 3 loss 5.080596446990967
Layer  6  loss:  5.061481475830078 0.0 10.22513198852539
logits torch.Size([320, 4, 1024]) labels torch.Size([320, 4]) 0 1019
Curr loss timestep torch.Size([320, 4]) tensor([284, 247, 235, 100], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 5.364628314971924
bi 1 loss 5.231752395629883
bi 2 loss 3.6164138317108154
bi 3 loss 4.934033393859863
Epoch 0: :   3%|▎         | 15099/600000 [00:41<27:04, v_num=12, reduced_train_loss=1.050, global_step=15097.0, consumed_samples=60392.0, train_step_timing in s=0.393]Epoch 0: :   3%|▎         | 15099/600000 [00:41<27:04, v_num=12, reduced_train_loss=37.10, global_step=15098.0, consumed_samples=60396.0, train_step_timing in s=0.276]loss mask original None

First layer loss:  0.035424768924713135 torch.Size([367, 4]) 1.7380073070526123 0.0
Max loss timestep torch.Size([367, 4]) tensor([240, 224, 294, 181], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 0.03662022203207016
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 1 loss 0.013257689774036407
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 2 loss 0.03344883769750595
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 3 loss 0.04458903521299362
speech mask sum tensor(212, device='cuda:0') loss mask sum tensor(212, device='cuda:0')
logits torch.Size([367, 4, 257024]) labels torch.Size([367, 4]) 0 257023
Layer  0  loss:  0.053868554532527924 0.0 2.893472909927368
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1023
Curr loss timestep torch.Size([367, 4]) tensor([268, 223, 334, 304], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.05431682616472244
bi 1 loss 0.02258160710334778
bi 2 loss 0.037040580064058304
bi 3 loss 0.07719437032938004
Layer  1  loss:  0.05764136463403702 0.0 4.672725677490234
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1022
Curr loss timestep torch.Size([367, 4]) tensor([267, 193, 290, 303], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.07180223613977432
bi 1 loss 0.013819720596075058
bi 2 loss 0.05291345715522766
bi 3 loss 0.0688074380159378
Layer  2  loss:  0.06712857633829117 0.0 5.218058109283447
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1023
Curr loss timestep torch.Size([367, 4]) tensor([267, 197, 293, 304], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.06943221390247345
bi 1 loss 0.03262517973780632
bi 2 loss 0.04964588209986687
bi 3 loss 0.09096478670835495
Layer  3  loss:  0.0811922699213028 0.0 11.160917282104492
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1017
Curr loss timestep torch.Size([367, 4]) tensor([267, 193, 233, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.10585907846689224
bi 1 loss 0.030913155525922775
bi 2 loss 0.032020654529333115
bi 3 loss 0.11856374889612198
Layer  4  loss:  0.07497743517160416 0.0 9.659807205200195
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1023
Curr loss timestep torch.Size([367, 4]) tensor([267, 189, 336, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.08745855838060379
bi 1 loss 0.017155440524220467
bi 2 loss 0.03738672286272049
bi 3 loss 0.1151052936911583
Layer  5  loss:  0.059013672173023224 0.0 10.333675384521484
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1022
Curr loss timestep torch.Size([367, 4]) tensor([268, 221, 339, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.07543918490409851
bi 1 loss 0.017628416419029236
bi 2 loss 0.03394408896565437
bi 3 loss 0.08170820027589798
Layer  6  loss:  0.07728219777345657 0.0 7.397046089172363
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1022
Curr loss timestep torch.Size([367, 4]) tensor([267, 223, 276, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.08819923549890518
bi 1 loss 0.023427072912454605
bi 2 loss 0.04274386167526245
bi 3 loss 0.11478398740291595
Epoch 0: :   3%|▎         | 15100/600000 [00:42<27:16, v_num=12, reduced_train_loss=37.10, global_step=15098.0, consumed_samples=60396.0, train_step_timing in s=0.276]Epoch 0: :   3%|▎         | 15100/600000 [00:42<27:16, v_num=12, reduced_train_loss=0.507, global_step=15099.0, consumed_samples=60400.0, train_step_timing in s=0.278]loss mask original None

First layer loss:  0.028475821018218994 torch.Size([362, 4]) 0.7522130608558655 0.0
Max loss timestep torch.Size([362, 4]) tensor([283,  55, 141, 133], device='cuda:0') tensor(141, device='cuda:0')
bi 0 loss 0.030405636876821518
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 1 loss 0.02160451002418995
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 2 loss 0.03016902133822441
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 3 loss 0.026722121983766556
speech mask sum tensor(234, device='cuda:0') loss mask sum tensor(234, device='cuda:0')
logits torch.Size([362, 4, 257024]) labels torch.Size([362, 4]) 0 257022
Layer  0  loss:  0.028185324743390083 0.0 0.9984155893325806
logits torch.Size([362, 4, 1024]) labels torch.Size([362, 4]) 0 1023
Curr loss timestep torch.Size([362, 4]) tensor([282,  57, 223, 114], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 0.03214734047651291
bi 1 loss 0.015973148867487907
bi 2 loss 0.028040926903486252
bi 3 loss 0.0272503811866045
Layer  1  loss:  0.024284718558192253 0.0 0.3838118016719818
logits torch.Size([362, 4, 1024]) labels torch.Size([362, 4]) 0 1023
Curr loss timestep torch.Size([362, 4]) tensor([344,  55,  97, 173], device='cuda:0') tensor(97, device='cuda:0')
bi 0 loss 0.023852651938796043
bi 1 loss 0.019608676433563232
bi 2 loss 0.025407524779438972
bi 3 loss 0.025288330391049385
Layer  2  loss:  0.025524530559778214 0.0 0.8622815012931824
logits torch.Size([362, 4, 1024]) labels torch.Size([362, 4]) 0 1023
Curr loss timestep torch.Size([362, 4]) tensor([344,  58, 201, 110], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.030050475150346756
bi 1 loss 0.012875810265541077
bi 2 loss 0.027803950011730194
bi 3 loss 0.021840760484337807
Layer  3  loss:  0.02596897818148136 0.0 0.6075718402862549
logits torch.Size([362, 4, 1024]) labels torch.Size([362, 4]) 0 1023
Curr loss timestep torch.Size([362, 4]) tensor([339,  77, 256, 281], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.027140213176608086
bi 1 loss 0.019635509699583054
bi 2 loss 0.025974169373512268
bi 3 loss 0.026510652154684067
Layer  4  loss:  0.029296325519680977 0.0 0.7453596591949463
logits torch.Size([362, 4, 1024]) labels torch.Size([362, 4]) 0 1022
Curr loss timestep torch.Size([362, 4]) tensor([343,  51, 259, 187], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.03705624118447304
bi 1 loss 0.010033207945525646
bi 2 loss 0.03283573314547539
bi 3 loss 0.02254641428589821
Layer  5  loss:  0.03119976818561554 0.0 2.352485179901123
logits torch.Size([362, 4, 1024]) labels torch.Size([362, 4]) 0 1022
Curr loss timestep torch.Size([362, 4]) tensor([343,  72, 256, 141], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.035588864237070084
bi 1 loss 0.012862086296081543
bi 2 loss 0.02717200294137001
bi 3 loss 0.03517249971628189
Layer  6  loss:  0.03001617081463337 0.0 0.9377914667129517
logits torch.Size([362, 4, 1024]) labels torch.Size([362, 4]) 0 1023
Curr loss timestep torch.Size([362, 4]) tensor([189,  49, 227, 146], device='cuda:0') tensor(146, device='cuda:0')
bi 0 loss 0.03764452785253525
bi 1 loss 0.027774900197982788
bi 2 loss 0.020342038944363594
bi 3 loss 0.029961667954921722
Epoch 0: :   3%|▎         | 15101/600000 [00:42<27:28, v_num=12, reduced_train_loss=0.507, global_step=15099.0, consumed_samples=60400.0, train_step_timing in s=0.278]Epoch 0: :   3%|▎         | 15101/600000 [00:42<27:28, v_num=12, reduced_train_loss=0.223, global_step=15100.0, consumed_samples=60404.0, train_step_timing in s=0.277]loss mask original None

First layer loss:  2.8620424270629883 torch.Size([440, 4]) 11.908465385437012 0.0
Max loss timestep torch.Size([440, 4]) tensor([170, 110,  75, 206], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 3.3085122108459473
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 1 loss 2.912400484085083
speech mask sum tensor(56, device='cuda:0') loss mask sum tensor(56, device='cuda:0')
bi 2 loss 2.4345498085021973
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
bi 3 loss 2.7040724754333496
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
logits torch.Size([440, 4, 257024]) labels torch.Size([440, 4]) 0 257023
Layer  0  loss:  3.400167465209961 0.0 10.149988174438477
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([254, 111, 134, 348], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 3.9696896076202393
bi 1 loss 3.3106167316436768
bi 2 loss 3.0732078552246094
bi 3 loss 2.950511932373047
Layer  1  loss:  3.7000415325164795 0.0 10.096569061279297
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([168, 117, 133, 328], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.349841594696045
bi 1 loss 3.6980741024017334
bi 2 loss 3.335118055343628
bi 3 loss 3.1448161602020264
Layer  2  loss:  3.8533060550689697 0.0 10.520574569702148
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([173, 134, 125, 203], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 4.417644023895264
bi 1 loss 3.815308094024658
bi 2 loss 3.5416147708892822
bi 3 loss 3.3752949237823486
Layer  3  loss:  3.8628458976745605 0.0 10.602313995361328
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([423, 110, 258, 206], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 4.452865123748779
bi 1 loss 3.7608299255371094
bi 2 loss 3.6179323196411133
bi 3 loss 3.272714614868164
Layer  4  loss:  4.039429664611816 0.0 10.194042205810547
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([219, 123, 257, 312], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 4.496408462524414
bi 1 loss 4.092049598693848
bi 2 loss 3.704481840133667
bi 3 loss 3.738316059112549
Layer  5  loss:  4.137993812561035 0.0 11.420581817626953
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([254, 125, 108, 316], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 4.662986755371094
bi 1 loss 3.9357075691223145
bi 2 loss 3.7110700607299805
bi 3 loss 3.930905818939209
Layer  6  loss:  4.166819095611572 0.0 11.318115234375
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1021
Curr loss timestep torch.Size([440, 4]) tensor([236, 129, 104, 329], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.702857971191406
bi 1 loss 4.106786727905273
bi 2 loss 3.8005175590515137
bi 3 loss 3.815441131591797
Epoch 0: :   3%|▎         | 15102/600000 [00:42<27:41, v_num=12, reduced_train_loss=0.223, global_step=15100.0, consumed_samples=60404.0, train_step_timing in s=0.277]Epoch 0: :   3%|▎         | 15102/600000 [00:42<27:41, v_num=12, reduced_train_loss=30.00, global_step=15101.0, consumed_samples=60408.0, train_step_timing in s=0.304]loss mask original None

First layer loss:  0.09223522990942001 torch.Size([455, 4]) 11.314153671264648 0.0
Max loss timestep torch.Size([455, 4]) tensor([432, 290, 428, 143], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 0.12785150110721588
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 1 loss 0.09780792891979218
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 2 loss 0.07500186562538147
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
bi 3 loss 0.029146376997232437
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
logits torch.Size([455, 4, 257024]) labels torch.Size([455, 4]) 0 257023
Layer  0  loss:  0.0845094844698906 0.0 3.646171808242798
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1023
Curr loss timestep torch.Size([455, 4]) tensor([281, 396, 428,  99], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.11002606153488159
bi 1 loss 0.0855565071105957
bi 2 loss 0.0744665265083313
bi 3 loss 0.03407169505953789
Layer  1  loss:  0.0991850346326828 0.0 10.814861297607422
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([432, 292, 428, 144], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.104835145175457
bi 1 loss 0.11715047061443329
bi 2 loss 0.10330785810947418
bi 3 loss 0.030000045895576477
Layer  2  loss:  0.10312195867300034 0.0 12.245296478271484
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([346, 293, 428, 145], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.10062386840581894
bi 1 loss 0.14536643028259277
bi 2 loss 0.1015084907412529
bi 3 loss 0.04816479980945587
Layer  3  loss:  0.10678727924823761 0.0 7.201636791229248
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1023
Curr loss timestep torch.Size([455, 4]) tensor([432, 324, 428, 155], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 0.1065620630979538
bi 1 loss 0.16070035099983215
bi 2 loss 0.100741446018219
bi 3 loss 0.04349402338266373
Layer  4  loss:  0.08698396384716034 0.0 7.315000057220459
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1021
Curr loss timestep torch.Size([455, 4]) tensor([281, 395, 428, 136], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.09381470829248428
bi 1 loss 0.07402168214321136
bi 2 loss 0.09779354184865952
bi 3 loss 0.03600984439253807
Layer  5  loss:  0.09522420167922974 0.0 8.975140571594238
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([432, 290, 428, 139], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.11310562491416931
bi 1 loss 0.08868826180696487
bi 2 loss 0.09469003975391388
bi 3 loss 0.04332248494029045
Layer  6  loss:  0.10427528619766235 0.0 9.474250793457031
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1023
Curr loss timestep torch.Size([455, 4]) tensor([432, 290, 427, 133], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.10342808067798615
bi 1 loss 0.10252504050731659
bi 2 loss 0.11907336860895157
bi 3 loss 0.04476047679781914
Epoch 0: :   3%|▎         | 15103/600000 [00:43<27:55, v_num=12, reduced_train_loss=30.00, global_step=15101.0, consumed_samples=60408.0, train_step_timing in s=0.304]Epoch 0: :   3%|▎         | 15103/600000 [00:43<27:55, v_num=12, reduced_train_loss=0.772, global_step=15102.0, consumed_samples=60412.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  0.1112859770655632 torch.Size([637, 4]) 8.22766399383545 0.0
Max loss timestep torch.Size([637, 4]) tensor([293, 629, 119, 395], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.15717647969722748
speech mask sum tensor(246, device='cuda:0') loss mask sum tensor(246, device='cuda:0')
bi 1 loss 0.13289427757263184
speech mask sum tensor(459, device='cuda:0') loss mask sum tensor(459, device='cuda:0')
bi 2 loss 0.040651388466358185
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
bi 3 loss 0.08947976678609848
speech mask sum tensor(383, device='cuda:0') loss mask sum tensor(383, device='cuda:0')
logits torch.Size([637, 4, 257024]) labels torch.Size([637, 4]) 0 257022
Layer  0  loss:  0.1349250078201294 0.0 8.38704776763916
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([293, 573, 152, 430], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.1815352886915207
bi 1 loss 0.18272899091243744
bi 2 loss 0.05355129763484001
bi 3 loss 0.08636593073606491
Layer  1  loss:  0.1466514766216278 0.0 16.12653160095215
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1020
Curr loss timestep torch.Size([637, 4]) tensor([293, 627, 160, 359], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.2022005170583725
bi 1 loss 0.17381227016448975
bi 2 loss 0.06961528956890106
bi 3 loss 0.11502932757139206
Layer  2  loss:  0.15260766446590424 0.0 9.995319366455078
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1022
Curr loss timestep torch.Size([637, 4]) tensor([292, 336, 236, 365], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.18805307149887085
bi 1 loss 0.20636358857154846
bi 2 loss 0.05202414095401764
bi 3 loss 0.11321516335010529
Layer  3  loss:  0.1275453269481659 0.0 11.398295402526855
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1022
Curr loss timestep torch.Size([637, 4]) tensor([293, 588, 263, 446], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.16193465888500214
bi 1 loss 0.16290777921676636
bi 2 loss 0.05022158473730087
bi 3 loss 0.09982146322727203
Layer  4  loss:  0.14559873938560486 0.0 12.596383094787598
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([293, 588, 202, 389], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.24158070981502533
bi 1 loss 0.1912011206150055
bi 2 loss 0.034878406673669815
bi 3 loss 0.08191216737031937
Layer  5  loss:  0.13071861863136292 0.0 12.8135404586792
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([292, 628, 212, 433], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.20231369137763977
bi 1 loss 0.14851543307304382
bi 2 loss 0.04266911745071411
bi 3 loss 0.10524573177099228
Layer  6  loss:  0.1543702483177185 0.0 7.951138973236084
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([292, 588, 131, 431], device='cuda:0') tensor(588, device='cuda:0')
bi 0 loss 0.18476060032844543
bi 1 loss 0.22550369799137115
bi 2 loss 0.040410883724689484
bi 3 loss 0.10375494509935379
Epoch 0: :   3%|▎         | 15104/600000 [00:43<28:13, v_num=12, reduced_train_loss=0.772, global_step=15102.0, consumed_samples=60412.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15104/600000 [00:43<28:13, v_num=12, reduced_train_loss=1.100, global_step=15103.0, consumed_samples=60416.0, train_step_timing in s=0.433]loss mask original None

First layer loss:  0.08082200586795807 torch.Size([543, 4]) 4.397861003875732 0.0
Max loss timestep torch.Size([543, 4]) tensor([384, 297, 452, 306], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.10359219461679459
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 1 loss 0.08263818174600601
speech mask sum tensor(384, device='cuda:0') loss mask sum tensor(384, device='cuda:0')
bi 2 loss 0.11029623448848724
speech mask sum tensor(78, device='cuda:0') loss mask sum tensor(78, device='cuda:0')
bi 3 loss 0.06614711880683899
speech mask sum tensor(454, device='cuda:0') loss mask sum tensor(454, device='cuda:0')
logits torch.Size([543, 4, 257024]) labels torch.Size([543, 4]) 0 257022
Layer  0  loss:  0.08352851867675781 0.0 10.559815406799316
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([339, 303, 450, 290], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.10332801938056946
bi 1 loss 0.07602985948324203
bi 2 loss 0.1422474980354309
bi 3 loss 0.07276131212711334
Layer  1  loss:  0.09148149937391281 0.0 3.5175299644470215
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([385, 299, 452, 288], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.1477409452199936
bi 1 loss 0.07244087010622025
bi 2 loss 0.10588496923446655
bi 3 loss 0.08516069501638412
Layer  2  loss:  0.08268125355243683 0.0 5.432787895202637
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1022
Curr loss timestep torch.Size([543, 4]) tensor([385, 405, 452, 291], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.09678792208433151
bi 1 loss 0.06437881290912628
bi 2 loss 0.12214597314596176
bi 3 loss 0.08637886494398117
Layer  3  loss:  0.09092310070991516 0.0 6.114534378051758
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1021
Curr loss timestep torch.Size([543, 4]) tensor([385, 299, 452, 306], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.10142761468887329
bi 1 loss 0.08013737946748734
bi 2 loss 0.14255987107753754
bi 3 loss 0.08744914829730988
Layer  4  loss:  0.08359964936971664 0.0 4.222433567047119
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1022
Curr loss timestep torch.Size([543, 4]) tensor([283, 447, 452, 484], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.14739476144313812
bi 1 loss 0.06911035627126694
bi 2 loss 0.056279122829437256
bi 3 loss 0.07792536169290543
Layer  5  loss:  0.10746181756258011 0.0 5.4438862800598145
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([385, 299, 452, 411], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.137620210647583
bi 1 loss 0.08826270699501038
bi 2 loss 0.1357680857181549
bi 3 loss 0.10814257711172104
Layer  6  loss:  0.08832971751689911 0.0 5.361930847167969
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([384, 299, 452, 290], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.1072029173374176
bi 1 loss 0.08932069689035416
bi 2 loss 0.06604024022817612
bi 3 loss 0.08462808281183243
Epoch 0: :   3%|▎         | 15105/600000 [00:44<28:29, v_num=12, reduced_train_loss=1.100, global_step=15103.0, consumed_samples=60416.0, train_step_timing in s=0.433]Epoch 0: :   3%|▎         | 15105/600000 [00:44<28:29, v_num=12, reduced_train_loss=0.709, global_step=15104.0, consumed_samples=60420.0, train_step_timing in s=0.371]loss mask original None

First layer loss:  0.061957839876413345 torch.Size([485, 4]) 3.1975765228271484 0.0
Max loss timestep torch.Size([485, 4]) tensor([339, 103, 296, 343], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.06412167102098465
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
bi 1 loss 0.077877476811409
speech mask sum tensor(80, device='cuda:0') loss mask sum tensor(80, device='cuda:0')
bi 2 loss 0.04550423473119736
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 3 loss 0.07945866882801056
speech mask sum tensor(261, device='cuda:0') loss mask sum tensor(261, device='cuda:0')
logits torch.Size([485, 4, 257024]) labels torch.Size([485, 4]) 0 257023
Layer  0  loss:  0.05678562447428703 0.0 3.7663087844848633
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1023
Curr loss timestep torch.Size([485, 4]) tensor([383, 108, 334, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.08353663980960846
bi 1 loss 0.036792509257793427
bi 2 loss 0.034963756799697876
bi 3 loss 0.07173442840576172
Layer  1  loss:  0.0735095739364624 0.0 4.951132774353027
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([356, 107, 348, 343], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.1051163524389267
bi 1 loss 0.03595462813973427
bi 2 loss 0.06013328209519386
bi 3 loss 0.07714147865772247
Layer  2  loss:  0.06878598034381866 0.0 8.069679260253906
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([354, 106, 347, 345], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.0855744257569313
bi 1 loss 0.01667308621108532
bi 2 loss 0.07019638270139694
bi 3 loss 0.06801304221153259
Layer  3  loss:  0.06589062511920929 0.0 6.791413307189941
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1021
Curr loss timestep torch.Size([485, 4]) tensor([332,  80, 348, 343], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.08134667575359344
bi 1 loss 0.022242795675992966
bi 2 loss 0.04746255278587341
bi 3 loss 0.09295061975717545
Layer  4  loss:  0.08290798217058182 0.0 9.221034049987793
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1020
Curr loss timestep torch.Size([485, 4]) tensor([408,  85, 348, 344], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.12826228141784668
bi 1 loss 0.029619920998811722
bi 2 loss 0.06836730986833572
bi 3 loss 0.08107051253318787
Layer  5  loss:  0.08007286489009857 0.0 7.79049825668335
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([436, 108, 348, 345], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.10771922767162323
bi 1 loss 0.036306433379650116
bi 2 loss 0.047592587769031525
bi 3 loss 0.1172485500574112
Layer  6  loss:  0.06424093246459961 0.0 3.7221834659576416
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1023
Curr loss timestep torch.Size([485, 4]) tensor([356,  83, 346, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.08947555720806122
bi 1 loss 0.03281252458691597
bi 2 loss 0.050176724791526794
bi 3 loss 0.07257617264986038
Epoch 0: :   3%|▎         | 15106/600000 [00:44<28:43, v_num=12, reduced_train_loss=0.709, global_step=15104.0, consumed_samples=60420.0, train_step_timing in s=0.371]Epoch 0: :   3%|▎         | 15106/600000 [00:44<28:43, v_num=12, reduced_train_loss=0.554, global_step=15105.0, consumed_samples=60424.0, train_step_timing in s=0.338]loss mask original None

First layer loss:  0.05405871942639351 torch.Size([413, 4]) 1.621255874633789 0.0
Max loss timestep torch.Size([413, 4]) tensor([349, 283,  86, 317], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.05967935919761658
speech mask sum tensor(273, device='cuda:0') loss mask sum tensor(273, device='cuda:0')
bi 1 loss 0.038510825484991074
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 2 loss 0.04503399878740311
speech mask sum tensor(59, device='cuda:0') loss mask sum tensor(59, device='cuda:0')
bi 3 loss 0.06913968175649643
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
logits torch.Size([413, 4, 257024]) labels torch.Size([413, 4]) 0 257022
Layer  0  loss:  0.05516405403614044 0.0 3.436859607696533
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1023
Curr loss timestep torch.Size([413, 4]) tensor([396, 135, 113, 383], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.05612409859895706
bi 1 loss 0.04223388805985451
bi 2 loss 0.021522387862205505
bi 3 loss 0.08497650921344757
Layer  1  loss:  0.05974077060818672 0.0 2.6942267417907715
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1023
Curr loss timestep torch.Size([413, 4]) tensor([396, 264, 120, 283], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.06286435574293137
bi 1 loss 0.04669986292719841
bi 2 loss 0.040490563958883286
bi 3 loss 0.07998085021972656
Layer  2  loss:  0.07732976973056793 0.0 3.208115577697754
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([349, 222, 109, 354], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.08316976577043533
bi 1 loss 0.06027163937687874
bi 2 loss 0.04918108135461807
bi 3 loss 0.1017523780465126
Layer  3  loss:  0.05245305597782135 0.0 1.1876808404922485
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1019
Curr loss timestep torch.Size([413, 4]) tensor([383, 199, 115, 310], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.05281379818916321
bi 1 loss 0.04446392506361008
bi 2 loss 0.03763080760836601
bi 3 loss 0.06892449408769608
Layer  4  loss:  0.06424497812986374 0.0 3.92494797706604
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([396, 261, 108, 307], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.06724042445421219
bi 1 loss 0.05522971972823143
bi 2 loss 0.06422370672225952
bi 3 loss 0.07139818370342255
Layer  5  loss:  0.06513315439224243 0.0 2.9526450634002686
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1018
Curr loss timestep torch.Size([413, 4]) tensor([366, 260,  89, 308], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.08262167125940323
bi 1 loss 0.04745180159807205
bi 2 loss 0.045092105865478516
bi 3 loss 0.06571274995803833
Layer  6  loss:  0.07272116839885712 0.0 5.301219940185547
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([396, 290,  89, 355], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.10142649710178375
bi 1 loss 0.0358484648168087
bi 2 loss 0.03998623415827751
bi 3 loss 0.08464232087135315
Epoch 0: :   3%|▎         | 15107/600000 [00:44<28:56, v_num=12, reduced_train_loss=0.554, global_step=15105.0, consumed_samples=60424.0, train_step_timing in s=0.338]Epoch 0: :   3%|▎         | 15107/600000 [00:44<28:56, v_num=12, reduced_train_loss=0.501, global_step=15106.0, consumed_samples=60428.0, train_step_timing in s=0.304]loss mask original None

First layer loss:  0.15203949809074402 torch.Size([631, 4]) 10.195576667785645 0.0
Max loss timestep torch.Size([631, 4]) tensor([349,  49, 164, 295], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.20156371593475342
speech mask sum tensor(425, device='cuda:0') loss mask sum tensor(425, device='cuda:0')
bi 1 loss 0.03161037340760231
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 0.026072373613715172
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 3 loss 0.1636592000722885
speech mask sum tensor(456, device='cuda:0') loss mask sum tensor(456, device='cuda:0')
logits torch.Size([631, 4, 257024]) labels torch.Size([631, 4]) 0 257022
Layer  0  loss:  0.1277874857187271 0.0 11.33078384399414
logits torch.Size([631, 4, 1024]) labels torch.Size([631, 4]) 0 1023
Curr loss timestep torch.Size([631, 4]) tensor([468,  60, 149, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.15708887577056885
bi 1 loss 0.02443206124007702
bi 2 loss 0.03730519115924835
bi 3 loss 0.14689433574676514
Layer  1  loss:  0.15494289994239807 0.0 14.235285758972168
logits torch.Size([631, 4, 1024]) labels torch.Size([631, 4]) 0 1023
Curr loss timestep torch.Size([631, 4]) tensor([468,  37, 144, 295], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.20313584804534912
bi 1 loss 0.04455745220184326
bi 2 loss 0.033776212483644485
bi 3 loss 0.16401073336601257
Layer  2  loss:  0.17706972360610962 0.0 12.589725494384766
logits torch.Size([631, 4, 1024]) labels torch.Size([631, 4]) 0 1022
Curr loss timestep torch.Size([631, 4]) tensor([469,  60, 147, 295], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.24559146165847778
bi 1 loss 0.03448697179555893
bi 2 loss 0.051728732883930206
bi 3 loss 0.1773322969675064
Layer  3  loss:  0.15238597989082336 0.0 12.75108528137207
logits torch.Size([631, 4, 1024]) labels torch.Size([631, 4]) 0 1023
Curr loss timestep torch.Size([631, 4]) tensor([468,  53, 114, 295], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.21800418198108673
bi 1 loss 0.04607347771525383
bi 2 loss 0.031119108200073242
bi 3 loss 0.1440432369709015
Layer  4  loss:  0.16126900911331177 0.0 15.506892204284668
logits torch.Size([631, 4, 1024]) labels torch.Size([631, 4]) 0 1022
Curr loss timestep torch.Size([631, 4]) tensor([469,  98, 154, 296], device='cuda:0') tensor(469, device='cuda:0')
bi 0 loss 0.2009589672088623
bi 1 loss 0.04528253525495529
bi 2 loss 0.03882191330194473
bi 3 loss 0.1801256537437439
Layer  5  loss:  0.17013497650623322 0.0 14.502992630004883
logits torch.Size([631, 4, 1024]) labels torch.Size([631, 4]) 0 1022
Curr loss timestep torch.Size([631, 4]) tensor([468,  47, 100, 295], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.19779899716377258
bi 1 loss 0.0366981104016304
bi 2 loss 0.059411339461803436
bi 3 loss 0.20318156480789185
Layer  6  loss:  0.15906710922718048 0.0 11.956969261169434
logits torch.Size([631, 4, 1024]) labels torch.Size([631, 4]) 0 1023
Curr loss timestep torch.Size([631, 4]) tensor([469,  76, 100, 295], device='cuda:0') tensor(469, device='cuda:0')
bi 0 loss 0.2394571751356125
bi 1 loss 0.031729549169540405
bi 2 loss 0.03694840148091316
bi 3 loss 0.1432422548532486
Epoch 0: :   3%|▎         | 15108/600000 [00:45<29:14, v_num=12, reduced_train_loss=0.501, global_step=15106.0, consumed_samples=60428.0, train_step_timing in s=0.304]Epoch 0: :   3%|▎         | 15108/600000 [00:45<29:14, v_num=12, reduced_train_loss=1.250, global_step=15107.0, consumed_samples=60432.0, train_step_timing in s=0.427]loss mask original None

First layer loss:  0.0373571552336216 torch.Size([470, 4]) 2.690538167953491 0.0
Max loss timestep torch.Size([470, 4]) tensor([162, 143, 395, 333], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.024892158806324005
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
bi 1 loss 0.03056076169013977
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
bi 2 loss 0.05691590532660484
speech mask sum tensor(390, device='cuda:0') loss mask sum tensor(390, device='cuda:0')
bi 3 loss 0.022863397374749184
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
logits torch.Size([470, 4, 257024]) labels torch.Size([470, 4]) 0 257023
Layer  0  loss:  0.03586917370557785 0.0 0.8155847191810608
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1023
Curr loss timestep torch.Size([470, 4]) tensor([116, 171, 333, 294], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.01964048109948635
bi 1 loss 0.03347166255116463
bi 2 loss 0.05220547318458557
bi 3 loss 0.025999730452895164
Layer  1  loss:  0.035476796329021454 0.0 2.255676746368408
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1022
Curr loss timestep torch.Size([470, 4]) tensor([129, 140, 395, 348], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.022178618237376213
bi 1 loss 0.026479149237275124
bi 2 loss 0.05073091387748718
bi 3 loss 0.027247771620750427
Layer  2  loss:  0.04267977178096771 0.0 3.7367982864379883
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1023
Curr loss timestep torch.Size([470, 4]) tensor([ 84, 122, 395, 269], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.02668049931526184
bi 1 loss 0.019296390935778618
bi 2 loss 0.045716553926467896
bi 3 loss 0.0548383928835392
Layer  3  loss:  0.03337793052196503 0.0 4.2453413009643555
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1019
Curr loss timestep torch.Size([470, 4]) tensor([150, 153, 396, 273], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.02504444122314453
bi 1 loss 0.01621422730386257
bi 2 loss 0.04921635985374451
bi 3 loss 0.024138418957591057
Layer  4  loss:  0.039458174258470535 0.0 3.7367281913757324
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1022
Curr loss timestep torch.Size([470, 4]) tensor([108, 108, 396, 104], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.021511776372790337
bi 1 loss 0.026039693504571915
bi 2 loss 0.06637789309024811
bi 3 loss 0.02115526609122753
Layer  5  loss:  0.04243173450231552 0.0 2.6901931762695312
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1022
Curr loss timestep torch.Size([470, 4]) tensor([191, 144, 395, 125], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 0.023497117683291435
bi 1 loss 0.015383140183985233
bi 2 loss 0.05516323074698448
bi 3 loss 0.0457036979496479
Layer  6  loss:  0.04175622761249542 0.0 2.5807597637176514
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1022
Curr loss timestep torch.Size([470, 4]) tensor([113, 148, 333, 266], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.02491861954331398
bi 1 loss 0.023317191749811172
bi 2 loss 0.052910663187503815
bi 3 loss 0.04319526627659798
Epoch 0: :   3%|▎         | 15109/600000 [00:45<29:28, v_num=12, reduced_train_loss=1.250, global_step=15107.0, consumed_samples=60432.0, train_step_timing in s=0.427]Epoch 0: :   3%|▎         | 15109/600000 [00:45<29:28, v_num=12, reduced_train_loss=0.308, global_step=15108.0, consumed_samples=60436.0, train_step_timing in s=0.332]loss mask original None

First layer loss:  3.6358962059020996 torch.Size([560, 4]) 11.431485176086426 0.0
Max loss timestep torch.Size([560, 4]) tensor([246,  73, 193, 504], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 3.2941501140594482
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 1 loss 3.635745048522949
speech mask sum tensor(445, device='cuda:0') loss mask sum tensor(445, device='cuda:0')
bi 2 loss 3.859865427017212
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 3 loss 3.7259185314178467
speech mask sum tensor(408, device='cuda:0') loss mask sum tensor(408, device='cuda:0')
logits torch.Size([560, 4, 257024]) labels torch.Size([560, 4]) 0 257022
Layer  0  loss:  4.3595991134643555 0.0 11.11489486694336
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([131, 384, 163, 513], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 4.6533026695251465
bi 1 loss 4.065178871154785
bi 2 loss 4.51881217956543
bi 3 loss 4.4552321434021
Layer  1  loss:  4.7250590324401855 0.0 10.583391189575195
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([265, 300, 130, 497], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 4.699378490447998
bi 1 loss 4.793811321258545
bi 2 loss 4.770419597625732
bi 3 loss 4.644795894622803
Layer  2  loss:  5.040661334991455 0.0 9.980888366699219
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([137, 105, 219, 316], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 5.059330940246582
bi 1 loss 5.03645658493042
bi 2 loss 4.9943695068359375
bi 3 loss 5.054696083068848
Layer  3  loss:  5.207834243774414 0.0 11.744190216064453
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([267, 224, 204, 181], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 5.095761775970459
bi 1 loss 5.243258476257324
bi 2 loss 4.862724781036377
bi 3 loss 5.375117778778076
Layer  4  loss:  5.27490758895874 0.0 10.233794212341309
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([180, 370, 168, 312], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 5.229746341705322
bi 1 loss 5.2748703956604
bi 2 loss 4.982881546020508
bi 3 loss 5.422408103942871
Layer  5  loss:  5.441699504852295 0.0 10.513726234436035
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([244, 386, 134, 536], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 5.554189205169678
bi 1 loss 5.471827983856201
bi 2 loss 5.007591247558594
bi 3 loss 5.531187534332275
Layer  6  loss:  5.494632244110107 0.0 10.910027503967285
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([150, 145, 170, 269], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 5.42653751373291
bi 1 loss 5.479547023773193
bi 2 loss 5.315210342407227
bi 3 loss 5.623441219329834
Epoch 0: :   3%|▎         | 15110/600000 [00:46<29:43, v_num=12, reduced_train_loss=0.308, global_step=15108.0, consumed_samples=60436.0, train_step_timing in s=0.332]Epoch 0: :   3%|▎         | 15110/600000 [00:46<29:43, v_num=12, reduced_train_loss=39.20, global_step=15109.0, consumed_samples=60440.0, train_step_timing in s=0.349]loss mask original None

First layer loss:  0.04148466885089874 torch.Size([431, 4]) 4.45366096496582 0.0
Max loss timestep torch.Size([431, 4]) tensor([283, 305, 269, 279], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.039712581783533096
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 1 loss 0.05471425503492355
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 2 loss 0.038197677582502365
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 3 loss 0.025451725348830223
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
logits torch.Size([431, 4, 257024]) labels torch.Size([431, 4]) 0 257023
Layer  0  loss:  0.04147093743085861 0.0 3.969235420227051
logits torch.Size([431, 4, 1024]) labels torch.Size([431, 4]) 0 1023
Curr loss timestep torch.Size([431, 4]) tensor([249, 305, 301, 297], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.027733836323022842
bi 1 loss 0.04041464626789093
bi 2 loss 0.07050099223852158
bi 3 loss 0.03972950950264931
Layer  1  loss:  0.0448116771876812 0.0 4.840782165527344
logits torch.Size([431, 4, 1024]) labels torch.Size([431, 4]) 0 1023
Curr loss timestep torch.Size([431, 4]) tensor([291, 376, 301, 297], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.03844010829925537
bi 1 loss 0.03461984544992447
bi 2 loss 0.06989958137273788
bi 3 loss 0.05157271772623062
Layer  2  loss:  0.04348757117986679 0.0 3.362424612045288
logits torch.Size([431, 4, 1024]) labels torch.Size([431, 4]) 0 1023
Curr loss timestep torch.Size([431, 4]) tensor([ 89, 288, 301, 297], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.03312382102012634
bi 1 loss 0.05869457498192787
bi 2 loss 0.04640142247080803
bi 3 loss 0.02957739494740963
Layer  3  loss:  0.043296463787555695 0.0 1.3557307720184326
logits torch.Size([431, 4, 1024]) labels torch.Size([431, 4]) 0 1022
Curr loss timestep torch.Size([431, 4]) tensor([296,  69, 286, 297], device='cuda:0') tensor(69, device='cuda:0')
bi 0 loss 0.0461154542863369
bi 1 loss 0.04555072635412216
bi 2 loss 0.052462704479694366
bi 3 loss 0.03153983876109123
Layer  4  loss:  0.04336683452129364 0.0 3.976269483566284
logits torch.Size([431, 4, 1024]) labels torch.Size([431, 4]) 0 1022
Curr loss timestep torch.Size([431, 4]) tensor([238, 414, 301, 297], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.05528031662106514
bi 1 loss 0.03412601724267006
bi 2 loss 0.0709860622882843
bi 3 loss 0.028457295149564743
Layer  5  loss:  0.06455302983522415 0.0 7.786343097686768
logits torch.Size([431, 4, 1024]) labels torch.Size([431, 4]) 0 1022
Curr loss timestep torch.Size([431, 4]) tensor([291, 303, 301, 297], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.043477583676576614
bi 1 loss 0.08148276805877686
bi 2 loss 0.09650721400976181
bi 3 loss 0.04163345322012901
Layer  6  loss:  0.047623198479413986 0.0 3.0356597900390625
logits torch.Size([431, 4, 1024]) labels torch.Size([431, 4]) 0 1021
Curr loss timestep torch.Size([431, 4]) tensor([261, 281, 301, 297], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.047439005225896835
bi 1 loss 0.04336528852581978
bi 2 loss 0.06282506883144379
bi 3 loss 0.045081306248903275
Epoch 0: :   3%|▎         | 15111/600000 [00:46<29:56, v_num=12, reduced_train_loss=39.20, global_step=15109.0, consumed_samples=60440.0, train_step_timing in s=0.349]Epoch 0: :   3%|▎         | 15111/600000 [00:46<29:56, v_num=12, reduced_train_loss=0.370, global_step=15110.0, consumed_samples=60444.0, train_step_timing in s=0.310]loss mask original None

First layer loss:  3.8898932933807373 torch.Size([528, 4]) 9.99856185913086 0.0
Max loss timestep torch.Size([528, 4]) tensor([ 72, 188, 484, 323], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.046599864959717
speech mask sum tensor(158, device='cuda:0') loss mask sum tensor(158, device='cuda:0')
bi 1 loss 3.9199395179748535
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 2 loss 3.8123748302459717
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 3 loss 3.854954719543457
speech mask sum tensor(317, device='cuda:0') loss mask sum tensor(317, device='cuda:0')
logits torch.Size([528, 4, 257024]) labels torch.Size([528, 4]) 0 257023
Layer  0  loss:  4.38056755065918 0.0 11.691575050354004
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([161, 171, 304,  87], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 4.621422290802002
bi 1 loss 4.61918830871582
bi 2 loss 4.02994966506958
bi 3 loss 4.379292964935303
Layer  1  loss:  4.775748252868652 0.0 9.918344497680664
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([ 74, 198, 466, 370], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 4.824195384979248
bi 1 loss 4.901539325714111
bi 2 loss 4.607744216918945
bi 3 loss 4.799987316131592
Layer  2  loss:  4.883912563323975 0.0 9.972067832946777
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([ 91, 177, 491, 322], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 4.846475124359131
bi 1 loss 5.185949802398682
bi 2 loss 4.610733509063721
bi 3 loss 4.908665657043457
Layer  3  loss:  5.0802106857299805 0.0 10.781000137329102
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([ 84, 276, 456, 334], device='cuda:0') tensor(132, device='cuda:0')
bi 0 loss 5.287879467010498
bi 1 loss 5.394887924194336
bi 2 loss 4.718649864196777
bi 3 loss 5.0481061935424805
Layer  4  loss:  5.260104656219482 0.0 10.417325973510742
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([167, 218, 407, 266], device='cuda:0') tensor(127, device='cuda:0')
bi 0 loss 5.373176097869873
bi 1 loss 5.6261677742004395
bi 2 loss 4.975535869598389
bi 3 loss 5.171802520751953
Layer  5  loss:  5.328690052032471 0.0 9.595663070678711
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([147, 198, 301, 333], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 5.361617088317871
bi 1 loss 5.669798851013184
bi 2 loss 5.080731391906738
bi 3 loss 5.267961502075195
Layer  6  loss:  5.45599365234375 0.0 10.227263450622559
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([193, 108, 386, 249], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 5.566376686096191
bi 1 loss 5.839369773864746
bi 2 loss 5.1040263175964355
bi 3 loss 5.413123607635498
Epoch 0: :   3%|▎         | 15112/600000 [00:46<30:11, v_num=12, reduced_train_loss=0.370, global_step=15110.0, consumed_samples=60444.0, train_step_timing in s=0.310]Epoch 0: :   3%|▎         | 15112/600000 [00:46<30:11, v_num=12, reduced_train_loss=39.10, global_step=15111.0, consumed_samples=60448.0, train_step_timing in s=0.339]loss mask original None

First layer loss:  0.035755615681409836 torch.Size([445, 4]) 1.0906376838684082 0.0
Max loss timestep torch.Size([445, 4]) tensor([182, 147,  82, 331], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.03391120210289955
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 1 loss 0.020416947081685066
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
bi 2 loss 0.0532374233007431
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 3 loss 0.03864075243473053
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
logits torch.Size([445, 4, 257024]) labels torch.Size([445, 4]) 0 257022
Layer  0  loss:  0.029515672475099564 0.0 1.4283539056777954
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([255, 205,  60, 213], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 0.026136694476008415
bi 1 loss 0.03466317802667618
bi 2 loss 0.031071992591023445
bi 3 loss 0.028961099684238434
Layer  1  loss:  0.03247397020459175 0.0 1.285498857498169
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([271, 211,  76, 298], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.03547366335988045
bi 1 loss 0.020999357104301453
bi 2 loss 0.026173368096351624
bi 3 loss 0.03795585781335831
Layer  2  loss:  0.03514013811945915 0.0 0.6428035497665405
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([252, 209,  84, 406], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 0.031947068870067596
bi 1 loss 0.0358475036919117
bi 2 loss 0.029864659532904625
bi 3 loss 0.03889083489775658
Layer  3  loss:  0.03206099942326546 0.0 1.1805129051208496
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1020
Curr loss timestep torch.Size([445, 4]) tensor([118, 247,  61, 312], device='cuda:0') tensor(61, device='cuda:0')
bi 0 loss 0.027679389342665672
bi 1 loss 0.03037150204181671
bi 2 loss 0.03451849892735481
bi 3 loss 0.0352376326918602
Layer  4  loss:  0.03869590908288956 0.0 1.1609103679656982
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([150, 234,  94, 427], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.02959430031478405
bi 1 loss 0.035356178879737854
bi 2 loss 0.043816011399030685
bi 3 loss 0.045207321643829346
Layer  5  loss:  0.03195938467979431 0.0 1.2966735363006592
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([167, 191,  71, 229], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 0.03037145733833313
bi 1 loss 0.020540807396173477
bi 2 loss 0.02199234813451767
bi 3 loss 0.041980259120464325
Layer  6  loss:  0.035075247287750244 0.0 0.8522995710372925
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([172, 163,  76, 418], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.03668899089097977
bi 1 loss 0.02736290916800499
bi 2 loss 0.027728822082281113
bi 3 loss 0.04009713977575302
Epoch 0: :   3%|▎         | 15113/600000 [00:47<30:25, v_num=12, reduced_train_loss=39.10, global_step=15111.0, consumed_samples=60448.0, train_step_timing in s=0.339]Epoch 0: :   3%|▎         | 15113/600000 [00:47<30:25, v_num=12, reduced_train_loss=0.271, global_step=15112.0, consumed_samples=60452.0, train_step_timing in s=0.322]loss mask original None

First layer loss:  3.7288174629211426 torch.Size([520, 4]) 10.611902236938477 0.0
Max loss timestep torch.Size([520, 4]) tensor([453,  63, 171,  60], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 4.145102024078369
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 1 loss 3.687758207321167
speech mask sum tensor(245, device='cuda:0') loss mask sum tensor(245, device='cuda:0')
bi 2 loss 3.337998867034912
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 3 loss 2.873987913131714
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
logits torch.Size([520, 4, 257024]) labels torch.Size([520, 4]) 0 257023
Layer  0  loss:  4.1117377281188965 0.0 11.582183837890625
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([470, 171, 171, 104], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 4.199105739593506
bi 1 loss 4.130366802215576
bi 2 loss 3.9491920471191406
bi 3 loss 3.9293696880340576
Layer  1  loss:  4.360934257507324 0.0 9.54322624206543
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([231, 166, 166,  56], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.496815204620361
bi 1 loss 4.304161071777344
bi 2 loss 4.296596050262451
bi 3 loss 4.1350274085998535
Layer  2  loss:  4.648218631744385 0.0 9.849783897399902
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1022
Curr loss timestep torch.Size([520, 4]) tensor([475, 215, 181,  58], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.8260722160339355
bi 1 loss 4.639909744262695
bi 2 loss 4.532434463500977
bi 3 loss 4.223511695861816
Layer  3  loss:  4.894871711730957 0.0 9.775810241699219
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1022
Curr loss timestep torch.Size([520, 4]) tensor([337, 272, 211,  61], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 4.985122203826904
bi 1 loss 4.971108913421631
bi 2 loss 4.651732444763184
bi 3 loss 4.6308207511901855
Layer  4  loss:  5.0166473388671875 0.0 10.532737731933594
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1020
Curr loss timestep torch.Size([520, 4]) tensor([287, 221, 185, 118], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 5.083493232727051
bi 1 loss 5.128890514373779
bi 2 loss 4.860798358917236
bi 3 loss 4.674092769622803
Layer  5  loss:  5.0246405601501465 0.0 8.995253562927246
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([499, 233, 211, 117], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 5.13224458694458
bi 1 loss 5.064877510070801
bi 2 loss 4.8389105796813965
bi 3 loss 4.749281406402588
Layer  6  loss:  5.151050090789795 0.0 10.420162200927734
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([236, 161, 207, 111], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 5.12092924118042
bi 1 loss 5.3916497230529785
bi 2 loss 4.7231879234313965
bi 3 loss 5.00361967086792
Epoch 0: :   3%|▎         | 15114/600000 [00:47<30:39, v_num=12, reduced_train_loss=0.271, global_step=15112.0, consumed_samples=60452.0, train_step_timing in s=0.322]Epoch 0: :   3%|▎         | 15114/600000 [00:47<30:39, v_num=12, reduced_train_loss=36.90, global_step=15113.0, consumed_samples=60456.0, train_step_timing in s=0.336]loss mask original None

First layer loss:  3.6780285835266113 torch.Size([444, 4]) 10.275749206542969 0.0
Max loss timestep torch.Size([444, 4]) tensor([153, 182, 319, 340], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 4.405431270599365
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 1 loss 3.2538375854492188
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 2 loss 3.4356753826141357
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 3 loss 3.647113800048828
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
logits torch.Size([444, 4, 257024]) labels torch.Size([444, 4]) 0 257022
Layer  0  loss:  4.102996349334717 0.0 10.880455017089844
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1023
Curr loss timestep torch.Size([444, 4]) tensor([ 97, 178, 356, 320], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 4.559954643249512
bi 1 loss 4.043436527252197
bi 2 loss 4.13314962387085
bi 3 loss 3.8073782920837402
Layer  1  loss:  4.394010066986084 0.0 10.4146146774292
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([179, 106, 294, 246], device='cuda:0') tensor(133, device='cuda:0')
bi 0 loss 4.729197978973389
bi 1 loss 4.1702656745910645
bi 2 loss 4.490193843841553
bi 3 loss 4.229274272918701
Layer  2  loss:  4.5935773849487305 0.0 9.582706451416016
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([ 90, 159, 382, 310], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 4.947169780731201
bi 1 loss 4.367687225341797
bi 2 loss 4.6376142501831055
bi 3 loss 4.459926128387451
Layer  3  loss:  4.7285332679748535 0.0 10.355731964111328
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1019
Curr loss timestep torch.Size([444, 4]) tensor([116, 113, 362, 419], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 5.040191650390625
bi 1 loss 4.433507442474365
bi 2 loss 4.870816230773926
bi 3 loss 4.586732864379883
Layer  4  loss:  4.7616472244262695 0.0 9.457672119140625
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1023
Curr loss timestep torch.Size([444, 4]) tensor([158, 134, 282, 301], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 4.994784832000732
bi 1 loss 4.476593494415283
bi 2 loss 4.766664505004883
bi 3 loss 4.777611255645752
Layer  5  loss:  4.822822570800781 0.0 9.482382774353027
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1021
Curr loss timestep torch.Size([444, 4]) tensor([163, 107, 302, 402], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 5.207354545593262
bi 1 loss 4.347887992858887
bi 2 loss 4.888364791870117
bi 3 loss 4.805815696716309
Layer  6  loss:  4.867603778839111 0.0 10.109477996826172
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([116, 196, 359, 253], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 5.192472457885742
bi 1 loss 4.458340644836426
bi 2 loss 4.944990158081055
bi 3 loss 4.840423107147217
Epoch 0: :   3%|▎         | 15115/600000 [00:47<30:52, v_num=12, reduced_train_loss=36.90, global_step=15113.0, consumed_samples=60456.0, train_step_timing in s=0.336]Epoch 0: :   3%|▎         | 15115/600000 [00:47<30:52, v_num=12, reduced_train_loss=35.90, global_step=15114.0, consumed_samples=60460.0, train_step_timing in s=0.311]loss mask original None

First layer loss:  0.06912663578987122 torch.Size([513, 4]) 9.734565734863281 0.0
Max loss timestep torch.Size([513, 4]) tensor([258, 326,  93, 209], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.027376849204301834
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 1 loss 0.11950930207967758
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
bi 2 loss 0.02125145122408867
speech mask sum tensor(63, device='cuda:0') loss mask sum tensor(63, device='cuda:0')
bi 3 loss 0.0313323512673378
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([513, 4, 257024]) labels torch.Size([513, 4]) 0 257023
Layer  0  loss:  0.07504558563232422 0.0 12.522252082824707
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([279, 326,  91, 177], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.03009658306837082
bi 1 loss 0.13579005002975464
bi 2 loss 0.022409528493881226
bi 3 loss 0.02329801581799984
Layer  1  loss:  0.09493157267570496 0.0 13.226055145263672
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([275, 327,  72, 186], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.03658004850149155
bi 1 loss 0.18114472925662994
bi 2 loss 0.02461087517440319
bi 3 loss 0.015584156848490238
Layer  2  loss:  0.06567133218050003 0.0 12.122153282165527
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([250, 327,  68, 166], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.023201242089271545
bi 1 loss 0.11540086567401886
bi 2 loss 0.01824108324944973
bi 3 loss 0.029354242607951164
Layer  3  loss:  0.12055958062410355 0.0 19.230571746826172
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([279, 328,  84, 188], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.05996233597397804
bi 1 loss 0.22039169073104858
bi 2 loss 0.022979946807026863
bi 3 loss 0.0309820044785738
Layer  4  loss:  0.10039464384317398 0.0 15.047229766845703
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([264, 326,  89, 212], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.03301653265953064
bi 1 loss 0.18341808021068573
bi 2 loss 0.02048015035688877
bi 3 loss 0.03755749389529228
Layer  5  loss:  0.09763504564762115 0.0 16.101703643798828
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([281, 327,  89, 131], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.021670164540410042
bi 1 loss 0.19202248752117157
bi 2 loss 0.017810942605137825
bi 3 loss 0.020740870386362076
Layer  6  loss:  0.07558256387710571 0.0 12.568120002746582
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1019
Curr loss timestep torch.Size([513, 4]) tensor([263, 327,  78, 208], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.03259862959384918
bi 1 loss 0.13646088540554047
bi 2 loss 0.01693875342607498
bi 3 loss 0.02490636520087719
Epoch 0: :   3%|▎         | 15116/600000 [00:48<31:07, v_num=12, reduced_train_loss=35.90, global_step=15114.0, consumed_samples=60460.0, train_step_timing in s=0.311]Epoch 0: :   3%|▎         | 15116/600000 [00:48<31:07, v_num=12, reduced_train_loss=0.699, global_step=15115.0, consumed_samples=60464.0, train_step_timing in s=0.353]loss mask original None

First layer loss:  0.05611584335565567 torch.Size([379, 4]) 4.140152931213379 0.0
Max loss timestep torch.Size([379, 4]) tensor([365, 104, 345, 125], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.0771404355764389
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 1 loss 0.022026030346751213
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 0.0662483498454094
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 3 loss 0.04143645986914635
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
logits torch.Size([379, 4, 257024]) labels torch.Size([379, 4]) 0 257022
Layer  0  loss:  0.0576346255838871 0.0 7.001475811004639
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1023
Curr loss timestep torch.Size([379, 4]) tensor([201, 123, 345, 153], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.07257873564958572
bi 1 loss 0.026945866644382477
bi 2 loss 0.0673828125
bi 3 loss 0.04842253401875496
Layer  1  loss:  0.05662798136472702 0.0 6.880425930023193
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1023
Curr loss timestep torch.Size([379, 4]) tensor([364, 113, 345,  49], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.05497448518872261
bi 1 loss 0.01788482815027237
bi 2 loss 0.08869865536689758
bi 3 loss 0.03802524879574776
Layer  2  loss:  0.05029517784714699 0.0 4.517453193664551
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1022
Curr loss timestep torch.Size([379, 4]) tensor([316, 124, 274, 170], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.061079397797584534
bi 1 loss 0.030662715435028076
bi 2 loss 0.0643010288476944
bi 3 loss 0.02988450601696968
Layer  3  loss:  0.05924653634428978 0.0 10.786636352539062
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1021
Curr loss timestep torch.Size([379, 4]) tensor([362, 119, 345,  73], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.06056449934840202
bi 1 loss 0.02396736480295658
bi 2 loss 0.08796576410531998
bi 3 loss 0.03953583166003227
Layer  4  loss:  0.05933406949043274 0.0 11.487631797790527
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1021
Curr loss timestep torch.Size([379, 4]) tensor([362, 100, 345, 120], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.05877240374684334
bi 1 loss 0.027308763936161995
bi 2 loss 0.09202700108289719
bi 3 loss 0.032618071883916855
Layer  5  loss:  0.04695278778672218 0.0 1.4339828491210938
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1017
Curr loss timestep torch.Size([379, 4]) tensor([224, 112, 274,  74], device='cuda:0') tensor(112, device='cuda:0')
bi 0 loss 0.05346393957734108
bi 1 loss 0.04353582113981247
bi 2 loss 0.0482432022690773
bi 3 loss 0.03944098576903343
Layer  6  loss:  0.056966714560985565 0.0 10.50057315826416
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1023
Curr loss timestep torch.Size([379, 4]) tensor([332, 115, 345, 161], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.055365826934576035
bi 1 loss 0.02091836929321289
bi 2 loss 0.0922311469912529
bi 3 loss 0.03068472072482109
Epoch 0: :   3%|▎         | 15117/600000 [00:48<31:20, v_num=12, reduced_train_loss=0.699, global_step=15115.0, consumed_samples=60464.0, train_step_timing in s=0.353]Epoch 0: :   3%|▎         | 15117/600000 [00:48<31:20, v_num=12, reduced_train_loss=0.443, global_step=15116.0, consumed_samples=60468.0, train_step_timing in s=0.288]loss mask original None

First layer loss:  3.7862319946289062 torch.Size([576, 4]) 11.61022663116455 0.0
Max loss timestep torch.Size([576, 4]) tensor([179, 541, 398, 241], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 3.4072859287261963
speech mask sum tensor(351, device='cuda:0') loss mask sum tensor(351, device='cuda:0')
bi 1 loss 4.158144950866699
speech mask sum tensor(423, device='cuda:0') loss mask sum tensor(423, device='cuda:0')
bi 2 loss 3.893893241882324
speech mask sum tensor(398, device='cuda:0') loss mask sum tensor(398, device='cuda:0')
bi 3 loss 3.2850468158721924
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
logits torch.Size([576, 4, 257024]) labels torch.Size([576, 4]) 0 257022
Layer  0  loss:  4.424781322479248 0.0 10.499017715454102
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([465, 171, 369, 139], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 3.859943151473999
bi 1 loss 4.772616386413574
bi 2 loss 4.700111389160156
bi 3 loss 3.988532781600952
Layer  1  loss:  4.795146942138672 0.0 11.015244483947754
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([335, 447, 243, 175], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 4.205551624298096
bi 1 loss 5.1139068603515625
bi 2 loss 5.120965957641602
bi 3 loss 4.365567684173584
Layer  2  loss:  4.951892852783203 0.0 10.384751319885254
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([430, 313, 438, 255], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 4.356800556182861
bi 1 loss 5.293850421905518
bi 2 loss 5.233094692230225
bi 3 loss 4.596001148223877
Layer  3  loss:  5.036533832550049 0.0 10.375909805297852
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([194, 361, 278, 199], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 4.503281116485596
bi 1 loss 5.419236183166504
bi 2 loss 5.2216477394104
bi 3 loss 4.675443172454834
Layer  4  loss:  5.170401573181152 0.0 10.147600173950195
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([220, 362, 550, 184], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.538567066192627
bi 1 loss 5.594930648803711
bi 2 loss 5.316592693328857
bi 3 loss 5.051101207733154
Layer  5  loss:  5.177340984344482 0.0 10.740917205810547
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([256, 344, 437, 148], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 4.614943504333496
bi 1 loss 5.668926239013672
bi 2 loss 5.199359893798828
bi 3 loss 5.033290863037109
Layer  6  loss:  5.179872989654541 0.0 10.855449676513672
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([474, 553, 478, 168], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 4.534869194030762
bi 1 loss 5.580508708953857
bi 2 loss 5.35391902923584
bi 3 loss 5.087765216827393
Epoch 0: :   3%|▎         | 15118/600000 [00:48<31:35, v_num=12, reduced_train_loss=0.443, global_step=15116.0, consumed_samples=60468.0, train_step_timing in s=0.288]Epoch 0: :   3%|▎         | 15118/600000 [00:48<31:35, v_num=12, reduced_train_loss=38.50, global_step=15117.0, consumed_samples=60472.0, train_step_timing in s=0.364]loss mask original None

First layer loss:  0.06037105247378349 torch.Size([514, 4]) 4.970738887786865 0.0
Max loss timestep torch.Size([514, 4]) tensor([381, 116, 176, 287], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.07626848667860031
speech mask sum tensor(425, device='cuda:0') loss mask sum tensor(425, device='cuda:0')
bi 1 loss 0.04063164070248604
speech mask sum tensor(83, device='cuda:0') loss mask sum tensor(83, device='cuda:0')
bi 2 loss 0.04487527534365654
speech mask sum tensor(110, device='cuda:0') loss mask sum tensor(110, device='cuda:0')
bi 3 loss 0.03776505962014198
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
logits torch.Size([514, 4, 257024]) labels torch.Size([514, 4]) 0 257023
Layer  0  loss:  0.08995065838098526 0.0 7.8428874015808105
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([360,  66, 261, 252], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.10824651271104813
bi 1 loss 0.0791037306189537
bi 2 loss 0.06435639411211014
bi 3 loss 0.06306272000074387
Layer  1  loss:  0.05611015856266022 0.0 4.3042311668396
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1022
Curr loss timestep torch.Size([514, 4]) tensor([360, 116, 206, 237], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.0709647536277771
bi 1 loss 0.04938141256570816
bi 2 loss 0.02607884630560875
bi 3 loss 0.039876539260149
Layer  2  loss:  0.058765754103660583 0.0 3.4717776775360107
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1022
Curr loss timestep torch.Size([514, 4]) tensor([360, 118, 261, 286], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.07512617856264114
bi 1 loss 0.03668423742055893
bi 2 loss 0.029517589136958122
bi 3 loss 0.04616231471300125
Layer  3  loss:  0.045224666595458984 0.0 2.690230369567871
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1022
Curr loss timestep torch.Size([514, 4]) tensor([360,  93, 233, 309], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.05445857346057892
bi 1 loss 0.02039669081568718
bi 2 loss 0.022643011063337326
bi 3 loss 0.04933256655931473
Layer  4  loss:  0.05104975774884224 0.0 3.8723790645599365
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([360,  76, 261, 294], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.06583397090435028
bi 1 loss 0.03373907133936882
bi 2 loss 0.01783931255340576
bi 3 loss 0.043146733194589615
Layer  5  loss:  0.050418075174093246 0.0 2.791440486907959
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([373,  95, 207, 299], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.054365888237953186
bi 1 loss 0.030071279034018517
bi 2 loss 0.04230998829007149
bi 3 loss 0.0563972182571888
Layer  6  loss:  0.07141660898923874 0.0 6.779538154602051
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([405,  71, 261, 307], device='cuda:0') tensor(405, device='cuda:0')
bi 0 loss 0.08620776236057281
bi 1 loss 0.03977281227707863
bi 2 loss 0.046143531799316406
bi 3 loss 0.06559034436941147
Epoch 0: :   3%|▎         | 15119/600000 [00:49<31:50, v_num=12, reduced_train_loss=38.50, global_step=15117.0, consumed_samples=60472.0, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15119/600000 [00:49<31:50, v_num=12, reduced_train_loss=0.483, global_step=15118.0, consumed_samples=60476.0, train_step_timing in s=0.353]loss mask original None

First layer loss:  0.14968253672122955 torch.Size([661, 4]) 13.745566368103027 0.0
Max loss timestep torch.Size([661, 4]) tensor([565, 263,  60, 164], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.2024078071117401
speech mask sum tensor(498, device='cuda:0') loss mask sum tensor(498, device='cuda:0')
bi 1 loss 0.16969087719917297
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
bi 2 loss 0.07312256842851639
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
bi 3 loss 0.047943342477083206
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
logits torch.Size([661, 4, 257024]) labels torch.Size([661, 4]) 0 257022
Layer  0  loss:  0.17304126918315887 0.0 15.29137134552002
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([270, 303, 313, 189], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.25736454129219055
bi 1 loss 0.16604457795619965
bi 2 loss 0.07167091965675354
bi 3 loss 0.08749412000179291
Layer  1  loss:  0.21839460730552673 0.0 11.458781242370605
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([277, 264, 313, 203], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.38914668560028076
bi 1 loss 0.14361345767974854
bi 2 loss 0.09076382219791412
bi 3 loss 0.033488400280475616
Layer  2  loss:  0.19920769333839417 0.0 12.176957130432129
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([565, 263, 312, 221], device='cuda:0') tensor(565, device='cuda:0')
bi 0 loss 0.35116294026374817
bi 1 loss 0.16561146080493927
bi 2 loss 0.04634001851081848
bi 3 loss 0.03243247792124748
Layer  3  loss:  0.21208982169628143 0.0 13.582855224609375
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1022
Curr loss timestep torch.Size([661, 4]) tensor([261, 264, 310, 168], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.3428882956504822
bi 1 loss 0.16559788584709167
bi 2 loss 0.10858185589313507
bi 3 loss 0.04883062466979027
Layer  4  loss:  0.211711585521698 0.0 10.563826560974121
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([259, 264, 308, 218], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.3355482220649719
bi 1 loss 0.16421383619308472
bi 2 loss 0.11983934789896011
bi 3 loss 0.05158010497689247
Layer  5  loss:  0.223458930850029 0.0 15.501468658447266
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([405, 263, 313, 177], device='cuda:0') tensor(405, device='cuda:0')
bi 0 loss 0.38924476504325867
bi 1 loss 0.14283789694309235
bi 2 loss 0.09354277700185776
bi 3 loss 0.09007284790277481
Layer  6  loss:  0.2124839425086975 0.0 13.611699104309082
logits torch.Size([661, 4, 1024]) labels torch.Size([661, 4]) 0 1023
Curr loss timestep torch.Size([661, 4]) tensor([565, 262, 313, 210], device='cuda:0') tensor(565, device='cuda:0')
bi 0 loss 0.3938198387622833
bi 1 loss 0.13104332983493805
bi 2 loss 0.07036154717206955
bi 3 loss 0.04262348636984825
Epoch 0: :   3%|▎         | 15120/600000 [00:49<32:09, v_num=12, reduced_train_loss=0.483, global_step=15118.0, consumed_samples=60476.0, train_step_timing in s=0.353]Epoch 0: :   3%|▎         | 15120/600000 [00:49<32:09, v_num=12, reduced_train_loss=1.600, global_step=15119.0, consumed_samples=60480.0, train_step_timing in s=0.453]loss mask original None

First layer loss:  0.036975447088479996 torch.Size([454, 4]) 2.1244900226593018 0.0
Max loss timestep torch.Size([454, 4]) tensor([366, 265, 155, 111], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.039072293788194656
speech mask sum tensor(387, device='cuda:0') loss mask sum tensor(387, device='cuda:0')
bi 1 loss 0.0398174487054348
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
bi 2 loss 0.029173048213124275
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 3 loss 0.03587860241532326
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
logits torch.Size([454, 4, 257024]) labels torch.Size([454, 4]) 0 257022
Layer  0  loss:  0.06501510739326477 0.0 4.835834503173828
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([411, 396, 207, 135], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.063534677028656
bi 1 loss 0.10001851618289948
bi 2 loss 0.04221488907933235
bi 3 loss 0.0385679230093956
Layer  1  loss:  0.06547918170690536 0.0 6.394958972930908
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([366, 396, 127, 110], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.06081759184598923
bi 1 loss 0.10207775235176086
bi 2 loss 0.05216868594288826
bi 3 loss 0.033316247165203094
Layer  2  loss:  0.07449425756931305 0.0 10.412209510803223
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([365, 396, 243, 114], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.0624559186398983
bi 1 loss 0.127616286277771
bi 2 loss 0.05412838235497475
bi 3 loss 0.04656386002898216
Layer  3  loss:  0.07124417275190353 0.0 5.1636481285095215
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1018
Curr loss timestep torch.Size([454, 4]) tensor([366, 396, 212, 115], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.060807570815086365
bi 1 loss 0.1319291591644287
bi 2 loss 0.04587678611278534
bi 3 loss 0.031402457505464554
Layer  4  loss:  0.06039871275424957 0.0 2.397552490234375
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([319, 266, 162,  69], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.06306398659944534
bi 1 loss 0.07990504801273346
bi 2 loss 0.04241316393017769
bi 3 loss 0.0415961854159832
Layer  5  loss:  0.05354325845837593 0.0 1.9299193620681763
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([135, 396, 120, 119], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.04546000808477402
bi 1 loss 0.08975721895694733
bi 2 loss 0.04208359494805336
bi 3 loss 0.030708417296409607
Layer  6  loss:  0.05615263804793358 0.0 4.0457611083984375
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([366, 396, 112,  72], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.04581538960337639
bi 1 loss 0.08648897707462311
bi 2 loss 0.05280254781246185
bi 3 loss 0.039980076253414154
Epoch 0: :   3%|▎         | 15121/600000 [00:50<32:23, v_num=12, reduced_train_loss=1.600, global_step=15119.0, consumed_samples=60480.0, train_step_timing in s=0.453]Epoch 0: :   3%|▎         | 15121/600000 [00:50<32:23, v_num=12, reduced_train_loss=0.483, global_step=15120.0, consumed_samples=60484.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  3.6285057067871094 torch.Size([488, 4]) 11.403173446655273 0.0
Max loss timestep torch.Size([488, 4]) tensor([173, 166, 305, 131], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 3.7865841388702393
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 1 loss 3.4597928524017334
speech mask sum tensor(195, device='cuda:0') loss mask sum tensor(195, device='cuda:0')
bi 2 loss 3.7782070636749268
speech mask sum tensor(433, device='cuda:0') loss mask sum tensor(433, device='cuda:0')
bi 3 loss 3.0428056716918945
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257022
Layer  0  loss:  4.177184104919434 0.0 10.537188529968262
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([192, 158, 290, 110], device='cuda:0') tensor(114, device='cuda:0')
bi 0 loss 4.239307880401611
bi 1 loss 4.141547679901123
bi 2 loss 4.318094253540039
bi 3 loss 3.4585378170013428
Layer  1  loss:  4.4240570068359375 0.0 10.01814079284668
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([264, 173, 418, 157], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 4.597445011138916
bi 1 loss 4.212214946746826
bi 2 loss 4.625954627990723
bi 3 loss 3.651050567626953
Layer  2  loss:  4.751630783081055 0.0 9.817259788513184
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([229, 109, 449, 151], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 4.876837730407715
bi 1 loss 4.612983226776123
bi 2 loss 4.930405139923096
bi 3 loss 3.992558717727661
Layer  3  loss:  4.93665075302124 0.0 10.106630325317383
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([252, 172, 122, 124], device='cuda:0') tensor(138, device='cuda:0')
bi 0 loss 5.120450973510742
bi 1 loss 4.966528415679932
bi 2 loss 5.057700157165527
bi 3 loss 4.0071234703063965
Layer  4  loss:  5.00243616104126 0.0 9.747725486755371
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([225, 193, 298, 135], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 5.085089683532715
bi 1 loss 4.750819683074951
bi 2 loss 5.267099857330322
bi 3 loss 4.121561050415039
Layer  5  loss:  5.03580904006958 0.0 9.53204345703125
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([223, 195, 446, 138], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 5.0814900398254395
bi 1 loss 4.947040557861328
bi 2 loss 5.2472100257873535
bi 3 loss 4.10182523727417
Layer  6  loss:  5.146178245544434 0.0 9.75048828125
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1021
Curr loss timestep torch.Size([488, 4]) tensor([243, 230, 220, 143], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 5.11876916885376
bi 1 loss 4.956652641296387
bi 2 loss 5.437427997589111
bi 3 loss 4.133747577667236
Epoch 0: :   3%|▎         | 15122/600000 [00:50<32:37, v_num=12, reduced_train_loss=0.483, global_step=15120.0, consumed_samples=60484.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15122/600000 [00:50<32:37, v_num=12, reduced_train_loss=37.10, global_step=15121.0, consumed_samples=60488.0, train_step_timing in s=0.326]loss mask original None

First layer loss:  0.06551455706357956 torch.Size([483, 4]) 6.561316967010498 0.0
Max loss timestep torch.Size([483, 4]) tensor([146, 260,  81, 126], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.02984139695763588
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
bi 1 loss 0.07725510001182556
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 2 loss 0.15996438264846802
speech mask sum tensor(54, device='cuda:0') loss mask sum tensor(54, device='cuda:0')
bi 3 loss 0.022198941558599472
speech mask sum tensor(108, device='cuda:0') loss mask sum tensor(108, device='cuda:0')
logits torch.Size([483, 4, 257024]) labels torch.Size([483, 4]) 0 257022
Layer  0  loss:  0.04061504453420639 0.0 4.743635177612305
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1023
Curr loss timestep torch.Size([483, 4]) tensor([139, 260,  97, 124], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.015184053219854832
bi 1 loss 0.05989767238497734
bi 2 loss 0.022620532661676407
bi 3 loss 0.024409567937254906
Layer  1  loss:  0.03801488131284714 0.0 0.8771759271621704
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1023
Curr loss timestep torch.Size([483, 4]) tensor([144, 259,  86, 111], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.03433799371123314
bi 1 loss 0.04916596785187721
bi 2 loss 0.013941528275609016
bi 3 loss 0.024957753717899323
Layer  2  loss:  0.04911883920431137 0.0 7.3168792724609375
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1022
Curr loss timestep torch.Size([483, 4]) tensor([142, 260,  86, 123], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.02273596078157425
bi 1 loss 0.0742550939321518
bi 2 loss 0.018911156803369522
bi 3 loss 0.02491430938243866
Layer  3  loss:  0.029880179092288017 0.0 1.459015130996704
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1022
Curr loss timestep torch.Size([483, 4]) tensor([188, 337,  81,  86], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.020649177953600883
bi 1 loss 0.03992066904902458
bi 2 loss 0.0164251197129488
bi 3 loss 0.019659338518977165
Layer  4  loss:  0.04508184641599655 0.0 5.726014614105225
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1023
Curr loss timestep torch.Size([483, 4]) tensor([128, 260,  89, 126], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.02152976766228676
bi 1 loss 0.06820192188024521
bi 2 loss 0.009905887767672539
bi 3 loss 0.02583284303545952
Layer  5  loss:  0.036814574152231216 0.0 1.4677298069000244
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1022
Curr loss timestep torch.Size([483, 4]) tensor([149, 337,  81,  72], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.02423856407403946
bi 1 loss 0.05082590505480766
bi 2 loss 0.024212263524532318
bi 3 loss 0.01917305216193199
Layer  6  loss:  0.03544541448354721 0.0 3.4240264892578125
logits torch.Size([483, 4, 1024]) labels torch.Size([483, 4]) 0 1020
Curr loss timestep torch.Size([483, 4]) tensor([173, 260,  81,  98], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.011391901411116123
bi 1 loss 0.04999282583594322
bi 2 loss 0.026386039331555367
bi 3 loss 0.025603609159588814
Epoch 0: :   3%|▎         | 15123/600000 [00:50<32:51, v_num=12, reduced_train_loss=37.10, global_step=15121.0, consumed_samples=60488.0, train_step_timing in s=0.326]Epoch 0: :   3%|▎         | 15123/600000 [00:50<32:51, v_num=12, reduced_train_loss=0.340, global_step=15122.0, consumed_samples=60492.0, train_step_timing in s=0.340]loss mask original None

First layer loss:  0.06528964638710022 torch.Size([423, 4]) 2.983595848083496 0.0
Max loss timestep torch.Size([423, 4]) tensor([275, 219, 393, 271], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.06128312274813652
speech mask sum tensor(57, device='cuda:0') loss mask sum tensor(57, device='cuda:0')
bi 1 loss 0.02491723746061325
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 2 loss 0.08131105452775955
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.08029735833406448
speech mask sum tensor(158, device='cuda:0') loss mask sum tensor(158, device='cuda:0')
logits torch.Size([423, 4, 257024]) labels torch.Size([423, 4]) 0 257023
Layer  0  loss:  0.11932150274515152 0.0 12.73123550415039
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([274, 201, 282, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.025649715214967728
bi 1 loss 0.037591736763715744
bi 2 loss 0.19476519525051117
bi 3 loss 0.13946552574634552
Layer  1  loss:  0.09514327347278595 0.0 7.5360002517700195
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([307, 243, 282, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.044123295694589615
bi 1 loss 0.04576190188527107
bi 2 loss 0.11089666187763214
bi 3 loss 0.1338108330965042
Layer  2  loss:  0.1024433895945549 0.0 7.00861930847168
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([288, 250, 282, 271], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.037685494869947433
bi 1 loss 0.037035632878541946
bi 2 loss 0.14080625772476196
bi 3 loss 0.1359211504459381
Layer  3  loss:  0.12579430639743805 0.0 9.384467124938965
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([286, 200, 282, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.06208924576640129
bi 1 loss 0.023343687877058983
bi 2 loss 0.18142884969711304
bi 3 loss 0.1688784658908844
Layer  4  loss:  0.0949268713593483 0.0 7.115614891052246
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([306, 248, 282, 263], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.05819638445973396
bi 1 loss 0.024670377373695374
bi 2 loss 0.1487647294998169
bi 3 loss 0.1069718599319458
Layer  5  loss:  0.09460046142339706 0.0 7.536040306091309
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([278, 263, 285, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.0494244359433651
bi 1 loss 0.02524753287434578
bi 2 loss 0.14538101851940155
bi 3 loss 0.11196786165237427
Layer  6  loss:  0.0907100960612297 0.0 7.330747604370117
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1019
Curr loss timestep torch.Size([423, 4]) tensor([283, 266, 285, 271], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.05217517167329788
bi 1 loss 0.02267245016992092
bi 2 loss 0.16048377752304077
bi 3 loss 0.08658929914236069
Epoch 0: :   3%|▎         | 15124/600000 [00:51<33:04, v_num=12, reduced_train_loss=0.340, global_step=15122.0, consumed_samples=60492.0, train_step_timing in s=0.340]Epoch 0: :   3%|▎         | 15124/600000 [00:51<33:04, v_num=12, reduced_train_loss=0.788, global_step=15123.0, consumed_samples=60496.0, train_step_timing in s=0.314]loss mask original None

First layer loss:  3.8599650859832764 torch.Size([600, 4]) 12.682554244995117 0.0
Max loss timestep torch.Size([600, 4]) tensor([244, 403, 362, 294], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 3.838705062866211
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 1 loss 3.670942783355713
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 2 loss 4.18952751159668
speech mask sum tensor(505, device='cuda:0') loss mask sum tensor(505, device='cuda:0')
bi 3 loss 3.3789539337158203
speech mask sum tensor(251, device='cuda:0') loss mask sum tensor(251, device='cuda:0')
logits torch.Size([600, 4, 257024]) labels torch.Size([600, 4]) 0 257023
Layer  0  loss:  4.267074108123779 0.0 11.505685806274414
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([165, 371, 522, 332], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 4.088514804840088
bi 1 loss 4.107875823974609
bi 2 loss 4.417046546936035
bi 3 loss 4.25947380065918
Layer  1  loss:  4.527049541473389 0.0 11.53579330444336
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([243, 358, 385, 387], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 4.320103645324707
bi 1 loss 4.304265022277832
bi 2 loss 4.721756935119629
bi 3 loss 4.509300708770752
Layer  2  loss:  4.729282855987549 0.0 10.923179626464844
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([131, 383, 179, 334], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 4.722988128662109
bi 1 loss 4.495138168334961
bi 2 loss 4.824028015136719
bi 3 loss 4.746605396270752
Layer  3  loss:  4.907636642456055 0.0 9.922248840332031
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([151, 462, 471, 239], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 4.894444465637207
bi 1 loss 4.739546298980713
bi 2 loss 4.965490818023682
bi 3 loss 4.9481201171875
Layer  4  loss:  5.106897354125977 0.0 10.15200138092041
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([283, 283, 156, 311], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 5.044756889343262
bi 1 loss 4.910419464111328
bi 2 loss 5.228734970092773
bi 3 loss 5.086094379425049
Layer  5  loss:  5.066570281982422 0.0 9.671651840209961
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1019
Curr loss timestep torch.Size([600, 4]) tensor([313, 336, 178, 259], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 5.059374809265137
bi 1 loss 4.887044429779053
bi 2 loss 5.130178451538086
bi 3 loss 5.100107192993164
Layer  6  loss:  5.167354583740234 0.0 12.848028182983398
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([144, 302, 175, 335], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 5.153628826141357
bi 1 loss 4.986020565032959
bi 2 loss 5.268295764923096
bi 3 loss 5.133070468902588
Epoch 0: :   3%|▎         | 15125/600000 [00:51<33:20, v_num=12, reduced_train_loss=0.788, global_step=15123.0, consumed_samples=60496.0, train_step_timing in s=0.314]Epoch 0: :   3%|▎         | 15125/600000 [00:51<33:20, v_num=12, reduced_train_loss=37.60, global_step=15124.0, consumed_samples=60500.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  0.06586378812789917 torch.Size([445, 4]) 17.501340866088867 0.0
Max loss timestep torch.Size([445, 4]) tensor([ 51, 412,  99, 421], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.023298241198062897
speech mask sum tensor(60, device='cuda:0') loss mask sum tensor(60, device='cuda:0')
bi 1 loss 0.047167617827653885
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 2 loss 0.011593805626034737
speech mask sum tensor(78, device='cuda:0') loss mask sum tensor(78, device='cuda:0')
bi 3 loss 0.0972992479801178
speech mask sum tensor(386, device='cuda:0') loss mask sum tensor(386, device='cuda:0')
logits torch.Size([445, 4, 257024]) labels torch.Size([445, 4]) 0 257022
Layer  0  loss:  0.05354160815477371 0.0 7.062540531158447
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([ 52, 291, 115, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.03393183648586273
bi 1 loss 0.04132319986820221
bi 2 loss 0.027226591482758522
bi 3 loss 0.07096032053232193
Layer  1  loss:  0.06438948214054108 0.0 8.439828872680664
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([ 42, 412, 119, 421], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.02680620551109314
bi 1 loss 0.04541321098804474
bi 2 loss 0.0139017254114151
bi 3 loss 0.09449377655982971
Layer  2  loss:  0.07047674059867859 0.0 10.377472877502441
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([ 61, 367, 118, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.03961052745580673
bi 1 loss 0.053928326815366745
bi 2 loss 0.025653595104813576
bi 3 loss 0.09659337997436523
Layer  3  loss:  0.07471786439418793 0.0 11.438556671142578
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1021
Curr loss timestep torch.Size([445, 4]) tensor([ 61, 412, 109, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.06748703867197037
bi 1 loss 0.061487890779972076
bi 2 loss 0.023705005645751953
bi 3 loss 0.09595264494419098
Layer  4  loss:  0.07365433126688004 0.0 12.219501495361328
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([ 30, 412, 104, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.021325277164578438
bi 1 loss 0.05006197839975357
bi 2 loss 0.042878177016973495
bi 3 loss 0.10548774152994156
Layer  5  loss:  0.07113341987133026 0.0 10.136149406433105
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([ 52, 412, 111, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.02521512843668461
bi 1 loss 0.038834236562252045
bi 2 loss 0.02292807027697563
bi 3 loss 0.11194349825382233
Layer  6  loss:  0.0843585729598999 0.0 10.26526927947998
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1019
Curr loss timestep torch.Size([445, 4]) tensor([ 29, 412, 121, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.023617390543222427
bi 1 loss 0.07529930770397186
bi 2 loss 0.014080669730901718
bi 3 loss 0.11471375823020935
Epoch 0: :   3%|▎         | 15126/600000 [00:52<33:34, v_num=12, reduced_train_loss=37.60, global_step=15124.0, consumed_samples=60500.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15126/600000 [00:52<33:34, v_num=12, reduced_train_loss=0.558, global_step=15125.0, consumed_samples=60504.0, train_step_timing in s=0.319]loss mask original None

First layer loss:  0.168056458234787 torch.Size([623, 4]) 8.252701759338379 0.0
Max loss timestep torch.Size([623, 4]) tensor([504, 590,  56, 348], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.15297046303749084
speech mask sum tensor(380, device='cuda:0') loss mask sum tensor(380, device='cuda:0')
bi 1 loss 0.2625088691711426
speech mask sum tensor(503, device='cuda:0') loss mask sum tensor(503, device='cuda:0')
bi 2 loss 0.02850855328142643
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 3 loss 0.110725998878479
speech mask sum tensor(293, device='cuda:0') loss mask sum tensor(293, device='cuda:0')
logits torch.Size([623, 4, 257024]) labels torch.Size([623, 4]) 0 257022
Layer  0  loss:  0.18369841575622559 0.0 12.944598197937012
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([519, 543,  79, 402], device='cuda:0') tensor(543, device='cuda:0')
bi 0 loss 0.18649922311306
bi 1 loss 0.2494678944349289
bi 2 loss 0.05028102546930313
bi 3 loss 0.14866551756858826
Layer  1  loss:  0.2090415358543396 0.0 13.330375671386719
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([379, 543,  62, 339], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.19070598483085632
bi 1 loss 0.31740307807922363
bi 2 loss 0.03904198110103607
bi 3 loss 0.1506510078907013
Layer  2  loss:  0.20303203165531158 0.0 13.312704086303711
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([379, 444, 129, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.22857949137687683
bi 1 loss 0.2756109833717346
bi 2 loss 0.04531911388039589
bi 3 loss 0.1416510045528412
Layer  3  loss:  0.20092852413654327 0.0 13.997611045837402
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1021
Curr loss timestep torch.Size([623, 4]) tensor([450, 543, 112, 516], device='cuda:0') tensor(543, device='cuda:0')
bi 0 loss 0.19055557250976562
bi 1 loss 0.2941511571407318
bi 2 loss 0.03860117867588997
bi 3 loss 0.15351325273513794
Layer  4  loss:  0.21704554557800293 0.0 15.968379020690918
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([517, 537, 212, 294], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.23903696238994598
bi 1 loss 0.31026822328567505
bi 2 loss 0.026406820863485336
bi 3 loss 0.1449519395828247
Layer  5  loss:  0.21158060431480408 0.0 11.913772583007812
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([379, 519,  66, 312], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.22472822666168213
bi 1 loss 0.3081313669681549
bi 2 loss 0.028068754822015762
bi 3 loss 0.14088940620422363
Layer  6  loss:  0.19468025863170624 0.0 15.338976860046387
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([324, 536,  59, 268], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.2010839581489563
bi 1 loss 0.2895265817642212
bi 2 loss 0.038063157349824905
bi 3 loss 0.11923100799322128
Epoch 0: :   3%|▎         | 15127/600000 [00:52<33:51, v_num=12, reduced_train_loss=0.558, global_step=15125.0, consumed_samples=60504.0, train_step_timing in s=0.319]Epoch 0: :   3%|▎         | 15127/600000 [00:52<33:51, v_num=12, reduced_train_loss=1.590, global_step=15126.0, consumed_samples=60508.0, train_step_timing in s=0.420]loss mask original None

First layer loss:  0.19704392552375793 torch.Size([634, 4]) 16.80786895751953 0.0
Max loss timestep torch.Size([634, 4]) tensor([352, 367, 214, 445], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.25195518136024475
speech mask sum tensor(396, device='cuda:0') loss mask sum tensor(396, device='cuda:0')
bi 1 loss 0.1130114495754242
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
bi 2 loss 0.17968592047691345
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
bi 3 loss 0.2214832305908203
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
logits torch.Size([634, 4, 257024]) labels torch.Size([634, 4]) 0 257022
Layer  0  loss:  0.22457565367221832 0.0 9.953651428222656
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([425, 367, 537, 444], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.25369560718536377
bi 1 loss 0.17132341861724854
bi 2 loss 0.24232113361358643
bi 3 loss 0.20338541269302368
Layer  1  loss:  0.18450462818145752 0.0 14.027497291564941
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1022
Curr loss timestep torch.Size([634, 4]) tensor([421, 397, 599, 445], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.2193284034729004
bi 1 loss 0.16821935772895813
bi 2 loss 0.15587761998176575
bi 3 loss 0.1934306025505066
Layer  2  loss:  0.2319876253604889 0.0 11.597350120544434
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([425, 392, 355, 445], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.21322104334831238
bi 1 loss 0.21866708993911743
bi 2 loss 0.2508801519870758
bi 3 loss 0.2421400398015976
Layer  3  loss:  0.26159852743148804 0.0 18.460784912109375
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1022
Curr loss timestep torch.Size([634, 4]) tensor([352, 367, 537, 444], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.24182337522506714
bi 1 loss 0.19261731207370758
bi 2 loss 0.28144457936286926
bi 3 loss 0.3230801224708557
Layer  4  loss:  0.23122930526733398 0.0 15.491070747375488
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1022
Curr loss timestep torch.Size([634, 4]) tensor([352, 367, 537, 325], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.2238663136959076
bi 1 loss 0.2602901756763458
bi 2 loss 0.22605305910110474
bi 3 loss 0.2232782542705536
Layer  5  loss:  0.26295262575149536 0.0 12.969942092895508
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1021
Curr loss timestep torch.Size([634, 4]) tensor([352, 392, 609, 445], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.2664050757884979
bi 1 loss 0.21975524723529816
bi 2 loss 0.2989889085292816
bi 3 loss 0.24137628078460693
Layer  6  loss:  0.2528214454650879 0.0 14.078248977661133
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([353, 443, 537, 445], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.2150353193283081
bi 1 loss 0.20699569582939148
bi 2 loss 0.2800557613372803
bi 3 loss 0.3077012002468109
Epoch 0: :   3%|▎         | 15128/600000 [00:53<34:09, v_num=12, reduced_train_loss=1.590, global_step=15126.0, consumed_samples=60508.0, train_step_timing in s=0.420]Epoch 0: :   3%|▎         | 15128/600000 [00:53<34:09, v_num=12, reduced_train_loss=1.850, global_step=15127.0, consumed_samples=60512.0, train_step_timing in s=0.425]loss mask original None

First layer loss:  0.29316192865371704 torch.Size([589, 4]) 16.363941192626953 0.0
Max loss timestep torch.Size([589, 4]) tensor([280, 390, 322, 387], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.2687000036239624
speech mask sum tensor(375, device='cuda:0') loss mask sum tensor(375, device='cuda:0')
bi 1 loss 0.29042160511016846
speech mask sum tensor(492, device='cuda:0') loss mask sum tensor(492, device='cuda:0')
bi 2 loss 0.20743082463741302
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 3 loss 0.4099709987640381
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
logits torch.Size([589, 4, 257024]) labels torch.Size([589, 4]) 0 257023
Layer  0  loss:  0.30916163325309753 0.0 13.822887420654297
logits torch.Size([589, 4, 1024]) labels torch.Size([589, 4]) 0 1023
Curr loss timestep torch.Size([589, 4]) tensor([278, 461, 323, 301], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.23595312237739563
bi 1 loss 0.3108341693878174
bi 2 loss 0.27831873297691345
bi 3 loss 0.42213255167007446
Layer  1  loss:  0.3924187421798706 0.0 14.516355514526367
logits torch.Size([589, 4, 1024]) labels torch.Size([589, 4]) 0 1022
Curr loss timestep torch.Size([589, 4]) tensor([490, 297, 327, 298], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.32974520325660706
bi 1 loss 0.34889695048332214
bi 2 loss 0.3248711824417114
bi 3 loss 0.5981962084770203
Layer  2  loss:  0.4149426221847534 0.0 14.28321647644043
logits torch.Size([589, 4, 1024]) labels torch.Size([589, 4]) 0 1023
Curr loss timestep torch.Size([589, 4]) tensor([280, 413, 324, 533], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.2800214886665344
bi 1 loss 0.4022841155529022
bi 2 loss 0.34787818789482117
bi 3 loss 0.6572276949882507
Layer  3  loss:  0.41125115752220154 0.0 19.333166122436523
logits torch.Size([589, 4, 1024]) labels torch.Size([589, 4]) 0 1023
Curr loss timestep torch.Size([589, 4]) tensor([279, 428, 327, 299], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.2681434750556946
bi 1 loss 0.38909265398979187
bi 2 loss 0.32517769932746887
bi 3 loss 0.6962407231330872
Layer  4  loss:  0.3675144612789154 0.0 17.45268440246582
logits torch.Size([589, 4, 1024]) labels torch.Size([589, 4]) 0 1023
Curr loss timestep torch.Size([589, 4]) tensor([279, 458, 327, 386], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.29841387271881104
bi 1 loss 0.3614957928657532
bi 2 loss 0.26326844096183777
bi 3 loss 0.5594885945320129
Layer  5  loss:  0.4192463159561157 0.0 13.986278533935547
logits torch.Size([589, 4, 1024]) labels torch.Size([589, 4]) 0 1020
Curr loss timestep torch.Size([589, 4]) tensor([279, 461, 323, 299], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.33403870463371277
bi 1 loss 0.3598521649837494
bi 2 loss 0.36155691742897034
bi 3 loss 0.6658446788787842
Layer  6  loss:  0.4206865429878235 0.0 14.2816743850708
logits torch.Size([589, 4, 1024]) labels torch.Size([589, 4]) 0 1023
Curr loss timestep torch.Size([589, 4]) tensor([279, 390, 323, 298], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.2849321961402893
bi 1 loss 0.43557652831077576
bi 2 loss 0.3026326298713684
bi 3 loss 0.671888530254364
Epoch 0: :   3%|▎         | 15129/600000 [00:53<34:26, v_num=12, reduced_train_loss=1.850, global_step=15127.0, consumed_samples=60512.0, train_step_timing in s=0.425]Epoch 0: :   3%|▎         | 15129/600000 [00:53<34:26, v_num=12, reduced_train_loss=3.030, global_step=15128.0, consumed_samples=60516.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  3.3826451301574707 torch.Size([540, 4]) 10.246452331542969 0.0
Max loss timestep torch.Size([540, 4]) tensor([ 59, 315, 328, 201], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 3.0128815174102783
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
bi 1 loss 3.137537956237793
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
bi 2 loss 3.1318764686584473
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
bi 3 loss 3.7004847526550293
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
logits torch.Size([540, 4, 257024]) labels torch.Size([540, 4]) 0 257023
Layer  0  loss:  4.020797252655029 0.0 12.421030044555664
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 47, 192, 272, 506], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 3.573429822921753
bi 1 loss 3.72334361076355
bi 2 loss 4.096994876861572
bi 3 loss 4.264147758483887
Layer  1  loss:  4.315301418304443 0.0 10.248395919799805
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 87, 262, 304, 190], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 4.0304436683654785
bi 1 loss 3.8729069232940674
bi 2 loss 4.499587059020996
bi 3 loss 4.561578750610352
Layer  2  loss:  4.546497344970703 0.0 9.396970748901367
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([ 40, 325, 250, 402], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.138038635253906
bi 1 loss 4.205214500427246
bi 2 loss 4.791322231292725
bi 3 loss 4.74238395690918
Layer  3  loss:  4.67792272567749 0.0 10.157459259033203
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1021
Curr loss timestep torch.Size([540, 4]) tensor([ 47, 263, 235, 317], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 4.3863725662231445
bi 1 loss 4.244925022125244
bi 2 loss 5.013912677764893
bi 3 loss 4.863863945007324
Layer  4  loss:  4.770065784454346 0.0 9.636398315429688
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([ 95, 197, 301, 289], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 4.500602722167969
bi 1 loss 4.42971134185791
bi 2 loss 4.890697956085205
bi 3 loss 4.979222297668457
Layer  5  loss:  4.8582563400268555 0.0 9.910594940185547
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 76, 186, 324, 318], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.549801349639893
bi 1 loss 4.427252769470215
bi 2 loss 5.056698322296143
bi 3 loss 5.098384857177734
Layer  6  loss:  4.949207305908203 0.0 10.165505409240723
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 67, 332, 263, 502], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 4.686578273773193
bi 1 loss 4.591428756713867
bi 2 loss 5.254716873168945
bi 3 loss 5.097527027130127
Epoch 0: :   3%|▎         | 15130/600000 [00:53<34:40, v_num=12, reduced_train_loss=3.030, global_step=15128.0, consumed_samples=60516.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15130/600000 [00:53<34:40, v_num=12, reduced_train_loss=35.50, global_step=15129.0, consumed_samples=60520.0, train_step_timing in s=0.345]loss mask original None

First layer loss:  3.877034902572632 torch.Size([616, 4]) 12.822212219238281 0.0
Max loss timestep torch.Size([616, 4]) tensor([147,  80, 237, 284], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 3.831925630569458
speech mask sum tensor(342, device='cuda:0') loss mask sum tensor(342, device='cuda:0')
bi 1 loss 3.3903005123138428
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 2 loss 3.8117425441741943
speech mask sum tensor(239, device='cuda:0') loss mask sum tensor(239, device='cuda:0')
bi 3 loss 4.047781944274902
speech mask sum tensor(444, device='cuda:0') loss mask sum tensor(444, device='cuda:0')
logits torch.Size([616, 4, 257024]) labels torch.Size([616, 4]) 0 257021
Layer  0  loss:  4.589254379272461 0.0 11.5198974609375
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([219,  54, 218, 227], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 4.4795241355896
bi 1 loss 3.9266138076782227
bi 2 loss 4.5083723068237305
bi 3 loss 4.854617595672607
Layer  1  loss:  4.725618362426758 0.0 10.226733207702637
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([325,  58, 176, 356], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 4.430802345275879
bi 1 loss 4.306954383850098
bi 2 loss 4.912542343139648
bi 3 loss 4.938836097717285
Layer  2  loss:  4.902815818786621 0.0 10.154684066772461
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([101,  61, 112, 342], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.728726387023926
bi 1 loss 4.0755934715271
bi 2 loss 5.042859077453613
bi 3 loss 5.1329345703125
Layer  3  loss:  5.06491756439209 0.0 10.980843544006348
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([232, 104, 238, 403], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 4.936277866363525
bi 1 loss 4.449861526489258
bi 2 loss 5.248456001281738
bi 3 loss 5.19265079498291
Layer  4  loss:  5.162034511566162 0.0 10.157682418823242
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([275, 106, 294, 289], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 4.99630069732666
bi 1 loss 4.708084583282471
bi 2 loss 5.400426864624023
bi 3 loss 5.255432605743408
Layer  5  loss:  5.251180171966553 0.0 9.612763404846191
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([187, 103, 308, 426], device='cuda:0') tensor(103, device='cuda:0')
bi 0 loss 5.0677571296691895
bi 1 loss 4.695886135101318
bi 2 loss 5.423871994018555
bi 3 loss 5.414568901062012
Layer  6  loss:  5.244736194610596 0.0 10.780553817749023
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([351, 104, 224, 236], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 5.0979509353637695
bi 1 loss 4.490322113037109
bi 2 loss 5.506997108459473
bi 3 loss 5.37294864654541
Epoch 0: :   3%|▎         | 15131/600000 [00:54<34:56, v_num=12, reduced_train_loss=35.50, global_step=15129.0, consumed_samples=60520.0, train_step_timing in s=0.345]Epoch 0: :   3%|▎         | 15131/600000 [00:54<34:56, v_num=12, reduced_train_loss=38.80, global_step=15130.0, consumed_samples=60524.0, train_step_timing in s=0.376]loss mask original None

First layer loss:  0.1120745912194252 torch.Size([561, 4]) 7.251226902008057 0.0
Max loss timestep torch.Size([561, 4]) tensor([299, 267, 255, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.11870288848876953
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 1 loss 0.062206171452999115
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 2 loss 0.10773679614067078
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
bi 3 loss 0.13425783812999725
speech mask sum tensor(395, device='cuda:0') loss mask sum tensor(395, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257023
Layer  0  loss:  0.1280103474855423 0.0 6.689332962036133
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([280, 267, 292, 518], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.11458153277635574
bi 1 loss 0.07478457689285278
bi 2 loss 0.1276732236146927
bi 3 loss 0.16375060379505157
Layer  1  loss:  0.11563201993703842 0.0 6.884583950042725
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([314, 266, 313, 518], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.10433336347341537
bi 1 loss 0.09920816123485565
bi 2 loss 0.06650330871343613
bi 3 loss 0.1581140011548996
Layer  2  loss:  0.13237202167510986 0.0 15.249673843383789
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([280, 267, 344, 518], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.15948477387428284
bi 1 loss 0.07217474281787872
bi 2 loss 0.11085527390241623
bi 3 loss 0.1545267105102539
Layer  3  loss:  0.130217045545578 0.0 8.634367942810059
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([299, 267, 344, 518], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.13726595044136047
bi 1 loss 0.0923389196395874
bi 2 loss 0.09417551010847092
bi 3 loss 0.1633123904466629
Layer  4  loss:  0.1460317224264145 0.0 14.524052619934082
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([280, 267, 358, 518], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.15130522847175598
bi 1 loss 0.08595945686101913
bi 2 loss 0.15488573908805847
bi 3 loss 0.16706298291683197
Layer  5  loss:  0.11198381334543228 0.0 9.671221733093262
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([280, 267, 345, 518], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.10279370099306107
bi 1 loss 0.06826641410589218
bi 2 loss 0.07794854044914246
bi 3 loss 0.1582530289888382
Layer  6  loss:  0.13298819959163666 0.0 10.282492637634277
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([299, 266, 263, 518], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.10462907701730728
bi 1 loss 0.13281957805156708
bi 2 loss 0.0904620960354805
bi 3 loss 0.17589013278484344
Epoch 0: :   3%|▎         | 15132/600000 [00:54<35:12, v_num=12, reduced_train_loss=38.80, global_step=15130.0, consumed_samples=60524.0, train_step_timing in s=0.376]Epoch 0: :   3%|▎         | 15132/600000 [00:54<35:12, v_num=12, reduced_train_loss=1.010, global_step=15131.0, consumed_samples=60528.0, train_step_timing in s=0.386]loss mask original None

First layer loss:  0.3710430860519409 torch.Size([741, 4]) 15.62574291229248 0.0
Max loss timestep torch.Size([741, 4]) tensor([714, 343, 147, 392], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.544708788394928
speech mask sum tensor(422, device='cuda:0') loss mask sum tensor(422, device='cuda:0')
bi 1 loss 0.2798696458339691
speech mask sum tensor(402, device='cuda:0') loss mask sum tensor(402, device='cuda:0')
bi 2 loss 0.05974674969911575
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 3 loss 0.3855293095111847
speech mask sum tensor(501, device='cuda:0') loss mask sum tensor(501, device='cuda:0')
logits torch.Size([741, 4, 257024]) labels torch.Size([741, 4]) 0 257022
Layer  0  loss:  0.44553858041763306 0.0 15.135099411010742
logits torch.Size([741, 4, 1024]) labels torch.Size([741, 4]) 0 1023
Curr loss timestep torch.Size([741, 4]) tensor([433, 342, 205, 433], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.65555340051651
bi 1 loss 0.39366331696510315
bi 2 loss 0.0676150843501091
bi 3 loss 0.4166260063648224
Layer  1  loss:  0.4598703384399414 0.0 18.689062118530273
logits torch.Size([741, 4, 1024]) labels torch.Size([741, 4]) 0 1022
Curr loss timestep torch.Size([741, 4]) tensor([514, 342, 148, 392], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.6195591688156128
bi 1 loss 0.3985970616340637
bi 2 loss 0.05610090121626854
bi 3 loss 0.48816293478012085
Layer  2  loss:  0.49983155727386475 0.0 13.985321044921875
logits torch.Size([741, 4, 1024]) labels torch.Size([741, 4]) 0 1023
Curr loss timestep torch.Size([741, 4]) tensor([418, 343, 169, 433], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.7135671973228455
bi 1 loss 0.4568842053413391
bi 2 loss 0.0680624470114708
bi 3 loss 0.47577548027038574
Layer  3  loss:  0.5030080080032349 0.0 18.723121643066406
logits torch.Size([741, 4, 1024]) labels torch.Size([741, 4]) 0 1022
Curr loss timestep torch.Size([741, 4]) tensor([514, 342, 197, 432], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 0.6980712413787842
bi 1 loss 0.47761794924736023
bi 2 loss 0.10458172112703323
bi 3 loss 0.4712080955505371
Layer  4  loss:  0.5245240330696106 0.0 16.063907623291016
logits torch.Size([741, 4, 1024]) labels torch.Size([741, 4]) 0 1023
Curr loss timestep torch.Size([741, 4]) tensor([418, 342, 134, 685], device='cuda:0') tensor(685, device='cuda:0')
bi 0 loss 0.7447476387023926
bi 1 loss 0.49036839604377747
bi 2 loss 0.05757535994052887
bi 3 loss 0.4978494346141815
Layer  5  loss:  0.5176385641098022 0.0 13.59555435180664
logits torch.Size([741, 4, 1024]) labels torch.Size([741, 4]) 0 1017
Curr loss timestep torch.Size([741, 4]) tensor([695, 559, 119, 433], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.7628559470176697
bi 1 loss 0.43244194984436035
bi 2 loss 0.0668954849243164
bi 3 loss 0.5063055157661438
Layer  6  loss:  0.5053933262825012 0.0 16.783737182617188
logits torch.Size([741, 4, 1024]) labels torch.Size([741, 4]) 0 1021
Curr loss timestep torch.Size([741, 4]) tensor([418, 343, 132, 432], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.658979594707489
bi 1 loss 0.48950281739234924
bi 2 loss 0.07518427073955536
bi 3 loss 0.509852409362793
Epoch 0: :   3%|▎         | 15133/600000 [00:55<35:33, v_num=12, reduced_train_loss=1.010, global_step=15131.0, consumed_samples=60528.0, train_step_timing in s=0.386]Epoch 0: :   3%|▎         | 15133/600000 [00:55<35:33, v_num=12, reduced_train_loss=3.830, global_step=15132.0, consumed_samples=60532.0, train_step_timing in s=0.498]loss mask original None

First layer loss:  0.24817511439323425 torch.Size([711, 4]) 12.407079696655273 0.0
Max loss timestep torch.Size([711, 4]) tensor([585, 322, 514, 271], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.3702300786972046
speech mask sum tensor(504, device='cuda:0') loss mask sum tensor(504, device='cuda:0')
bi 1 loss 0.12218832224607468
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
bi 2 loss 0.29863256216049194
speech mask sum tensor(198, device='cuda:0') loss mask sum tensor(198, device='cuda:0')
bi 3 loss 0.05688236281275749
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
logits torch.Size([711, 4, 257024]) labels torch.Size([711, 4]) 0 257022
Layer  0  loss:  0.26726865768432617 0.0 11.000082015991211
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1023
Curr loss timestep torch.Size([711, 4]) tensor([585, 323, 514, 296], device='cuda:0') tensor(585, device='cuda:0')
bi 0 loss 0.4052736759185791
bi 1 loss 0.12012318521738052
bi 2 loss 0.31456777453422546
bi 3 loss 0.07667519152164459
Layer  1  loss:  0.31524187326431274 0.0 12.969679832458496
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1023
Curr loss timestep torch.Size([711, 4]) tensor([685, 323, 514, 319], device='cuda:0') tensor(685, device='cuda:0')
bi 0 loss 0.4960106611251831
bi 1 loss 0.13614608347415924
bi 2 loss 0.36080604791641235
bi 3 loss 0.05416908115148544
Layer  2  loss:  0.3046225607395172 0.0 13.03475284576416
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1023
Curr loss timestep torch.Size([711, 4]) tensor([626, 454, 536, 320], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.45540013909339905
bi 1 loss 0.14753305912017822
bi 2 loss 0.3525539040565491
bi 3 loss 0.09236863255500793
Layer  3  loss:  0.3416411578655243 0.0 14.159850120544434
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1021
Curr loss timestep torch.Size([711, 4]) tensor([672, 327, 435, 296], device='cuda:0') tensor(672, device='cuda:0')
bi 0 loss 0.5437268614768982
bi 1 loss 0.13120579719543457
bi 2 loss 0.3880695402622223
bi 3 loss 0.08207353949546814
Layer  4  loss:  0.35632845759391785 0.0 14.343544006347656
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1022
Curr loss timestep torch.Size([711, 4]) tensor([585, 454, 536, 320], device='cuda:0') tensor(585, device='cuda:0')
bi 0 loss 0.5527652502059937
bi 1 loss 0.19095486402511597
bi 2 loss 0.3316870331764221
bi 3 loss 0.10334611684083939
Layer  5  loss:  0.3333086669445038 0.0 11.593761444091797
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1023
Curr loss timestep torch.Size([711, 4]) tensor([685, 327, 435, 196], device='cuda:0') tensor(685, device='cuda:0')
bi 0 loss 0.5199620127677917
bi 1 loss 0.14538653194904327
bi 2 loss 0.3709721565246582
bi 3 loss 0.08460675925016403
Layer  6  loss:  0.36822447180747986 0.0 14.087740898132324
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1023
Curr loss timestep torch.Size([711, 4]) tensor([585, 322, 514, 320], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.5447690486907959
bi 1 loss 0.159141406416893
bi 2 loss 0.4909808337688446
bi 3 loss 0.08922632038593292
Epoch 0: :   3%|▎         | 15134/600000 [00:55<35:53, v_num=12, reduced_train_loss=3.830, global_step=15132.0, consumed_samples=60532.0, train_step_timing in s=0.498]Epoch 0: :   3%|▎         | 15134/600000 [00:55<35:53, v_num=12, reduced_train_loss=2.530, global_step=15133.0, consumed_samples=60536.0, train_step_timing in s=0.476]loss mask original None

First layer loss:  0.10596350580453873 torch.Size([563, 4]) 12.581612586975098 0.0
Max loss timestep torch.Size([563, 4]) tensor([466, 408, 393, 223], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.18681445717811584
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 1 loss 0.06752663105726242
speech mask sum tensor(281, device='cuda:0') loss mask sum tensor(281, device='cuda:0')
bi 2 loss 0.13379305601119995
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 0.022806484252214432
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
logits torch.Size([563, 4, 257024]) labels torch.Size([563, 4]) 0 257023
Layer  0  loss:  0.12699097394943237 0.0 12.644365310668945
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([468, 408, 393, 215], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.2275170087814331
bi 1 loss 0.06986984610557556
bi 2 loss 0.17501835525035858
bi 3 loss 0.02819281443953514
Layer  1  loss:  0.13302384316921234 0.0 14.081372261047363
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([466, 409, 393, 139], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.274553507566452
bi 1 loss 0.078362837433815
bi 2 loss 0.09333455562591553
bi 3 loss 0.03257197141647339
Layer  2  loss:  0.13037581741809845 0.0 11.037307739257812
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([468, 311, 463, 229], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.22723102569580078
bi 1 loss 0.07901004701852798
bi 2 loss 0.16602471470832825
bi 3 loss 0.03728403523564339
Layer  3  loss:  0.144807830452919 0.0 13.28244400024414
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([467, 352, 393, 216], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.30005598068237305
bi 1 loss 0.07257021963596344
bi 2 loss 0.12576943635940552
bi 3 loss 0.035673875361680984
Layer  4  loss:  0.15075865387916565 0.0 16.542478561401367
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([467, 409, 393, 133], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.2983584403991699
bi 1 loss 0.08799228072166443
bi 2 loss 0.15151698887348175
bi 3 loss 0.024091333150863647
Layer  5  loss:  0.14974041283130646 0.0 14.876953125
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([466, 408, 393, 235], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.2930311858654022
bi 1 loss 0.09194260835647583
bi 2 loss 0.12967075407505035
bi 3 loss 0.03713320195674896
Layer  6  loss:  0.137377068400383 0.0 17.720489501953125
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1021
Curr loss timestep torch.Size([563, 4]) tensor([467, 348, 393, 223], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.29940885305404663
bi 1 loss 0.0639888197183609
bi 2 loss 0.07837609946727753
bi 3 loss 0.048973239958286285
Epoch 0: :   3%|▎         | 15135/600000 [00:56<36:09, v_num=12, reduced_train_loss=2.530, global_step=15133.0, consumed_samples=60536.0, train_step_timing in s=0.476]Epoch 0: :   3%|▎         | 15135/600000 [00:56<36:09, v_num=12, reduced_train_loss=1.080, global_step=15134.0, consumed_samples=60540.0, train_step_timing in s=0.386]loss mask original None

First layer loss:  0.06696514785289764 torch.Size([559, 4]) 3.196772336959839 0.0
Max loss timestep torch.Size([559, 4]) tensor([480, 262, 351,  91], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.07914628833532333
speech mask sum tensor(471, device='cuda:0') loss mask sum tensor(471, device='cuda:0')
bi 1 loss 0.050189707428216934
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
bi 2 loss 0.07096397131681442
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 3 loss 0.03112524189054966
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
logits torch.Size([559, 4, 257024]) labels torch.Size([559, 4]) 0 257022
Layer  0  loss:  0.10395539551973343 0.0 6.007180213928223
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([415, 270, 350, 127], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.13731367886066437
bi 1 loss 0.057212505489587784
bi 2 loss 0.11139427125453949
bi 3 loss 0.01730109378695488
Layer  1  loss:  0.10308891534805298 0.0 10.970866203308105
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([416, 278, 444,  69], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.11978182941675186
bi 1 loss 0.06038011237978935
bi 2 loss 0.12849579751491547
bi 3 loss 0.043113984167575836
Layer  2  loss:  0.11441772431135178 0.0 11.518117904663086
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([416, 206, 444, 124], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.12495922297239304
bi 1 loss 0.06513288617134094
bi 2 loss 0.15343528985977173
bi 3 loss 0.06308268755674362
Layer  3  loss:  0.09742792695760727 0.0 6.6276655197143555
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1019
Curr loss timestep torch.Size([559, 4]) tensor([416, 158, 350,  85], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.11050097644329071
bi 1 loss 0.05395447462797165
bi 2 loss 0.13261042535305023
bi 3 loss 0.030708134174346924
Layer  4  loss:  0.09065522253513336 0.0 12.926719665527344
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([416, 108, 352, 127], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.11619095504283905
bi 1 loss 0.0464840903878212
bi 2 loss 0.09271083772182465
bi 3 loss 0.05315307900309563
Layer  5  loss:  0.1027124896645546 0.0 9.236495018005371
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([416, 280, 352,  82], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.11185915023088455
bi 1 loss 0.03276599943637848
bi 2 loss 0.1590179055929184
bi 3 loss 0.057052887976169586
Layer  6  loss:  0.12970471382141113 0.0 8.95287036895752
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([415, 265, 350,  75], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.13636477291584015
bi 1 loss 0.06002337113022804
bi 2 loss 0.20554153621196747
bi 3 loss 0.042258121073246
Epoch 0: :   3%|▎         | 15136/600000 [00:56<36:25, v_num=12, reduced_train_loss=1.080, global_step=15134.0, consumed_samples=60540.0, train_step_timing in s=0.386]Epoch 0: :   3%|▎         | 15136/600000 [00:56<36:25, v_num=12, reduced_train_loss=0.809, global_step=15135.0, consumed_samples=60544.0, train_step_timing in s=0.378]loss mask original None

First layer loss:  3.613809108734131 torch.Size([572, 4]) 11.352163314819336 0.0
Max loss timestep torch.Size([572, 4]) tensor([457, 362, 305, 405], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 3.7686777114868164
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
bi 1 loss 3.549736261367798
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
bi 2 loss 3.9915108680725098
speech mask sum tensor(125, device='cuda:0') loss mask sum tensor(125, device='cuda:0')
bi 3 loss 3.4367191791534424
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
logits torch.Size([572, 4, 257024]) labels torch.Size([572, 4]) 0 257022
Layer  0  loss:  4.1826934814453125 0.0 11.107154846191406
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([413, 302, 305,  75], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 3.8099448680877686
bi 1 loss 4.617823600769043
bi 2 loss 4.447681427001953
bi 3 loss 4.00687837600708
Layer  1  loss:  4.507167339324951 0.0 10.526169776916504
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([326, 551, 325, 414], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 4.418982028961182
bi 1 loss 4.778597354888916
bi 2 loss 4.898800849914551
bi 3 loss 4.20556640625
Layer  2  loss:  4.733680725097656 0.0 9.959137916564941
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([269, 200, 308, 149], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 4.777816295623779
bi 1 loss 4.902369976043701
bi 2 loss 5.122881889343262
bi 3 loss 4.417189121246338
Layer  3  loss:  4.85883903503418 0.0 10.98091983795166
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([202, 249, 340, 431], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 5.044075965881348
bi 1 loss 4.89127254486084
bi 2 loss 5.184055328369141
bi 3 loss 4.570164203643799
Layer  4  loss:  4.985382080078125 0.0 10.76048469543457
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([171, 133, 266,  73], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 5.2731547355651855
bi 1 loss 5.034317970275879
bi 2 loss 5.3267107009887695
bi 3 loss 4.582544803619385
Layer  5  loss:  5.0445780754089355 0.0 10.483133316040039
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([380, 273, 344, 333], device='cuda:0') tensor(354, device='cuda:0')
bi 0 loss 5.263246059417725
bi 1 loss 5.082911014556885
bi 2 loss 5.294047832489014
bi 3 loss 4.739974498748779
Layer  6  loss:  5.072498798370361 0.0 12.037492752075195
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([325, 407, 317, 135], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 5.301595211029053
bi 1 loss 5.11381721496582
bi 2 loss 5.540435314178467
bi 3 loss 4.696541786193848
Epoch 0: :   3%|▎         | 15137/600000 [00:56<36:40, v_num=12, reduced_train_loss=0.809, global_step=15135.0, consumed_samples=60544.0, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15137/600000 [00:56<36:40, v_num=12, reduced_train_loss=37.00, global_step=15136.0, consumed_samples=60548.0, train_step_timing in s=0.364]loss mask original None

First layer loss:  3.8461148738861084 torch.Size([736, 4]) 13.34543228149414 0.0
Max loss timestep torch.Size([736, 4]) tensor([430, 280, 363, 503], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 3.570810317993164
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
bi 1 loss 4.150261402130127
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
bi 2 loss 3.936330556869507
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 3 loss 3.829239845275879
speech mask sum tensor(452, device='cuda:0') loss mask sum tensor(452, device='cuda:0')
logits torch.Size([736, 4, 257024]) labels torch.Size([736, 4]) 0 257023
Layer  0  loss:  4.1714653968811035 0.0 11.246087074279785
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([556, 268, 369, 344], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 3.9283945560455322
bi 1 loss 4.673964977264404
bi 2 loss 4.129358768463135
bi 3 loss 4.072946071624756
Layer  1  loss:  4.593736171722412 0.0 10.596057891845703
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([696, 375, 288, 363], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 4.432207107543945
bi 1 loss 4.892877578735352
bi 2 loss 4.693813323974609
bi 3 loss 4.463829040527344
Layer  2  loss:  4.820162773132324 0.0 10.449951171875
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([345, 434, 377, 138], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 4.693793296813965
bi 1 loss 5.058878421783447
bi 2 loss 4.79070520401001
bi 3 loss 4.790482997894287
Layer  3  loss:  4.931798458099365 0.0 9.798178672790527
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([334, 422, 214, 286], device='cuda:0') tensor(422, device='cuda:0')
bi 0 loss 4.812527656555176
bi 1 loss 5.150937557220459
bi 2 loss 4.836379051208496
bi 3 loss 4.955504417419434
Layer  4  loss:  5.053879261016846 0.0 10.359987258911133
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([632, 163, 356, 339], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 4.964942455291748
bi 1 loss 5.289979457855225
bi 2 loss 5.105122089385986
bi 3 loss 4.933558464050293
Layer  5  loss:  5.1588239669799805 0.0 10.493919372558594
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([365, 297, 243, 389], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 5.1606221199035645
bi 1 loss 5.378429412841797
bi 2 loss 5.127618312835693
bi 3 loss 5.020517349243164
Layer  6  loss:  5.1766791343688965 0.0 10.22452449798584
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([604, 189, 464, 392], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 5.1161346435546875
bi 1 loss 5.4763665199279785
bi 2 loss 5.057989120483398
bi 3 loss 5.101912498474121
Epoch 0: :   3%|▎         | 15138/600000 [00:57<36:58, v_num=12, reduced_train_loss=37.00, global_step=15136.0, consumed_samples=60548.0, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15138/600000 [00:57<36:58, v_num=12, reduced_train_loss=37.80, global_step=15137.0, consumed_samples=60552.0, train_step_timing in s=0.439]loss mask original None

First layer loss:  0.1176413744688034 torch.Size([582, 4]) 8.618423461914062 0.0
Max loss timestep torch.Size([582, 4]) tensor([404, 267, 339, 114], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.08736609667539597
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 1 loss 0.16508005559444427
speech mask sum tensor(368, device='cuda:0') loss mask sum tensor(368, device='cuda:0')
bi 2 loss 0.11171883344650269
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 3 loss 0.05326008424162865
speech mask sum tensor(167, device='cuda:0') loss mask sum tensor(167, device='cuda:0')
logits torch.Size([582, 4, 257024]) labels torch.Size([582, 4]) 0 257022
Layer  0  loss:  0.15163351595401764 0.0 11.59432315826416
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([405, 436, 338, 138], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.11524956673383713
bi 1 loss 0.18336543440818787
bi 2 loss 0.19905178248882294
bi 3 loss 0.04734537750482559
Layer  1  loss:  0.14523617923259735 0.0 9.038509368896484
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([267, 546, 339, 131], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.16240109503269196
bi 1 loss 0.16612230241298676
bi 2 loss 0.17028746008872986
bi 3 loss 0.043580882251262665
Layer  2  loss:  0.1496998518705368 0.0 15.031258583068848
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([267, 554, 338, 195], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.15403024852275848
bi 1 loss 0.1788199096918106
bi 2 loss 0.15910467505455017
bi 3 loss 0.06682313978672028
Layer  3  loss:  0.13685527443885803 0.0 7.849311828613281
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1017
Curr loss timestep torch.Size([582, 4]) tensor([405, 554, 341, 189], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 0.10648427903652191
bi 1 loss 0.17907343804836273
bi 2 loss 0.1649782657623291
bi 3 loss 0.032498449087142944
Layer  4  loss:  0.14078538119792938 0.0 10.426876068115234
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([267, 293, 339, 179], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.10194026678800583
bi 1 loss 0.18627247214317322
bi 2 loss 0.15843315422534943
bi 3 loss 0.05382262542843819
Layer  5  loss:  0.16712068021297455 0.0 12.640932083129883
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([267, 364, 339, 110], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.15485955774784088
bi 1 loss 0.2116899937391281
bi 2 loss 0.18712465465068817
bi 3 loss 0.05123088136315346
Layer  6  loss:  0.13944454491138458 0.0 9.720810890197754
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1021
Curr loss timestep torch.Size([582, 4]) tensor([415, 560, 339, 212], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.13334284722805023
bi 1 loss 0.16324149072170258
bi 2 loss 0.16746041178703308
bi 3 loss 0.050846949219703674
Epoch 0: :   3%|▎         | 15139/600000 [00:57<37:15, v_num=12, reduced_train_loss=37.80, global_step=15137.0, consumed_samples=60552.0, train_step_timing in s=0.439]Epoch 0: :   3%|▎         | 15139/600000 [00:57<37:15, v_num=12, reduced_train_loss=1.150, global_step=15138.0, consumed_samples=60556.0, train_step_timing in s=0.393]loss mask original None

First layer loss:  0.10930634289979935 torch.Size([693, 4]) 6.623247146606445 0.0
Max loss timestep torch.Size([693, 4]) tensor([100, 177, 301, 132], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.05262137949466705
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
bi 1 loss 0.04482156038284302
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 2 loss 0.1642821878194809
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
bi 3 loss 0.05048328638076782
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
logits torch.Size([693, 4, 257024]) labels torch.Size([693, 4]) 0 257022
Layer  0  loss:  0.13896508514881134 0.0 8.306721687316895
logits torch.Size([693, 4, 1024]) labels torch.Size([693, 4]) 0 1023
Curr loss timestep torch.Size([693, 4]) tensor([293, 207, 469, 140], device='cuda:0') tensor(469, device='cuda:0')
bi 0 loss 0.07872386276721954
bi 1 loss 0.030833054333925247
bi 2 loss 0.20897579193115234
bi 3 loss 0.07639892399311066
Layer  1  loss:  0.14395351707935333 0.0 7.228272914886475
logits torch.Size([693, 4, 1024]) labels torch.Size([693, 4]) 0 1023
Curr loss timestep torch.Size([693, 4]) tensor([293, 219, 466, 147], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.08836789429187775
bi 1 loss 0.06479977071285248
bi 2 loss 0.2096589356660843
bi 3 loss 0.043071478605270386
Layer  2  loss:  0.13740916550159454 0.0 5.350584983825684
logits torch.Size([693, 4, 1024]) labels torch.Size([693, 4]) 0 1022
Curr loss timestep torch.Size([693, 4]) tensor([293, 223, 466, 136], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.08874659985303879
bi 1 loss 0.040467940270900726
bi 2 loss 0.19944597780704498
bi 3 loss 0.07066867500543594
Layer  3  loss:  0.16084304451942444 0.0 9.13166332244873
logits torch.Size([693, 4, 1024]) labels torch.Size([693, 4]) 0 1020
Curr loss timestep torch.Size([693, 4]) tensor([285, 186, 301, 142], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.07892266660928726
bi 1 loss 0.06419263035058975
bi 2 loss 0.24835798144340515
bi 3 loss 0.033166058361530304
Layer  4  loss:  0.1301114410161972 0.0 7.453108310699463
logits torch.Size([693, 4, 1024]) labels torch.Size([693, 4]) 0 1022
Curr loss timestep torch.Size([693, 4]) tensor([137, 157, 466, 133], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.07319623231887817
bi 1 loss 0.046735137701034546
bi 2 loss 0.19346770644187927
bi 3 loss 0.05465131998062134
Layer  5  loss:  0.1345931738615036 0.0 5.545638084411621
logits torch.Size([693, 4, 1024]) labels torch.Size([693, 4]) 0 1022
Curr loss timestep torch.Size([693, 4]) tensor([285, 135, 593, 146], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.075228750705719
bi 1 loss 0.048715151846408844
bi 2 loss 0.20102214813232422
bi 3 loss 0.0518701933324337
Layer  6  loss:  0.14963920414447784 0.0 7.261791706085205
logits torch.Size([693, 4, 1024]) labels torch.Size([693, 4]) 0 1019
Curr loss timestep torch.Size([693, 4]) tensor([293, 136, 466, 137], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.08130083978176117
bi 1 loss 0.056860364973545074
bi 2 loss 0.22533240914344788
bi 3 loss 0.04836200177669525
Epoch 0: :   3%|▎         | 15140/600000 [00:58<37:34, v_num=12, reduced_train_loss=1.150, global_step=15138.0, consumed_samples=60556.0, train_step_timing in s=0.393]Epoch 0: :   3%|▎         | 15140/600000 [00:58<37:34, v_num=12, reduced_train_loss=1.100, global_step=15139.0, consumed_samples=60560.0, train_step_timing in s=0.471]loss mask original None

First layer loss:  0.03568526357412338 torch.Size([375, 4]) 0.5880326628684998 0.0
Max loss timestep torch.Size([375, 4]) tensor([ 64, 310, 151, 107], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 0.019461002200841904
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 0.05252113938331604
speech mask sum tensor(237, device='cuda:0') loss mask sum tensor(237, device='cuda:0')
bi 2 loss 0.019204461947083473
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
bi 3 loss 0.031769733875989914
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
logits torch.Size([375, 4, 257024]) labels torch.Size([375, 4]) 0 257022
Layer  0  loss:  0.03168033808469772 0.0 1.2307528257369995
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([109, 348, 172, 107], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.013349740765988827
bi 1 loss 0.05362443998456001
bi 2 loss 0.01442185789346695
bi 3 loss 0.01961512118577957
Layer  1  loss:  0.027694005519151688 0.0 0.6383267641067505
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1020
Curr loss timestep torch.Size([375, 4]) tensor([112, 319, 163, 139], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.017439616844058037
bi 1 loss 0.038556549698114395
bi 2 loss 0.014471917413175106
bi 3 loss 0.027388568967580795
Layer  2  loss:  0.027630619704723358 0.0 1.4875179529190063
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([ 52, 296, 179,  84], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.020326025784015656
bi 1 loss 0.039910510182380676
bi 2 loss 0.01292435359209776
bi 3 loss 0.02253374457359314
Layer  3  loss:  0.025994131341576576 0.0 0.5691861510276794
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1019
Curr loss timestep torch.Size([375, 4]) tensor([ 73, 295, 205, 123], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 0.011371028609573841
bi 1 loss 0.03275851532816887
bi 2 loss 0.025262700393795967
bi 3 loss 0.027405474334955215
Layer  4  loss:  0.029314527288079262 0.0 1.011519432067871
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1021
Curr loss timestep torch.Size([375, 4]) tensor([ 49, 347, 176, 149], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.023115569725632668
bi 1 loss 0.0405549556016922
bi 2 loss 0.01756562851369381
bi 3 loss 0.02251669205725193
Layer  5  loss:  0.03382812812924385 0.0 1.9997832775115967
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([ 88, 348, 181, 137], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.01052835863083601
bi 1 loss 0.05187466740608215
bi 2 loss 0.03030174970626831
bi 3 loss 0.022503895685076714
Layer  6  loss:  0.027693698182702065 0.0 0.5826370716094971
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([ 94, 211, 179,  93], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 0.015319476835429668
bi 1 loss 0.043818067759275436
bi 2 loss 0.01481143943965435
bi 3 loss 0.017862802371382713
Epoch 0: :   3%|▎         | 15141/600000 [00:58<37:47, v_num=12, reduced_train_loss=1.100, global_step=15139.0, consumed_samples=60560.0, train_step_timing in s=0.471]Epoch 0: :   3%|▎         | 15141/600000 [00:58<37:47, v_num=12, reduced_train_loss=0.240, global_step=15140.0, consumed_samples=60564.0, train_step_timing in s=0.286]loss mask original None

First layer loss:  0.0970807820558548 torch.Size([542, 4]) 7.632956027984619 0.0
Max loss timestep torch.Size([542, 4]) tensor([165, 341, 420, 193], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.009451019577682018
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 1 loss 0.08571857213973999
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
bi 2 loss 0.1676613986492157
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 3 loss 0.036317214369773865
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
logits torch.Size([542, 4, 257024]) labels torch.Size([542, 4]) 0 257022
Layer  0  loss:  0.13206715881824493 0.0 10.183844566345215
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1023
Curr loss timestep torch.Size([542, 4]) tensor([176, 471, 271, 290], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.08558471500873566
bi 1 loss 0.09814592450857162
bi 2 loss 0.2202104777097702
bi 3 loss 0.07421144843101501
Layer  1  loss:  0.14994122087955475 0.0 11.094298362731934
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1022
Curr loss timestep torch.Size([542, 4]) tensor([147, 268, 271, 186], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.030190860852599144
bi 1 loss 0.13467726111412048
bi 2 loss 0.25868159532546997
bi 3 loss 0.042433962225914
Layer  2  loss:  0.1401975154876709 0.0 9.402383804321289
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1022
Curr loss timestep torch.Size([542, 4]) tensor([172, 375, 419, 304], device='cuda:0') tensor(419, device='cuda:0')
bi 0 loss 0.023750174790620804
bi 1 loss 0.1328207403421402
bi 2 loss 0.21089820563793182
bi 3 loss 0.08407147228717804
Layer  3  loss:  0.15266859531402588 0.0 8.843168258666992
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1023
Curr loss timestep torch.Size([542, 4]) tensor([153, 330, 420, 286], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.017783110961318016
bi 1 loss 0.1209656149148941
bi 2 loss 0.28758925199508667
bi 3 loss 0.045225005596876144
Layer  4  loss:  0.15167644619941711 0.0 10.257387161254883
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1022
Curr loss timestep torch.Size([542, 4]) tensor([168, 268, 328, 304], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.030684921890497208
bi 1 loss 0.11893032491207123
bi 2 loss 0.25678783655166626
bi 3 loss 0.09730340540409088
Layer  5  loss:  0.15712736546993256 0.0 11.49410343170166
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1018
Curr loss timestep torch.Size([542, 4]) tensor([170, 268, 421, 304], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.0170641727745533
bi 1 loss 0.14745289087295532
bi 2 loss 0.23319387435913086
bi 3 loss 0.10907147079706192
Layer  6  loss:  0.12514342367649078 0.0 10.750354766845703
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1021
Curr loss timestep torch.Size([542, 4]) tensor([139, 268, 421, 304], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.018964027985930443
bi 1 loss 0.09508444368839264
bi 2 loss 0.21969389915466309
bi 3 loss 0.07639738917350769
Epoch 0: :   3%|▎         | 15142/600000 [00:59<38:02, v_num=12, reduced_train_loss=0.240, global_step=15140.0, consumed_samples=60564.0, train_step_timing in s=0.286]Epoch 0: :   3%|▎         | 15142/600000 [00:59<38:02, v_num=12, reduced_train_loss=1.110, global_step=15141.0, consumed_samples=60568.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  0.07486612349748611 torch.Size([563, 4]) 4.0256195068359375 0.0
Max loss timestep torch.Size([563, 4]) tensor([400, 342, 527, 356], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.03527233004570007
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
bi 1 loss 0.08561435341835022
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 2 loss 0.12246953696012497
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
bi 3 loss 0.041791874915361404
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
logits torch.Size([563, 4, 257024]) labels torch.Size([563, 4]) 0 257022
Layer  0  loss:  0.10816939920186996 0.0 6.7409586906433105
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([359, 347, 527, 414], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.11887237429618835
bi 1 loss 0.09928224980831146
bi 2 loss 0.12817777693271637
bi 3 loss 0.06791998445987701
Layer  1  loss:  0.10139685124158859 0.0 8.879831314086914
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([350, 330, 527, 317], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.08416707068681717
bi 1 loss 0.07238797098398209
bi 2 loss 0.14911697804927826
bi 3 loss 0.06927183270454407
Layer  2  loss:  0.09447371959686279 0.0 6.336530685424805
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([362, 347, 527, 296], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.10506846755743027
bi 1 loss 0.1051984652876854
bi 2 loss 0.10087528824806213
bi 3 loss 0.061225906014442444
Layer  3  loss:  0.0973084345459938 0.0 7.425344944000244
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([296, 353, 527, 283], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.07095666229724884
bi 1 loss 0.0998120978474617
bi 2 loss 0.12619811296463013
bi 3 loss 0.08353900164365768
Layer  4  loss:  0.08333693444728851 0.0 5.047619819641113
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([147, 347, 281, 311], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.05992504954338074
bi 1 loss 0.09491731226444244
bi 2 loss 0.09077483415603638
bi 3 loss 0.09361868351697922
Layer  5  loss:  0.1067834347486496 0.0 11.613303184509277
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([186, 347, 527, 447], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.10671952366828918
bi 1 loss 0.1523592472076416
bi 2 loss 0.11549478024244308
bi 3 loss 0.05667373165488243
Layer  6  loss:  0.13802774250507355 0.0 12.937335968017578
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([344, 347, 282, 311], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.11569493263959885
bi 1 loss 0.14002659916877747
bi 2 loss 0.17696630954742432
bi 3 loss 0.10275531560182571
Epoch 0: :   3%|▎         | 15143/600000 [00:59<38:18, v_num=12, reduced_train_loss=1.110, global_step=15141.0, consumed_samples=60568.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15143/600000 [00:59<38:18, v_num=12, reduced_train_loss=0.804, global_step=15142.0, consumed_samples=60572.0, train_step_timing in s=0.385]loss mask original None

First layer loss:  0.13446681201457977 torch.Size([814, 4]) 13.950666427612305 0.0
Max loss timestep torch.Size([814, 4]) tensor([664, 366, 164, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.18173891305923462
speech mask sum tensor(477, device='cuda:0') loss mask sum tensor(477, device='cuda:0')
bi 1 loss 0.09930173307657242
speech mask sum tensor(331, device='cuda:0') loss mask sum tensor(331, device='cuda:0')
bi 2 loss 0.055202893912792206
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 3 loss 0.15031030774116516
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
logits torch.Size([814, 4, 257024]) labels torch.Size([814, 4]) 0 257023
Layer  0  loss:  0.15519925951957703 0.0 15.833723068237305
logits torch.Size([814, 4, 1024]) labels torch.Size([814, 4]) 0 1023
Curr loss timestep torch.Size([814, 4]) tensor([664, 369,  89, 347], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.227416530251503
bi 1 loss 0.09400202333927155
bi 2 loss 0.03210199624300003
bi 3 loss 0.19030281901359558
Layer  1  loss:  0.18975591659545898 0.0 9.09984302520752
logits torch.Size([814, 4, 1024]) labels torch.Size([814, 4]) 0 1023
Curr loss timestep torch.Size([814, 4]) tensor([664, 369, 152, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.27863776683807373
bi 1 loss 0.11874056607484818
bi 2 loss 0.0757247731089592
bi 3 loss 0.2003488391637802
Layer  2  loss:  0.17984043061733246 0.0 13.515488624572754
logits torch.Size([814, 4, 1024]) labels torch.Size([814, 4]) 0 1022
Curr loss timestep torch.Size([814, 4]) tensor([803, 369, 174, 348], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.2558554410934448
bi 1 loss 0.11139139533042908
bi 2 loss 0.05920584872364998
bi 3 loss 0.2154054492712021
Layer  3  loss:  0.1878843456506729 0.0 14.576838493347168
logits torch.Size([814, 4, 1024]) labels torch.Size([814, 4]) 0 1023
Curr loss timestep torch.Size([814, 4]) tensor([664, 369,  87, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.2940811812877655
bi 1 loss 0.10078466683626175
bi 2 loss 0.059178147464990616
bi 3 loss 0.19791603088378906
Layer  4  loss:  0.18164318799972534 0.0 13.612092971801758
logits torch.Size([814, 4, 1024]) labels torch.Size([814, 4]) 0 1022
Curr loss timestep torch.Size([814, 4]) tensor([664, 369, 127, 347], device='cuda:0') tensor(664, device='cuda:0')
bi 0 loss 0.28729352355003357
bi 1 loss 0.08796001225709915
bi 2 loss 0.06273004412651062
bi 3 loss 0.19388528168201447
Layer  5  loss:  0.1922435760498047 0.0 15.771221160888672
logits torch.Size([814, 4, 1024]) labels torch.Size([814, 4]) 0 1022
Curr loss timestep torch.Size([814, 4]) tensor([664, 369, 259, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.28180527687072754
bi 1 loss 0.09153929352760315
bi 2 loss 0.04972491413354874
bi 3 loss 0.25976547598838806
Layer  6  loss:  0.17552731931209564 0.0 13.029597282409668
logits torch.Size([814, 4, 1024]) labels torch.Size([814, 4]) 0 1023
Curr loss timestep torch.Size([814, 4]) tensor([664, 369, 258, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.2626186013221741
bi 1 loss 0.09265852719545364
bi 2 loss 0.05141725018620491
bi 3 loss 0.21166439354419708
Epoch 0: :   3%|▎         | 15144/600000 [01:00<38:50, v_num=12, reduced_train_loss=0.804, global_step=15142.0, consumed_samples=60572.0, train_step_timing in s=0.385]Epoch 0: :   3%|▎         | 15144/600000 [01:00<38:50, v_num=12, reduced_train_loss=1.400, global_step=15143.0, consumed_samples=60576.0, train_step_timing in s=0.779]loss mask original None

First layer loss:  0.15507565438747406 torch.Size([682, 4]) 15.388014793395996 0.0
Max loss timestep torch.Size([682, 4]) tensor([ 56, 261, 347, 614], device='cuda:0') tensor(614, device='cuda:0')
bi 0 loss 0.036252301186323166
speech mask sum tensor(107, device='cuda:0') loss mask sum tensor(107, device='cuda:0')
bi 1 loss 0.19313466548919678
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 2 loss 0.10503020882606506
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 3 loss 0.1993914395570755
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
logits torch.Size([682, 4, 257024]) labels torch.Size([682, 4]) 0 257023
Layer  0  loss:  0.1619947999715805 0.0 17.26564598083496
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([ 46, 260, 328, 602], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.03542127460241318
bi 1 loss 0.2255168855190277
bi 2 loss 0.08204209804534912
bi 3 loss 0.21547715365886688
Layer  1  loss:  0.17342332005500793 0.0 15.722297668457031
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([ 59, 260, 348, 614], device='cuda:0') tensor(614, device='cuda:0')
bi 0 loss 0.022594893351197243
bi 1 loss 0.21151204407215118
bi 2 loss 0.06757842749357224
bi 3 loss 0.25761526823043823
Layer  2  loss:  0.20206791162490845 0.0 12.11863899230957
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([ 48, 260, 348, 593], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.017867248505353928
bi 1 loss 0.24426212906837463
bi 2 loss 0.1033877357840538
bi 3 loss 0.2891998887062073
Layer  3  loss:  0.17956429719924927 0.0 12.03464126586914
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([104, 261, 347, 613], device='cuda:0') tensor(613, device='cuda:0')
bi 0 loss 0.05833781138062477
bi 1 loss 0.21165399253368378
bi 2 loss 0.06412743777036667
bi 3 loss 0.26389119029045105
Layer  4  loss:  0.19070640206336975 0.0 11.723310470581055
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1022
Curr loss timestep torch.Size([682, 4]) tensor([ 63, 260, 347, 671], device='cuda:0') tensor(671, device='cuda:0')
bi 0 loss 0.03806861862540245
bi 1 loss 0.18667864799499512
bi 2 loss 0.09224455058574677
bi 3 loss 0.28737393021583557
Layer  5  loss:  0.1833186149597168 0.0 11.762990951538086
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([ 84, 260, 355, 614], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.04994717612862587
bi 1 loss 0.18574605882167816
bi 2 loss 0.08557577431201935
bi 3 loss 0.27213990688323975
Layer  6  loss:  0.20479446649551392 0.0 12.846925735473633
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1022
Curr loss timestep torch.Size([682, 4]) tensor([103, 261, 348, 614], device='cuda:0') tensor(614, device='cuda:0')
bi 0 loss 0.0347197949886322
bi 1 loss 0.2522580623626709
bi 2 loss 0.13054566085338593
bi 3 loss 0.27240630984306335
Epoch 0: :   3%|▎         | 15145/600000 [01:00<39:09, v_num=12, reduced_train_loss=1.400, global_step=15143.0, consumed_samples=60576.0, train_step_timing in s=0.779]Epoch 0: :   3%|▎         | 15145/600000 [01:00<39:09, v_num=12, reduced_train_loss=1.450, global_step=15144.0, consumed_samples=60580.0, train_step_timing in s=0.458]loss mask original None

First layer loss:  0.05879754200577736 torch.Size([522, 4]) 6.669310092926025 0.0
Max loss timestep torch.Size([522, 4]) tensor([106, 225, 257, 504], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.03920804336667061
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 1 loss 0.036018647253513336
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 2 loss 0.051978372037410736
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 3 loss 0.08594994246959686
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
logits torch.Size([522, 4, 257024]) labels torch.Size([522, 4]) 0 257023
Layer  0  loss:  0.06823409348726273 0.0 8.938676834106445
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([153, 313, 273, 504], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.038493044674396515
bi 1 loss 0.07989533245563507
bi 2 loss 0.05606432631611824
bi 3 loss 0.08761301636695862
Layer  1  loss:  0.06479939073324203 0.0 3.148615837097168
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([173, 288, 295, 257], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.02900380641222
bi 1 loss 0.052945319563150406
bi 2 loss 0.06425987929105759
bi 3 loss 0.09065859019756317
Layer  2  loss:  0.07116758823394775 0.0 10.38113021850586
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([216, 264, 283, 504], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.03438429534435272
bi 1 loss 0.046484723687171936
bi 2 loss 0.06685072183609009
bi 3 loss 0.10679563134908676
Layer  3  loss:  0.06299486011266708 0.0 3.312877655029297
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([223, 238, 331, 482], device='cuda:0') tensor(482, device='cuda:0')
bi 0 loss 0.028201093897223473
bi 1 loss 0.043060868978500366
bi 2 loss 0.07300405204296112
bi 3 loss 0.08454805612564087
Layer  4  loss:  0.06429373472929001 0.0 10.255393981933594
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1020
Curr loss timestep torch.Size([522, 4]) tensor([146, 314, 309, 504], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.034425485879182816
bi 1 loss 0.05095590651035309
bi 2 loss 0.051037706434726715
bi 3 loss 0.09708237648010254
Layer  5  loss:  0.06900954991579056 0.0 10.252175331115723
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1022
Curr loss timestep torch.Size([522, 4]) tensor([219, 185, 225, 504], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.027704834938049316
bi 1 loss 0.04933030158281326
bi 2 loss 0.06633727252483368
bi 3 loss 0.10337565839290619
Layer  6  loss:  0.0631016418337822 0.0 2.411294460296631
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1022
Curr loss timestep torch.Size([522, 4]) tensor([172, 268, 318, 505], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.03476632013916969
bi 1 loss 0.07607116550207138
bi 2 loss 0.057450708001852036
bi 3 loss 0.07623074948787689
Epoch 0: :   3%|▎         | 15146/600000 [01:01<39:24, v_num=12, reduced_train_loss=1.450, global_step=15144.0, consumed_samples=60580.0, train_step_timing in s=0.458]Epoch 0: :   3%|▎         | 15146/600000 [01:01<39:24, v_num=12, reduced_train_loss=0.522, global_step=15145.0, consumed_samples=60584.0, train_step_timing in s=0.357]loss mask original None

First layer loss:  3.7757740020751953 torch.Size([516, 4]) 11.585212707519531 0.0
Max loss timestep torch.Size([516, 4]) tensor([ 46, 439, 355,  74], device='cuda:0') tensor(107, device='cuda:0')
bi 0 loss 3.2562830448150635
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 1 loss 3.745208740234375
speech mask sum tensor(467, device='cuda:0') loss mask sum tensor(467, device='cuda:0')
bi 2 loss 4.415673732757568
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 3 loss 4.021428108215332
speech mask sum tensor(114, device='cuda:0') loss mask sum tensor(114, device='cuda:0')
logits torch.Size([516, 4, 257024]) labels torch.Size([516, 4]) 0 257022
Layer  0  loss:  4.397745132446289 0.0 11.297957420349121
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([ 70, 102, 397,  97], device='cuda:0') tensor(102, device='cuda:0')
bi 0 loss 3.6030521392822266
bi 1 loss 4.59378719329834
bi 2 loss 4.747011184692383
bi 3 loss 4.364348411560059
Layer  1  loss:  4.665024280548096 0.0 10.172876358032227
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([147, 397, 385, 147], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 4.4157514572143555
bi 1 loss 4.821995735168457
bi 2 loss 4.243658542633057
bi 3 loss 4.757087707519531
Layer  2  loss:  4.854251861572266 0.0 10.326909065246582
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([ 67, 222, 413,  62], device='cuda:0') tensor(67, device='cuda:0')
bi 0 loss 4.261843204498291
bi 1 loss 4.981728553771973
bi 2 loss 4.80499267578125
bi 3 loss 5.193709373474121
Layer  3  loss:  5.172799587249756 0.0 9.867881774902344
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([ 86, 119, 396,  73], device='cuda:0') tensor(73, device='cuda:0')
bi 0 loss 5.422079563140869
bi 1 loss 5.067419528961182
bi 2 loss 5.2531819343566895
bi 3 loss 5.1864399909973145
Layer  4  loss:  5.20316219329834 0.0 10.041107177734375
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([114, 261, 414, 111], device='cuda:0') tensor(111, device='cuda:0')
bi 0 loss 4.9699249267578125
bi 1 loss 5.22346305847168
bi 2 loss 5.215357780456543
bi 3 loss 5.429872035980225
Layer  5  loss:  5.31528377532959 0.0 11.096973419189453
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1017
Curr loss timestep torch.Size([516, 4]) tensor([ 70, 343, 446, 124], device='cuda:0') tensor(129, device='cuda:0')
bi 0 loss 5.124528884887695
bi 1 loss 5.3459367752075195
bi 2 loss 5.289649963378906
bi 3 loss 5.476255416870117
Layer  6  loss:  5.407769203186035 0.0 9.171092987060547
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([167, 478, 363,  65], device='cuda:0') tensor(95, device='cuda:0')
bi 0 loss 5.466883182525635
bi 1 loss 5.396326541900635
bi 2 loss 5.469476699829102
bi 3 loss 5.315853595733643
Epoch 0: :   3%|▎         | 15147/600000 [01:01<39:38, v_num=12, reduced_train_loss=0.522, global_step=15145.0, consumed_samples=60584.0, train_step_timing in s=0.357]Epoch 0: :   3%|▎         | 15147/600000 [01:01<39:38, v_num=12, reduced_train_loss=38.80, global_step=15146.0, consumed_samples=60588.0, train_step_timing in s=0.338]loss mask original None

First layer loss:  0.0961211770772934 torch.Size([566, 4]) 9.337517738342285 0.0
Max loss timestep torch.Size([566, 4]) tensor([208, 323, 289, 103], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.03374020755290985
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 1 loss 0.1282818466424942
speech mask sum tensor(470, device='cuda:0') loss mask sum tensor(470, device='cuda:0')
bi 2 loss 0.07191501557826996
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
bi 3 loss 0.05140998214483261
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([566, 4, 257024]) labels torch.Size([566, 4]) 0 257023
Layer  0  loss:  0.08653295040130615 0.0 7.343818664550781
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([205, 521, 287,  62], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.01640286296606064
bi 1 loss 0.10642736405134201
bi 2 loss 0.0816708356142044
bi 3 loss 0.0460897833108902
Layer  1  loss:  0.10607495158910751 0.0 9.95769214630127
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([200, 323, 289,  82], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.04694601148366928
bi 1 loss 0.135336235165596
bi 2 loss 0.0861780196428299
bi 3 loss 0.06036069244146347
Layer  2  loss:  0.10006575286388397 0.0 9.168991088867188
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([204, 323, 289,  68], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.0175913218408823
bi 1 loss 0.1450781226158142
bi 2 loss 0.06617794185876846
bi 3 loss 0.034854236990213394
Layer  3  loss:  0.08528388291597366 0.0 8.01065444946289
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1021
Curr loss timestep torch.Size([566, 4]) tensor([206, 521, 347, 136], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.03847165405750275
bi 1 loss 0.11846154928207397
bi 2 loss 0.05191078037023544
bi 3 loss 0.05454743281006813
Layer  4  loss:  0.09436385333538055 0.0 11.118217468261719
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([203, 521, 345, 123], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.026393475010991096
bi 1 loss 0.13215945661067963
bi 2 loss 0.06353531777858734
bi 3 loss 0.04597726836800575
Layer  5  loss:  0.11252047121524811 0.0 8.723042488098145
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([200, 323, 287,  56], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.01567675732076168
bi 1 loss 0.13481780886650085
bi 2 loss 0.11387111991643906
bi 3 loss 0.05696205049753189
Layer  6  loss:  0.12233460694551468 0.0 10.789710998535156
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([198, 323, 287,  69], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.035450953990221024
bi 1 loss 0.183819979429245
bi 2 loss 0.06311745941638947
bi 3 loss 0.05760642886161804
Epoch 0: :   3%|▎         | 15148/600000 [01:02<39:55, v_num=12, reduced_train_loss=38.80, global_step=15146.0, consumed_samples=60588.0, train_step_timing in s=0.338]Epoch 0: :   3%|▎         | 15148/600000 [01:02<39:55, v_num=12, reduced_train_loss=0.803, global_step=15147.0, consumed_samples=60592.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.1444421410560608 torch.Size([527, 4]) 20.594074249267578 0.0
Max loss timestep torch.Size([527, 4]) tensor([287, 325, 133, 258], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.15881025791168213
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
bi 1 loss 0.1911899894475937
speech mask sum tensor(300, device='cuda:0') loss mask sum tensor(300, device='cuda:0')
bi 2 loss 0.07944134622812271
speech mask sum tensor(216, device='cuda:0') loss mask sum tensor(216, device='cuda:0')
bi 3 loss 0.08140837401151657
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
logits torch.Size([527, 4, 257024]) labels torch.Size([527, 4]) 0 257023
Layer  0  loss:  0.1640801876783371 0.0 17.642578125
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1023
Curr loss timestep torch.Size([527, 4]) tensor([289, 325, 164, 226], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.16992293298244476
bi 1 loss 0.24666617810726166
bi 2 loss 0.09653138369321823
bi 3 loss 0.01854558289051056
Layer  1  loss:  0.17685936391353607 0.0 14.605217933654785
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1023
Curr loss timestep torch.Size([527, 4]) tensor([286, 324, 263, 215], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.20052924752235413
bi 1 loss 0.21915926039218903
bi 2 loss 0.12234975397586823
bi 3 loss 0.061936698853969574
Layer  2  loss:  0.1318207085132599 0.0 12.961320877075195
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1022
Curr loss timestep torch.Size([527, 4]) tensor([286, 325, 261, 248], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.16017642617225647
bi 1 loss 0.17290587723255157
bi 2 loss 0.06937737762928009
bi 3 loss 0.02072843164205551
Layer  3  loss:  0.17640690505504608 0.0 16.76746368408203
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1018
Curr loss timestep torch.Size([527, 4]) tensor([287, 436, 180, 251], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.2091444879770279
bi 1 loss 0.24408955872058868
bi 2 loss 0.07664157450199127
bi 3 loss 0.04700293764472008
Layer  4  loss:  0.15646734833717346 0.0 14.693219184875488
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1022
Curr loss timestep torch.Size([527, 4]) tensor([286, 325, 258, 258], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.1520935446023941
bi 1 loss 0.23696283996105194
bi 2 loss 0.08688782155513763
bi 3 loss 0.06842432171106339
Layer  5  loss:  0.138936385512352 0.0 11.752083778381348
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1023
Curr loss timestep torch.Size([527, 4]) tensor([287, 325, 108, 218], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.1407400220632553
bi 1 loss 0.22049057483673096
bi 2 loss 0.06565998494625092
bi 3 loss 0.029370397329330444
Layer  6  loss:  0.15348540246486664 0.0 14.625036239624023
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1023
Curr loss timestep torch.Size([527, 4]) tensor([287, 324, 195, 233], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.1486251950263977
bi 1 loss 0.26017144322395325
bi 2 loss 0.04469196870923042
bi 3 loss 0.07479475438594818
Epoch 0: :   3%|▎         | 15149/600000 [01:02<40:10, v_num=12, reduced_train_loss=0.803, global_step=15147.0, consumed_samples=60592.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15149/600000 [01:02<40:10, v_num=12, reduced_train_loss=1.240, global_step=15148.0, consumed_samples=60596.0, train_step_timing in s=0.360]loss mask original None

First layer loss:  0.20474091172218323 torch.Size([703, 4]) 11.158596992492676 0.0
Max loss timestep torch.Size([703, 4]) tensor([315, 318, 355, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.19128315150737762
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
bi 1 loss 0.1070568710565567
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 2 loss 0.20642340183258057
speech mask sum tensor(470, device='cuda:0') loss mask sum tensor(470, device='cuda:0')
bi 3 loss 0.2584652900695801
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
logits torch.Size([703, 4, 257024]) labels torch.Size([703, 4]) 0 257022
Layer  0  loss:  0.210691899061203 0.0 17.985734939575195
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([349, 333, 356, 538], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.2728654444217682
bi 1 loss 0.1145063191652298
bi 2 loss 0.13722991943359375
bi 3 loss 0.27237871289253235
Layer  1  loss:  0.2440054714679718 0.0 16.398536682128906
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([292, 333, 479, 467], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.29086974263191223
bi 1 loss 0.1442357450723648
bi 2 loss 0.1716371476650238
bi 3 loss 0.32093754410743713
Layer  2  loss:  0.2310500591993332 0.0 13.518234252929688
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([292, 332, 557, 533], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.26838570833206177
bi 1 loss 0.12163982540369034
bi 2 loss 0.1798117756843567
bi 3 loss 0.29834169149398804
Layer  3  loss:  0.25627434253692627 0.0 13.563569068908691
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([348, 331, 646, 517], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.3561161458492279
bi 1 loss 0.09014933556318283
bi 2 loss 0.16647468507289886
bi 3 loss 0.3296169936656952
Layer  4  loss:  0.2562481462955475 0.0 16.698400497436523
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([292, 297, 355, 533], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.3205246031284332
bi 1 loss 0.21302227675914764
bi 2 loss 0.15669679641723633
bi 3 loss 0.32137560844421387
Layer  5  loss:  0.2564076781272888 0.0 16.937875747680664
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([348, 318, 648, 533], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.32118192315101624
bi 1 loss 0.14658145606517792
bi 2 loss 0.1696203649044037
bi 3 loss 0.33606329560279846
Layer  6  loss:  0.26866427063941956 0.0 15.822509765625
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([428, 316, 648, 533], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.31295669078826904
bi 1 loss 0.17020367085933685
bi 2 loss 0.15769413113594055
bi 3 loss 0.38971975445747375
Epoch 0: :   3%|▎         | 15150/600000 [01:02<40:29, v_num=12, reduced_train_loss=1.240, global_step=15148.0, consumed_samples=60596.0, train_step_timing in s=0.360]Epoch 0: :   3%|▎         | 15150/600000 [01:02<40:29, v_num=12, reduced_train_loss=1.930, global_step=15149.0, consumed_samples=60600.0, train_step_timing in s=0.476]loss mask original None

First layer loss:  3.730574131011963 torch.Size([792, 4]) 11.790355682373047 0.0
Max loss timestep torch.Size([792, 4]) tensor([169, 143, 357, 599], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 3.938715934753418
speech mask sum tensor(200, device='cuda:0') loss mask sum tensor(200, device='cuda:0')
bi 1 loss 3.894606113433838
speech mask sum tensor(303, device='cuda:0') loss mask sum tensor(303, device='cuda:0')
bi 2 loss 3.821976900100708
speech mask sum tensor(498, device='cuda:0') loss mask sum tensor(498, device='cuda:0')
bi 3 loss 3.4047439098358154
speech mask sum tensor(420, device='cuda:0') loss mask sum tensor(420, device='cuda:0')
logits torch.Size([792, 4, 257024]) labels torch.Size([792, 4]) 0 257023
Layer  0  loss:  4.5247650146484375 0.0 10.764622688293457
logits torch.Size([792, 4, 1024]) labels torch.Size([792, 4]) 0 1023
Curr loss timestep torch.Size([792, 4]) tensor([199, 320, 378, 405], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 4.508385181427002
bi 1 loss 4.621593952178955
bi 2 loss 4.646302223205566
bi 3 loss 4.318601608276367
Layer  1  loss:  4.727430820465088 0.0 9.951855659484863
logits torch.Size([792, 4, 1024]) labels torch.Size([792, 4]) 0 1022
Curr loss timestep torch.Size([792, 4]) tensor([151, 363, 437, 242], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 4.3472137451171875
bi 1 loss 4.9491472244262695
bi 2 loss 4.907731056213379
bi 3 loss 4.534749984741211
Layer  2  loss:  5.0045013427734375 0.0 9.871660232543945
logits torch.Size([792, 4, 1024]) labels torch.Size([792, 4]) 0 1023
Curr loss timestep torch.Size([792, 4]) tensor([132, 182, 741, 569], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.960732460021973
bi 1 loss 5.296828269958496
bi 2 loss 5.082305908203125
bi 3 loss 4.722197532653809
Layer  3  loss:  5.186934947967529 0.0 9.881818771362305
logits torch.Size([792, 4, 1024]) labels torch.Size([792, 4]) 0 1023
Curr loss timestep torch.Size([792, 4]) tensor([112, 244, 661, 385], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.982291221618652
bi 1 loss 5.387596130371094
bi 2 loss 5.376980781555176
bi 3 loss 4.914281845092773
Layer  4  loss:  5.326204299926758 0.0 10.400578498840332
logits torch.Size([792, 4, 1024]) labels torch.Size([792, 4]) 0 1023
Curr loss timestep torch.Size([792, 4]) tensor([148, 246, 500, 551], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 5.0722880363464355
bi 1 loss 5.531440734863281
bi 2 loss 5.451137542724609
bi 3 loss 5.150918483734131
Layer  5  loss:  5.395874977111816 0.0 11.051678657531738
logits torch.Size([792, 4, 1024]) labels torch.Size([792, 4]) 0 1023
Curr loss timestep torch.Size([792, 4]) tensor([198, 300, 742, 605], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 5.072096347808838
bi 1 loss 5.566417217254639
bi 2 loss 5.517990589141846
bi 3 loss 5.282227039337158
Layer  6  loss:  5.417759895324707 0.0 10.579387664794922
logits torch.Size([792, 4, 1024]) labels torch.Size([792, 4]) 0 1023
Curr loss timestep torch.Size([792, 4]) tensor([144, 271, 447, 606], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 5.309621810913086
bi 1 loss 5.55111026763916
bi 2 loss 5.539611339569092
bi 3 loss 5.228569030761719
Epoch 0: :   3%|▎         | 15151/600000 [01:03<40:49, v_num=12, reduced_train_loss=1.930, global_step=15149.0, consumed_samples=60600.0, train_step_timing in s=0.476]Epoch 0: :   3%|▎         | 15151/600000 [01:03<40:49, v_num=12, reduced_train_loss=39.30, global_step=15150.0, consumed_samples=60604.0, train_step_timing in s=0.461]loss mask original None

First layer loss:  0.09866269677877426 torch.Size([487, 4]) 8.111089706420898 0.0
Max loss timestep torch.Size([487, 4]) tensor([428, 269, 157, 370], device='cuda:0') tensor(370, device='cuda:0')
bi 0 loss 0.08062855154275894
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
bi 1 loss 0.04764292761683464
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 2 loss 0.12264619022607803
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 3 loss 0.11660841107368469
speech mask sum tensor(354, device='cuda:0') loss mask sum tensor(354, device='cuda:0')
logits torch.Size([487, 4, 257024]) labels torch.Size([487, 4]) 0 257023
Layer  0  loss:  0.128158837556839 0.0 12.394891738891602
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([439, 269, 267, 370], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.21446628868579865
bi 1 loss 0.07034943252801895
bi 2 loss 0.073268361389637
bi 3 loss 0.12060514837503433
Layer  1  loss:  0.1095450296998024 0.0 11.380781173706055
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([439, 269, 267, 310], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.1422518640756607
bi 1 loss 0.05878645181655884
bi 2 loss 0.12655484676361084
bi 3 loss 0.09123251587152481
Layer  2  loss:  0.12733273208141327 0.0 8.969858169555664
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([440, 269, 266, 352], device='cuda:0') tensor(440, device='cuda:0')
bi 0 loss 0.15587696433067322
bi 1 loss 0.1262243390083313
bi 2 loss 0.13926872611045837
bi 3 loss 0.09610506147146225
Layer  3  loss:  0.12640371918678284 0.0 13.452502250671387
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([440, 269, 267, 370], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.12752977013587952
bi 1 loss 0.08129041641950607
bi 2 loss 0.15297651290893555
bi 3 loss 0.12459580600261688
Layer  4  loss:  0.1273486614227295 0.0 9.289480209350586
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1021
Curr loss timestep torch.Size([487, 4]) tensor([428, 269, 267, 352], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.16572251915931702
bi 1 loss 0.07391601800918579
bi 2 loss 0.09363648295402527
bi 3 loss 0.1417647898197174
Layer  5  loss:  0.15898945927619934 0.0 15.29653549194336
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([440, 242, 267, 370], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.15886437892913818
bi 1 loss 0.11223544180393219
bi 2 loss 0.17640450596809387
bi 3 loss 0.1653989553451538
Layer  6  loss:  0.12814711034297943 0.0 10.34408187866211
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([292, 267, 267, 352], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.14709970355033875
bi 1 loss 0.115678571164608
bi 2 loss 0.09382633864879608
bi 3 loss 0.14231178164482117
Epoch 0: :   3%|▎         | 15152/600000 [01:03<41:03, v_num=12, reduced_train_loss=39.30, global_step=15150.0, consumed_samples=60604.0, train_step_timing in s=0.461]Epoch 0: :   3%|▎         | 15152/600000 [01:03<41:03, v_num=12, reduced_train_loss=1.000, global_step=15151.0, consumed_samples=60608.0, train_step_timing in s=0.343]loss mask original None

First layer loss:  3.5918614864349365 torch.Size([540, 4]) 11.432528495788574 0.0
Max loss timestep torch.Size([540, 4]) tensor([180, 179, 244, 388], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 4.133432865142822
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 1 loss 3.3629212379455566
speech mask sum tensor(320, device='cuda:0') loss mask sum tensor(320, device='cuda:0')
bi 2 loss 3.2046141624450684
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
bi 3 loss 4.092378616333008
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
logits torch.Size([540, 4, 257024]) labels torch.Size([540, 4]) 0 257022
Layer  0  loss:  4.171220779418945 0.0 9.57503890991211
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([105, 178, 387, 252], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 4.423466682434082
bi 1 loss 4.114832878112793
bi 2 loss 4.0710248947143555
bi 3 loss 4.2117767333984375
Layer  1  loss:  4.47362756729126 0.0 9.394021034240723
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 89, 218, 243, 216], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 4.9089789390563965
bi 1 loss 4.414703845977783
bi 2 loss 4.219367504119873
bi 3 loss 4.636844158172607
Layer  2  loss:  4.736783981323242 0.0 10.078289985656738
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([226, 202, 266, 388], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 5.072138786315918
bi 1 loss 4.595463275909424
bi 2 loss 4.5113959312438965
bi 3 loss 5.021925449371338
Layer  3  loss:  4.842792987823486 0.0 10.473512649536133
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([183, 344, 399, 230], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 5.3117523193359375
bi 1 loss 4.814648151397705
bi 2 loss 4.511504650115967
bi 3 loss 5.074997425079346
Layer  4  loss:  4.9433465003967285 0.0 10.718175888061523
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([226, 184, 257, 256], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 5.282520294189453
bi 1 loss 4.755206108093262
bi 2 loss 4.648615837097168
bi 3 loss 5.395969390869141
Layer  5  loss:  5.022494792938232 0.0 10.158239364624023
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([ 76, 247, 319, 229], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 5.474369049072266
bi 1 loss 5.031393527984619
bi 2 loss 4.674885272979736
bi 3 loss 5.252934455871582
Layer  6  loss:  5.030920505523682 0.0 9.709182739257812
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([148, 379, 509, 399], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 5.393568992614746
bi 1 loss 4.961518287658691
bi 2 loss 4.70869779586792
bi 3 loss 5.376245975494385
Epoch 0: :   3%|▎         | 15153/600000 [01:04<41:18, v_num=12, reduced_train_loss=1.000, global_step=15151.0, consumed_samples=60608.0, train_step_timing in s=0.343]Epoch 0: :   3%|▎         | 15153/600000 [01:04<41:18, v_num=12, reduced_train_loss=36.80, global_step=15152.0, consumed_samples=60612.0, train_step_timing in s=0.347]loss mask original None

First layer loss:  0.02917543798685074 torch.Size([443, 4]) 0.5363336801528931 0.0
Max loss timestep torch.Size([443, 4]) tensor([191, 238, 403, 160], device='cuda:0') tensor(191, device='cuda:0')
bi 0 loss 0.02449987083673477
speech mask sum tensor(144, device='cuda:0') loss mask sum tensor(144, device='cuda:0')
bi 1 loss 0.02232498675584793
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 2 loss 0.03719602897763252
speech mask sum tensor(332, device='cuda:0') loss mask sum tensor(332, device='cuda:0')
bi 3 loss 0.01661086641252041
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
logits torch.Size([443, 4, 257024]) labels torch.Size([443, 4]) 0 257023
Layer  0  loss:  0.028706861659884453 0.0 0.5308750867843628
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1023
Curr loss timestep torch.Size([443, 4]) tensor([171, 209, 408, 148], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.02300635166466236
bi 1 loss 0.020588256418704987
bi 2 loss 0.03697807341814041
bi 3 loss 0.01748320274055004
Layer  1  loss:  0.028601014986634254 0.0 0.6167418956756592
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1023
Curr loss timestep torch.Size([443, 4]) tensor([192, 230, 362, 118], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.021671943366527557
bi 1 loss 0.020764125511050224
bi 2 loss 0.03596485033631325
bi 3 loss 0.02125290222465992
Layer  2  loss:  0.027112456038594246 0.0 0.5826901793479919
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([152, 232, 168, 128], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 0.022479070350527763
bi 1 loss 0.01971082203090191
bi 2 loss 0.033898692578077316
bi 3 loss 0.018314972519874573
Layer  3  loss:  0.024690676480531693 0.0 0.3949897885322571
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([134, 250, 179, 138], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 0.022281914949417114
bi 1 loss 0.03200278431177139
bi 2 loss 0.02588067017495632
bi 3 loss 0.019696515053510666
Layer  4  loss:  0.03201843425631523 0.0 1.0022441148757935
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([214, 246, 276, 113], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.028992274776101112
bi 1 loss 0.03650100901722908
bi 2 loss 0.03499108925461769
bi 3 loss 0.024536531418561935
Layer  5  loss:  0.02642153576016426 0.0 0.4185570776462555
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1019
Curr loss timestep torch.Size([443, 4]) tensor([199, 238, 422, 124], device='cuda:0') tensor(422, device='cuda:0')
bi 0 loss 0.025281690061092377
bi 1 loss 0.0155649958178401
bi 2 loss 0.0320257730782032
bi 3 loss 0.018853016197681427
Layer  6  loss:  0.0295542124658823 0.0 0.4499887228012085
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1021
Curr loss timestep torch.Size([443, 4]) tensor([205, 233, 404,  88], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.020529750734567642
bi 1 loss 0.03733105957508087
bi 2 loss 0.0331583246588707
bi 3 loss 0.025549743324518204
Epoch 0: :   3%|▎         | 15154/600000 [01:04<41:31, v_num=12, reduced_train_loss=36.80, global_step=15152.0, consumed_samples=60612.0, train_step_timing in s=0.347]Epoch 0: :   3%|▎         | 15154/600000 [01:04<41:31, v_num=12, reduced_train_loss=0.226, global_step=15153.0, consumed_samples=60616.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.09432065486907959 torch.Size([647, 4]) 9.168622016906738 0.0
Max loss timestep torch.Size([647, 4]) tensor([607, 180, 357, 259], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.11543016135692596
speech mask sum tensor(487, device='cuda:0') loss mask sum tensor(487, device='cuda:0')
bi 1 loss 0.03781973570585251
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 2 loss 0.2062341570854187
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
bi 3 loss 0.039179738610982895
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
logits torch.Size([647, 4, 257024]) labels torch.Size([647, 4]) 0 257022
Layer  0  loss:  0.11079750955104828 0.0 8.003561019897461
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([610, 208, 357, 260], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.15612000226974487
bi 1 loss 0.03755374997854233
bi 2 loss 0.16804784536361694
bi 3 loss 0.03157450258731842
Layer  1  loss:  0.11314372718334198 0.0 8.163952827453613
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([617, 194, 354, 249], device='cuda:0') tensor(617, device='cuda:0')
bi 0 loss 0.1583903729915619
bi 1 loss 0.038360726088285446
bi 2 loss 0.16794246435165405
bi 3 loss 0.03754862770438194
Layer  2  loss:  0.13286051154136658 0.0 9.399985313415527
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([605,  51, 354, 274], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.1821105182170868
bi 1 loss 0.036819711327552795
bi 2 loss 0.24555456638336182
bi 3 loss 0.04015792906284332
Layer  3  loss:  0.11095888167619705 0.0 11.313950538635254
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1021
Curr loss timestep torch.Size([647, 4]) tensor([610, 219, 354, 266], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.14730826020240784
bi 1 loss 0.03805576637387276
bi 2 loss 0.23035094141960144
bi 3 loss 0.024962592869997025
Layer  4  loss:  0.12729781866073608 0.0 14.255156517028809
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([610, 160, 354, 268], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.18092530965805054
bi 1 loss 0.038217928260564804
bi 2 loss 0.1976795196533203
bi 3 loss 0.03525057062506676
Layer  5  loss:  0.1066015213727951 0.0 8.941116333007812
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([530, 184, 357, 221], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.14412569999694824
bi 1 loss 0.03257580101490021
bi 2 loss 0.2204829603433609
bi 3 loss 0.021439945325255394
Layer  6  loss:  0.14136290550231934 0.0 9.966938018798828
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([530, 128, 354, 199], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.20252662897109985
bi 1 loss 0.03402504697442055
bi 2 loss 0.24475456774234772
bi 3 loss 0.030998285859823227
Epoch 0: :   3%|▎         | 15155/600000 [01:05<41:49, v_num=12, reduced_train_loss=0.226, global_step=15153.0, consumed_samples=60616.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15155/600000 [01:05<41:50, v_num=12, reduced_train_loss=0.937, global_step=15154.0, consumed_samples=60620.0, train_step_timing in s=0.437]loss mask original None

First layer loss:  0.20862646400928497 torch.Size([623, 4]) 10.552838325500488 0.0
Max loss timestep torch.Size([623, 4]) tensor([105, 313, 557, 305], device='cuda:0') tensor(557, device='cuda:0')
bi 0 loss 0.02024994231760502
speech mask sum tensor(51, device='cuda:0') loss mask sum tensor(51, device='cuda:0')
bi 1 loss 0.2255578190088272
speech mask sum tensor(392, device='cuda:0') loss mask sum tensor(392, device='cuda:0')
bi 2 loss 0.2518981993198395
speech mask sum tensor(478, device='cuda:0') loss mask sum tensor(478, device='cuda:0')
bi 3 loss 0.13451024889945984
speech mask sum tensor(239, device='cuda:0') loss mask sum tensor(239, device='cuda:0')
logits torch.Size([623, 4, 257024]) labels torch.Size([623, 4]) 0 257022
Layer  0  loss:  0.26192590594291687 0.0 13.76460075378418
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([104, 280, 287, 296], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.050382986664772034
bi 1 loss 0.24238236248493195
bi 2 loss 0.3152828514575958
bi 3 loss 0.2324075996875763
Layer  1  loss:  0.2595454752445221 0.0 11.365771293640137
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([110, 281, 557, 452], device='cuda:0') tensor(557, device='cuda:0')
bi 0 loss 0.023346690461039543
bi 1 loss 0.2334454208612442
bi 2 loss 0.30523681640625
bi 3 loss 0.26137351989746094
Layer  2  loss:  0.28307563066482544 0.0 13.090362548828125
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([ 98, 281, 295, 291], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.10380371659994125
bi 1 loss 0.23912958800792694
bi 2 loss 0.28661540150642395
bi 3 loss 0.3863295912742615
Layer  3  loss:  0.32845601439476013 0.0 10.42292594909668
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([ 87, 280, 287, 305], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.01863928511738777
bi 1 loss 0.2443280965089798
bi 2 loss 0.3934849798679352
bi 3 loss 0.40249353647232056
Layer  4  loss:  0.28889012336730957 0.0 14.114946365356445
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([105, 313, 289, 326], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.038849059492349625
bi 1 loss 0.2608335018157959
bi 2 loss 0.27682504057884216
bi 3 loss 0.41239380836486816
Layer  5  loss:  0.2682739198207855 0.0 12.289970397949219
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([ 94, 280, 557, 328], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.04791787266731262
bi 1 loss 0.24128539860248566
bi 2 loss 0.30241528153419495
bi 3 loss 0.291278600692749
Layer  6  loss:  0.30168840289115906 0.0 14.783793449401855
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([ 97, 313, 295, 452], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.04110647737979889
bi 1 loss 0.21158841252326965
bi 2 loss 0.3643074333667755
bi 3 loss 0.379834920167923
Epoch 0: :   3%|▎         | 15156/600000 [01:05<42:07, v_num=12, reduced_train_loss=0.937, global_step=15154.0, consumed_samples=60620.0, train_step_timing in s=0.437]Epoch 0: :   3%|▎         | 15156/600000 [01:05<42:07, v_num=12, reduced_train_loss=2.200, global_step=15155.0, consumed_samples=60624.0, train_step_timing in s=0.422]loss mask original None

First layer loss:  0.048258911818265915 torch.Size([402, 4]) 4.126506328582764 0.0
Max loss timestep torch.Size([402, 4]) tensor([308, 213,  61, 251], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.06394679099321365
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
bi 1 loss 0.0272589810192585
speech mask sum tensor(84, device='cuda:0') loss mask sum tensor(84, device='cuda:0')
bi 2 loss 0.028612317517399788
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.049886900931596756
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
logits torch.Size([402, 4, 257024]) labels torch.Size([402, 4]) 0 257023
Layer  0  loss:  0.0419490672647953 0.0 1.758406639099121
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1023
Curr loss timestep torch.Size([402, 4]) tensor([202, 197,  56, 281], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 0.05556245893239975
bi 1 loss 0.028061319142580032
bi 2 loss 0.024200817570090294
bi 3 loss 0.042195215821266174
Layer  1  loss:  0.05730624124407768 0.0 3.3378429412841797
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1023
Curr loss timestep torch.Size([402, 4]) tensor([377, 211, 131, 383], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.07244604080915451
bi 1 loss 0.04829118773341179
bi 2 loss 0.038612350821495056
bi 3 loss 0.05472937226295471
Layer  2  loss:  0.0650554746389389 0.0 5.325876235961914
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1022
Curr loss timestep torch.Size([402, 4]) tensor([308, 198, 100, 382], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 0.06611032038927078
bi 1 loss 0.05063321068882942
bi 2 loss 0.03497309237718582
bi 3 loss 0.08527319133281708
Layer  3  loss:  0.0483354777097702 0.0 3.4187095165252686
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1022
Curr loss timestep torch.Size([402, 4]) tensor([308, 215, 131, 383], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.0591297373175621
bi 1 loss 0.04735784977674484
bi 2 loss 0.02680434286594391
bi 3 loss 0.04897273704409599
Layer  4  loss:  0.05617525428533554 0.0 6.1934895515441895
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1023
Curr loss timestep torch.Size([402, 4]) tensor([308, 216,  81, 383], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.07037496566772461
bi 1 loss 0.018676882609725
bi 2 loss 0.04437895491719246
bi 3 loss 0.06100856512784958
Layer  5  loss:  0.05337822437286377 0.0 3.914276361465454
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1022
Curr loss timestep torch.Size([402, 4]) tensor([322, 209, 114, 382], device='cuda:0') tensor(114, device='cuda:0')
bi 0 loss 0.0460052564740181
bi 1 loss 0.021427419036626816
bi 2 loss 0.06259926408529282
bi 3 loss 0.06750500202178955
Layer  6  loss:  0.05925718694925308 0.0 8.8087158203125
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1023
Curr loss timestep torch.Size([402, 4]) tensor([308, 158, 146, 382], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.0764416977763176
bi 1 loss 0.022891957312822342
bi 2 loss 0.036179348826408386
bi 3 loss 0.06663425266742706
Epoch 0: :   3%|▎         | 15157/600000 [01:05<42:20, v_num=12, reduced_train_loss=2.200, global_step=15155.0, consumed_samples=60624.0, train_step_timing in s=0.422]Epoch 0: :   3%|▎         | 15157/600000 [01:05<42:20, v_num=12, reduced_train_loss=0.430, global_step=15156.0, consumed_samples=60628.0, train_step_timing in s=0.299]loss mask original None

First layer loss:  0.08401467651128769 torch.Size([445, 4]) 8.269501686096191 0.0
Max loss timestep torch.Size([445, 4]) tensor([341, 274, 103, 361], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.0745372399687767
speech mask sum tensor(292, device='cuda:0') loss mask sum tensor(292, device='cuda:0')
bi 1 loss 0.1056765466928482
speech mask sum tensor(345, device='cuda:0') loss mask sum tensor(345, device='cuda:0')
bi 2 loss 0.0656457394361496
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
bi 3 loss 0.07701098918914795
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
logits torch.Size([445, 4, 257024]) labels torch.Size([445, 4]) 0 257023
Layer  0  loss:  0.09718947857618332 0.0 7.126221656799316
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([341, 274, 158, 425], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.07760310173034668
bi 1 loss 0.11502224206924438
bi 2 loss 0.059720445424318314
bi 3 loss 0.1146199032664299
Layer  1  loss:  0.1018168032169342 0.0 8.063767433166504
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([339, 274, 120, 359], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.054957762360572815
bi 1 loss 0.13911136984825134
bi 2 loss 0.02926243096590042
bi 3 loss 0.14129485189914703
Layer  2  loss:  0.12666568160057068 0.0 7.773615837097168
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([292, 274, 187, 425], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.10736142843961716
bi 1 loss 0.15119734406471252
bi 2 loss 0.05943087860941887
bi 3 loss 0.15085145831108093
Layer  3  loss:  0.10697242617607117 0.0 10.714733123779297
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1021
Curr loss timestep torch.Size([445, 4]) tensor([340, 274, 130, 425], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.08224903792142868
bi 1 loss 0.15030619502067566
bi 2 loss 0.0480775460600853
bi 3 loss 0.1099749356508255
Layer  4  loss:  0.10406342893838882 0.0 12.561382293701172
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1021
Curr loss timestep torch.Size([445, 4]) tensor([340, 274, 110, 268], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.09599970281124115
bi 1 loss 0.13924288749694824
bi 2 loss 0.04907296597957611
bi 3 loss 0.09799528867006302
Layer  5  loss:  0.10179074108600616 0.0 6.7653679847717285
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([340, 275, 109, 425], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.09575417637825012
bi 1 loss 0.12369247525930405
bi 2 loss 0.044509176164865494
bi 3 loss 0.1106824055314064
Layer  6  loss:  0.1121920794248581 0.0 6.149294376373291
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([340, 274, 152, 425], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.08269140869379044
bi 1 loss 0.14001232385635376
bi 2 loss 0.03865739703178406
bi 3 loss 0.1459369957447052
Epoch 0: :   3%|▎         | 15158/600000 [01:06<42:33, v_num=12, reduced_train_loss=0.430, global_step=15156.0, consumed_samples=60628.0, train_step_timing in s=0.299]Epoch 0: :   3%|▎         | 15158/600000 [01:06<42:33, v_num=12, reduced_train_loss=0.835, global_step=15157.0, consumed_samples=60632.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.15149541199207306 torch.Size([729, 4]) 10.326502799987793 0.0
Max loss timestep torch.Size([729, 4]) tensor([179,  67, 283, 693], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 0.1403040885925293
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
bi 1 loss 0.049646299332380295
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 2 loss 0.11519782990217209
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 3 loss 0.25107669830322266
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
logits torch.Size([729, 4, 257024]) labels torch.Size([729, 4]) 0 257023
Layer  0  loss:  0.1572566032409668 0.0 9.306286811828613
logits torch.Size([729, 4, 1024]) labels torch.Size([729, 4]) 0 1023
Curr loss timestep torch.Size([729, 4]) tensor([347, 223, 283, 689], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.11156301200389862
bi 1 loss 0.03435897454619408
bi 2 loss 0.1137983426451683
bi 3 loss 0.3111969828605652
Layer  1  loss:  0.1552685797214508 0.0 14.997987747192383
logits torch.Size([729, 4, 1024]) labels torch.Size([729, 4]) 0 1023
Curr loss timestep torch.Size([729, 4]) tensor([418, 199, 363, 693], device='cuda:0') tensor(693, device='cuda:0')
bi 0 loss 0.11209826916456223
bi 1 loss 0.035145554691553116
bi 2 loss 0.09725586324930191
bi 3 loss 0.32039159536361694
Layer  2  loss:  0.1652829945087433 0.0 12.408217430114746
logits torch.Size([729, 4, 1024]) labels torch.Size([729, 4]) 0 1022
Curr loss timestep torch.Size([729, 4]) tensor([466, 213, 283, 524], device='cuda:0') tensor(524, device='cuda:0')
bi 0 loss 0.08155281096696854
bi 1 loss 0.06681263446807861
bi 2 loss 0.12824830412864685
bi 3 loss 0.3409077823162079
Layer  3  loss:  0.19683055579662323 0.0 17.877870559692383
logits torch.Size([729, 4, 1024]) labels torch.Size([729, 4]) 0 1023
Curr loss timestep torch.Size([729, 4]) tensor([347,  72, 283, 693], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.12631694972515106
bi 1 loss 0.0727137103676796
bi 2 loss 0.14714349806308746
bi 3 loss 0.3841983675956726
Layer  4  loss:  0.1652240753173828 0.0 10.326536178588867
logits torch.Size([729, 4, 1024]) labels torch.Size([729, 4]) 0 1023
Curr loss timestep torch.Size([729, 4]) tensor([416, 171, 284, 610], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.07783139497041702
bi 1 loss 0.04542664438486099
bi 2 loss 0.15729576349258423
bi 3 loss 0.32472851872444153
Layer  5  loss:  0.17642468214035034 0.0 17.09213638305664
logits torch.Size([729, 4, 1024]) labels torch.Size([729, 4]) 0 1023
Curr loss timestep torch.Size([729, 4]) tensor([418, 207, 283, 693], device='cuda:0') tensor(693, device='cuda:0')
bi 0 loss 0.1266544759273529
bi 1 loss 0.048997387290000916
bi 2 loss 0.1333160102367401
bi 3 loss 0.33653613924980164
Layer  6  loss:  0.1645582616329193 0.0 15.937325477600098
logits torch.Size([729, 4, 1024]) labels torch.Size([729, 4]) 0 1022
Curr loss timestep torch.Size([729, 4]) tensor([288,  96, 283, 693], device='cuda:0') tensor(693, device='cuda:0')
bi 0 loss 0.09001648426055908
bi 1 loss 0.05222778394818306
bi 2 loss 0.11828695982694626
bi 3 loss 0.3468675911426544
Epoch 0: :   3%|▎         | 15159/600000 [01:06<42:54, v_num=12, reduced_train_loss=0.835, global_step=15157.0, consumed_samples=60632.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15159/600000 [01:06<42:54, v_num=12, reduced_train_loss=1.330, global_step=15158.0, consumed_samples=60636.0, train_step_timing in s=0.502]loss mask original None

First layer loss:  0.03239068016409874 torch.Size([382, 4]) 1.2728818655014038 0.0
Max loss timestep torch.Size([382, 4]) tensor([ 69, 276,  59, 341], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 0.022891946136951447
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
bi 1 loss 0.02732996456325054
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 2 loss 0.02020915597677231
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
bi 3 loss 0.04652734845876694
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
logits torch.Size([382, 4, 257024]) labels torch.Size([382, 4]) 0 257022
Layer  0  loss:  0.04059520736336708 0.0 3.3769118785858154
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1023
Curr loss timestep torch.Size([382, 4]) tensor([ 82, 289,  43, 341], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 0.0338161364197731
bi 1 loss 0.04787055030465126
bi 2 loss 0.018484340980648994
bi 3 loss 0.043136801570653915
Layer  1  loss:  0.04771317541599274 0.0 5.7170515060424805
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1022
Curr loss timestep torch.Size([382, 4]) tensor([ 69, 288,  67, 339], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.02237602323293686
bi 1 loss 0.06288795918226242
bi 2 loss 0.040184732526540756
bi 3 loss 0.04258574917912483
Layer  2  loss:  0.039846573024988174 0.0 2.530536413192749
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1022
Curr loss timestep torch.Size([382, 4]) tensor([ 86, 289,  66, 323], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.024760453030467033
bi 1 loss 0.04650892689824104
bi 2 loss 0.024785280227661133
bi 3 loss 0.043579451739788055
Layer  3  loss:  0.0326693058013916 0.0 1.1309031248092651
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1021
Curr loss timestep torch.Size([382, 4]) tensor([ 67, 264,  52, 341], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.026965828612446785
bi 1 loss 0.03454073145985603
bi 2 loss 0.02307617850601673
bi 3 loss 0.03631746768951416
Layer  4  loss:  0.037358563393354416 0.0 3.008175849914551
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1022
Curr loss timestep torch.Size([382, 4]) tensor([ 39, 289,  43, 339], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.021379925310611725
bi 1 loss 0.043413229286670685
bi 2 loss 0.024840740486979485
bi 3 loss 0.04116929695010185
Layer  5  loss:  0.03655572235584259 0.0 1.420708179473877
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1020
Curr loss timestep torch.Size([382, 4]) tensor([ 89, 264,  72, 341], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.03197818621993065
bi 1 loss 0.03964349627494812
bi 2 loss 0.018633536994457245
bi 3 loss 0.04153227061033249
Layer  6  loss:  0.03652622923254967 0.0 1.3241610527038574
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1022
Curr loss timestep torch.Size([382, 4]) tensor([ 84, 232,  53, 339], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.015192610211670399
bi 1 loss 0.03234592452645302
bi 2 loss 0.017413297668099403
bi 3 loss 0.0567840039730072
Epoch 0: :   3%|▎         | 15160/600000 [01:07<43:06, v_num=12, reduced_train_loss=1.330, global_step=15158.0, consumed_samples=60636.0, train_step_timing in s=0.502]Epoch 0: :   3%|▎         | 15160/600000 [01:07<43:07, v_num=12, reduced_train_loss=0.304, global_step=15159.0, consumed_samples=60640.0, train_step_timing in s=0.290]loss mask original None

First layer loss:  0.057795293629169464 torch.Size([447, 4]) 9.683517456054688 0.0
Max loss timestep torch.Size([447, 4]) tensor([137, 312, 266, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.03739083930850029
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 1 loss 0.0301580261439085
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 2 loss 0.029932593926787376
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
bi 3 loss 0.09841226786375046
speech mask sum tensor(365, device='cuda:0') loss mask sum tensor(365, device='cuda:0')
logits torch.Size([447, 4, 257024]) labels torch.Size([447, 4]) 0 257022
Layer  0  loss:  0.0637359619140625 0.0 12.202983856201172
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([192, 168, 262, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.04227970540523529
bi 1 loss 0.03125835210084915
bi 2 loss 0.023906351998448372
bi 3 loss 0.11200576275587082
Layer  1  loss:  0.07024354487657547 0.0 13.696155548095703
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([ 73, 231, 197, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.04242873191833496
bi 1 loss 0.019393881782889366
bi 2 loss 0.02389383688569069
bi 3 loss 0.1363629251718521
Layer  2  loss:  0.07816939055919647 0.0 14.31424331665039
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([282, 234, 201, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.039898280054330826
bi 1 loss 0.03404190018773079
bi 2 loss 0.04538949951529503
bi 3 loss 0.143225759267807
Layer  3  loss:  0.06250420212745667 0.0 7.634613037109375
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1021
Curr loss timestep torch.Size([447, 4]) tensor([269, 237, 194, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.030616017058491707
bi 1 loss 0.03692670166492462
bi 2 loss 0.03293554112315178
bi 3 loss 0.1106826588511467
Layer  4  loss:  0.06692804396152496 0.0 11.13272762298584
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([161, 119, 285, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.03973124548792839
bi 1 loss 0.021722018718719482
bi 2 loss 0.033138763159513474
bi 3 loss 0.12502282857894897
Layer  5  loss:  0.06413087993860245 0.0 9.251471519470215
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([225, 296, 239, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.042162034660577774
bi 1 loss 0.03147360309958458
bi 2 loss 0.024254901334643364
bi 3 loss 0.11289277672767639
Layer  6  loss:  0.05893551558256149 0.0 9.295897483825684
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([269, 228, 239, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.03838258981704712
bi 1 loss 0.031098555773496628
bi 2 loss 0.023001354187726974
bi 3 loss 0.10245569050312042
Epoch 0: :   3%|▎         | 15161/600000 [01:07<43:20, v_num=12, reduced_train_loss=0.304, global_step=15159.0, consumed_samples=60640.0, train_step_timing in s=0.290]Epoch 0: :   3%|▎         | 15161/600000 [01:07<43:20, v_num=12, reduced_train_loss=0.522, global_step=15160.0, consumed_samples=60644.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.027407575398683548 torch.Size([430, 4]) 0.34705865383148193 0.0
Max loss timestep torch.Size([430, 4]) tensor([ 77, 145, 270, 286], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 0.025014499202370644
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 0.02209732122719288
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 2 loss 0.03914891183376312
speech mask sum tensor(192, device='cuda:0') loss mask sum tensor(192, device='cuda:0')
bi 3 loss 0.02348249778151512
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
logits torch.Size([430, 4, 257024]) labels torch.Size([430, 4]) 0 257022
Layer  0  loss:  0.02250669337809086 0.0 0.43640953302383423
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1023
Curr loss timestep torch.Size([430, 4]) tensor([ 73,  77, 334, 171], device='cuda:0') tensor(77, device='cuda:0')
bi 0 loss 0.022794121876358986
bi 1 loss 0.016905903816223145
bi 2 loss 0.03127153217792511
bi 3 loss 0.019947774708271027
Layer  1  loss:  0.02449052967131138 0.0 1.8933541774749756
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1022
Curr loss timestep torch.Size([430, 4]) tensor([110, 146, 338, 241], device='cuda:0') tensor(146, device='cuda:0')
bi 0 loss 0.018159963190555573
bi 1 loss 0.0293666273355484
bi 2 loss 0.0321427546441555
bi 3 loss 0.01720731146633625
Layer  2  loss:  0.024366021156311035 0.0 0.5070072412490845
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1022
Curr loss timestep torch.Size([430, 4]) tensor([ 70, 120, 369, 173], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 0.02023971453309059
bi 1 loss 0.02233714982867241
bi 2 loss 0.02879289723932743
bi 3 loss 0.024486491456627846
Layer  3  loss:  0.02145363949239254 0.0 0.4214373528957367
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1021
Curr loss timestep torch.Size([430, 4]) tensor([153, 158, 268, 256], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.0112212635576725
bi 1 loss 0.01935032196342945
bi 2 loss 0.0297503974288702
bi 3 loss 0.021463459357619286
Layer  4  loss:  0.023980455473065376 0.0 0.6255305409431458
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1022
Curr loss timestep torch.Size([430, 4]) tensor([102, 247, 392, 213], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 0.01964993216097355
bi 1 loss 0.021166926249861717
bi 2 loss 0.03201741725206375
bi 3 loss 0.021915800869464874
Layer  5  loss:  0.024917852133512497 0.0 0.36512136459350586
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1017
Curr loss timestep torch.Size([430, 4]) tensor([ 98, 238, 269, 251], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.02266816422343254
bi 1 loss 0.02521568164229393
bi 2 loss 0.03105795942246914
bi 3 loss 0.020749956369400024
Layer  6  loss:  0.02112056314945221 0.0 0.29660263657569885
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1022
Curr loss timestep torch.Size([430, 4]) tensor([126, 246, 396, 226], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.017881006002426147
bi 1 loss 0.01721101626753807
bi 2 loss 0.0282824095338583
bi 3 loss 0.020165134221315384
Epoch 0: :   3%|▎         | 15162/600000 [01:07<43:33, v_num=12, reduced_train_loss=0.522, global_step=15160.0, consumed_samples=60644.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15162/600000 [01:07<43:33, v_num=12, reduced_train_loss=0.190, global_step=15161.0, consumed_samples=60648.0, train_step_timing in s=0.311]loss mask original None

First layer loss:  4.013613700866699 torch.Size([556, 4]) 12.596012115478516 0.0
Max loss timestep torch.Size([556, 4]) tensor([286, 117, 419, 245], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 4.045316219329834
speech mask sum tensor(463, device='cuda:0') loss mask sum tensor(463, device='cuda:0')
bi 1 loss 3.5927155017852783
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 2 loss 4.350142002105713
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 3 loss 3.6030778884887695
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
logits torch.Size([556, 4, 257024]) labels torch.Size([556, 4]) 0 257022
Layer  0  loss:  4.7351393699646 0.0 12.011344909667969
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([101, 246, 421, 285], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 4.847226142883301
bi 1 loss 4.242241382598877
bi 2 loss 5.0509490966796875
bi 3 loss 4.230775356292725
Layer  1  loss:  4.874682903289795 0.0 10.038036346435547
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([409, 250, 465, 250], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 4.948163032531738
bi 1 loss 4.361409664154053
bi 2 loss 5.249797821044922
bi 3 loss 4.358254432678223
Layer  2  loss:  5.13787317276001 0.0 10.693534851074219
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([296, 144, 199, 293], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 5.285555839538574
bi 1 loss 4.565371513366699
bi 2 loss 5.489494800567627
bi 3 loss 4.532954692840576
Layer  3  loss:  5.196447849273682 0.0 10.294289588928223
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([396, 140, 484, 261], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 5.335661888122559
bi 1 loss 4.598969459533691
bi 2 loss 5.559523105621338
bi 3 loss 4.655745029449463
Layer  4  loss:  5.367042064666748 0.0 11.208362579345703
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([111, 107, 429, 298], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 5.480104446411133
bi 1 loss 4.92392110824585
bi 2 loss 5.635505676269531
bi 3 loss 4.921273708343506
Layer  5  loss:  5.351644515991211 0.0 10.014947891235352
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([318, 148, 331, 255], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 5.455692291259766
bi 1 loss 4.91815185546875
bi 2 loss 5.645583629608154
bi 3 loss 4.809638023376465
Layer  6  loss:  5.46261739730835 0.0 10.262045860290527
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([381, 111, 487, 285], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 5.6037917137146
bi 1 loss 4.9469218254089355
bi 2 loss 5.789163112640381
bi 3 loss 4.834275722503662
High loss detected
Logging training audio
Epoch 0: :   3%|▎         | 15163/600000 [01:08<43:58, v_num=12, reduced_train_loss=0.190, global_step=15161.0, consumed_samples=60648.0, train_step_timing in s=0.311]Epoch 0: :   3%|▎         | 15163/600000 [01:08<43:58, v_num=12, reduced_train_loss=40.10, global_step=15162.0, consumed_samples=60652.0, train_step_timing in s=0.597]loss mask original None

First layer loss:  0.06300613284111023 torch.Size([617, 4]) 5.781867980957031 0.0
Max loss timestep torch.Size([617, 4]) tensor([414, 125, 267, 331], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.07773296535015106
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 1 loss 0.044525984674692154
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
bi 2 loss 0.03428306803107262
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 3 loss 0.06935383379459381
speech mask sum tensor(487, device='cuda:0') loss mask sum tensor(487, device='cuda:0')
logits torch.Size([617, 4, 257024]) labels torch.Size([617, 4]) 0 257023
Layer  0  loss:  0.05983242392539978 0.0 5.988178253173828
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([199, 182, 268, 404], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 0.06967941671609879
bi 1 loss 0.04792365804314613
bi 2 loss 0.05588274449110031
bi 3 loss 0.056954044848680496
Layer  1  loss:  0.07236912101507187 0.0 6.87952184677124
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([414, 169, 147, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.07521907985210419
bi 1 loss 0.04603298753499985
bi 2 loss 0.03968290984630585
bi 3 loss 0.09298292547464371
Layer  2  loss:  0.08635123074054718 0.0 4.511836528778076
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([143, 172, 264, 431], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.07471495121717453
bi 1 loss 0.05260257050395012
bi 2 loss 0.050153519958257675
bi 3 loss 0.12309618294239044
Layer  3  loss:  0.07106634229421616 0.0 7.813384056091309
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([320, 177, 227, 210], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.08924415707588196
bi 1 loss 0.0654400959610939
bi 2 loss 0.04480321332812309
bi 3 loss 0.06943538784980774
Layer  4  loss:  0.05981534719467163 0.0 4.924310207366943
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([414, 102, 228, 512], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.08031219244003296
bi 1 loss 0.045789603143930435
bi 2 loss 0.04446412995457649
bi 3 loss 0.05379575490951538
Layer  5  loss:  0.09145031869411469 0.0 4.001593589782715
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([414, 129, 100, 370], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.07901908457279205
bi 1 loss 0.06375245749950409
bi 2 loss 0.05374565348029137
bi 3 loss 0.12770655751228333
Layer  6  loss:  0.07338191568851471 0.0 4.885944843292236
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([320, 205, 254, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.06692259758710861
bi 1 loss 0.05353521183133125
bi 2 loss 0.02956254407763481
bi 3 loss 0.10498380661010742
Epoch 0: :   3%|▎         | 15164/600000 [01:08<44:15, v_num=12, reduced_train_loss=40.10, global_step=15162.0, consumed_samples=60652.0, train_step_timing in s=0.597]Epoch 0: :   3%|▎         | 15164/600000 [01:08<44:15, v_num=12, reduced_train_loss=0.577, global_step=15163.0, consumed_samples=60656.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.2177945077419281 torch.Size([658, 4]) 14.316251754760742 0.0
Max loss timestep torch.Size([658, 4]) tensor([527, 107, 153, 546], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.19676551222801208
speech mask sum tensor(454, device='cuda:0') loss mask sum tensor(454, device='cuda:0')
bi 1 loss 0.030503667891025543
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 2 loss 0.06486257165670395
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 0.3130471110343933
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
logits torch.Size([658, 4, 257024]) labels torch.Size([658, 4]) 0 257022
Layer  0  loss:  0.26482093334198 0.0 14.074270248413086
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([304,  71, 165, 615], device='cuda:0') tensor(615, device='cuda:0')
bi 0 loss 0.23739197850227356
bi 1 loss 0.11493641138076782
bi 2 loss 0.06341631710529327
bi 3 loss 0.3733053505420685
Layer  1  loss:  0.2812265157699585 0.0 12.343786239624023
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([308,  92, 226, 615], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.23478662967681885
bi 1 loss 0.03778775781393051
bi 2 loss 0.07630440592765808
bi 3 loss 0.4250166714191437
Layer  2  loss:  0.30514588952064514 0.0 12.019598007202148
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([448,  77, 184, 546], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.25861653685569763
bi 1 loss 0.040789585560560226
bi 2 loss 0.044251371175050735
bi 3 loss 0.468304842710495
Layer  3  loss:  0.2764415442943573 0.0 10.830225944519043
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1021
Curr loss timestep torch.Size([658, 4]) tensor([278,  93, 166, 615], device='cuda:0') tensor(615, device='cuda:0')
bi 0 loss 0.23146279156208038
bi 1 loss 0.04856736585497856
bi 2 loss 0.04799067601561546
bi 3 loss 0.422736257314682
Layer  4  loss:  0.283974289894104 0.0 16.225618362426758
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([308,  79, 170, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.25902870297431946
bi 1 loss 0.025445301085710526
bi 2 loss 0.08274157345294952
bi 3 loss 0.4087924063205719
Layer  5  loss:  0.32114261388778687 0.0 14.454446792602539
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([443,  93, 146, 274], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.22076526284217834
bi 1 loss 0.03588078171014786
bi 2 loss 0.062288425862789154
bi 3 loss 0.5388066172599792
Layer  6  loss:  0.2958433926105499 0.0 13.310250282287598
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([308,  85, 216, 542], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.24407067894935608
bi 1 loss 0.03485498204827309
bi 2 loss 0.04903829097747803
bi 3 loss 0.4594874680042267
Epoch 0: :   3%|▎         | 15165/600000 [01:09<44:34, v_num=12, reduced_train_loss=0.577, global_step=15163.0, consumed_samples=60656.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15165/600000 [01:09<44:34, v_num=12, reduced_train_loss=2.250, global_step=15164.0, consumed_samples=60660.0, train_step_timing in s=0.464]loss mask original None

First layer loss:  0.143991157412529 torch.Size([622, 4]) 9.053552627563477 0.0
Max loss timestep torch.Size([622, 4]) tensor([303, 283, 530, 384], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.07083779573440552
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
bi 1 loss 0.09231144189834595
speech mask sum tensor(288, device='cuda:0') loss mask sum tensor(288, device='cuda:0')
bi 2 loss 0.2216271609067917
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
bi 3 loss 0.13869041204452515
speech mask sum tensor(477, device='cuda:0') loss mask sum tensor(477, device='cuda:0')
logits torch.Size([622, 4, 257024]) labels torch.Size([622, 4]) 0 257023
Layer  0  loss:  0.16416536271572113 0.0 11.194334030151367
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([266, 296, 594, 521], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.06997408717870712
bi 1 loss 0.08706692606210709
bi 2 loss 0.24268284440040588
bi 3 loss 0.18354091048240662
Layer  1  loss:  0.1835458129644394 0.0 14.603257179260254
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([347, 313, 530, 457], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.1373419165611267
bi 1 loss 0.10786930471658707
bi 2 loss 0.2992423474788666
bi 3 loss 0.1445511132478714
Layer  2  loss:  0.1672152578830719 0.0 11.141942977905273
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([348, 442, 594, 506], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.14491407573223114
bi 1 loss 0.08116418868303299
bi 2 loss 0.23739370703697205
bi 3 loss 0.16504181921482086
Layer  3  loss:  0.1889633983373642 0.0 12.189623832702637
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([343, 431, 530, 508], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.2444419264793396
bi 1 loss 0.11281698197126389
bi 2 loss 0.26714134216308594
bi 3 loss 0.13591019809246063
Layer  4  loss:  0.17162975668907166 0.0 8.422372817993164
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([258, 282, 594, 457], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.22101818025112152
bi 1 loss 0.09235914796590805
bi 2 loss 0.2293519824743271
bi 3 loss 0.14231127500534058
Layer  5  loss:  0.19932258129119873 0.0 15.312516212463379
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([343, 286, 529, 506], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.21536879241466522
bi 1 loss 0.0835777223110199
bi 2 loss 0.28247836232185364
bi 3 loss 0.1845892071723938
Layer  6  loss:  0.18596850335597992 0.0 12.846207618713379
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([346, 398, 529, 535], device='cuda:0') tensor(529, device='cuda:0')
bi 0 loss 0.21417158842086792
bi 1 loss 0.08056973665952682
bi 2 loss 0.2959821820259094
bi 3 loss 0.1342957764863968
Epoch 0: :   3%|▎         | 15166/600000 [01:09<44:51, v_num=12, reduced_train_loss=2.250, global_step=15164.0, consumed_samples=60660.0, train_step_timing in s=0.464]Epoch 0: :   3%|▎         | 15166/600000 [01:09<44:51, v_num=12, reduced_train_loss=1.400, global_step=15165.0, consumed_samples=60664.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  3.8097429275512695 torch.Size([368, 4]) 14.453507423400879 0.0
Max loss timestep torch.Size([368, 4]) tensor([329, 161, 109, 286], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.317140102386475
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 1 loss 4.057046890258789
speech mask sum tensor(210, device='cuda:0') loss mask sum tensor(210, device='cuda:0')
bi 2 loss 3.594132423400879
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 3 loss 3.1905763149261475
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
logits torch.Size([368, 4, 257024]) labels torch.Size([368, 4]) 0 257022
Layer  0  loss:  4.2031168937683105 0.0 10.387035369873047
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1023
Curr loss timestep torch.Size([368, 4]) tensor([194, 236, 189, 288], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.805968761444092
bi 1 loss 4.216005802154541
bi 2 loss 3.7927706241607666
bi 3 loss 3.9025638103485107
Layer  1  loss:  4.507073402404785 0.0 9.75731086730957
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1022
Curr loss timestep torch.Size([368, 4]) tensor([207, 184, 127, 310], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.858016014099121
bi 1 loss 4.652791976928711
bi 2 loss 4.024729251861572
bi 3 loss 4.386080265045166
Layer  2  loss:  4.878561019897461 0.0 9.388437271118164
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1022
Curr loss timestep torch.Size([368, 4]) tensor([240, 223, 158, 339], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 5.148334980010986
bi 1 loss 5.133064270019531
bi 2 loss 4.692762851715088
bi 3 loss 4.475240707397461
Layer  3  loss:  4.924749374389648 0.0 10.203015327453613
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1023
Curr loss timestep torch.Size([368, 4]) tensor([329, 263, 159, 214], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 5.01527738571167
bi 1 loss 5.191730976104736
bi 2 loss 4.683732509613037
bi 3 loss 4.741805076599121
Layer  4  loss:  5.034648895263672 0.0 9.503644943237305
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1023
Curr loss timestep torch.Size([368, 4]) tensor([256, 222, 129, 313], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 5.2149200439453125
bi 1 loss 5.19136905670166
bi 2 loss 4.790111541748047
bi 3 loss 4.880706310272217
Layer  5  loss:  5.10805606842041 0.0 9.670591354370117
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1022
Curr loss timestep torch.Size([368, 4]) tensor([225, 274,  84, 193], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 5.3076043128967285
bi 1 loss 5.325567245483398
bi 2 loss 4.900261878967285
bi 3 loss 4.836948871612549
Layer  6  loss:  5.193308353424072 0.0 10.46297836303711
logits torch.Size([368, 4, 1024]) labels torch.Size([368, 4]) 0 1023
Curr loss timestep torch.Size([368, 4]) tensor([350, 281, 184, 220], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 5.3588385581970215
bi 1 loss 5.510743141174316
bi 2 loss 4.899735450744629
bi 3 loss 4.921084403991699
Epoch 0: :   3%|▎         | 15167/600000 [01:10<45:04, v_num=12, reduced_train_loss=1.400, global_step=15165.0, consumed_samples=60664.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15167/600000 [01:10<45:04, v_num=12, reduced_train_loss=37.70, global_step=15166.0, consumed_samples=60668.0, train_step_timing in s=0.290]loss mask original None

First layer loss:  0.049803487956523895 torch.Size([487, 4]) 3.8960835933685303 0.0
Max loss timestep torch.Size([487, 4]) tensor([194, 134, 381, 117], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.04239483177661896
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
bi 1 loss 0.03072279877960682
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
bi 2 loss 0.06811985373497009
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 3 loss 0.030732056125998497
speech mask sum tensor(144, device='cuda:0') loss mask sum tensor(144, device='cuda:0')
logits torch.Size([487, 4, 257024]) labels torch.Size([487, 4]) 0 257022
Layer  0  loss:  0.058926284313201904 0.0 5.860198974609375
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([313,  96, 381, 163], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.03278457000851631
bi 1 loss 0.036204803735017776
bi 2 loss 0.0888434574007988
bi 3 loss 0.03837525099515915
Layer  1  loss:  0.06460138410329819 0.0 10.280378341674805
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([196, 135, 381, 167], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.034502722322940826
bi 1 loss 0.0360976904630661
bi 2 loss 0.10587888211011887
bi 3 loss 0.02874547243118286
Layer  2  loss:  0.06074070185422897 0.0 4.829169750213623
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([313, 113, 381,  98], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.04420389235019684
bi 1 loss 0.03735211491584778
bi 2 loss 0.08626823127269745
bi 3 loss 0.03909704089164734
Layer  3  loss:  0.05357795208692551 0.0 5.749381065368652
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1021
Curr loss timestep torch.Size([487, 4]) tensor([313, 106, 378,  85], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.0426974780857563
bi 1 loss 0.028239527717232704
bi 2 loss 0.07951273024082184
bi 3 loss 0.026196883991360664
Layer  4  loss:  0.06397490948438644 0.0 12.422080039978027
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([313, 100, 381,  69], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.043197035789489746
bi 1 loss 0.022525129839777946
bi 2 loss 0.10321584343910217
bi 3 loss 0.028458084911108017
Layer  5  loss:  0.06404635310173035 0.0 6.968481063842773
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([313, 132, 381, 127], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.043192822486162186
bi 1 loss 0.020113244652748108
bi 2 loss 0.10186778753995895
bi 3 loss 0.032523397356271744
Layer  6  loss:  0.059164952486753464 0.0 8.169979095458984
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([313, 146, 378, 104], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.037453025579452515
bi 1 loss 0.01739680767059326
bi 2 loss 0.09441569447517395
bi 3 loss 0.03252148628234863
Epoch 0: :   3%|▎         | 15168/600000 [01:10<45:18, v_num=12, reduced_train_loss=37.70, global_step=15166.0, consumed_samples=60668.0, train_step_timing in s=0.290]Epoch 0: :   3%|▎         | 15168/600000 [01:10<45:18, v_num=12, reduced_train_loss=0.475, global_step=15167.0, consumed_samples=60672.0, train_step_timing in s=0.341]loss mask original None

First layer loss:  0.05237763002514839 torch.Size([423, 4]) 5.509506702423096 0.0
Max loss timestep torch.Size([423, 4]) tensor([248, 129, 319, 393], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.05056629702448845
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 1 loss 0.029454870149493217
speech mask sum tensor(122, device='cuda:0') loss mask sum tensor(122, device='cuda:0')
bi 2 loss 0.04035415127873421
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 3 loss 0.07010659575462341
speech mask sum tensor(348, device='cuda:0') loss mask sum tensor(348, device='cuda:0')
logits torch.Size([423, 4, 257024]) labels torch.Size([423, 4]) 0 257023
Layer  0  loss:  0.053372353315353394 0.0 5.685612201690674
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([236, 179, 284, 387], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.04349052906036377
bi 1 loss 0.04316224530339241
bi 2 loss 0.033756520599126816
bi 3 loss 0.07561153173446655
Layer  1  loss:  0.05282048508524895 0.0 4.457914352416992
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([152, 121, 294, 393], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.0457681342959404
bi 1 loss 0.04705274477601051
bi 2 loss 0.03649527207016945
bi 3 loss 0.06989055126905441
Layer  2  loss:  0.05272199586033821 0.0 4.265299320220947
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([161, 129, 315, 386], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.04406997188925743
bi 1 loss 0.036064207553863525
bi 2 loss 0.05668563023209572
bi 3 loss 0.059167131781578064
Layer  3  loss:  0.060649748891592026 0.0 4.038183212280273
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1018
Curr loss timestep torch.Size([423, 4]) tensor([255, 139, 315, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.049508970230817795
bi 1 loss 0.028257839381694794
bi 2 loss 0.05067978799343109
bi 3 loss 0.08400366455316544
Layer  4  loss:  0.061827436089515686 0.0 9.913019180297852
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1011
Curr loss timestep torch.Size([423, 4]) tensor([234, 197, 298, 388], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.04793751239776611
bi 1 loss 0.018352266401052475
bi 2 loss 0.04368782043457031
bi 3 loss 0.09627683460712433
Layer  5  loss:  0.06193751469254494 0.0 3.5145628452301025
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1019
Curr loss timestep torch.Size([423, 4]) tensor([207, 132, 266, 388], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.02615359239280224
bi 1 loss 0.043224141001701355
bi 2 loss 0.04671556502580643
bi 3 loss 0.09453125298023224
Layer  6  loss:  0.06333328038454056 0.0 5.818854808807373
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1019
Curr loss timestep torch.Size([423, 4]) tensor([148, 140, 321, 411], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.030474189668893814
bi 1 loss 0.04341753199696541
bi 2 loss 0.04469207301735878
bi 3 loss 0.09769146144390106
Epoch 0: :   3%|▎         | 15169/600000 [01:10<45:31, v_num=12, reduced_train_loss=0.475, global_step=15167.0, consumed_samples=60672.0, train_step_timing in s=0.341]Epoch 0: :   3%|▎         | 15169/600000 [01:10<45:31, v_num=12, reduced_train_loss=0.459, global_step=15168.0, consumed_samples=60676.0, train_step_timing in s=0.309]loss mask original None

First layer loss:  0.03512609750032425 torch.Size([434, 4]) 1.814317226409912 0.0
Max loss timestep torch.Size([434, 4]) tensor([343, 181, 114, 183], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.04633280634880066
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 1 loss 0.036063265055418015
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
bi 2 loss 0.016305457800626755
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 0.026319272816181183
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
logits torch.Size([434, 4, 257024]) labels torch.Size([434, 4]) 0 257022
Layer  0  loss:  0.034216396510601044 0.0 0.8476129174232483
logits torch.Size([434, 4, 1024]) labels torch.Size([434, 4]) 0 1023
Curr loss timestep torch.Size([434, 4]) tensor([120, 188, 208, 190], device='cuda:0') tensor(120, device='cuda:0')
bi 0 loss 0.045295875519514084
bi 1 loss 0.04022812843322754
bi 2 loss 0.010484887287020683
bi 3 loss 0.0263852309435606
Layer  1  loss:  0.04602019488811493 0.0 1.8634068965911865
logits torch.Size([434, 4, 1024]) labels torch.Size([434, 4]) 0 1023
Curr loss timestep torch.Size([434, 4]) tensor([292, 212, 126, 190], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.06753014028072357
bi 1 loss 0.0357721708714962
bi 2 loss 0.025858044624328613
bi 3 loss 0.024309296160936356
Layer  2  loss:  0.033666275441646576 0.0 0.849969208240509
logits torch.Size([434, 4, 1024]) labels torch.Size([434, 4]) 0 1022
Curr loss timestep torch.Size([434, 4]) tensor([252, 150, 126, 212], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 0.04210374504327774
bi 1 loss 0.024529486894607544
bi 2 loss 0.01748397760093212
bi 3 loss 0.03387204185128212
Layer  3  loss:  0.040131449699401855 0.0 1.3408215045928955
logits torch.Size([434, 4, 1024]) labels torch.Size([434, 4]) 0 1021
Curr loss timestep torch.Size([434, 4]) tensor([401, 159, 204,  97], device='cuda:0') tensor(97, device='cuda:0')
bi 0 loss 0.044445138424634933
bi 1 loss 0.05199984833598137
bi 2 loss 0.02751721441745758
bi 3 loss 0.03427056223154068
Layer  4  loss:  0.03637055307626724 0.0 0.9102098345756531
logits torch.Size([434, 4, 1024]) labels torch.Size([434, 4]) 0 1022
Curr loss timestep torch.Size([434, 4]) tensor([343, 159, 213, 123], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 0.04211404547095299
bi 1 loss 0.041281845420598984
bi 2 loss 0.025636859238147736
bi 3 loss 0.03020511567592621
Layer  5  loss:  0.03869078308343887 0.0 3.3574724197387695
logits torch.Size([434, 4, 1024]) labels torch.Size([434, 4]) 0 1021
Curr loss timestep torch.Size([434, 4]) tensor([330, 182, 181, 157], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.0509815588593483
bi 1 loss 0.024995965883135796
bi 2 loss 0.02092471718788147
bi 3 loss 0.03504985198378563
Layer  6  loss:  0.04148977994918823 0.0 2.0882763862609863
logits torch.Size([434, 4, 1024]) labels torch.Size([434, 4]) 0 1021
Curr loss timestep torch.Size([434, 4]) tensor([343, 220, 207, 191], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.05114484205842018
bi 1 loss 0.05097384378314018
bi 2 loss 0.02309114672243595
bi 3 loss 0.030705738812685013
Epoch 0: :   3%|▎         | 15170/600000 [01:11<45:45, v_num=12, reduced_train_loss=0.459, global_step=15168.0, consumed_samples=60676.0, train_step_timing in s=0.309]Epoch 0: :   3%|▎         | 15170/600000 [01:11<45:45, v_num=12, reduced_train_loss=0.306, global_step=15169.0, consumed_samples=60680.0, train_step_timing in s=0.315]loss mask original None

First layer loss:  3.9133975505828857 torch.Size([692, 4]) 15.491628646850586 0.0
Max loss timestep torch.Size([692, 4]) tensor([246, 420, 592, 479], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 3.7834954261779785
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 1 loss 3.5054996013641357
speech mask sum tensor(490, device='cuda:0') loss mask sum tensor(490, device='cuda:0')
bi 2 loss 4.187482833862305
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 3 loss 4.122288703918457
speech mask sum tensor(495, device='cuda:0') loss mask sum tensor(495, device='cuda:0')
logits torch.Size([692, 4, 257024]) labels torch.Size([692, 4]) 0 257023
Layer  0  loss:  4.305156230926514 0.0 11.628667831420898
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1023
Curr loss timestep torch.Size([692, 4]) tensor([247, 380, 343, 327], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 4.0741448402404785
bi 1 loss 4.274805545806885
bi 2 loss 4.236084938049316
bi 3 loss 4.455179691314697
Layer  1  loss:  4.649887561798096 0.0 11.072073936462402
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1023
Curr loss timestep torch.Size([692, 4]) tensor([170, 560, 510, 218], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 4.354345321655273
bi 1 loss 4.495057582855225
bi 2 loss 4.642524719238281
bi 3 loss 4.888734817504883
Layer  2  loss:  4.9513630867004395 0.0 11.048624038696289
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1022
Curr loss timestep torch.Size([692, 4]) tensor([221, 493, 537, 526], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 4.684447288513184
bi 1 loss 4.7806549072265625
bi 2 loss 4.948380947113037
bi 3 loss 5.194562911987305
Layer  3  loss:  5.072169303894043 0.0 10.545638084411621
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1022
Curr loss timestep torch.Size([692, 4]) tensor([156, 216, 376, 653], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 4.912134170532227
bi 1 loss 4.833869934082031
bi 2 loss 5.105971336364746
bi 3 loss 5.322723388671875
Layer  4  loss:  5.187812805175781 0.0 10.272768020629883
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1023
Curr loss timestep torch.Size([692, 4]) tensor([210, 235, 298, 439], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 4.937845230102539
bi 1 loss 4.921928882598877
bi 2 loss 5.25283670425415
bi 3 loss 5.463659286499023
Layer  5  loss:  5.275505542755127 0.0 11.035295486450195
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1022
Curr loss timestep torch.Size([692, 4]) tensor([219, 228, 297, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 4.980809211730957
bi 1 loss 5.016787052154541
bi 2 loss 5.419705390930176
bi 3 loss 5.489898204803467
Layer  6  loss:  5.344880104064941 0.0 11.256443977355957
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1023
Curr loss timestep torch.Size([692, 4]) tensor([256, 627, 379, 626], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 5.14695405960083
bi 1 loss 5.021219253540039
bi 2 loss 5.474212646484375
bi 3 loss 5.61002254486084
Epoch 0: :   3%|▎         | 15171/600000 [01:11<46:03, v_num=12, reduced_train_loss=0.306, global_step=15169.0, consumed_samples=60680.0, train_step_timing in s=0.315]Epoch 0: :   3%|▎         | 15171/600000 [01:11<46:03, v_num=12, reduced_train_loss=38.70, global_step=15170.0, consumed_samples=60684.0, train_step_timing in s=0.452]loss mask original None

First layer loss:  0.10059844702482224 torch.Size([577, 4]) 4.698235034942627 0.0
Max loss timestep torch.Size([577, 4]) tensor([420, 568, 435, 211], device='cuda:0') tensor(568, device='cuda:0')
bi 0 loss 0.09706734865903854
speech mask sum tensor(327, device='cuda:0') loss mask sum tensor(327, device='cuda:0')
bi 1 loss 0.13713279366493225
speech mask sum tensor(452, device='cuda:0') loss mask sum tensor(452, device='cuda:0')
bi 2 loss 0.08914326876401901
speech mask sum tensor(351, device='cuda:0') loss mask sum tensor(351, device='cuda:0')
bi 3 loss 0.03270568326115608
speech mask sum tensor(167, device='cuda:0') loss mask sum tensor(167, device='cuda:0')
logits torch.Size([577, 4, 257024]) labels torch.Size([577, 4]) 0 257023
Layer  0  loss:  0.10894884914159775 0.0 10.605152130126953
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([340, 336, 504, 233], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.14703653752803802
bi 1 loss 0.11700520664453506
bi 2 loss 0.09137088060379028
bi 3 loss 0.04951004683971405
Layer  1  loss:  0.11325186491012573 0.0 11.334672927856445
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([340, 336, 504, 205], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.10166119039058685
bi 1 loss 0.1473306268453598
bi 2 loss 0.11501018702983856
bi 3 loss 0.04001462087035179
Layer  2  loss:  0.10953902453184128 0.0 9.603958129882812
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([377, 336, 504, 133], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.08796270936727524
bi 1 loss 0.16289645433425903
bi 2 loss 0.09313486516475677
bi 3 loss 0.04184894636273384
Layer  3  loss:  0.11158906668424606 0.0 13.236320495605469
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([386, 336, 383, 151], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.07088955491781235
bi 1 loss 0.1770457923412323
bi 2 loss 0.09063055366277695
bi 3 loss 0.05816834419965744
Layer  4  loss:  0.10933257639408112 0.0 7.504837512969971
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([340, 336, 431, 132], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.10821879655122757
bi 1 loss 0.1385931372642517
bi 2 loss 0.08484739065170288
bi 3 loss 0.08378008753061295
Layer  5  loss:  0.13569729030132294 0.0 8.318890571594238
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([340, 336, 504, 125], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.12113659828901291
bi 1 loss 0.19199998676776886
bi 2 loss 0.09799078851938248
bi 3 loss 0.09107159078121185
Layer  6  loss:  0.14064498245716095 0.0 8.045364379882812
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([420, 546, 498, 172], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.12142802029848099
bi 1 loss 0.20775820314884186
bi 2 loss 0.10945463925600052
bi 3 loss 0.06218137964606285
Epoch 0: :   3%|▎         | 15172/600000 [01:12<46:19, v_num=12, reduced_train_loss=38.70, global_step=15170.0, consumed_samples=60684.0, train_step_timing in s=0.452]Epoch 0: :   3%|▎         | 15172/600000 [01:12<46:19, v_num=12, reduced_train_loss=0.930, global_step=15171.0, consumed_samples=60688.0, train_step_timing in s=0.394]loss mask original None

First layer loss:  3.982698440551758 torch.Size([576, 4]) 10.79725170135498 0.0
Max loss timestep torch.Size([576, 4]) tensor([195, 150, 108, 502], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 3.802664279937744
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 1 loss 4.128361225128174
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 2 loss 3.379909038543701
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
bi 3 loss 4.197926044464111
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
logits torch.Size([576, 4, 257024]) labels torch.Size([576, 4]) 0 257023
Layer  0  loss:  4.42880392074585 0.0 12.157295227050781
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([353, 184, 134, 313], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 4.429477214813232
bi 1 loss 4.638982772827148
bi 2 loss 4.187954902648926
bi 3 loss 4.392904758453369
Layer  1  loss:  4.7057881355285645 0.0 10.788910865783691
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([419, 146,  55, 166], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 4.62050199508667
bi 1 loss 4.777981281280518
bi 2 loss 4.359565734863281
bi 3 loss 4.824438571929932
Layer  2  loss:  4.999065399169922 0.0 11.155200004577637
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([362, 174,  66, 280], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.892352104187012
bi 1 loss 5.011923313140869
bi 2 loss 4.635271072387695
bi 3 loss 5.16646146774292
Layer  3  loss:  5.084329605102539 0.0 10.140755653381348
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([367, 261,  95, 513], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 5.031184673309326
bi 1 loss 5.149872779846191
bi 2 loss 4.82282829284668
bi 3 loss 5.161503791809082
Layer  4  loss:  5.2051568031311035 0.0 10.074688911437988
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([409, 120,  66, 426], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 5.170141220092773
bi 1 loss 5.216928482055664
bi 2 loss 4.873401165008545
bi 3 loss 5.320382595062256
Layer  5  loss:  5.314019680023193 0.0 10.54719352722168
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([434, 224, 127, 222], device='cuda:0') tensor(127, device='cuda:0')
bi 0 loss 5.154469966888428
bi 1 loss 5.3538031578063965
bi 2 loss 5.169715404510498
bi 3 loss 5.432929992675781
Layer  6  loss:  5.328481197357178 0.0 10.737581253051758
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([379, 161, 103, 303], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 5.18256139755249
bi 1 loss 5.413059234619141
bi 2 loss 5.0232768058776855
bi 3 loss 5.464758396148682
Epoch 0: :   3%|▎         | 15173/600000 [01:12<46:35, v_num=12, reduced_train_loss=0.930, global_step=15171.0, consumed_samples=60688.0, train_step_timing in s=0.394]Epoch 0: :   3%|▎         | 15173/600000 [01:12<46:35, v_num=12, reduced_train_loss=39.00, global_step=15172.0, consumed_samples=60692.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  3.8595988750457764 torch.Size([500, 4]) 10.525360107421875 0.0
Max loss timestep torch.Size([500, 4]) tensor([316,  89, 148, 122], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 3.8742358684539795
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 1 loss 3.7559852600097656
speech mask sum tensor(442, device='cuda:0') loss mask sum tensor(442, device='cuda:0')
bi 2 loss 3.693202495574951
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 3 loss 4.107060432434082
speech mask sum tensor(249, device='cuda:0') loss mask sum tensor(249, device='cuda:0')
logits torch.Size([500, 4, 257024]) labels torch.Size([500, 4]) 0 257022
Layer  0  loss:  4.332213878631592 0.0 9.800493240356445
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([232, 315, 129, 291], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 4.506178379058838
bi 1 loss 4.183676242828369
bi 2 loss 3.8476223945617676
bi 3 loss 4.685449600219727
Layer  1  loss:  4.669984817504883 0.0 10.677177429199219
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([307, 356, 164, 269], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 4.88347864151001
bi 1 loss 4.6031107902526855
bi 2 loss 4.3946404457092285
bi 3 loss 4.756246566772461
Layer  2  loss:  4.8748779296875 0.0 10.213682174682617
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([182, 476, 125, 125], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 5.036433219909668
bi 1 loss 4.823084354400635
bi 2 loss 4.6048102378845215
bi 3 loss 4.96977424621582
Layer  3  loss:  4.961292266845703 0.0 10.24728775024414
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1021
Curr loss timestep torch.Size([500, 4]) tensor([187, 187, 127, 120], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 5.15910005569458
bi 1 loss 4.970298767089844
bi 2 loss 4.676191806793213
bi 3 loss 4.9286088943481445
Layer  4  loss:  5.113193511962891 0.0 9.528328895568848
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([217, 290,  98, 274], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 5.216196537017822
bi 1 loss 5.109007358551025
bi 2 loss 4.879838466644287
bi 3 loss 5.149775505065918
Layer  5  loss:  5.129420280456543 0.0 10.937246322631836
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1021
Curr loss timestep torch.Size([500, 4]) tensor([187, 445, 156, 320], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 5.307608604431152
bi 1 loss 5.100431442260742
bi 2 loss 4.975813388824463
bi 3 loss 5.119827747344971
Layer  6  loss:  5.183651447296143 0.0 9.938838005065918
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1021
Curr loss timestep torch.Size([500, 4]) tensor([221, 399, 106, 305], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 5.51412296295166
bi 1 loss 5.1108078956604
bi 2 loss 4.8846821784973145
bi 3 loss 5.206007480621338
Epoch 0: :   3%|▎         | 15174/600000 [01:12<46:49, v_num=12, reduced_train_loss=39.00, global_step=15172.0, consumed_samples=60692.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15174/600000 [01:12<46:49, v_num=12, reduced_train_loss=38.10, global_step=15173.0, consumed_samples=60696.0, train_step_timing in s=0.332]loss mask original None

First layer loss:  0.09143921732902527 torch.Size([517, 4]) 6.03587007522583 0.0
Max loss timestep torch.Size([517, 4]) tensor([263, 277, 349, 268], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.07964223623275757
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
bi 1 loss 0.11208222061395645
speech mask sum tensor(311, device='cuda:0') loss mask sum tensor(311, device='cuda:0')
bi 2 loss 0.0730958878993988
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 3 loss 0.09464875608682632
speech mask sum tensor(219, device='cuda:0') loss mask sum tensor(219, device='cuda:0')
logits torch.Size([517, 4, 257024]) labels torch.Size([517, 4]) 0 257023
Layer  0  loss:  0.08879539370536804 0.0 4.988098621368408
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([417, 264, 349, 267], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.11311133950948715
bi 1 loss 0.07124673575162888
bi 2 loss 0.08915607631206512
bi 3 loss 0.07403634488582611
Layer  1  loss:  0.08386604487895966 0.0 6.068752765655518
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([284, 264, 351, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.08485280722379684
bi 1 loss 0.0822909027338028
bi 2 loss 0.08353608846664429
bi 3 loss 0.0847444236278534
Layer  2  loss:  0.09906122088432312 0.0 9.725555419921875
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([177, 264, 275, 267], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.09268379956483841
bi 1 loss 0.11378613859415054
bi 2 loss 0.08029432594776154
bi 3 loss 0.10219929367303848
Layer  3  loss:  0.08894512802362442 0.0 6.398636817932129
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([417, 263, 349, 265], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.08733532577753067
bi 1 loss 0.08415261656045914
bi 2 loss 0.09666160494089127
bi 3 loss 0.0927228257060051
Layer  4  loss:  0.09117065370082855 0.0 6.736140251159668
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1021
Curr loss timestep torch.Size([517, 4]) tensor([417, 277, 351, 267], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.095230832695961
bi 1 loss 0.1000390574336052
bi 2 loss 0.055182553827762604
bi 3 loss 0.09828775376081467
Layer  5  loss:  0.10910475254058838 0.0 8.439142227172852
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([284, 277, 278, 267], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.10491044819355011
bi 1 loss 0.10017134994268417
bi 2 loss 0.12570251524448395
bi 3 loss 0.11646374315023422
Layer  6  loss:  0.08491583168506622 0.0 5.157860279083252
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([284, 277, 268, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.07535584270954132
bi 1 loss 0.09529280662536621
bi 2 loss 0.07671251147985458
bi 3 loss 0.09166964888572693
Epoch 0: :   3%|▎         | 15175/600000 [01:13<47:04, v_num=12, reduced_train_loss=38.10, global_step=15173.0, consumed_samples=60696.0, train_step_timing in s=0.332]Epoch 0: :   3%|▎         | 15175/600000 [01:13<47:04, v_num=12, reduced_train_loss=0.737, global_step=15174.0, consumed_samples=60700.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  0.14654046297073364 torch.Size([554, 4]) 11.688004493713379 0.0
Max loss timestep torch.Size([554, 4]) tensor([478, 356,  83, 398], device='cuda:0') tensor(398, device='cuda:0')
bi 0 loss 0.16258969902992249
speech mask sum tensor(414, device='cuda:0') loss mask sum tensor(414, device='cuda:0')
bi 1 loss 0.1726057082414627
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 2 loss 0.0539349727332592
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 3 loss 0.13084286451339722
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
logits torch.Size([554, 4, 257024]) labels torch.Size([554, 4]) 0 257022
Layer  0  loss:  0.15424448251724243 0.0 15.859071731567383
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([478, 356, 113, 336], device='cuda:0') tensor(478, device='cuda:0')
bi 0 loss 0.18505443632602692
bi 1 loss 0.20726512372493744
bi 2 loss 0.040509968996047974
bi 3 loss 0.10497163981199265
Layer  1  loss:  0.14902804791927338 0.0 11.131218910217285
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([478, 357, 115, 398], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.17502370476722717
bi 1 loss 0.22009330987930298
bi 2 loss 0.035625845193862915
bi 3 loss 0.09235178679227829
Layer  2  loss:  0.17135919630527496 0.0 11.627921104431152
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([478, 356,  88, 398], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.19493696093559265
bi 1 loss 0.21781796216964722
bi 2 loss 0.06524945795536041
bi 3 loss 0.13428331911563873
Layer  3  loss:  0.18453623354434967 0.0 15.344029426574707
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([478, 356,  76, 335], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.17116856575012207
bi 1 loss 0.3227946162223816
bi 2 loss 0.046156350523233414
bi 3 loss 0.13477300107479095
Layer  4  loss:  0.16393956542015076 0.0 12.062767028808594
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([478, 356, 120, 336], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.1891697198152542
bi 1 loss 0.21011418104171753
bi 2 loss 0.04216962307691574
bi 3 loss 0.12908579409122467
Layer  5  loss:  0.15688040852546692 0.0 12.95680046081543
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([478, 357, 108, 336], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.16222459077835083
bi 1 loss 0.19473902881145477
bi 2 loss 0.06029021739959717
bi 3 loss 0.14717155694961548
Layer  6  loss:  0.18689154088497162 0.0 17.063344955444336
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([478, 357,  95, 335], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.21003398299217224
bi 1 loss 0.3006184697151184
bi 2 loss 0.027889972552657127
bi 3 loss 0.11399088054895401
Epoch 0: :   3%|▎         | 15176/600000 [01:13<47:20, v_num=12, reduced_train_loss=0.737, global_step=15174.0, consumed_samples=60700.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15176/600000 [01:13<47:20, v_num=12, reduced_train_loss=1.310, global_step=15175.0, consumed_samples=60704.0, train_step_timing in s=0.377]loss mask original None

First layer loss:  0.1552470177412033 torch.Size([563, 4]) 13.032418251037598 0.0
Max loss timestep torch.Size([563, 4]) tensor([536, 101, 343, 293], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.276312917470932
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
bi 1 loss 0.052098751068115234
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 2 loss 0.07518640160560608
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 3 loss 0.08719073981046677
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
logits torch.Size([563, 4, 257024]) labels torch.Size([563, 4]) 0 257022
Layer  0  loss:  0.1393648236989975 0.0 13.72951889038086
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([487, 104, 259, 293], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.22540639340877533
bi 1 loss 0.05290551483631134
bi 2 loss 0.07498471438884735
bi 3 loss 0.10436251759529114
Layer  1  loss:  0.16387739777565002 0.0 12.956419944763184
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([487,  98, 273, 293], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.29668575525283813
bi 1 loss 0.04899093881249428
bi 2 loss 0.06589724123477936
bi 3 loss 0.09889167547225952
Layer  2  loss:  0.19142895936965942 0.0 12.238040924072266
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([489, 129, 343, 293], device='cuda:0') tensor(489, device='cuda:0')
bi 0 loss 0.3393118977546692
bi 1 loss 0.0845407098531723
bi 2 loss 0.09973237663507462
bi 3 loss 0.09299546480178833
Layer  3  loss:  0.1738535314798355 0.0 11.23204231262207
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([529, 102, 276, 293], device='cuda:0') tensor(529, device='cuda:0')
bi 0 loss 0.3068180978298187
bi 1 loss 0.044411029666662216
bi 2 loss 0.08659679442644119
bi 3 loss 0.10701839625835419
Layer  4  loss:  0.1775406301021576 0.0 14.545539855957031
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([489, 110, 343, 282], device='cuda:0') tensor(489, device='cuda:0')
bi 0 loss 0.312284380197525
bi 1 loss 0.07497575879096985
bi 2 loss 0.10654494911432266
bi 3 loss 0.07974063605070114
Layer  5  loss:  0.1638912409543991 0.0 11.939108848571777
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1021
Curr loss timestep torch.Size([563, 4]) tensor([487,  55, 343, 293], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.2794027030467987
bi 1 loss 0.0647185668349266
bi 2 loss 0.1034078374505043
bi 3 loss 0.08563385903835297
Layer  6  loss:  0.18107232451438904 0.0 11.583318710327148
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([487, 145, 343, 293], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.3183882534503937
bi 1 loss 0.06885683536529541
bi 2 loss 0.09552092105150223
bi 3 loss 0.09683649241924286
Epoch 0: :   3%|▎         | 15177/600000 [01:14<47:36, v_num=12, reduced_train_loss=1.310, global_step=15175.0, consumed_samples=60704.0, train_step_timing in s=0.377]Epoch 0: :   3%|▎         | 15177/600000 [01:14<47:36, v_num=12, reduced_train_loss=1.350, global_step=15176.0, consumed_samples=60708.0, train_step_timing in s=0.390]loss mask original None

First layer loss:  3.604379653930664 torch.Size([548, 4]) 10.102422714233398 0.0
Max loss timestep torch.Size([548, 4]) tensor([236, 217, 421, 227], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 3.509692907333374
speech mask sum tensor(174, device='cuda:0') loss mask sum tensor(174, device='cuda:0')
bi 1 loss 3.3336265087127686
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 2 loss 3.9075140953063965
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
bi 3 loss 3.37458872795105
speech mask sum tensor(168, device='cuda:0') loss mask sum tensor(168, device='cuda:0')
logits torch.Size([548, 4, 257024]) labels torch.Size([548, 4]) 0 257022
Layer  0  loss:  4.220284461975098 0.0 10.613886833190918
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([203, 253, 321, 239], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 4.384809970855713
bi 1 loss 3.5821762084960938
bi 2 loss 4.543436050415039
bi 3 loss 4.006165981292725
Layer  1  loss:  4.362448215484619 0.0 9.771879196166992
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([233, 297, 309, 257], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 4.033443927764893
bi 1 loss 3.8077094554901123
bi 2 loss 4.861238479614258
bi 3 loss 4.259308815002441
Layer  2  loss:  4.5661444664001465 0.0 10.173200607299805
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([175, 302, 265, 138], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 4.4344024658203125
bi 1 loss 4.1746506690979
bi 2 loss 4.956481456756592
bi 3 loss 4.317913055419922
Layer  3  loss:  4.634167671203613 0.0 11.390970230102539
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1016
Curr loss timestep torch.Size([548, 4]) tensor([177, 275, 515, 189], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 4.486408710479736
bi 1 loss 4.211330890655518
bi 2 loss 5.10458517074585
bi 3 loss 4.280751705169678
Layer  4  loss:  4.834478378295898 0.0 9.689504623413086
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([300, 265, 424, 243], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 4.913445949554443
bi 1 loss 4.412171363830566
bi 2 loss 5.199699878692627
bi 3 loss 4.44176721572876
Layer  5  loss:  4.821047306060791 0.0 10.060384750366211
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([162, 308, 522, 191], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 4.835084915161133
bi 1 loss 4.51530122756958
bi 2 loss 5.1517510414123535
bi 3 loss 4.457906246185303
Layer  6  loss:  4.845843315124512 0.0 9.250569343566895
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([242, 317, 515, 170], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 4.826120853424072
bi 1 loss 4.434595584869385
bi 2 loss 5.230863094329834
bi 3 loss 4.508783340454102
Epoch 0: :   3%|▎         | 15178/600000 [01:14<47:51, v_num=12, reduced_train_loss=1.350, global_step=15176.0, consumed_samples=60708.0, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15178/600000 [01:14<47:51, v_num=12, reduced_train_loss=35.90, global_step=15177.0, consumed_samples=60712.0, train_step_timing in s=0.349]loss mask original None

First layer loss:  0.08986693620681763 torch.Size([614, 4]) 5.1041646003723145 0.0
Max loss timestep torch.Size([614, 4]) tensor([357, 375, 147, 584], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.05290577560663223
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 1 loss 0.17082028090953827
speech mask sum tensor(261, device='cuda:0') loss mask sum tensor(261, device='cuda:0')
bi 2 loss 0.035950373858213425
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 3 loss 0.09199248999357224
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
logits torch.Size([614, 4, 257024]) labels torch.Size([614, 4]) 0 257022
Layer  0  loss:  0.1271059662103653 0.0 9.628146171569824
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([135, 375, 306, 553], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.05917825177311897
bi 1 loss 0.1831522285938263
bi 2 loss 0.06577738374471664
bi 3 loss 0.1654093861579895
Layer  1  loss:  0.1386980414390564 0.0 8.363350868225098
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([286, 275, 308, 473], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.07643149793148041
bi 1 loss 0.20918172597885132
bi 2 loss 0.03706662729382515
bi 3 loss 0.1835445761680603
Layer  2  loss:  0.14044436812400818 0.0 9.526662826538086
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([366, 299, 306, 553], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.04196317121386528
bi 1 loss 0.2003476321697235
bi 2 loss 0.09430018067359924
bi 3 loss 0.188664048910141
Layer  3  loss:  0.14322170615196228 0.0 9.7227144241333
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([305, 275, 309, 553], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.050137974321842194
bi 1 loss 0.25854915380477905
bi 2 loss 0.051662273705005646
bi 3 loss 0.17776820063591003
Layer  4  loss:  0.1336173713207245 0.0 8.967007637023926
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1019
Curr loss timestep torch.Size([614, 4]) tensor([258, 375, 263, 473], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.0504896342754364
bi 1 loss 0.1796019822359085
bi 2 loss 0.0849844440817833
bi 3 loss 0.18118037283420563
Layer  5  loss:  0.15273013710975647 0.0 8.482148170471191
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([306, 375, 307, 553], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.07323897629976273
bi 1 loss 0.25061357021331787
bi 2 loss 0.05706499516963959
bi 3 loss 0.19037777185440063
Layer  6  loss:  0.1495126336812973 0.0 12.58026123046875
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([238, 307, 308, 553], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.0711309164762497
bi 1 loss 0.24212157726287842
bi 2 loss 0.057798612862825394
bi 3 loss 0.18762663006782532
Epoch 0: :   3%|▎         | 15179/600000 [01:14<48:08, v_num=12, reduced_train_loss=35.90, global_step=15177.0, consumed_samples=60712.0, train_step_timing in s=0.349]Epoch 0: :   3%|▎         | 15179/600000 [01:14<48:08, v_num=12, reduced_train_loss=1.080, global_step=15178.0, consumed_samples=60716.0, train_step_timing in s=0.412]loss mask original None

First layer loss:  0.041511110961437225 torch.Size([513, 4]) 3.8872220516204834 0.0
Max loss timestep torch.Size([513, 4]) tensor([ 74, 412, 162, 106], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.03528713807463646
speech mask sum tensor(116, device='cuda:0') loss mask sum tensor(116, device='cuda:0')
bi 1 loss 0.05024933069944382
speech mask sum tensor(348, device='cuda:0') loss mask sum tensor(348, device='cuda:0')
bi 2 loss 0.017672592774033546
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 3 loss 0.04098696634173393
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
logits torch.Size([513, 4, 257024]) labels torch.Size([513, 4]) 0 257023
Layer  0  loss:  0.054835446178913116 0.0 6.631571292877197
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([ 49, 412, 128,  95], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.0239624734967947
bi 1 loss 0.08514883369207382
bi 2 loss 0.011900260113179684
bi 3 loss 0.03515838086605072
Layer  1  loss:  0.05429665744304657 0.0 2.4163708686828613
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([114, 500, 173, 183], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.05637449398636818
bi 1 loss 0.06684105843305588
bi 2 loss 0.017218539491295815
bi 3 loss 0.04677224159240723
Layer  2  loss:  0.04959572106599808 0.0 3.9099531173706055
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([127, 413, 171,  95], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.015475111082196236
bi 1 loss 0.07396252453327179
bi 2 loss 0.014503144659101963
bi 3 loss 0.04138796776533127
Layer  3  loss:  0.05940735340118408 0.0 6.58522891998291
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([ 76, 412, 133,  62], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.03152468428015709
bi 1 loss 0.08711662888526917
bi 2 loss 0.008538559079170227
bi 3 loss 0.04848942905664444
Layer  4  loss:  0.048238955438137054 0.0 6.325813293457031
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1021
Curr loss timestep torch.Size([513, 4]) tensor([ 50, 412, 128, 140], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.030023809522390366
bi 1 loss 0.0716773197054863
bi 2 loss 0.007424929644912481
bi 3 loss 0.033426374197006226
Layer  5  loss:  0.06440776586532593 0.0 9.377349853515625
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1021
Curr loss timestep torch.Size([513, 4]) tensor([ 65, 412, 192, 176], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.028532501310110092
bi 1 loss 0.10162492841482162
bi 2 loss 0.018047276884317398
bi 3 loss 0.03466174751520157
Layer  6  loss:  0.055809468030929565 0.0 4.7938642501831055
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([123, 412, 180, 111], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.026870060712099075
bi 1 loss 0.08513694256544113
bi 2 loss 0.007103945128619671
bi 3 loss 0.04057006537914276
Epoch 0: :   3%|▎         | 15180/600000 [01:15<48:23, v_num=12, reduced_train_loss=1.080, global_step=15178.0, consumed_samples=60716.0, train_step_timing in s=0.412]Epoch 0: :   3%|▎         | 15180/600000 [01:15<48:23, v_num=12, reduced_train_loss=0.428, global_step=15179.0, consumed_samples=60720.0, train_step_timing in s=0.357]loss mask original None

First layer loss:  0.014007585123181343 torch.Size([385, 4]) 0.1782916635274887 0.0
Max loss timestep torch.Size([385, 4]) tensor([288, 140, 217, 164], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.014948947355151176
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 1 loss 0.012219001539051533
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 2 loss 0.012032645754516125
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 3 loss 0.014553396962583065
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
logits torch.Size([385, 4, 257024]) labels torch.Size([385, 4]) 0 257022
Layer  0  loss:  0.014560075476765633 0.0 0.28084057569503784
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1023
Curr loss timestep torch.Size([385, 4]) tensor([169, 170, 214, 133], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 0.0169903002679348
bi 1 loss 0.010294119827449322
bi 2 loss 0.012390687130391598
bi 3 loss 0.013993614353239536
Layer  1  loss:  0.012446027249097824 0.0 0.1076178252696991
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1022
Curr loss timestep torch.Size([385, 4]) tensor([267, 175, 208, 221], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 0.013949879445135593
bi 1 loss 0.008145411498844624
bi 2 loss 0.015167586505413055
bi 3 loss 0.010844333097338676
Layer  2  loss:  0.012935994192957878 0.0 0.13970313966274261
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1022
Curr loss timestep torch.Size([385, 4]) tensor([146, 181, 218, 150], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 0.014750810340046883
bi 1 loss 0.010919686406850815
bi 2 loss 0.011883740313351154
bi 3 loss 0.011366408318281174
Layer  3  loss:  0.012319843284785748 0.0 0.316568523645401
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1022
Curr loss timestep torch.Size([385, 4]) tensor([288, 141, 200, 212], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.011861089617013931
bi 1 loss 0.010306290350854397
bi 2 loss 0.014012850821018219
bi 3 loss 0.013622588478028774
Layer  4  loss:  0.013802247121930122 0.0 0.13175317645072937
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1022
Curr loss timestep torch.Size([385, 4]) tensor([346, 173, 232, 223], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 0.015655677765607834
bi 1 loss 0.012075860984623432
bi 2 loss 0.015056579373776913
bi 3 loss 0.010591492056846619
Layer  5  loss:  0.014628928154706955 0.0 0.14056424796581268
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1022
Curr loss timestep torch.Size([385, 4]) tensor([236, 130, 234, 181], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 0.016515662893652916
bi 1 loss 0.012961553409695625
bi 2 loss 0.013126200996339321
bi 3 loss 0.0129414526745677
Layer  6  loss:  0.01349060982465744 0.0 0.16905610263347626
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1023
Curr loss timestep torch.Size([385, 4]) tensor([338, 146, 231, 242], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 0.014405385591089725
bi 1 loss 0.010598275810480118
bi 2 loss 0.01699652150273323
bi 3 loss 0.011613884009420872
Epoch 0: :   3%|▎         | 15181/600000 [01:15<48:35, v_num=12, reduced_train_loss=0.428, global_step=15179.0, consumed_samples=60720.0, train_step_timing in s=0.357]Epoch 0: :   3%|▎         | 15181/600000 [01:15<48:35, v_num=12, reduced_train_loss=0.108, global_step=15180.0, consumed_samples=60724.0, train_step_timing in s=0.291]loss mask original None

First layer loss:  0.023701420053839684 torch.Size([478, 4]) 1.2798123359680176 0.0
Max loss timestep torch.Size([478, 4]) tensor([151, 305, 165, 216], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.013727552257478237
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 1 loss 0.030168630182743073
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 2 loss 0.025417955592274666
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 3 loss 0.022388804703950882
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
logits torch.Size([478, 4, 257024]) labels torch.Size([478, 4]) 0 257022
Layer  0  loss:  0.030546676367521286 0.0 3.6539974212646484
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1023
Curr loss timestep torch.Size([478, 4]) tensor([ 72, 446, 170, 163], device='cuda:0') tensor(446, device='cuda:0')
bi 0 loss 0.01500466838479042
bi 1 loss 0.0494411326944828
bi 2 loss 0.01819421537220478
bi 3 loss 0.019267724826931953
Layer  1  loss:  0.030789636075496674 0.0 4.976506233215332
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([149, 446, 135, 238], device='cuda:0') tensor(446, device='cuda:0')
bi 0 loss 0.013811674900352955
bi 1 loss 0.04973810911178589
bi 2 loss 0.021115105599164963
bi 3 loss 0.019658837467432022
Layer  2  loss:  0.03795205429196358 0.0 2.601675033569336
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([180, 446, 189, 241], device='cuda:0') tensor(446, device='cuda:0')
bi 0 loss 0.017414607107639313
bi 1 loss 0.06531161069869995
bi 2 loss 0.021841535344719887
bi 3 loss 0.017878063023090363
Layer  3  loss:  0.032285869121551514 0.0 8.313395500183105
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([ 92, 446, 198, 172], device='cuda:0') tensor(446, device='cuda:0')
bi 0 loss 0.016246836632490158
bi 1 loss 0.05226186662912369
bi 2 loss 0.01754908263683319
bi 3 loss 0.02087678201496601
Layer  4  loss:  0.03779171407222748 0.0 9.350577354431152
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([142, 446, 184, 216], device='cuda:0') tensor(446, device='cuda:0')
bi 0 loss 0.01461004838347435
bi 1 loss 0.06553491950035095
bi 2 loss 0.018442712724208832
bi 3 loss 0.02246719039976597
Layer  5  loss:  0.05035097151994705 0.0 7.932226181030273
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1019
Curr loss timestep torch.Size([478, 4]) tensor([ 73, 446, 171, 236], device='cuda:0') tensor(446, device='cuda:0')
bi 0 loss 0.014476979151368141
bi 1 loss 0.09516258537769318
bi 2 loss 0.019571296870708466
bi 3 loss 0.02319944277405739
Layer  6  loss:  0.03671426698565483 0.0 6.56673002243042
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1021
Curr loss timestep torch.Size([478, 4]) tensor([140, 446, 158, 222], device='cuda:0') tensor(446, device='cuda:0')
bi 0 loss 0.014392795041203499
bi 1 loss 0.06187395751476288
bi 2 loss 0.027714615687727928
bi 3 loss 0.019248194992542267
Epoch 0: :   3%|▎         | 15182/600000 [01:16<48:49, v_num=12, reduced_train_loss=0.108, global_step=15180.0, consumed_samples=60724.0, train_step_timing in s=0.291]Epoch 0: :   3%|▎         | 15182/600000 [01:16<48:49, v_num=12, reduced_train_loss=0.280, global_step=15181.0, consumed_samples=60728.0, train_step_timing in s=0.340]loss mask original None

First layer loss:  0.02044021524488926 torch.Size([317, 4]) 0.3100113868713379 0.0
Max loss timestep torch.Size([317, 4]) tensor([273, 143, 267, 265], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.021037761121988297
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 1 loss 0.01576312817633152
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 2 loss 0.02343585342168808
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
bi 3 loss 0.0207089614123106
speech mask sum tensor(107, device='cuda:0') loss mask sum tensor(107, device='cuda:0')
logits torch.Size([317, 4, 257024]) labels torch.Size([317, 4]) 0 257023
Layer  0  loss:  0.018559737130999565 0.0 0.2286994606256485
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1023
Curr loss timestep torch.Size([317, 4]) tensor([220, 194,  73, 245], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 0.024642353877425194
bi 1 loss 0.012990741059184074
bi 2 loss 0.017489144578576088
bi 3 loss 0.023924171924591064
Layer  1  loss:  0.01678026095032692 0.0 0.18489627540111542
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1022
Curr loss timestep torch.Size([317, 4]) tensor([278, 163, 161, 244], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.02170405164361
bi 1 loss 0.013191763311624527
bi 2 loss 0.01679043471813202
bi 3 loss 0.017694294452667236
Layer  2  loss:  0.018252359703183174 0.0 0.2476763129234314
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1022
Curr loss timestep torch.Size([317, 4]) tensor([228, 185, 121, 227], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 0.015960831195116043
bi 1 loss 0.013121766969561577
bi 2 loss 0.021791962906718254
bi 3 loss 0.020875234156847
Layer  3  loss:  0.020131440833210945 0.0 0.3631414771080017
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1022
Curr loss timestep torch.Size([317, 4]) tensor([295, 221, 201, 265], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.01977037638425827
bi 1 loss 0.01562606543302536
bi 2 loss 0.02621001936495304
bi 3 loss 0.014207461848855019
Layer  4  loss:  0.0176728293299675 0.0 0.20002411305904388
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1022
Curr loss timestep torch.Size([317, 4]) tensor([231, 169,  98, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.018850618973374367
bi 1 loss 0.014476954936981201
bi 2 loss 0.018978431820869446
bi 3 loss 0.018750302493572235
Layer  5  loss:  0.01838943548500538 0.0 0.2966662645339966
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1022
Curr loss timestep torch.Size([317, 4]) tensor([274, 197,  93, 265], device='cuda:0') tensor(93, device='cuda:0')
bi 0 loss 0.01767735928297043
bi 1 loss 0.011200353503227234
bi 2 loss 0.02292880229651928
bi 3 loss 0.020547563210129738
Layer  6  loss:  0.019483570009469986 0.0 0.2736840546131134
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1022
Curr loss timestep torch.Size([317, 4]) tensor([228, 156, 195, 271], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.02223028428852558
bi 1 loss 0.013339505530893803
bi 2 loss 0.022856200113892555
bi 3 loss 0.019162895157933235
Epoch 0: :   3%|▎         | 15183/600000 [01:16<49:01, v_num=12, reduced_train_loss=0.280, global_step=15181.0, consumed_samples=60728.0, train_step_timing in s=0.340]Epoch 0: :   3%|▎         | 15183/600000 [01:16<49:01, v_num=12, reduced_train_loss=0.150, global_step=15182.0, consumed_samples=60732.0, train_step_timing in s=0.261]loss mask original None

First layer loss:  0.01672874204814434 torch.Size([323, 4]) 0.19390742480754852 0.0
Max loss timestep torch.Size([323, 4]) tensor([159, 269, 239, 149], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.01551169902086258
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 1 loss 0.01622645929455757
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
bi 2 loss 0.01612759381532669
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 3 loss 0.01960287243127823
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
logits torch.Size([323, 4, 257024]) labels torch.Size([323, 4]) 0 257023
Layer  0  loss:  0.018057996407151222 0.0 0.23587666451931
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1023
Curr loss timestep torch.Size([323, 4]) tensor([143, 271, 256, 111], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 0.01700741797685623
bi 1 loss 0.017249012365937233
bi 2 loss 0.01806672289967537
bi 3 loss 0.020351383835077286
Layer  1  loss:  0.014995977282524109 0.0 0.22005757689476013
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([236, 141, 273, 184], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 0.01509919110685587
bi 1 loss 0.013767302967607975
bi 2 loss 0.01611245423555374
bi 3 loss 0.015073196031153202
Layer  2  loss:  0.01451342273503542 0.0 0.15449881553649902
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([194, 195, 267, 149], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 0.010283475741744041
bi 1 loss 0.015259835869073868
bi 2 loss 0.016703734174370766
bi 3 loss 0.015430562198162079
Layer  3  loss:  0.01670263335108757 0.0 0.5679831504821777
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1020
Curr loss timestep torch.Size([323, 4]) tensor([177, 282, 267, 181], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.013419282622635365
bi 1 loss 0.019626615568995476
bi 2 loss 0.017707452178001404
bi 3 loss 0.015139192342758179
Layer  4  loss:  0.015297173522412777 0.0 0.8064192533493042
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1021
Curr loss timestep torch.Size([323, 4]) tensor([165, 285, 190, 119], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.013800925575196743
bi 1 loss 0.01917112246155739
bi 2 loss 0.013971713371574879
bi 3 loss 0.013483372516930103
Layer  5  loss:  0.016007790341973305 0.0 1.0539677143096924
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([169, 285, 216, 202], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.013154856860637665
bi 1 loss 0.020173372700810432
bi 2 loss 0.014258861541748047
bi 3 loss 0.015909690409898758
Layer  6  loss:  0.014863994903862476 0.0 1.3046985864639282
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1023
Curr loss timestep torch.Size([323, 4]) tensor([223, 285, 249, 155], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.01214004959911108
bi 1 loss 0.019610725343227386
bi 2 loss 0.012007547542452812
bi 3 loss 0.015294157899916172
Epoch 0: :   3%|▎         | 15184/600000 [01:16<49:12, v_num=12, reduced_train_loss=0.150, global_step=15182.0, consumed_samples=60732.0, train_step_timing in s=0.261]Epoch 0: :   3%|▎         | 15184/600000 [01:16<49:12, v_num=12, reduced_train_loss=0.127, global_step=15183.0, consumed_samples=60736.0, train_step_timing in s=0.261]loss mask original None

First layer loss:  3.3516829013824463 torch.Size([596, 4]) 12.231280326843262 0.0
Max loss timestep torch.Size([596, 4]) tensor([240, 132, 148, 277], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 2.2628211975097656
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
bi 1 loss 3.7905232906341553
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 2 loss 4.265834808349609
speech mask sum tensor(68, device='cuda:0') loss mask sum tensor(68, device='cuda:0')
bi 3 loss 3.1682515144348145
speech mask sum tensor(392, device='cuda:0') loss mask sum tensor(392, device='cuda:0')
logits torch.Size([596, 4, 257024]) labels torch.Size([596, 4]) 0 257023
Layer  0  loss:  3.7364389896392822 0.0 9.98552417755127
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([268, 121, 160, 239], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 3.0849862098693848
bi 1 loss 4.1605048179626465
bi 2 loss 4.37164306640625
bi 3 loss 3.5368034839630127
Layer  1  loss:  3.9734396934509277 0.0 9.837575912475586
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([267, 131, 148, 366], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 3.141880750656128
bi 1 loss 4.4457621574401855
bi 2 loss 5.074773788452148
bi 3 loss 3.7000691890716553
Layer  2  loss:  4.290953636169434 0.0 10.858394622802734
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([267, 178, 146, 278], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 3.446983575820923
bi 1 loss 4.834578514099121
bi 2 loss 4.567681789398193
bi 3 loss 4.129730701446533
Layer  3  loss:  4.2944416999816895 0.0 9.854071617126465
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([254, 125, 174, 265], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 3.4018642902374268
bi 1 loss 4.842283725738525
bi 2 loss 4.879596710205078
bi 3 loss 4.085704803466797
Layer  4  loss:  4.459003925323486 0.0 10.233686447143555
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([272, 205, 152, 291], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 3.3247761726379395
bi 1 loss 5.1506547927856445
bi 2 loss 5.131765842437744
bi 3 loss 4.208121299743652
Layer  5  loss:  4.564391613006592 0.0 10.176336288452148
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([260, 243, 175, 361], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 3.999803066253662
bi 1 loss 5.1586480140686035
bi 2 loss 5.129611015319824
bi 3 loss 4.2841315269470215
Layer  6  loss:  4.555700302124023 0.0 10.084393501281738
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1021
Curr loss timestep torch.Size([596, 4]) tensor([281, 263, 168, 315], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 3.789231777191162
bi 1 loss 5.176331520080566
bi 2 loss 5.188272476196289
bi 3 loss 4.284539699554443
Epoch 0: :   3%|▎         | 15185/600000 [01:17<49:28, v_num=12, reduced_train_loss=0.127, global_step=15183.0, consumed_samples=60736.0, train_step_timing in s=0.261]Epoch 0: :   3%|▎         | 15185/600000 [01:17<49:28, v_num=12, reduced_train_loss=33.20, global_step=15184.0, consumed_samples=60740.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  0.04279336705803871 torch.Size([439, 4]) 3.8444087505340576 0.0
Max loss timestep torch.Size([439, 4]) tensor([ 95, 303, 409, 147], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.028231535106897354
speech mask sum tensor(269, device='cuda:0') loss mask sum tensor(269, device='cuda:0')
bi 1 loss 0.025992905721068382
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 2 loss 0.07527929544448853
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
bi 3 loss 0.02837458625435829
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
logits torch.Size([439, 4, 257024]) labels torch.Size([439, 4]) 0 257022
Layer  0  loss:  0.04391249641776085 0.0 4.762414932250977
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([276, 298, 407, 138], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.021426845341920853
bi 1 loss 0.012455730699002743
bi 2 loss 0.09246724098920822
bi 3 loss 0.035820357501506805
Layer  1  loss:  0.06265762448310852 0.0 8.159004211425781
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1022
Curr loss timestep torch.Size([439, 4]) tensor([142, 303, 420, 145], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.034992516040802
bi 1 loss 0.033611755818128586
bi 2 loss 0.1173909455537796
bi 3 loss 0.04781438782811165
Layer  2  loss:  0.05375707149505615 0.0 5.3191070556640625
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1022
Curr loss timestep torch.Size([439, 4]) tensor([105, 268, 268, 171], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.031172776594758034
bi 1 loss 0.011355418711900711
bi 2 loss 0.11147182434797287
bi 3 loss 0.0425751730799675
Layer  3  loss:  0.06592192500829697 0.0 9.126262664794922
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([150, 260, 407, 127], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.030926084145903587
bi 1 loss 0.023905159905552864
bi 2 loss 0.14697587490081787
bi 3 loss 0.026669727638363838
Layer  4  loss:  0.038814470171928406 0.0 2.023165702819824
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([240, 303, 420, 141], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.02408737502992153
bi 1 loss 0.018847515806555748
bi 2 loss 0.07394211739301682
bi 3 loss 0.023876823484897614
Layer  5  loss:  0.0848679468035698 0.0 15.047410011291504
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([272, 260, 407, 162], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.04153614863753319
bi 1 loss 0.01750120148062706
bi 2 loss 0.19478724896907806
bi 3 loss 0.039938345551490784
Layer  6  loss:  0.07232395559549332 0.0 9.750134468078613
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1022
Curr loss timestep torch.Size([439, 4]) tensor([ 99, 303, 276, 154], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.039943255484104156
bi 1 loss 0.025693129748106003
bi 2 loss 0.15172064304351807
bi 3 loss 0.03895998001098633
Epoch 0: :   3%|▎         | 15186/600000 [01:17<49:41, v_num=12, reduced_train_loss=33.20, global_step=15184.0, consumed_samples=60740.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15186/600000 [01:17<49:41, v_num=12, reduced_train_loss=0.465, global_step=15185.0, consumed_samples=60744.0, train_step_timing in s=0.318]loss mask original None

First layer loss:  3.7168407440185547 torch.Size([564, 4]) 11.556946754455566 0.0
Max loss timestep torch.Size([564, 4]) tensor([103,  76, 406, 217], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 3.5830259323120117
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 1 loss 3.2312278747558594
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 2 loss 4.132614612579346
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
bi 3 loss 3.5656039714813232
speech mask sum tensor(93, device='cuda:0') loss mask sum tensor(93, device='cuda:0')
logits torch.Size([564, 4, 257024]) labels torch.Size([564, 4]) 0 257023
Layer  0  loss:  4.148475646972656 0.0 11.947428703308105
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([143,  97, 405, 219], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 4.235448837280273
bi 1 loss 3.734590530395508
bi 2 loss 4.39836311340332
bi 3 loss 4.076358795166016
Layer  1  loss:  4.3601250648498535 0.0 9.40009880065918
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([146, 183, 548, 238], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.72592306137085
bi 1 loss 3.640303373336792
bi 2 loss 4.710988998413086
bi 3 loss 4.200367450714111
Layer  2  loss:  4.640332221984863 0.0 9.823542594909668
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([175, 228, 412, 256], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 5.026690483093262
bi 1 loss 4.064275741577148
bi 2 loss 4.820349216461182
bi 3 loss 4.717128753662109
Layer  3  loss:  4.756742000579834 0.0 10.169581413269043
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([197, 226, 308, 243], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 5.256870746612549
bi 1 loss 4.315876483917236
bi 2 loss 4.799940586090088
bi 3 loss 4.833328723907471
Layer  4  loss:  4.835696697235107 0.0 10.379987716674805
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([108, 224, 263, 206], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 5.334346294403076
bi 1 loss 4.357166290283203
bi 2 loss 4.909379959106445
bi 3 loss 4.893276214599609
Layer  5  loss:  4.826172828674316 0.0 10.015277862548828
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([171, 186, 417, 204], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 5.521798610687256
bi 1 loss 4.360209941864014
bi 2 loss 4.850341796875
bi 3 loss 4.73095178604126
Layer  6  loss:  4.967113971710205 0.0 11.412419319152832
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1019
Curr loss timestep torch.Size([564, 4]) tensor([ 93, 157, 334, 220], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 5.570034027099609
bi 1 loss 4.4634175300598145
bi 2 loss 5.007256507873535
bi 3 loss 5.039011001586914
Epoch 0: :   3%|▎         | 15187/600000 [01:17<49:56, v_num=12, reduced_train_loss=0.465, global_step=15185.0, consumed_samples=60744.0, train_step_timing in s=0.318]Epoch 0: :   3%|▎         | 15187/600000 [01:17<49:56, v_num=12, reduced_train_loss=36.30, global_step=15186.0, consumed_samples=60748.0, train_step_timing in s=0.364]loss mask original None

First layer loss:  3.755791187286377 torch.Size([564, 4]) 11.45339584350586 0.0
Max loss timestep torch.Size([564, 4]) tensor([339, 229, 215,  47], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 3.7928130626678467
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
bi 1 loss 4.077930927276611
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 2 loss 2.718459129333496
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 3 loss 4.307657241821289
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
logits torch.Size([564, 4, 257024]) labels torch.Size([564, 4]) 0 257023
Layer  0  loss:  4.313416957855225 0.0 11.573955535888672
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([115, 287, 337,  77], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.382672309875488
bi 1 loss 4.570112228393555
bi 2 loss 3.647855043411255
bi 3 loss 4.496616363525391
Layer  1  loss:  4.71571683883667 0.0 10.913200378417969
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([501, 156, 333,  76], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 4.817286491394043
bi 1 loss 4.914222717285156
bi 2 loss 3.813370704650879
bi 3 loss 5.138457298278809
Layer  2  loss:  4.9430646896362305 0.0 10.025217056274414
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([341,  88, 351, 136], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 5.079408645629883
bi 1 loss 5.4243316650390625
bi 2 loss 3.88279128074646
bi 3 loss 5.080926418304443
Layer  3  loss:  5.114129066467285 0.0 10.271979331970215
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([434, 163, 348, 136], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 5.234994411468506
bi 1 loss 5.274170875549316
bi 2 loss 4.362434387207031
bi 3 loss 5.388243198394775
Layer  4  loss:  5.221796035766602 0.0 11.6992826461792
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1021
Curr loss timestep torch.Size([564, 4]) tensor([241, 251, 205,  42], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 5.363510608673096
bi 1 loss 5.443530082702637
bi 2 loss 4.363893508911133
bi 3 loss 5.47553014755249
Layer  5  loss:  5.335944652557373 0.0 10.38174819946289
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([290, 261, 263,  42], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 5.432006359100342
bi 1 loss 5.606170654296875
bi 2 loss 4.57248592376709
bi 3 loss 5.538336753845215
Layer  6  loss:  5.285897254943848 0.0 9.86640739440918
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([147, 188, 237, 199], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 5.426395893096924
bi 1 loss 5.5008697509765625
bi 2 loss 4.419554710388184
bi 3 loss 5.5597453117370605
Epoch 0: :   3%|▎         | 15188/600000 [01:18<50:12, v_num=12, reduced_train_loss=36.30, global_step=15186.0, consumed_samples=60748.0, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15188/600000 [01:18<50:12, v_num=12, reduced_train_loss=38.70, global_step=15187.0, consumed_samples=60752.0, train_step_timing in s=0.370]loss mask original None

First layer loss:  0.026002097874879837 torch.Size([454, 4]) 1.0177719593048096 0.0
Max loss timestep torch.Size([454, 4]) tensor([205, 173, 409,  87], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.005414889194071293
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
bi 1 loss 0.032004840672016144
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 2 loss 0.03389273211359978
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 3 loss 0.019837019965052605
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
logits torch.Size([454, 4, 257024]) labels torch.Size([454, 4]) 0 257022
Layer  0  loss:  0.024959774687886238 0.0 0.3434504270553589
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([217, 190, 389, 102], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.0051201507449150085
bi 1 loss 0.03064040094614029
bi 2 loss 0.029089579358696938
bi 3 loss 0.02489771507680416
Layer  1  loss:  0.026297859847545624 0.0 0.7147389054298401
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([192, 302, 370, 159], device='cuda:0') tensor(370, device='cuda:0')
bi 0 loss 0.007438272703438997
bi 1 loss 0.020942792296409607
bi 2 loss 0.03818298876285553
bi 3 loss 0.023628992959856987
Layer  2  loss:  0.028877083212137222 0.0 3.966045618057251
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([173, 282, 409,  85], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.0031678443774580956
bi 1 loss 0.029703382402658463
bi 2 loss 0.042265452444553375
bi 3 loss 0.021889718249440193
Layer  3  loss:  0.02947659231722355 0.0 2.253995656967163
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([202, 250, 409,  93], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.006928844843059778
bi 1 loss 0.029535969719290733
bi 2 loss 0.041826341301202774
bi 3 loss 0.02299516461789608
Layer  4  loss:  0.035983286798000336 0.0 7.232227802276611
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([201, 201, 409, 133], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.005639954470098019
bi 1 loss 0.033304404467344284
bi 2 loss 0.058225367218256
bi 3 loss 0.02063799276947975
Layer  5  loss:  0.02497103624045849 0.0 0.30619633197784424
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([163, 284, 282,  89], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 0.003790799994021654
bi 1 loss 0.027890512719750404
bi 2 loss 0.02930307574570179
bi 3 loss 0.028138915076851845
Layer  6  loss:  0.023093897849321365 0.0 0.8035231232643127
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([210, 304, 409, 133], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.003786712884902954
bi 1 loss 0.02199924923479557
bi 2 loss 0.030732914805412292
bi 3 loss 0.023556454107165337
Epoch 0: :   3%|▎         | 15189/600000 [01:18<50:25, v_num=12, reduced_train_loss=38.70, global_step=15187.0, consumed_samples=60752.0, train_step_timing in s=0.370]Epoch 0: :   3%|▎         | 15189/600000 [01:18<50:25, v_num=12, reduced_train_loss=0.220, global_step=15188.0, consumed_samples=60756.0, train_step_timing in s=0.322]loss mask original None

First layer loss:  3.449205160140991 torch.Size([788, 4]) 9.91606330871582 0.0
Max loss timestep torch.Size([788, 4]) tensor([154, 424, 526, 210], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 2.807206392288208
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 1 loss 3.16381573677063
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
bi 2 loss 3.7260496616363525
speech mask sum tensor(379, device='cuda:0') loss mask sum tensor(379, device='cuda:0')
bi 3 loss 3.897813320159912
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
logits torch.Size([788, 4, 257024]) labels torch.Size([788, 4]) 0 257023
Layer  0  loss:  4.222426891326904 0.0 9.92391586303711
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1023
Curr loss timestep torch.Size([788, 4]) tensor([181, 612, 243, 232], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 3.6471166610717773
bi 1 loss 3.8714239597320557
bi 2 loss 4.5913496017456055
bi 3 loss 4.631728172302246
Layer  1  loss:  4.550886631011963 0.0 11.712952613830566
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1023
Curr loss timestep torch.Size([788, 4]) tensor([150, 744, 481, 321], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 3.963958740234375
bi 1 loss 4.473507404327393
bi 2 loss 4.609594821929932
bi 3 loss 4.873791694641113
Layer  2  loss:  4.713460922241211 0.0 10.478401184082031
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1022
Curr loss timestep torch.Size([788, 4]) tensor([130, 495, 242, 375], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 3.9482815265655518
bi 1 loss 4.58193302154541
bi 2 loss 4.944833755493164
bi 3 loss 4.915932655334473
Layer  3  loss:  4.798830032348633 0.0 10.920654296875
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1020
Curr loss timestep torch.Size([788, 4]) tensor([178, 525, 538, 234], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 4.102516174316406
bi 1 loss 4.680896282196045
bi 2 loss 4.84996223449707
bi 3 loss 5.282316207885742
Layer  4  loss:  4.8799896240234375 0.0 10.122426986694336
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1022
Curr loss timestep torch.Size([788, 4]) tensor([181, 628, 343, 348], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 4.125205993652344
bi 1 loss 4.69832181930542
bi 2 loss 5.063516139984131
bi 3 loss 5.294274806976318
Layer  5  loss:  4.9659810066223145 0.0 10.998762130737305
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1022
Curr loss timestep torch.Size([788, 4]) tensor([136, 695, 349, 310], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 4.168610572814941
bi 1 loss 4.772294521331787
bi 2 loss 5.143828868865967
bi 3 loss 5.4385881423950195
Layer  6  loss:  4.976945400238037 0.0 12.173118591308594
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1022
Curr loss timestep torch.Size([788, 4]) tensor([184, 542, 511, 346], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 4.313755512237549
bi 1 loss 4.704916954040527
bi 2 loss 5.177055835723877
bi 3 loss 5.547122955322266
Epoch 0: :   3%|▎         | 15190/600000 [01:19<50:45, v_num=12, reduced_train_loss=0.220, global_step=15188.0, consumed_samples=60756.0, train_step_timing in s=0.322]Epoch 0: :   3%|▎         | 15190/600000 [01:19<50:45, v_num=12, reduced_train_loss=36.60, global_step=15189.0, consumed_samples=60760.0, train_step_timing in s=0.468]loss mask original None

First layer loss:  0.10157666355371475 torch.Size([521, 4]) 6.715602397918701 0.0
Max loss timestep torch.Size([521, 4]) tensor([388, 327, 189, 317], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.16325679421424866
speech mask sum tensor(359, device='cuda:0') loss mask sum tensor(359, device='cuda:0')
bi 1 loss 0.08568544685840607
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 2 loss 0.026218347251415253
speech mask sum tensor(62, device='cuda:0') loss mask sum tensor(62, device='cuda:0')
bi 3 loss 0.03683756664395332
speech mask sum tensor(195, device='cuda:0') loss mask sum tensor(195, device='cuda:0')
logits torch.Size([521, 4, 257024]) labels torch.Size([521, 4]) 0 257023
Layer  0  loss:  0.11388109624385834 0.0 10.695793151855469
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1023
Curr loss timestep torch.Size([521, 4]) tensor([393, 327, 186, 162], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.14920933544635773
bi 1 loss 0.1311964988708496
bi 2 loss 0.027135975658893585
bi 3 loss 0.04933837428689003
Layer  1  loss:  0.1042826920747757 0.0 9.392326354980469
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([499, 327, 195, 300], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.1504979431629181
bi 1 loss 0.09552200883626938
bi 2 loss 0.029655825346708298
bi 3 loss 0.05662935599684715
Layer  2  loss:  0.11263022571802139 0.0 18.7293758392334
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1023
Curr loss timestep torch.Size([521, 4]) tensor([389, 327, 205, 294], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.13509653508663177
bi 1 loss 0.14867743849754333
bi 2 loss 0.025622937828302383
bi 3 loss 0.04255146160721779
Layer  3  loss:  0.12117072194814682 0.0 14.545866012573242
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([402, 327, 199, 264], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.17183753848075867
bi 1 loss 0.12282966077327728
bi 2 loss 0.021400094032287598
bi 3 loss 0.05701901763677597
Layer  4  loss:  0.10126957297325134 0.0 15.446962356567383
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([393, 327, 188, 308], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.11728823184967041
bi 1 loss 0.13816075026988983
bi 2 loss 0.036535248160362244
bi 3 loss 0.03465944528579712
Layer  5  loss:  0.10236886143684387 0.0 7.8239874839782715
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([303, 327, 199, 268], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.15475991368293762
bi 1 loss 0.09686440974473953
bi 2 loss 0.017517799511551857
bi 3 loss 0.04150346666574478
Layer  6  loss:  0.12814491987228394 0.0 10.628005027770996
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([388, 327, 199, 274], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.1975364089012146
bi 1 loss 0.12146686762571335
bi 2 loss 0.00876768771559
bi 3 loss 0.04879440739750862
Epoch 0: :   3%|▎         | 15191/600000 [01:19<51:00, v_num=12, reduced_train_loss=36.60, global_step=15189.0, consumed_samples=60760.0, train_step_timing in s=0.468]Epoch 0: :   3%|▎         | 15191/600000 [01:19<51:00, v_num=12, reduced_train_loss=0.885, global_step=15190.0, consumed_samples=60764.0, train_step_timing in s=0.360]loss mask original None

First layer loss:  0.08539211750030518 torch.Size([415, 4]) 11.841129302978516 0.0
Max loss timestep torch.Size([415, 4]) tensor([274, 184, 175, 264], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.119048573076725
speech mask sum tensor(261, device='cuda:0') loss mask sum tensor(261, device='cuda:0')
bi 1 loss 0.015304293483495712
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 2 loss 0.030177777633070946
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 3 loss 0.1024022251367569
speech mask sum tensor(185, device='cuda:0') loss mask sum tensor(185, device='cuda:0')
logits torch.Size([415, 4, 257024]) labels torch.Size([415, 4]) 0 257022
Layer  0  loss:  0.08014236390590668 0.0 10.940195083618164
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1023
Curr loss timestep torch.Size([415, 4]) tensor([369, 143, 180, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.050477009266614914
bi 1 loss 0.028100257739424706
bi 2 loss 0.037651222199201584
bi 3 loss 0.17078621685504913
Layer  1  loss:  0.08503315597772598 0.0 14.670903205871582
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([322, 140, 128, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.05586906149983406
bi 1 loss 0.02169036492705345
bi 2 loss 0.030136827379465103
bi 3 loss 0.18748897314071655
Layer  2  loss:  0.06299613416194916 0.0 9.430354118347168
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([166, 151, 167, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.039699822664260864
bi 1 loss 0.016964847221970558
bi 2 loss 0.02898220717906952
bi 3 loss 0.13685807585716248
Layer  3  loss:  0.07489678263664246 0.0 12.817879676818848
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1019
Curr loss timestep torch.Size([415, 4]) tensor([383, 184, 145, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.04093238338828087
bi 1 loss 0.02144104614853859
bi 2 loss 0.05762488394975662
bi 3 loss 0.1569645255804062
Layer  4  loss:  0.0687045156955719 0.0 8.425315856933594
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1021
Curr loss timestep torch.Size([415, 4]) tensor([256, 180, 204, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.031597163528203964
bi 1 loss 0.022596638649702072
bi 2 loss 0.03445491939783096
bi 3 loss 0.16222788393497467
Layer  5  loss:  0.11015723645687103 0.0 12.824349403381348
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([367, 172, 203, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.07552781701087952
bi 1 loss 0.02565198950469494
bi 2 loss 0.03244774788618088
bi 3 loss 0.24351491034030914
Layer  6  loss:  0.07976388186216354 0.0 13.634417533874512
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1020
Curr loss timestep torch.Size([415, 4]) tensor([209, 150, 143, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.047120559960603714
bi 1 loss 0.0219288133084774
bi 2 loss 0.0311470665037632
bi 3 loss 0.18088531494140625
Epoch 0: :   3%|▎         | 15192/600000 [01:19<51:13, v_num=12, reduced_train_loss=0.885, global_step=15190.0, consumed_samples=60764.0, train_step_timing in s=0.360]Epoch 0: :   3%|▎         | 15192/600000 [01:19<51:13, v_num=12, reduced_train_loss=0.647, global_step=15191.0, consumed_samples=60768.0, train_step_timing in s=0.304]loss mask original None

First layer loss:  0.036434631794691086 torch.Size([375, 4]) 0.7147011160850525 0.0
Max loss timestep torch.Size([375, 4]) tensor([272, 179, 225, 170], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 0.03989271819591522
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 1 loss 0.02864188328385353
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 2 loss 0.03884267061948776
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 3 loss 0.03804551064968109
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
logits torch.Size([375, 4, 257024]) labels torch.Size([375, 4]) 0 257023
Layer  0  loss:  0.05695461109280586 0.0 2.0910918712615967
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([283, 164, 180, 190], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.05856618285179138
bi 1 loss 0.04745813086628914
bi 2 loss 0.09837201982736588
bi 3 loss 0.04030364006757736
Layer  1  loss:  0.04031725227832794 0.0 2.690983772277832
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([289, 180, 258, 229], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.05829530209302902
bi 1 loss 0.04436832666397095
bi 2 loss 0.02357667125761509
bi 3 loss 0.031609341502189636
Layer  2  loss:  0.053501617163419724 0.0 2.4941093921661377
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([311, 163, 185, 299], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.06982506811618805
bi 1 loss 0.045942217111587524
bi 2 loss 0.04740879684686661
bi 3 loss 0.04897068068385124
Layer  3  loss:  0.04331035912036896 0.0 2.113485336303711
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1019
Curr loss timestep torch.Size([375, 4]) tensor([289,  61, 263, 123], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.06535525619983673
bi 1 loss 0.04474034160375595
bi 2 loss 0.018590809777379036
bi 3 loss 0.03750113025307655
Layer  4  loss:  0.044108133763074875 0.0 2.373958110809326
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([315, 117, 227, 308], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.05245889723300934
bi 1 loss 0.0372501015663147
bi 2 loss 0.026178648695349693
bi 3 loss 0.05198187008500099
Layer  5  loss:  0.06713796406984329 0.0 4.7392258644104
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([289, 132, 203, 301], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.09494751691818237
bi 1 loss 0.04116472974419594
bi 2 loss 0.07292570173740387
bi 3 loss 0.060356639325618744
Layer  6  loss:  0.051079027354717255 0.0 4.829476833343506
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([315, 106, 177, 299], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.05705610662698746
bi 1 loss 0.039422761648893356
bi 2 loss 0.032498765736818314
bi 3 loss 0.0647885799407959
Epoch 0: :   3%|▎         | 15193/600000 [01:20<51:25, v_num=12, reduced_train_loss=0.647, global_step=15191.0, consumed_samples=60768.0, train_step_timing in s=0.304]Epoch 0: :   3%|▎         | 15193/600000 [01:20<51:26, v_num=12, reduced_train_loss=0.393, global_step=15192.0, consumed_samples=60772.0, train_step_timing in s=0.303]loss mask original None

First layer loss:  0.10704289376735687 torch.Size([651, 4]) 9.062874794006348 0.0
Max loss timestep torch.Size([651, 4]) tensor([283, 283, 309, 397], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.05051255598664284
speech mask sum tensor(65, device='cuda:0') loss mask sum tensor(65, device='cuda:0')
bi 1 loss 0.07333920150995255
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
bi 2 loss 0.07761482894420624
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 3 loss 0.1398974359035492
speech mask sum tensor(502, device='cuda:0') loss mask sum tensor(502, device='cuda:0')
logits torch.Size([651, 4, 257024]) labels torch.Size([651, 4]) 0 257023
Layer  0  loss:  0.14122334122657776 0.0 10.407894134521484
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([261, 284, 309, 397], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.09604407101869583
bi 1 loss 0.07903110235929489
bi 2 loss 0.11200974881649017
bi 3 loss 0.18289686739444733
Layer  1  loss:  0.14992816746234894 0.0 10.022173881530762
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([272, 302, 292, 630], device='cuda:0') tensor(630, device='cuda:0')
bi 0 loss 0.1354273557662964
bi 1 loss 0.12790271639823914
bi 2 loss 0.051670581102371216
bi 3 loss 0.20407046377658844
Layer  2  loss:  0.15738722681999207 0.0 11.600401878356934
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([272, 321, 309, 611], device='cuda:0') tensor(611, device='cuda:0')
bi 0 loss 0.12865962088108063
bi 1 loss 0.12933306396007538
bi 2 loss 0.1274767369031906
bi 3 loss 0.18479952216148376
Layer  3  loss:  0.15394996106624603 0.0 10.188879013061523
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1021
Curr loss timestep torch.Size([651, 4]) tensor([272, 343, 309, 397], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.03330613300204277
bi 1 loss 0.10293874144554138
bi 2 loss 0.1148023009300232
bi 3 loss 0.20579113066196442
Layer  4  loss:  0.16446934640407562 0.0 15.522319793701172
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([245, 267, 309, 612], device='cuda:0') tensor(612, device='cuda:0')
bi 0 loss 0.08659013360738754
bi 1 loss 0.16398616135120392
bi 2 loss 0.15251784026622772
bi 3 loss 0.18011000752449036
Layer  5  loss:  0.16109631955623627 0.0 9.959238052368164
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([287, 284, 306, 612], device='cuda:0') tensor(612, device='cuda:0')
bi 0 loss 0.09165234863758087
bi 1 loss 0.1826355755329132
bi 2 loss 0.1331978291273117
bi 3 loss 0.174796000123024
Layer  6  loss:  0.14747707545757294 0.0 11.406982421875
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([282, 344, 309, 387], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.13026757538318634
bi 1 loss 0.10199633240699768
bi 2 loss 0.11301181465387344
bi 3 loss 0.18180124461650848
Epoch 0: :   3%|▎         | 15194/600000 [01:20<51:44, v_num=12, reduced_train_loss=0.393, global_step=15192.0, consumed_samples=60772.0, train_step_timing in s=0.303]Epoch 0: :   3%|▎         | 15194/600000 [01:20<51:44, v_num=12, reduced_train_loss=1.180, global_step=15193.0, consumed_samples=60776.0, train_step_timing in s=0.443]loss mask original None

First layer loss:  3.575606107711792 torch.Size([332, 4]) 9.766526222229004 0.0
Max loss timestep torch.Size([332, 4]) tensor([166, 135, 164, 240], device='cuda:0') tensor(135, device='cuda:0')
bi 0 loss 3.4024765491485596
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 1 loss 2.6868388652801514
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 2 loss 3.838005781173706
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 3 loss 4.161081314086914
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
logits torch.Size([332, 4, 257024]) labels torch.Size([332, 4]) 0 257023
Layer  0  loss:  4.334984302520752 0.0 10.1907320022583
logits torch.Size([332, 4, 1024]) labels torch.Size([332, 4]) 0 1023
Curr loss timestep torch.Size([332, 4]) tensor([ 88, 144, 158, 253], device='cuda:0') tensor(138, device='cuda:0')
bi 0 loss 4.258723258972168
bi 1 loss 3.6891229152679443
bi 2 loss 4.714278697967529
bi 3 loss 4.503762245178223
Layer  1  loss:  4.6623759269714355 0.0 10.389549255371094
logits torch.Size([332, 4, 1024]) labels torch.Size([332, 4]) 0 1023
Curr loss timestep torch.Size([332, 4]) tensor([173, 212, 306, 199], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 4.606675148010254
bi 1 loss 4.271970748901367
bi 2 loss 4.76107120513916
bi 3 loss 4.927356243133545
Layer  2  loss:  4.874111175537109 0.0 9.842559814453125
logits torch.Size([332, 4, 1024]) labels torch.Size([332, 4]) 0 1022
Curr loss timestep torch.Size([332, 4]) tensor([157, 126, 300, 244], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 4.854547500610352
bi 1 loss 4.652078628540039
bi 2 loss 4.914028644561768
bi 3 loss 5.037100791931152
Layer  3  loss:  5.105296611785889 0.0 9.780692100524902
logits torch.Size([332, 4, 1024]) labels torch.Size([332, 4]) 0 1023
Curr loss timestep torch.Size([332, 4]) tensor([112, 117, 162, 174], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 5.19504451751709
bi 1 loss 4.806395053863525
bi 2 loss 5.13623046875
bi 3 loss 5.28287935256958
Layer  4  loss:  5.224777698516846 0.0 9.302730560302734
logits torch.Size([332, 4, 1024]) labels torch.Size([332, 4]) 0 1022
Curr loss timestep torch.Size([332, 4]) tensor([ 82, 158, 172, 105], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 5.416480541229248
bi 1 loss 5.021327018737793
bi 2 loss 5.070526599884033
bi 3 loss 5.478763580322266
Layer  5  loss:  5.253314018249512 0.0 10.555307388305664
logits torch.Size([332, 4, 1024]) labels torch.Size([332, 4]) 0 1016
Curr loss timestep torch.Size([332, 4]) tensor([134, 136, 247, 207], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 5.3454813957214355
bi 1 loss 5.070109844207764
bi 2 loss 5.000211238861084
bi 3 loss 5.6675639152526855
Layer  6  loss:  5.2432756423950195 0.0 10.244012832641602
logits torch.Size([332, 4, 1024]) labels torch.Size([332, 4]) 0 1022
Curr loss timestep torch.Size([332, 4]) tensor([107, 138, 286, 161], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 5.2733049392700195
bi 1 loss 5.125319957733154
bi 2 loss 5.086390018463135
bi 3 loss 5.520170211791992
Epoch 0: :   3%|▎         | 15195/600000 [01:20<51:55, v_num=12, reduced_train_loss=1.180, global_step=15193.0, consumed_samples=60776.0, train_step_timing in s=0.443]Epoch 0: :   3%|▎         | 15195/600000 [01:20<51:55, v_num=12, reduced_train_loss=38.30, global_step=15194.0, consumed_samples=60780.0, train_step_timing in s=0.261]loss mask original None

First layer loss:  0.1314724087715149 torch.Size([567, 4]) 14.539779663085938 0.0
Max loss timestep torch.Size([567, 4]) tensor([215,  69, 327, 430], device='cuda:0') tensor(430, device='cuda:0')
bi 0 loss 0.03308343514800072
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 1 loss 0.1097337082028389
speech mask sum tensor(368, device='cuda:0') loss mask sum tensor(368, device='cuda:0')
bi 2 loss 0.11695303022861481
speech mask sum tensor(333, device='cuda:0') loss mask sum tensor(333, device='cuda:0')
bi 3 loss 0.19582141935825348
speech mask sum tensor(360, device='cuda:0') loss mask sum tensor(360, device='cuda:0')
logits torch.Size([567, 4, 257024]) labels torch.Size([567, 4]) 0 257022
Layer  0  loss:  0.11519885808229446 0.0 9.964649200439453
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([166, 330, 357, 432], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 0.02623165398836136
bi 1 loss 0.08220276236534119
bi 2 loss 0.07669615745544434
bi 3 loss 0.21049194037914276
Layer  1  loss:  0.13860949873924255 0.0 13.283827781677246
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([165, 330, 281, 431], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.02518284134566784
bi 1 loss 0.09438575059175491
bi 2 loss 0.11323579400777817
bi 3 loss 0.24036943912506104
Layer  2  loss:  0.1431116908788681 0.0 12.458362579345703
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([187, 330, 455, 431], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.014642897993326187
bi 1 loss 0.11012487858533859
bi 2 loss 0.15934833884239197
bi 3 loss 0.199282705783844
Layer  3  loss:  0.15321218967437744 0.0 12.342975616455078
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1021
Curr loss timestep torch.Size([567, 4]) tensor([163, 330, 254, 431], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.05040827393531799
bi 1 loss 0.12298917770385742
bi 2 loss 0.1582844853401184
bi 3 loss 0.20939946174621582
Layer  4  loss:  0.14640159904956818 0.0 17.31258201599121
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1022
Curr loss timestep torch.Size([567, 4]) tensor([208, 333, 458, 432], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 0.05247887969017029
bi 1 loss 0.10335575044155121
bi 2 loss 0.12195314466953278
bi 3 loss 0.24041296541690826
Layer  5  loss:  0.12596957385540009 0.0 9.806490898132324
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([169, 330, 470, 430], device='cuda:0') tensor(430, device='cuda:0')
bi 0 loss 0.05565367266535759
bi 1 loss 0.09415541589260101
bi 2 loss 0.08977936208248138
bi 3 loss 0.2124754637479782
Layer  6  loss:  0.13501368463039398 0.0 13.31353759765625
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([165, 320, 366, 432], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 0.034012261778116226
bi 1 loss 0.09008703380823135
bi 2 loss 0.0974697396159172
bi 3 loss 0.2451256662607193
Epoch 0: :   3%|▎         | 15196/600000 [01:21<52:12, v_num=12, reduced_train_loss=38.30, global_step=15194.0, consumed_samples=60780.0, train_step_timing in s=0.261]Epoch 0: :   3%|▎         | 15196/600000 [01:21<52:12, v_num=12, reduced_train_loss=1.090, global_step=15195.0, consumed_samples=60784.0, train_step_timing in s=0.401]loss mask original None

First layer loss:  0.05258043482899666 torch.Size([451, 4]) 2.113834857940674 0.0
Max loss timestep torch.Size([451, 4]) tensor([272, 142, 306,  50], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.07209219038486481
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 1 loss 0.04017351195216179
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 2 loss 0.048764850944280624
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 3 loss 0.039379801601171494
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
logits torch.Size([451, 4, 257024]) labels torch.Size([451, 4]) 0 257023
Layer  0  loss:  0.044680818915367126 0.0 1.1432949304580688
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([272, 162, 206, 115], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.051527999341487885
bi 1 loss 0.04585438221693039
bi 2 loss 0.04317125305533409
bi 3 loss 0.034482602030038834
Layer  1  loss:  0.046205583959817886 0.0 3.670888662338257
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([325, 293, 306, 217], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.05294211581349373
bi 1 loss 0.03701081871986389
bi 2 loss 0.056572142988443375
bi 3 loss 0.036901745945215225
Layer  2  loss:  0.034847442060709 0.0 1.0001109838485718
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1022
Curr loss timestep torch.Size([451, 4]) tensor([235, 250, 226, 153], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 0.04548819735646248
bi 1 loss 0.03600268438458443
bi 2 loss 0.031577855348587036
bi 3 loss 0.02046576328575611
Layer  3  loss:  0.04989631846547127 0.0 3.9149553775787354
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1021
Curr loss timestep torch.Size([451, 4]) tensor([283, 135, 306,  61], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.06385252624750137
bi 1 loss 0.04724642261862755
bi 2 loss 0.04458557814359665
bi 3 loss 0.036194752901792526
Layer  4  loss:  0.041234228760004044 0.0 1.8132375478744507
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1022
Curr loss timestep torch.Size([451, 4]) tensor([283, 155, 256, 203], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.05639250949025154
bi 1 loss 0.04225469008088112
bi 2 loss 0.03968009725213051
bi 3 loss 0.018784454092383385
Layer  5  loss:  0.044811759144067764 0.0 2.803056478500366
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([408, 279, 306, 218], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.05458083748817444
bi 1 loss 0.04811232164502144
bi 2 loss 0.03664037585258484
bi 3 loss 0.0336390845477581
Layer  6  loss:  0.043133366852998734 0.0 1.5994505882263184
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1022
Curr loss timestep torch.Size([451, 4]) tensor([282, 279, 306, 117], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.05845518410205841
bi 1 loss 0.035033948719501495
bi 2 loss 0.04389737546443939
bi 3 loss 0.027910152450203896
Epoch 0: :   3%|▎         | 15197/600000 [01:21<52:25, v_num=12, reduced_train_loss=1.090, global_step=15195.0, consumed_samples=60784.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15197/600000 [01:21<52:25, v_num=12, reduced_train_loss=0.357, global_step=15196.0, consumed_samples=60788.0, train_step_timing in s=0.322]loss mask original None

First layer loss:  0.19309121370315552 torch.Size([583, 4]) 10.784808158874512 0.0
Max loss timestep torch.Size([583, 4]) tensor([546, 397, 344, 141], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.2610134780406952
speech mask sum tensor(321, device='cuda:0') loss mask sum tensor(321, device='cuda:0')
bi 1 loss 0.19368936121463776
speech mask sum tensor(258, device='cuda:0') loss mask sum tensor(258, device='cuda:0')
bi 2 loss 0.17244337499141693
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
bi 3 loss 0.015403480269014835
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
logits torch.Size([583, 4, 257024]) labels torch.Size([583, 4]) 0 257022
Layer  0  loss:  0.2313915640115738 0.0 14.99501895904541
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([546, 395, 344, 122], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.40723904967308044
bi 1 loss 0.15347781777381897
bi 2 loss 0.1799851506948471
bi 3 loss 0.03329279646277428
Layer  1  loss:  0.26494258642196655 0.0 12.874870300292969
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([545, 396, 344, 123], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.39276739954948425
bi 1 loss 0.20169749855995178
bi 2 loss 0.25033384561538696
bi 3 loss 0.01683500036597252
Layer  2  loss:  0.25784507393836975 0.0 14.291412353515625
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([570, 394, 345, 108], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.32844194769859314
bi 1 loss 0.19785703718662262
bi 2 loss 0.2796347439289093
bi 3 loss 0.04060829058289528
Layer  3  loss:  0.27630725502967834 0.0 15.185951232910156
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1021
Curr loss timestep torch.Size([583, 4]) tensor([456, 396, 345, 111], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.41163450479507446
bi 1 loss 0.22842471301555634
bi 2 loss 0.24663834273815155
bi 3 loss 0.02717764489352703
Layer  4  loss:  0.28861063718795776 0.0 11.031429290771484
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([545, 396, 399, 144], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.41705188155174255
bi 1 loss 0.22036151587963104
bi 2 loss 0.2786814868450165
bi 3 loss 0.028997574001550674
Layer  5  loss:  0.33135536313056946 0.0 19.024351119995117
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([411, 396, 344, 102], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.5280775427818298
bi 1 loss 0.18135754764080048
bi 2 loss 0.323650598526001
bi 3 loss 0.048318035900592804
Layer  6  loss:  0.2860863506793976 0.0 13.713776588439941
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1019
Curr loss timestep torch.Size([583, 4]) tensor([546, 350, 399, 126], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.4053964614868164
bi 1 loss 0.2009916603565216
bi 2 loss 0.29064807295799255
bi 3 loss 0.042740561068058014
Epoch 0: :   3%|▎         | 15198/600000 [01:22<52:42, v_num=12, reduced_train_loss=0.357, global_step=15196.0, consumed_samples=60788.0, train_step_timing in s=0.322]Epoch 0: :   3%|▎         | 15198/600000 [01:22<52:42, v_num=12, reduced_train_loss=2.130, global_step=15197.0, consumed_samples=60792.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  0.18414568901062012 torch.Size([626, 4]) 11.843836784362793 0.0
Max loss timestep torch.Size([626, 4]) tensor([486, 526, 262, 280], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.08777119964361191
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
bi 1 loss 0.23650643229484558
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
bi 2 loss 0.20889970660209656
speech mask sum tensor(339, device='cuda:0') loss mask sum tensor(339, device='cuda:0')
bi 3 loss 0.22478412091732025
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
logits torch.Size([626, 4, 257024]) labels torch.Size([626, 4]) 0 257022
Layer  0  loss:  0.22627635300159454 0.0 14.954046249389648
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1023
Curr loss timestep torch.Size([626, 4]) tensor([295, 521, 265, 391], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.11191561818122864
bi 1 loss 0.3052178621292114
bi 2 loss 0.232016459107399
bi 3 loss 0.27928757667541504
Layer  1  loss:  0.25169655680656433 0.0 15.336392402648926
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1023
Curr loss timestep torch.Size([626, 4]) tensor([297, 533, 436, 393], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.15613077580928802
bi 1 loss 0.3254711329936981
bi 2 loss 0.24773110449314117
bi 3 loss 0.29646140336990356
Layer  2  loss:  0.27936553955078125 0.0 16.82380485534668
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1022
Curr loss timestep torch.Size([626, 4]) tensor([297, 526, 265, 391], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.11925988644361496
bi 1 loss 0.4089996814727783
bi 2 loss 0.25555938482284546
bi 3 loss 0.3629692792892456
Layer  3  loss:  0.2846311926841736 0.0 9.812606811523438
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1017
Curr loss timestep torch.Size([626, 4]) tensor([259, 292, 265, 280], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.13342051208019257
bi 1 loss 0.3768555521965027
bi 2 loss 0.32385244965553284
bi 3 loss 0.3397160470485687
Layer  4  loss:  0.2784649431705475 0.0 14.209357261657715
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1023
Curr loss timestep torch.Size([626, 4]) tensor([258, 533, 265, 391], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.1596849262714386
bi 1 loss 0.3491995930671692
bi 2 loss 0.299646258354187
bi 3 loss 0.3308010697364807
Layer  5  loss:  0.3235435485839844 0.0 13.828259468078613
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1022
Curr loss timestep torch.Size([626, 4]) tensor([486, 353, 436, 541], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.18717727065086365
bi 1 loss 0.39144933223724365
bi 2 loss 0.3167541027069092
bi 3 loss 0.4193831980228424
Layer  6  loss:  0.32319438457489014 0.0 14.922295570373535
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1023
Curr loss timestep torch.Size([626, 4]) tensor([486, 521, 262, 393], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.14367079734802246
bi 1 loss 0.39410877227783203
bi 2 loss 0.2986464500427246
bi 3 loss 0.47712400555610657
Epoch 0: :   3%|▎         | 15199/600000 [01:22<52:59, v_num=12, reduced_train_loss=2.130, global_step=15197.0, consumed_samples=60792.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15199/600000 [01:22<52:59, v_num=12, reduced_train_loss=2.150, global_step=15198.0, consumed_samples=60796.0, train_step_timing in s=0.424]loss mask original None

First layer loss:  0.30125224590301514 torch.Size([714, 4]) 11.769193649291992 0.0
Max loss timestep torch.Size([714, 4]) tensor([351, 522, 301, 263], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.2879478335380554
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 0.3712020516395569
speech mask sum tensor(500, device='cuda:0') loss mask sum tensor(500, device='cuda:0')
bi 2 loss 0.2901915907859802
speech mask sum tensor(315, device='cuda:0') loss mask sum tensor(315, device='cuda:0')
bi 3 loss 0.12184618413448334
speech mask sum tensor(167, device='cuda:0') loss mask sum tensor(167, device='cuda:0')
logits torch.Size([714, 4, 257024]) labels torch.Size([714, 4]) 0 257022
Layer  0  loss:  0.4201103746891022 0.0 17.368925094604492
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([353, 530, 292, 263], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.351533979177475
bi 1 loss 0.5633241534233093
bi 2 loss 0.3226350247859955
bi 3 loss 0.22241076827049255
Layer  1  loss:  0.48816734552383423 0.0 15.87964153289795
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1022
Curr loss timestep torch.Size([714, 4]) tensor([353, 530, 299, 263], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.33392533659935
bi 1 loss 0.6918421387672424
bi 2 loss 0.37803155183792114
bi 3 loss 0.19231823086738586
Layer  2  loss:  0.5209442973136902 0.0 17.785154342651367
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1022
Curr loss timestep torch.Size([714, 4]) tensor([351, 562, 298, 263], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.42329248785972595
bi 1 loss 0.6694662570953369
bi 2 loss 0.47081270813941956
bi 3 loss 0.23807284235954285
Layer  3  loss:  0.4646165370941162 0.0 17.47662353515625
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([352, 564, 291, 263], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.2658655345439911
bi 1 loss 0.6672706007957458
bi 2 loss 0.36360451579093933
bi 3 loss 0.1852640062570572
Layer  4  loss:  0.5463600754737854 0.0 13.622286796569824
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1022
Curr loss timestep torch.Size([714, 4]) tensor([353, 555, 298, 264], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.33347058296203613
bi 1 loss 0.7639243006706238
bi 2 loss 0.4187386631965637
bi 3 loss 0.2822936773300171
Layer  5  loss:  0.5140276551246643 0.0 15.653290748596191
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1022
Curr loss timestep torch.Size([714, 4]) tensor([351, 555, 299, 263], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.4098139703273773
bi 1 loss 0.7342648506164551
bi 2 loss 0.35954225063323975
bi 3 loss 0.2177935391664505
Layer  6  loss:  0.511262059211731 0.0 16.609445571899414
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([353, 563, 291, 263], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.35688841342926025
bi 1 loss 0.7428879737854004
bi 2 loss 0.35847511887550354
bi 3 loss 0.21226775646209717
Epoch 0: :   3%|▎         | 15200/600000 [01:23<53:19, v_num=12, reduced_train_loss=2.150, global_step=15198.0, consumed_samples=60796.0, train_step_timing in s=0.424]Epoch 0: :   3%|▎         | 15200/600000 [01:23<53:19, v_num=12, reduced_train_loss=3.770, global_step=15199.0, consumed_samples=60800.0, train_step_timing in s=0.480]loss mask original None

First layer loss:  0.016894228756427765 torch.Size([290, 4]) 1.8366491794586182 0.0
Max loss timestep torch.Size([290, 4]) tensor([208, 198, 221, 139], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 0.01416295487433672
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 1 loss 0.02823774516582489
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 2 loss 0.01280905306339264
speech mask sum tensor(78, device='cuda:0') loss mask sum tensor(78, device='cuda:0')
bi 3 loss 0.012086217291653156
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
logits torch.Size([290, 4, 257024]) labels torch.Size([290, 4]) 0 257022
Layer  0  loss:  0.014087045565247536 0.0 0.3648476004600525
logits torch.Size([290, 4, 1024]) labels torch.Size([290, 4]) 0 1023
Curr loss timestep torch.Size([290, 4]) tensor([132, 207, 278,  88], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.01385473646223545
bi 1 loss 0.01641129143536091
bi 2 loss 0.016395922750234604
bi 3 loss 0.011052098125219345
Layer  1  loss:  0.01297038421034813 0.0 0.5462812781333923
logits torch.Size([290, 4, 1024]) labels torch.Size([290, 4]) 0 1022
Curr loss timestep torch.Size([290, 4]) tensor([228, 264, 261, 156], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.012901512905955315
bi 1 loss 0.01496752630919218
bi 2 loss 0.011104783974587917
bi 3 loss 0.012113338336348534
Layer  2  loss:  0.012204328551888466 0.0 0.13830308616161346
logits torch.Size([290, 4, 1024]) labels torch.Size([290, 4]) 0 1022
Curr loss timestep torch.Size([290, 4]) tensor([120, 252, 278, 184], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 0.014668126590549946
bi 1 loss 0.012554553337395191
bi 2 loss 0.009052945300936699
bi 3 loss 0.009945137426257133
Layer  3  loss:  0.01305864192545414 0.0 0.16146957874298096
logits torch.Size([290, 4, 1024]) labels torch.Size([290, 4]) 0 1023
Curr loss timestep torch.Size([290, 4]) tensor([261, 161, 253,  78], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 0.013396765105426311
bi 1 loss 0.012085380963981152
bi 2 loss 0.015178554691374302
bi 3 loss 0.012432776391506195
Layer  4  loss:  0.012742436490952969 0.0 0.15341295301914215
logits torch.Size([290, 4, 1024]) labels torch.Size([290, 4]) 0 1022
Curr loss timestep torch.Size([290, 4]) tensor([ 84, 165, 278, 150], device='cuda:0') tensor(150, device='cuda:0')
bi 0 loss 0.012186061590909958
bi 1 loss 0.014352426864206791
bi 2 loss 0.011527357622981071
bi 3 loss 0.012620284222066402
Layer  5  loss:  0.013082229532301426 0.0 0.38930782675743103
logits torch.Size([290, 4, 1024]) labels torch.Size([290, 4]) 0 1023
Curr loss timestep torch.Size([290, 4]) tensor([109, 245, 278,  79], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.012244157493114471
bi 1 loss 0.014680800959467888
bi 2 loss 0.013574297539889812
bi 3 loss 0.012513474561274052
Layer  6  loss:  0.011251960881054401 0.0 0.18109188973903656
logits torch.Size([290, 4, 1024]) labels torch.Size([290, 4]) 0 1023
Curr loss timestep torch.Size([290, 4]) tensor([134, 200, 250, 127], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 0.011622176505625248
bi 1 loss 0.013313883915543556
bi 2 loss 0.010292244143784046
bi 3 loss 0.009251557290554047
Epoch 0: :   3%|▎         | 15201/600000 [01:23<53:30, v_num=12, reduced_train_loss=3.770, global_step=15199.0, consumed_samples=60800.0, train_step_timing in s=0.480]Epoch 0: :   3%|▎         | 15201/600000 [01:23<53:30, v_num=12, reduced_train_loss=0.106, global_step=15200.0, consumed_samples=60804.0, train_step_timing in s=0.250]loss mask original None

First layer loss:  3.413682699203491 torch.Size([404, 4]) 10.49240779876709 0.0
Max loss timestep torch.Size([404, 4]) tensor([112, 104, 106, 227], device='cuda:0') tensor(104, device='cuda:0')
bi 0 loss 3.1651344299316406
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
bi 1 loss 3.303786039352417
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 2 loss 3.9439868927001953
speech mask sum tensor(269, device='cuda:0') loss mask sum tensor(269, device='cuda:0')
bi 3 loss 3.093216896057129
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
logits torch.Size([404, 4, 257024]) labels torch.Size([404, 4]) 0 257022
Layer  0  loss:  3.9161593914031982 0.0 11.005291938781738
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([117, 136, 295, 374], device='cuda:0') tensor(117, device='cuda:0')
bi 0 loss 3.718440532684326
bi 1 loss 4.196944713592529
bi 2 loss 4.099559307098389
bi 3 loss 3.773866891860962
Layer  1  loss:  4.336520671844482 0.0 10.64808464050293
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([102,  86, 142, 158], device='cuda:0') tensor(142, device='cuda:0')
bi 0 loss 4.185150623321533
bi 1 loss 4.543288707733154
bi 2 loss 4.534298896789551
bi 3 loss 4.173587799072266
Layer  2  loss:  4.620223045349121 0.0 10.84293270111084
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([124, 112, 353, 274], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 4.38521671295166
bi 1 loss 4.567683696746826
bi 2 loss 4.77484655380249
bi 3 loss 4.642994403839111
Layer  3  loss:  4.822104454040527 0.0 10.955578804016113
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([223, 147, 108, 212], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 4.717498302459717
bi 1 loss 4.70235538482666
bi 2 loss 4.987471103668213
bi 3 loss 4.769003391265869
Layer  4  loss:  4.912870407104492 0.0 9.738452911376953
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([ 89,  85, 323, 298], device='cuda:0') tensor(138, device='cuda:0')
bi 0 loss 4.697760105133057
bi 1 loss 4.750393867492676
bi 2 loss 5.153545379638672
bi 3 loss 4.873932361602783
Layer  5  loss:  4.949901580810547 0.0 10.029770851135254
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([158, 143, 130, 370], device='cuda:0') tensor(143, device='cuda:0')
bi 0 loss 4.765995979309082
bi 1 loss 5.058646202087402
bi 2 loss 5.044959545135498
bi 3 loss 4.943241119384766
Layer  6  loss:  5.097962856292725 0.0 9.528501510620117
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1021
Curr loss timestep torch.Size([404, 4]) tensor([131, 115, 351, 166], device='cuda:0') tensor(150, device='cuda:0')
bi 0 loss 4.984862804412842
bi 1 loss 4.8778839111328125
bi 2 loss 5.336853981018066
bi 3 loss 5.0114288330078125
Epoch 0: :   3%|▎         | 15202/600000 [01:23<53:42, v_num=12, reduced_train_loss=0.106, global_step=15200.0, consumed_samples=60804.0, train_step_timing in s=0.250]Epoch 0: :   3%|▎         | 15202/600000 [01:23<53:42, v_num=12, reduced_train_loss=36.10, global_step=15201.0, consumed_samples=60808.0, train_step_timing in s=0.291]loss mask original None

First layer loss:  0.1376192569732666 torch.Size([554, 4]) 10.109683990478516 0.0
Max loss timestep torch.Size([554, 4]) tensor([514, 289, 520, 306], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.14469659328460693
speech mask sum tensor(192, device='cuda:0') loss mask sum tensor(192, device='cuda:0')
bi 1 loss 0.1264198273420334
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 2 loss 0.16374312341213226
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
bi 3 loss 0.11930480599403381
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
logits torch.Size([554, 4, 257024]) labels torch.Size([554, 4]) 0 257022
Layer  0  loss:  0.16158460080623627 0.0 8.56828784942627
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([516, 265, 524, 267], device='cuda:0') tensor(524, device='cuda:0')
bi 0 loss 0.10623755306005478
bi 1 loss 0.17144544422626495
bi 2 loss 0.223195418715477
bi 3 loss 0.13773445785045624
Layer  1  loss:  0.20479175448417664 0.0 10.125335693359375
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([514, 286, 525, 349], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.12785370647907257
bi 1 loss 0.2148304283618927
bi 2 loss 0.2524138391017914
bi 3 loss 0.2049892693758011
Layer  2  loss:  0.18526573479175568 0.0 10.30630111694336
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([356, 367, 527, 460], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.11967959254980087
bi 1 loss 0.19981595873832703
bi 2 loss 0.23538562655448914
bi 3 loss 0.17383290827274323
Layer  3  loss:  0.21347400546073914 0.0 11.804583549499512
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([517, 286, 524, 347], device='cuda:0') tensor(524, device='cuda:0')
bi 0 loss 0.16439686715602875
bi 1 loss 0.2061857432126999
bi 2 loss 0.29925259947776794
bi 3 loss 0.17718923091888428
Layer  4  loss:  0.1880015730857849 0.0 9.473040580749512
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([357, 283, 303, 351], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.1781032532453537
bi 1 loss 0.17460450530052185
bi 2 loss 0.2709406912326813
bi 3 loss 0.13479600846767426
Layer  5  loss:  0.2077031284570694 0.0 17.055282592773438
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([357, 286, 527, 348], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.1631632149219513
bi 1 loss 0.17027722299098969
bi 2 loss 0.33795398473739624
bi 3 loss 0.15176396071910858
Layer  6  loss:  0.18246681988239288 0.0 18.67241668701172
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([355, 265, 527, 491], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.12831084430217743
bi 1 loss 0.12369316071271896
bi 2 loss 0.30537518858909607
bi 3 loss 0.15185807645320892
Epoch 0: :   3%|▎         | 15203/600000 [01:24<53:58, v_num=12, reduced_train_loss=36.10, global_step=15201.0, consumed_samples=60808.0, train_step_timing in s=0.291]Epoch 0: :   3%|▎         | 15203/600000 [01:24<53:58, v_num=12, reduced_train_loss=1.480, global_step=15202.0, consumed_samples=60812.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  3.8215651512145996 torch.Size([444, 4]) 10.83653450012207 0.0
Max loss timestep torch.Size([444, 4]) tensor([257, 161, 369, 280], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 3.3823437690734863
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 1 loss 3.54815936088562
speech mask sum tensor(159, device='cuda:0') loss mask sum tensor(159, device='cuda:0')
bi 2 loss 4.142281532287598
speech mask sum tensor(257, device='cuda:0') loss mask sum tensor(257, device='cuda:0')
bi 3 loss 3.8588969707489014
speech mask sum tensor(239, device='cuda:0') loss mask sum tensor(239, device='cuda:0')
logits torch.Size([444, 4, 257024]) labels torch.Size([444, 4]) 0 257023
Layer  0  loss:  4.1455607414245605 0.0 11.878863334655762
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1023
Curr loss timestep torch.Size([444, 4]) tensor([242, 109, 194, 215], device='cuda:0') tensor(191, device='cuda:0')
bi 0 loss 4.127785682678223
bi 1 loss 4.091446876525879
bi 2 loss 3.98789644241333
bi 3 loss 4.3592071533203125
Layer  1  loss:  4.432420253753662 0.0 9.780841827392578
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1023
Curr loss timestep torch.Size([444, 4]) tensor([169, 144, 420, 334], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 4.528197288513184
bi 1 loss 4.375514507293701
bi 2 loss 4.351348876953125
bi 3 loss 4.5137739181518555
Layer  2  loss:  4.846675872802734 0.0 10.683321952819824
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([185,  64, 264, 182], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.92186975479126
bi 1 loss 4.821852684020996
bi 2 loss 4.853124141693115
bi 3 loss 4.821961879730225
Layer  3  loss:  4.951161861419678 0.0 9.980827331542969
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1023
Curr loss timestep torch.Size([444, 4]) tensor([223,  83, 214, 362], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.985400199890137
bi 1 loss 4.865780830383301
bi 2 loss 5.035676956176758
bi 3 loss 4.901468276977539
Layer  4  loss:  5.063912391662598 0.0 9.813423156738281
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([208,  61, 348, 344], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.991396903991699
bi 1 loss 4.9420366287231445
bi 2 loss 5.184311389923096
bi 3 loss 5.04859733581543
Layer  5  loss:  5.099044322967529 0.0 9.656676292419434
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1021
Curr loss timestep torch.Size([444, 4]) tensor([183, 111, 421, 296], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 5.039644718170166
bi 1 loss 4.914816856384277
bi 2 loss 5.295566558837891
bi 3 loss 5.037373065948486
Layer  6  loss:  5.197739124298096 0.0 9.665571212768555
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([232, 191, 247, 192], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 5.352821350097656
bi 1 loss 5.135343074798584
bi 2 loss 5.328817367553711
bi 3 loss 5.027571678161621
Epoch 0: :   3%|▎         | 15204/600000 [01:24<54:11, v_num=12, reduced_train_loss=1.480, global_step=15202.0, consumed_samples=60812.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15204/600000 [01:24<54:11, v_num=12, reduced_train_loss=37.60, global_step=15203.0, consumed_samples=60816.0, train_step_timing in s=0.309]loss mask original None

First layer loss:  0.0891912505030632 torch.Size([490, 4]) 8.953768730163574 0.0
Max loss timestep torch.Size([490, 4]) tensor([339, 412, 118, 285], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.07250922173261642
speech mask sum tensor(306, device='cuda:0') loss mask sum tensor(306, device='cuda:0')
bi 1 loss 0.05113353580236435
speech mask sum tensor(276, device='cuda:0') loss mask sum tensor(276, device='cuda:0')
bi 2 loss 0.02880064956843853
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 3 loss 0.16910138726234436
speech mask sum tensor(317, device='cuda:0') loss mask sum tensor(317, device='cuda:0')
logits torch.Size([490, 4, 257024]) labels torch.Size([490, 4]) 0 257022
Layer  0  loss:  0.10481223464012146 0.0 8.604425430297852
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([446, 208, 174, 285], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.10271015763282776
bi 1 loss 0.05800360441207886
bi 2 loss 0.029071111232042313
bi 3 loss 0.1860637664794922
Layer  1  loss:  0.10937301814556122 0.0 13.158884048461914
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1022
Curr loss timestep torch.Size([490, 4]) tensor([395, 380, 222, 393], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.09743152558803558
bi 1 loss 0.05457933619618416
bi 2 loss 0.040446046739816666
bi 3 loss 0.2036140263080597
Layer  2  loss:  0.10345945507287979 0.0 10.98248291015625
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1022
Curr loss timestep torch.Size([490, 4]) tensor([301, 152, 172, 393], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.09688626974821091
bi 1 loss 0.04526308923959732
bi 2 loss 0.03316371142864227
bi 3 loss 0.196176216006279
Layer  3  loss:  0.11110226064920425 0.0 15.67042064666748
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1022
Curr loss timestep torch.Size([490, 4]) tensor([351, 189, 183, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.09847306460142136
bi 1 loss 0.05884101986885071
bi 2 loss 0.05525032803416252
bi 3 loss 0.19716154038906097
Layer  4  loss:  0.10442408919334412 0.0 10.7117338180542
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1022
Curr loss timestep torch.Size([490, 4]) tensor([326, 411, 202, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.10952290147542953
bi 1 loss 0.0432111918926239
bi 2 loss 0.03452639654278755
bi 3 loss 0.18829810619354248
Layer  5  loss:  0.08899048715829849 0.0 7.563368797302246
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([434, 239, 207, 393], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.10283549875020981
bi 1 loss 0.057530395686626434
bi 2 loss 0.02503335289657116
bi 3 loss 0.1354999840259552
Layer  6  loss:  0.1012413427233696 0.0 8.389452934265137
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([436, 370, 222, 285], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.10722298920154572
bi 1 loss 0.05755685642361641
bi 2 loss 0.02171912044286728
bi 3 loss 0.17388997972011566
Epoch 0: :   3%|▎         | 15205/600000 [01:24<54:25, v_num=12, reduced_train_loss=37.60, global_step=15203.0, consumed_samples=60816.0, train_step_timing in s=0.309]Epoch 0: :   3%|▎         | 15205/600000 [01:24<54:25, v_num=12, reduced_train_loss=0.813, global_step=15204.0, consumed_samples=60820.0, train_step_timing in s=0.340]loss mask original None

First layer loss:  0.06768953055143356 torch.Size([499, 4]) 6.253481864929199 0.0
Max loss timestep torch.Size([499, 4]) tensor([365, 259, 116, 411], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.07810380309820175
speech mask sum tensor(409, device='cuda:0') loss mask sum tensor(409, device='cuda:0')
bi 1 loss 0.06224198639392853
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 2 loss 0.030326977372169495
speech mask sum tensor(110, device='cuda:0') loss mask sum tensor(110, device='cuda:0')
bi 3 loss 0.07011979818344116
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
logits torch.Size([499, 4, 257024]) labels torch.Size([499, 4]) 0 257019
Layer  0  loss:  0.07364819198846817 0.0 6.090292453765869
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([276, 165, 157, 349], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.08313493430614471
bi 1 loss 0.032144978642463684
bi 2 loss 0.02604237198829651
bi 3 loss 0.10180076956748962
Layer  1  loss:  0.09932497143745422 0.0 12.257223129272461
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([276, 259, 170, 413], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.11003046482801437
bi 1 loss 0.040346577763557434
bi 2 loss 0.035312749445438385
bi 3 loss 0.14216940104961395
Layer  2  loss:  0.12375345081090927 0.0 7.276003837585449
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([311, 271, 169, 411], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.1373457908630371
bi 1 loss 0.05648548901081085
bi 2 loss 0.02537667378783226
bi 3 loss 0.18121099472045898
Layer  3  loss:  0.10112567245960236 0.0 6.97005558013916
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1021
Curr loss timestep torch.Size([499, 4]) tensor([311, 252, 151, 349], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.1096377968788147
bi 1 loss 0.045402560383081436
bi 2 loss 0.03841354325413704
bi 3 loss 0.14508429169654846
Layer  4  loss:  0.10622275620698929 0.0 9.909666061401367
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([276, 255, 172, 413], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.1283838003873825
bi 1 loss 0.04303903505206108
bi 2 loss 0.07132074981927872
bi 3 loss 0.1209356039762497
Layer  5  loss:  0.10249581933021545 0.0 7.065990924835205
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([363, 258, 140, 358], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 0.10391957312822342
bi 1 loss 0.036819618195295334
bi 2 loss 0.04312824085354805
bi 3 loss 0.16172288358211517
Layer  6  loss:  0.09762925654649734 0.0 9.813485145568848
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([276, 155, 172, 413], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.11169349402189255
bi 1 loss 0.04520002007484436
bi 2 loss 0.02781483344733715
bi 3 loss 0.13401803374290466
Epoch 0: :   3%|▎         | 15206/600000 [01:25<54:40, v_num=12, reduced_train_loss=0.813, global_step=15204.0, consumed_samples=60820.0, train_step_timing in s=0.340]Epoch 0: :   3%|▎         | 15206/600000 [01:25<54:40, v_num=12, reduced_train_loss=0.772, global_step=15205.0, consumed_samples=60824.0, train_step_timing in s=0.348]loss mask original None

First layer loss:  3.2817788124084473 torch.Size([460, 4]) 12.887433052062988 0.0
Max loss timestep torch.Size([460, 4]) tensor([167, 425, 193, 167], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 2.92185378074646
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 1 loss 3.292524814605713
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 2 loss 3.2511415481567383
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 3 loss 3.6476030349731445
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
logits torch.Size([460, 4, 257024]) labels torch.Size([460, 4]) 0 257023
Layer  0  loss:  3.9912149906158447 0.0 10.728135108947754
logits torch.Size([460, 4, 1024]) labels torch.Size([460, 4]) 0 1023
Curr loss timestep torch.Size([460, 4]) tensor([217, 105, 196, 213], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 3.649977922439575
bi 1 loss 4.089326858520508
bi 2 loss 3.5890305042266846
bi 3 loss 4.332371234893799
Layer  1  loss:  4.35004186630249 0.0 9.282794952392578
logits torch.Size([460, 4, 1024]) labels torch.Size([460, 4]) 0 1022
Curr loss timestep torch.Size([460, 4]) tensor([184,  85, 167, 223], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.2327561378479
bi 1 loss 4.317934513092041
bi 2 loss 4.102272987365723
bi 3 loss 4.764028549194336
Layer  2  loss:  4.589011192321777 0.0 10.168447494506836
logits torch.Size([460, 4, 1024]) labels torch.Size([460, 4]) 0 1022
Curr loss timestep torch.Size([460, 4]) tensor([170, 347, 156, 211], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 4.360671520233154
bi 1 loss 4.716606140136719
bi 2 loss 3.988682985305786
bi 3 loss 4.864684581756592
Layer  3  loss:  4.712336540222168 0.0 10.142684936523438
logits torch.Size([460, 4, 1024]) labels torch.Size([460, 4]) 0 1019
Curr loss timestep torch.Size([460, 4]) tensor([160, 317, 228, 205], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.6126017570495605
bi 1 loss 4.808849811553955
bi 2 loss 4.202394485473633
bi 3 loss 4.88625955581665
Layer  4  loss:  4.758921146392822 0.0 10.349847793579102
logits torch.Size([460, 4, 1024]) labels torch.Size([460, 4]) 0 1022
Curr loss timestep torch.Size([460, 4]) tensor([199, 362, 186, 206], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.486935138702393
bi 1 loss 4.884474754333496
bi 2 loss 4.481337070465088
bi 3 loss 4.844327926635742
Layer  5  loss:  4.904838562011719 0.0 10.109601974487305
logits torch.Size([460, 4, 1024]) labels torch.Size([460, 4]) 0 1022
Curr loss timestep torch.Size([460, 4]) tensor([142, 226, 168, 137], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 4.664190292358398
bi 1 loss 5.085077285766602
bi 2 loss 4.532067775726318
bi 3 loss 4.850876331329346
Layer  6  loss:  4.887948989868164 0.0 10.913408279418945
logits torch.Size([460, 4, 1024]) labels torch.Size([460, 4]) 0 1023
Curr loss timestep torch.Size([460, 4]) tensor([193, 366, 225, 225], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 4.8072686195373535
bi 1 loss 4.980866432189941
bi 2 loss 4.595470905303955
bi 3 loss 4.8900346755981445
Epoch 0: :   3%|▎         | 15207/600000 [01:25<54:53, v_num=12, reduced_train_loss=0.772, global_step=15205.0, consumed_samples=60824.0, train_step_timing in s=0.348]Epoch 0: :   3%|▎         | 15207/600000 [01:25<54:53, v_num=12, reduced_train_loss=35.50, global_step=15206.0, consumed_samples=60828.0, train_step_timing in s=0.317]loss mask original None

First layer loss:  0.08201643824577332 torch.Size([451, 4]) 7.16170072555542 0.0
Max loss timestep torch.Size([451, 4]) tensor([130, 366, 365,  93], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.05858775973320007
speech mask sum tensor(71, device='cuda:0') loss mask sum tensor(71, device='cuda:0')
bi 1 loss 0.14604027569293976
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 2 loss 0.05660305544734001
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
bi 3 loss 0.03311274200677872
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
logits torch.Size([451, 4, 257024]) labels torch.Size([451, 4]) 0 257022
Layer  0  loss:  0.1092473641037941 0.0 11.476061820983887
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([138, 366, 424, 119], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.034602921456098557
bi 1 loss 0.1932121217250824
bi 2 loss 0.08793283998966217
bi 3 loss 0.03196649253368378
Layer  1  loss:  0.11265378445386887 0.0 14.619023323059082
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([108, 367, 425, 112], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.01692976802587509
bi 1 loss 0.23494789004325867
bi 2 loss 0.06939356029033661
bi 3 loss 0.0337122343480587
Layer  2  loss:  0.10885521024465561 0.0 13.536130905151367
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1022
Curr loss timestep torch.Size([451, 4]) tensor([138, 367, 425,  85], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.01932123303413391
bi 1 loss 0.21185140311717987
bi 2 loss 0.07718809694051743
bi 3 loss 0.03171180561184883
Layer  3  loss:  0.12073293328285217 0.0 17.11884307861328
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1018
Curr loss timestep torch.Size([451, 4]) tensor([134, 366, 384,  84], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.020508304238319397
bi 1 loss 0.24913179874420166
bi 2 loss 0.07766936719417572
bi 3 loss 0.02958579547703266
Layer  4  loss:  0.11802584677934647 0.0 12.85506534576416
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1022
Curr loss timestep torch.Size([451, 4]) tensor([109, 366, 425,  79], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.040565066039562225
bi 1 loss 0.21764595806598663
bi 2 loss 0.0883074551820755
bi 3 loss 0.03443991765379906
Layer  5  loss:  0.11434448510408401 0.0 11.368204116821289
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1020
Curr loss timestep torch.Size([451, 4]) tensor([140, 366, 428, 120], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.05417459085583687
bi 1 loss 0.1980874389410019
bi 2 loss 0.09045891463756561
bi 3 loss 0.037153493613004684
Layer  6  loss:  0.07382988184690475 0.0 5.484237194061279
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([111, 367, 365,  88], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.021376049146056175
bi 1 loss 0.13094668090343475
bi 2 loss 0.05639319866895676
bi 3 loss 0.03241543099284172
Epoch 0: :   3%|▎         | 15208/600000 [01:26<55:07, v_num=12, reduced_train_loss=35.50, global_step=15206.0, consumed_samples=60828.0, train_step_timing in s=0.317]Epoch 0: :   3%|▎         | 15208/600000 [01:26<55:07, v_num=12, reduced_train_loss=0.840, global_step=15207.0, consumed_samples=60832.0, train_step_timing in s=0.323]loss mask original None

First layer loss:  0.06884649395942688 torch.Size([549, 4]) 7.111988544464111 0.0
Max loss timestep torch.Size([549, 4]) tensor([218, 117, 403, 273], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.04916516691446304
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 1 loss 0.03078984096646309
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 2 loss 0.10083986073732376
speech mask sum tensor(299, device='cuda:0') loss mask sum tensor(299, device='cuda:0')
bi 3 loss 0.06620345264673233
speech mask sum tensor(357, device='cuda:0') loss mask sum tensor(357, device='cuda:0')
logits torch.Size([549, 4, 257024]) labels torch.Size([549, 4]) 0 257023
Layer  0  loss:  0.08713338524103165 0.0 8.963829040527344
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([186, 122, 396, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.04389183968305588
bi 1 loss 0.03125901147723198
bi 2 loss 0.11919165402650833
bi 3 loss 0.10410220921039581
Layer  1  loss:  0.12015504390001297 0.0 16.359420776367188
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([232, 170, 396, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.07237076759338379
bi 1 loss 0.037226155400276184
bi 2 loss 0.18077921867370605
bi 3 loss 0.12486385554075241
Layer  2  loss:  0.10624627768993378 0.0 12.0314302444458
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([200, 122, 402, 272], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.04315771162509918
bi 1 loss 0.040729451924562454
bi 2 loss 0.15851624310016632
bi 3 loss 0.12106478959321976
Layer  3  loss:  0.10513398796319962 0.0 12.735970497131348
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1022
Curr loss timestep torch.Size([549, 4]) tensor([230, 120, 396, 304], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.044573791325092316
bi 1 loss 0.04198380559682846
bi 2 loss 0.14467807114124298
bi 3 loss 0.12834885716438293
Layer  4  loss:  0.10482744872570038 0.0 15.992119789123535
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1022
Curr loss timestep torch.Size([549, 4]) tensor([149, 135, 403, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.04974609985947609
bi 1 loss 0.02736518904566765
bi 2 loss 0.14933393895626068
bi 3 loss 0.12546466290950775
Layer  5  loss:  0.10180389136075974 0.0 8.225595474243164
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1020
Curr loss timestep torch.Size([549, 4]) tensor([136, 119, 396, 272], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.04998104274272919
bi 1 loss 0.022184917703270912
bi 2 loss 0.15224087238311768
bi 3 loss 0.11629453301429749
Layer  6  loss:  0.11266600340604782 0.0 10.584640502929688
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([103, 162, 396, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.05034720152616501
bi 1 loss 0.036183107644319534
bi 2 loss 0.14759264886379242
bi 3 loss 0.14521700143814087
Epoch 0: :   3%|▎         | 15209/600000 [01:26<55:22, v_num=12, reduced_train_loss=0.840, global_step=15207.0, consumed_samples=60832.0, train_step_timing in s=0.323]Epoch 0: :   3%|▎         | 15209/600000 [01:26<55:23, v_num=12, reduced_train_loss=0.807, global_step=15208.0, consumed_samples=60836.0, train_step_timing in s=0.377]loss mask original None

First layer loss:  0.05814063921570778 torch.Size([469, 4]) 5.898320198059082 0.0
Max loss timestep torch.Size([469, 4]) tensor([259,  78, 243, 270], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.06717822700738907
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
bi 1 loss 0.024908848106861115
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 2 loss 0.04468311741948128
speech mask sum tensor(389, device='cuda:0') loss mask sum tensor(389, device='cuda:0')
bi 3 loss 0.09522738307714462
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
logits torch.Size([469, 4, 257024]) labels torch.Size([469, 4]) 0 257022
Layer  0  loss:  0.08477115631103516 0.0 5.889211177825928
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1023
Curr loss timestep torch.Size([469, 4]) tensor([297, 129, 260, 444], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.11462146788835526
bi 1 loss 0.02022768370807171
bi 2 loss 0.09750639647245407
bi 3 loss 0.09888195246458054
Layer  1  loss:  0.08033569157123566 0.0 6.945021629333496
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1023
Curr loss timestep torch.Size([469, 4]) tensor([296, 164, 331, 355], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.17982888221740723
bi 1 loss 0.013776901178061962
bi 2 loss 0.0791580006480217
bi 3 loss 0.09637989848852158
Layer  2  loss:  0.07151438295841217 0.0 8.192741394042969
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1022
Curr loss timestep torch.Size([469, 4]) tensor([297, 144, 362, 404], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.21792729198932648
bi 1 loss 0.022529078647494316
bi 2 loss 0.06105678901076317
bi 3 loss 0.07697469741106033
Layer  3  loss:  0.07856464385986328 0.0 5.817402362823486
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1021
Curr loss timestep torch.Size([469, 4]) tensor([296,  52, 259, 444], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.2046445906162262
bi 1 loss 0.038388922810554504
bi 2 loss 0.07812243700027466
bi 3 loss 0.06999513506889343
Layer  4  loss:  0.07177892327308655 0.0 6.605942726135254
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1021
Curr loss timestep torch.Size([469, 4]) tensor([297,  52, 102, 444], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.16584165394306183
bi 1 loss 0.024531148374080658
bi 2 loss 0.05981399118900299
bi 3 loss 0.09245138615369797
Layer  5  loss:  0.09501127153635025 0.0 7.2245049476623535
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1022
Curr loss timestep torch.Size([469, 4]) tensor([297,  76, 259, 444], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.2062940001487732
bi 1 loss 0.027818521484732628
bi 2 loss 0.07489873468875885
bi 3 loss 0.13484783470630646
Layer  6  loss:  0.10069684684276581 0.0 9.601981163024902
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1023
Curr loss timestep torch.Size([469, 4]) tensor([296,  54, 259, 444], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.19888214766979218
bi 1 loss 0.017518771812319756
bi 2 loss 0.08393736183643341
bi 3 loss 0.14929674565792084
Epoch 0: :   3%|▎         | 15210/600000 [01:26<55:37, v_num=12, reduced_train_loss=0.807, global_step=15208.0, consumed_samples=60836.0, train_step_timing in s=0.377]Epoch 0: :   3%|▎         | 15210/600000 [01:26<55:37, v_num=12, reduced_train_loss=0.641, global_step=15209.0, consumed_samples=60840.0, train_step_timing in s=0.344]loss mask original None

First layer loss:  0.15665888786315918 torch.Size([639, 4]) 13.657994270324707 0.0
Max loss timestep torch.Size([639, 4]) tensor([424, 277, 198, 314], device='cuda:0') tensor(424, device='cuda:0')
bi 0 loss 0.1504698395729065
speech mask sum tensor(483, device='cuda:0') loss mask sum tensor(483, device='cuda:0')
bi 1 loss 0.0717778354883194
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
bi 2 loss 0.04508655518293381
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 3 loss 0.2279619425535202
speech mask sum tensor(485, device='cuda:0') loss mask sum tensor(485, device='cuda:0')
logits torch.Size([639, 4, 257024]) labels torch.Size([639, 4]) 0 257022
Layer  0  loss:  0.15706850588321686 0.0 10.236757278442383
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1023
Curr loss timestep torch.Size([639, 4]) tensor([408, 289, 220, 547], device='cuda:0') tensor(547, device='cuda:0')
bi 0 loss 0.14770196378231049
bi 1 loss 0.051680296659469604
bi 2 loss 0.03426402434706688
bi 3 loss 0.24189192056655884
Layer  1  loss:  0.18360893428325653 0.0 12.273033142089844
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1023
Curr loss timestep torch.Size([639, 4]) tensor([424, 245, 126, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.1655394434928894
bi 1 loss 0.05063521862030029
bi 2 loss 0.04306976497173309
bi 3 loss 0.29192855954170227
Layer  2  loss:  0.16815228760242462 0.0 12.484026908874512
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([424, 195, 100, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.14281007647514343
bi 1 loss 0.08568280935287476
bi 2 loss 0.05349479988217354
bi 3 loss 0.25881972908973694
Layer  3  loss:  0.2102537900209427 0.0 19.354877471923828
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1021
Curr loss timestep torch.Size([639, 4]) tensor([408, 299, 183, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.15479232370853424
bi 1 loss 0.06740205734968185
bi 2 loss 0.07254677265882492
bi 3 loss 0.3579784035682678
Layer  4  loss:  0.202694833278656 0.0 16.094539642333984
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([424, 292, 101, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.15787021815776825
bi 1 loss 0.08636318892240524
bi 2 loss 0.06291837990283966
bi 3 loss 0.33211392164230347
Layer  5  loss:  0.20460177958011627 0.0 19.194475173950195
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([424, 256, 106, 314], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.14968271553516388
bi 1 loss 0.07978995144367218
bi 2 loss 0.05997199937701225
bi 3 loss 0.3484274446964264
Layer  6  loss:  0.18966545164585114 0.0 11.002328872680664
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([435, 303, 115, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.14453940093517303
bi 1 loss 0.03648759052157402
bi 2 loss 0.058855388313531876
bi 3 loss 0.32801541686058044
Epoch 0: :   3%|▎         | 15211/600000 [01:27<55:55, v_num=12, reduced_train_loss=0.641, global_step=15209.0, consumed_samples=60840.0, train_step_timing in s=0.344]Epoch 0: :   3%|▎         | 15211/600000 [01:27<55:55, v_num=12, reduced_train_loss=1.470, global_step=15210.0, consumed_samples=60844.0, train_step_timing in s=0.436]loss mask original None

First layer loss:  3.667215347290039 torch.Size([416, 4]) 10.484441757202148 0.0
Max loss timestep torch.Size([416, 4]) tensor([256, 263, 109, 276], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 3.8636627197265625
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 1 loss 3.7326908111572266
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
bi 2 loss 3.4912877082824707
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 3 loss 3.5622334480285645
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
logits torch.Size([416, 4, 257024]) labels torch.Size([416, 4]) 0 257022
Layer  0  loss:  4.015190124511719 0.0 11.071121215820312
logits torch.Size([416, 4, 1024]) labels torch.Size([416, 4]) 0 1023
Curr loss timestep torch.Size([416, 4]) tensor([221, 205, 160, 205], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.063281536102295
bi 1 loss 3.9065957069396973
bi 2 loss 3.8741071224212646
bi 3 loss 4.186232566833496
Layer  1  loss:  4.3265910148620605 0.0 11.231600761413574
logits torch.Size([416, 4, 1024]) labels torch.Size([416, 4]) 0 1022
Curr loss timestep torch.Size([416, 4]) tensor([180, 379, 248, 323], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 4.651489734649658
bi 1 loss 4.1290283203125
bi 2 loss 4.234163761138916
bi 3 loss 4.30322790145874
Layer  2  loss:  4.582140922546387 0.0 9.984646797180176
logits torch.Size([416, 4, 1024]) labels torch.Size([416, 4]) 0 1022
Curr loss timestep torch.Size([416, 4]) tensor([198, 300, 194, 334], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 4.8444623947143555
bi 1 loss 4.349161624908447
bi 2 loss 4.5477166175842285
bi 3 loss 4.605045795440674
Layer  3  loss:  4.757234573364258 0.0 9.664898872375488
logits torch.Size([416, 4, 1024]) labels torch.Size([416, 4]) 0 1022
Curr loss timestep torch.Size([416, 4]) tensor([234, 205, 164, 263], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 5.113218307495117
bi 1 loss 4.5393781661987305
bi 2 loss 4.6488237380981445
bi 3 loss 4.738414287567139
Layer  4  loss:  4.867330551147461 0.0 11.232536315917969
logits torch.Size([416, 4, 1024]) labels torch.Size([416, 4]) 0 1023
Curr loss timestep torch.Size([416, 4]) tensor([307, 400, 255, 352], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 5.20213508605957
bi 1 loss 4.540363311767578
bi 2 loss 4.8580217361450195
bi 3 loss 4.899446964263916
Layer  5  loss:  4.990114212036133 0.0 10.023299217224121
logits torch.Size([416, 4, 1024]) labels torch.Size([416, 4]) 0 1021
Curr loss timestep torch.Size([416, 4]) tensor([335, 255, 222, 186], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 5.3455400466918945
bi 1 loss 4.682923793792725
bi 2 loss 4.931634426116943
bi 3 loss 5.021780490875244
Layer  6  loss:  5.0308661460876465 0.0 10.927813529968262
logits torch.Size([416, 4, 1024]) labels torch.Size([416, 4]) 0 1023
Curr loss timestep torch.Size([416, 4]) tensor([318, 310, 231, 166], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 5.2111029624938965
bi 1 loss 4.721644878387451
bi 2 loss 5.224559307098389
bi 3 loss 5.028583526611328
Epoch 0: :   3%|▎         | 15212/600000 [01:27<56:07, v_num=12, reduced_train_loss=1.470, global_step=15210.0, consumed_samples=60844.0, train_step_timing in s=0.436]Epoch 0: :   3%|▎         | 15212/600000 [01:27<56:07, v_num=12, reduced_train_loss=36.20, global_step=15211.0, consumed_samples=60848.0, train_step_timing in s=0.295]loss mask original None

First layer loss:  0.2008943110704422 torch.Size([582, 4]) 9.468995094299316 0.0
Max loss timestep torch.Size([582, 4]) tensor([497, 174, 516, 322], device='cuda:0') tensor(496, device='cuda:0')
bi 0 loss 0.31520265340805054
speech mask sum tensor(428, device='cuda:0') loss mask sum tensor(428, device='cuda:0')
bi 1 loss 0.05344156548380852
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 2 loss 0.18935681879520416
speech mask sum tensor(299, device='cuda:0') loss mask sum tensor(299, device='cuda:0')
bi 3 loss 0.0892007052898407
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
logits torch.Size([582, 4, 257024]) labels torch.Size([582, 4]) 0 257023
Layer  0  loss:  0.215238556265831 0.0 16.33850860595703
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([496, 159, 392, 329], device='cuda:0') tensor(496, device='cuda:0')
bi 0 loss 0.36482444405555725
bi 1 loss 0.04803571477532387
bi 2 loss 0.17041008174419403
bi 3 loss 0.09188111871480942
Layer  1  loss:  0.2718699872493744 0.0 12.634870529174805
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([487, 114, 515, 325], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.43304285407066345
bi 1 loss 0.037805501371622086
bi 2 loss 0.21307580173015594
bi 3 loss 0.16698259115219116
Layer  2  loss:  0.2518760859966278 0.0 17.29657554626465
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([497, 117, 516, 345], device='cuda:0') tensor(497, device='cuda:0')
bi 0 loss 0.4199586808681488
bi 1 loss 0.055644288659095764
bi 2 loss 0.22254209220409393
bi 3 loss 0.09399660676717758
Layer  3  loss:  0.23215928673744202 0.0 13.437684059143066
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([496, 166, 392, 325], device='cuda:0') tensor(496, device='cuda:0')
bi 0 loss 0.3532451093196869
bi 1 loss 0.04412278160452843
bi 2 loss 0.23514792323112488
bi 3 loss 0.10809300094842911
Layer  4  loss:  0.2638908326625824 0.0 15.279284477233887
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([497, 150, 390, 325], device='cuda:0') tensor(497, device='cuda:0')
bi 0 loss 0.40654897689819336
bi 1 loss 0.049838390201330185
bi 2 loss 0.19625794887542725
bi 3 loss 0.18947729468345642
Layer  5  loss:  0.28528085350990295 0.0 15.095101356506348
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([487, 160, 516, 315], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.4302912652492523
bi 1 loss 0.06518541276454926
bi 2 loss 0.26459988951683044
bi 3 loss 0.1603604406118393
Layer  6  loss:  0.2732035517692566 0.0 18.17656898498535
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([497, 169, 393, 403], device='cuda:0') tensor(497, device='cuda:0')
bi 0 loss 0.4190405011177063
bi 1 loss 0.05749911442399025
bi 2 loss 0.2624652087688446
bi 3 loss 0.13529987633228302
Epoch 0: :   3%|▎         | 15213/600000 [01:28<56:24, v_num=12, reduced_train_loss=36.20, global_step=15211.0, consumed_samples=60848.0, train_step_timing in s=0.295]Epoch 0: :   3%|▎         | 15213/600000 [01:28<56:24, v_num=12, reduced_train_loss=1.990, global_step=15212.0, consumed_samples=60852.0, train_step_timing in s=0.412]loss mask original None

First layer loss:  3.9615347385406494 torch.Size([592, 4]) 11.594589233398438 0.0
Max loss timestep torch.Size([592, 4]) tensor([486, 222, 183,  66], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.062472820281982
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
bi 1 loss 4.005457878112793
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 2 loss 3.8235321044921875
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 3 loss 3.841893434524536
speech mask sum tensor(167, device='cuda:0') loss mask sum tensor(167, device='cuda:0')
logits torch.Size([592, 4, 257024]) labels torch.Size([592, 4]) 0 257023
Layer  0  loss:  4.3302388191223145 0.0 10.420007705688477
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([520, 172, 176, 208], device='cuda:0') tensor(97, device='cuda:0')
bi 0 loss 4.339921474456787
bi 1 loss 4.17536735534668
bi 2 loss 4.452810764312744
bi 3 loss 4.380651950836182
Layer  1  loss:  4.699443817138672 0.0 10.710245132446289
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([412, 174,  80, 126], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 4.896288871765137
bi 1 loss 4.597842216491699
bi 2 loss 4.410579681396484
bi 3 loss 4.707821846008301
Layer  2  loss:  4.9985527992248535 0.0 9.951690673828125
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1022
Curr loss timestep torch.Size([592, 4]) tensor([544, 205, 180, 120], device='cuda:0') tensor(120, device='cuda:0')
bi 0 loss 5.159325122833252
bi 1 loss 5.029901027679443
bi 2 loss 4.903522968292236
bi 3 loss 4.736698150634766
Layer  3  loss:  5.042529582977295 0.0 10.996624946594238
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1021
Curr loss timestep torch.Size([592, 4]) tensor([334, 159,  74,  66], device='cuda:0') tensor(107, device='cuda:0')
bi 0 loss 5.1108198165893555
bi 1 loss 5.079086780548096
bi 2 loss 4.839493751525879
bi 3 loss 5.056534767150879
Layer  4  loss:  5.19101095199585 0.0 9.938879013061523
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1022
Curr loss timestep torch.Size([592, 4]) tensor([516, 204,  98, 143], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 5.331146240234375
bi 1 loss 5.188961029052734
bi 2 loss 5.043289661407471
bi 3 loss 5.058774471282959
Layer  5  loss:  5.220373153686523 0.0 9.498542785644531
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([311, 180, 102,  81], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 5.4137396812438965
bi 1 loss 5.249706268310547
bi 2 loss 4.851365089416504
bi 3 loss 5.154860973358154
Layer  6  loss:  5.307582855224609 0.0 10.561830520629883
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1020
Curr loss timestep torch.Size([592, 4]) tensor([524, 249, 153, 214], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 5.398666858673096
bi 1 loss 5.346358299255371
bi 2 loss 5.154576778411865
bi 3 loss 5.227417469024658
Epoch 0: :   3%|▎         | 15214/600000 [01:28<56:40, v_num=12, reduced_train_loss=1.990, global_step=15212.0, consumed_samples=60852.0, train_step_timing in s=0.412]Epoch 0: :   3%|▎         | 15214/600000 [01:28<56:40, v_num=12, reduced_train_loss=38.80, global_step=15213.0, consumed_samples=60856.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  3.454179525375366 torch.Size([340, 4]) 10.374970436096191 0.0
Max loss timestep torch.Size([340, 4]) tensor([126, 166,  88, 152], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 3.2497341632843018
speech mask sum tensor(129, device='cuda:0') loss mask sum tensor(129, device='cuda:0')
bi 1 loss 2.9473040103912354
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 2 loss 3.4897658824920654
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 3 loss 3.7526025772094727
speech mask sum tensor(216, device='cuda:0') loss mask sum tensor(216, device='cuda:0')
logits torch.Size([340, 4, 257024]) labels torch.Size([340, 4]) 0 257023
Layer  0  loss:  3.8729465007781982 0.0 10.620856285095215
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1023
Curr loss timestep torch.Size([340, 4]) tensor([ 69, 189, 100, 166], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 3.7560622692108154
bi 1 loss 3.170292377471924
bi 2 loss 3.460846424102783
bi 3 loss 4.30467414855957
Layer  1  loss:  4.2218804359436035 0.0 10.276666641235352
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1022
Curr loss timestep torch.Size([340, 4]) tensor([127, 156,  88, 318], device='cuda:0') tensor(156, device='cuda:0')
bi 0 loss 3.9195425510406494
bi 1 loss 3.3715672492980957
bi 2 loss 3.99379825592041
bi 3 loss 4.771514415740967
Layer  2  loss:  4.450331687927246 0.0 10.440134048461914
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1022
Curr loss timestep torch.Size([340, 4]) tensor([173, 165,  87, 212], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 4.431614875793457
bi 1 loss 3.592926025390625
bi 2 loss 4.356194019317627
bi 3 loss 4.799069404602051
Layer  3  loss:  4.49641227722168 0.0 9.23617172241211
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1023
Curr loss timestep torch.Size([340, 4]) tensor([120, 207, 101, 309], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 4.497502326965332
bi 1 loss 3.3864567279815674
bi 2 loss 4.235466480255127
bi 3 loss 4.968161582946777
Layer  4  loss:  4.600908279418945 0.0 9.872899055480957
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1022
Curr loss timestep torch.Size([340, 4]) tensor([102, 176,  88, 273], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.581646919250488
bi 1 loss 3.8200483322143555
bi 2 loss 4.395816326141357
bi 3 loss 4.950226306915283
Layer  5  loss:  4.6441121101379395 0.0 8.809266090393066
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1022
Curr loss timestep torch.Size([340, 4]) tensor([ 85, 173,  74, 293], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 4.433040618896484
bi 1 loss 3.894805431365967
bi 2 loss 4.614657402038574
bi 3 loss 5.051721096038818
Layer  6  loss:  4.766774654388428 0.0 9.573596954345703
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1020
Curr loss timestep torch.Size([340, 4]) tensor([103, 161,  76, 324], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 4.850225925445557
bi 1 loss 3.9293019771575928
bi 2 loss 4.440306186676025
bi 3 loss 5.106362342834473
Epoch 0: :   3%|▎         | 15215/600000 [01:28<56:51, v_num=12, reduced_train_loss=38.80, global_step=15213.0, consumed_samples=60856.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15215/600000 [01:28<56:51, v_num=12, reduced_train_loss=34.50, global_step=15214.0, consumed_samples=60860.0, train_step_timing in s=0.266]loss mask original None

First layer loss:  0.15361514687538147 torch.Size([773, 4]) 13.207523345947266 0.0
Max loss timestep torch.Size([773, 4]) tensor([746, 289,  69, 279], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.21377557516098022
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
bi 1 loss 0.1583765149116516
speech mask sum tensor(192, device='cuda:0') loss mask sum tensor(192, device='cuda:0')
bi 2 loss 0.021509956568479538
speech mask sum tensor(77, device='cuda:0') loss mask sum tensor(77, device='cuda:0')
bi 3 loss 0.10553193837404251
speech mask sum tensor(383, device='cuda:0') loss mask sum tensor(383, device='cuda:0')
logits torch.Size([773, 4, 257024]) labels torch.Size([773, 4]) 0 257023
Layer  0  loss:  0.1870223432779312 0.0 10.332343101501465
logits torch.Size([773, 4, 1024]) labels torch.Size([773, 4]) 0 1023
Curr loss timestep torch.Size([773, 4]) tensor([746, 289,  90, 367], device='cuda:0') tensor(746, device='cuda:0')
bi 0 loss 0.24639062583446503
bi 1 loss 0.10748279094696045
bi 2 loss 0.03513813763856888
bi 3 loss 0.1861274689435959
Layer  1  loss:  0.19218340516090393 0.0 11.306221008300781
logits torch.Size([773, 4, 1024]) labels torch.Size([773, 4]) 0 1022
Curr loss timestep torch.Size([773, 4]) tensor([669, 289,  75, 280], device='cuda:0') tensor(669, device='cuda:0')
bi 0 loss 0.3104667663574219
bi 1 loss 0.15988485515117645
bi 2 loss 0.02332174964249134
bi 3 loss 0.1002599447965622
Layer  2  loss:  0.18792860209941864 0.0 12.00121784210205
logits torch.Size([773, 4, 1024]) labels torch.Size([773, 4]) 0 1022
Curr loss timestep torch.Size([773, 4]) tensor([746, 289,  54, 367], device='cuda:0') tensor(746, device='cuda:0')
bi 0 loss 0.2802260220050812
bi 1 loss 0.1050327941775322
bi 2 loss 0.030426718294620514
bi 3 loss 0.15029628574848175
Layer  3  loss:  0.20203621685504913 0.0 9.272608757019043
logits torch.Size([773, 4, 1024]) labels torch.Size([773, 4]) 0 1023
Curr loss timestep torch.Size([773, 4]) tensor([751, 303,  92, 280], device='cuda:0') tensor(751, device='cuda:0')
bi 0 loss 0.33810147643089294
bi 1 loss 0.08777061104774475
bi 2 loss 0.043618667870759964
bi 3 loss 0.1277467906475067
Layer  4  loss:  0.19845156371593475 0.0 16.12209129333496
logits torch.Size([773, 4, 1024]) labels torch.Size([773, 4]) 0 1022
Curr loss timestep torch.Size([773, 4]) tensor([746, 289,  63, 323], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.30020299553871155
bi 1 loss 0.14837105572223663
bi 2 loss 0.019581135362386703
bi 3 loss 0.13731010258197784
Layer  5  loss:  0.1876237392425537 0.0 11.765701293945312
logits torch.Size([773, 4, 1024]) labels torch.Size([773, 4]) 0 1023
Curr loss timestep torch.Size([773, 4]) tensor([751, 289,  56, 367], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.29653260111808777
bi 1 loss 0.14230148494243622
bi 2 loss 0.02520960569381714
bi 3 loss 0.11219210177659988
Layer  6  loss:  0.1885778158903122 0.0 11.084043502807617
logits torch.Size([773, 4, 1024]) labels torch.Size([773, 4]) 0 1023
Curr loss timestep torch.Size([773, 4]) tensor([695, 289,  99, 279], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.29747694730758667
bi 1 loss 0.12949545681476593
bi 2 loss 0.011891134083271027
bi 3 loss 0.12292525172233582
Epoch 0: :   3%|▎         | 15216/600000 [01:29<57:13, v_num=12, reduced_train_loss=34.50, global_step=15214.0, consumed_samples=60860.0, train_step_timing in s=0.266]Epoch 0: :   3%|▎         | 15216/600000 [01:29<57:13, v_num=12, reduced_train_loss=1.500, global_step=15215.0, consumed_samples=60864.0, train_step_timing in s=0.534]loss mask original None

First layer loss:  0.06277719140052795 torch.Size([470, 4]) 4.819304943084717 0.0
Max loss timestep torch.Size([470, 4]) tensor([288, 359, 412, 341], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.1388857513666153
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 1 loss 0.04986020177602768
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 2 loss 0.047519609332084656
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
bi 3 loss 0.05514046922326088
speech mask sum tensor(258, device='cuda:0') loss mask sum tensor(258, device='cuda:0')
logits torch.Size([470, 4, 257024]) labels torch.Size([470, 4]) 0 257022
Layer  0  loss:  0.07146621495485306 0.0 5.0693793296813965
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1023
Curr loss timestep torch.Size([470, 4]) tensor([289, 114, 263, 315], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.08988875150680542
bi 1 loss 0.058208346366882324
bi 2 loss 0.08785136789083481
bi 3 loss 0.052287399768829346
Layer  1  loss:  0.0790000930428505 0.0 6.765981197357178
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1023
Curr loss timestep torch.Size([470, 4]) tensor([289, 359, 258, 207], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.1393461674451828
bi 1 loss 0.08100512623786926
bi 2 loss 0.04651452600955963
bi 3 loss 0.0883704349398613
Layer  2  loss:  0.07707618176937103 0.0 4.449323654174805
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1022
Curr loss timestep torch.Size([470, 4]) tensor([289, 359, 279, 307], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.09170224517583847
bi 1 loss 0.08172590285539627
bi 2 loss 0.06820410490036011
bi 3 loss 0.07615206390619278
Layer  3  loss:  0.08517628908157349 0.0 8.585663795471191
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1022
Curr loss timestep torch.Size([470, 4]) tensor([289, 359, 260, 225], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.11068902164697647
bi 1 loss 0.08675206452608109
bi 2 loss 0.09224636852741241
bi 3 loss 0.05873723700642586
Layer  4  loss:  0.08148632943630219 0.0 5.899642467498779
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1022
Curr loss timestep torch.Size([470, 4]) tensor([289, 359, 412, 268], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.11639589816331863
bi 1 loss 0.10780778527259827
bi 2 loss 0.07590863108634949
bi 3 loss 0.04021678864955902
Layer  5  loss:  0.09599194675683975 0.0 6.337141990661621
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1022
Curr loss timestep torch.Size([470, 4]) tensor([288, 359, 339, 280], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.14656825363636017
bi 1 loss 0.07915623486042023
bi 2 loss 0.1191026046872139
bi 3 loss 0.05276757851243019
Layer  6  loss:  0.08812769502401352 0.0 4.511683464050293
logits torch.Size([470, 4, 1024]) labels torch.Size([470, 4]) 0 1021
Curr loss timestep torch.Size([470, 4]) tensor([295, 195, 261, 301], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.11417219042778015
bi 1 loss 0.06616632640361786
bi 2 loss 0.10914519429206848
bi 3 loss 0.06763522326946259
Epoch 0: :   3%|▎         | 15217/600000 [01:29<57:27, v_num=12, reduced_train_loss=1.500, global_step=15215.0, consumed_samples=60864.0, train_step_timing in s=0.534]Epoch 0: :   3%|▎         | 15217/600000 [01:29<57:27, v_num=12, reduced_train_loss=0.641, global_step=15216.0, consumed_samples=60868.0, train_step_timing in s=0.334]loss mask original None

First layer loss:  3.7778573036193848 torch.Size([488, 4]) 12.445284843444824 0.0
Max loss timestep torch.Size([488, 4]) tensor([328, 260, 336, 133], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 3.988142967224121
speech mask sum tensor(270, device='cuda:0') loss mask sum tensor(270, device='cuda:0')
bi 1 loss 3.790318250656128
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 2 loss 3.5770182609558105
speech mask sum tensor(351, device='cuda:0') loss mask sum tensor(351, device='cuda:0')
bi 3 loss 3.821608066558838
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257022
Layer  0  loss:  4.301309108734131 0.0 10.228837966918945
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([253, 337, 376, 325], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 4.468751430511475
bi 1 loss 4.174027442932129
bi 2 loss 4.205684185028076
bi 3 loss 4.356253623962402
Layer  1  loss:  4.825910568237305 0.0 11.458560943603516
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([478, 341,  86, 141], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 5.105183124542236
bi 1 loss 4.9179205894470215
bi 2 loss 4.557649612426758
bi 3 loss 4.82657527923584
Layer  2  loss:  4.956943511962891 0.0 10.60877799987793
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([382, 263, 167, 309], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 5.181508541107178
bi 1 loss 4.953568458557129
bi 2 loss 4.856517791748047
bi 3 loss 4.860453128814697
Layer  3  loss:  5.170534610748291 0.0 11.5106201171875
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([467, 354, 194, 330], device='cuda:0') tensor(332, device='cuda:0')
bi 0 loss 5.322045803070068
bi 1 loss 5.070160388946533
bi 2 loss 5.051147937774658
bi 3 loss 5.253629684448242
Layer  4  loss:  5.245635032653809 0.0 9.857770919799805
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([254, 391, 248, 219], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 5.537164688110352
bi 1 loss 5.147953033447266
bi 2 loss 5.136838912963867
bi 3 loss 5.164407730102539
Layer  5  loss:  5.330214977264404 0.0 9.590251922607422
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([428, 433, 311, 258], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 5.489906311035156
bi 1 loss 5.370842456817627
bi 2 loss 5.2469258308410645
bi 3 loss 5.243930816650391
Layer  6  loss:  5.37306022644043 0.0 11.017722129821777
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([257, 442, 252, 238], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 5.5274224281311035
bi 1 loss 5.262943267822266
bi 2 loss 5.294468402862549
bi 3 loss 5.40490198135376
Epoch 0: :   3%|▎         | 15218/600000 [01:30<57:41, v_num=12, reduced_train_loss=0.641, global_step=15216.0, consumed_samples=60868.0, train_step_timing in s=0.334]Epoch 0: :   3%|▎         | 15218/600000 [01:30<57:41, v_num=12, reduced_train_loss=39.00, global_step=15217.0, consumed_samples=60872.0, train_step_timing in s=0.325]loss mask original None

First layer loss:  0.11147129535675049 torch.Size([481, 4]) 6.2206878662109375 0.0
Max loss timestep torch.Size([481, 4]) tensor([339, 261, 313, 321], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.056456152349710464
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
bi 1 loss 0.12094921618700027
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 2 loss 0.19787491858005524
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 3 loss 0.11774355918169022
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
logits torch.Size([481, 4, 257024]) labels torch.Size([481, 4]) 0 257022
Layer  0  loss:  0.13500146567821503 0.0 9.53160285949707
logits torch.Size([481, 4, 1024]) labels torch.Size([481, 4]) 0 1023
Curr loss timestep torch.Size([481, 4]) tensor([349, 351, 312, 411], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.06865916401147842
bi 1 loss 0.13462898135185242
bi 2 loss 0.27382293343544006
bi 3 loss 0.13077573478221893
Layer  1  loss:  0.1256258487701416 0.0 12.029170036315918
logits torch.Size([481, 4, 1024]) labels torch.Size([481, 4]) 0 1023
Curr loss timestep torch.Size([481, 4]) tensor([349, 284, 313, 274], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.0601871982216835
bi 1 loss 0.1597893387079239
bi 2 loss 0.20048388838768005
bi 3 loss 0.13705186545848846
Layer  2  loss:  0.13514049351215363 0.0 8.600137710571289
logits torch.Size([481, 4, 1024]) labels torch.Size([481, 4]) 0 1022
Curr loss timestep torch.Size([481, 4]) tensor([343, 283, 312, 286], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.09123855084180832
bi 1 loss 0.19054573774337769
bi 2 loss 0.20813775062561035
bi 3 loss 0.1183847188949585
Layer  3  loss:  0.13159365952014923 0.0 7.195201396942139
logits torch.Size([481, 4, 1024]) labels torch.Size([481, 4]) 0 1017
Curr loss timestep torch.Size([481, 4]) tensor([349, 352, 312, 323], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.07617808133363724
bi 1 loss 0.12774451076984406
bi 2 loss 0.2401682436466217
bi 3 loss 0.1330844759941101
Layer  4  loss:  0.1406969577074051 0.0 11.014545440673828
logits torch.Size([481, 4, 1024]) labels torch.Size([481, 4]) 0 1023
Curr loss timestep torch.Size([481, 4]) tensor([349, 352, 313, 279], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.06698489189147949
bi 1 loss 0.15607966482639313
bi 2 loss 0.28681859374046326
bi 3 loss 0.13337132334709167
Layer  5  loss:  0.16287900507450104 0.0 12.62541675567627
logits torch.Size([481, 4, 1024]) labels torch.Size([481, 4]) 0 1022
Curr loss timestep torch.Size([481, 4]) tensor([349, 352, 312, 322], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.06618912518024445
bi 1 loss 0.14783839881420135
bi 2 loss 0.3063819110393524
bi 3 loss 0.19105184078216553
Layer  6  loss:  0.16726069152355194 0.0 14.56293773651123
logits torch.Size([481, 4, 1024]) labels torch.Size([481, 4]) 0 1022
Curr loss timestep torch.Size([481, 4]) tensor([349, 283, 312, 322], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.09336540848016739
bi 1 loss 0.22950679063796997
bi 2 loss 0.25924810767173767
bi 3 loss 0.1667717546224594
Epoch 0: :   3%|▎         | 15219/600000 [01:30<57:55, v_num=12, reduced_train_loss=39.00, global_step=15217.0, consumed_samples=60872.0, train_step_timing in s=0.325]Epoch 0: :   3%|▎         | 15219/600000 [01:30<57:55, v_num=12, reduced_train_loss=1.110, global_step=15218.0, consumed_samples=60876.0, train_step_timing in s=0.336]loss mask original None

First layer loss:  0.10451476275920868 torch.Size([599, 4]) 10.801799774169922 0.0
Max loss timestep torch.Size([599, 4]) tensor([358, 241, 279, 295], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.12540632486343384
speech mask sum tensor(400, device='cuda:0') loss mask sum tensor(400, device='cuda:0')
bi 1 loss 0.12882541120052338
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 2 loss 0.11152908205986023
speech mask sum tensor(488, device='cuda:0') loss mask sum tensor(488, device='cuda:0')
bi 3 loss 0.048779599368572235
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257022
Layer  0  loss:  0.10393334180116653 0.0 7.074702262878418
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([530, 259, 279, 291], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.13253630697727203
bi 1 loss 0.05090298131108284
bi 2 loss 0.11188394576311111
bi 3 loss 0.0707320049405098
Layer  1  loss:  0.11052156239748001 0.0 14.860671043395996
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([360, 231, 278, 233], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.13359805941581726
bi 1 loss 0.061278220266103745
bi 2 loss 0.12952885031700134
bi 3 loss 0.06354338675737381
Layer  2  loss:  0.13091601431369781 0.0 8.181492805480957
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([360, 291, 279, 266], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.17181949317455292
bi 1 loss 0.11259134858846664
bi 2 loss 0.1293802112340927
bi 3 loss 0.08050844818353653
Layer  3  loss:  0.11028435826301575 0.0 7.41227912902832
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([358, 251, 278, 294], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.14120246469974518
bi 1 loss 0.0488692969083786
bi 2 loss 0.1201658695936203
bi 3 loss 0.07392450422048569
Layer  4  loss:  0.11800453811883926 0.0 13.96922492980957
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([399, 263, 278, 291], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.14713725447654724
bi 1 loss 0.06250147521495819
bi 2 loss 0.14626501500606537
bi 3 loss 0.04775049909949303
Layer  5  loss:  0.1479163020849228 0.0 14.797030448913574
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([358, 258, 278, 294], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.185268834233284
bi 1 loss 0.07658516615629196
bi 2 loss 0.18259617686271667
bi 3 loss 0.060780175030231476
Layer  6  loss:  0.1314702183008194 0.0 8.845946311950684
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1021
Curr loss timestep torch.Size([599, 4]) tensor([360, 291, 278, 291], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.18388809263706207
bi 1 loss 0.09131715446710587
bi 2 loss 0.14310544729232788
bi 3 loss 0.049559611827135086
Epoch 0: :   3%|▎         | 15220/600000 [01:30<58:12, v_num=12, reduced_train_loss=1.110, global_step=15218.0, consumed_samples=60876.0, train_step_timing in s=0.336]Epoch 0: :   3%|▎         | 15220/600000 [01:30<58:12, v_num=12, reduced_train_loss=0.958, global_step=15219.0, consumed_samples=60880.0, train_step_timing in s=0.410]loss mask original None

First layer loss:  0.19815127551555634 torch.Size([562, 4]) 16.41566276550293 0.0
Max loss timestep torch.Size([562, 4]) tensor([ 32, 349, 276, 518], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.06949353218078613
speech mask sum tensor(37, device='cuda:0') loss mask sum tensor(37, device='cuda:0')
bi 1 loss 0.22365140914916992
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
bi 2 loss 0.12464821338653564
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 3 loss 0.24698077142238617
speech mask sum tensor(409, device='cuda:0') loss mask sum tensor(409, device='cuda:0')
logits torch.Size([562, 4, 257024]) labels torch.Size([562, 4]) 0 257023
Layer  0  loss:  0.20318548381328583 0.0 10.250154495239258
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([ 45, 348, 276, 473], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.08288778364658356
bi 1 loss 0.2075776606798172
bi 2 loss 0.15462467074394226
bi 3 loss 0.248474583029747
Layer  1  loss:  0.23741617798805237 0.0 9.54093074798584
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1022
Curr loss timestep torch.Size([562, 4]) tensor([ 53, 336, 351, 340], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.0288629699498415
bi 1 loss 0.2565048635005951
bi 2 loss 0.1700221598148346
bi 3 loss 0.29377201199531555
Layer  2  loss:  0.265562504529953 0.0 15.604430198669434
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1022
Curr loss timestep torch.Size([562, 4]) tensor([ 37, 337, 353, 527], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.04472651705145836
bi 1 loss 0.3101227879524231
bi 2 loss 0.18323656916618347
bi 3 loss 0.3145599365234375
Layer  3  loss:  0.3004355728626251 0.0 13.660907745361328
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([ 50, 337, 276, 521], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.024947205558419228
bi 1 loss 0.3305719792842865
bi 2 loss 0.1975267231464386
bi 3 loss 0.38182172179222107
Layer  4  loss:  0.25748175382614136 0.0 12.229421615600586
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([ 55, 349, 276, 538], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.08617137372493744
bi 1 loss 0.27204689383506775
bi 2 loss 0.21778079867362976
bi 3 loss 0.2924415171146393
Layer  5  loss:  0.24826815724372864 0.0 9.534069061279297
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([ 43, 335, 277, 340], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.09838163107633591
bi 1 loss 0.27273598313331604
bi 2 loss 0.1489071547985077
bi 3 loss 0.3200012743473053
Layer  6  loss:  0.2956618070602417 0.0 14.075867652893066
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([ 38, 337, 277, 552], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.018166564404964447
bi 1 loss 0.33253541588783264
bi 2 loss 0.1709391176700592
bi 3 loss 0.38892272114753723
Epoch 0: :   3%|▎         | 15221/600000 [01:31<58:28, v_num=12, reduced_train_loss=0.958, global_step=15219.0, consumed_samples=60880.0, train_step_timing in s=0.410]Epoch 0: :   3%|▎         | 15221/600000 [01:31<58:28, v_num=12, reduced_train_loss=2.010, global_step=15220.0, consumed_samples=60884.0, train_step_timing in s=0.388]loss mask original None

First layer loss:  3.4972968101501465 torch.Size([572, 4]) 10.178203582763672 0.0
Max loss timestep torch.Size([572, 4]) tensor([119, 149, 475, 416], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 3.3516738414764404
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
bi 1 loss 3.2011897563934326
speech mask sum tensor(40, device='cuda:0') loss mask sum tensor(40, device='cuda:0')
bi 2 loss 3.571021556854248
speech mask sum tensor(303, device='cuda:0') loss mask sum tensor(303, device='cuda:0')
bi 3 loss 3.5355963706970215
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
logits torch.Size([572, 4, 257024]) labels torch.Size([572, 4]) 0 257022
Layer  0  loss:  3.97662091255188 0.0 12.224120140075684
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([131, 159, 274, 489], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 3.527060031890869
bi 1 loss 3.11114239692688
bi 2 loss 4.117467880249023
bi 3 loss 4.1530866622924805
Layer  1  loss:  4.1723151206970215 0.0 9.990333557128906
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([174, 148, 449, 425], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 3.803074359893799
bi 1 loss 3.388033390045166
bi 2 loss 4.381433010101318
bi 3 loss 4.256550312042236
Layer  2  loss:  4.381114959716797 0.0 11.375626564025879
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([162, 164, 399, 404], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 4.213445663452148
bi 1 loss 3.8119845390319824
bi 2 loss 4.491021633148193
bi 3 loss 4.428912162780762
Layer  3  loss:  4.5620856285095215 0.0 11.207977294921875
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([165, 150, 461, 420], device='cuda:0') tensor(165, device='cuda:0')
bi 0 loss 4.615291118621826
bi 1 loss 3.9316811561584473
bi 2 loss 4.7782745361328125
bi 3 loss 4.442535400390625
Layer  4  loss:  4.481451511383057 0.0 9.232608795166016
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([185, 154, 395, 403], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 4.226474761962891
bi 1 loss 3.714932918548584
bi 2 loss 4.777867317199707
bi 3 loss 4.450956344604492
Layer  5  loss:  4.6908860206604 0.0 9.348197937011719
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([188, 158, 444, 278], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.513966083526611
bi 1 loss 3.9265923500061035
bi 2 loss 4.974100112915039
bi 3 loss 4.635759353637695
Layer  6  loss:  4.764119625091553 0.0 10.712206840515137
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([195, 166, 388, 551], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 4.601681232452393
bi 1 loss 4.126911163330078
bi 2 loss 5.155264377593994
bi 3 loss 4.612289905548096
Epoch 0: :   3%|▎         | 15222/600000 [01:31<58:43, v_num=12, reduced_train_loss=2.010, global_step=15220.0, consumed_samples=60884.0, train_step_timing in s=0.388]Epoch 0: :   3%|▎         | 15222/600000 [01:31<58:43, v_num=12, reduced_train_loss=34.50, global_step=15221.0, consumed_samples=60888.0, train_step_timing in s=0.366]loss mask original None

First layer loss:  0.09106460213661194 torch.Size([581, 4]) 6.439749717712402 0.0
Max loss timestep torch.Size([581, 4]) tensor([ 30, 185, 116, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.015130503103137016
speech mask sum tensor(43, device='cuda:0') loss mask sum tensor(43, device='cuda:0')
bi 1 loss 0.03093540109694004
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 2 loss 0.018761368468403816
speech mask sum tensor(68, device='cuda:0') loss mask sum tensor(68, device='cuda:0')
bi 3 loss 0.130130335688591
speech mask sum tensor(428, device='cuda:0') loss mask sum tensor(428, device='cuda:0')
logits torch.Size([581, 4, 257024]) labels torch.Size([581, 4]) 0 257023
Layer  0  loss:  0.10353769361972809 0.0 11.618464469909668
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([ 29, 241, 110, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.03378256410360336
bi 1 loss 0.03435239568352699
bi 2 loss 0.03407171368598938
bi 3 loss 0.14453646540641785
Layer  1  loss:  0.08613276481628418 0.0 10.3222017288208
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([ 44, 257, 117, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.015447452664375305
bi 1 loss 0.04055573046207428
bi 2 loss 0.02104727365076542
bi 3 loss 0.11869636178016663
Layer  2  loss:  0.08648356050252914 0.0 10.529115676879883
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([ 37, 185, 104, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.023591790348291397
bi 1 loss 0.028396915644407272
bi 2 loss 0.02604479342699051
bi 3 loss 0.12167628109455109
Layer  3  loss:  0.09628010541200638 0.0 15.67631721496582
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([ 39, 194, 116, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.01635260321199894
bi 1 loss 0.03922569751739502
bi 2 loss 0.024466032162308693
bi 3 loss 0.13464918732643127
Layer  4  loss:  0.08486339449882507 0.0 10.228802680969238
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([ 33, 236,  95, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.015326455235481262
bi 1 loss 0.03173310309648514
bi 2 loss 0.018422797322273254
bi 3 loss 0.1200328916311264
Layer  5  loss:  0.08675484359264374 0.0 15.748262405395508
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([ 30, 172, 104, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.022182375192642212
bi 1 loss 0.057996731251478195
bi 2 loss 0.016325106844305992
bi 3 loss 0.11397328972816467
Layer  6  loss:  0.09853730350732803 0.0 10.196688652038574
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([ 33, 257, 121, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.019446171820163727
bi 1 loss 0.06005385145545006
bi 2 loss 0.015194018371403217
bi 3 loss 0.13249270617961884
Epoch 0: :   3%|▎         | 15223/600000 [01:32<59:00, v_num=12, reduced_train_loss=34.50, global_step=15221.0, consumed_samples=60888.0, train_step_timing in s=0.366]Epoch 0: :   3%|▎         | 15223/600000 [01:32<59:00, v_num=12, reduced_train_loss=0.734, global_step=15222.0, consumed_samples=60892.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.18314892053604126 torch.Size([709, 4]) 13.338214874267578 0.0
Max loss timestep torch.Size([709, 4]) tensor([579,  98, 412, 392], device='cuda:0') tensor(579, device='cuda:0')
bi 0 loss 0.28190532326698303
speech mask sum tensor(490, device='cuda:0') loss mask sum tensor(490, device='cuda:0')
bi 1 loss 0.018073422834277153
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 2 loss 0.18684835731983185
speech mask sum tensor(243, device='cuda:0') loss mask sum tensor(243, device='cuda:0')
bi 3 loss 0.08560597896575928
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
logits torch.Size([709, 4, 257024]) labels torch.Size([709, 4]) 0 257022
Layer  0  loss:  0.23445340991020203 0.0 13.36422061920166
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([642,  65, 411, 222], device='cuda:0') tensor(642, device='cuda:0')
bi 0 loss 0.3626452088356018
bi 1 loss 0.02051001787185669
bi 2 loss 0.2853145897388458
bi 3 loss 0.06542214006185532
Layer  1  loss:  0.2741455137729645 0.0 13.352365493774414
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([529, 113, 423, 347], device='cuda:0') tensor(423, device='cuda:0')
bi 0 loss 0.4304499924182892
bi 1 loss 0.034933023154735565
bi 2 loss 0.29113104939460754
bi 3 loss 0.09773595631122589
Layer  2  loss:  0.22360771894454956 0.0 10.513373374938965
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([642,  79, 413, 355], device='cuda:0') tensor(642, device='cuda:0')
bi 0 loss 0.3759826421737671
bi 1 loss 0.021098459139466286
bi 2 loss 0.203036829829216
bi 3 loss 0.0692354142665863
Layer  3  loss:  0.2809370756149292 0.0 14.531532287597656
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1022
Curr loss timestep torch.Size([709, 4]) tensor([579, 123, 411, 299], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.4190402925014496
bi 1 loss 0.03221312537789345
bi 2 loss 0.365902304649353
bi 3 loss 0.0809432864189148
Layer  4  loss:  0.2671804428100586 0.0 14.61855411529541
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([286,  83, 412, 398], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.4396611452102661
bi 1 loss 0.04513503611087799
bi 2 loss 0.25764673948287964
bi 3 loss 0.07597889751195908
Layer  5  loss:  0.26301056146621704 0.0 14.865472793579102
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([287,  63, 417, 421], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.41868945956230164
bi 1 loss 0.028561102226376534
bi 2 loss 0.27524662017822266
bi 3 loss 0.08956065028905869
Layer  6  loss:  0.2683073580265045 0.0 14.119869232177734
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1021
Curr loss timestep torch.Size([709, 4]) tensor([579, 123, 411, 340], device='cuda:0') tensor(579, device='cuda:0')
bi 0 loss 0.4321412742137909
bi 1 loss 0.021181413903832436
bi 2 loss 0.2978688180446625
bi 3 loss 0.07068408280611038
Epoch 0: :   3%|▎         | 15224/600000 [01:32<59:19, v_num=12, reduced_train_loss=0.734, global_step=15222.0, consumed_samples=60892.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15224/600000 [01:32<59:19, v_num=12, reduced_train_loss=1.990, global_step=15223.0, consumed_samples=60896.0, train_step_timing in s=0.483]loss mask original None

First layer loss:  3.777780055999756 torch.Size([488, 4]) 10.931489944458008 0.0
Max loss timestep torch.Size([488, 4]) tensor([ 96, 381, 239,  81], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 3.481173276901245
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
bi 1 loss 3.858935594558716
speech mask sum tensor(335, device='cuda:0') loss mask sum tensor(335, device='cuda:0')
bi 2 loss 3.5194356441497803
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 3 loss 3.9558701515197754
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257022
Layer  0  loss:  4.186967849731445 0.0 10.359179496765137
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([ 92, 186, 252,  90], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.4172043800354
bi 1 loss 4.273305892944336
bi 2 loss 3.4956865310668945
bi 3 loss 4.15300178527832
Layer  1  loss:  4.50093936920166 0.0 9.9345703125
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([127, 452, 196,  68], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 4.409024715423584
bi 1 loss 4.589956283569336
bi 2 loss 4.228376865386963
bi 3 loss 4.528883457183838
Layer  2  loss:  4.702820777893066 0.0 9.251638412475586
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([177, 183, 250, 138], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.728176593780518
bi 1 loss 4.702790260314941
bi 2 loss 4.403977394104004
bi 3 loss 4.7987751960754395
Layer  3  loss:  4.974576950073242 0.0 10.47987174987793
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([126, 241, 207, 231], device='cuda:0') tensor(207, device='cuda:0')
bi 0 loss 4.758555889129639
bi 1 loss 5.126718997955322
bi 2 loss 4.673882484436035
bi 3 loss 5.000754356384277
Layer  4  loss:  5.069315433502197 0.0 11.0052490234375
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([206, 400, 225, 141], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 5.057409763336182
bi 1 loss 5.095486164093018
bi 2 loss 5.074932098388672
bi 3 loss 5.034346580505371
Layer  5  loss:  5.163492679595947 0.0 9.124691009521484
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1018
Curr loss timestep torch.Size([488, 4]) tensor([210, 461, 247,  82], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 5.114476203918457
bi 1 loss 5.175989151000977
bi 2 loss 5.206480503082275
bi 3 loss 5.16178035736084
Layer  6  loss:  5.177478790283203 0.0 9.41695499420166
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1021
Curr loss timestep torch.Size([488, 4]) tensor([202, 313, 256,  72], device='cuda:0') tensor(207, device='cuda:0')
bi 0 loss 5.194639205932617
bi 1 loss 5.2010579109191895
bi 2 loss 5.151339530944824
bi 3 loss 5.138331413269043
Epoch 0: :   3%|▎         | 15225/600000 [01:33<59:34, v_num=12, reduced_train_loss=1.990, global_step=15223.0, consumed_samples=60896.0, train_step_timing in s=0.483]Epoch 0: :   3%|▎         | 15225/600000 [01:33<59:34, v_num=12, reduced_train_loss=37.60, global_step=15224.0, consumed_samples=60900.0, train_step_timing in s=0.332]loss mask original None

First layer loss:  0.006981989368796349 torch.Size([297, 4]) 0.08115209639072418 0.0
Max loss timestep torch.Size([297, 4]) tensor([193,  91, 260, 154], device='cuda:0') tensor(154, device='cuda:0')
bi 0 loss 0.006565020885318518
speech mask sum tensor(44, device='cuda:0') loss mask sum tensor(44, device='cuda:0')
bi 1 loss 0.005433531478047371
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
bi 2 loss 0.008495091460645199
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 3 loss 0.0055752103216946125
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
logits torch.Size([297, 4, 257024]) labels torch.Size([297, 4]) 0 257022
Layer  0  loss:  0.00656531285494566 0.0 0.059859368950128555
logits torch.Size([297, 4, 1024]) labels torch.Size([297, 4]) 0 1023
Curr loss timestep torch.Size([297, 4]) tensor([209, 123, 147,  93], device='cuda:0') tensor(93, device='cuda:0')
bi 0 loss 0.006237084977328777
bi 1 loss 0.006116083357483149
bi 2 loss 0.007691796403378248
bi 3 loss 0.005058567970991135
Layer  1  loss:  0.00646880641579628 0.0 0.054291509091854095
logits torch.Size([297, 4, 1024]) labels torch.Size([297, 4]) 0 1022
Curr loss timestep torch.Size([297, 4]) tensor([213, 153, 235, 159], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 0.006159488577395678
bi 1 loss 0.005113186314702034
bi 2 loss 0.007706819102168083
bi 3 loss 0.005365672521293163
Layer  2  loss:  0.006305695045739412 0.0 0.05568384751677513
logits torch.Size([297, 4, 1024]) labels torch.Size([297, 4]) 0 1022
Curr loss timestep torch.Size([297, 4]) tensor([210, 100, 183, 134], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 0.003908873535692692
bi 1 loss 0.0053915902972221375
bi 2 loss 0.0076985894702374935
bi 3 loss 0.005353722255676985
Layer  3  loss:  0.0062225391156971455 0.0 0.07794539630413055
logits torch.Size([297, 4, 1024]) labels torch.Size([297, 4]) 0 1023
Curr loss timestep torch.Size([297, 4]) tensor([200, 142, 260, 111], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.005704695358872414
bi 1 loss 0.004720490425825119
bi 2 loss 0.007902084849774837
bi 3 loss 0.004536244552582502
Layer  4  loss:  0.0074040330946445465 0.0 0.2324094921350479
logits torch.Size([297, 4, 1024]) labels torch.Size([297, 4]) 0 1023
Curr loss timestep torch.Size([297, 4]) tensor([214, 110, 260,  86], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.00505666621029377
bi 1 loss 0.0058642481453716755
bi 2 loss 0.009980454109609127
bi 3 loss 0.004837236367166042
Layer  5  loss:  0.007131831254810095 0.0 0.11638131737709045
logits torch.Size([297, 4, 1024]) labels torch.Size([297, 4]) 0 1016
Curr loss timestep torch.Size([297, 4]) tensor([194, 128, 271, 153], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.005272733047604561
bi 1 loss 0.006046196911484003
bi 2 loss 0.008696611039340496
bi 3 loss 0.0058191269636154175
Layer  6  loss:  0.006093402858823538 0.0 0.0836050808429718
logits torch.Size([297, 4, 1024]) labels torch.Size([297, 4]) 0 1022
Curr loss timestep torch.Size([297, 4]) tensor([205, 132, 260,  98], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.005807045381516218
bi 1 loss 0.005635850131511688
bi 2 loss 0.007731329184025526
bi 3 loss 0.0037085369694978
Epoch 0: :   3%|▎         | 15226/600000 [01:33<59:44, v_num=12, reduced_train_loss=37.60, global_step=15224.0, consumed_samples=60900.0, train_step_timing in s=0.332]Epoch 0: :   3%|▎         | 15226/600000 [01:33<59:44, v_num=12, reduced_train_loss=0.0532, global_step=15225.0, consumed_samples=60904.0, train_step_timing in s=0.250]loss mask original None

First layer loss:  3.648442506790161 torch.Size([540, 4]) 11.400818824768066 0.0
Max loss timestep torch.Size([540, 4]) tensor([332, 196, 294, 384], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 3.452784776687622
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 1 loss 3.4549739360809326
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 2 loss 3.6463897228240967
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 3 loss 3.8746707439422607
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
logits torch.Size([540, 4, 257024]) labels torch.Size([540, 4]) 0 257023
Layer  0  loss:  4.044641971588135 0.0 10.018331527709961
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([390, 198, 265, 296], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 3.7332727909088135
bi 1 loss 3.7794981002807617
bi 2 loss 4.216204643249512
bi 3 loss 4.274526119232178
Layer  1  loss:  4.537814140319824 0.0 9.780753135681152
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([390, 207, 321, 456], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 4.349154472351074
bi 1 loss 4.022706508636475
bi 2 loss 4.721895694732666
bi 3 loss 4.703607559204102
Layer  2  loss:  4.720941543579102 0.0 10.370615005493164
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([370, 197, 317, 311], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 4.55078649520874
bi 1 loss 4.208808422088623
bi 2 loss 4.963469982147217
bi 3 loss 4.828787803649902
Layer  3  loss:  4.839463710784912 0.0 9.911623001098633
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([356, 235, 365, 380], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 4.70760440826416
bi 1 loss 4.456589698791504
bi 2 loss 5.120398044586182
bi 3 loss 4.855831146240234
Layer  4  loss:  4.974990367889404 0.0 10.848237991333008
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([406, 251, 470, 204], device='cuda:0') tensor(406, device='cuda:0')
bi 0 loss 4.772344589233398
bi 1 loss 4.609499931335449
bi 2 loss 5.315614700317383
bi 3 loss 5.011497974395752
Layer  5  loss:  5.134533882141113 0.0 11.30280876159668
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([441, 252, 482, 281], device='cuda:0') tensor(441, device='cuda:0')
bi 0 loss 4.9037933349609375
bi 1 loss 4.730807781219482
bi 2 loss 5.373818397521973
bi 3 loss 5.275459289550781
Layer  6  loss:  5.127195835113525 0.0 9.36917495727539
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1020
Curr loss timestep torch.Size([540, 4]) tensor([254, 224, 313, 366], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 4.961015701293945
bi 1 loss 4.414253234863281
bi 2 loss 5.438252925872803
bi 3 loss 5.230477809906006
Epoch 0: :   3%|▎         | 15227/600000 [01:33<59:59, v_num=12, reduced_train_loss=0.0532, global_step=15225.0, consumed_samples=60904.0, train_step_timing in s=0.250]Epoch 0: :   3%|▎         | 15227/600000 [01:33<59:59, v_num=12, reduced_train_loss=37.00, global_step=15226.0, consumed_samples=60908.0, train_step_timing in s=0.352] loss mask original None

First layer loss:  3.514449119567871 torch.Size([644, 4]) 10.098430633544922 0.0
Max loss timestep torch.Size([644, 4]) tensor([371, 342, 231, 253], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 3.731438398361206
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
bi 1 loss 3.2113406658172607
speech mask sum tensor(479, device='cuda:0') loss mask sum tensor(479, device='cuda:0')
bi 2 loss 3.9727580547332764
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 3 loss 3.066063165664673
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
logits torch.Size([644, 4, 257024]) labels torch.Size([644, 4]) 0 257023
Layer  0  loss:  4.320499420166016 0.0 11.207992553710938
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([183, 486, 307, 203], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 4.435037612915039
bi 1 loss 4.140070915222168
bi 2 loss 4.509519100189209
bi 3 loss 4.244889259338379
Layer  1  loss:  4.488914966583252 0.0 9.892306327819824
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([486, 471, 281, 232], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 4.733145713806152
bi 1 loss 4.358466625213623
bi 2 loss 4.508278846740723
bi 3 loss 4.057250499725342
Layer  2  loss:  4.7194037437438965 0.0 10.24831771850586
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([239, 476, 178, 269], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 4.930434703826904
bi 1 loss 4.646820545196533
bi 2 loss 4.5923309326171875
bi 3 loss 4.442271709442139
Layer  3  loss:  4.926033020019531 0.0 10.251640319824219
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1020
Curr loss timestep torch.Size([644, 4]) tensor([232, 373, 342, 257], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 5.175177097320557
bi 1 loss 4.763113021850586
bi 2 loss 4.827968597412109
bi 3 loss 4.788445472717285
Layer  4  loss:  5.0421037673950195 0.0 10.237100601196289
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([302, 537, 299, 233], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 5.324191093444824
bi 1 loss 4.737603187561035
bi 2 loss 5.290219306945801
bi 3 loss 4.717737197875977
Layer  5  loss:  5.094672203063965 0.0 10.038145065307617
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1019
Curr loss timestep torch.Size([644, 4]) tensor([445, 198, 159, 272], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 5.280690670013428
bi 1 loss 4.913168907165527
bi 2 loss 5.2137980461120605
bi 3 loss 4.885837078094482
Layer  6  loss:  5.138107776641846 0.0 10.443582534790039
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([572, 203, 273, 250], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 5.356595516204834
bi 1 loss 5.014217853546143
bi 2 loss 5.098919868469238
bi 3 loss 4.871695041656494
Epoch 0: :   3%|▎         | 15228/600000 [01:34<1:00:15, v_num=12, reduced_train_loss=37.00, global_step=15226.0, consumed_samples=60908.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15228/600000 [01:34<1:00:15, v_num=12, reduced_train_loss=37.20, global_step=15227.0, consumed_samples=60912.0, train_step_timing in s=0.393]loss mask original None

First layer loss:  0.07027934491634369 torch.Size([553, 4]) 12.157328605651855 0.0
Max loss timestep torch.Size([553, 4]) tensor([249, 407, 483, 297], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.02276761643588543
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
bi 1 loss 0.14733260869979858
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 2 loss 0.06741207838058472
speech mask sum tensor(358, device='cuda:0') loss mask sum tensor(358, device='cuda:0')
bi 3 loss 0.039491429924964905
speech mask sum tensor(225, device='cuda:0') loss mask sum tensor(225, device='cuda:0')
logits torch.Size([553, 4, 257024]) labels torch.Size([553, 4]) 0 257022
Layer  0  loss:  0.08126556873321533 0.0 7.198378086090088
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([185, 277, 488, 252], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.033477336168289185
bi 1 loss 0.16593217849731445
bi 2 loss 0.07350213825702667
bi 3 loss 0.052202943712472916
Layer  1  loss:  0.07937644422054291 0.0 9.940814971923828
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([184, 277, 205, 297], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.02109166607260704
bi 1 loss 0.15369151532649994
bi 2 loss 0.08322213590145111
bi 3 loss 0.046419017016887665
Layer  2  loss:  0.0769389420747757 0.0 8.001420974731445
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([240, 277, 511, 297], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.0365997776389122
bi 1 loss 0.14924821257591248
bi 2 loss 0.07084933668375015
bi 3 loss 0.050981637090444565
Layer  3  loss:  0.09672436118125916 0.0 7.712003707885742
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([203, 277, 278, 297], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.03991580009460449
bi 1 loss 0.1733928918838501
bi 2 loss 0.11498092114925385
bi 3 loss 0.03805350884795189
Layer  4  loss:  0.10329672694206238 0.0 8.46091079711914
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([194, 407, 268, 164], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.025593971833586693
bi 1 loss 0.17991523444652557
bi 2 loss 0.12136322259902954
bi 3 loss 0.05713426321744919
Layer  5  loss:  0.08225227147340775 0.0 9.762063980102539
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1021
Curr loss timestep torch.Size([553, 4]) tensor([264, 407, 365, 223], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.016478393226861954
bi 1 loss 0.22729317843914032
bi 2 loss 0.06231200322508812
bi 3 loss 0.03366325423121452
Layer  6  loss:  0.09110182523727417 0.0 6.398382186889648
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([163, 407, 365, 216], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.02772567979991436
bi 1 loss 0.17035482823848724
bi 2 loss 0.09767108410596848
bi 3 loss 0.052737075835466385
Epoch 0: :   3%|▎         | 15229/600000 [01:34<1:00:31, v_num=12, reduced_train_loss=37.20, global_step=15227.0, consumed_samples=60912.0, train_step_timing in s=0.393]Epoch 0: :   3%|▎         | 15229/600000 [01:34<1:00:31, v_num=12, reduced_train_loss=0.681, global_step=15228.0, consumed_samples=60916.0, train_step_timing in s=0.376]loss mask original None

First layer loss:  0.13999219238758087 torch.Size([565, 4]) 10.344003677368164 0.0
Max loss timestep torch.Size([565, 4]) tensor([132, 329, 284, 451], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.04216063767671585
speech mask sum tensor(114, device='cuda:0') loss mask sum tensor(114, device='cuda:0')
bi 1 loss 0.08263680338859558
speech mask sum tensor(345, device='cuda:0') loss mask sum tensor(345, device='cuda:0')
bi 2 loss 0.1528889238834381
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
bi 3 loss 0.216216042637825
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
logits torch.Size([565, 4, 257024]) labels torch.Size([565, 4]) 0 257022
Layer  0  loss:  0.14427237212657928 0.0 10.861983299255371
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([ 94, 459, 282, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.052468251436948776
bi 1 loss 0.09201464056968689
bi 2 loss 0.10341475158929825
bi 3 loss 0.24751988053321838
Layer  1  loss:  0.1646825671195984 0.0 10.583152770996094
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([154, 459, 283, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.050653014332056046
bi 1 loss 0.07479685544967651
bi 2 loss 0.1424221396446228
bi 3 loss 0.2985512912273407
Layer  2  loss:  0.1777295470237732 0.0 10.629240989685059
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([ 72, 458, 282, 289], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.059586673974990845
bi 1 loss 0.13709291815757751
bi 2 loss 0.18187975883483887
bi 3 loss 0.25002753734588623
Layer  3  loss:  0.16702516376972198 0.0 10.510353088378906
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([ 93, 458, 282, 372], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.042856890708208084
bi 1 loss 0.10125619918107986
bi 2 loss 0.14775288105010986
bi 3 loss 0.2794995903968811
Layer  4  loss:  0.16597682237625122 0.0 14.031294822692871
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([115, 448, 283, 502], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.07112794369459152
bi 1 loss 0.077494777739048
bi 2 loss 0.1918821632862091
bi 3 loss 0.2623824179172516
Layer  5  loss:  0.17407140135765076 0.0 10.47617244720459
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([117, 402, 283, 288], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.05561188608407974
bi 1 loss 0.10554108768701553
bi 2 loss 0.20801162719726562
bi 3 loss 0.25401991605758667
Layer  6  loss:  0.16483569145202637 0.0 12.892428398132324
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([ 86, 458, 284, 288], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.04563046246767044
bi 1 loss 0.0719585120677948
bi 2 loss 0.2129030078649521
bi 3 loss 0.25904974341392517
Epoch 0: :   3%|▎         | 15230/600000 [01:35<1:00:47, v_num=12, reduced_train_loss=0.681, global_step=15228.0, consumed_samples=60916.0, train_step_timing in s=0.376]Epoch 0: :   3%|▎         | 15230/600000 [01:35<1:00:47, v_num=12, reduced_train_loss=1.300, global_step=15229.0, consumed_samples=60920.0, train_step_timing in s=0.400]loss mask original None

First layer loss:  0.08084847778081894 torch.Size([473, 4]) 6.758395671844482 0.0
Max loss timestep torch.Size([473, 4]) tensor([263, 121, 325, 378], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.05438363179564476
speech mask sum tensor(204, device='cuda:0') loss mask sum tensor(204, device='cuda:0')
bi 1 loss 0.012483303435146809
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 2 loss 0.14477555453777313
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
bi 3 loss 0.0696636214852333
speech mask sum tensor(294, device='cuda:0') loss mask sum tensor(294, device='cuda:0')
logits torch.Size([473, 4, 257024]) labels torch.Size([473, 4]) 0 257022
Layer  0  loss:  0.07390578836202621 0.0 6.914210796356201
logits torch.Size([473, 4, 1024]) labels torch.Size([473, 4]) 0 1023
Curr loss timestep torch.Size([473, 4]) tensor([219,  59, 324, 315], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.0561533123254776
bi 1 loss 0.034907542169094086
bi 2 loss 0.11015915125608444
bi 3 loss 0.06959094852209091
Layer  1  loss:  0.07058905065059662 0.0 2.798748016357422
logits torch.Size([473, 4, 1024]) labels torch.Size([473, 4]) 0 1022
Curr loss timestep torch.Size([473, 4]) tensor([241, 133, 324, 315], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.0564139299094677
bi 1 loss 0.044504471123218536
bi 2 loss 0.09025447815656662
bi 3 loss 0.0740855485200882
Layer  2  loss:  0.07842659950256348 0.0 6.1474409103393555
logits torch.Size([473, 4, 1024]) labels torch.Size([473, 4]) 0 1022
Curr loss timestep torch.Size([473, 4]) tensor([104, 136, 324, 315], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.06196898967027664
bi 1 loss 0.016183022409677505
bi 2 loss 0.12785716354846954
bi 3 loss 0.07210395485162735
Layer  3  loss:  0.08445200324058533 0.0 6.868828773498535
logits torch.Size([473, 4, 1024]) labels torch.Size([473, 4]) 0 1022
Curr loss timestep torch.Size([473, 4]) tensor([136,  71, 273, 385], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.05765256658196449
bi 1 loss 0.03456228971481323
bi 2 loss 0.13874000310897827
bi 3 loss 0.07350993156433105
Layer  4  loss:  0.08923869580030441 0.0 11.231996536254883
logits torch.Size([473, 4, 1024]) labels torch.Size([473, 4]) 0 1022
Curr loss timestep torch.Size([473, 4]) tensor([245, 149, 324, 317], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.050813447684049606
bi 1 loss 0.031658656895160675
bi 2 loss 0.1724810153245926
bi 3 loss 0.060314081609249115
Layer  5  loss:  0.07348240911960602 0.0 5.594995498657227
logits torch.Size([473, 4, 1024]) labels torch.Size([473, 4]) 0 1023
Curr loss timestep torch.Size([473, 4]) tensor([230, 164, 324, 371], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.05083467438817024
bi 1 loss 0.020458152517676353
bi 2 loss 0.11272752285003662
bi 3 loss 0.07707345485687256
Layer  6  loss:  0.07835597544908524 0.0 8.102723121643066
logits torch.Size([473, 4, 1024]) labels torch.Size([473, 4]) 0 1022
Curr loss timestep torch.Size([473, 4]) tensor([259, 164, 324, 276], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.05819065868854523
bi 1 loss 0.030622074380517006
bi 2 loss 0.11405810713768005
bi 3 loss 0.08104506134986877
Epoch 0: :   3%|▎         | 15231/600000 [01:35<1:01:02, v_num=12, reduced_train_loss=1.300, global_step=15229.0, consumed_samples=60920.0, train_step_timing in s=0.400]Epoch 0: :   3%|▎         | 15231/600000 [01:35<1:01:02, v_num=12, reduced_train_loss=0.629, global_step=15230.0, consumed_samples=60924.0, train_step_timing in s=0.337]loss mask original None

First layer loss:  3.957746744155884 torch.Size([680, 4]) 13.482135772705078 0.0
Max loss timestep torch.Size([680, 4]) tensor([128, 556, 273,  83], device='cuda:0') tensor(85, device='cuda:0')
bi 0 loss 3.4002139568328857
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 1 loss 4.363259792327881
speech mask sum tensor(504, device='cuda:0') loss mask sum tensor(504, device='cuda:0')
bi 2 loss 3.454991102218628
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 3 loss 4.131753921508789
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
logits torch.Size([680, 4, 257024]) labels torch.Size([680, 4]) 0 257022
Layer  0  loss:  4.380862236022949 0.0 10.267297744750977
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([116, 603, 536, 114], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 4.065589427947998
bi 1 loss 4.714069843292236
bi 2 loss 3.9966745376586914
bi 3 loss 4.317720890045166
Layer  1  loss:  4.634690284729004 0.0 10.943904876708984
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([164, 254, 478,  78], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 4.1590657234191895
bi 1 loss 5.018921375274658
bi 2 loss 4.211597442626953
bi 3 loss 4.620659351348877
Layer  2  loss:  5.022280216217041 0.0 11.070330619812012
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([103, 418, 440, 149], device='cuda:0') tensor(103, device='cuda:0')
bi 0 loss 4.561266899108887
bi 1 loss 5.2650322914123535
bi 2 loss 4.857464790344238
bi 3 loss 4.918977737426758
Layer  3  loss:  5.015048027038574 0.0 11.89371395111084
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([105, 654, 267, 101], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 4.569322109222412
bi 1 loss 5.263054370880127
bi 2 loss 4.8194804191589355
bi 3 loss 4.95106840133667
Layer  4  loss:  5.139808654785156 0.0 10.245948791503906
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([ 95, 288, 500, 132], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 4.766973972320557
bi 1 loss 5.3386454582214355
bi 2 loss 4.963531970977783
bi 3 loss 5.150341033935547
Layer  5  loss:  5.160253524780273 0.0 10.09029769897461
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([141, 271, 482, 103], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 4.676469326019287
bi 1 loss 5.398014545440674
bi 2 loss 5.0044145584106445
bi 3 loss 5.076339244842529
Layer  6  loss:  5.294822692871094 0.0 11.55797290802002
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1021
Curr loss timestep torch.Size([680, 4]) tensor([170, 253, 562, 117], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 5.0366339683532715
bi 1 loss 5.514315128326416
bi 2 loss 5.062367916107178
bi 3 loss 5.251608371734619
Epoch 0: :   3%|▎         | 15232/600000 [01:35<1:01:19, v_num=12, reduced_train_loss=0.629, global_step=15230.0, consumed_samples=60924.0, train_step_timing in s=0.337]Epoch 0: :   3%|▎         | 15232/600000 [01:35<1:01:19, v_num=12, reduced_train_loss=38.60, global_step=15231.0, consumed_samples=60928.0, train_step_timing in s=0.413]loss mask original None

First layer loss:  0.15847934782505035 torch.Size([655, 4]) 9.72357177734375 0.0
Max loss timestep torch.Size([655, 4]) tensor([320, 285, 626, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.1448831856250763
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 1 loss 0.08643928915262222
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
bi 2 loss 0.21699118614196777
speech mask sum tensor(369, device='cuda:0') loss mask sum tensor(369, device='cuda:0')
bi 3 loss 0.17024517059326172
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
logits torch.Size([655, 4, 257024]) labels torch.Size([655, 4]) 0 257023
Layer  0  loss:  0.19803334772586823 0.0 10.784842491149902
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([311, 285, 407, 562], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.16155897080898285
bi 1 loss 0.09275326877832413
bi 2 loss 0.2811645567417145
bi 3 loss 0.23739677667617798
Layer  1  loss:  0.19573627412319183 0.0 8.200368881225586
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([320, 285, 610, 394], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.1328132152557373
bi 1 loss 0.07647993415594101
bi 2 loss 0.34177330136299133
bi 3 loss 0.2017894983291626
Layer  2  loss:  0.23627617955207825 0.0 14.312851905822754
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([320, 275, 610, 562], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.15517617762088776
bi 1 loss 0.12774397432804108
bi 2 loss 0.37655216455459595
bi 3 loss 0.26038458943367004
Layer  3  loss:  0.21077615022659302 0.0 13.729227066040039
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1020
Curr loss timestep torch.Size([655, 4]) tensor([311, 280, 613, 562], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.1208319142460823
bi 1 loss 0.10787548869848251
bi 2 loss 0.33571216464042664
bi 3 loss 0.25864994525909424
Layer  4  loss:  0.21821223199367523 0.0 8.845452308654785
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([311, 295, 586, 562], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.14960169792175293
bi 1 loss 0.10746968537569046
bi 2 loss 0.3695524036884308
bi 3 loss 0.2163541167974472
Layer  5  loss:  0.22431717813014984 0.0 16.71965789794922
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([320, 285, 613, 562], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.1215876042842865
bi 1 loss 0.13354432582855225
bi 2 loss 0.328334778547287
bi 3 loss 0.30125683546066284
Layer  6  loss:  0.2562934458255768 0.0 10.492093086242676
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([320, 294, 610, 562], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.1583029180765152
bi 1 loss 0.13025018572807312
bi 2 loss 0.37421441078186035
bi 3 loss 0.34385520219802856
Epoch 0: :   3%|▎         | 15233/600000 [01:36<1:01:37, v_num=12, reduced_train_loss=38.60, global_step=15231.0, consumed_samples=60928.0, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15233/600000 [01:36<1:01:37, v_num=12, reduced_train_loss=1.700, global_step=15232.0, consumed_samples=60932.0, train_step_timing in s=0.445]loss mask original None

First layer loss:  0.07949551939964294 torch.Size([599, 4]) 7.041010856628418 0.0
Max loss timestep torch.Size([599, 4]) tensor([580, 300, 382,  79], device='cuda:0') tensor(580, device='cuda:0')
bi 0 loss 0.0930592343211174
speech mask sum tensor(482, device='cuda:0') loss mask sum tensor(482, device='cuda:0')
bi 1 loss 0.06382378935813904
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 2 loss 0.08338858932256699
speech mask sum tensor(252, device='cuda:0') loss mask sum tensor(252, device='cuda:0')
bi 3 loss 0.038728389889001846
speech mask sum tensor(126, device='cuda:0') loss mask sum tensor(126, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257023
Layer  0  loss:  0.12816296517848969 0.0 8.854941368103027
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([580, 299, 384,  81], device='cuda:0') tensor(580, device='cuda:0')
bi 0 loss 0.15850237011909485
bi 1 loss 0.07082459330558777
bi 2 loss 0.14589743316173553
bi 3 loss 0.0458039753139019
Layer  1  loss:  0.11584112048149109 0.0 8.151734352111816
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([580, 255, 384, 103], device='cuda:0') tensor(580, device='cuda:0')
bi 0 loss 0.14688849449157715
bi 1 loss 0.08764547109603882
bi 2 loss 0.11518397927284241
bi 3 loss 0.0324007049202919
Layer  2  loss:  0.10882499068975449 0.0 7.517108917236328
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([428, 255, 384, 101], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.1456996351480484
bi 1 loss 0.04418496787548065
bi 2 loss 0.1090918555855751
bi 3 loss 0.04520953819155693
Layer  3  loss:  0.11572340130805969 0.0 9.128966331481934
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1021
Curr loss timestep torch.Size([599, 4]) tensor([580, 296, 395, 103], device='cuda:0') tensor(580, device='cuda:0')
bi 0 loss 0.1290067732334137
bi 1 loss 0.06456531584262848
bi 2 loss 0.1478191465139389
bi 3 loss 0.06243220716714859
Layer  4  loss:  0.11262678354978561 0.0 6.878013610839844
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([580, 230, 384, 136], device='cuda:0') tensor(580, device='cuda:0')
bi 0 loss 0.11577216535806656
bi 1 loss 0.06364191323518753
bi 2 loss 0.18007095158100128
bi 3 loss 0.024798931553959846
Layer  5  loss:  0.14148163795471191 0.0 8.9569673538208
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([427, 258, 384,  75], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.17822569608688354
bi 1 loss 0.09432356059551239
bi 2 loss 0.15091578662395477
bi 3 loss 0.03894175589084625
Layer  6  loss:  0.14130781590938568 0.0 9.728081703186035
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([428, 300, 263,  60], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.19066980481147766
bi 1 loss 0.08782465755939484
bi 2 loss 0.12664347887039185
bi 3 loss 0.046326667070388794
Epoch 0: :   3%|▎         | 15234/600000 [01:37<1:02:04, v_num=12, reduced_train_loss=1.700, global_step=15232.0, consumed_samples=60932.0, train_step_timing in s=0.445]Epoch 0: :   3%|▎         | 15234/600000 [01:37<1:02:04, v_num=12, reduced_train_loss=0.943, global_step=15233.0, consumed_samples=60936.0, train_step_timing in s=0.687]loss mask original None

First layer loss:  3.2151596546173096 torch.Size([408, 4]) 11.518888473510742 0.0
Max loss timestep torch.Size([408, 4]) tensor([178, 195, 288, 237], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 3.928443193435669
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 1 loss 3.265932559967041
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
bi 2 loss 2.765171766281128
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 3 loss 3.404792547225952
speech mask sum tensor(99, device='cuda:0') loss mask sum tensor(99, device='cuda:0')
logits torch.Size([408, 4, 257024]) labels torch.Size([408, 4]) 0 257023
Layer  0  loss:  3.97282075881958 0.0 9.787185668945312
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1023
Curr loss timestep torch.Size([408, 4]) tensor([212, 292, 235, 196], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 4.169724464416504
bi 1 loss 4.211569309234619
bi 2 loss 3.6363799571990967
bi 3 loss 3.838710308074951
Layer  1  loss:  4.3906755447387695 0.0 9.23049259185791
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1023
Curr loss timestep torch.Size([408, 4]) tensor([196, 387, 113, 177], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 4.414239406585693
bi 1 loss 4.548224449157715
bi 2 loss 4.141529560089111
bi 3 loss 4.491046905517578
Layer  2  loss:  4.578001499176025 0.0 10.985392570495605
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1022
Curr loss timestep torch.Size([408, 4]) tensor([242, 249, 125, 246], device='cuda:0') tensor(244, device='cuda:0')
bi 0 loss 4.702910423278809
bi 1 loss 4.7750067710876465
bi 2 loss 4.254485607147217
bi 3 loss 4.627216815948486
Layer  3  loss:  4.690155029296875 0.0 10.435258865356445
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1021
Curr loss timestep torch.Size([408, 4]) tensor([248, 161, 272, 177], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 4.943609714508057
bi 1 loss 4.955071449279785
bi 2 loss 4.245626926422119
bi 3 loss 4.684835433959961
Layer  4  loss:  4.767545700073242 0.0 9.973666191101074
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1022
Curr loss timestep torch.Size([408, 4]) tensor([216, 224, 231, 229], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 5.025981903076172
bi 1 loss 5.033331871032715
bi 2 loss 4.318617820739746
bi 3 loss 4.765100955963135
Layer  5  loss:  4.87808895111084 0.0 10.876601219177246
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1021
Curr loss timestep torch.Size([408, 4]) tensor([239, 257, 187, 181], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 5.1415605545043945
bi 1 loss 5.127357482910156
bi 2 loss 4.485872745513916
bi 3 loss 4.7782206535339355
Layer  6  loss:  4.982831954956055 0.0 10.344942092895508
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1023
Curr loss timestep torch.Size([408, 4]) tensor([235, 259, 270, 225], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 5.336160659790039
bi 1 loss 5.155073165893555
bi 2 loss 4.541935920715332
bi 3 loss 5.157644748687744
Epoch 0: :   3%|▎         | 15235/600000 [01:37<1:02:17, v_num=12, reduced_train_loss=0.943, global_step=15233.0, consumed_samples=60936.0, train_step_timing in s=0.687]Epoch 0: :   3%|▎         | 15235/600000 [01:37<1:02:17, v_num=12, reduced_train_loss=35.50, global_step=15234.0, consumed_samples=60940.0, train_step_timing in s=0.306]loss mask original None

First layer loss:  0.16751454770565033 torch.Size([703, 4]) 6.982828140258789 0.0
Max loss timestep torch.Size([703, 4]) tensor([641,  94, 147, 175], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 0.13575415313243866
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 1 loss 0.06915180385112762
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 2 loss 0.4307851493358612
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 3 loss 0.0462920106947422
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
logits torch.Size([703, 4, 257024]) labels torch.Size([703, 4]) 0 257023
Layer  0  loss:  0.12186957895755768 0.0 5.170013427734375
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([673, 303, 270, 140], device='cuda:0') tensor(673, device='cuda:0')
bi 0 loss 0.17104248702526093
bi 1 loss 0.07888709008693695
bi 2 loss 0.1431645154953003
bi 3 loss 0.03286347538232803
Layer  1  loss:  0.13107240200042725 0.0 7.808813095092773
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([568, 274, 314, 269], device='cuda:0') tensor(568, device='cuda:0')
bi 0 loss 0.20728938281536102
bi 1 loss 0.09055640548467636
bi 2 loss 0.10623667389154434
bi 3 loss 0.030832527205348015
Layer  2  loss:  0.13621287047863007 0.0 9.08230972290039
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([679, 341, 278, 240], device='cuda:0') tensor(679, device='cuda:0')
bi 0 loss 0.2194308042526245
bi 1 loss 0.09713657945394516
bi 2 loss 0.10307575762271881
bi 3 loss 0.026383157819509506
Layer  3  loss:  0.13327240943908691 0.0 6.309366226196289
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1021
Curr loss timestep torch.Size([703, 4]) tensor([316, 342, 311, 244], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.21203643083572388
bi 1 loss 0.0728718489408493
bi 2 loss 0.12046416103839874
bi 3 loss 0.04373031482100487
Layer  4  loss:  0.1346491575241089 0.0 7.722435474395752
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([342, 303, 270, 239], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 0.2064523547887802
bi 1 loss 0.09261470288038254
bi 2 loss 0.12123455107212067
bi 3 loss 0.03257536515593529
Layer  5  loss:  0.1455034464597702 0.0 6.095103740692139
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([679, 303, 259, 217], device='cuda:0') tensor(679, device='cuda:0')
bi 0 loss 0.21677328646183014
bi 1 loss 0.11039119213819504
bi 2 loss 0.13037274777889252
bi 3 loss 0.03516652435064316
Layer  6  loss:  0.15671129524707794 0.0 10.939912796020508
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1021
Curr loss timestep torch.Size([703, 4]) tensor([679, 343, 332, 276], device='cuda:0') tensor(679, device='cuda:0')
bi 0 loss 0.2616181969642639
bi 1 loss 0.07539764046669006
bi 2 loss 0.14383800327777863
bi 3 loss 0.03291434794664383
Epoch 0: :   3%|▎         | 15236/600000 [01:37<1:02:37, v_num=12, reduced_train_loss=35.50, global_step=15234.0, consumed_samples=60940.0, train_step_timing in s=0.306]Epoch 0: :   3%|▎         | 15236/600000 [01:37<1:02:37, v_num=12, reduced_train_loss=1.130, global_step=15235.0, consumed_samples=60944.0, train_step_timing in s=0.479]loss mask original None

First layer loss:  0.13913652300834656 torch.Size([573, 4]) 15.344161033630371 0.0
Max loss timestep torch.Size([573, 4]) tensor([385, 199, 179, 514], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.18171338737010956
speech mask sum tensor(331, device='cuda:0') loss mask sum tensor(331, device='cuda:0')
bi 1 loss 0.0412113256752491
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 2 loss 0.05572955682873726
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 3 loss 0.1807452291250229
speech mask sum tensor(438, device='cuda:0') loss mask sum tensor(438, device='cuda:0')
logits torch.Size([573, 4, 257024]) labels torch.Size([573, 4]) 0 257023
Layer  0  loss:  0.1307353526353836 0.0 10.533864974975586
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([384, 135, 106, 514], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.14520302414894104
bi 1 loss 0.04026123881340027
bi 2 loss 0.03664436936378479
bi 3 loss 0.19294913113117218
Layer  1  loss:  0.16493824124336243 0.0 13.643327713012695
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([384, 203, 191, 518], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.17419825494289398
bi 1 loss 0.05892058089375496
bi 2 loss 0.06100669503211975
bi 3 loss 0.2418060004711151
Layer  2  loss:  0.16951347887516022 0.0 8.216852188110352
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1022
Curr loss timestep torch.Size([573, 4]) tensor([384, 207, 109, 518], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.22098034620285034
bi 1 loss 0.044168807566165924
bi 2 loss 0.034540414810180664
bi 3 loss 0.23330844938755035
Layer  3  loss:  0.15530352294445038 0.0 12.533038139343262
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([385,  71, 124, 480], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.16854515671730042
bi 1 loss 0.0537017285823822
bi 2 loss 0.043694112449884415
bi 3 loss 0.22917798161506653
Layer  4  loss:  0.18612328171730042 0.0 10.528267860412598
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([384, 223, 191, 514], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.2246120721101761
bi 1 loss 0.07411643862724304
bi 2 loss 0.04410683736205101
bi 3 loss 0.25505441427230835
Layer  5  loss:  0.1597663164138794 0.0 15.989664077758789
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([385, 193, 192, 522], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.18695172667503357
bi 1 loss 0.06457927078008652
bi 2 loss 0.06466469168663025
bi 3 loss 0.21504250168800354
Layer  6  loss:  0.16972927749156952 0.0 13.41972541809082
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1022
Curr loss timestep torch.Size([573, 4]) tensor([384, 159, 161, 546], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.18647535145282745
bi 1 loss 0.07148896157741547
bi 2 loss 0.06672607362270355
bi 3 loss 0.2367442548274994
Epoch 0: :   3%|▎         | 15237/600000 [01:38<1:02:53, v_num=12, reduced_train_loss=1.130, global_step=15235.0, consumed_samples=60944.0, train_step_timing in s=0.479]Epoch 0: :   3%|▎         | 15237/600000 [01:38<1:02:53, v_num=12, reduced_train_loss=1.280, global_step=15236.0, consumed_samples=60948.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  0.07134592533111572 torch.Size([471, 4]) 7.562993049621582 0.0
Max loss timestep torch.Size([471, 4]) tensor([408, 272, 170, 309], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.10595794022083282
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 1 loss 0.05647282674908638
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 0.026876265183091164
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 3 loss 0.053334176540374756
speech mask sum tensor(258, device='cuda:0') loss mask sum tensor(258, device='cuda:0')
logits torch.Size([471, 4, 257024]) labels torch.Size([471, 4]) 0 257022
Layer  0  loss:  0.08819826692342758 0.0 7.594951629638672
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([342, 272, 138, 367], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 0.12169624865055084
bi 1 loss 0.09049858897924423
bi 2 loss 0.026642965152859688
bi 3 loss 0.07213623076677322
Layer  1  loss:  0.08239579945802689 0.0 5.942316055297852
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([343, 272, 181, 380], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.10310087352991104
bi 1 loss 0.11225981265306473
bi 2 loss 0.042957909405231476
bi 3 loss 0.058555036783218384
Layer  2  loss:  0.08969573676586151 0.0 5.224874496459961
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([402, 272, 192, 303], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.10613162815570831
bi 1 loss 0.106040358543396
bi 2 loss 0.04194667935371399
bi 3 loss 0.08342444151639938
Layer  3  loss:  0.08565818518400192 0.0 4.96340799331665
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([403, 206, 146, 363], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.12572547793388367
bi 1 loss 0.060011543333530426
bi 2 loss 0.023822447285056114
bi 3 loss 0.07473291456699371
Layer  4  loss:  0.10896751284599304 0.0 9.500882148742676
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([408, 272, 137, 163], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.1587700992822647
bi 1 loss 0.1544191539287567
bi 2 loss 0.036860451102256775
bi 3 loss 0.05296309292316437
Layer  5  loss:  0.08816947042942047 0.0 5.323489665985107
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([404, 271, 146, 363], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.1116408035159111
bi 1 loss 0.042397331446409225
bi 2 loss 0.040948107838630676
bi 3 loss 0.10354571044445038
Layer  6  loss:  0.11917702853679657 0.0 9.375545501708984
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1021
Curr loss timestep torch.Size([471, 4]) tensor([408, 272, 157, 309], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.15667879581451416
bi 1 loss 0.13411349058151245
bi 2 loss 0.03745553642511368
bi 3 loss 0.10172382742166519
Epoch 0: :   3%|▎         | 15238/600000 [01:38<1:03:07, v_num=12, reduced_train_loss=1.280, global_step=15236.0, consumed_samples=60948.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15238/600000 [01:38<1:03:07, v_num=12, reduced_train_loss=0.734, global_step=15237.0, consumed_samples=6.1e+4, train_step_timing in s=0.334] loss mask original None

First layer loss:  0.05809853598475456 torch.Size([555, 4]) 4.762552738189697 0.0
Max loss timestep torch.Size([555, 4]) tensor([323, 177, 203,  93], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.09926805645227432
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
bi 1 loss 0.03342678025364876
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
bi 2 loss 0.02055317535996437
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 3 loss 0.057983819395303726
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
logits torch.Size([555, 4, 257024]) labels torch.Size([555, 4]) 0 257022
Layer  0  loss:  0.0715954527258873 0.0 4.727958679199219
logits torch.Size([555, 4, 1024]) labels torch.Size([555, 4]) 0 1023
Curr loss timestep torch.Size([555, 4]) tensor([323, 259,  76,  49], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.12621115148067474
bi 1 loss 0.05674653872847557
bi 2 loss 0.04953090101480484
bi 3 loss 0.031012577936053276
Layer  1  loss:  0.05705304443836212 0.0 2.9044270515441895
logits torch.Size([555, 4, 1024]) labels torch.Size([555, 4]) 0 1023
Curr loss timestep torch.Size([555, 4]) tensor([464, 157, 189, 190], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.11033778637647629
bi 1 loss 0.022568948566913605
bi 2 loss 0.04066694155335426
bi 3 loss 0.027898458763957024
Layer  2  loss:  0.06279131025075912 0.0 3.166487216949463
logits torch.Size([555, 4, 1024]) labels torch.Size([555, 4]) 0 1022
Curr loss timestep torch.Size([555, 4]) tensor([452, 276,  91, 176], device='cuda:0') tensor(91, device='cuda:0')
bi 0 loss 0.09753289818763733
bi 1 loss 0.03744134306907654
bi 2 loss 0.060939427465200424
bi 3 loss 0.037495288997888565
Layer  3  loss:  0.06255742907524109 0.0 4.30646276473999
logits torch.Size([555, 4, 1024]) labels torch.Size([555, 4]) 0 1021
Curr loss timestep torch.Size([555, 4]) tensor([323, 230,  70, 144], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.10904689133167267
bi 1 loss 0.05228836089372635
bi 2 loss 0.04395228624343872
bi 3 loss 0.02601972594857216
Layer  4  loss:  0.058148063719272614 0.0 2.443350315093994
logits torch.Size([555, 4, 1024]) labels torch.Size([555, 4]) 0 1022
Curr loss timestep torch.Size([555, 4]) tensor([463, 240, 211,  83], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.11139649152755737
bi 1 loss 0.040244799107313156
bi 2 loss 0.030482515692710876
bi 3 loss 0.02713329717516899
Layer  5  loss:  0.06660579144954681 0.0 4.507315635681152
logits torch.Size([555, 4, 1024]) labels torch.Size([555, 4]) 0 1022
Curr loss timestep torch.Size([555, 4]) tensor([519, 275, 159,  81], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.11921359598636627
bi 1 loss 0.04942016303539276
bi 2 loss 0.04338212311267853
bi 3 loss 0.03162679448723793
Layer  6  loss:  0.062177352607250214 0.0 2.7115683555603027
logits torch.Size([555, 4, 1024]) labels torch.Size([555, 4]) 0 1020
Curr loss timestep torch.Size([555, 4]) tensor([484, 275, 154,  48], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 0.12056872248649597
bi 1 loss 0.04331826791167259
bi 2 loss 0.024057524278759956
bi 3 loss 0.03505510464310646
Epoch 0: :   3%|▎         | 15239/600000 [01:39<1:03:23, v_num=12, reduced_train_loss=0.734, global_step=15237.0, consumed_samples=6.1e+4, train_step_timing in s=0.334]Epoch 0: :   3%|▎         | 15239/600000 [01:39<1:03:23, v_num=12, reduced_train_loss=0.499, global_step=15238.0, consumed_samples=6.1e+4, train_step_timing in s=0.378]loss mask original None

First layer loss:  3.6000287532806396 torch.Size([664, 4]) 10.729961395263672 0.0
Max loss timestep torch.Size([664, 4]) tensor([244, 352, 443, 432], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 3.2587010860443115
speech mask sum tensor(65, device='cuda:0') loss mask sum tensor(65, device='cuda:0')
bi 1 loss 3.7041118144989014
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
bi 2 loss 3.55275297164917
speech mask sum tensor(446, device='cuda:0') loss mask sum tensor(446, device='cuda:0')
bi 3 loss 3.6402275562286377
speech mask sum tensor(266, device='cuda:0') loss mask sum tensor(266, device='cuda:0')
logits torch.Size([664, 4, 257024]) labels torch.Size([664, 4]) 0 257022
Layer  0  loss:  4.189332485198975 0.0 10.292403221130371
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([212, 174, 469, 318], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 3.844444751739502
bi 1 loss 4.242600917816162
bi 2 loss 4.141888618469238
bi 3 loss 4.290478706359863
Layer  1  loss:  4.4766621589660645 0.0 10.138370513916016
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([235, 139, 433, 453], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 4.384558200836182
bi 1 loss 4.521929740905762
bi 2 loss 4.456477642059326
bi 3 loss 4.479745388031006
Layer  2  loss:  4.750074863433838 0.0 10.714948654174805
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([209, 190, 569, 318], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 4.489088535308838
bi 1 loss 4.718442916870117
bi 2 loss 4.719079494476318
bi 3 loss 4.903039455413818
Layer  3  loss:  4.875746250152588 0.0 10.71683120727539
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([238, 166, 273, 324], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 4.501726150512695
bi 1 loss 4.879929065704346
bi 2 loss 4.852738380432129
bi 3 loss 5.000799655914307
Layer  4  loss:  4.929831027984619 0.0 10.024090766906738
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([227, 146, 277, 301], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 4.69612979888916
bi 1 loss 4.9336442947387695
bi 2 loss 4.936949253082275
bi 3 loss 4.970516681671143
Layer  5  loss:  5.031449317932129 0.0 11.553874969482422
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([225, 239, 648, 310], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 4.718131065368652
bi 1 loss 5.019392490386963
bi 2 loss 5.0502610206604
bi 3 loss 5.0906572341918945
Layer  6  loss:  5.196442127227783 0.0 10.187932014465332
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([244, 367, 416, 457], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.77841329574585
bi 1 loss 5.174831390380859
bi 2 loss 5.167620658874512
bi 3 loss 5.372345447540283
Epoch 0: :   3%|▎         | 15240/600000 [01:39<1:03:40, v_num=12, reduced_train_loss=0.499, global_step=15238.0, consumed_samples=6.1e+4, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15240/600000 [01:39<1:03:40, v_num=12, reduced_train_loss=37.00, global_step=15239.0, consumed_samples=6.1e+4, train_step_timing in s=0.407]loss mask original None

First layer loss:  0.015733983367681503 torch.Size([393, 4]) 0.31989482045173645 0.0
Max loss timestep torch.Size([393, 4]) tensor([231, 152, 373, 117], device='cuda:0') tensor(152, device='cuda:0')
bi 0 loss 0.017309539020061493
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 1 loss 0.014394981786608696
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 2 loss 0.016509298235177994
speech mask sum tensor(251, device='cuda:0') loss mask sum tensor(251, device='cuda:0')
bi 3 loss 0.012825869023799896
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
logits torch.Size([393, 4, 257024]) labels torch.Size([393, 4]) 0 257022
Layer  0  loss:  0.015578835271298885 0.0 0.18635623157024384
logits torch.Size([393, 4, 1024]) labels torch.Size([393, 4]) 0 1023
Curr loss timestep torch.Size([393, 4]) tensor([157, 148, 368, 184], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 0.015084058977663517
bi 1 loss 0.013954858295619488
bi 2 loss 0.016652023419737816
bi 3 loss 0.01511436514556408
Layer  1  loss:  0.017583930864930153 0.0 0.27899715304374695
logits torch.Size([393, 4, 1024]) labels torch.Size([393, 4]) 0 1022
Curr loss timestep torch.Size([393, 4]) tensor([ 85, 145, 335, 148], device='cuda:0') tensor(85, device='cuda:0')
bi 0 loss 0.0189705491065979
bi 1 loss 0.009616473689675331
bi 2 loss 0.019712258130311966
bi 3 loss 0.015850214287638664
Layer  2  loss:  0.016838017851114273 0.0 0.25951603055000305
logits torch.Size([393, 4, 1024]) labels torch.Size([393, 4]) 0 1022
Curr loss timestep torch.Size([393, 4]) tensor([214, 128, 221, 132], device='cuda:0') tensor(128, device='cuda:0')
bi 0 loss 0.014288987964391708
bi 1 loss 0.020841186866164207
bi 2 loss 0.018676865845918655
bi 3 loss 0.014888717792928219
Layer  3  loss:  0.015909254550933838 0.0 0.2943664789199829
logits torch.Size([393, 4, 1024]) labels torch.Size([393, 4]) 0 1021
Curr loss timestep torch.Size([393, 4]) tensor([210, 156, 385, 126], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.01720285974442959
bi 1 loss 0.013339388184249401
bi 2 loss 0.017558986321091652
bi 3 loss 0.012408548034727573
Layer  4  loss:  0.013610928319394588 0.0 0.25722137093544006
logits torch.Size([393, 4, 1024]) labels torch.Size([393, 4]) 0 1023
Curr loss timestep torch.Size([393, 4]) tensor([137, 157, 385, 162], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.012241736054420471
bi 1 loss 0.007496069185435772
bi 2 loss 0.017399916425347328
bi 3 loss 0.011648016050457954
Layer  5  loss:  0.016983281821012497 0.0 0.21351511776447296
logits torch.Size([393, 4, 1024]) labels torch.Size([393, 4]) 0 1019
Curr loss timestep torch.Size([393, 4]) tensor([164, 154, 334, 117], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.017925575375556946
bi 1 loss 0.013776682317256927
bi 2 loss 0.017668811604380608
bi 3 loss 0.016072876751422882
Layer  6  loss:  0.017703821882605553 0.0 0.23659993708133698
logits torch.Size([393, 4, 1024]) labels torch.Size([393, 4]) 0 1023
Curr loss timestep torch.Size([393, 4]) tensor([244, 136, 214, 139], device='cuda:0') tensor(139, device='cuda:0')
bi 0 loss 0.014337553642690182
bi 1 loss 0.011289834976196289
bi 2 loss 0.0232055876404047
bi 3 loss 0.01547976303845644
Epoch 0: :   3%|▎         | 15241/600000 [01:39<1:03:52, v_num=12, reduced_train_loss=37.00, global_step=15239.0, consumed_samples=6.1e+4, train_step_timing in s=0.407]Epoch 0: :   3%|▎         | 15241/600000 [01:39<1:03:52, v_num=12, reduced_train_loss=0.130, global_step=15240.0, consumed_samples=6.1e+4, train_step_timing in s=0.295]loss mask original None

First layer loss:  0.10293614119291306 torch.Size([551, 4]) 8.878435134887695 0.0
Max loss timestep torch.Size([551, 4]) tensor([320, 119, 317, 520], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.11896492540836334
speech mask sum tensor(363, device='cuda:0') loss mask sum tensor(363, device='cuda:0')
bi 1 loss 0.03033830039203167
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 2 loss 0.035529740154743195
speech mask sum tensor(201, device='cuda:0') loss mask sum tensor(201, device='cuda:0')
bi 3 loss 0.14445760846138
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
logits torch.Size([551, 4, 257024]) labels torch.Size([551, 4]) 0 257023
Layer  0  loss:  0.12111400067806244 0.0 11.838618278503418
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1023
Curr loss timestep torch.Size([551, 4]) tensor([444, 111, 168, 501], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.09967642277479172
bi 1 loss 0.023289412260055542
bi 2 loss 0.04869093373417854
bi 3 loss 0.208274245262146
Layer  1  loss:  0.11060533672571182 0.0 10.751070976257324
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1023
Curr loss timestep torch.Size([551, 4]) tensor([442, 133, 246, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.12648026645183563
bi 1 loss 0.03372856229543686
bi 2 loss 0.050482071936130524
bi 3 loss 0.14969535171985626
Layer  2  loss:  0.11943140625953674 0.0 9.815770149230957
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1023
Curr loss timestep torch.Size([551, 4]) tensor([442, 101, 212, 527], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.11210928857326508
bi 1 loss 0.03373716399073601
bi 2 loss 0.05480341240763664
bi 3 loss 0.18552018702030182
Layer  3  loss:  0.11640793085098267 0.0 8.132673263549805
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1023
Curr loss timestep torch.Size([551, 4]) tensor([318, 165, 267, 527], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.10252111405134201
bi 1 loss 0.01981647126376629
bi 2 loss 0.06811586767435074
bi 3 loss 0.18333424627780914
Layer  4  loss:  0.1289471536874771 0.0 15.328752517700195
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1021
Curr loss timestep torch.Size([551, 4]) tensor([442, 110, 334, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.1324601173400879
bi 1 loss 0.033673517405986786
bi 2 loss 0.054012175649404526
bi 3 loss 0.19297167658805847
Layer  5  loss:  0.12213102728128433 0.0 8.722908020019531
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1023
Curr loss timestep torch.Size([551, 4]) tensor([442, 121, 225, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.10188665241003036
bi 1 loss 0.026165654882788658
bi 2 loss 0.04127298295497894
bi 3 loss 0.2120506465435028
Layer  6  loss:  0.14181876182556152 0.0 13.969378471374512
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1021
Curr loss timestep torch.Size([551, 4]) tensor([443, 129, 197, 527], device='cuda:0') tensor(443, device='cuda:0')
bi 0 loss 0.1262044608592987
bi 1 loss 0.040453534573316574
bi 2 loss 0.03368953615427017
bi 3 loss 0.24327130615711212
Epoch 0: :   3%|▎         | 15242/600000 [01:40<1:04:08, v_num=12, reduced_train_loss=0.130, global_step=15240.0, consumed_samples=6.1e+4, train_step_timing in s=0.295]Epoch 0: :   3%|▎         | 15242/600000 [01:40<1:04:08, v_num=12, reduced_train_loss=0.963, global_step=15241.0, consumed_samples=6.1e+4, train_step_timing in s=0.377]loss mask original None

First layer loss:  0.04324651509523392 torch.Size([522, 4]) 4.770131587982178 0.0
Max loss timestep torch.Size([522, 4]) tensor([ 89, 351,  65, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.02130010537803173
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 1 loss 0.05744615197181702
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
bi 2 loss 0.026175927370786667
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 3 loss 0.04618069902062416
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
logits torch.Size([522, 4, 257024]) labels torch.Size([522, 4]) 0 257022
Layer  0  loss:  0.04596015810966492 0.0 1.4849815368652344
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([240, 335,  74, 127], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.030220145359635353
bi 1 loss 0.07215706259012222
bi 2 loss 0.013208947144448757
bi 3 loss 0.0399220809340477
Layer  1  loss:  0.04755507409572601 0.0 1.9019078016281128
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([226, 505,  83, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.02691798284649849
bi 1 loss 0.06166692078113556
bi 2 loss 0.026459557935595512
bi 3 loss 0.050851356238126755
Layer  2  loss:  0.03955213725566864 0.0 6.192099094390869
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([228, 505,  97, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.018554244190454483
bi 1 loss 0.050213322043418884
bi 2 loss 0.015587094239890575
bi 3 loss 0.04642731323838234
Layer  3  loss:  0.04547164589166641 0.0 1.6664531230926514
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1022
Curr loss timestep torch.Size([522, 4]) tensor([243, 263,  97, 167], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.02033635787665844
bi 1 loss 0.07469455897808075
bi 2 loss 0.0255538709461689
bi 3 loss 0.03856069967150688
Layer  4  loss:  0.054324258118867874 0.0 5.01408052444458
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1020
Curr loss timestep torch.Size([522, 4]) tensor([ 95, 505, 107, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.028598614037036896
bi 1 loss 0.08119916915893555
bi 2 loss 0.04058132320642471
bi 3 loss 0.04816877841949463
Layer  5  loss:  0.04557059705257416 0.0 3.1856720447540283
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1022
Curr loss timestep torch.Size([522, 4]) tensor([204, 351,  85, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.018408024683594704
bi 1 loss 0.06490802019834518
bi 2 loss 0.03388240188360214
bi 3 loss 0.04565274342894554
Layer  6  loss:  0.03910104185342789 0.0 2.568875551223755
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1019
Curr loss timestep torch.Size([522, 4]) tensor([114, 505,  88, 373], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.021065879613161087
bi 1 loss 0.057888079434633255
bi 2 loss 0.02692299522459507
bi 3 loss 0.03540556877851486
Epoch 0: :   3%|▎         | 15243/600000 [01:40<1:04:23, v_num=12, reduced_train_loss=0.963, global_step=15241.0, consumed_samples=6.1e+4, train_step_timing in s=0.377]Epoch 0: :   3%|▎         | 15243/600000 [01:40<1:04:23, v_num=12, reduced_train_loss=0.361, global_step=15242.0, consumed_samples=6.1e+4, train_step_timing in s=0.360]loss mask original None

First layer loss:  0.07420287281274796 torch.Size([529, 4]) 6.180675506591797 0.0
Max loss timestep torch.Size([529, 4]) tensor([337, 249, 281, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.09616312384605408
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
bi 1 loss 0.06704600900411606
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 2 loss 0.019309276714920998
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 3 loss 0.08486493676900864
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
logits torch.Size([529, 4, 257024]) labels torch.Size([529, 4]) 0 257022
Layer  0  loss:  0.08186545222997665 0.0 9.59985637664795
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([278, 301, 280, 304], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.12456823140382767
bi 1 loss 0.05354755371809006
bi 2 loss 0.047503672540187836
bi 3 loss 0.06421352177858353
Layer  1  loss:  0.07700984179973602 0.0 4.1304450035095215
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([337, 305, 148, 276], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.10594382137060165
bi 1 loss 0.053932998329401016
bi 2 loss 0.04075679928064346
bi 3 loss 0.07505321502685547
Layer  2  loss:  0.09244517236948013 0.0 7.87253475189209
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([279, 300, 277, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.09573651105165482
bi 1 loss 0.052167050540447235
bi 2 loss 0.041409481316804886
bi 3 loss 0.13979601860046387
Layer  3  loss:  0.08481510728597641 0.0 5.3191633224487305
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([337, 293, 277, 275], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.09333181381225586
bi 1 loss 0.11253383755683899
bi 2 loss 0.06615746766328812
bi 3 loss 0.07257242500782013
Layer  4  loss:  0.10611581057310104 0.0 8.569070816040039
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([279, 289, 280, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.13773690164089203
bi 1 loss 0.03961164131760597
bi 2 loss 0.056225329637527466
bi 3 loss 0.130352184176445
Layer  5  loss:  0.11124692857265472 0.0 8.400556564331055
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([337, 295, 277, 276], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.14358824491500854
bi 1 loss 0.08461913466453552
bi 2 loss 0.047831226140260696
bi 3 loss 0.12380320578813553
Layer  6  loss:  0.09089737385511398 0.0 9.031795501708984
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([268, 273, 280, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.10353076457977295
bi 1 loss 0.03398500382900238
bi 2 loss 0.03829058259725571
bi 3 loss 0.13570398092269897
Epoch 0: :   3%|▎         | 15244/600000 [01:41<1:04:38, v_num=12, reduced_train_loss=0.361, global_step=15242.0, consumed_samples=6.1e+4, train_step_timing in s=0.360]Epoch 0: :   3%|▎         | 15244/600000 [01:41<1:04:38, v_num=12, reduced_train_loss=0.719, global_step=15243.0, consumed_samples=6.1e+4, train_step_timing in s=0.367]loss mask original None

First layer loss:  0.08453570306301117 torch.Size([518, 4]) 12.000470161437988 0.0
Max loss timestep torch.Size([518, 4]) tensor([351, 390, 299, 230], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.06403961777687073
speech mask sum tensor(389, device='cuda:0') loss mask sum tensor(389, device='cuda:0')
bi 1 loss 0.12255091220140457
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 2 loss 0.07002709805965424
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 3 loss 0.01759152300655842
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
logits torch.Size([518, 4, 257024]) labels torch.Size([518, 4]) 0 257022
Layer  0  loss:  0.09340661019086838 0.0 14.165216445922852
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([351, 391, 263, 214], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.10506498068571091
bi 1 loss 0.10838872194290161
bi 2 loss 0.06872709840536118
bi 3 loss 0.028282783925533295
Layer  1  loss:  0.07928106188774109 0.0 8.619466781616211
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([351, 390, 312, 200], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.06751075387001038
bi 1 loss 0.1060408502817154
bi 2 loss 0.0681367740035057
bi 3 loss 0.020454466342926025
Layer  2  loss:  0.09575583040714264 0.0 10.859777450561523
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1022
Curr loss timestep torch.Size([518, 4]) tensor([351, 391, 300, 205], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.07064913213253021
bi 1 loss 0.13372153043746948
bi 2 loss 0.08425623178482056
bi 3 loss 0.043862562626600266
Layer  3  loss:  0.09396927058696747 0.0 9.998364448547363
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([400, 390, 300, 208], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.05838320776820183
bi 1 loss 0.13056091964244843
bi 2 loss 0.0989287868142128
bi 3 loss 0.04590089991688728
Layer  4  loss:  0.09271281212568283 0.0 7.818403720855713
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([351, 390, 291, 223], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.07416587322950363
bi 1 loss 0.12710998952388763
bi 2 loss 0.08274175226688385
bi 3 loss 0.019521908834576607
Layer  5  loss:  0.09348206222057343 0.0 14.35693359375
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1021
Curr loss timestep torch.Size([518, 4]) tensor([351, 391, 300, 222], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.08487740904092789
bi 1 loss 0.11507336050271988
bi 2 loss 0.09144566208124161
bi 3 loss 0.013015072792768478
Layer  6  loss:  0.09686901420354843 0.0 11.502240180969238
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([351, 391, 300, 207], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.08373992145061493
bi 1 loss 0.12005013972520828
bi 2 loss 0.09561488777399063
bi 3 loss 0.029338251799345016
Epoch 0: :   3%|▎         | 15245/600000 [01:41<1:04:53, v_num=12, reduced_train_loss=0.719, global_step=15243.0, consumed_samples=6.1e+4, train_step_timing in s=0.367]Epoch 0: :   3%|▎         | 15245/600000 [01:41<1:04:53, v_num=12, reduced_train_loss=0.730, global_step=15244.0, consumed_samples=6.1e+4, train_step_timing in s=0.357]loss mask original None

First layer loss:  0.05946759134531021 torch.Size([558, 4]) 9.699392318725586 0.0
Max loss timestep torch.Size([558, 4]) tensor([464, 126, 312, 145], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.10297058522701263
speech mask sum tensor(380, device='cuda:0') loss mask sum tensor(380, device='cuda:0')
bi 1 loss 0.019135696813464165
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
bi 2 loss 0.019157283008098602
speech mask sum tensor(171, device='cuda:0') loss mask sum tensor(171, device='cuda:0')
bi 3 loss 0.028713034465909004
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
logits torch.Size([558, 4, 257024]) labels torch.Size([558, 4]) 0 257023
Layer  0  loss:  0.06867749243974686 0.0 6.814114093780518
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([465, 117, 313, 115], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.1040949746966362
bi 1 loss 0.018786566331982613
bi 2 loss 0.06333748251199722
bi 3 loss 0.02711338922381401
Layer  1  loss:  0.0715770348906517 0.0 12.207446098327637
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([464, 147, 291, 204], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.12343406677246094
bi 1 loss 0.011753101833164692
bi 2 loss 0.030080929398536682
bi 3 loss 0.03548580780625343
Layer  2  loss:  0.0859069973230362 0.0 13.495388984680176
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([464, 121, 313, 149], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.14920516312122345
bi 1 loss 0.016062546521425247
bi 2 loss 0.049535371363162994
bi 3 loss 0.026189884170889854
Layer  3  loss:  0.10488693416118622 0.0 17.254135131835938
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1021
Curr loss timestep torch.Size([558, 4]) tensor([464, 157, 313, 188], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.18615874648094177
bi 1 loss 0.01783173158764839
bi 2 loss 0.05248740687966347
bi 3 loss 0.03217937424778938
Layer  4  loss:  0.08583603799343109 0.0 18.039688110351562
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([464, 121, 313,  86], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.15680773556232452
bi 1 loss 0.01698724925518036
bi 2 loss 0.03033108450472355
bi 3 loss 0.027544334530830383
Layer  5  loss:  0.07216913253068924 0.0 12.71593189239502
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1020
Curr loss timestep torch.Size([558, 4]) tensor([465,  99, 312,  97], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.12091189622879028
bi 1 loss 0.021047720685601234
bi 2 loss 0.03191133588552475
bi 3 loss 0.036454204469919205
Layer  6  loss:  0.08725965768098831 0.0 13.366533279418945
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1021
Curr loss timestep torch.Size([558, 4]) tensor([465, 124, 312, 146], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.1475335955619812
bi 1 loss 0.02147156186401844
bi 2 loss 0.045032087713479996
bi 3 loss 0.03730924800038338
Epoch 0: :   3%|▎         | 15246/600000 [01:41<1:05:09, v_num=12, reduced_train_loss=0.730, global_step=15244.0, consumed_samples=6.1e+4, train_step_timing in s=0.357]Epoch 0: :   3%|▎         | 15246/600000 [01:41<1:05:09, v_num=12, reduced_train_loss=0.636, global_step=15245.0, consumed_samples=6.1e+4, train_step_timing in s=0.379]loss mask original None

First layer loss:  0.0451318584382534 torch.Size([419, 4]) 9.571695327758789 0.0
Max loss timestep torch.Size([419, 4]) tensor([343, 290, 267, 268], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.03071628510951996
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
bi 1 loss 0.1285618245601654
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 2 loss 0.02611526846885681
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 3 loss 0.041964489966630936
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
logits torch.Size([419, 4, 257024]) labels torch.Size([419, 4]) 0 257022
Layer  0  loss:  0.04432905465364456 0.0 7.390565395355225
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1023
Curr loss timestep torch.Size([419, 4]) tensor([348, 290, 243, 269], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.027981983497738838
bi 1 loss 0.13217763602733612
bi 2 loss 0.030596230179071426
bi 3 loss 0.030637066811323166
Layer  1  loss:  0.04085472226142883 0.0 4.57927131652832
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1023
Curr loss timestep torch.Size([419, 4]) tensor([301, 290, 358, 269], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.026031581684947014
bi 1 loss 0.09043104201555252
bi 2 loss 0.03414499759674072
bi 3 loss 0.04263778775930405
Layer  2  loss:  0.04311734810471535 0.0 13.469036102294922
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1022
Curr loss timestep torch.Size([419, 4]) tensor([288, 290, 336, 209], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.03488799184560776
bi 1 loss 0.14003077149391174
bi 2 loss 0.02075876109302044
bi 3 loss 0.02230110950767994
Layer  3  loss:  0.04180840775370598 0.0 9.072261810302734
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1023
Curr loss timestep torch.Size([419, 4]) tensor([288, 290, 340, 269], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.02723596803843975
bi 1 loss 0.10504238307476044
bi 2 loss 0.027198446914553642
bi 3 loss 0.047379136085510254
Layer  4  loss:  0.04520152509212494 0.0 9.565479278564453
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1020
Curr loss timestep torch.Size([419, 4]) tensor([368, 290, 255, 269], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.026029355823993683
bi 1 loss 0.1314433366060257
bi 2 loss 0.029034486040472984
bi 3 loss 0.043703239411115646
Layer  5  loss:  0.039649732410907745 0.0 5.324856758117676
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1023
Curr loss timestep torch.Size([419, 4]) tensor([348, 290, 273, 268], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.024815134704113007
bi 1 loss 0.08876525610685349
bi 2 loss 0.029008066281676292
bi 3 loss 0.049841903150081635
Layer  6  loss:  0.051007144153118134 0.0 5.399440765380859
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1021
Curr loss timestep torch.Size([419, 4]) tensor([368, 290, 327, 268], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.04128945246338844
bi 1 loss 0.08684477210044861
bi 2 loss 0.032031625509262085
bi 3 loss 0.07892482727766037
Epoch 0: :   3%|▎         | 15247/600000 [01:42<1:05:22, v_num=12, reduced_train_loss=0.636, global_step=15245.0, consumed_samples=6.1e+4, train_step_timing in s=0.379]Epoch 0: :   3%|▎         | 15247/600000 [01:42<1:05:22, v_num=12, reduced_train_loss=0.351, global_step=15246.0, consumed_samples=6.1e+4, train_step_timing in s=0.306]loss mask original None

First layer loss:  0.058651041239500046 torch.Size([370, 4]) 7.03988790512085 0.0
Max loss timestep torch.Size([370, 4]) tensor([280, 222,  71, 341], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.1011105328798294
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
bi 1 loss 0.045172322541475296
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 2 loss 0.028130173683166504
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 3 loss 0.054248563945293427
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
logits torch.Size([370, 4, 257024]) labels torch.Size([370, 4]) 0 257023
Layer  0  loss:  0.0635211244225502 0.0 10.969200134277344
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1023
Curr loss timestep torch.Size([370, 4]) tensor([280, 212,  77, 325], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.1191415786743164
bi 1 loss 0.03735631704330444
bi 2 loss 0.03411191701889038
bi 3 loss 0.050752706825733185
Layer  1  loss:  0.07221020013093948 0.0 11.813433647155762
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1023
Curr loss timestep torch.Size([370, 4]) tensor([280, 245, 227, 339], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.14917635917663574
bi 1 loss 0.02504165843129158
bi 2 loss 0.033360790461301804
bi 3 loss 0.061194613575935364
Layer  2  loss:  0.06553826481103897 0.0 10.951624870300293
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1022
Curr loss timestep torch.Size([370, 4]) tensor([280, 213, 129, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.1447332501411438
bi 1 loss 0.03240198642015457
bi 2 loss 0.027194874361157417
bi 3 loss 0.03923556208610535
Layer  3  loss:  0.06262394040822983 0.0 8.882935523986816
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1022
Curr loss timestep torch.Size([370, 4]) tensor([281, 263,  94, 325], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.11494332551956177
bi 1 loss 0.04679974541068077
bi 2 loss 0.0379333458840847
bi 3 loss 0.039352476596832275
Layer  4  loss:  0.06018606573343277 0.0 8.674817085266113
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1022
Curr loss timestep torch.Size([370, 4]) tensor([280, 180,  99, 328], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.11868741363286972
bi 1 loss 0.03313329070806503
bi 2 loss 0.029828771948814392
bi 3 loss 0.045602358877658844
Layer  5  loss:  0.07658199965953827 0.0 15.144944190979004
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1022
Curr loss timestep torch.Size([370, 4]) tensor([280, 212, 124, 323], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.17356206476688385
bi 1 loss 0.02432289347052574
bi 2 loss 0.02996428683400154
bi 3 loss 0.05363244190812111
Layer  6  loss:  0.07947264611721039 0.0 19.328495025634766
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1023
Curr loss timestep torch.Size([370, 4]) tensor([280, 245,  87, 325], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.18363991379737854
bi 1 loss 0.03588750585913658
bi 2 loss 0.03227386251091957
bi 3 loss 0.040569599717855453
Epoch 0: :   3%|▎         | 15248/600000 [01:42<1:05:34, v_num=12, reduced_train_loss=0.351, global_step=15246.0, consumed_samples=6.1e+4, train_step_timing in s=0.306]Epoch 0: :   3%|▎         | 15248/600000 [01:42<1:05:34, v_num=12, reduced_train_loss=0.539, global_step=15247.0, consumed_samples=6.1e+4, train_step_timing in s=0.295]loss mask original None

First layer loss:  0.13593226671218872 torch.Size([609, 4]) 6.358977317810059 0.0
Max loss timestep torch.Size([609, 4]) tensor([115, 546, 296, 482], device='cuda:0') tensor(482, device='cuda:0')
bi 0 loss 0.04932282865047455
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 1 loss 0.1363079845905304
speech mask sum tensor(482, device='cuda:0') loss mask sum tensor(482, device='cuda:0')
bi 2 loss 0.10070736706256866
speech mask sum tensor(368, device='cuda:0') loss mask sum tensor(368, device='cuda:0')
bi 3 loss 0.19060267508029938
speech mask sum tensor(454, device='cuda:0') loss mask sum tensor(454, device='cuda:0')
logits torch.Size([609, 4, 257024]) labels torch.Size([609, 4]) 0 257023
Layer  0  loss:  0.15781384706497192 0.0 8.738548278808594
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1023
Curr loss timestep torch.Size([609, 4]) tensor([164, 308, 329, 350], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.022462718188762665
bi 1 loss 0.16257242858409882
bi 2 loss 0.13117386400699615
bi 3 loss 0.21579550206661224
Layer  1  loss:  0.22489991784095764 0.0 13.078463554382324
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1023
Curr loss timestep torch.Size([609, 4]) tensor([118, 543, 294, 353], device='cuda:0') tensor(543, device='cuda:0')
bi 0 loss 0.027725987136363983
bi 1 loss 0.20370668172836304
bi 2 loss 0.17064562439918518
bi 3 loss 0.35174551606178284
Layer  2  loss:  0.2013823688030243 0.0 11.544909477233887
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1022
Curr loss timestep torch.Size([609, 4]) tensor([ 84, 544, 425, 350], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.04968329146504402
bi 1 loss 0.18386685848236084
bi 2 loss 0.1660064160823822
bi 3 loss 0.2950982451438904
Layer  3  loss:  0.18681803345680237 0.0 10.622325897216797
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1021
Curr loss timestep torch.Size([609, 4]) tensor([162, 544, 377, 410], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.04681479558348656
bi 1 loss 0.21251541376113892
bi 2 loss 0.10372090339660645
bi 3 loss 0.2697565257549286
Layer  4  loss:  0.2005002349615097 0.0 12.812883377075195
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1022
Curr loss timestep torch.Size([609, 4]) tensor([ 85, 584, 435, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.07826534658670425
bi 1 loss 0.1836865097284317
bi 2 loss 0.19381307065486908
bi 3 loss 0.26119568943977356
Layer  5  loss:  0.1971292942762375 0.0 11.84599494934082
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1023
Curr loss timestep torch.Size([609, 4]) tensor([120, 309, 329, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.05495210736989975
bi 1 loss 0.2372640073299408
bi 2 loss 0.0957009494304657
bi 3 loss 0.28026437759399414
Layer  6  loss:  0.2027672529220581 0.0 9.86087703704834
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1023
Curr loss timestep torch.Size([609, 4]) tensor([ 79, 424, 435, 352], device='cuda:0') tensor(424, device='cuda:0')
bi 0 loss 0.04349451884627342
bi 1 loss 0.25322210788726807
bi 2 loss 0.1491594761610031
bi 3 loss 0.2414178103208542
Epoch 0: :   3%|▎         | 15249/600000 [01:43<1:05:51, v_num=12, reduced_train_loss=0.539, global_step=15247.0, consumed_samples=6.1e+4, train_step_timing in s=0.295]Epoch 0: :   3%|▎         | 15249/600000 [01:43<1:05:51, v_num=12, reduced_train_loss=1.510, global_step=15248.0, consumed_samples=6.1e+4, train_step_timing in s=0.420]loss mask original None

First layer loss:  3.8448352813720703 torch.Size([540, 4]) 12.37460994720459 0.0
Max loss timestep torch.Size([540, 4]) tensor([295, 108, 420, 217], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 3.6393678188323975
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 1 loss 3.0644960403442383
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 2 loss 3.926316022872925
speech mask sum tensor(482, device='cuda:0') loss mask sum tensor(482, device='cuda:0')
bi 3 loss 4.39350700378418
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
logits torch.Size([540, 4, 257024]) labels torch.Size([540, 4]) 0 257022
Layer  0  loss:  4.202667236328125 0.0 11.546285629272461
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([174, 108,  87, 196], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 3.9029738903045654
bi 1 loss 3.6809041500091553
bi 2 loss 4.345806121826172
bi 3 loss 4.538958549499512
Layer  1  loss:  4.57599401473999 0.0 10.796324729919434
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([205, 109, 187, 198], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.173578262329102
bi 1 loss 4.238738059997559
bi 2 loss 4.711228370666504
bi 3 loss 4.942845821380615
Layer  2  loss:  4.886072635650635 0.0 9.858020782470703
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([329, 133, 277, 267], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 4.702884197235107
bi 1 loss 4.418076515197754
bi 2 loss 4.988888263702393
bi 3 loss 5.147701740264893
Layer  3  loss:  4.959515571594238 0.0 10.277971267700195
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([275,  93, 295, 270], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 4.877338886260986
bi 1 loss 4.557834625244141
bi 2 loss 5.047298431396484
bi 3 loss 5.0908660888671875
Layer  4  loss:  5.0828447341918945 0.0 10.669027328491211
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([280, 137, 385, 248], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 4.995257377624512
bi 1 loss 4.8956618309021
bi 2 loss 5.101222038269043
bi 3 loss 5.265739917755127
Layer  5  loss:  5.135228157043457 0.0 11.428115844726562
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1021
Curr loss timestep torch.Size([540, 4]) tensor([341, 115, 484, 152], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 4.871509075164795
bi 1 loss 5.034078598022461
bi 2 loss 5.211190223693848
bi 3 loss 5.331457614898682
Layer  6  loss:  5.115377426147461 0.0 10.171359062194824
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([201,  89,  65, 166], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 4.95918607711792
bi 1 loss 4.999798774719238
bi 2 loss 5.137259483337402
bi 3 loss 5.328887462615967
Epoch 0: :   3%|▎         | 15250/600000 [01:43<1:06:06, v_num=12, reduced_train_loss=1.510, global_step=15248.0, consumed_samples=6.1e+4, train_step_timing in s=0.420]Epoch 0: :   3%|▎         | 15250/600000 [01:43<1:06:06, v_num=12, reduced_train_loss=37.80, global_step=15249.0, consumed_samples=6.1e+4, train_step_timing in s=0.348]loss mask original None

First layer loss:  0.22486433386802673 torch.Size([649, 4]) 11.017888069152832 0.0
Max loss timestep torch.Size([649, 4]) tensor([274, 424, 207, 544], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.06083178520202637
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 1 loss 0.18917496502399445
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 2 loss 0.30008557438850403
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 3 loss 0.26850607991218567
speech mask sum tensor(471, device='cuda:0') loss mask sum tensor(471, device='cuda:0')
logits torch.Size([649, 4, 257024]) labels torch.Size([649, 4]) 0 257022
Layer  0  loss:  0.20715203881263733 0.0 13.481158256530762
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([274, 323, 210, 600], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.028399497270584106
bi 1 loss 0.18748803436756134
bi 2 loss 0.13345085084438324
bi 3 loss 0.30265364050865173
Layer  1  loss:  0.18622693419456482 0.0 11.281636238098145
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([150, 323, 293, 586], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.058962710201740265
bi 1 loss 0.13251414895057678
bi 2 loss 0.07056637853384018
bi 3 loss 0.3030385673046112
Layer  2  loss:  0.21065491437911987 0.0 13.392261505126953
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([156, 424, 247, 514], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.05201719328761101
bi 1 loss 0.2030360847711563
bi 2 loss 0.07819158583879471
bi 3 loss 0.31510376930236816
Layer  3  loss:  0.2017451822757721 0.0 10.906593322753906
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1021
Curr loss timestep torch.Size([649, 4]) tensor([169, 424, 293, 633], device='cuda:0') tensor(633, device='cuda:0')
bi 0 loss 0.057268209755420685
bi 1 loss 0.1708974391222
bi 2 loss 0.11444824188947678
bi 3 loss 0.2988292872905731
Layer  4  loss:  0.2283935546875 0.0 13.757551193237305
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([153, 323, 257, 585], device='cuda:0') tensor(585, device='cuda:0')
bi 0 loss 0.03834333270788193
bi 1 loss 0.18905694782733917
bi 2 loss 0.07606111466884613
bi 3 loss 0.3697446882724762
Layer  5  loss:  0.2259140908718109 0.0 11.393816947937012
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([208, 323, 155, 584], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.04589906334877014
bi 1 loss 0.17651581764221191
bi 2 loss 0.1335456818342209
bi 3 loss 0.34734880924224854
Layer  6  loss:  0.2217731773853302 0.0 11.74748706817627
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([184, 323, 293, 573], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.04073408246040344
bi 1 loss 0.17399056255817413
bi 2 loss 0.10141026973724365
bi 3 loss 0.3532829284667969
Epoch 0: :   3%|▎         | 15251/600000 [01:43<1:06:24, v_num=12, reduced_train_loss=37.80, global_step=15249.0, consumed_samples=6.1e+4, train_step_timing in s=0.348]Epoch 0: :   3%|▎         | 15251/600000 [01:43<1:06:24, v_num=12, reduced_train_loss=1.710, global_step=15250.0, consumed_samples=6.1e+4, train_step_timing in s=0.445]loss mask original None

First layer loss:  0.14895345270633698 torch.Size([765, 4]) 13.146265983581543 0.0
Max loss timestep torch.Size([765, 4]) tensor([292, 424, 522, 153], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.04007701948285103
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 1 loss 0.10115716606378555
speech mask sum tensor(372, device='cuda:0') loss mask sum tensor(372, device='cuda:0')
bi 2 loss 0.2881767153739929
speech mask sum tensor(431, device='cuda:0') loss mask sum tensor(431, device='cuda:0')
bi 3 loss 0.025731422007083893
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
logits torch.Size([765, 4, 257024]) labels torch.Size([765, 4]) 0 257022
Layer  0  loss:  0.20911015570163727 0.0 20.447389602661133
logits torch.Size([765, 4, 1024]) labels torch.Size([765, 4]) 0 1023
Curr loss timestep torch.Size([765, 4]) tensor([253, 303, 646, 287], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.07068421691656113
bi 1 loss 0.22608980536460876
bi 2 loss 0.3109079897403717
bi 3 loss 0.07027051597833633
Layer  1  loss:  0.20908626914024353 0.0 12.215461730957031
logits torch.Size([765, 4, 1024]) labels torch.Size([765, 4]) 0 1022
Curr loss timestep torch.Size([765, 4]) tensor([175, 303, 616, 286], device='cuda:0') tensor(616, device='cuda:0')
bi 0 loss 0.059460025280714035
bi 1 loss 0.1978883594274521
bi 2 loss 0.34403690695762634
bi 3 loss 0.06030996888875961
Layer  2  loss:  0.2201284021139145 0.0 16.754072189331055
logits torch.Size([765, 4, 1024]) labels torch.Size([765, 4]) 0 1022
Curr loss timestep torch.Size([765, 4]) tensor([276, 303, 517, 290], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.04926181584596634
bi 1 loss 0.2325357347726822
bi 2 loss 0.3400348126888275
bi 3 loss 0.07762160897254944
Layer  3  loss:  0.26526543498039246 0.0 19.711074829101562
logits torch.Size([765, 4, 1024]) labels torch.Size([765, 4]) 0 1022
Curr loss timestep torch.Size([765, 4]) tensor([292, 303, 616, 287], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.05646905675530434
bi 1 loss 0.2595357894897461
bi 2 loss 0.4384464621543884
bi 3 loss 0.0721563920378685
Layer  4  loss:  0.25149279832839966 0.0 10.407896995544434
logits torch.Size([765, 4, 1024]) labels torch.Size([765, 4]) 0 1023
Curr loss timestep torch.Size([765, 4]) tensor([157, 303, 517, 152], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.041664380580186844
bi 1 loss 0.22909709811210632
bi 2 loss 0.42834997177124023
bi 3 loss 0.08280538767576218
Layer  5  loss:  0.20693935453891754 0.0 13.102897644042969
logits torch.Size([765, 4, 1024]) labels torch.Size([765, 4]) 0 1022
Curr loss timestep torch.Size([765, 4]) tensor([276, 303, 522, 287], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.02291334606707096
bi 1 loss 0.197213813662529
bi 2 loss 0.351056307554245
bi 3 loss 0.0643465518951416
Layer  6  loss:  0.22540788352489471 0.0 10.812601089477539
logits torch.Size([765, 4, 1024]) labels torch.Size([765, 4]) 0 1020
Curr loss timestep torch.Size([765, 4]) tensor([173, 424, 616, 286], device='cuda:0') tensor(616, device='cuda:0')
bi 0 loss 0.06347393989562988
bi 1 loss 0.1819452941417694
bi 2 loss 0.39707085490226746
bi 3 loss 0.06756286323070526
Epoch 0: :   3%|▎         | 15252/600000 [01:44<1:06:45, v_num=12, reduced_train_loss=1.710, global_step=15250.0, consumed_samples=6.1e+4, train_step_timing in s=0.445]Epoch 0: :   3%|▎         | 15252/600000 [01:44<1:06:45, v_num=12, reduced_train_loss=1.740, global_step=15251.0, consumed_samples=6.1e+4, train_step_timing in s=0.527]loss mask original None

First layer loss:  0.16931237280368805 torch.Size([641, 4]) 10.095711708068848 0.0
Max loss timestep torch.Size([641, 4]) tensor([ 83, 114, 160, 616], device='cuda:0') tensor(616, device='cuda:0')
bi 0 loss 0.0628357008099556
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 1 loss 0.02347317524254322
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 2 loss 0.03273185342550278
speech mask sum tensor(60, device='cuda:0') loss mask sum tensor(60, device='cuda:0')
bi 3 loss 0.26097404956817627
speech mask sum tensor(445, device='cuda:0') loss mask sum tensor(445, device='cuda:0')
logits torch.Size([641, 4, 257024]) labels torch.Size([641, 4]) 0 257023
Layer  0  loss:  0.1867613047361374 0.0 15.654749870300293
logits torch.Size([641, 4, 1024]) labels torch.Size([641, 4]) 0 1023
Curr loss timestep torch.Size([641, 4]) tensor([ 90,  89, 173, 616], device='cuda:0') tensor(616, device='cuda:0')
bi 0 loss 0.07137801498174667
bi 1 loss 0.013493400998413563
bi 2 loss 0.017534760758280754
bi 3 loss 0.292202889919281
Layer  1  loss:  0.17411422729492188 0.0 14.30843448638916
logits torch.Size([641, 4, 1024]) labels torch.Size([641, 4]) 0 1022
Curr loss timestep torch.Size([641, 4]) tensor([187, 140, 172, 616], device='cuda:0') tensor(616, device='cuda:0')
bi 0 loss 0.04082322493195534
bi 1 loss 0.045952294021844864
bi 2 loss 0.06029065325856209
bi 3 loss 0.2695389688014984
Layer  2  loss:  0.23311400413513184 0.0 19.034740447998047
logits torch.Size([641, 4, 1024]) labels torch.Size([641, 4]) 0 1022
Curr loss timestep torch.Size([641, 4]) tensor([133, 163, 151, 616], device='cuda:0') tensor(616, device='cuda:0')
bi 0 loss 0.054392170161008835
bi 1 loss 0.025479361414909363
bi 2 loss 0.03374797850847244
bi 3 loss 0.3750067949295044
Layer  3  loss:  0.19897331297397614 0.0 12.548704147338867
logits torch.Size([641, 4, 1024]) labels torch.Size([641, 4]) 0 1022
Curr loss timestep torch.Size([641, 4]) tensor([124, 114, 142, 544], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.053921833634376526
bi 1 loss 0.027513157576322556
bi 2 loss 0.054035838693380356
bi 3 loss 0.31248795986175537
Layer  4  loss:  0.18818700313568115 0.0 9.456921577453613
logits torch.Size([641, 4, 1024]) labels torch.Size([641, 4]) 0 1021
Curr loss timestep torch.Size([641, 4]) tensor([144, 115, 148, 557], device='cuda:0') tensor(557, device='cuda:0')
bi 0 loss 0.0722610205411911
bi 1 loss 0.029393645003437996
bi 2 loss 0.04165725037455559
bi 3 loss 0.2876929044723511
Layer  5  loss:  0.20816317200660706 0.0 15.614693641662598
logits torch.Size([641, 4, 1024]) labels torch.Size([641, 4]) 0 1019
Curr loss timestep torch.Size([641, 4]) tensor([223, 121, 155, 523], device='cuda:0') tensor(523, device='cuda:0')
bi 0 loss 0.04276604577898979
bi 1 loss 0.02132938802242279
bi 2 loss 0.03365281969308853
bi 3 loss 0.3369940221309662
Layer  6  loss:  0.21777218580245972 0.0 11.75316333770752
logits torch.Size([641, 4, 1024]) labels torch.Size([641, 4]) 0 1023
Curr loss timestep torch.Size([641, 4]) tensor([ 91, 159, 167, 559], device='cuda:0') tensor(559, device='cuda:0')
bi 0 loss 0.07868704199790955
bi 1 loss 0.02814331464469433
bi 2 loss 0.026390615850687027
bi 3 loss 0.3390679955482483
Epoch 0: :   3%|▎         | 15253/600000 [01:44<1:07:03, v_num=12, reduced_train_loss=1.740, global_step=15251.0, consumed_samples=6.1e+4, train_step_timing in s=0.527]Epoch 0: :   3%|▎         | 15253/600000 [01:44<1:07:03, v_num=12, reduced_train_loss=1.580, global_step=15252.0, consumed_samples=6.1e+4, train_step_timing in s=0.440]loss mask original None

First layer loss:  0.08788897097110748 torch.Size([537, 4]) 8.561426162719727 0.0
Max loss timestep torch.Size([537, 4]) tensor([369,  94, 244, 368], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.04671347141265869
speech mask sum tensor(422, device='cuda:0') loss mask sum tensor(422, device='cuda:0')
bi 1 loss 0.04580586776137352
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 2 loss 0.06782792508602142
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 3 loss 0.14703455567359924
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
logits torch.Size([537, 4, 257024]) labels torch.Size([537, 4]) 0 257022
Layer  0  loss:  0.10114647448062897 0.0 13.594560623168945
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([287,  67, 271, 369], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.06472209095954895
bi 1 loss 0.028321145102381706
bi 2 loss 0.05760965496301651
bi 3 loss 0.17554274201393127
Layer  1  loss:  0.12430507689714432 0.0 10.41052532196045
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([369,  89, 292, 326], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.12256421893835068
bi 1 loss 0.028551241382956505
bi 2 loss 0.08553171157836914
bi 3 loss 0.16618970036506653
Layer  2  loss:  0.11179105192422867 0.0 11.159005165100098
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([286,  97, 282, 326], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.12514165043830872
bi 1 loss 0.014082745648920536
bi 2 loss 0.05486888810992241
bi 3 loss 0.150862455368042
Layer  3  loss:  0.12483693659305573 0.0 8.726375579833984
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([369,  94, 153, 368], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.14452259242534637
bi 1 loss 0.0424138680100441
bi 2 loss 0.04956427216529846
bi 3 loss 0.1667720526456833
Layer  4  loss:  0.12803781032562256 0.0 13.5169677734375
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([369,  87, 250, 369], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.11209353804588318
bi 1 loss 0.030100008472800255
bi 2 loss 0.06221155449748039
bi 3 loss 0.2008855938911438
Layer  5  loss:  0.12322165071964264 0.0 14.401395797729492
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1018
Curr loss timestep torch.Size([537, 4]) tensor([369,  54, 256, 369], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.13263104856014252
bi 1 loss 0.05063929408788681
bi 2 loss 0.04473227262496948
bi 3 loss 0.17541375756263733
Layer  6  loss:  0.12465117871761322 0.0 11.736712455749512
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([369,  90, 296, 368], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.14703817665576935
bi 1 loss 0.03418323025107384
bi 2 loss 0.07493600994348526
bi 3 loss 0.14931753277778625
Epoch 0: :   3%|▎         | 15254/600000 [01:45<1:07:19, v_num=12, reduced_train_loss=1.580, global_step=15252.0, consumed_samples=6.1e+4, train_step_timing in s=0.440]Epoch 0: :   3%|▎         | 15254/600000 [01:45<1:07:19, v_num=12, reduced_train_loss=0.926, global_step=15253.0, consumed_samples=6.1e+4, train_step_timing in s=0.372]loss mask original None

First layer loss:  0.1489647626876831 torch.Size([611, 4]) 13.612220764160156 0.0
Max loss timestep torch.Size([611, 4]) tensor([303, 451,  72, 308], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.12306944280862808
speech mask sum tensor(46, device='cuda:0') loss mask sum tensor(46, device='cuda:0')
bi 1 loss 0.2075791358947754
speech mask sum tensor(386, device='cuda:0') loss mask sum tensor(386, device='cuda:0')
bi 2 loss 0.04398445412516594
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 3 loss 0.08303791284561157
speech mask sum tensor(99, device='cuda:0') loss mask sum tensor(99, device='cuda:0')
logits torch.Size([611, 4, 257024]) labels torch.Size([611, 4]) 0 257023
Layer  0  loss:  0.170181542634964 0.0 9.062702178955078
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([302, 591,  77, 321], device='cuda:0') tensor(591, device='cuda:0')
bi 0 loss 0.2783237397670746
bi 1 loss 0.21772682666778564
bi 2 loss 0.03229093179106712
bi 3 loss 0.1323375403881073
Layer  1  loss:  0.21039888262748718 0.0 13.942696571350098
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([304, 451, 103, 321], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.2494603395462036
bi 1 loss 0.29111987352371216
bi 2 loss 0.06368731707334518
bi 3 loss 0.08795369416475296
Layer  2  loss:  0.1831371933221817 0.0 6.707438945770264
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([302, 373, 153, 321], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.20633921027183533
bi 1 loss 0.2301243245601654
bi 2 loss 0.046343643218278885
bi 3 loss 0.1853630244731903
Layer  3  loss:  0.2056216150522232 0.0 9.696891784667969
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([304, 464,  55, 321], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.26967066526412964
bi 1 loss 0.2880668342113495
bi 2 loss 0.02966943196952343
bi 3 loss 0.10678435117006302
Layer  4  loss:  0.21966487169265747 0.0 10.708423614501953
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([303, 591, 159, 289], device='cuda:0') tensor(591, device='cuda:0')
bi 0 loss 0.3397803008556366
bi 1 loss 0.3055550456047058
bi 2 loss 0.03783373162150383
bi 3 loss 0.08977699279785156
Layer  5  loss:  0.190131276845932 0.0 8.626270294189453
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1019
Curr loss timestep torch.Size([611, 4]) tensor([304, 464, 126, 319], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.4161856174468994
bi 1 loss 0.23870983719825745
bi 2 loss 0.03731570392847061
bi 3 loss 0.11487868428230286
Layer  6  loss:  0.24740192294120789 0.0 16.24353790283203
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([304, 276, 143, 303], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.42600682377815247
bi 1 loss 0.3065071403980255
bi 2 loss 0.05450882390141487
bi 3 loss 0.21063818037509918
Epoch 0: :   3%|▎         | 15255/600000 [01:45<1:07:36, v_num=12, reduced_train_loss=0.926, global_step=15253.0, consumed_samples=6.1e+4, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15255/600000 [01:45<1:07:36, v_num=12, reduced_train_loss=1.580, global_step=15254.0, consumed_samples=6.1e+4, train_step_timing in s=0.424]loss mask original None

First layer loss:  0.22089406847953796 torch.Size([715, 4]) 12.55398178100586 0.0
Max loss timestep torch.Size([715, 4]) tensor([305, 597,  53, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.30045515298843384
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
bi 1 loss 0.25113245844841003
speech mask sum tensor(483, device='cuda:0') loss mask sum tensor(483, device='cuda:0')
bi 2 loss 0.020045850425958633
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 3 loss 0.13926132023334503
speech mask sum tensor(267, device='cuda:0') loss mask sum tensor(267, device='cuda:0')
logits torch.Size([715, 4, 257024]) labels torch.Size([715, 4]) 0 257023
Layer  0  loss:  0.24796974658966064 0.0 15.626729965209961
logits torch.Size([715, 4, 1024]) labels torch.Size([715, 4]) 0 1023
Curr loss timestep torch.Size([715, 4]) tensor([652, 597,  78, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.3307810127735138
bi 1 loss 0.2631591856479645
bi 2 loss 0.078835129737854
bi 3 loss 0.17033302783966064
Layer  1  loss:  0.25379061698913574 0.0 13.236554145812988
logits torch.Size([715, 4, 1024]) labels torch.Size([715, 4]) 0 1023
Curr loss timestep torch.Size([715, 4]) tensor([383, 597,  98, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.3937799334526062
bi 1 loss 0.2221779227256775
bi 2 loss 0.06633057445287704
bi 3 loss 0.1716107279062271
Layer  2  loss:  0.2748575210571289 0.0 12.128378868103027
logits torch.Size([715, 4, 1024]) labels torch.Size([715, 4]) 0 1022
Curr loss timestep torch.Size([715, 4]) tensor([383, 535, 137, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.3646792769432068
bi 1 loss 0.3069743514060974
bi 2 loss 0.06240735948085785
bi 3 loss 0.17842647433280945
Layer  3  loss:  0.2621415853500366 0.0 11.746098518371582
logits torch.Size([715, 4, 1024]) labels torch.Size([715, 4]) 0 1022
Curr loss timestep torch.Size([715, 4]) tensor([652, 597,  73, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.4335344135761261
bi 1 loss 0.22014327347278595
bi 2 loss 0.04601238667964935
bi 3 loss 0.1600666493177414
Layer  4  loss:  0.253460168838501 0.0 13.73719310760498
logits torch.Size([715, 4, 1024]) labels torch.Size([715, 4]) 0 1022
Curr loss timestep torch.Size([715, 4]) tensor([653, 597,  99, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.38992059230804443
bi 1 loss 0.21016556024551392
bi 2 loss 0.027426371350884438
bi 3 loss 0.2199271321296692
Layer  5  loss:  0.2674717307090759 0.0 11.74947452545166
logits torch.Size([715, 4, 1024]) labels torch.Size([715, 4]) 0 1023
Curr loss timestep torch.Size([715, 4]) tensor([382, 597, 149, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.4195435047149658
bi 1 loss 0.2459152787923813
bi 2 loss 0.04624610394239426
bi 3 loss 0.16481947898864746
Layer  6  loss:  0.2844894826412201 0.0 15.797544479370117
logits torch.Size([715, 4, 1024]) labels torch.Size([715, 4]) 0 1022
Curr loss timestep torch.Size([715, 4]) tensor([686, 597,  52, 264], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.4254160523414612
bi 1 loss 0.2718884348869324
bi 2 loss 0.03970140963792801
bi 3 loss 0.19806621968746185
Epoch 0: :   3%|▎         | 15256/600000 [01:46<1:07:56, v_num=12, reduced_train_loss=1.580, global_step=15254.0, consumed_samples=6.1e+4, train_step_timing in s=0.424]Epoch 0: :   3%|▎         | 15256/600000 [01:46<1:07:56, v_num=12, reduced_train_loss=2.070, global_step=15255.0, consumed_samples=6.1e+4, train_step_timing in s=0.488]loss mask original None

First layer loss:  0.055094458162784576 torch.Size([482, 4]) 4.767292499542236 0.0
Max loss timestep torch.Size([482, 4]) tensor([297, 432, 312, 178], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.032619282603263855
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
bi 1 loss 0.05492651090025902
speech mask sum tensor(354, device='cuda:0') loss mask sum tensor(354, device='cuda:0')
bi 2 loss 0.08668157458305359
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 3 loss 0.054108645766973495
speech mask sum tensor(185, device='cuda:0') loss mask sum tensor(185, device='cuda:0')
logits torch.Size([482, 4, 257024]) labels torch.Size([482, 4]) 0 257023
Layer  0  loss:  0.05780276656150818 0.0 4.877065658569336
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([297, 272, 314, 204], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.045006368309259415
bi 1 loss 0.05462132394313812
bi 2 loss 0.09645162522792816
bi 3 loss 0.04337533563375473
Layer  1  loss:  0.06308669596910477 0.0 6.994669437408447
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([297, 443, 345, 211], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.058636367321014404
bi 1 loss 0.06280513107776642
bi 2 loss 0.08071523159742355
bi 3 loss 0.05248453840613365
Layer  2  loss:  0.06815050542354584 0.0 3.918445587158203
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([297, 446, 314, 170], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.06264711171388626
bi 1 loss 0.07557481527328491
bi 2 loss 0.09846245497465134
bi 3 loss 0.03202282637357712
Layer  3  loss:  0.05184502899646759 0.0 4.232108116149902
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1021
Curr loss timestep torch.Size([482, 4]) tensor([297, 304, 312, 125], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.0380052886903286
bi 1 loss 0.06308738887310028
bi 2 loss 0.06899165362119675
bi 3 loss 0.03173213452100754
Layer  4  loss:  0.07250212132930756 0.0 4.383735656738281
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([264, 290, 312, 149], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.05910991132259369
bi 1 loss 0.060805875808000565
bi 2 loss 0.14632989466190338
bi 3 loss 0.041476696729660034
Layer  5  loss:  0.05597769096493721 0.0 2.3558719158172607
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([297, 439, 267,  82], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.03463713079690933
bi 1 loss 0.07490991801023483
bi 2 loss 0.05284782499074936
bi 3 loss 0.0501994788646698
Layer  6  loss:  0.06123693659901619 0.0 6.932096481323242
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([296, 443, 314, 130], device='cuda:0') tensor(443, device='cuda:0')
bi 0 loss 0.04415931925177574
bi 1 loss 0.07274074107408524
bi 2 loss 0.0862787738442421
bi 3 loss 0.037235457450151443
Epoch 0: :   3%|▎         | 15257/600000 [01:46<1:08:10, v_num=12, reduced_train_loss=2.070, global_step=15255.0, consumed_samples=6.1e+4, train_step_timing in s=0.488]Epoch 0: :   3%|▎         | 15257/600000 [01:46<1:08:10, v_num=12, reduced_train_loss=0.486, global_step=15256.0, consumed_samples=6.1e+4, train_step_timing in s=0.340]loss mask original None

First layer loss:  0.27807173132896423 torch.Size([651, 4]) 12.00165843963623 0.0
Max loss timestep torch.Size([651, 4]) tensor([328, 327, 585, 514], device='cuda:0') tensor(585, device='cuda:0')
bi 0 loss 0.3491680920124054
speech mask sum tensor(309, device='cuda:0') loss mask sum tensor(309, device='cuda:0')
bi 1 loss 0.13972732424736023
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 2 loss 0.20413704216480255
speech mask sum tensor(426, device='cuda:0') loss mask sum tensor(426, device='cuda:0')
bi 3 loss 0.34207817912101746
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
logits torch.Size([651, 4, 257024]) labels torch.Size([651, 4]) 0 257023
Layer  0  loss:  0.3496415913105011 0.0 16.20747184753418
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([406, 310, 586, 514], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.4929429292678833
bi 1 loss 0.1802782267332077
bi 2 loss 0.3120809495449066
bi 3 loss 0.3479534983634949
Layer  1  loss:  0.3615097105503082 0.0 17.554443359375
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([406, 276, 585, 375], device='cuda:0') tensor(406, device='cuda:0')
bi 0 loss 0.5208989381790161
bi 1 loss 0.14724460244178772
bi 2 loss 0.34012624621391296
bi 3 loss 0.35062602162361145
Layer  2  loss:  0.40765315294265747 0.0 17.633913040161133
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([407, 291, 586, 375], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.6076971292495728
bi 1 loss 0.1588653326034546
bi 2 loss 0.32683688402175903
bi 3 loss 0.4335404336452484
Layer  3  loss:  0.4061051607131958 0.0 15.902728080749512
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([407, 282, 583, 583], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.656549870967865
bi 1 loss 0.23370186984539032
bi 2 loss 0.294581800699234
bi 3 loss 0.40219905972480774
Layer  4  loss:  0.4091607630252838 0.0 15.579689979553223
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([328, 312, 586, 405], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.6378627419471741
bi 1 loss 0.23767989873886108
bi 2 loss 0.3145541548728943
bi 3 loss 0.4039771556854248
Layer  5  loss:  0.44181951880455017 0.0 13.572650909423828
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([291, 310, 544, 584], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.6279338598251343
bi 1 loss 0.2123967856168747
bi 2 loss 0.40178003907203674
bi 3 loss 0.4352343678474426
Layer  6  loss:  0.4089490473270416 0.0 13.531549453735352
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([406, 332, 533, 514], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.580930233001709
bi 1 loss 0.19969452917575836
bi 2 loss 0.3215559720993042
bi 3 loss 0.444994181394577
Epoch 0: :   3%|▎         | 15258/600000 [01:47<1:08:28, v_num=12, reduced_train_loss=0.486, global_step=15256.0, consumed_samples=6.1e+4, train_step_timing in s=0.340]Epoch 0: :   3%|▎         | 15258/600000 [01:47<1:08:28, v_num=12, reduced_train_loss=3.060, global_step=15257.0, consumed_samples=6.1e+4, train_step_timing in s=0.443]loss mask original None

First layer loss:  0.13433094322681427 torch.Size([579, 4]) 7.0962042808532715 0.0
Max loss timestep torch.Size([579, 4]) tensor([289, 439, 292, 146], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.1524357944726944
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
bi 1 loss 0.14142829179763794
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
bi 2 loss 0.16472120583057404
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
bi 3 loss 0.03353319317102432
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([579, 4, 257024]) labels torch.Size([579, 4]) 0 257023
Layer  0  loss:  0.11714044958353043 0.0 5.395607948303223
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([394, 439, 348, 152], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.14114201068878174
bi 1 loss 0.1178162544965744
bi 2 loss 0.14840002357959747
bi 3 loss 0.015574119053781033
Layer  1  loss:  0.14675281941890717 0.0 7.992522239685059
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1022
Curr loss timestep torch.Size([579, 4]) tensor([394, 287, 312, 178], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.16922003030776978
bi 1 loss 0.15970733761787415
bi 2 loss 0.18747596442699432
bi 3 loss 0.008152080699801445
Layer  2  loss:  0.14875230193138123 0.0 9.39857006072998
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1022
Curr loss timestep torch.Size([579, 4]) tensor([395, 287, 267,  64], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.1574205607175827
bi 1 loss 0.19204245507717133
bi 2 loss 0.12762798368930817
bi 3 loss 0.056965697556734085
Layer  3  loss:  0.13171127438545227 0.0 6.252102851867676
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([395, 287, 348, 135], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.1663690209388733
bi 1 loss 0.13086733222007751
bi 2 loss 0.1569044142961502
bi 3 loss 0.015903949737548828
Layer  4  loss:  0.13237683475017548 0.0 7.962688446044922
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([395, 288, 312, 146], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.15503564476966858
bi 1 loss 0.14230965077877045
bi 2 loss 0.1389254629611969
bi 3 loss 0.04595457762479782
Layer  5  loss:  0.13224858045578003 0.0 6.236644268035889
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([395, 439, 323, 145], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.14167606830596924
bi 1 loss 0.18677343428134918
bi 2 loss 0.09894221276044846
bi 3 loss 0.029220007359981537
Layer  6  loss:  0.12714612483978271 0.0 8.559703826904297
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1020
Curr loss timestep torch.Size([579, 4]) tensor([395, 288, 348, 144], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.13613341748714447
bi 1 loss 0.17652453482151031
bi 2 loss 0.09794989228248596
bi 3 loss 0.03145857900381088
Epoch 0: :   3%|▎         | 15259/600000 [01:47<1:08:45, v_num=12, reduced_train_loss=3.060, global_step=15257.0, consumed_samples=6.1e+4, train_step_timing in s=0.443]Epoch 0: :   3%|▎         | 15259/600000 [01:47<1:08:45, v_num=12, reduced_train_loss=1.070, global_step=15258.0, consumed_samples=6.1e+4, train_step_timing in s=0.398]loss mask original None

First layer loss:  3.3847060203552246 torch.Size([440, 4]) 9.27363395690918 0.0
Max loss timestep torch.Size([440, 4]) tensor([275, 273, 213, 125], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 3.1251838207244873
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 1 loss 3.5488510131835938
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 2 loss 4.245120048522949
speech mask sum tensor(69, device='cuda:0') loss mask sum tensor(69, device='cuda:0')
bi 3 loss 3.003916025161743
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([440, 4, 257024]) labels torch.Size([440, 4]) 0 257023
Layer  0  loss:  3.8847217559814453 0.0 10.459094047546387
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([224, 240, 229,  87], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 3.9492740631103516
bi 1 loss 4.0873122215271
bi 2 loss 4.155697345733643
bi 3 loss 3.37268328666687
Layer  1  loss:  4.221794605255127 0.0 10.211292266845703
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([257, 251, 208, 113], device='cuda:0') tensor(241, device='cuda:0')
bi 0 loss 4.222829818725586
bi 1 loss 4.17804479598999
bi 2 loss 4.860342502593994
bi 3 loss 3.969430685043335
Layer  2  loss:  4.629276752471924 0.0 10.388954162597656
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([251, 374, 256,  69], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 4.610157012939453
bi 1 loss 4.787568092346191
bi 2 loss 4.774362564086914
bi 3 loss 4.340845108032227
Layer  3  loss:  4.659496307373047 0.0 9.711105346679688
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([270, 305, 251, 116], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.687514781951904
bi 1 loss 4.791472911834717
bi 2 loss 4.923835277557373
bi 3 loss 4.298189640045166
Layer  4  loss:  4.711032867431641 0.0 9.918146133422852
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([256, 402, 226, 109], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 4.705125331878662
bi 1 loss 4.7371625900268555
bi 2 loss 5.195967197418213
bi 3 loss 4.4376935958862305
Layer  5  loss:  4.839332580566406 0.0 9.329254150390625
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([285, 259, 248, 146], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 4.899907112121582
bi 1 loss 4.903799057006836
bi 2 loss 5.114506244659424
bi 3 loss 4.537384033203125
Layer  6  loss:  4.917223930358887 0.0 10.20292854309082
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([291, 320, 219, 113], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 4.985055923461914
bi 1 loss 5.0083465576171875
bi 2 loss 5.2805047035217285
bi 3 loss 4.523264408111572
Epoch 0: :   3%|▎         | 15260/600000 [01:47<1:08:58, v_num=12, reduced_train_loss=1.070, global_step=15258.0, consumed_samples=6.1e+4, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15260/600000 [01:47<1:08:58, v_num=12, reduced_train_loss=35.20, global_step=15259.0, consumed_samples=6.1e+4, train_step_timing in s=0.311]loss mask original None

First layer loss:  0.15058404207229614 torch.Size([475, 4]) 14.469986915588379 0.0
Max loss timestep torch.Size([475, 4]) tensor([307, 428, 350, 427], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.2297438532114029
speech mask sum tensor(369, device='cuda:0') loss mask sum tensor(369, device='cuda:0')
bi 1 loss 0.07218517363071442
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 2 loss 0.06604032218456268
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 3 loss 0.1683100312948227
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
logits torch.Size([475, 4, 257024]) labels torch.Size([475, 4]) 0 257022
Layer  0  loss:  0.21690116822719574 0.0 16.025272369384766
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1023
Curr loss timestep torch.Size([475, 4]) tensor([304, 332, 276, 428], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.26441890001296997
bi 1 loss 0.23981249332427979
bi 2 loss 0.1821441948413849
bi 3 loss 0.1619015485048294
Layer  1  loss:  0.19182555377483368 0.0 14.473031997680664
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1023
Curr loss timestep torch.Size([475, 4]) tensor([303, 339, 276, 428], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.28492221236228943
bi 1 loss 0.14399245381355286
bi 2 loss 0.19682617485523224
bi 3 loss 0.12005200237035751
Layer  2  loss:  0.24263030290603638 0.0 14.08680534362793
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1022
Curr loss timestep torch.Size([475, 4]) tensor([303, 327, 277, 427], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.29134175181388855
bi 1 loss 0.21945345401763916
bi 2 loss 0.23960508406162262
bi 3 loss 0.2066197246313095
Layer  3  loss:  0.23752573132514954 0.0 22.257877349853516
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1022
Curr loss timestep torch.Size([475, 4]) tensor([303, 342, 276, 427], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.27552616596221924
bi 1 loss 0.2016923874616623
bi 2 loss 0.22288548946380615
bi 3 loss 0.2305346578359604
Layer  4  loss:  0.25079962611198425 0.0 18.422107696533203
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1022
Curr loss timestep torch.Size([475, 4]) tensor([302, 310, 277, 428], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.36186057329177856
bi 1 loss 0.18862900137901306
bi 2 loss 0.18586698174476624
bi 3 loss 0.20768368244171143
Layer  5  loss:  0.288017213344574 0.0 18.715343475341797
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1023
Curr loss timestep torch.Size([475, 4]) tensor([304, 326, 277, 427], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.3282633125782013
bi 1 loss 0.25329896807670593
bi 2 loss 0.2342456579208374
bi 3 loss 0.29867732524871826
Layer  6  loss:  0.2692144811153412 0.0 16.07118797302246
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1022
Curr loss timestep torch.Size([475, 4]) tensor([302, 326, 277, 427], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.31428390741348267
bi 1 loss 0.2878001928329468
bi 2 loss 0.21853037178516388
bi 3 loss 0.22919349372386932
Epoch 0: :   3%|▎         | 15261/600000 [01:48<1:09:12, v_num=12, reduced_train_loss=35.20, global_step=15259.0, consumed_samples=6.1e+4, train_step_timing in s=0.311]Epoch 0: :   3%|▎         | 15261/600000 [01:48<1:09:12, v_num=12, reduced_train_loss=1.850, global_step=15260.0, consumed_samples=6.1e+4, train_step_timing in s=0.343]loss mask original None

First layer loss:  0.11057959496974945 torch.Size([691, 4]) 11.098596572875977 0.0
Max loss timestep torch.Size([691, 4]) tensor([434, 273, 618, 365], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.13841082155704498
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
bi 1 loss 0.05583309754729271
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
bi 2 loss 0.1020222008228302
speech mask sum tensor(480, device='cuda:0') loss mask sum tensor(480, device='cuda:0')
bi 3 loss 0.12179233133792877
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
logits torch.Size([691, 4, 257024]) labels torch.Size([691, 4]) 0 257023
Layer  0  loss:  0.15015773475170135 0.0 13.253113746643066
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([434, 271, 618, 270], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.16759683191776276
bi 1 loss 0.07044894248247147
bi 2 loss 0.13546060025691986
bi 3 loss 0.19314956665039062
Layer  1  loss:  0.13763485848903656 0.0 6.112427711486816
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([434, 278, 621, 450], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.14652244746685028
bi 1 loss 0.05603500455617905
bi 2 loss 0.15004783868789673
bi 3 loss 0.14937883615493774
Layer  2  loss:  0.16247719526290894 0.0 10.938189506530762
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([278, 165, 465, 365], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.17076580226421356
bi 1 loss 0.05308697372674942
bi 2 loss 0.16361168026924133
bi 3 loss 0.20521268248558044
Layer  3  loss:  0.1625939905643463 0.0 13.580046653747559
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1020
Curr loss timestep torch.Size([691, 4]) tensor([434, 269, 465, 365], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.22357654571533203
bi 1 loss 0.09569333493709564
bi 2 loss 0.14650075137615204
bi 3 loss 0.15755034983158112
Layer  4  loss:  0.14916889369487762 0.0 11.830714225769043
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([434, 273, 618, 453], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.193442702293396
bi 1 loss 0.06293731182813644
bi 2 loss 0.14981529116630554
bi 3 loss 0.14513514935970306
Layer  5  loss:  0.16608156263828278 0.0 8.467966079711914
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([434, 164, 465, 365], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.21882686018943787
bi 1 loss 0.09614459425210953
bi 2 loss 0.16695067286491394
bi 3 loss 0.1452951431274414
Layer  6  loss:  0.18001964688301086 0.0 13.471720695495605
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([434, 265, 465, 365], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.24441732466220856
bi 1 loss 0.06801913678646088
bi 2 loss 0.19142955541610718
bi 3 loss 0.1519170105457306
Epoch 0: :   3%|▎         | 15262/600000 [01:48<1:09:31, v_num=12, reduced_train_loss=1.850, global_step=15260.0, consumed_samples=6.1e+4, train_step_timing in s=0.343]Epoch 0: :   3%|▎         | 15262/600000 [01:48<1:09:31, v_num=12, reduced_train_loss=1.220, global_step=15261.0, consumed_samples=6.1e+4, train_step_timing in s=0.477]loss mask original None

First layer loss:  0.07368135452270508 torch.Size([401, 4]) 12.42831039428711 0.0
Max loss timestep torch.Size([401, 4]) tensor([335, 383,  86, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.06301507353782654
speech mask sum tensor(200, device='cuda:0') loss mask sum tensor(200, device='cuda:0')
bi 1 loss 0.05180516466498375
speech mask sum tensor(334, device='cuda:0') loss mask sum tensor(334, device='cuda:0')
bi 2 loss 0.01665288396179676
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 3 loss 0.186070054769516
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
logits torch.Size([401, 4, 257024]) labels torch.Size([401, 4]) 0 257022
Layer  0  loss:  0.06586113572120667 0.0 16.3677921295166
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1023
Curr loss timestep torch.Size([401, 4]) tensor([314, 383,  80, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.0710657387971878
bi 1 loss 0.03633486106991768
bi 2 loss 0.026366621255874634
bi 3 loss 0.15590520203113556
Layer  1  loss:  0.0795263946056366 0.0 14.16224193572998
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1022
Curr loss timestep torch.Size([401, 4]) tensor([314, 383,  75, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.043516360223293304
bi 1 loss 0.05714484304189682
bi 2 loss 0.026721172034740448
bi 3 loss 0.21533872187137604
Layer  2  loss:  0.08470690250396729 0.0 18.05552864074707
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1022
Curr loss timestep torch.Size([401, 4]) tensor([317, 392, 177, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.06933077424764633
bi 1 loss 0.04370925948023796
bi 2 loss 0.02172454632818699
bi 3 loss 0.24274888634681702
Layer  3  loss:  0.08416590094566345 0.0 9.50252628326416
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1022
Curr loss timestep torch.Size([401, 4]) tensor([313, 383, 202, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.061837196350097656
bi 1 loss 0.05059181898832321
bi 2 loss 0.02857978083193302
bi 3 loss 0.22835557162761688
Layer  4  loss:  0.07976214587688446 0.0 11.810211181640625
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1022
Curr loss timestep torch.Size([401, 4]) tensor([317, 383, 169, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.060473423451185226
bi 1 loss 0.04997803270816803
bi 2 loss 0.016347093507647514
bi 3 loss 0.22243008017539978
Layer  5  loss:  0.08133947104215622 0.0 13.829289436340332
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1020
Curr loss timestep torch.Size([401, 4]) tensor([317, 383, 236, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.06845256686210632
bi 1 loss 0.0689489021897316
bi 2 loss 0.017956282943487167
bi 3 loss 0.18605932593345642
Layer  6  loss:  0.07961365580558777 0.0 10.658576011657715
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1020
Curr loss timestep torch.Size([401, 4]) tensor([317, 383, 144, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.06013103947043419
bi 1 loss 0.06388584524393082
bi 2 loss 0.020192967727780342
bi 3 loss 0.19304689764976501
Epoch 0: :   3%|▎         | 15263/600000 [01:49<1:09:44, v_num=12, reduced_train_loss=1.220, global_step=15261.0, consumed_samples=6.1e+4, train_step_timing in s=0.477]Epoch 0: :   3%|▎         | 15263/600000 [01:49<1:09:44, v_num=12, reduced_train_loss=0.629, global_step=15262.0, consumed_samples=61052.0, train_step_timing in s=0.299]loss mask original None

First layer loss:  0.09596209973096848 torch.Size([471, 4]) 7.56377649307251 0.0
Max loss timestep torch.Size([471, 4]) tensor([319, 291, 246, 308], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.07044599950313568
speech mask sum tensor(334, device='cuda:0') loss mask sum tensor(334, device='cuda:0')
bi 1 loss 0.12323659658432007
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
bi 2 loss 0.07177416980266571
speech mask sum tensor(201, device='cuda:0') loss mask sum tensor(201, device='cuda:0')
bi 3 loss 0.12047673016786575
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
logits torch.Size([471, 4, 257024]) labels torch.Size([471, 4]) 0 257022
Layer  0  loss:  0.08720474690198898 0.0 5.630642414093018
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([419, 291, 254, 303], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.08270151913166046
bi 1 loss 0.09831259399652481
bi 2 loss 0.08476240187883377
bi 3 loss 0.07430211454629898
Layer  1  loss:  0.12183104455471039 0.0 8.167255401611328
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([319, 290, 296, 303], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.07024101167917252
bi 1 loss 0.14861750602722168
bi 2 loss 0.1120784655213356
bi 3 loss 0.18595120310783386
Layer  2  loss:  0.11206743866205215 0.0 8.453263282775879
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([335, 293, 288, 307], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.05735225975513458
bi 1 loss 0.11638210713863373
bi 2 loss 0.16890382766723633
bi 3 loss 0.1472928524017334
Layer  3  loss:  0.11519639939069748 0.0 8.720738410949707
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([319, 291, 345, 308], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.07738181948661804
bi 1 loss 0.15585292875766754
bi 2 loss 0.07982438802719116
bi 3 loss 0.15034057199954987
Layer  4  loss:  0.1387949138879776 0.0 9.838196754455566
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([428, 293, 288, 303], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.09716198593378067
bi 1 loss 0.1681276261806488
bi 2 loss 0.0996798425912857
bi 3 loss 0.2139897346496582
Layer  5  loss:  0.117652028799057 0.0 7.720073223114014
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([319, 291, 185, 303], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.07637745141983032
bi 1 loss 0.15622586011886597
bi 2 loss 0.0775470957159996
bi 3 loss 0.17164595425128937
Layer  6  loss:  0.11362600326538086 0.0 6.292246341705322
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([229, 290, 288, 308], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.06406864523887634
bi 1 loss 0.14762760698795319
bi 2 loss 0.13765351474285126
bi 3 loss 0.11132169514894485
Epoch 0: :   3%|▎         | 15264/600000 [01:49<1:09:58, v_num=12, reduced_train_loss=0.629, global_step=15262.0, consumed_samples=61052.0, train_step_timing in s=0.299]Epoch 0: :   3%|▎         | 15264/600000 [01:49<1:09:58, v_num=12, reduced_train_loss=0.902, global_step=15263.0, consumed_samples=61056.0, train_step_timing in s=0.337]loss mask original None

First layer loss:  0.05824277549982071 torch.Size([561, 4]) 2.5469939708709717 0.0
Max loss timestep torch.Size([561, 4]) tensor([341, 456, 553, 308], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.061052121222019196
speech mask sum tensor(285, device='cuda:0') loss mask sum tensor(285, device='cuda:0')
bi 1 loss 0.048192884773015976
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
bi 2 loss 0.07162132114171982
speech mask sum tensor(476, device='cuda:0') loss mask sum tensor(476, device='cuda:0')
bi 3 loss 0.04433874785900116
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257022
Layer  0  loss:  0.07476905733346939 0.0 5.380797863006592
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([328, 264, 518, 271], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.05512088164687157
bi 1 loss 0.09145341068506241
bi 2 loss 0.0753258764743805
bi 3 loss 0.07249776273965836
Layer  1  loss:  0.0731717050075531 0.0 4.76997184753418
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([191, 360, 408,  99], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.04080791771411896
bi 1 loss 0.0829787477850914
bi 2 loss 0.09026831388473511
bi 3 loss 0.0639214962720871
Layer  2  loss:  0.06789252907037735 0.0 2.8877525329589844
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([106, 355, 397, 107], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.06291202455759048
bi 1 loss 0.06963812559843063
bi 2 loss 0.08704399317502975
bi 3 loss 0.03578311204910278
Layer  3  loss:  0.07513244450092316 0.0 5.178212642669678
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1020
Curr loss timestep torch.Size([561, 4]) tensor([328, 297, 408, 271], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.06085530295968056
bi 1 loss 0.07916548103094101
bi 2 loss 0.08580747991800308
bi 3 loss 0.06569593399763107
Layer  4  loss:  0.06768946349620819 0.0 4.2088236808776855
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([325, 354, 408, 194], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.06546208262443542
bi 1 loss 0.053515609353780746
bi 2 loss 0.081996388733387
bi 3 loss 0.06327411532402039
Layer  5  loss:  0.06810331344604492 0.0 4.879299640655518
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([327, 265, 366, 300], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.05236617475748062
bi 1 loss 0.06255073845386505
bi 2 loss 0.09508421272039413
bi 3 loss 0.04344438761472702
Layer  6  loss:  0.07496222108602524 0.0 4.856614589691162
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([327, 264, 540, 283], device='cuda:0') tensor(540, device='cuda:0')
bi 0 loss 0.05486005172133446
bi 1 loss 0.055030275136232376
bi 2 loss 0.10619309544563293
bi 3 loss 0.0670049637556076
Epoch 0: :   3%|▎         | 15265/600000 [01:50<1:10:15, v_num=12, reduced_train_loss=0.902, global_step=15263.0, consumed_samples=61056.0, train_step_timing in s=0.337]Epoch 0: :   3%|▎         | 15265/600000 [01:50<1:10:15, v_num=12, reduced_train_loss=0.560, global_step=15264.0, consumed_samples=61060.0, train_step_timing in s=0.399]loss mask original None

First layer loss:  0.07716361433267593 torch.Size([726, 4]) 7.572546482086182 0.0
Max loss timestep torch.Size([726, 4]) tensor([280, 154,  82, 562], device='cuda:0') tensor(82, device='cuda:0')
bi 0 loss 0.017055772244930267
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 1 loss 0.03624508157372475
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 2 loss 0.08624712377786636
speech mask sum tensor(258, device='cuda:0') loss mask sum tensor(258, device='cuda:0')
bi 3 loss 0.0914318710565567
speech mask sum tensor(478, device='cuda:0') loss mask sum tensor(478, device='cuda:0')
logits torch.Size([726, 4, 257024]) labels torch.Size([726, 4]) 0 257022
Layer  0  loss:  0.0720190703868866 0.0 7.338589668273926
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1023
Curr loss timestep torch.Size([726, 4]) tensor([262, 134, 300, 562], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.03768651559948921
bi 1 loss 0.024374399334192276
bi 2 loss 0.07070772349834442
bi 3 loss 0.09012607485055923
Layer  1  loss:  0.07207393646240234 0.0 8.211590766906738
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1023
Curr loss timestep torch.Size([726, 4]) tensor([246,  74, 299, 495], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.026224317029118538
bi 1 loss 0.03779303655028343
bi 2 loss 0.09416872262954712
bi 3 loss 0.07558709383010864
Layer  2  loss:  0.09578502178192139 0.0 10.876062393188477
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1022
Curr loss timestep torch.Size([726, 4]) tensor([253, 155, 300, 526], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.022833192721009254
bi 1 loss 0.04949195683002472
bi 2 loss 0.10581442713737488
bi 3 loss 0.11274414509534836
Layer  3  loss:  0.06807184219360352 0.0 6.040480136871338
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1018
Curr loss timestep torch.Size([726, 4]) tensor([251, 127, 301, 562], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.053729381412267685
bi 1 loss 0.018392059952020645
bi 2 loss 0.07490921020507812
bi 3 loss 0.07956115901470184
Layer  4  loss:  0.06933503597974777 0.0 6.465432643890381
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1022
Curr loss timestep torch.Size([726, 4]) tensor([271,  77, 299, 527], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.031657587736845016
bi 1 loss 0.036284394562244415
bi 2 loss 0.07001577317714691
bi 3 loss 0.0829511508345604
Layer  5  loss:  0.08300908654928207 0.0 8.396308898925781
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1022
Curr loss timestep torch.Size([726, 4]) tensor([280, 151, 300, 526], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.04145082086324692
bi 1 loss 0.030015315860509872
bi 2 loss 0.06777811795473099
bi 3 loss 0.11104809492826462
Layer  6  loss:  0.09314326196908951 0.0 13.12899112701416
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1019
Curr loss timestep torch.Size([726, 4]) tensor([260, 106, 300, 526], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.034554313868284225
bi 1 loss 0.038426950573921204
bi 2 loss 0.10040535777807236
bi 3 loss 0.11185082793235779
Epoch 0: :   3%|▎         | 15266/600000 [01:50<1:10:35, v_num=12, reduced_train_loss=0.560, global_step=15264.0, consumed_samples=61060.0, train_step_timing in s=0.399]Epoch 0: :   3%|▎         | 15266/600000 [01:50<1:10:35, v_num=12, reduced_train_loss=0.631, global_step=15265.0, consumed_samples=61064.0, train_step_timing in s=0.497]loss mask original None

First layer loss:  3.796818256378174 torch.Size([436, 4]) 10.47362232208252 0.0
Max loss timestep torch.Size([436, 4]) tensor([369, 259, 239,  52], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 3.7117786407470703
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 1 loss 4.026797294616699
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
bi 2 loss 3.876628875732422
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
bi 3 loss 3.481590986251831
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
logits torch.Size([436, 4, 257024]) labels torch.Size([436, 4]) 0 257023
Layer  0  loss:  4.292515277862549 0.0 9.718466758728027
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([416, 364, 254, 142], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 4.237873077392578
bi 1 loss 4.3703932762146
bi 2 loss 4.481454372406006
bi 3 loss 4.066036701202393
Layer  1  loss:  4.593512535095215 0.0 9.859195709228516
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([390, 358, 243, 103], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 4.764989376068115
bi 1 loss 4.650596618652344
bi 2 loss 4.646517753601074
bi 3 loss 4.302516937255859
Layer  2  loss:  4.918018341064453 0.0 10.560230255126953
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([325, 295, 289,  75], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 4.938766956329346
bi 1 loss 5.216768741607666
bi 2 loss 4.854493141174316
bi 3 loss 4.532756805419922
Layer  3  loss:  5.109358310699463 0.0 10.552846908569336
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([342, 279, 251,  73], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 5.2616071701049805
bi 1 loss 5.348931312561035
bi 2 loss 4.918432235717773
bi 3 loss 4.796201705932617
Layer  4  loss:  5.140042781829834 0.0 11.1439847946167
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([292, 248, 267,  63], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 5.393726825714111
bi 1 loss 5.4203314781188965
bi 2 loss 4.937453269958496
bi 3 loss 4.683274745941162
Layer  5  loss:  5.237138748168945 0.0 9.951854705810547
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([425, 367, 314,  35], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 5.440880298614502
bi 1 loss 5.603711128234863
bi 2 loss 5.039448261260986
bi 3 loss 4.701581954956055
Layer  6  loss:  5.421957492828369 0.0 9.85122299194336
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([289, 185, 223, 178], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 5.518105983734131
bi 1 loss 5.605240345001221
bi 2 loss 5.332115173339844
bi 3 loss 5.151602745056152
Epoch 0: :   3%|▎         | 15267/600000 [01:50<1:10:48, v_num=12, reduced_train_loss=0.631, global_step=15265.0, consumed_samples=61064.0, train_step_timing in s=0.497]Epoch 0: :   3%|▎         | 15267/600000 [01:50<1:10:48, v_num=12, reduced_train_loss=38.50, global_step=15266.0, consumed_samples=61068.0, train_step_timing in s=0.305]loss mask original None

First layer loss:  0.16362258791923523 torch.Size([701, 4]) 9.519332885742188 0.0
Max loss timestep torch.Size([701, 4]) tensor([329, 135, 259, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.06507547199726105
speech mask sum tensor(174, device='cuda:0') loss mask sum tensor(174, device='cuda:0')
bi 1 loss 0.07242429256439209
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
bi 2 loss 0.03646694868803024
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 3 loss 0.26095837354660034
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
logits torch.Size([701, 4, 257024]) labels torch.Size([701, 4]) 0 257023
Layer  0  loss:  0.2362552434206009 0.0 15.359914779663086
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1023
Curr loss timestep torch.Size([701, 4]) tensor([320,  56, 265, 573], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.10298336297273636
bi 1 loss 0.07679907977581024
bi 2 loss 0.1731628030538559
bi 3 loss 0.3585023283958435
Layer  1  loss:  0.23519626259803772 0.0 13.445905685424805
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1022
Curr loss timestep torch.Size([701, 4]) tensor([257, 166, 259, 316], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.06968975067138672
bi 1 loss 0.06109293922781944
bi 2 loss 0.17117372155189514
bi 3 loss 0.3759017586708069
Layer  2  loss:  0.29389676451683044 0.0 15.174293518066406
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1022
Curr loss timestep torch.Size([701, 4]) tensor([326,  67, 259, 316], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.1188262403011322
bi 1 loss 0.06594139337539673
bi 2 loss 0.22655145823955536
bi 3 loss 0.45773667097091675
Layer  3  loss:  0.29512444138526917 0.0 15.27486515045166
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1023
Curr loss timestep torch.Size([701, 4]) tensor([326,  77, 259, 656], device='cuda:0') tensor(656, device='cuda:0')
bi 0 loss 0.15659774839878082
bi 1 loss 0.04803852736949921
bi 2 loss 0.226003035902977
bi 3 loss 0.4509109556674957
Layer  4  loss:  0.25163087248802185 0.0 16.00566291809082
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1023
Curr loss timestep torch.Size([701, 4]) tensor([341,  55, 286, 656], device='cuda:0') tensor(656, device='cuda:0')
bi 0 loss 0.14606745541095734
bi 1 loss 0.0855853483080864
bi 2 loss 0.19990068674087524
bi 3 loss 0.3624982237815857
Layer  5  loss:  0.28158336877822876 0.0 14.20885181427002
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1022
Curr loss timestep torch.Size([701, 4]) tensor([258, 174, 282, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.07701501250267029
bi 1 loss 0.052982404828071594
bi 2 loss 0.15455369651317596
bi 3 loss 0.46971577405929565
Layer  6  loss:  0.2683483958244324 0.0 12.171330451965332
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1023
Curr loss timestep torch.Size([701, 4]) tensor([278,  74, 282, 573], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.09257557988166809
bi 1 loss 0.03748185187578201
bi 2 loss 0.09375967085361481
bi 3 loss 0.4549781382083893
Epoch 0: :   3%|▎         | 15268/600000 [01:51<1:11:07, v_num=12, reduced_train_loss=38.50, global_step=15266.0, consumed_samples=61068.0, train_step_timing in s=0.305]Epoch 0: :   3%|▎         | 15268/600000 [01:51<1:11:07, v_num=12, reduced_train_loss=2.030, global_step=15267.0, consumed_samples=61072.0, train_step_timing in s=0.480]loss mask original None

First layer loss:  0.12428468465805054 torch.Size([498, 4]) 11.688632011413574 0.0
Max loss timestep torch.Size([498, 4]) tensor([237, 419, 412, 368], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.019048789516091347
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
bi 1 loss 0.06601367890834808
speech mask sum tensor(347, device='cuda:0') loss mask sum tensor(347, device='cuda:0')
bi 2 loss 0.1514437049627304
speech mask sum tensor(295, device='cuda:0') loss mask sum tensor(295, device='cuda:0')
bi 3 loss 0.18423159420490265
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
logits torch.Size([498, 4, 257024]) labels torch.Size([498, 4]) 0 257023
Layer  0  loss:  0.12545500695705414 0.0 10.97856616973877
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([211, 429, 412, 369], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.02779276669025421
bi 1 loss 0.08192938566207886
bi 2 loss 0.11891991645097733
bi 3 loss 0.19913101196289062
Layer  1  loss:  0.13791416585445404 0.0 10.750321388244629
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1022
Curr loss timestep torch.Size([498, 4]) tensor([209, 466, 412, 297], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.033783793449401855
bi 1 loss 0.08049388974905014
bi 2 loss 0.1333610862493515
bi 3 loss 0.22630766034126282
Layer  2  loss:  0.15533170104026794 0.0 17.52361297607422
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1022
Curr loss timestep torch.Size([498, 4]) tensor([226, 468, 410, 368], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.07676108181476593
bi 1 loss 0.06869059056043625
bi 2 loss 0.17940819263458252
bi 3 loss 0.24390894174575806
Layer  3  loss:  0.15665987133979797 0.0 14.094461441040039
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1022
Curr loss timestep torch.Size([498, 4]) tensor([238, 420, 412, 368], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.07166457921266556
bi 1 loss 0.10609086602926254
bi 2 loss 0.13228893280029297
bi 3 loss 0.2521553635597229
Layer  4  loss:  0.12805971503257751 0.0 8.437918663024902
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1022
Curr loss timestep torch.Size([498, 4]) tensor([227, 466, 412, 369], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.05683980882167816
bi 1 loss 0.0761203020811081
bi 2 loss 0.13868845999240875
bi 3 loss 0.18959634006023407
Layer  5  loss:  0.15392500162124634 0.0 10.781991958618164
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([244, 466, 410, 295], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.048364099115133286
bi 1 loss 0.08557293564081192
bi 2 loss 0.14147859811782837
bi 3 loss 0.26198118925094604
Layer  6  loss:  0.15854711830615997 0.0 17.750049591064453
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([223, 466, 410, 297], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.011198845691978931
bi 1 loss 0.08112763613462448
bi 2 loss 0.16777296364307404
bi 3 loss 0.26479148864746094
Epoch 0: :   3%|▎         | 15269/600000 [01:51<1:11:22, v_num=12, reduced_train_loss=2.030, global_step=15267.0, consumed_samples=61072.0, train_step_timing in s=0.480]Epoch 0: :   3%|▎         | 15269/600000 [01:51<1:11:22, v_num=12, reduced_train_loss=1.140, global_step=15268.0, consumed_samples=61076.0, train_step_timing in s=0.350]loss mask original None

First layer loss:  0.055494945496320724 torch.Size([498, 4]) 10.914237976074219 0.0
Max loss timestep torch.Size([498, 4]) tensor([ 95, 301, 260, 275], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.013618748635053635
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 1 loss 0.08621705323457718
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
bi 2 loss 0.025206828489899635
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 3 loss 0.05586763471364975
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([498, 4, 257024]) labels torch.Size([498, 4]) 0 257022
Layer  0  loss:  0.04717012122273445 0.0 2.6953141689300537
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([ 59, 272, 245, 223], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.03269841521978378
bi 1 loss 0.06904026865959167
bi 2 loss 0.025841079652309418
bi 3 loss 0.02816714532673359
Layer  1  loss:  0.040835797786712646 0.0 1.509081244468689
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1022
Curr loss timestep torch.Size([498, 4]) tensor([ 86, 399, 184, 285], device='cuda:0') tensor(399, device='cuda:0')
bi 0 loss 0.021637925878167152
bi 1 loss 0.05454353615641594
bi 2 loss 0.028751350939273834
bi 3 loss 0.039160218089818954
Layer  2  loss:  0.05485856160521507 0.0 3.9465465545654297
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([ 52, 424, 242, 279], device='cuda:0') tensor(424, device='cuda:0')
bi 0 loss 0.033056166023015976
bi 1 loss 0.07906563580036163
bi 2 loss 0.030814876779913902
bi 3 loss 0.04169325530529022
Layer  3  loss:  0.04460269585251808 0.0 2.115664005279541
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([ 54, 424, 220, 265], device='cuda:0') tensor(424, device='cuda:0')
bi 0 loss 0.03865501284599304
bi 1 loss 0.047453686594963074
bi 2 loss 0.03681217133998871
bi 3 loss 0.05578809604048729
Layer  4  loss:  0.04891340062022209 0.0 3.1584463119506836
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1022
Curr loss timestep torch.Size([498, 4]) tensor([ 63, 424, 260, 246], device='cuda:0') tensor(424, device='cuda:0')
bi 0 loss 0.030232490971684456
bi 1 loss 0.06757195293903351
bi 2 loss 0.029908236116170883
bi 3 loss 0.041890550404787064
Layer  5  loss:  0.04379325360059738 0.0 1.417847752571106
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([115, 265, 251, 285], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.01820896752178669
bi 1 loss 0.06816724687814713
bi 2 loss 0.02331109158694744
bi 3 loss 0.0285557322204113
Layer  6  loss:  0.047284480184316635 0.0 2.3121285438537598
logits torch.Size([498, 4, 1024]) labels torch.Size([498, 4]) 0 1023
Curr loss timestep torch.Size([498, 4]) tensor([101, 277, 247, 276], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.023930829018354416
bi 1 loss 0.06615574657917023
bi 2 loss 0.03161675110459328
bi 3 loss 0.039518460631370544
Epoch 0: :   3%|▎         | 15270/600000 [01:52<1:11:36, v_num=12, reduced_train_loss=1.140, global_step=15268.0, consumed_samples=61076.0, train_step_timing in s=0.350]Epoch 0: :   3%|▎         | 15270/600000 [01:52<1:11:36, v_num=12, reduced_train_loss=0.383, global_step=15269.0, consumed_samples=61080.0, train_step_timing in s=0.348]loss mask original None

First layer loss:  0.05360184237360954 torch.Size([401, 4]) 11.215062141418457 0.0
Max loss timestep torch.Size([401, 4]) tensor([107,  85, 329, 192], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.03507126122713089
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
bi 1 loss 0.025286082178354263
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 2 loss 0.08769910037517548
speech mask sum tensor(332, device='cuda:0') loss mask sum tensor(332, device='cuda:0')
bi 3 loss 0.019328534603118896
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
logits torch.Size([401, 4, 257024]) labels torch.Size([401, 4]) 0 257023
Layer  0  loss:  0.05405215546488762 0.0 11.174327850341797
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1023
Curr loss timestep torch.Size([401, 4]) tensor([206,  69, 329, 263], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.02136453241109848
bi 1 loss 0.020946918055415154
bi 2 loss 0.09753253310918808
bi 3 loss 0.01789012923836708
Layer  1  loss:  0.058002498000860214 0.0 9.045869827270508
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1022
Curr loss timestep torch.Size([401, 4]) tensor([226, 169, 329, 267], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.031990207731723785
bi 1 loss 0.03118639811873436
bi 2 loss 0.0952666625380516
bi 3 loss 0.02293536067008972
Layer  2  loss:  0.06968002766370773 0.0 13.673887252807617
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1022
Curr loss timestep torch.Size([401, 4]) tensor([189, 119, 329, 260], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.020268823951482773
bi 1 loss 0.031410712748765945
bi 2 loss 0.12951108813285828
bi 3 loss 0.017301522195339203
Layer  3  loss:  0.06294474005699158 0.0 9.399459838867188
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1023
Curr loss timestep torch.Size([401, 4]) tensor([144, 172, 327, 234], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.020201560109853745
bi 1 loss 0.02350635640323162
bi 2 loss 0.11945230513811111
bi 3 loss 0.012371677905321121
Layer  4  loss:  0.06639739125967026 0.0 15.71474838256836
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1023
Curr loss timestep torch.Size([401, 4]) tensor([167,  67, 329, 212], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.015879135578870773
bi 1 loss 0.023458637297153473
bi 2 loss 0.1292876899242401
bi 3 loss 0.012590622529387474
Layer  5  loss:  0.055518243461847305 0.0 12.004021644592285
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1022
Curr loss timestep torch.Size([401, 4]) tensor([100,  64, 329, 227], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.01764947921037674
bi 1 loss 0.018502071499824524
bi 2 loss 0.10596983134746552
bi 3 loss 0.011972160078585148
Layer  6  loss:  0.06911833584308624 0.0 11.876566886901855
logits torch.Size([401, 4, 1024]) labels torch.Size([401, 4]) 0 1021
Curr loss timestep torch.Size([401, 4]) tensor([212,  89, 329, 213], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.030566461384296417
bi 1 loss 0.026154261082410812
bi 2 loss 0.12297388911247253
bi 3 loss 0.024144750088453293
Epoch 0: :   3%|▎         | 15271/600000 [01:52<1:11:49, v_num=12, reduced_train_loss=0.383, global_step=15269.0, consumed_samples=61080.0, train_step_timing in s=0.348]Epoch 0: :   3%|▎         | 15271/600000 [01:52<1:11:49, v_num=12, reduced_train_loss=0.489, global_step=15270.0, consumed_samples=61084.0, train_step_timing in s=0.300]loss mask original None

First layer loss:  0.08581902086734772 torch.Size([509, 4]) 4.356523513793945 0.0
Max loss timestep torch.Size([509, 4]) tensor([229, 227, 265, 293], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 0.0503760501742363
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 1 loss 0.12061561644077301
speech mask sum tensor(379, device='cuda:0') loss mask sum tensor(379, device='cuda:0')
bi 2 loss 0.03744746744632721
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 3 loss 0.08135288953781128
speech mask sum tensor(233, device='cuda:0') loss mask sum tensor(233, device='cuda:0')
logits torch.Size([509, 4, 257024]) labels torch.Size([509, 4]) 0 257022
Layer  0  loss:  0.08028638362884521 0.0 4.885921955108643
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([193, 327, 200, 290], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.03843162953853607
bi 1 loss 0.09665639698505402
bi 2 loss 0.02671060524880886
bi 3 loss 0.11277394741773605
Layer  1  loss:  0.08113205432891846 0.0 9.410576820373535
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([156, 350, 177, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.040181856602430344
bi 1 loss 0.06615814566612244
bi 2 loss 0.02474505454301834
bi 3 loss 0.16606895625591278
Layer  2  loss:  0.07617075741291046 0.0 6.438514232635498
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([224, 340, 161, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.029618030413985252
bi 1 loss 0.0827292874455452
bi 2 loss 0.03587447479367256
bi 3 loss 0.1179218515753746
Layer  3  loss:  0.07865535467863083 0.0 7.257889270782471
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([178, 303, 265, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.034235626459121704
bi 1 loss 0.0685722604393959
bi 2 loss 0.02803724631667137
bi 3 loss 0.1534820795059204
Layer  4  loss:  0.06856946647167206 0.0 4.334396839141846
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([241, 451, 265, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.03292839601635933
bi 1 loss 0.07907214015722275
bi 2 loss 0.04571299999952316
bi 3 loss 0.08609405159950256
Layer  5  loss:  0.08375680446624756 0.0 7.730051517486572
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([161, 219, 157, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.04167930781841278
bi 1 loss 0.0857328549027443
bi 2 loss 0.03735233098268509
bi 3 loss 0.13481998443603516
Layer  6  loss:  0.08837296813726425 0.0 4.762089729309082
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([183, 407, 265, 291], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.03791666403412819
bi 1 loss 0.11945303529500961
bi 2 loss 0.027986949309706688
bi 3 loss 0.10617954283952713
Epoch 0: :   3%|▎         | 15272/600000 [01:52<1:12:03, v_num=12, reduced_train_loss=0.489, global_step=15270.0, consumed_samples=61084.0, train_step_timing in s=0.300]Epoch 0: :   3%|▎         | 15272/600000 [01:52<1:12:03, v_num=12, reduced_train_loss=0.643, global_step=15271.0, consumed_samples=61088.0, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.016531718894839287 torch.Size([306, 4]) 0.25949928164482117 0.0
Max loss timestep torch.Size([306, 4]) tensor([214, 264, 279, 115], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.02109469659626484
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 1 loss 0.01715579442679882
speech mask sum tensor(237, device='cuda:0') loss mask sum tensor(237, device='cuda:0')
bi 2 loss 0.01777549833059311
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 3 loss 0.008962164632976055
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
logits torch.Size([306, 4, 257024]) labels torch.Size([306, 4]) 0 257022
Layer  0  loss:  0.0281883105635643 0.0 3.2377820014953613
logits torch.Size([306, 4, 1024]) labels torch.Size([306, 4]) 0 1023
Curr loss timestep torch.Size([306, 4]) tensor([166, 284, 272, 176], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.023355217650532722
bi 1 loss 0.0428781621158123
bi 2 loss 0.028761349618434906
bi 3 loss 0.011235838755965233
Layer  1  loss:  0.029659248888492584 0.0 7.8147873878479
logits torch.Size([306, 4, 1024]) labels torch.Size([306, 4]) 0 1021
Curr loss timestep torch.Size([306, 4]) tensor([ 70, 285, 253, 166], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.019622724503278732
bi 1 loss 0.052810922265052795
bi 2 loss 0.018892517313361168
bi 3 loss 0.011539986357092857
Layer  2  loss:  0.02600380778312683 0.0 4.23488712310791
logits torch.Size([306, 4, 1024]) labels torch.Size([306, 4]) 0 1022
Curr loss timestep torch.Size([306, 4]) tensor([180, 285, 259, 149], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.016287822276353836
bi 1 loss 0.04253023862838745
bi 2 loss 0.029513375833630562
bi 3 loss 0.011242528446018696
Layer  3  loss:  0.028551150113344193 0.0 9.439845085144043
logits torch.Size([306, 4, 1024]) labels torch.Size([306, 4]) 0 1017
Curr loss timestep torch.Size([306, 4]) tensor([108, 285, 278, 145], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.01596912369132042
bi 1 loss 0.05436447262763977
bi 2 loss 0.02517017349600792
bi 3 loss 0.006185159552842379
Layer  4  loss:  0.022886164486408234 0.0 5.461005210876465
logits torch.Size([306, 4, 1024]) labels torch.Size([306, 4]) 0 1022
Curr loss timestep torch.Size([306, 4]) tensor([173, 285, 249,  98], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.014618626795709133
bi 1 loss 0.03879423439502716
bi 2 loss 0.017914200201630592
bi 3 loss 0.011118381284177303
Layer  5  loss:  0.033452559262514114 0.0 10.81688117980957
logits torch.Size([306, 4, 1024]) labels torch.Size([306, 4]) 0 1023
Curr loss timestep torch.Size([306, 4]) tensor([129, 285, 266, 118], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.016182107850909233
bi 1 loss 0.06743638962507248
bi 2 loss 0.020841360092163086
bi 3 loss 0.008720346726477146
Layer  6  loss:  0.03672259673476219 0.0 11.985074043273926
logits torch.Size([306, 4, 1024]) labels torch.Size([306, 4]) 0 1021
Curr loss timestep torch.Size([306, 4]) tensor([134, 285, 266,  96], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.015319193713366985
bi 1 loss 0.07469919323921204
bi 2 loss 0.031379569321870804
bi 3 loss 0.007800980005413294
Epoch 0: :   3%|▎         | 15273/600000 [01:53<1:12:14, v_num=12, reduced_train_loss=0.643, global_step=15271.0, consumed_samples=61088.0, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15273/600000 [01:53<1:12:14, v_num=12, reduced_train_loss=0.222, global_step=15272.0, consumed_samples=61092.0, train_step_timing in s=0.253]loss mask original None

First layer loss:  0.09229838103055954 torch.Size([501, 4]) 7.942042827606201 0.0
Max loss timestep torch.Size([501, 4]) tensor([111, 321, 163, 324], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.07365143299102783
speech mask sum tensor(327, device='cuda:0') loss mask sum tensor(327, device='cuda:0')
bi 1 loss 0.08792953938245773
speech mask sum tensor(359, device='cuda:0') loss mask sum tensor(359, device='cuda:0')
bi 2 loss 0.01703367568552494
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 3 loss 0.13217489421367645
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
logits torch.Size([501, 4, 257024]) labels torch.Size([501, 4]) 0 257023
Layer  0  loss:  0.07332080602645874 0.0 9.661765098571777
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1023
Curr loss timestep torch.Size([501, 4]) tensor([316, 321, 112, 483], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.039781685918569565
bi 1 loss 0.10206744074821472
bi 2 loss 0.012592541053891182
bi 3 loss 0.09028105437755585
Layer  1  loss:  0.07840164750814438 0.0 7.553717136383057
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1022
Curr loss timestep torch.Size([501, 4]) tensor([168, 321, 141, 359], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.06028853729367256
bi 1 loss 0.0769805833697319
bi 2 loss 0.025951771065592766
bi 3 loss 0.10918759554624557
Layer  2  loss:  0.0960996076464653 0.0 9.423004150390625
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1022
Curr loss timestep torch.Size([501, 4]) tensor([372, 321, 136, 307], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.06268548220396042
bi 1 loss 0.13115479052066803
bi 2 loss 0.07469229400157928
bi 3 loss 0.09689540416002274
Layer  3  loss:  0.08487295359373093 0.0 7.938041687011719
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1020
Curr loss timestep torch.Size([501, 4]) tensor([366, 435, 144, 307], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.04721519723534584
bi 1 loss 0.11588504910469055
bi 2 loss 0.026646247133612633
bi 3 loss 0.10267342627048492
Layer  4  loss:  0.10659586638212204 0.0 10.659276962280273
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1022
Curr loss timestep torch.Size([501, 4]) tensor([304, 320, 125, 307], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.07989825308322906
bi 1 loss 0.14044606685638428
bi 2 loss 0.029974086210131645
bi 3 loss 0.11634994298219681
Layer  5  loss:  0.103247731924057 0.0 11.941972732543945
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1023
Curr loss timestep torch.Size([501, 4]) tensor([306, 320, 126, 294], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.09136097133159637
bi 1 loss 0.12403510510921478
bi 2 loss 0.044763438403606415
bi 3 loss 0.10804548114538193
Layer  6  loss:  0.08758078515529633 0.0 8.375683784484863
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1022
Curr loss timestep torch.Size([501, 4]) tensor([307, 320, 127, 311], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.08567305654287338
bi 1 loss 0.12114738672971725
bi 2 loss 0.014447811990976334
bi 3 loss 0.0744723305106163
Epoch 0: :   3%|▎         | 15274/600000 [01:53<1:12:29, v_num=12, reduced_train_loss=0.222, global_step=15272.0, consumed_samples=61092.0, train_step_timing in s=0.253]Epoch 0: :   3%|▎         | 15274/600000 [01:53<1:12:29, v_num=12, reduced_train_loss=0.722, global_step=15273.0, consumed_samples=61096.0, train_step_timing in s=0.362]loss mask original None

First layer loss:  3.633894443511963 torch.Size([372, 4]) 10.055109024047852 0.0
Max loss timestep torch.Size([372, 4]) tensor([332,  36, 120, 361], device='cuda:0') tensor(120, device='cuda:0')
bi 0 loss 4.019713401794434
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 1 loss 3.11983060836792
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 2 loss 3.250990390777588
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 3 loss 3.5814297199249268
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
logits torch.Size([372, 4, 257024]) labels torch.Size([372, 4]) 0 257020
Layer  0  loss:  4.320991516113281 0.0 9.812372207641602
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1023
Curr loss timestep torch.Size([372, 4]) tensor([248,  96, 160, 224], device='cuda:0') tensor(124, device='cuda:0')
bi 0 loss 4.536159038543701
bi 1 loss 4.034148693084717
bi 2 loss 3.861295461654663
bi 3 loss 4.374157428741455
Layer  1  loss:  4.479464530944824 0.0 10.407546043395996
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1022
Curr loss timestep torch.Size([372, 4]) tensor([252,  66, 154, 120], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 4.681070804595947
bi 1 loss 4.061383247375488
bi 2 loss 4.099408149719238
bi 3 loss 4.571939468383789
Layer  2  loss:  4.841096878051758 0.0 10.65828800201416
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1022
Curr loss timestep torch.Size([372, 4]) tensor([352,  76, 137, 208], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 4.903654098510742
bi 1 loss 4.5518646240234375
bi 2 loss 4.43184232711792
bi 3 loss 5.03095006942749
Layer  3  loss:  4.799462795257568 0.0 10.923361778259277
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1022
Curr loss timestep torch.Size([372, 4]) tensor([322,  53, 133, 191], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 4.87249755859375
bi 1 loss 4.7896833419799805
bi 2 loss 4.16840934753418
bi 3 loss 4.941483497619629
Layer  4  loss:  4.981723308563232 0.0 10.023941993713379
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1022
Curr loss timestep torch.Size([372, 4]) tensor([257, 111,  96, 280], device='cuda:0') tensor(128, device='cuda:0')
bi 0 loss 5.116354465484619
bi 1 loss 4.965455055236816
bi 2 loss 4.337648391723633
bi 3 loss 5.069094657897949
Layer  5  loss:  5.0106987953186035 0.0 9.391252517700195
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1022
Curr loss timestep torch.Size([372, 4]) tensor([324,  72, 141, 312], device='cuda:0') tensor(130, device='cuda:0')
bi 0 loss 5.12615966796875
bi 1 loss 5.049763202667236
bi 2 loss 4.4361042976379395
bi 3 loss 5.071900844573975
Layer  6  loss:  5.112776756286621 0.0 10.099258422851562
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1023
Curr loss timestep torch.Size([372, 4]) tensor([321,  75,  92, 125], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 5.161095142364502
bi 1 loss 5.401314735412598
bi 2 loss 4.340150833129883
bi 3 loss 5.207782745361328
Epoch 0: :   3%|▎         | 15275/600000 [01:53<1:12:41, v_num=12, reduced_train_loss=0.722, global_step=15273.0, consumed_samples=61096.0, train_step_timing in s=0.362]Epoch 0: :   3%|▎         | 15275/600000 [01:53<1:12:41, v_num=12, reduced_train_loss=37.20, global_step=15274.0, consumed_samples=61100.0, train_step_timing in s=0.279]loss mask original None

First layer loss:  0.09179390221834183 torch.Size([418, 4]) 7.688348770141602 0.0
Max loss timestep torch.Size([418, 4]) tensor([383, 275, 173, 401], device='cuda:0') tensor(401, device='cuda:0')
bi 0 loss 0.07519751042127609
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 1 loss 0.030221201479434967
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 2 loss 0.03564530238509178
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
bi 3 loss 0.1674424260854721
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
logits torch.Size([418, 4, 257024]) labels torch.Size([418, 4]) 0 257023
Layer  0  loss:  0.09745145589113235 0.0 13.971384048461914
logits torch.Size([418, 4, 1024]) labels torch.Size([418, 4]) 0 1023
Curr loss timestep torch.Size([418, 4]) tensor([383, 276, 201, 304], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.09365814179182053
bi 1 loss 0.059517599642276764
bi 2 loss 0.017712710425257683
bi 3 loss 0.1505059003829956
Layer  1  loss:  0.09861043840646744 0.0 11.316553115844727
logits torch.Size([418, 4, 1024]) labels torch.Size([418, 4]) 0 1022
Curr loss timestep torch.Size([418, 4]) tensor([383, 296, 189, 304], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.11537118256092072
bi 1 loss 0.03902820125222206
bi 2 loss 0.012456000782549381
bi 3 loss 0.12058277428150177
Layer  2  loss:  0.10732371360063553 0.0 13.970365524291992
logits torch.Size([418, 4, 1024]) labels torch.Size([418, 4]) 0 1022
Curr loss timestep torch.Size([418, 4]) tensor([383, 299, 195, 304], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.0992049053311348
bi 1 loss 0.10419051349163055
bi 2 loss 0.025595448911190033
bi 3 loss 0.1589362472295761
Layer  3  loss:  0.10656458139419556 0.0 8.990163803100586
logits torch.Size([418, 4, 1024]) labels torch.Size([418, 4]) 0 1023
Curr loss timestep torch.Size([418, 4]) tensor([383, 293, 192, 283], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.10440218448638916
bi 1 loss 0.0556180477142334
bi 2 loss 0.03745037689805031
bi 3 loss 0.1559448391199112
Layer  4  loss:  0.1004989892244339 0.0 5.0424089431762695
logits torch.Size([418, 4, 1024]) labels torch.Size([418, 4]) 0 1022
Curr loss timestep torch.Size([418, 4]) tensor([383, 295, 216, 305], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.10715503990650177
bi 1 loss 0.05952756106853485
bi 2 loss 0.031840160489082336
bi 3 loss 0.12919887900352478
Layer  5  loss:  0.12459369748830795 0.0 9.693150520324707
logits torch.Size([418, 4, 1024]) labels torch.Size([418, 4]) 0 1022
Curr loss timestep torch.Size([418, 4]) tensor([382, 300, 173, 304], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 0.11851005256175995
bi 1 loss 0.07370202988386154
bi 2 loss 0.03677395358681679
bi 3 loss 0.1896146982908249
Layer  6  loss:  0.11170362681150436 0.0 15.442261695861816
logits torch.Size([418, 4, 1024]) labels torch.Size([418, 4]) 0 1019
Curr loss timestep torch.Size([418, 4]) tensor([383, 291, 173, 395], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.11517095565795898
bi 1 loss 0.059031885117292404
bi 2 loss 0.028574727475643158
bi 3 loss 0.15645794570446014
Epoch 0: :   3%|▎         | 15276/600000 [01:54<1:12:54, v_num=12, reduced_train_loss=37.20, global_step=15274.0, consumed_samples=61100.0, train_step_timing in s=0.279]Epoch 0: :   3%|▎         | 15276/600000 [01:54<1:12:54, v_num=12, reduced_train_loss=0.839, global_step=15275.0, consumed_samples=61104.0, train_step_timing in s=0.304]loss mask original None

First layer loss:  0.1656849980354309 torch.Size([602, 4]) 11.989090919494629 0.0
Max loss timestep torch.Size([602, 4]) tensor([ 70, 555, 260, 360], device='cuda:0') tensor(555, device='cuda:0')
bi 0 loss 0.03997405618429184
speech mask sum tensor(43, device='cuda:0') loss mask sum tensor(43, device='cuda:0')
bi 1 loss 0.18721100687980652
speech mask sum tensor(463, device='cuda:0') loss mask sum tensor(463, device='cuda:0')
bi 2 loss 0.03663476184010506
speech mask sum tensor(59, device='cuda:0') loss mask sum tensor(59, device='cuda:0')
bi 3 loss 0.1764349788427353
speech mask sum tensor(284, device='cuda:0') loss mask sum tensor(284, device='cuda:0')
logits torch.Size([602, 4, 257024]) labels torch.Size([602, 4]) 0 257022
Layer  0  loss:  0.1626894623041153 0.0 13.015669822692871
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1023
Curr loss timestep torch.Size([602, 4]) tensor([ 83, 555, 258, 369], device='cuda:0') tensor(555, device='cuda:0')
bi 0 loss 0.03712126985192299
bi 1 loss 0.22651347517967224
bi 2 loss 0.0648934543132782
bi 3 loss 0.09796715527772903
Layer  1  loss:  0.20174969732761383 0.0 12.577116012573242
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1021
Curr loss timestep torch.Size([602, 4]) tensor([ 76, 464, 258, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.02540295384824276
bi 1 loss 0.25416478514671326
bi 2 loss 0.07139281928539276
bi 3 loss 0.17007991671562195
Layer  2  loss:  0.21260413527488708 0.0 14.114251136779785
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1022
Curr loss timestep torch.Size([602, 4]) tensor([ 71, 556, 223, 418], device='cuda:0') tensor(556, device='cuda:0')
bi 0 loss 0.03003285638988018
bi 1 loss 0.24517762660980225
bi 2 loss 0.10396057367324829
bi 3 loss 0.20971329510211945
Layer  3  loss:  0.18683001399040222 0.0 15.400688171386719
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1021
Curr loss timestep torch.Size([602, 4]) tensor([ 71, 464, 253, 360], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.01754450611770153
bi 1 loss 0.2311827689409256
bi 2 loss 0.030476193875074387
bi 3 loss 0.1726357340812683
Layer  4  loss:  0.21723784506320953 0.0 12.612546920776367
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1022
Curr loss timestep torch.Size([602, 4]) tensor([ 89, 464, 260, 360], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.017603736370801926
bi 1 loss 0.30613499879837036
bi 2 loss 0.024099819362163544
bi 3 loss 0.14266042411327362
Layer  5  loss:  0.19154535233974457 0.0 15.706454277038574
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1023
Curr loss timestep torch.Size([602, 4]) tensor([ 70, 464, 230, 360], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.05360698699951172
bi 1 loss 0.25680476427078247
bi 2 loss 0.02599385380744934
bi 3 loss 0.14043185114860535
Layer  6  loss:  0.2387382984161377 0.0 11.127303123474121
logits torch.Size([602, 4, 1024]) labels torch.Size([602, 4]) 0 1019
Curr loss timestep torch.Size([602, 4]) tensor([ 70, 592, 258, 452], device='cuda:0') tensor(592, device='cuda:0')
bi 0 loss 0.036854952573776245
bi 1 loss 0.28212928771972656
bi 2 loss 0.058043044060468674
bi 3 loss 0.23610445857048035
Epoch 0: :   3%|▎         | 15277/600000 [01:54<1:13:11, v_num=12, reduced_train_loss=0.839, global_step=15275.0, consumed_samples=61104.0, train_step_timing in s=0.304]Epoch 0: :   3%|▎         | 15277/600000 [01:54<1:13:11, v_num=12, reduced_train_loss=1.580, global_step=15276.0, consumed_samples=61108.0, train_step_timing in s=0.413]loss mask original None

First layer loss:  0.12290304899215698 torch.Size([630, 4]) 10.231871604919434 0.0
Max loss timestep torch.Size([630, 4]) tensor([414, 363, 352, 199], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.22442670166492462
speech mask sum tensor(425, device='cuda:0') loss mask sum tensor(425, device='cuda:0')
bi 1 loss 0.10562602430582047
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
bi 2 loss 0.09797587990760803
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
bi 3 loss 0.03638113662600517
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
logits torch.Size([630, 4, 257024]) labels torch.Size([630, 4]) 0 257022
Layer  0  loss:  0.14842019975185394 0.0 11.122715950012207
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([415, 363, 265, 337], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.2578963041305542
bi 1 loss 0.1088954508304596
bi 2 loss 0.10297825187444687
bi 3 loss 0.07959416508674622
Layer  1  loss:  0.16595734655857086 0.0 13.660408973693848
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1022
Curr loss timestep torch.Size([630, 4]) tensor([528, 301, 265, 453], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 0.3110661506652832
bi 1 loss 0.10601972788572311
bi 2 loss 0.08859533816576004
bi 3 loss 0.09031058102846146
Layer  2  loss:  0.14726285636425018 0.0 11.10649585723877
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1022
Curr loss timestep torch.Size([630, 4]) tensor([445, 362, 294, 453], device='cuda:0') tensor(445, device='cuda:0')
bi 0 loss 0.2226393073797226
bi 1 loss 0.09032078087329865
bi 2 loss 0.08481661975383759
bi 3 loss 0.137765571475029
Layer  3  loss:  0.17020729184150696 0.0 14.204655647277832
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1022
Curr loss timestep torch.Size([630, 4]) tensor([445, 363, 265, 331], device='cuda:0') tensor(445, device='cuda:0')
bi 0 loss 0.2894953191280365
bi 1 loss 0.12115409970283508
bi 2 loss 0.06552261114120483
bi 3 loss 0.13445815443992615
Layer  4  loss:  0.18270651996135712 0.0 15.504541397094727
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1022
Curr loss timestep torch.Size([630, 4]) tensor([415, 299, 296, 469], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.3528863787651062
bi 1 loss 0.1071833074092865
bi 2 loss 0.08382738381624222
bi 3 loss 0.1023818776011467
Layer  5  loss:  0.19209711253643036 0.0 14.548778533935547
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([415, 365, 265, 331], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.32455116510391235
bi 1 loss 0.1402074098587036
bi 2 loss 0.09455835819244385
bi 3 loss 0.13877233862876892
Layer  6  loss:  0.18053728342056274 0.0 10.260116577148438
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([414, 363, 265, 337], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.3133819103240967
bi 1 loss 0.16868871450424194
bi 2 loss 0.08950768411159515
bi 3 loss 0.09867028146982193
Epoch 0: :   3%|▎         | 15278/600000 [01:55<1:13:28, v_num=12, reduced_train_loss=1.580, global_step=15276.0, consumed_samples=61108.0, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15278/600000 [01:55<1:13:28, v_num=12, reduced_train_loss=1.310, global_step=15277.0, consumed_samples=61112.0, train_step_timing in s=0.430]loss mask original None

First layer loss:  3.5468459129333496 torch.Size([312, 4]) 11.278244018554688 0.0
Max loss timestep torch.Size([312, 4]) tensor([131, 166,  60, 113], device='cuda:0') tensor(140, device='cuda:0')
bi 0 loss 3.454824686050415
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 1 loss 3.5300328731536865
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 2 loss 3.6793179512023926
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
bi 3 loss 3.5131566524505615
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
logits torch.Size([312, 4, 257024]) labels torch.Size([312, 4]) 0 257022
Layer  0  loss:  3.8747074604034424 0.0 10.19937515258789
logits torch.Size([312, 4, 1024]) labels torch.Size([312, 4]) 0 1023
Curr loss timestep torch.Size([312, 4]) tensor([131, 134, 157, 112], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 3.806309223175049
bi 1 loss 3.6740903854370117
bi 2 loss 4.300196170806885
bi 3 loss 3.8130393028259277
Layer  1  loss:  4.345865249633789 0.0 10.376923561096191
logits torch.Size([312, 4, 1024]) labels torch.Size([312, 4]) 0 1019
Curr loss timestep torch.Size([312, 4]) tensor([152, 277, 139, 167], device='cuda:0') tensor(130, device='cuda:0')
bi 0 loss 4.566277027130127
bi 1 loss 4.073302745819092
bi 2 loss 4.6487908363342285
bi 3 loss 4.286840438842773
Layer  2  loss:  4.578616142272949 0.0 10.119324684143066
logits torch.Size([312, 4, 1024]) labels torch.Size([312, 4]) 0 1022
Curr loss timestep torch.Size([312, 4]) tensor([ 87, 284,  71, 102], device='cuda:0') tensor(130, device='cuda:0')
bi 0 loss 4.822871685028076
bi 1 loss 4.462113380432129
bi 2 loss 4.690445899963379
bi 3 loss 4.4475417137146
Layer  3  loss:  4.687473297119141 0.0 9.196077346801758
logits torch.Size([312, 4, 1024]) labels torch.Size([312, 4]) 0 1023
Curr loss timestep torch.Size([312, 4]) tensor([145, 257, 133, 168], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 4.991584777832031
bi 1 loss 4.471731662750244
bi 2 loss 5.036674976348877
bi 3 loss 4.420688152313232
Layer  4  loss:  4.88815975189209 0.0 10.625577926635742
logits torch.Size([312, 4, 1024]) labels torch.Size([312, 4]) 0 1022
Curr loss timestep torch.Size([312, 4]) tensor([102, 199, 116, 110], device='cuda:0') tensor(117, device='cuda:0')
bi 0 loss 5.055104732513428
bi 1 loss 4.7321038246154785
bi 2 loss 5.13479471206665
bi 3 loss 4.745176792144775
Layer  5  loss:  4.856318473815918 0.0 10.588830947875977
logits torch.Size([312, 4, 1024]) labels torch.Size([312, 4]) 0 1023
Curr loss timestep torch.Size([312, 4]) tensor([152, 132, 160, 105], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 4.892297744750977
bi 1 loss 4.730410575866699
bi 2 loss 5.171528339385986
bi 3 loss 4.702686786651611
Layer  6  loss:  4.906047344207764 0.0 13.076377868652344
logits torch.Size([312, 4, 1024]) labels torch.Size([312, 4]) 0 1022
Curr loss timestep torch.Size([312, 4]) tensor([136, 116, 153, 118], device='cuda:0') tensor(116, device='cuda:0')
bi 0 loss 4.876040935516357
bi 1 loss 4.724857807159424
bi 2 loss 5.261181831359863
bi 3 loss 4.854152679443359
Epoch 0: :   3%|▎         | 15279/600000 [01:55<1:13:39, v_num=12, reduced_train_loss=1.310, global_step=15277.0, consumed_samples=61112.0, train_step_timing in s=0.430]Epoch 0: :   3%|▎         | 15279/600000 [01:55<1:13:39, v_num=12, reduced_train_loss=35.70, global_step=15278.0, consumed_samples=61116.0, train_step_timing in s=0.261]loss mask original None

First layer loss:  0.010962514206767082 torch.Size([374, 4]) 0.0914638414978981 0.0
Max loss timestep torch.Size([374, 4]) tensor([127, 136,  99, 327], device='cuda:0') tensor(127, device='cuda:0')
bi 0 loss 0.015088568441569805
speech mask sum tensor(54, device='cuda:0') loss mask sum tensor(54, device='cuda:0')
bi 1 loss 0.00800733920186758
speech mask sum tensor(98, device='cuda:0') loss mask sum tensor(98, device='cuda:0')
bi 2 loss 0.009424102492630482
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.012664970010519028
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
logits torch.Size([374, 4, 257024]) labels torch.Size([374, 4]) 0 257022
Layer  0  loss:  0.009943712502717972 0.0 0.1089167445898056
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1023
Curr loss timestep torch.Size([374, 4]) tensor([122,  98, 104, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.01130556408315897
bi 1 loss 0.009241538122296333
bi 2 loss 0.009796375408768654
bi 3 loss 0.010034523904323578
Layer  1  loss:  0.010922315530478954 0.0 0.18760666251182556
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1022
Curr loss timestep torch.Size([374, 4]) tensor([120, 166, 173, 288], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 0.011480086483061314
bi 1 loss 0.012058691121637821
bi 2 loss 0.008332859724760056
bi 3 loss 0.012139043770730495
Layer  2  loss:  0.00964170042425394 0.0 0.15927405655384064
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1022
Curr loss timestep torch.Size([374, 4]) tensor([136, 161, 113, 274], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 0.01264887023717165
bi 1 loss 0.0063912332989275455
bi 2 loss 0.007731222547590733
bi 3 loss 0.012231240049004555
Layer  3  loss:  0.010413944721221924 0.0 0.17501425743103027
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1017
Curr loss timestep torch.Size([374, 4]) tensor([124, 102, 127, 337], device='cuda:0') tensor(124, device='cuda:0')
bi 0 loss 0.013881408609449863
bi 1 loss 0.007615057751536369
bi 2 loss 0.009460941888391972
bi 3 loss 0.011765108443796635
Layer  4  loss:  0.010477416217327118 0.0 0.10517719388008118
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1023
Curr loss timestep torch.Size([374, 4]) tensor([135, 154,  93, 249], device='cuda:0') tensor(124, device='cuda:0')
bi 0 loss 0.011919348500669003
bi 1 loss 0.005771338474005461
bi 2 loss 0.009785089641809464
bi 3 loss 0.01353752426803112
Layer  5  loss:  0.009808582253754139 0.0 0.0865018367767334
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1022
Curr loss timestep torch.Size([374, 4]) tensor([126, 168, 133, 339], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 0.012845511548221111
bi 1 loss 0.007084053009748459
bi 2 loss 0.009069627150893211
bi 3 loss 0.011086874641478062
Layer  6  loss:  0.010333211161196232 0.0 0.0965864434838295
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1021
Curr loss timestep torch.Size([374, 4]) tensor([125, 130, 172, 278], device='cuda:0') tensor(130, device='cuda:0')
bi 0 loss 0.013673413544893265
bi 1 loss 0.0077057224698364735
bi 2 loss 0.009793996810913086
bi 3 loss 0.011278684251010418
Epoch 0: :   3%|▎         | 15280/600000 [01:55<1:13:51, v_num=12, reduced_train_loss=35.70, global_step=15278.0, consumed_samples=61116.0, train_step_timing in s=0.261]Epoch 0: :   3%|▎         | 15280/600000 [01:55<1:13:51, v_num=12, reduced_train_loss=0.0825, global_step=15279.0, consumed_samples=61120.0, train_step_timing in s=0.285]loss mask original None

First layer loss:  3.766390562057495 torch.Size([780, 4]) 12.543517112731934 0.0
Max loss timestep torch.Size([780, 4]) tensor([128, 594, 233, 105], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 3.770462989807129
speech mask sum tensor(395, device='cuda:0') loss mask sum tensor(395, device='cuda:0')
bi 1 loss 3.9832229614257812
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
bi 2 loss 2.9968647956848145
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 3.719841480255127
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
logits torch.Size([780, 4, 257024]) labels torch.Size([780, 4]) 0 257023
Layer  0  loss:  4.304755687713623 0.0 10.298067092895508
logits torch.Size([780, 4, 1024]) labels torch.Size([780, 4]) 0 1023
Curr loss timestep torch.Size([780, 4]) tensor([170, 709, 262, 128], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.32086706161499
bi 1 loss 4.553538799285889
bi 2 loss 3.0158231258392334
bi 3 loss 4.6125335693359375
Layer  1  loss:  4.679454326629639 0.0 12.3876953125
logits torch.Size([780, 4, 1024]) labels torch.Size([780, 4]) 0 1023
Curr loss timestep torch.Size([780, 4]) tensor([154, 734, 272,  90], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.772683620452881
bi 1 loss 4.693549156188965
bi 2 loss 3.9320247173309326
bi 3 loss 5.0854339599609375
Layer  2  loss:  4.7845001220703125 0.0 10.684362411499023
logits torch.Size([780, 4, 1024]) labels torch.Size([780, 4]) 0 1022
Curr loss timestep torch.Size([780, 4]) tensor([214, 685, 178, 177], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 4.825388431549072
bi 1 loss 4.936798572540283
bi 2 loss 3.5911812782287598
bi 3 loss 5.2759246826171875
Layer  3  loss:  4.847220420837402 0.0 9.752514839172363
logits torch.Size([780, 4, 1024]) labels torch.Size([780, 4]) 0 1023
Curr loss timestep torch.Size([780, 4]) tensor([ 84, 515, 280, 114], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 5.102968215942383
bi 1 loss 4.932413101196289
bi 2 loss 3.576411485671997
bi 3 loss 5.0363593101501465
Layer  4  loss:  5.046345233917236 0.0 10.001076698303223
logits torch.Size([780, 4, 1024]) labels torch.Size([780, 4]) 0 1023
Curr loss timestep torch.Size([780, 4]) tensor([426, 464, 180, 103], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 5.347300052642822
bi 1 loss 4.938868045806885
bi 2 loss 4.121011257171631
bi 3 loss 5.464491367340088
Layer  5  loss:  5.106443405151367 0.0 10.547706604003906
logits torch.Size([780, 4, 1024]) labels torch.Size([780, 4]) 0 1021
Curr loss timestep torch.Size([780, 4]) tensor([280, 412, 204, 119], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 5.360197067260742
bi 1 loss 5.041318893432617
bi 2 loss 4.188238143920898
bi 3 loss 5.501043319702148
Layer  6  loss:  5.090898513793945 0.0 10.18157958984375
logits torch.Size([780, 4, 1024]) labels torch.Size([780, 4]) 0 1023
Curr loss timestep torch.Size([780, 4]) tensor([137, 588, 268, 107], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 5.309647083282471
bi 1 loss 5.073310852050781
bi 2 loss 4.149065971374512
bi 3 loss 5.437953948974609
Epoch 0: :   3%|▎         | 15281/600000 [01:56<1:14:10, v_num=12, reduced_train_loss=0.0825, global_step=15279.0, consumed_samples=61120.0, train_step_timing in s=0.285]Epoch 0: :   3%|▎         | 15281/600000 [01:56<1:14:10, v_num=12, reduced_train_loss=37.60, global_step=15280.0, consumed_samples=61124.0, train_step_timing in s=0.457] loss mask original None

First layer loss:  3.7491509914398193 torch.Size([468, 4]) 11.431221961975098 0.0
Max loss timestep torch.Size([468, 4]) tensor([284, 292, 139,  70], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 3.747244119644165
speech mask sum tensor(379, device='cuda:0') loss mask sum tensor(379, device='cuda:0')
bi 1 loss 3.9955203533172607
speech mask sum tensor(233, device='cuda:0') loss mask sum tensor(233, device='cuda:0')
bi 2 loss 3.604459762573242
speech mask sum tensor(219, device='cuda:0') loss mask sum tensor(219, device='cuda:0')
bi 3 loss 3.638556480407715
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
logits torch.Size([468, 4, 257024]) labels torch.Size([468, 4]) 0 257023
Layer  0  loss:  4.195603370666504 0.0 10.561527252197266
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([ 99, 275, 266, 227], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 4.058509349822998
bi 1 loss 4.424446105957031
bi 2 loss 3.8608474731445312
bi 3 loss 4.513968467712402
Layer  1  loss:  4.469130516052246 0.0 10.734703063964844
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([326, 417, 254,  69], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 4.488185882568359
bi 1 loss 4.6551923751831055
bi 2 loss 3.9464685916900635
bi 3 loss 4.751822471618652
Layer  2  loss:  4.825393199920654 0.0 11.317143440246582
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([161, 265, 208, 193], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 4.920485019683838
bi 1 loss 4.936941623687744
bi 2 loss 4.342291831970215
bi 3 loss 5.019059181213379
Layer  3  loss:  4.938977241516113 0.0 10.802223205566406
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([386, 345, 264, 225], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 5.049769401550293
bi 1 loss 5.112396240234375
bi 2 loss 4.342207908630371
bi 3 loss 5.152674198150635
Layer  4  loss:  5.028098106384277 0.0 9.774150848388672
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([274, 293, 202, 208], device='cuda:0') tensor(244, device='cuda:0')
bi 0 loss 5.195149898529053
bi 1 loss 5.2437005043029785
bi 2 loss 4.264861583709717
bi 3 loss 5.265269756317139
Layer  5  loss:  5.152544975280762 0.0 9.889484405517578
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([399, 248, 163, 168], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 5.412781238555908
bi 1 loss 5.174463272094727
bi 2 loss 4.488832473754883
bi 3 loss 5.336690425872803
Layer  6  loss:  5.114500999450684 0.0 10.333520889282227
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1019
Curr loss timestep torch.Size([468, 4]) tensor([108, 409, 240, 119], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 5.344687461853027
bi 1 loss 5.176358699798584
bi 2 loss 4.349730491638184
bi 3 loss 5.405787467956543
Epoch 0: :   3%|▎         | 15282/600000 [01:56<1:14:23, v_num=12, reduced_train_loss=37.60, global_step=15280.0, consumed_samples=61124.0, train_step_timing in s=0.457]Epoch 0: :   3%|▎         | 15282/600000 [01:56<1:14:23, v_num=12, reduced_train_loss=37.50, global_step=15281.0, consumed_samples=61128.0, train_step_timing in s=0.319]loss mask original None

First layer loss:  3.382885694503784 torch.Size([600, 4]) 11.726129531860352 0.0
Max loss timestep torch.Size([600, 4]) tensor([147, 353, 166, 311], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 3.562859296798706
speech mask sum tensor(503, device='cuda:0') loss mask sum tensor(503, device='cuda:0')
bi 1 loss 2.7777903079986572
speech mask sum tensor(481, device='cuda:0') loss mask sum tensor(481, device='cuda:0')
bi 2 loss 4.06195592880249
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 3 loss 3.495147705078125
speech mask sum tensor(401, device='cuda:0') loss mask sum tensor(401, device='cuda:0')
logits torch.Size([600, 4, 257024]) labels torch.Size([600, 4]) 0 257022
Layer  0  loss:  4.014927864074707 0.0 11.984546661376953
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([ 43, 236, 149, 367], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 4.290260314941406
bi 1 loss 3.367121458053589
bi 2 loss 4.590625286102295
bi 3 loss 4.117839813232422
Layer  1  loss:  4.295325756072998 0.0 9.912202835083008
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([490, 141, 229, 322], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 4.575255393981934
bi 1 loss 3.5787675380706787
bi 2 loss 5.03627347946167
bi 3 loss 4.3805694580078125
Layer  2  loss:  4.58349084854126 0.0 10.475048065185547
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([162, 376, 297, 209], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 4.934017181396484
bi 1 loss 3.836639881134033
bi 2 loss 5.163848400115967
bi 3 loss 4.708225250244141
Layer  3  loss:  4.668220043182373 0.0 10.282950401306152
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([256, 364, 234, 444], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.942609786987305
bi 1 loss 3.8801488876342773
bi 2 loss 5.415715217590332
bi 3 loss 4.842452049255371
Layer  4  loss:  4.825921535491943 0.0 10.608732223510742
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([384, 529, 264, 124], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 5.130644798278809
bi 1 loss 4.031847953796387
bi 2 loss 5.496922016143799
bi 3 loss 5.012989521026611
Layer  5  loss:  4.973878860473633 0.0 10.488061904907227
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([379, 202, 139, 239], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 5.385162830352783
bi 1 loss 4.140995979309082
bi 2 loss 5.570940971374512
bi 3 loss 5.11605978012085
Layer  6  loss:  4.984338283538818 0.0 11.478313446044922
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([537, 520, 195, 315], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 5.324925899505615
bi 1 loss 4.138480186462402
bi 2 loss 5.754804611206055
bi 3 loss 5.131732940673828
Epoch 0: :   3%|▎         | 15283/600000 [01:57<1:14:40, v_num=12, reduced_train_loss=37.50, global_step=15281.0, consumed_samples=61128.0, train_step_timing in s=0.319]Epoch 0: :   3%|▎         | 15283/600000 [01:57<1:14:40, v_num=12, reduced_train_loss=35.70, global_step=15282.0, consumed_samples=61132.0, train_step_timing in s=0.401]loss mask original None

First layer loss:  3.599005699157715 torch.Size([528, 4]) 9.939580917358398 0.0
Max loss timestep torch.Size([528, 4]) tensor([467, 156, 177, 370], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 3.9304561614990234
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
bi 1 loss 2.86421275138855
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 2 loss 3.367899179458618
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 3 loss 3.705253839492798
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([528, 4, 257024]) labels torch.Size([528, 4]) 0 257023
Layer  0  loss:  4.182171821594238 0.0 11.157456398010254
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([331,  80, 255, 351], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 4.482236862182617
bi 1 loss 3.893094062805176
bi 2 loss 3.633634090423584
bi 3 loss 4.407477855682373
Layer  1  loss:  4.471903324127197 0.0 9.495950698852539
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([205, 136, 105, 375], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 4.8495354652404785
bi 1 loss 4.040907859802246
bi 2 loss 3.8236145973205566
bi 3 loss 4.758697032928467
Layer  2  loss:  4.72853422164917 0.0 10.287302017211914
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([311,  90, 220, 398], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 5.205789566040039
bi 1 loss 4.199544906616211
bi 2 loss 4.225526809692383
bi 3 loss 4.6280059814453125
Layer  3  loss:  4.903101921081543 0.0 10.20865249633789
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1021
Curr loss timestep torch.Size([528, 4]) tensor([171, 159, 110, 445], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 5.325972557067871
bi 1 loss 4.513615608215332
bi 2 loss 4.184139728546143
bi 3 loss 5.127238750457764
Layer  4  loss:  5.08309268951416 0.0 11.339653015136719
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([477,  74, 157, 355], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 5.453079700469971
bi 1 loss 4.785276889801025
bi 2 loss 4.387881755828857
bi 3 loss 5.332787990570068
Layer  5  loss:  5.148487567901611 0.0 9.898112297058105
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([437,  97, 260, 453], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 5.487951755523682
bi 1 loss 4.9015398025512695
bi 2 loss 4.608429908752441
bi 3 loss 5.21437931060791
Layer  6  loss:  5.143261432647705 0.0 9.443544387817383
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1021
Curr loss timestep torch.Size([528, 4]) tensor([505, 157, 121, 466], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 5.5801215171813965
bi 1 loss 4.758172035217285
bi 2 loss 4.464774131774902
bi 3 loss 5.26757287979126
Epoch 0: :   3%|▎         | 15284/600000 [01:57<1:14:54, v_num=12, reduced_train_loss=35.70, global_step=15282.0, consumed_samples=61132.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15284/600000 [01:57<1:14:54, v_num=12, reduced_train_loss=37.30, global_step=15283.0, consumed_samples=61136.0, train_step_timing in s=0.341]loss mask original None

First layer loss:  0.04934260621666908 torch.Size([601, 4]) 5.444747447967529 0.0
Max loss timestep torch.Size([601, 4]) tensor([117, 517, 275, 256], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.032277196645736694
speech mask sum tensor(171, device='cuda:0') loss mask sum tensor(171, device='cuda:0')
bi 1 loss 0.09256605803966522
speech mask sum tensor(204, device='cuda:0') loss mask sum tensor(204, device='cuda:0')
bi 2 loss 0.04023641720414162
speech mask sum tensor(68, device='cuda:0') loss mask sum tensor(68, device='cuda:0')
bi 3 loss 0.0239571463316679
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
logits torch.Size([601, 4, 257024]) labels torch.Size([601, 4]) 0 257022
Layer  0  loss:  0.05191953480243683 0.0 3.1153693199157715
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([202, 517, 262, 128], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.029254907742142677
bi 1 loss 0.09794794023036957
bi 2 loss 0.04525865614414215
bi 3 loss 0.027586810290813446
Layer  1  loss:  0.05076197162270546 0.0 4.28147554397583
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([144, 446, 285,  98], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.02352503128349781
bi 1 loss 0.08339738100767136
bi 2 loss 0.10134075582027435
bi 3 loss 0.024610698223114014
Layer  2  loss:  0.06328213959932327 0.0 4.183963298797607
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([187, 517, 304, 156], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.03432195633649826
bi 1 loss 0.08427564799785614
bi 2 loss 0.1374456286430359
bi 3 loss 0.042255185544490814
Layer  3  loss:  0.059309329837560654 0.0 6.864964485168457
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([241, 566, 285, 197], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.017931248992681503
bi 1 loss 0.12401656806468964
bi 2 loss 0.06631886959075928
bi 3 loss 0.027572456747293472
Layer  4  loss:  0.050866276025772095 0.0 4.673619270324707
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([217, 478, 285, 169], device='cuda:0') tensor(478, device='cuda:0')
bi 0 loss 0.03892160952091217
bi 1 loss 0.09233134239912033
bi 2 loss 0.06115148961544037
bi 3 loss 0.01665602996945381
Layer  5  loss:  0.04751340672373772 0.0 4.589041709899902
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1017
Curr loss timestep torch.Size([601, 4]) tensor([232, 514, 285, 200], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.021527815610170364
bi 1 loss 0.06248082220554352
bi 2 loss 0.15107618272304535
bi 3 loss 0.020339926704764366
Layer  6  loss:  0.0515240803360939 0.0 5.692322254180908
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1020
Curr loss timestep torch.Size([601, 4]) tensor([229, 522, 304, 138], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.030115211382508278
bi 1 loss 0.08259069919586182
bi 2 loss 0.09150964766740799
bi 3 loss 0.025583254173398018
Epoch 0: :   3%|▎         | 15285/600000 [01:57<1:15:11, v_num=12, reduced_train_loss=37.30, global_step=15283.0, consumed_samples=61136.0, train_step_timing in s=0.341]Epoch 0: :   3%|▎         | 15285/600000 [01:57<1:15:11, v_num=12, reduced_train_loss=0.425, global_step=15284.0, consumed_samples=61140.0, train_step_timing in s=0.410]loss mask original None

First layer loss:  0.10369890928268433 torch.Size([514, 4]) 11.049267768859863 0.0
Max loss timestep torch.Size([514, 4]) tensor([253, 415, 468, 325], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.016006039455533028
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 1 loss 0.059914495795965195
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 2 loss 0.17524561285972595
speech mask sum tensor(324, device='cuda:0') loss mask sum tensor(324, device='cuda:0')
bi 3 loss 0.10044344514608383
speech mask sum tensor(299, device='cuda:0') loss mask sum tensor(299, device='cuda:0')
logits torch.Size([514, 4, 257024]) labels torch.Size([514, 4]) 0 257022
Layer  0  loss:  0.09441279619932175 0.0 6.7539381980896
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([221, 431, 466, 262], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.02696915529668331
bi 1 loss 0.06323444843292236
bi 2 loss 0.12318217009305954
bi 3 loss 0.11734753847122192
Layer  1  loss:  0.12801288068294525 0.0 9.41931438446045
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([219, 344, 466, 325], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.03695196658372879
bi 1 loss 0.07444000989198685
bi 2 loss 0.2222224324941635
bi 3 loss 0.11284016072750092
Layer  2  loss:  0.10922622680664062 0.0 14.40687084197998
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([231, 320, 467, 413], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.04522711783647537
bi 1 loss 0.08628764748573303
bi 2 loss 0.17224636673927307
bi 3 loss 0.08425714075565338
Layer  3  loss:  0.11524923145771027 0.0 14.615678787231445
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([252, 432, 468, 274], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.07035695761442184
bi 1 loss 0.08665986359119415
bi 2 loss 0.15996846556663513
bi 3 loss 0.11226881295442581
Layer  4  loss:  0.12031608819961548 0.0 14.390975952148438
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1021
Curr loss timestep torch.Size([514, 4]) tensor([225, 281, 467, 434], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.051944125443696976
bi 1 loss 0.07772246748209
bi 2 loss 0.20557406544685364
bi 3 loss 0.09604809433221817
Layer  5  loss:  0.14411567151546478 0.0 11.145151138305664
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1022
Curr loss timestep torch.Size([514, 4]) tensor([230, 339, 468, 308], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.03366653248667717
bi 1 loss 0.14779245853424072
bi 2 loss 0.19226109981536865
bi 3 loss 0.11447130888700485
Layer  6  loss:  0.13188166916370392 0.0 13.544504165649414
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([250, 339, 467, 325], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.05756678804755211
bi 1 loss 0.12647645175457
bi 2 loss 0.1827777624130249
bi 3 loss 0.10139983147382736
Epoch 0: :   3%|▎         | 15286/600000 [01:58<1:15:25, v_num=12, reduced_train_loss=0.425, global_step=15284.0, consumed_samples=61140.0, train_step_timing in s=0.410]Epoch 0: :   3%|▎         | 15286/600000 [01:58<1:15:26, v_num=12, reduced_train_loss=0.947, global_step=15285.0, consumed_samples=61144.0, train_step_timing in s=0.357]loss mask original None

First layer loss:  3.8650286197662354 torch.Size([648, 4]) 11.461098670959473 0.0
Max loss timestep torch.Size([648, 4]) tensor([328, 223, 263, 256], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 3.7401950359344482
speech mask sum tensor(428, device='cuda:0') loss mask sum tensor(428, device='cuda:0')
bi 1 loss 3.465726852416992
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 2 loss 3.8493025302886963
speech mask sum tensor(447, device='cuda:0') loss mask sum tensor(447, device='cuda:0')
bi 3 loss 4.234616279602051
speech mask sum tensor(317, device='cuda:0') loss mask sum tensor(317, device='cuda:0')
logits torch.Size([648, 4, 257024]) labels torch.Size([648, 4]) 0 257022
Layer  0  loss:  4.4194746017456055 0.0 10.707988739013672
logits torch.Size([648, 4, 1024]) labels torch.Size([648, 4]) 0 1023
Curr loss timestep torch.Size([648, 4]) tensor([613, 192, 518, 168], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.333372116088867
bi 1 loss 4.462334632873535
bi 2 loss 4.2275872230529785
bi 3 loss 4.787106513977051
Layer  1  loss:  4.812809467315674 0.0 10.697724342346191
logits torch.Size([648, 4, 1024]) labels torch.Size([648, 4]) 0 1022
Curr loss timestep torch.Size([648, 4]) tensor([454, 185, 339, 240], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 4.800302505493164
bi 1 loss 4.800838947296143
bi 2 loss 4.56057596206665
bi 3 loss 5.190732479095459
Layer  2  loss:  4.969188690185547 0.0 10.536624908447266
logits torch.Size([648, 4, 1024]) labels torch.Size([648, 4]) 0 1022
Curr loss timestep torch.Size([648, 4]) tensor([347, 239, 385, 320], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 4.874732971191406
bi 1 loss 4.93851900100708
bi 2 loss 4.734234809875488
bi 3 loss 5.441765785217285
Layer  3  loss:  5.058280944824219 0.0 10.215030670166016
logits torch.Size([648, 4, 1024]) labels torch.Size([648, 4]) 0 1022
Curr loss timestep torch.Size([648, 4]) tensor([321, 181, 438, 238], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 4.97953462600708
bi 1 loss 5.052706241607666
bi 2 loss 4.788571834564209
bi 3 loss 5.547415256500244
Layer  4  loss:  5.169752597808838 0.0 10.961727142333984
logits torch.Size([648, 4, 1024]) labels torch.Size([648, 4]) 0 1023
Curr loss timestep torch.Size([648, 4]) tensor([215, 248, 322, 194], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 5.1305718421936035
bi 1 loss 5.128350734710693
bi 2 loss 4.834887981414795
bi 3 loss 5.713389873504639
Layer  5  loss:  5.161310195922852 0.0 9.628856658935547
logits torch.Size([648, 4, 1024]) labels torch.Size([648, 4]) 0 1023
Curr loss timestep torch.Size([648, 4]) tensor([291, 175, 400, 308], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 5.012983798980713
bi 1 loss 5.141124248504639
bi 2 loss 4.9797444343566895
bi 3 loss 5.6266398429870605
Layer  6  loss:  5.2913031578063965 0.0 11.068845748901367
logits torch.Size([648, 4, 1024]) labels torch.Size([648, 4]) 0 1023
Curr loss timestep torch.Size([648, 4]) tensor([478, 207, 627, 341], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 5.1452202796936035
bi 1 loss 5.0749359130859375
bi 2 loss 5.0632524490356445
bi 3 loss 5.9070329666137695
Epoch 0: :   3%|▎         | 15287/600000 [01:58<1:15:42, v_num=12, reduced_train_loss=0.947, global_step=15285.0, consumed_samples=61144.0, train_step_timing in s=0.357]Epoch 0: :   3%|▎         | 15287/600000 [01:58<1:15:42, v_num=12, reduced_train_loss=38.70, global_step=15286.0, consumed_samples=61148.0, train_step_timing in s=0.403]loss mask original None

First layer loss:  3.8679521083831787 torch.Size([552, 4]) 10.535682678222656 0.0
Max loss timestep torch.Size([552, 4]) tensor([211, 210, 350, 405], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 3.6282126903533936
speech mask sum tensor(485, device='cuda:0') loss mask sum tensor(485, device='cuda:0')
bi 1 loss 3.776733160018921
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 2 loss 4.198537826538086
speech mask sum tensor(338, device='cuda:0') loss mask sum tensor(338, device='cuda:0')
bi 3 loss 3.925039291381836
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
logits torch.Size([552, 4, 257024]) labels torch.Size([552, 4]) 0 257022
Layer  0  loss:  4.451445579528809 0.0 10.249629020690918
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([154, 269, 377, 316], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.128970146179199
bi 1 loss 4.521337032318115
bi 2 loss 4.758790016174316
bi 3 loss 4.616637229919434
Layer  1  loss:  4.724761009216309 0.0 9.886327743530273
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([128, 224, 112, 390], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.324873924255371
bi 1 loss 4.753822326660156
bi 2 loss 5.085999011993408
bi 3 loss 4.980050563812256
Layer  2  loss:  4.949826240539551 0.0 10.740974426269531
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([369, 236, 244, 392], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.566539287567139
bi 1 loss 4.98994779586792
bi 2 loss 5.318492412567139
bi 3 loss 5.160834789276123
Layer  3  loss:  5.0845136642456055 0.0 10.978143692016602
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([271, 225, 242, 294], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 4.71852445602417
bi 1 loss 5.03526496887207
bi 2 loss 5.474498271942139
bi 3 loss 5.2766852378845215
Layer  4  loss:  5.142239093780518 0.0 10.451126098632812
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([206, 176, 115, 221], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 4.844180107116699
bi 1 loss 5.262845516204834
bi 2 loss 5.382672309875488
bi 3 loss 5.325303554534912
Layer  5  loss:  5.225902557373047 0.0 10.855497360229492
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([415, 265, 173, 266], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.837515830993652
bi 1 loss 5.53412389755249
bi 2 loss 5.486884593963623
bi 3 loss 5.463906764984131
Layer  6  loss:  5.244873046875 0.0 9.838501930236816
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([371, 281, 390, 197], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.953607082366943
bi 1 loss 5.315603256225586
bi 2 loss 5.600314140319824
bi 3 loss 5.292555809020996
Epoch 0: :   3%|▎         | 15288/600000 [01:59<1:15:57, v_num=12, reduced_train_loss=38.70, global_step=15286.0, consumed_samples=61148.0, train_step_timing in s=0.403]Epoch 0: :   3%|▎         | 15288/600000 [01:59<1:15:57, v_num=12, reduced_train_loss=38.70, global_step=15287.0, consumed_samples=61152.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  0.19884496927261353 torch.Size([653, 4]) 10.482394218444824 0.0
Max loss timestep torch.Size([653, 4]) tensor([406, 143, 610, 305], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.10233599692583084
speech mask sum tensor(345, device='cuda:0') loss mask sum tensor(345, device='cuda:0')
bi 1 loss 0.13881288468837738
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 2 loss 0.36209073662757874
speech mask sum tensor(359, device='cuda:0') loss mask sum tensor(359, device='cuda:0')
bi 3 loss 0.1312417984008789
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
logits torch.Size([653, 4, 257024]) labels torch.Size([653, 4]) 0 257022
Layer  0  loss:  0.1936185657978058 0.0 13.615397453308105
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([384, 190, 605, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.1267988383769989
bi 1 loss 0.09652820974588394
bi 2 loss 0.33756333589553833
bi 3 loss 0.14492438733577728
Layer  1  loss:  0.20629464089870453 0.0 12.688519477844238
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([406, 204, 594, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.14632679522037506
bi 1 loss 0.07330486178398132
bi 2 loss 0.37111586332321167
bi 3 loss 0.14316712319850922
Layer  2  loss:  0.1846960186958313 0.0 12.22177505493164
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([495, 199, 610, 305], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.13307452201843262
bi 1 loss 0.10629795491695404
bi 2 loss 0.31808963418006897
bi 3 loss 0.11106022447347641
Layer  3  loss:  0.22103066742420197 0.0 12.15347671508789
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([406, 205, 610, 305], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.12408851087093353
bi 1 loss 0.13466326892375946
bi 2 loss 0.39676204323768616
bi 3 loss 0.1571211814880371
Layer  4  loss:  0.19545835256576538 0.0 13.669072151184082
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([406,  50, 610, 305], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.1264680027961731
bi 1 loss 0.09326539188623428
bi 2 loss 0.36089712381362915
bi 3 loss 0.11729280650615692
Layer  5  loss:  0.2525382936000824 0.0 13.284173011779785
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([406,  72, 610, 305], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.20223765075206757
bi 1 loss 0.10687227547168732
bi 2 loss 0.4366498291492462
bi 3 loss 0.150918647646904
Layer  6  loss:  0.2344408631324768 0.0 13.921365737915039
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1021
Curr loss timestep torch.Size([653, 4]) tensor([406, 127, 605, 305], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.153720885515213
bi 1 loss 0.09647584706544876
bi 2 loss 0.4375207722187042
bi 3 loss 0.14365237951278687
Epoch 0: :   3%|▎         | 15289/600000 [01:59<1:16:16, v_num=12, reduced_train_loss=38.70, global_step=15287.0, consumed_samples=61152.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15289/600000 [01:59<1:16:16, v_num=12, reduced_train_loss=1.690, global_step=15288.0, consumed_samples=61156.0, train_step_timing in s=0.453]loss mask original None

First layer loss:  0.11128503829240799 torch.Size([593, 4]) 7.349719047546387 0.0
Max loss timestep torch.Size([593, 4]) tensor([478, 264, 302, 414], device='cuda:0') tensor(478, device='cuda:0')
bi 0 loss 0.11854803562164307
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
bi 1 loss 0.04531329125165939
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
bi 2 loss 0.17947080731391907
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 3 loss 0.12716874480247498
speech mask sum tensor(340, device='cuda:0') loss mask sum tensor(340, device='cuda:0')
logits torch.Size([593, 4, 257024]) labels torch.Size([593, 4]) 0 257022
Layer  0  loss:  0.10036852955818176 0.0 14.20483112335205
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([519, 295, 279, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.10042748600244522
bi 1 loss 0.05559808388352394
bi 2 loss 0.07149641215801239
bi 3 loss 0.13010713458061218
Layer  1  loss:  0.10743589699268341 0.0 6.817553997039795
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1022
Curr loss timestep torch.Size([593, 4]) tensor([537, 253, 304, 414], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.09614776819944382
bi 1 loss 0.055705614387989044
bi 2 loss 0.10456382483243942
bi 3 loss 0.15273091197013855
Layer  2  loss:  0.11503356695175171 0.0 14.90176773071289
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1022
Curr loss timestep torch.Size([593, 4]) tensor([584, 196, 263, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.106739841401577
bi 1 loss 0.06924685090780258
bi 2 loss 0.14066040515899658
bi 3 loss 0.1481962502002716
Layer  3  loss:  0.11642272025346756 0.0 10.818375587463379
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1021
Curr loss timestep torch.Size([593, 4]) tensor([396, 201, 281, 464], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.10091943293809891
bi 1 loss 0.06396498531103134
bi 2 loss 0.15532970428466797
bi 3 loss 0.16125686466693878
Layer  4  loss:  0.10835161805152893 0.0 7.2280449867248535
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1022
Curr loss timestep torch.Size([593, 4]) tensor([554, 288, 269, 464], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.09172335267066956
bi 1 loss 0.03255309537053108
bi 2 loss 0.10309579968452454
bi 3 loss 0.1750134378671646
Layer  5  loss:  0.13942717015743256 0.0 16.065065383911133
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([584, 295, 283, 412], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.12541399896144867
bi 1 loss 0.055316559970378876
bi 2 loss 0.14543947577476501
bi 3 loss 0.20528218150138855
Layer  6  loss:  0.11610198020935059 0.0 6.959872245788574
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1022
Curr loss timestep torch.Size([593, 4]) tensor([537, 288, 302, 412], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.10832665860652924
bi 1 loss 0.057621799409389496
bi 2 loss 0.07415264844894409
bi 3 loss 0.16660259664058685
Epoch 0: :   3%|▎         | 15290/600000 [02:00<1:16:33, v_num=12, reduced_train_loss=1.690, global_step=15288.0, consumed_samples=61156.0, train_step_timing in s=0.453]Epoch 0: :   3%|▎         | 15290/600000 [02:00<1:16:33, v_num=12, reduced_train_loss=0.914, global_step=15289.0, consumed_samples=61160.0, train_step_timing in s=0.417]loss mask original None

First layer loss:  0.06507755815982819 torch.Size([509, 4]) 4.0765380859375 0.0
Max loss timestep torch.Size([509, 4]) tensor([188, 493,  90, 269], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.05704301968216896
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
bi 1 loss 0.08868631720542908
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 2 loss 0.01598798856139183
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 3 loss 0.08086717873811722
speech mask sum tensor(207, device='cuda:0') loss mask sum tensor(207, device='cuda:0')
logits torch.Size([509, 4, 257024]) labels torch.Size([509, 4]) 0 257022
Layer  0  loss:  0.07644146680831909 0.0 11.250259399414062
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([166, 493, 118, 268], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.04794526845216751
bi 1 loss 0.13484440743923187
bi 2 loss 0.017941312864422798
bi 3 loss 0.0669664591550827
Layer  1  loss:  0.07456085085868835 0.0 9.91131591796875
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([135, 492, 209, 267], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.047948163002729416
bi 1 loss 0.1160140410065651
bi 2 loss 0.028455201536417007
bi 3 loss 0.07665661722421646
Layer  2  loss:  0.09524179995059967 0.0 10.087820053100586
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([191, 492, 207, 277], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.05312907323241234
bi 1 loss 0.16687121987342834
bi 2 loss 0.02247662842273712
bi 3 loss 0.08990806341171265
Layer  3  loss:  0.10595065355300903 0.0 7.314571857452393
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1021
Curr loss timestep torch.Size([509, 4]) tensor([235, 493, 129, 268], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.0852152407169342
bi 1 loss 0.1769370138645172
bi 2 loss 0.018220042809844017
bi 3 loss 0.0984962210059166
Layer  4  loss:  0.10133334249258041 0.0 10.647783279418945
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([160, 493, 145, 248], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.09661460667848587
bi 1 loss 0.15509505569934845
bi 2 loss 0.03913096711039543
bi 3 loss 0.08370095491409302
Layer  5  loss:  0.10435601323843002 0.0 9.128220558166504
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([150, 283,  89, 247], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.07395626604557037
bi 1 loss 0.19647309184074402
bi 2 loss 0.019443316385149956
bi 3 loss 0.07201535999774933
Layer  6  loss:  0.07851213216781616 0.0 9.394935607910156
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([172, 493, 167, 268], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.03541179746389389
bi 1 loss 0.1387072652578354
bi 2 loss 0.024570776149630547
bi 3 loss 0.07353751361370087
Epoch 0: :   3%|▎         | 15291/600000 [02:00<1:16:47, v_num=12, reduced_train_loss=0.914, global_step=15289.0, consumed_samples=61160.0, train_step_timing in s=0.417]Epoch 0: :   3%|▎         | 15291/600000 [02:00<1:16:47, v_num=12, reduced_train_loss=0.701, global_step=15290.0, consumed_samples=61164.0, train_step_timing in s=0.356]loss mask original None

First layer loss:  0.10732398182153702 torch.Size([549, 4]) 6.6894025802612305 0.0
Max loss timestep torch.Size([549, 4]) tensor([281, 337, 306, 168], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.09841632843017578
speech mask sum tensor(288, device='cuda:0') loss mask sum tensor(288, device='cuda:0')
bi 1 loss 0.10745466500520706
speech mask sum tensor(410, device='cuda:0') loss mask sum tensor(410, device='cuda:0')
bi 2 loss 0.14459550380706787
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 3 loss 0.02402288280427456
speech mask sum tensor(126, device='cuda:0') loss mask sum tensor(126, device='cuda:0')
logits torch.Size([549, 4, 257024]) labels torch.Size([549, 4]) 0 257022
Layer  0  loss:  0.10069926828145981 0.0 5.784107685089111
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([292, 337, 307, 210], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.09219316393136978
bi 1 loss 0.09211872518062592
bi 2 loss 0.1404770016670227
bi 3 loss 0.03788458928465843
Layer  1  loss:  0.11895769834518433 0.0 7.233127593994141
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([292, 175, 306, 151], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.10684274137020111
bi 1 loss 0.10128958523273468
bi 2 loss 0.16639938950538635
bi 3 loss 0.07273460924625397
Layer  2  loss:  0.1128096878528595 0.0 11.343828201293945
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1022
Curr loss timestep torch.Size([549, 4]) tensor([292, 322, 306, 164], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.13156315684318542
bi 1 loss 0.08560523390769958
bi 2 loss 0.1525612622499466
bi 3 loss 0.0483616478741169
Layer  3  loss:  0.09929895401000977 0.0 5.523871898651123
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([284, 337, 306, 179], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.08180955052375793
bi 1 loss 0.10482780635356903
bi 2 loss 0.12645238637924194
bi 3 loss 0.046073444187641144
Layer  4  loss:  0.12414675951004028 0.0 7.415593147277832
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1022
Curr loss timestep torch.Size([549, 4]) tensor([281, 335, 306, 150], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.1077733263373375
bi 1 loss 0.12535792589187622
bi 2 loss 0.1652439683675766
bi 3 loss 0.04379774257540703
Layer  5  loss:  0.11238783597946167 0.0 4.884494781494141
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([292, 335, 464, 204], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.11640899628400803
bi 1 loss 0.09338274598121643
bi 2 loss 0.1495620608329773
bi 3 loss 0.062071867287158966
Layer  6  loss:  0.10671267658472061 0.0 5.460035800933838
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1022
Curr loss timestep torch.Size([549, 4]) tensor([314, 337, 462, 168], device='cuda:0') tensor(462, device='cuda:0')
bi 0 loss 0.09846113622188568
bi 1 loss 0.10822050273418427
bi 2 loss 0.13947094976902008
bi 3 loss 0.029931621626019478
Epoch 0: :   3%|▎         | 15292/600000 [02:00<1:17:03, v_num=12, reduced_train_loss=0.701, global_step=15290.0, consumed_samples=61164.0, train_step_timing in s=0.356]Epoch 0: :   3%|▎         | 15292/600000 [02:00<1:17:03, v_num=12, reduced_train_loss=0.882, global_step=15291.0, consumed_samples=61168.0, train_step_timing in s=0.379]loss mask original None

First layer loss:  0.1853768676519394 torch.Size([593, 4]) 8.898093223571777 0.0
Max loss timestep torch.Size([593, 4]) tensor([ 71, 265, 560, 275], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.08659921586513519
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 1 loss 0.2783854305744171
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 2 loss 0.22963844239711761
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
bi 3 loss 0.0415906123816967
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
logits torch.Size([593, 4, 257024]) labels torch.Size([593, 4]) 0 257022
Layer  0  loss:  0.22272899746894836 0.0 13.859979629516602
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([129, 546, 263, 270], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.07100386917591095
bi 1 loss 0.3032042384147644
bi 2 loss 0.3046627342700958
bi 3 loss 0.06326259672641754
Layer  1  loss:  0.22998623549938202 0.0 10.34280014038086
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([126, 534, 528, 359], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.0860782340168953
bi 1 loss 0.3548053801059723
bi 2 loss 0.2640222907066345
bi 3 loss 0.08215043693780899
Layer  2  loss:  0.21703629195690155 0.0 11.285914421081543
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1022
Curr loss timestep torch.Size([593, 4]) tensor([105, 545, 263, 273], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.05738404765725136
bi 1 loss 0.3126927316188812
bi 2 loss 0.27761906385421753
bi 3 loss 0.07452816516160965
Layer  3  loss:  0.22248432040214539 0.0 13.532885551452637
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1021
Curr loss timestep torch.Size([593, 4]) tensor([107, 442, 413, 395], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.05603204295039177
bi 1 loss 0.288547545671463
bi 2 loss 0.32700997591018677
bi 3 loss 0.05434887856245041
Layer  4  loss:  0.24250610172748566 0.0 11.057886123657227
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([ 58, 265, 413, 403], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.06348924338817596
bi 1 loss 0.3481806218624115
bi 2 loss 0.30303755402565
bi 3 loss 0.09634539484977722
Layer  5  loss:  0.24030132591724396 0.0 14.633964538574219
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([125, 550, 574, 271], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.08398173004388809
bi 1 loss 0.3540377914905548
bi 2 loss 0.3036462068557739
bi 3 loss 0.06775255501270294
Layer  6  loss:  0.24766674637794495 0.0 13.058431625366211
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1021
Curr loss timestep torch.Size([593, 4]) tensor([114, 534, 263, 359], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.03494489565491676
bi 1 loss 0.32303017377853394
bi 2 loss 0.3576790392398834
bi 3 loss 0.08156823366880417
Epoch 0: :   3%|▎         | 15293/600000 [02:01<1:17:20, v_num=12, reduced_train_loss=0.882, global_step=15291.0, consumed_samples=61168.0, train_step_timing in s=0.379]Epoch 0: :   3%|▎         | 15293/600000 [02:01<1:17:20, v_num=12, reduced_train_loss=1.810, global_step=15292.0, consumed_samples=61172.0, train_step_timing in s=0.407]loss mask original None

First layer loss:  3.585008382797241 torch.Size([596, 4]) 11.363012313842773 0.0
Max loss timestep torch.Size([596, 4]) tensor([298, 306,  52, 270], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 3.43084716796875
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
bi 1 loss 3.5048859119415283
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
bi 2 loss 3.3504483699798584
speech mask sum tensor(77, device='cuda:0') loss mask sum tensor(77, device='cuda:0')
bi 3 loss 3.780080556869507
speech mask sum tensor(408, device='cuda:0') loss mask sum tensor(408, device='cuda:0')
logits torch.Size([596, 4, 257024]) labels torch.Size([596, 4]) 0 257022
Layer  0  loss:  4.1635918617248535 0.0 11.278519630432129
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([225, 260,  75, 193], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.359433174133301
bi 1 loss 4.000607967376709
bi 2 loss 3.839083194732666
bi 3 loss 4.23443078994751
Layer  1  loss:  4.511645793914795 0.0 10.376381874084473
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([341, 133,  54, 245], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 4.773324966430664
bi 1 loss 4.370632171630859
bi 2 loss 4.3407883644104
bi 3 loss 4.498387813568115
Layer  2  loss:  4.709770202636719 0.0 11.064205169677734
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([404, 268,  95, 399], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 5.093757152557373
bi 1 loss 4.624380588531494
bi 2 loss 4.378735065460205
bi 3 loss 4.613131046295166
Layer  3  loss:  4.8007612228393555 0.0 9.783849716186523
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([339, 248,  40, 247], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 4.9667863845825195
bi 1 loss 4.70053768157959
bi 2 loss 4.625696182250977
bi 3 loss 4.813103675842285
Layer  4  loss:  4.966560363769531 0.0 9.199687957763672
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([297, 120,  82, 233], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 5.333261013031006
bi 1 loss 4.940572261810303
bi 2 loss 4.707669258117676
bi 3 loss 4.821258068084717
Layer  5  loss:  5.022303104400635 0.0 10.15861701965332
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1020
Curr loss timestep torch.Size([596, 4]) tensor([401,  61,  86, 228], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 5.546599864959717
bi 1 loss 4.94100284576416
bi 2 loss 5.03840446472168
bi 3 loss 4.7751970291137695
Layer  6  loss:  5.0698628425598145 0.0 9.769177436828613
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([241,  66,  84, 355], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 5.382081508636475
bi 1 loss 5.0891571044921875
bi 2 loss 4.926247596740723
bi 3 loss 4.900179862976074
Epoch 0: :   3%|▎         | 15294/600000 [02:01<1:17:35, v_num=12, reduced_train_loss=1.810, global_step=15292.0, consumed_samples=61172.0, train_step_timing in s=0.407]Epoch 0: :   3%|▎         | 15294/600000 [02:01<1:17:35, v_num=12, reduced_train_loss=36.80, global_step=15293.0, consumed_samples=61176.0, train_step_timing in s=0.371]loss mask original None

First layer loss:  0.08988682180643082 torch.Size([553, 4]) 4.040263652801514 0.0
Max loss timestep torch.Size([553, 4]) tensor([296, 535, 121, 288], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.06158581003546715
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 1 loss 0.12275731563568115
speech mask sum tensor(447, device='cuda:0') loss mask sum tensor(447, device='cuda:0')
bi 2 loss 0.03563038259744644
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 3 loss 0.06853991746902466
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
logits torch.Size([553, 4, 257024]) labels torch.Size([553, 4]) 0 257023
Layer  0  loss:  0.07954789698123932 0.0 5.199770927429199
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([315, 275, 113, 250], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.07354696840047836
bi 1 loss 0.10578245669603348
bi 2 loss 0.023799529299139977
bi 3 loss 0.06454228609800339
Layer  1  loss:  0.08291944861412048 0.0 3.33553409576416
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([342, 535, 111, 208], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 0.12990882992744446
bi 1 loss 0.0879732146859169
bi 2 loss 0.04862416535615921
bi 3 loss 0.07531294226646423
Layer  2  loss:  0.11041643470525742 0.0 7.376509189605713
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([332, 260, 180, 340], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.05874864012002945
bi 1 loss 0.14377820491790771
bi 2 loss 0.04140297695994377
bi 3 loss 0.11225404590368271
Layer  3  loss:  0.1314765363931656 0.0 7.269643783569336
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([278, 535, 195, 300], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.10922376066446304
bi 1 loss 0.19255861639976501
bi 2 loss 0.03973359987139702
bi 3 loss 0.06863485276699066
Layer  4  loss:  0.09526331722736359 0.0 4.6971116065979
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([314, 535,  99, 340], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.07761889696121216
bi 1 loss 0.11659523099660873
bi 2 loss 0.04850713536143303
bi 3 loss 0.09079034626483917
Layer  5  loss:  0.09826226532459259 0.0 7.502164840698242
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1019
Curr loss timestep torch.Size([553, 4]) tensor([284, 308, 120, 340], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.06303108483552933
bi 1 loss 0.13576152920722961
bi 2 loss 0.06439342349767685
bi 3 loss 0.05174652859568596
Layer  6  loss:  0.11820339411497116 0.0 8.448996543884277
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([342, 521, 105, 210], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.06960971653461456
bi 1 loss 0.17441661655902863
bi 2 loss 0.05702780559659004
bi 3 loss 0.055103376507759094
Epoch 0: :   3%|▎         | 15295/600000 [02:02<1:17:51, v_num=12, reduced_train_loss=36.80, global_step=15293.0, consumed_samples=61176.0, train_step_timing in s=0.371]Epoch 0: :   3%|▎         | 15295/600000 [02:02<1:17:51, v_num=12, reduced_train_loss=0.806, global_step=15294.0, consumed_samples=61180.0, train_step_timing in s=0.378]loss mask original None

First layer loss:  0.03488573059439659 torch.Size([427, 4]) 3.9968929290771484 0.0
Max loss timestep torch.Size([427, 4]) tensor([390,  89, 292, 104], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.04754825308918953
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
bi 1 loss 0.019995547831058502
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
bi 2 loss 0.021763019263744354
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 3 loss 0.016611116006970406
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
logits torch.Size([427, 4, 257024]) labels torch.Size([427, 4]) 0 257022
Layer  0  loss:  0.0571834035217762 0.0 9.282979965209961
logits torch.Size([427, 4, 1024]) labels torch.Size([427, 4]) 0 1023
Curr loss timestep torch.Size([427, 4]) tensor([329,  73, 279,  61], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.07916054129600525
bi 1 loss 0.03070709854364395
bi 2 loss 0.03736143186688423
bi 3 loss 0.02269987016916275
Layer  1  loss:  0.040022339671850204 0.0 4.947995185852051
logits torch.Size([427, 4, 1024]) labels torch.Size([427, 4]) 0 1021
Curr loss timestep torch.Size([427, 4]) tensor([329,  56, 275, 107], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.05530507117509842
bi 1 loss 0.02483471669256687
bi 2 loss 0.021458057686686516
bi 3 loss 0.018645938485860825
Layer  2  loss:  0.05194506421685219 0.0 10.407516479492188
logits torch.Size([427, 4, 1024]) labels torch.Size([427, 4]) 0 1022
Curr loss timestep torch.Size([427, 4]) tensor([329,  70, 250,  94], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.07479917258024216
bi 1 loss 0.018397826701402664
bi 2 loss 0.034078214317560196
bi 3 loss 0.01813437230885029
Layer  3  loss:  0.0447361022233963 0.0 5.087287425994873
logits torch.Size([427, 4, 1024]) labels torch.Size([427, 4]) 0 1018
Curr loss timestep torch.Size([427, 4]) tensor([329,  80, 258,  81], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.0643807202577591
bi 1 loss 0.02364172413945198
bi 2 loss 0.02362173981964588
bi 3 loss 0.015522227622568607
Layer  4  loss:  0.04824995622038841 0.0 10.626913070678711
logits torch.Size([427, 4, 1024]) labels torch.Size([427, 4]) 0 1022
Curr loss timestep torch.Size([427, 4]) tensor([329,  60, 212,  89], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.07031720876693726
bi 1 loss 0.031926289200782776
bi 2 loss 0.020878218114376068
bi 3 loss 0.013243675231933594
Layer  5  loss:  0.0547407791018486 0.0 13.56645393371582
logits torch.Size([427, 4, 1024]) labels torch.Size([427, 4]) 0 1018
Curr loss timestep torch.Size([427, 4]) tensor([329,  75, 258,  90], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.08144775778055191
bi 1 loss 0.0239656250923872
bi 2 loss 0.022238025441765785
bi 3 loss 0.0210589412599802
Layer  6  loss:  0.04714936017990112 0.0 7.204293727874756
logits torch.Size([427, 4, 1024]) labels torch.Size([427, 4]) 0 1022
Curr loss timestep torch.Size([427, 4]) tensor([329,  74, 257, 105], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.0653468519449234
bi 1 loss 0.03058924712240696
bi 2 loss 0.026338454335927963
bi 3 loss 0.018950507044792175
Epoch 0: :   3%|▎         | 15296/600000 [02:02<1:18:04, v_num=12, reduced_train_loss=0.806, global_step=15294.0, consumed_samples=61180.0, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15296/600000 [02:02<1:18:04, v_num=12, reduced_train_loss=0.379, global_step=15295.0, consumed_samples=61184.0, train_step_timing in s=0.312]loss mask original None

First layer loss:  0.16144788265228271 torch.Size([558, 4]) 9.772418022155762 0.0
Max loss timestep torch.Size([558, 4]) tensor([275, 352, 381, 517], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.07192166149616241
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 1 loss 0.13985362648963928
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 2 loss 0.16985902190208435
speech mask sum tensor(438, device='cuda:0') loss mask sum tensor(438, device='cuda:0')
bi 3 loss 0.20149490237236023
speech mask sum tensor(470, device='cuda:0') loss mask sum tensor(470, device='cuda:0')
logits torch.Size([558, 4, 257024]) labels torch.Size([558, 4]) 0 257023
Layer  0  loss:  0.19013914465904236 0.0 12.160530090332031
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([288, 380, 380, 284], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.08184735476970673
bi 1 loss 0.18803535401821136
bi 2 loss 0.17996253073215485
bi 3 loss 0.2409382313489914
Layer  1  loss:  0.1768321990966797 0.0 13.608694076538086
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([286, 379, 517, 508], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.06406042724847794
bi 1 loss 0.15911170840263367
bi 2 loss 0.1776835173368454
bi 3 loss 0.2298019826412201
Layer  2  loss:  0.19781547784805298 0.0 13.067112922668457
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([284, 378, 380, 368], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.09945552051067352
bi 1 loss 0.2039622813463211
bi 2 loss 0.18683135509490967
bi 3 loss 0.24000617861747742
Layer  3  loss:  0.23092177510261536 0.0 15.164168357849121
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1021
Curr loss timestep torch.Size([558, 4]) tensor([299, 380, 380, 521], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.062000010162591934
bi 1 loss 0.21843767166137695
bi 2 loss 0.23845702409744263
bi 3 loss 0.29470980167388916
Layer  4  loss:  0.21099916100502014 0.0 11.105523109436035
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1021
Curr loss timestep torch.Size([558, 4]) tensor([279, 380, 521, 508], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.06964150816202164
bi 1 loss 0.21676847338676453
bi 2 loss 0.20779447257518768
bi 3 loss 0.26202788949012756
Layer  5  loss:  0.2152208387851715 0.0 13.924492835998535
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([151, 263, 517, 508], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.06722354143857956
bi 1 loss 0.2553216218948364
bi 2 loss 0.1997467279434204
bi 3 loss 0.2563876807689667
Layer  6  loss:  0.2396949976682663 0.0 15.857165336608887
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1021
Curr loss timestep torch.Size([558, 4]) tensor([299, 451, 381, 508], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.08450044691562653
bi 1 loss 0.2290099859237671
bi 2 loss 0.23344619572162628
bi 3 loss 0.3100317120552063
Epoch 0: :   3%|▎         | 15297/600000 [02:02<1:18:19, v_num=12, reduced_train_loss=0.379, global_step=15295.0, consumed_samples=61184.0, train_step_timing in s=0.312]Epoch 0: :   3%|▎         | 15297/600000 [02:02<1:18:19, v_num=12, reduced_train_loss=1.620, global_step=15296.0, consumed_samples=61188.0, train_step_timing in s=0.378]loss mask original None

First layer loss:  3.8025670051574707 torch.Size([760, 4]) 10.984760284423828 0.0
Max loss timestep torch.Size([760, 4]) tensor([207, 430, 119, 309], device='cuda:0') tensor(474, device='cuda:0')
bi 0 loss 4.2740559577941895
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 1 loss 3.7542152404785156
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
bi 2 loss 3.482124090194702
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
bi 3 loss 4.027368545532227
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
logits torch.Size([760, 4, 257024]) labels torch.Size([760, 4]) 0 257023
Layer  0  loss:  4.320833206176758 0.0 10.163520812988281
logits torch.Size([760, 4, 1024]) labels torch.Size([760, 4]) 0 1023
Curr loss timestep torch.Size([760, 4]) tensor([137, 431, 119, 505], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 4.568181991577148
bi 1 loss 4.316877841949463
bi 2 loss 4.058920383453369
bi 3 loss 4.545947551727295
Layer  1  loss:  4.566477298736572 0.0 10.386209487915039
logits torch.Size([760, 4, 1024]) labels torch.Size([760, 4]) 0 1023
Curr loss timestep torch.Size([760, 4]) tensor([222, 729, 445, 231], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.723606586456299
bi 1 loss 4.4732513427734375
bi 2 loss 4.406777858734131
bi 3 loss 4.818455696105957
Layer  2  loss:  4.814857006072998 0.0 11.048766136169434
logits torch.Size([760, 4, 1024]) labels torch.Size([760, 4]) 0 1023
Curr loss timestep torch.Size([760, 4]) tensor([ 90, 551, 302, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 4.814758777618408
bi 1 loss 4.6478681564331055
bi 2 loss 4.782086372375488
bi 3 loss 5.080472946166992
Layer  3  loss:  4.902772903442383 0.0 9.675898551940918
logits torch.Size([760, 4, 1024]) labels torch.Size([760, 4]) 0 1019
Curr loss timestep torch.Size([760, 4]) tensor([164, 460, 309, 432], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 5.035659313201904
bi 1 loss 4.769937992095947
bi 2 loss 4.907211780548096
bi 3 loss 4.985450744628906
Layer  4  loss:  5.0106024742126465 0.0 11.50113296508789
logits torch.Size([760, 4, 1024]) labels torch.Size([760, 4]) 0 1023
Curr loss timestep torch.Size([760, 4]) tensor([241, 713, 453, 235], device='cuda:0') tensor(453, device='cuda:0')
bi 0 loss 5.1455278396606445
bi 1 loss 4.714362621307373
bi 2 loss 5.03317403793335
bi 3 loss 5.279495716094971
Layer  5  loss:  5.090794563293457 0.0 10.238091468811035
logits torch.Size([760, 4, 1024]) labels torch.Size([760, 4]) 0 1023
Curr loss timestep torch.Size([760, 4]) tensor([ 80, 597, 348, 439], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 5.229556083679199
bi 1 loss 4.804637908935547
bi 2 loss 5.114356517791748
bi 3 loss 5.34263801574707
Layer  6  loss:  5.136760711669922 0.0 11.144792556762695
logits torch.Size([760, 4, 1024]) labels torch.Size([760, 4]) 0 1021
Curr loss timestep torch.Size([760, 4]) tensor([237, 575, 357, 202], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 5.350966930389404
bi 1 loss 4.748102188110352
bi 2 loss 5.186128616333008
bi 3 loss 5.43740177154541
Epoch 0: :   3%|▎         | 15298/600000 [02:03<1:18:38, v_num=12, reduced_train_loss=1.620, global_step=15296.0, consumed_samples=61188.0, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15298/600000 [02:03<1:18:38, v_num=12, reduced_train_loss=37.60, global_step=15297.0, consumed_samples=61192.0, train_step_timing in s=0.450]loss mask original None

First layer loss:  0.15985527634620667 torch.Size([633, 4]) 8.690597534179688 0.0
Max loss timestep torch.Size([633, 4]) tensor([235, 498, 138, 610], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 0.13364878296852112
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 1 loss 0.154475137591362
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
bi 2 loss 0.0298501867800951
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
bi 3 loss 0.2321368008852005
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
logits torch.Size([633, 4, 257024]) labels torch.Size([633, 4]) 0 257023
Layer  0  loss:  0.17115001380443573 0.0 12.579439163208008
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([134, 379,  76, 578], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.05225009471178055
bi 1 loss 0.18916061520576477
bi 2 loss 0.03470804542303085
bi 3 loss 0.26661360263824463
Layer  1  loss:  0.20732708275318146 0.0 17.979562759399414
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([237, 379, 210, 602], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.06039850786328316
bi 1 loss 0.2870413064956665
bi 2 loss 0.0346192792057991
bi 3 loss 0.2776622772216797
Layer  2  loss:  0.17747089266777039 0.0 13.320416450500488
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([260, 379,  67, 514], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.062236517667770386
bi 1 loss 0.2006968855857849
bi 2 loss 0.05405432730913162
bi 3 loss 0.26121702790260315
Layer  3  loss:  0.20683424174785614 0.0 15.178723335266113
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1021
Curr loss timestep torch.Size([633, 4]) tensor([207, 436,  82, 610], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.06961455196142197
bi 1 loss 0.23064672946929932
bi 2 loss 0.03512486070394516
bi 3 loss 0.32056206464767456
Layer  4  loss:  0.2148522585630417 0.0 13.772016525268555
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([262, 379, 144, 514], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.0613214336335659
bi 1 loss 0.2372911423444748
bi 2 loss 0.037678733468055725
bi 3 loss 0.33925220370292664
Layer  5  loss:  0.20421002805233002 0.0 11.089409828186035
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([229, 380, 174, 334], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.05252435803413391
bi 1 loss 0.2320091724395752
bi 2 loss 0.06074097380042076
bi 3 loss 0.30862390995025635
Layer  6  loss:  0.17834122478961945 0.0 18.47116470336914
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([126, 379, 178, 514], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.04481374844908714
bi 1 loss 0.24680151045322418
bi 2 loss 0.04599696025252342
bi 3 loss 0.2350468933582306
Epoch 0: :   3%|▎         | 15299/600000 [02:03<1:18:55, v_num=12, reduced_train_loss=37.60, global_step=15297.0, consumed_samples=61192.0, train_step_timing in s=0.450]Epoch 0: :   3%|▎         | 15299/600000 [02:03<1:18:55, v_num=12, reduced_train_loss=1.520, global_step=15298.0, consumed_samples=61196.0, train_step_timing in s=0.434]loss mask original None

First layer loss:  0.11072611808776855 torch.Size([583, 4]) 18.105539321899414 0.0
Max loss timestep torch.Size([583, 4]) tensor([550, 263, 147, 337], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.15748350322246552
speech mask sum tensor(375, device='cuda:0') loss mask sum tensor(375, device='cuda:0')
bi 1 loss 0.07715205103158951
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 2 loss 0.14940756559371948
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
bi 3 loss 0.03933887183666229
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
logits torch.Size([583, 4, 257024]) labels torch.Size([583, 4]) 0 257023
Layer  0  loss:  0.08728045225143433 0.0 10.897982597351074
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([438, 263, 236, 336], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.1287657618522644
bi 1 loss 0.09034015238285065
bi 2 loss 0.055240657180547714
bi 3 loss 0.056864410638809204
Layer  1  loss:  0.08140388131141663 0.0 14.09652042388916
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1021
Curr loss timestep torch.Size([583, 4]) tensor([550, 263,  82, 137], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.11039473116397858
bi 1 loss 0.12388740479946136
bi 2 loss 0.039832644164562225
bi 3 loss 0.050638120621442795
Layer  2  loss:  0.11205562949180603 0.0 17.69286346435547
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([550, 263, 150, 228], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.18922752141952515
bi 1 loss 0.10080277174711227
bi 2 loss 0.0757068395614624
bi 3 loss 0.04729089513421059
Layer  3  loss:  0.08100568503141403 0.0 9.312787055969238
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1021
Curr loss timestep torch.Size([583, 4]) tensor([434, 263, 259, 291], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.1129622533917427
bi 1 loss 0.0909489318728447
bi 2 loss 0.06084028631448746
bi 3 loss 0.049278758466243744
Layer  4  loss:  0.10942916572093964 0.0 9.518588066101074
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([550, 263, 193,  97], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.20221349596977234
bi 1 loss 0.05914318561553955
bi 2 loss 0.0650133416056633
bi 3 loss 0.05480245500802994
Layer  5  loss:  0.10621970146894455 0.0 12.148921966552734
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([550, 263,  81, 336], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.1812538504600525
bi 1 loss 0.08107049763202667
bi 2 loss 0.0747716873884201
bi 3 loss 0.04889095202088356
Layer  6  loss:  0.09303652495145798 0.0 11.512600898742676
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([550, 263, 269, 336], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.1357222944498062
bi 1 loss 0.09323329478502274
bi 2 loss 0.052604928612709045
bi 3 loss 0.06954272836446762
Epoch 0: :   3%|▎         | 15300/600000 [02:04<1:19:12, v_num=12, reduced_train_loss=1.520, global_step=15298.0, consumed_samples=61196.0, train_step_timing in s=0.434]Epoch 0: :   3%|▎         | 15300/600000 [02:04<1:19:12, v_num=12, reduced_train_loss=0.781, global_step=15299.0, consumed_samples=61200.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  0.17920826375484467 torch.Size([611, 4]) 12.571725845336914 0.0
Max loss timestep torch.Size([611, 4]) tensor([534, 507, 443, 150], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.17238430678844452
speech mask sum tensor(419, device='cuda:0') loss mask sum tensor(419, device='cuda:0')
bi 1 loss 0.33429989218711853
speech mask sum tensor(357, device='cuda:0') loss mask sum tensor(357, device='cuda:0')
bi 2 loss 0.1027931272983551
speech mask sum tensor(482, device='cuda:0') loss mask sum tensor(482, device='cuda:0')
bi 3 loss 0.027010442689061165
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
logits torch.Size([611, 4, 257024]) labels torch.Size([611, 4]) 0 257023
Layer  0  loss:  0.20077279210090637 0.0 18.09932518005371
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([533, 507, 443, 175], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.22723577916622162
bi 1 loss 0.3179931938648224
bi 2 loss 0.1237049326300621
bi 3 loss 0.0474817231297493
Layer  1  loss:  0.22933706641197205 0.0 15.303159713745117
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([598, 419, 443, 172], device='cuda:0') tensor(419, device='cuda:0')
bi 0 loss 0.2395118921995163
bi 1 loss 0.34074994921684265
bi 2 loss 0.17540481686592102
bi 3 loss 0.054169271141290665
Layer  2  loss:  0.23248887062072754 0.0 14.459391593933105
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([534, 506, 540, 124], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.29648083448410034
bi 1 loss 0.3377106487751007
bi 2 loss 0.13276299834251404
bi 3 loss 0.07414978742599487
Layer  3  loss:  0.2116641402244568 0.0 16.07404327392578
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([534, 483, 427, 149], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.26424962282180786
bi 1 loss 0.30914080142974854
bi 2 loss 0.12534545361995697
bi 3 loss 0.06383015960454941
Layer  4  loss:  0.2252017855644226 0.0 13.391390800476074
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([533, 507, 549, 114], device='cuda:0') tensor(507, device='cuda:0')
bi 0 loss 0.23236459493637085
bi 1 loss 0.36309462785720825
bi 2 loss 0.15900477766990662
bi 3 loss 0.02790077030658722
Layer  5  loss:  0.22042731940746307 0.0 11.166487693786621
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1020
Curr loss timestep torch.Size([611, 4]) tensor([534, 419, 427, 147], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.27251455187797546
bi 1 loss 0.3241748809814453
bi 2 loss 0.1331944763660431
bi 3 loss 0.05716335028409958
Layer  6  loss:  0.21944771707057953 0.0 16.802621841430664
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([534, 507, 427, 167], device='cuda:0') tensor(508, device='cuda:0')
bi 0 loss 0.2643103003501892
bi 1 loss 0.3459424376487732
bi 2 loss 0.11946587264537811
bi 3 loss 0.06639166921377182
Epoch 0: :   3%|▎         | 15301/600000 [02:04<1:19:28, v_num=12, reduced_train_loss=0.781, global_step=15299.0, consumed_samples=61200.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15301/600000 [02:04<1:19:28, v_num=12, reduced_train_loss=1.720, global_step=15300.0, consumed_samples=61204.0, train_step_timing in s=0.415]loss mask original None

First layer loss:  0.03131719306111336 torch.Size([466, 4]) 0.6924150586128235 0.0
Max loss timestep torch.Size([466, 4]) tensor([426, 247, 291, 181], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.03565194830298424
speech mask sum tensor(294, device='cuda:0') loss mask sum tensor(294, device='cuda:0')
bi 1 loss 0.03417915478348732
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 2 loss 0.03396216034889221
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
bi 3 loss 0.013307610526680946
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
logits torch.Size([466, 4, 257024]) labels torch.Size([466, 4]) 0 257022
Layer  0  loss:  0.028440382331609726 0.0 0.544270932674408
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([404, 235, 323, 221], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.03084651194512844
bi 1 loss 0.02211812324821949
bi 2 loss 0.03144441917538643
bi 3 loss 0.023185962811112404
Layer  1  loss:  0.030032286420464516 0.0 1.123390793800354
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([197, 217, 291, 195], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.02738841623067856
bi 1 loss 0.026437165215611458
bi 2 loss 0.04046282917261124
bi 3 loss 0.02046608366072178
Layer  2  loss:  0.027399985119700432 0.0 0.6498494148254395
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1022
Curr loss timestep torch.Size([466, 4]) tensor([330, 184, 237, 185], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 0.02699129655957222
bi 1 loss 0.02571396343410015
bi 2 loss 0.03263905271887779
bi 3 loss 0.020282892510294914
Layer  3  loss:  0.030393298715353012 0.0 0.6055493950843811
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1020
Curr loss timestep torch.Size([466, 4]) tensor([315, 221, 324, 224], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 0.030084503814578056
bi 1 loss 0.0383620411157608
bi 2 loss 0.035001274198293686
bi 3 loss 0.014944951049983501
Layer  4  loss:  0.026236269623041153 0.0 0.5772666335105896
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1022
Curr loss timestep torch.Size([466, 4]) tensor([342, 176, 292, 178], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.028994766995310783
bi 1 loss 0.022452225908637047
bi 2 loss 0.02741026133298874
bi 3 loss 0.021096831187605858
Layer  5  loss:  0.027602434158325195 0.0 0.5128949284553528
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1022
Curr loss timestep torch.Size([466, 4]) tensor([323, 190, 147, 206], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 0.02952657826244831
bi 1 loss 0.01752684824168682
bi 2 loss 0.030440036207437515
bi 3 loss 0.027409328147768974
Layer  6  loss:  0.025120090693235397 0.0 0.7488760352134705
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1021
Curr loss timestep torch.Size([466, 4]) tensor([271, 195, 309, 196], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.026805317029356956
bi 1 loss 0.0186352226883173
bi 2 loss 0.028850730508565903
bi 3 loss 0.020397908985614777
Epoch 0: :   3%|▎         | 15302/600000 [02:05<1:19:42, v_num=12, reduced_train_loss=1.720, global_step=15300.0, consumed_samples=61204.0, train_step_timing in s=0.415]Epoch 0: :   3%|▎         | 15302/600000 [02:05<1:19:42, v_num=12, reduced_train_loss=0.227, global_step=15301.0, consumed_samples=61208.0, train_step_timing in s=0.332]loss mask original None

First layer loss:  3.585996389389038 torch.Size([708, 4]) 10.70556640625 0.0
Max loss timestep torch.Size([708, 4]) tensor([528, 118, 647,  97], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 3.58493709564209
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
bi 1 loss 2.8954899311065674
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
bi 2 loss 3.7455315589904785
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 3 loss 3.1396446228027344
speech mask sum tensor(49, device='cuda:0') loss mask sum tensor(49, device='cuda:0')
logits torch.Size([708, 4, 257024]) labels torch.Size([708, 4]) 0 257023
Layer  0  loss:  4.1509528160095215 0.0 10.649679183959961
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([612, 130, 259,  99], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 4.240866184234619
bi 1 loss 3.3162856101989746
bi 2 loss 4.337119102478027
bi 3 loss 2.8529834747314453
Layer  1  loss:  4.53610897064209 0.0 10.357192993164062
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([405, 152, 511, 102], device='cuda:0') tensor(406, device='cuda:0')
bi 0 loss 4.671919345855713
bi 1 loss 3.879788637161255
bi 2 loss 4.627756118774414
bi 3 loss 3.4125287532806396
Layer  2  loss:  4.800960540771484 0.0 10.971478462219238
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([404, 154, 328,  91], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 4.875982761383057
bi 1 loss 4.160958290100098
bi 2 loss 4.9671478271484375
bi 3 loss 3.5455539226531982
Layer  3  loss:  4.964853763580322 0.0 11.005650520324707
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([422, 149, 438,  94], device='cuda:0') tensor(438, device='cuda:0')
bi 0 loss 5.053048610687256
bi 1 loss 4.044565677642822
bi 2 loss 5.20491361618042
bi 3 loss 3.3263967037200928
Layer  4  loss:  5.033729076385498 0.0 10.797560691833496
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([423, 120, 401,  96], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 5.095548152923584
bi 1 loss 4.163478374481201
bi 2 loss 5.2459588050842285
bi 3 loss 3.8073983192443848
Layer  5  loss:  5.147144317626953 0.0 10.895974159240723
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([429, 136, 570,  92], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 5.265399932861328
bi 1 loss 4.2992634773254395
bi 2 loss 5.342514514923096
bi 3 loss 3.5325510501861572
Layer  6  loss:  5.2297868728637695 0.0 11.395851135253906
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1019
Curr loss timestep torch.Size([708, 4]) tensor([641, 131, 662, 108], device='cuda:0') tensor(662, device='cuda:0')
bi 0 loss 5.339406490325928
bi 1 loss 4.245874404907227
bi 2 loss 5.415907859802246
bi 3 loss 3.9597208499908447
Epoch 0: :   3%|▎         | 15303/600000 [02:05<1:20:00, v_num=12, reduced_train_loss=0.227, global_step=15301.0, consumed_samples=61208.0, train_step_timing in s=0.332]Epoch 0: :   3%|▎         | 15303/600000 [02:05<1:20:00, v_num=12, reduced_train_loss=37.40, global_step=15302.0, consumed_samples=61212.0, train_step_timing in s=0.428]loss mask original None

First layer loss:  3.704678535461426 torch.Size([556, 4]) 14.14278507232666 0.0
Max loss timestep torch.Size([556, 4]) tensor([171, 384, 206, 384], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 3.82598876953125
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 1 loss 3.6192426681518555
speech mask sum tensor(340, device='cuda:0') loss mask sum tensor(340, device='cuda:0')
bi 2 loss 3.5615034103393555
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 3 loss 3.7839548587799072
speech mask sum tensor(321, device='cuda:0') loss mask sum tensor(321, device='cuda:0')
logits torch.Size([556, 4, 257024]) labels torch.Size([556, 4]) 0 257022
Layer  0  loss:  4.118780612945557 0.0 11.334465026855469
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([131, 447, 191, 445], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 4.397597312927246
bi 1 loss 4.077237606048584
bi 2 loss 3.901195526123047
bi 3 loss 4.107481479644775
Layer  1  loss:  4.449026584625244 0.0 9.6741361618042
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1021
Curr loss timestep torch.Size([556, 4]) tensor([189, 373, 159, 204], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.6536865234375
bi 1 loss 4.6247878074646
bi 2 loss 4.18135929107666
bi 3 loss 4.250855445861816
Layer  2  loss:  4.740197658538818 0.0 10.916991233825684
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([149, 337, 169, 358], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.544234275817871
bi 1 loss 4.9656147956848145
bi 2 loss 4.555810451507568
bi 3 loss 4.629626274108887
Layer  3  loss:  4.912181377410889 0.0 10.802070617675781
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1021
Curr loss timestep torch.Size([556, 4]) tensor([199, 418, 170, 440], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 5.122838020324707
bi 1 loss 5.067103862762451
bi 2 loss 4.3404059410095215
bi 3 loss 4.814180374145508
Layer  4  loss:  5.1478166580200195 0.0 10.636150360107422
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([ 99, 346, 159, 277], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 5.13752555847168
bi 1 loss 5.378163814544678
bi 2 loss 4.781191349029541
bi 3 loss 5.005084037780762
Layer  5  loss:  5.0686750411987305 0.0 9.990997314453125
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([128, 510, 174, 273], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 5.161077499389648
bi 1 loss 5.251678466796875
bi 2 loss 4.665375709533691
bi 3 loss 4.944211483001709
Layer  6  loss:  5.123875617980957 0.0 10.019368171691895
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([183, 426, 179, 302], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 5.300709247589111
bi 1 loss 5.3071699142456055
bi 2 loss 4.624233245849609
bi 3 loss 4.990421295166016
Epoch 0: :   3%|▎         | 15304/600000 [02:06<1:20:14, v_num=12, reduced_train_loss=37.40, global_step=15302.0, consumed_samples=61212.0, train_step_timing in s=0.428]Epoch 0: :   3%|▎         | 15304/600000 [02:06<1:20:14, v_num=12, reduced_train_loss=37.30, global_step=15303.0, consumed_samples=61216.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  0.23180139064788818 torch.Size([691, 4]) 10.100269317626953 0.0
Max loss timestep torch.Size([691, 4]) tensor([ 86, 238, 582, 158], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 0.033015962690114975
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 1 loss 0.46390554308891296
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 2 loss 0.2610817551612854
speech mask sum tensor(477, device='cuda:0') loss mask sum tensor(477, device='cuda:0')
bi 3 loss 0.12779471278190613
speech mask sum tensor(414, device='cuda:0') loss mask sum tensor(414, device='cuda:0')
logits torch.Size([691, 4, 257024]) labels torch.Size([691, 4]) 0 257022
Layer  0  loss:  0.20693962275981903 0.0 10.195383071899414
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([ 56, 226, 339, 471], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.015967054292559624
bi 1 loss 0.08305840939283371
bi 2 loss 0.3531383275985718
bi 3 loss 0.1326863169670105
Layer  1  loss:  0.22869810461997986 0.0 11.977165222167969
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([ 83, 234, 545, 513], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.028420977294445038
bi 1 loss 0.06888215988874435
bi 2 loss 0.43173933029174805
bi 3 loss 0.10747998207807541
Layer  2  loss:  0.2343425154685974 0.0 11.205836296081543
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([ 45, 147, 444, 541], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.011341179721057415
bi 1 loss 0.06770184636116028
bi 2 loss 0.41668638586997986
bi 3 loss 0.14448918402194977
Layer  3  loss:  0.2524164915084839 0.0 11.858967781066895
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([ 88,  93, 576, 413], device='cuda:0') tensor(576, device='cuda:0')
bi 0 loss 0.03959210216999054
bi 1 loss 0.07874172925949097
bi 2 loss 0.4406968057155609
bi 3 loss 0.15706045925617218
Layer  4  loss:  0.25519630312919617 0.0 14.400749206542969
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([ 61, 249, 339, 541], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.020723607391119003
bi 1 loss 0.10951314121484756
bi 2 loss 0.44768068194389343
bi 3 loss 0.14607828855514526
Layer  5  loss:  0.256147176027298 0.0 17.759963989257812
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([ 47, 183, 658, 416], device='cuda:0') tensor(658, device='cuda:0')
bi 0 loss 0.07664642482995987
bi 1 loss 0.07719609886407852
bi 2 loss 0.45848867297172546
bi 3 loss 0.1406911164522171
Layer  6  loss:  0.2695930600166321 0.0 15.102438926696777
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([ 86, 241, 654, 541], device='cuda:0') tensor(654, device='cuda:0')
bi 0 loss 0.02816472388803959
bi 1 loss 0.09709061682224274
bi 2 loss 0.4961274564266205
bi 3 loss 0.1350734978914261
Epoch 0: :   3%|▎         | 15305/600000 [02:06<1:20:34, v_num=12, reduced_train_loss=37.30, global_step=15303.0, consumed_samples=61216.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15305/600000 [02:06<1:20:34, v_num=12, reduced_train_loss=1.940, global_step=15304.0, consumed_samples=61220.0, train_step_timing in s=0.476]loss mask original None

First layer loss:  0.10870463401079178 torch.Size([709, 4]) 11.157044410705566 0.0
Max loss timestep torch.Size([709, 4]) tensor([696, 361, 160, 135], device='cuda:0') tensor(696, device='cuda:0')
bi 0 loss 0.17367374897003174
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 1 loss 0.12430571764707565
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
bi 2 loss 0.04917554184794426
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 3 loss 0.02974294126033783
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
logits torch.Size([709, 4, 257024]) labels torch.Size([709, 4]) 0 257022
Layer  0  loss:  0.10265228152275085 0.0 12.554720878601074
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([665, 358, 178, 318], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 0.13636523485183716
bi 1 loss 0.14015358686447144
bi 2 loss 0.04674600809812546
bi 3 loss 0.039266813546419144
Layer  1  loss:  0.12982594966888428 0.0 14.279812812805176
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([661, 359, 164, 166], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.1725342720746994
bi 1 loss 0.19700323045253754
bi 2 loss 0.03224582597613335
bi 3 loss 0.04109654948115349
Layer  2  loss:  0.1523032784461975 0.0 16.73458480834961
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1022
Curr loss timestep torch.Size([709, 4]) tensor([677, 359, 152, 339], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.22958631813526154
bi 1 loss 0.19936080276966095
bi 2 loss 0.048372674733400345
bi 3 loss 0.04246223345398903
Layer  3  loss:  0.12573036551475525 0.0 11.756826400756836
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1019
Curr loss timestep torch.Size([709, 4]) tensor([522, 359, 158, 339], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.20133157074451447
bi 1 loss 0.15055449306964874
bi 2 loss 0.02311478555202484
bi 3 loss 0.0468730553984642
Layer  4  loss:  0.12180336564779282 0.0 21.313383102416992
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([677, 359, 145, 298], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.15084850788116455
bi 1 loss 0.1665411740541458
bi 2 loss 0.04845287278294563
bi 3 loss 0.06728436797857285
Layer  5  loss:  0.1410275101661682 0.0 11.337759971618652
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1020
Curr loss timestep torch.Size([709, 4]) tensor([665, 361, 143, 128], device='cuda:0') tensor(665, device='cuda:0')
bi 0 loss 0.23315200209617615
bi 1 loss 0.1598515808582306
bi 2 loss 0.03705117106437683
bi 3 loss 0.046216968446969986
Layer  6  loss:  0.14246110618114471 0.0 15.810888290405273
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([677, 359, 171, 316], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.1912684589624405
bi 1 loss 0.1765507459640503
bi 2 loss 0.024976739659905434
bi 3 loss 0.10126078128814697
Epoch 0: :   3%|▎         | 15306/600000 [02:07<1:20:53, v_num=12, reduced_train_loss=1.940, global_step=15304.0, consumed_samples=61220.0, train_step_timing in s=0.476]Epoch 0: :   3%|▎         | 15306/600000 [02:07<1:20:53, v_num=12, reduced_train_loss=1.020, global_step=15305.0, consumed_samples=61224.0, train_step_timing in s=0.480]loss mask original None

First layer loss:  0.07208172976970673 torch.Size([497, 4]) 9.455546379089355 0.0
Max loss timestep torch.Size([497, 4]) tensor([401, 456, 105, 270], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.0982523038983345
speech mask sum tensor(348, device='cuda:0') loss mask sum tensor(348, device='cuda:0')
bi 1 loss 0.07332129776477814
speech mask sum tensor(437, device='cuda:0') loss mask sum tensor(437, device='cuda:0')
bi 2 loss 0.042393121868371964
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.04523880034685135
speech mask sum tensor(219, device='cuda:0') loss mask sum tensor(219, device='cuda:0')
logits torch.Size([497, 4, 257024]) labels torch.Size([497, 4]) 0 257023
Layer  0  loss:  0.07199208438396454 0.0 6.745422840118408
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([401, 467, 139, 312], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.07714071869850159
bi 1 loss 0.08795004338026047
bi 2 loss 0.028012869879603386
bi 3 loss 0.05747159197926521
Layer  1  loss:  0.07631968706846237 0.0 5.821388244628906
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([401, 456, 144, 181], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.08237218856811523
bi 1 loss 0.09346558153629303
bi 2 loss 0.03660900145769119
bi 3 loss 0.05551706999540329
Layer  2  loss:  0.07389453798532486 0.0 8.413805961608887
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([352, 456, 102, 167], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.07375136762857437
bi 1 loss 0.10438307374715805
bi 2 loss 0.021580064669251442
bi 3 loss 0.04362180083990097
Layer  3  loss:  0.06842582672834396 0.0 4.8332343101501465
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([427, 456, 131, 274], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.07172033190727234
bi 1 loss 0.0808974876999855
bi 2 loss 0.03970305249094963
bi 3 loss 0.0549609400331974
Layer  4  loss:  0.07663621753454208 0.0 9.068984985351562
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([401, 456, 180, 134], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.09224750101566315
bi 1 loss 0.09295142441987991
bi 2 loss 0.035952840000391006
bi 3 loss 0.04286595433950424
Layer  5  loss:  0.06385808438062668 0.0 4.454333305358887
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([401, 456, 202, 280], device='cuda:0') tensor(401, device='cuda:0')
bi 0 loss 0.08823113143444061
bi 1 loss 0.06515073776245117
bi 2 loss 0.023674199357628822
bi 3 loss 0.045851919800043106
Layer  6  loss:  0.08785213530063629 0.0 9.875715255737305
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([401, 456, 192, 303], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.11557269096374512
bi 1 loss 0.1003875732421875
bi 2 loss 0.024114640429615974
bi 3 loss 0.05575127899646759
Epoch 0: :   3%|▎         | 15307/600000 [02:07<1:21:08, v_num=12, reduced_train_loss=1.020, global_step=15305.0, consumed_samples=61224.0, train_step_timing in s=0.480]Epoch 0: :   3%|▎         | 15307/600000 [02:07<1:21:08, v_num=12, reduced_train_loss=0.591, global_step=15306.0, consumed_samples=61228.0, train_step_timing in s=0.348]loss mask original None

First layer loss:  0.13238471746444702 torch.Size([599, 4]) 11.89736270904541 0.0
Max loss timestep torch.Size([599, 4]) tensor([463, 522, 150, 326], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.13059258460998535
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 1 loss 0.18819426000118256
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
bi 2 loss 0.04951737821102142
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 3 loss 0.12925809621810913
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257022
Layer  0  loss:  0.140273317694664 0.0 12.067829132080078
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([463, 547, 330, 326], device='cuda:0') tensor(547, device='cuda:0')
bi 0 loss 0.11221318691968918
bi 1 loss 0.23374730348587036
bi 2 loss 0.07043525576591492
bi 3 loss 0.10199026018381119
Layer  1  loss:  0.1589743047952652 0.0 10.344985961914062
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([463, 566, 332, 329], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.16041520237922668
bi 1 loss 0.2280014455318451
bi 2 loss 0.06992369145154953
bi 3 loss 0.13233979046344757
Layer  2  loss:  0.16494129598140717 0.0 10.93826961517334
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([463, 547, 270, 326], device='cuda:0') tensor(547, device='cuda:0')
bi 0 loss 0.16706974804401398
bi 1 loss 0.2384905219078064
bi 2 loss 0.07127898186445236
bi 3 loss 0.1339939385652542
Layer  3  loss:  0.1613389253616333 0.0 14.750227928161621
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([463, 547, 115, 326], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.16737091541290283
bi 1 loss 0.22543630003929138
bi 2 loss 0.07007721811532974
bi 3 loss 0.13769614696502686
Layer  4  loss:  0.1726328730583191 0.0 14.672454833984375
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([463, 547, 330, 326], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.15723630785942078
bi 1 loss 0.2704285979270935
bi 2 loss 0.08043557405471802
bi 3 loss 0.12835395336151123
Layer  5  loss:  0.18811209499835968 0.0 11.5315523147583
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([463, 522, 270, 326], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.1974109411239624
bi 1 loss 0.2494051307439804
bi 2 loss 0.11162541061639786
bi 3 loss 0.14610102772712708
Layer  6  loss:  0.19507534801959991 0.0 11.09797477722168
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([402, 522, 270, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.1686231791973114
bi 1 loss 0.30430909991264343
bi 2 loss 0.07596515119075775
bi 3 loss 0.18223567306995392
Epoch 0: :   3%|▎         | 15308/600000 [02:07<1:21:24, v_num=12, reduced_train_loss=0.591, global_step=15306.0, consumed_samples=61228.0, train_step_timing in s=0.348]Epoch 0: :   3%|▎         | 15308/600000 [02:07<1:21:24, v_num=12, reduced_train_loss=1.310, global_step=15307.0, consumed_samples=61232.0, train_step_timing in s=0.410]loss mask original None

First layer loss:  3.6671791076660156 torch.Size([676, 4]) 10.693073272705078 0.0
Max loss timestep torch.Size([676, 4]) tensor([221, 210, 265,  85], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 3.9140000343322754
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 1 loss 3.5596132278442383
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
bi 2 loss 3.5530474185943604
speech mask sum tensor(433, device='cuda:0') loss mask sum tensor(433, device='cuda:0')
bi 3 loss 3.8869762420654297
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
logits torch.Size([676, 4, 257024]) labels torch.Size([676, 4]) 0 257022
Layer  0  loss:  4.230282306671143 0.0 10.657907485961914
logits torch.Size([676, 4, 1024]) labels torch.Size([676, 4]) 0 1023
Curr loss timestep torch.Size([676, 4]) tensor([227, 521, 498,  97], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 4.403112411499023
bi 1 loss 4.27762508392334
bi 2 loss 3.992992401123047
bi 3 loss 4.45711612701416
Layer  1  loss:  4.593133926391602 0.0 11.405898094177246
logits torch.Size([676, 4, 1024]) labels torch.Size([676, 4]) 0 1022
Curr loss timestep torch.Size([676, 4]) tensor([187, 164, 414, 150], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 4.787294387817383
bi 1 loss 4.692161560058594
bi 2 loss 4.308445930480957
bi 3 loss 4.785299777984619
Layer  2  loss:  4.801177024841309 0.0 10.175790786743164
logits torch.Size([676, 4, 1024]) labels torch.Size([676, 4]) 0 1023
Curr loss timestep torch.Size([676, 4]) tensor([243, 310, 653,  86], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 5.073160171508789
bi 1 loss 4.717963695526123
bi 2 loss 4.647979736328125
bi 3 loss 5.024872779846191
Layer  3  loss:  4.851922512054443 0.0 10.786280632019043
logits torch.Size([676, 4, 1024]) labels torch.Size([676, 4]) 0 1023
Curr loss timestep torch.Size([676, 4]) tensor([348, 171, 251,  89], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 5.182363986968994
bi 1 loss 4.862060070037842
bi 2 loss 4.6046648025512695
bi 3 loss 5.009607315063477
Layer  4  loss:  4.957815170288086 0.0 9.719839096069336
logits torch.Size([676, 4, 1024]) labels torch.Size([676, 4]) 0 1022
Curr loss timestep torch.Size([676, 4]) tensor([369, 172, 368, 140], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 5.294208526611328
bi 1 loss 4.935235500335693
bi 2 loss 4.651829719543457
bi 3 loss 5.3119306564331055
Layer  5  loss:  5.025898456573486 0.0 10.018533706665039
logits torch.Size([676, 4, 1024]) labels torch.Size([676, 4]) 0 1022
Curr loss timestep torch.Size([676, 4]) tensor([191, 178, 422, 237], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 5.324737548828125
bi 1 loss 4.958213806152344
bi 2 loss 4.809376239776611
bi 3 loss 5.324979782104492
Layer  6  loss:  5.053535461425781 0.0 10.201790809631348
logits torch.Size([676, 4, 1024]) labels torch.Size([676, 4]) 0 1021
Curr loss timestep torch.Size([676, 4]) tensor([255, 207, 640, 112], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 5.28623628616333
bi 1 loss 5.053713798522949
bi 2 loss 4.809848785400391
bi 3 loss 5.333850860595703
Epoch 0: :   3%|▎         | 15309/600000 [02:08<1:21:41, v_num=12, reduced_train_loss=1.310, global_step=15307.0, consumed_samples=61232.0, train_step_timing in s=0.410]Epoch 0: :   3%|▎         | 15309/600000 [02:08<1:21:41, v_num=12, reduced_train_loss=37.20, global_step=15308.0, consumed_samples=61236.0, train_step_timing in s=0.408]loss mask original None

First layer loss:  0.15396565198898315 torch.Size([610, 4]) 9.875815391540527 0.0
Max loss timestep torch.Size([610, 4]) tensor([533, 198, 312, 106], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.2041473388671875
speech mask sum tensor(420, device='cuda:0') loss mask sum tensor(420, device='cuda:0')
bi 1 loss 0.15235741436481476
speech mask sum tensor(264, device='cuda:0') loss mask sum tensor(264, device='cuda:0')
bi 2 loss 0.1554592251777649
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
bi 3 loss 0.04783882945775986
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
logits torch.Size([610, 4, 257024]) labels torch.Size([610, 4]) 0 257023
Layer  0  loss:  0.1503879427909851 0.0 10.68599796295166
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([533, 208, 312, 171], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.2652890980243683
bi 1 loss 0.05954949930310249
bi 2 loss 0.1394820362329483
bi 3 loss 0.0455457828938961
Layer  1  loss:  0.17541898787021637 0.0 16.35770034790039
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([519, 204, 312, 184], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.25510379672050476
bi 1 loss 0.07001500576734543
bi 2 loss 0.2289363443851471
bi 3 loss 0.0628969669342041
Layer  2  loss:  0.19438056647777557 0.0 16.43882179260254
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1022
Curr loss timestep torch.Size([610, 4]) tensor([530, 176, 312, 188], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.3106006383895874
bi 1 loss 0.05785277113318443
bi 2 loss 0.2437243014574051
bi 3 loss 0.052603304386138916
Layer  3  loss:  0.16700726747512817 0.0 10.283940315246582
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1020
Curr loss timestep torch.Size([610, 4]) tensor([519, 279, 312, 100], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.29130885004997253
bi 1 loss 0.06413666903972626
bi 2 loss 0.16239632666110992
bi 3 loss 0.048386186361312866
Layer  4  loss:  0.1699499636888504 0.0 14.109496116638184
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([493, 259, 313, 176], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.28249841928482056
bi 1 loss 0.06338607519865036
bi 2 loss 0.19536323845386505
bi 3 loss 0.03381014242768288
Layer  5  loss:  0.182097390294075 0.0 16.308835983276367
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([530, 144, 312,  57], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.3024706542491913
bi 1 loss 0.08799992501735687
bi 2 loss 0.18468542397022247
bi 3 loss 0.04880548641085625
Layer  6  loss:  0.17935720086097717 0.0 20.218826293945312
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([493, 295, 313,  94], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.2906772196292877
bi 1 loss 0.0445282980799675
bi 2 loss 0.19201809167861938
bi 3 loss 0.10336508601903915
Epoch 0: :   3%|▎         | 15310/600000 [02:08<1:21:58, v_num=12, reduced_train_loss=37.20, global_step=15308.0, consumed_samples=61236.0, train_step_timing in s=0.408]Epoch 0: :   3%|▎         | 15310/600000 [02:08<1:21:58, v_num=12, reduced_train_loss=1.370, global_step=15309.0, consumed_samples=61240.0, train_step_timing in s=0.414]loss mask original None

First layer loss:  0.11098391562700272 torch.Size([542, 4]) 10.024075508117676 0.0
Max loss timestep torch.Size([542, 4]) tensor([266, 449, 300, 349], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.028112610802054405
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 1 loss 0.11111018061637878
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
bi 2 loss 0.2209717184305191
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 3 loss 0.05968193709850311
speech mask sum tensor(329, device='cuda:0') loss mask sum tensor(329, device='cuda:0')
logits torch.Size([542, 4, 257024]) labels torch.Size([542, 4]) 0 257023
Layer  0  loss:  0.11365754902362823 0.0 9.253853797912598
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1023
Curr loss timestep torch.Size([542, 4]) tensor([242, 455, 270, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.04632679000496864
bi 1 loss 0.08854862302541733
bi 2 loss 0.18048162758350372
bi 3 loss 0.1191275492310524
Layer  1  loss:  0.09238538891077042 0.0 9.004901885986328
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1022
Curr loss timestep torch.Size([542, 4]) tensor([261, 325, 301, 349], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.030363036319613457
bi 1 loss 0.07679293304681778
bi 2 loss 0.16592954099178314
bi 3 loss 0.0799129456281662
Layer  2  loss:  0.11188486218452454 0.0 11.909018516540527
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1023
Curr loss timestep torch.Size([542, 4]) tensor([229, 449, 301, 349], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.047905322164297104
bi 1 loss 0.09968990087509155
bi 2 loss 0.17845778167247772
bi 3 loss 0.10005021840333939
Layer  3  loss:  0.12867312133312225 0.0 9.668214797973633
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1022
Curr loss timestep torch.Size([542, 4]) tensor([258, 455, 272, 349], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.04930677264928818
bi 1 loss 0.12495358288288116
bi 2 loss 0.1746399849653244
bi 3 loss 0.12310730665922165
Layer  4  loss:  0.10880404710769653 0.0 8.148271560668945
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1022
Curr loss timestep torch.Size([542, 4]) tensor([249, 456, 300, 346], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 0.03808070346713066
bi 1 loss 0.08834117650985718
bi 2 loss 0.16028903424739838
bi 3 loss 0.11909906566143036
Layer  5  loss:  0.13325081765651703 0.0 11.451263427734375
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1023
Curr loss timestep torch.Size([542, 4]) tensor([221, 455, 301, 346], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.04608762636780739
bi 1 loss 0.1240864247083664
bi 2 loss 0.22985951602458954
bi 3 loss 0.10368136316537857
Layer  6  loss:  0.12557177245616913 0.0 13.17401123046875
logits torch.Size([542, 4, 1024]) labels torch.Size([542, 4]) 0 1021
Curr loss timestep torch.Size([542, 4]) tensor([239, 455, 301, 391], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.030164020135998726
bi 1 loss 0.12410615384578705
bi 2 loss 0.17376138269901276
bi 3 loss 0.11960480362176895
Epoch 0: :   3%|▎         | 15311/600000 [02:09<1:22:13, v_num=12, reduced_train_loss=1.370, global_step=15309.0, consumed_samples=61240.0, train_step_timing in s=0.414]Epoch 0: :   3%|▎         | 15311/600000 [02:09<1:22:13, v_num=12, reduced_train_loss=0.925, global_step=15310.0, consumed_samples=61244.0, train_step_timing in s=0.370]loss mask original None

First layer loss:  0.21399559080600739 torch.Size([597, 4]) 13.43779468536377 0.0
Max loss timestep torch.Size([597, 4]) tensor([125, 469, 420, 578], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.08563457429409027
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 1 loss 0.15757867693901062
speech mask sum tensor(497, device='cuda:0') loss mask sum tensor(497, device='cuda:0')
bi 2 loss 0.05959032103419304
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
bi 3 loss 0.4364667236804962
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
logits torch.Size([597, 4, 257024]) labels torch.Size([597, 4]) 0 257023
Layer  0  loss:  0.2193572223186493 0.0 13.783082962036133
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([173, 524, 419, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.06503503769636154
bi 1 loss 0.14974665641784668
bi 2 loss 0.07421968132257462
bi 3 loss 0.4627363681793213
Layer  1  loss:  0.2108609527349472 0.0 15.478679656982422
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([137, 469, 448, 578], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.05432984232902527
bi 1 loss 0.1379152238368988
bi 2 loss 0.07593158632516861
bi 3 loss 0.4524516761302948
Layer  2  loss:  0.20888590812683105 0.0 14.969962120056152
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([120, 469, 356, 561], device='cuda:0') tensor(561, device='cuda:0')
bi 0 loss 0.06315230578184128
bi 1 loss 0.14119690656661987
bi 2 loss 0.08356638252735138
bi 3 loss 0.43336212635040283
Layer  3  loss:  0.24350836873054504 0.0 17.900588989257812
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([181, 468, 341, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.09837005287408829
bi 1 loss 0.15497124195098877
bi 2 loss 0.07693356275558472
bi 3 loss 0.5179082751274109
Layer  4  loss:  0.23167914152145386 0.0 18.204051971435547
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([130, 524, 233, 584], device='cuda:0') tensor(524, device='cuda:0')
bi 0 loss 0.057872187346220016
bi 1 loss 0.1744198054075241
bi 2 loss 0.07140031456947327
bi 3 loss 0.4798016846179962
Layer  5  loss:  0.22570006549358368 0.0 19.04792594909668
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1021
Curr loss timestep torch.Size([597, 4]) tensor([264, 524, 198, 584], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.06540462374687195
bi 1 loss 0.15700897574424744
bi 2 loss 0.05846438184380531
bi 3 loss 0.48503226041793823
Layer  6  loss:  0.25322768092155457 0.0 20.50766944885254
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([258, 524, 298, 585], device='cuda:0') tensor(585, device='cuda:0')
bi 0 loss 0.049862608313560486
bi 1 loss 0.1635412573814392
bi 2 loss 0.07139763981103897
bi 3 loss 0.5655552744865417
Epoch 0: :   3%|▎         | 15312/600000 [02:09<1:22:30, v_num=12, reduced_train_loss=0.925, global_step=15310.0, consumed_samples=61244.0, train_step_timing in s=0.370]Epoch 0: :   3%|▎         | 15312/600000 [02:09<1:22:30, v_num=12, reduced_train_loss=1.810, global_step=15311.0, consumed_samples=61248.0, train_step_timing in s=0.407]loss mask original None

First layer loss:  0.11469275504350662 torch.Size([539, 4]) 9.393850326538086 0.0
Max loss timestep torch.Size([539, 4]) tensor([288, 297, 327, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.041614096611738205
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 1 loss 0.16892464458942413
speech mask sum tensor(346, device='cuda:0') loss mask sum tensor(346, device='cuda:0')
bi 2 loss 0.08127333968877792
speech mask sum tensor(376, device='cuda:0') loss mask sum tensor(376, device='cuda:0')
bi 3 loss 0.13010191917419434
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
logits torch.Size([539, 4, 257024]) labels torch.Size([539, 4]) 0 257023
Layer  0  loss:  0.12241831421852112 0.0 5.226688861846924
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([289, 296, 260, 481], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.026839017868041992
bi 1 loss 0.16792307794094086
bi 2 loss 0.11689603328704834
bi 3 loss 0.12812715768814087
Layer  1  loss:  0.1315949559211731 0.0 10.01819133758545
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([292, 429, 147, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.034628044813871384
bi 1 loss 0.19954289495944977
bi 2 loss 0.08296379446983337
bi 3 loss 0.15983346104621887
Layer  2  loss:  0.13740593194961548 0.0 13.642991065979004
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([291, 450, 361, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.054961688816547394
bi 1 loss 0.19264551997184753
bi 2 loss 0.08060696721076965
bi 3 loss 0.17878063023090363
Layer  3  loss:  0.13426901400089264 0.0 9.464424133300781
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([262, 297, 308, 480], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.03984352573752403
bi 1 loss 0.273528516292572
bi 2 loss 0.07527237385511398
bi 3 loss 0.10744710266590118
Layer  4  loss:  0.1557539403438568 0.0 18.01442527770996
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([276, 297, 260, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.034103281795978546
bi 1 loss 0.23962917923927307
bi 2 loss 0.09783921390771866
bi 3 loss 0.1893879622220993
Layer  5  loss:  0.13472798466682434 0.0 21.2741641998291
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([262, 429, 359, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.03570088371634483
bi 1 loss 0.20803512632846832
bi 2 loss 0.08183092623949051
bi 3 loss 0.16320469975471497
Layer  6  loss:  0.13849058747291565 0.0 16.063081741333008
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([306, 297, 260, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.056578051298856735
bi 1 loss 0.20788104832172394
bi 2 loss 0.1059693917632103
bi 3 loss 0.14320839941501617
Epoch 0: :   3%|▎         | 15313/600000 [02:10<1:22:45, v_num=12, reduced_train_loss=1.810, global_step=15311.0, consumed_samples=61248.0, train_step_timing in s=0.407]Epoch 0: :   3%|▎         | 15313/600000 [02:10<1:22:45, v_num=12, reduced_train_loss=1.070, global_step=15312.0, consumed_samples=61252.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  0.07116109877824783 torch.Size([506, 4]) 6.728752136230469 0.0
Max loss timestep torch.Size([506, 4]) tensor([303, 439, 367, 199], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.056748926639556885
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
bi 1 loss 0.06402242928743362
speech mask sum tensor(329, device='cuda:0') loss mask sum tensor(329, device='cuda:0')
bi 2 loss 0.1144922599196434
speech mask sum tensor(251, device='cuda:0') loss mask sum tensor(251, device='cuda:0')
bi 3 loss 0.033090561628341675
speech mask sum tensor(185, device='cuda:0') loss mask sum tensor(185, device='cuda:0')
logits torch.Size([506, 4, 257024]) labels torch.Size([506, 4]) 0 257023
Layer  0  loss:  0.10795921832323074 0.0 11.87036418914795
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([282, 267, 367, 100], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.06141044944524765
bi 1 loss 0.12484622746706009
bi 2 loss 0.1568801999092102
bi 3 loss 0.037470199167728424
Layer  1  loss:  0.11517743021249771 0.0 10.097346305847168
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([274, 272, 367,  75], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.08812465518712997
bi 1 loss 0.12421548366546631
bi 2 loss 0.1727612316608429
bi 3 loss 0.03603896126151085
Layer  2  loss:  0.13333146274089813 0.0 14.62944507598877
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([260, 439, 366,  83], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.11361260712146759
bi 1 loss 0.08829708397388458
bi 2 loss 0.27645403146743774
bi 3 loss 0.030215760692954063
Layer  3  loss:  0.11390398442745209 0.0 14.525336265563965
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([312, 428, 367, 133], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.08649157732725143
bi 1 loss 0.11175351589918137
bi 2 loss 0.16860146820545197
bi 3 loss 0.05877918377518654
Layer  4  loss:  0.1192159503698349 0.0 10.978941917419434
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([258, 339, 367, 217], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.08579054474830627
bi 1 loss 0.09932304918766022
bi 2 loss 0.22678180038928986
bi 3 loss 0.027262192219495773
Layer  5  loss:  0.12445977330207825 0.0 14.052035331726074
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([251, 439, 366, 232], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.0722597986459732
bi 1 loss 0.12400750815868378
bi 2 loss 0.21574366092681885
bi 3 loss 0.030476724728941917
Layer  6  loss:  0.13747353851795197 0.0 16.610219955444336
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([288, 439, 367, 217], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.05112500861287117
bi 1 loss 0.14838634431362152
bi 2 loss 0.23915638029575348
bi 3 loss 0.02818268910050392
Epoch 0: :   3%|▎         | 15314/600000 [02:10<1:23:00, v_num=12, reduced_train_loss=1.070, global_step=15312.0, consumed_samples=61252.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15314/600000 [02:10<1:23:00, v_num=12, reduced_train_loss=0.923, global_step=15313.0, consumed_samples=61256.0, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.08826259523630142 torch.Size([575, 4]) 5.0773234367370605 0.0
Max loss timestep torch.Size([575, 4]) tensor([109, 313, 516, 285], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.07071826606988907
speech mask sum tensor(68, device='cuda:0') loss mask sum tensor(68, device='cuda:0')
bi 1 loss 0.14204701781272888
speech mask sum tensor(222, device='cuda:0') loss mask sum tensor(222, device='cuda:0')
bi 2 loss 0.06373947113752365
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 3 loss 0.0789649710059166
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
logits torch.Size([575, 4, 257024]) labels torch.Size([575, 4]) 0 257022
Layer  0  loss:  0.1152237132191658 0.0 12.001118659973145
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([ 98, 455, 260, 278], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.05228177830576897
bi 1 loss 0.1821850687265396
bi 2 loss 0.08405802398920059
bi 3 loss 0.12047888338565826
Layer  1  loss:  0.11395704746246338 0.0 7.001688003540039
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([102, 455, 261, 279], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.04702606797218323
bi 1 loss 0.16781741380691528
bi 2 loss 0.11250665783882141
bi 3 loss 0.07579563558101654
Layer  2  loss:  0.09463638067245483 0.0 6.698683738708496
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([117, 454, 261, 268], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.031925003975629807
bi 1 loss 0.13035669922828674
bi 2 loss 0.08311531692743301
bi 3 loss 0.09795447438955307
Layer  3  loss:  0.11346224695444107 0.0 11.59067153930664
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([125, 455, 261, 311], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.057484909892082214
bi 1 loss 0.162473663687706
bi 2 loss 0.09979086369276047
bi 3 loss 0.10226410627365112
Layer  4  loss:  0.11469341814517975 0.0 9.04162311553955
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([101, 454, 536, 320], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.030448485165834427
bi 1 loss 0.19828933477401733
bi 2 loss 0.08132357895374298
bi 3 loss 0.11201120167970657
Layer  5  loss:  0.12634681165218353 0.0 9.917558670043945
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([117, 455, 259, 276], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.05641300603747368
bi 1 loss 0.22478966414928436
bi 2 loss 0.10861886292695999
bi 3 loss 0.06779419630765915
Layer  6  loss:  0.12830275297164917 0.0 18.16446876525879
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1021
Curr loss timestep torch.Size([575, 4]) tensor([137, 455, 261, 349], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.028018893674016
bi 1 loss 0.2783910632133484
bi 2 loss 0.08727139979600906
bi 3 loss 0.06542112678289413
Epoch 0: :   3%|▎         | 15315/600000 [02:10<1:23:16, v_num=12, reduced_train_loss=0.923, global_step=15313.0, consumed_samples=61256.0, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15315/600000 [02:10<1:23:16, v_num=12, reduced_train_loss=0.895, global_step=15314.0, consumed_samples=61260.0, train_step_timing in s=0.400]loss mask original None

First layer loss:  0.1856587529182434 torch.Size([721, 4]) 11.420276641845703 0.0
Max loss timestep torch.Size([721, 4]) tensor([617, 335, 368, 400], device='cuda:0') tensor(617, device='cuda:0')
bi 0 loss 0.3219994008541107
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
bi 1 loss 0.11600767821073532
speech mask sum tensor(363, device='cuda:0') loss mask sum tensor(363, device='cuda:0')
bi 2 loss 0.08189763128757477
speech mask sum tensor(225, device='cuda:0') loss mask sum tensor(225, device='cuda:0')
bi 3 loss 0.12809711694717407
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
logits torch.Size([721, 4, 257024]) labels torch.Size([721, 4]) 0 257023
Layer  0  loss:  0.20526710152626038 0.0 13.234085083007812
logits torch.Size([721, 4, 1024]) labels torch.Size([721, 4]) 0 1023
Curr loss timestep torch.Size([721, 4]) tensor([520, 272, 294, 400], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.3456535339355469
bi 1 loss 0.15918461978435516
bi 2 loss 0.09408574551343918
bi 3 loss 0.12075814604759216
Layer  1  loss:  0.21170198917388916 0.0 15.613790512084961
logits torch.Size([721, 4, 1024]) labels torch.Size([721, 4]) 0 1023
Curr loss timestep torch.Size([721, 4]) tensor([680, 285, 330, 283], device='cuda:0') tensor(680, device='cuda:0')
bi 0 loss 0.3525422513484955
bi 1 loss 0.17690838873386383
bi 2 loss 0.09299801290035248
bi 3 loss 0.1192222610116005
Layer  2  loss:  0.2293219268321991 0.0 17.578235626220703
logits torch.Size([721, 4, 1024]) labels torch.Size([721, 4]) 0 1023
Curr loss timestep torch.Size([721, 4]) tensor([373, 272, 232, 284], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.3799869120121002
bi 1 loss 0.18863801658153534
bi 2 loss 0.11133182048797607
bi 3 loss 0.12806792557239532
Layer  3  loss:  0.19144602119922638 0.0 12.164286613464355
logits torch.Size([721, 4, 1024]) labels torch.Size([721, 4]) 0 1022
Curr loss timestep torch.Size([721, 4]) tensor([552, 432, 295, 400], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.34892940521240234
bi 1 loss 0.14448490738868713
bi 2 loss 0.050949156284332275
bi 3 loss 0.10219431668519974
Layer  4  loss:  0.2359181046485901 0.0 13.822175979614258
logits torch.Size([721, 4, 1024]) labels torch.Size([721, 4]) 0 1023
Curr loss timestep torch.Size([721, 4]) tensor([589, 420, 368, 284], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.41230833530426025
bi 1 loss 0.1984928399324417
bi 2 loss 0.06376974284648895
bi 3 loss 0.12933985888957977
Layer  5  loss:  0.25514474511146545 0.0 14.394577980041504
logits torch.Size([721, 4, 1024]) labels torch.Size([721, 4]) 0 1022
Curr loss timestep torch.Size([721, 4]) tensor([589, 272, 368, 283], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.4392683207988739
bi 1 loss 0.2058475762605667
bi 2 loss 0.10568176209926605
bi 3 loss 0.13453486561775208
Layer  6  loss:  0.2526099979877472 0.0 17.143386840820312
logits torch.Size([721, 4, 1024]) labels torch.Size([721, 4]) 0 1023
Curr loss timestep torch.Size([721, 4]) tensor([589, 272, 260, 400], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.4645712077617645
bi 1 loss 0.17858588695526123
bi 2 loss 0.08975762873888016
bi 3 loss 0.12648802995681763
Epoch 0: :   3%|▎         | 15316/600000 [02:11<1:23:36, v_num=12, reduced_train_loss=0.895, global_step=15314.0, consumed_samples=61260.0, train_step_timing in s=0.400]Epoch 0: :   3%|▎         | 15316/600000 [02:11<1:23:36, v_num=12, reduced_train_loss=1.770, global_step=15315.0, consumed_samples=61264.0, train_step_timing in s=0.498]loss mask original None

First layer loss:  3.7231087684631348 torch.Size([560, 4]) 11.803254127502441 0.0
Max loss timestep torch.Size([560, 4]) tensor([142,  75, 244, 331], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 3.872274875640869
speech mask sum tensor(290, device='cuda:0') loss mask sum tensor(290, device='cuda:0')
bi 1 loss 3.2831878662109375
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 2 loss 3.6121439933776855
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 3 loss 3.784823417663574
speech mask sum tensor(442, device='cuda:0') loss mask sum tensor(442, device='cuda:0')
logits torch.Size([560, 4, 257024]) labels torch.Size([560, 4]) 0 257023
Layer  0  loss:  4.291579246520996 0.0 11.214448928833008
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([325,  57, 356, 123], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 4.430958271026611
bi 1 loss 3.579298257827759
bi 2 loss 4.131067276000977
bi 3 loss 4.44711971282959
Layer  1  loss:  4.591440677642822 0.0 10.107959747314453
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([229,  76, 246, 457], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 4.701955318450928
bi 1 loss 4.34188175201416
bi 2 loss 4.460514068603516
bi 3 loss 4.649908542633057
Layer  2  loss:  4.817502975463867 0.0 10.418712615966797
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([188,  42, 335, 182], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 4.960360050201416
bi 1 loss 4.6903228759765625
bi 2 loss 4.729144096374512
bi 3 loss 4.803396224975586
Layer  3  loss:  4.882132530212402 0.0 9.358870506286621
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1021
Curr loss timestep torch.Size([560, 4]) tensor([327,  72, 274, 138], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 5.212644100189209
bi 1 loss 4.611088752746582
bi 2 loss 4.756875514984131
bi 3 loss 4.7974534034729
Layer  4  loss:  4.980203628540039 0.0 9.850210189819336
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([275, 101, 421, 464], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 5.246763229370117
bi 1 loss 4.845412731170654
bi 2 loss 4.827487468719482
bi 3 loss 4.92484712600708
Layer  5  loss:  5.076687335968018 0.0 10.6624755859375
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([245,  77, 353, 156], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 5.406305313110352
bi 1 loss 4.640321254730225
bi 2 loss 4.964904308319092
bi 3 loss 5.019737720489502
Layer  6  loss:  5.0920515060424805 0.0 11.639493942260742
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([176,  73, 291, 161], device='cuda:0') tensor(241, device='cuda:0')
bi 0 loss 5.466206073760986
bi 1 loss 4.675253868103027
bi 2 loss 4.941282749176025
bi 3 loss 5.024916648864746
Epoch 0: :   3%|▎         | 15317/600000 [02:11<1:23:51, v_num=12, reduced_train_loss=1.770, global_step=15315.0, consumed_samples=61264.0, train_step_timing in s=0.498]Epoch 0: :   3%|▎         | 15317/600000 [02:11<1:23:51, v_num=12, reduced_train_loss=37.50, global_step=15316.0, consumed_samples=61268.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  0.1658087521791458 torch.Size([622, 4]) 14.468551635742188 0.0
Max loss timestep torch.Size([622, 4]) tensor([118, 367,  96, 122], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.0357523187994957
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 1 loss 0.24727867543697357
speech mask sum tensor(440, device='cuda:0') loss mask sum tensor(440, device='cuda:0')
bi 2 loss 0.04004495590925217
speech mask sum tensor(72, device='cuda:0') loss mask sum tensor(72, device='cuda:0')
bi 3 loss 0.018719252198934555
speech mask sum tensor(84, device='cuda:0') loss mask sum tensor(84, device='cuda:0')
logits torch.Size([622, 4, 257024]) labels torch.Size([622, 4]) 0 257022
Layer  0  loss:  0.19778405129909515 0.0 11.461371421813965
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([ 59, 529,  81,  94], device='cuda:0') tensor(529, device='cuda:0')
bi 0 loss 0.07384262979030609
bi 1 loss 0.2931469976902008
bi 2 loss 0.01924578659236431
bi 3 loss 0.0150763476267457
Layer  1  loss:  0.21571291983127594 0.0 12.393781661987305
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([110, 569, 126, 115], device='cuda:0') tensor(569, device='cuda:0')
bi 0 loss 0.03899708390235901
bi 1 loss 0.3317560851573944
bi 2 loss 0.021599093452095985
bi 3 loss 0.0077682314440608025
Layer  2  loss:  0.218843013048172 0.0 12.261666297912598
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([ 71, 367, 114, 106], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.037009306252002716
bi 1 loss 0.33220458030700684
bi 2 loss 0.05235482007265091
bi 3 loss 0.008028765209019184
Layer  3  loss:  0.18785879015922546 0.0 9.070072174072266
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([ 79, 367,  83, 113], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.04292136803269386
bi 1 loss 0.27991870045661926
bi 2 loss 0.05342491343617439
bi 3 loss 0.012393740937113762
Layer  4  loss:  0.22241245210170746 0.0 12.538483619689941
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([106, 569,  89, 114], device='cuda:0') tensor(569, device='cuda:0')
bi 0 loss 0.028515098616480827
bi 1 loss 0.34089696407318115
bi 2 loss 0.03634488582611084
bi 3 loss 0.0174871776252985
Layer  5  loss:  0.2224484086036682 0.0 12.279959678649902
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([ 74, 366, 119, 108], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.026800507679581642
bi 1 loss 0.3409304618835449
bi 2 loss 0.028987573459744453
bi 3 loss 0.026186540722846985
Layer  6  loss:  0.23587362468242645 0.0 12.503814697265625
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1020
Curr loss timestep torch.Size([622, 4]) tensor([124, 530,  86, 105], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.03240666911005974
bi 1 loss 0.36018261313438416
bi 2 loss 0.04439731314778328
bi 3 loss 0.017720909789204597
Epoch 0: :   3%|▎         | 15318/600000 [02:12<1:24:08, v_num=12, reduced_train_loss=37.50, global_step=15316.0, consumed_samples=61268.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15318/600000 [02:12<1:24:08, v_num=12, reduced_train_loss=1.670, global_step=15317.0, consumed_samples=61272.0, train_step_timing in s=0.423]loss mask original None

First layer loss:  0.13269980251789093 torch.Size([681, 4]) 11.9691162109375 0.0
Max loss timestep torch.Size([681, 4]) tensor([260, 124, 311, 379], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.10358331352472305
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 1 loss 0.050480812788009644
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 2 loss 0.11683124303817749
speech mask sum tensor(299, device='cuda:0') loss mask sum tensor(299, device='cuda:0')
bi 3 loss 0.21263936161994934
speech mask sum tensor(422, device='cuda:0') loss mask sum tensor(422, device='cuda:0')
logits torch.Size([681, 4, 257024]) labels torch.Size([681, 4]) 0 257022
Layer  0  loss:  0.15234962105751038 0.0 7.894646167755127
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1023
Curr loss timestep torch.Size([681, 4]) tensor([450, 156, 311, 381], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.14285911619663239
bi 1 loss 0.047912079840898514
bi 2 loss 0.1325160562992096
bi 3 loss 0.2309245467185974
Layer  1  loss:  0.16000336408615112 0.0 9.969231605529785
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1022
Curr loss timestep torch.Size([681, 4]) tensor([259, 311, 312, 381], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.1452062726020813
bi 1 loss 0.02984050288796425
bi 2 loss 0.12243249267339706
bi 3 loss 0.26949429512023926
Layer  2  loss:  0.19150932133197784 0.0 14.062764167785645
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1023
Curr loss timestep torch.Size([681, 4]) tensor([259, 287, 312, 380], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.17338290810585022
bi 1 loss 0.043720997869968414
bi 2 loss 0.17095014452934265
bi 3 loss 0.30126482248306274
Layer  3  loss:  0.16033466160297394 0.0 13.001082420349121
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1023
Curr loss timestep torch.Size([681, 4]) tensor([302, 303, 313, 381], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.14716386795043945
bi 1 loss 0.04111791402101517
bi 2 loss 0.16668273508548737
bi 3 loss 0.23142270743846893
Layer  4  loss:  0.19760917127132416 0.0 14.34412956237793
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1023
Curr loss timestep torch.Size([681, 4]) tensor([260, 304, 312, 380], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.15621130168437958
bi 1 loss 0.04339779540896416
bi 2 loss 0.1806056946516037
bi 3 loss 0.32757672667503357
Layer  5  loss:  0.210978701710701 0.0 13.251484870910645
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1019
Curr loss timestep torch.Size([681, 4]) tensor([260, 132, 312, 380], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.2036546915769577
bi 1 loss 0.03330596163868904
bi 2 loss 0.1879487931728363
bi 3 loss 0.32976803183555603
Layer  6  loss:  0.21064279973506927 0.0 17.937585830688477
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1021
Curr loss timestep torch.Size([681, 4]) tensor([259, 298, 311, 381], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.2298719584941864
bi 1 loss 0.038348786532878876
bi 2 loss 0.1859467625617981
bi 3 loss 0.3057340383529663
Epoch 0: :   3%|▎         | 15319/600000 [02:12<1:24:27, v_num=12, reduced_train_loss=1.670, global_step=15317.0, consumed_samples=61272.0, train_step_timing in s=0.423]Epoch 0: :   3%|▎         | 15319/600000 [02:12<1:24:27, v_num=12, reduced_train_loss=1.420, global_step=15318.0, consumed_samples=61276.0, train_step_timing in s=0.461]loss mask original None

First layer loss:  0.08495606482028961 torch.Size([619, 4]) 3.6193742752075195 0.0
Max loss timestep torch.Size([619, 4]) tensor([278, 296, 167, 380], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.042708855122327805
speech mask sum tensor(242, device='cuda:0') loss mask sum tensor(242, device='cuda:0')
bi 1 loss 0.09750213474035263
speech mask sum tensor(399, device='cuda:0') loss mask sum tensor(399, device='cuda:0')
bi 2 loss 0.025689389556646347
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 3 loss 0.11664630472660065
speech mask sum tensor(419, device='cuda:0') loss mask sum tensor(419, device='cuda:0')
logits torch.Size([619, 4, 257024]) labels torch.Size([619, 4]) 0 257022
Layer  0  loss:  0.0993785411119461 0.0 7.234405040740967
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([291, 296, 186, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.05118240416049957
bi 1 loss 0.07377388328313828
bi 2 loss 0.04553850367665291
bi 3 loss 0.1690729856491089
Layer  1  loss:  0.11246563494205475 0.0 9.244908332824707
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([291, 387, 159, 267], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.07140040397644043
bi 1 loss 0.1077108159661293
bi 2 loss 0.04822612553834915
bi 3 loss 0.16156238317489624
Layer  2  loss:  0.10669099539518356 0.0 11.768034934997559
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([268, 387, 169, 584], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.09319010376930237
bi 1 loss 0.11276612430810928
bi 2 loss 0.04021190106868744
bi 3 loss 0.1302814483642578
Layer  3  loss:  0.1272004246711731 0.0 13.656984329223633
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([291, 296, 159, 584], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.09405244886875153
bi 1 loss 0.10884448140859604
bi 2 loss 0.034370772540569305
bi 3 loss 0.19395621120929718
Layer  4  loss:  0.1112927570939064 0.0 6.075141906738281
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([271, 387, 107, 584], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.07821463793516159
bi 1 loss 0.09210945665836334
bi 2 loss 0.04297827184200287
bi 3 loss 0.170838862657547
Layer  5  loss:  0.10956016927957535 0.0 8.601842880249023
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([290, 296, 166, 267], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.05389315262436867
bi 1 loss 0.08370655030012131
bi 2 loss 0.051559608429670334
bi 3 loss 0.18515704572200775
Layer  6  loss:  0.12694238126277924 0.0 11.938437461853027
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([290, 296, 156, 266], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.10080299526453018
bi 1 loss 0.08853547275066376
bi 2 loss 0.060962874442338943
bi 3 loss 0.20002903044223785
Epoch 0: :   3%|▎         | 15320/600000 [02:13<1:24:44, v_num=12, reduced_train_loss=1.420, global_step=15318.0, consumed_samples=61276.0, train_step_timing in s=0.461]Epoch 0: :   3%|▎         | 15320/600000 [02:13<1:24:44, v_num=12, reduced_train_loss=0.878, global_step=15319.0, consumed_samples=61280.0, train_step_timing in s=0.424]loss mask original None

First layer loss:  0.1608291119337082 torch.Size([525, 4]) 11.858407020568848 0.0
Max loss timestep torch.Size([525, 4]) tensor([271,  88, 392, 300], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.13116087019443512
speech mask sum tensor(327, device='cuda:0') loss mask sum tensor(327, device='cuda:0')
bi 1 loss 0.03221502527594566
speech mask sum tensor(249, device='cuda:0') loss mask sum tensor(249, device='cuda:0')
bi 2 loss 0.21318824589252472
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
bi 3 loss 0.21074943244457245
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
logits torch.Size([525, 4, 257024]) labels torch.Size([525, 4]) 0 257022
Layer  0  loss:  0.17016048729419708 0.0 13.73361873626709
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([271, 180, 393, 299], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.19451014697551727
bi 1 loss 0.04510977119207382
bi 2 loss 0.23803161084651947
bi 3 loss 0.1551973819732666
Layer  1  loss:  0.1767898052930832 0.0 13.6124849319458
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([271, 103, 492, 299], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.187029168009758
bi 1 loss 0.05480402335524559
bi 2 loss 0.23615452647209167
bi 3 loss 0.18111315369606018
Layer  2  loss:  0.17757664620876312 0.0 13.2213773727417
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1022
Curr loss timestep torch.Size([525, 4]) tensor([271, 267, 392, 299], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.1899198442697525
bi 1 loss 0.05205676332116127
bi 2 loss 0.22362959384918213
bi 3 loss 0.1970447301864624
Layer  3  loss:  0.16818684339523315 0.0 13.005547523498535
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1019
Curr loss timestep torch.Size([525, 4]) tensor([271, 183, 492, 298], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.13121075928211212
bi 1 loss 0.03958883509039879
bi 2 loss 0.23729729652404785
bi 3 loss 0.20582062005996704
Layer  4  loss:  0.16072504222393036 0.0 10.71019172668457
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1020
Curr loss timestep torch.Size([525, 4]) tensor([271, 265, 391, 300], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.15854625403881073
bi 1 loss 0.058926984667778015
bi 2 loss 0.215032696723938
bi 3 loss 0.1681240350008011
Layer  5  loss:  0.18953333795070648 0.0 14.000995635986328
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([309,  82, 392, 299], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.17991593480110168
bi 1 loss 0.0404457189142704
bi 2 loss 0.2688804566860199
bi 3 loss 0.20599332451820374
Layer  6  loss:  0.17663666605949402 0.0 18.188770294189453
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([309, 280, 492, 298], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.1592588722705841
bi 1 loss 0.04389030858874321
bi 2 loss 0.24995960295200348
bi 3 loss 0.1957797259092331
Epoch 0: :   3%|▎         | 15321/600000 [02:13<1:24:59, v_num=12, reduced_train_loss=0.878, global_step=15319.0, consumed_samples=61280.0, train_step_timing in s=0.424]Epoch 0: :   3%|▎         | 15321/600000 [02:13<1:24:59, v_num=12, reduced_train_loss=1.380, global_step=15320.0, consumed_samples=61284.0, train_step_timing in s=0.362]loss mask original None

First layer loss:  0.04570341855287552 torch.Size([457, 4]) 3.0232980251312256 0.0
Max loss timestep torch.Size([457, 4]) tensor([283, 258, 200, 340], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.054625820368528366
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
bi 1 loss 0.03670521080493927
speech mask sum tensor(201, device='cuda:0') loss mask sum tensor(201, device='cuda:0')
bi 2 loss 0.03593410179018974
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 3 loss 0.05306727811694145
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
logits torch.Size([457, 4, 257024]) labels torch.Size([457, 4]) 0 257023
Layer  0  loss:  0.05581856891512871 0.0 7.295766830444336
logits torch.Size([457, 4, 1024]) labels torch.Size([457, 4]) 0 1023
Curr loss timestep torch.Size([457, 4]) tensor([265, 265, 291, 247], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.032847486436367035
bi 1 loss 0.1043957844376564
bi 2 loss 0.03838084265589714
bi 3 loss 0.041787486523389816
Layer  1  loss:  0.041181083768606186 0.0 2.1569809913635254
logits torch.Size([457, 4, 1024]) labels torch.Size([457, 4]) 0 1022
Curr loss timestep torch.Size([457, 4]) tensor([226, 265, 291, 319], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.025784481316804886
bi 1 loss 0.03596774861216545
bi 2 loss 0.03503449261188507
bi 3 loss 0.05065034702420235
Layer  2  loss:  0.0415995828807354 0.0 2.745055675506592
logits torch.Size([457, 4, 1024]) labels torch.Size([457, 4]) 0 1022
Curr loss timestep torch.Size([457, 4]) tensor([271, 265, 273, 340], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.03234708681702614
bi 1 loss 0.043066564947366714
bi 2 loss 0.04454570263624191
bi 3 loss 0.041674304753541946
Layer  3  loss:  0.045392539352178574 0.0 2.270280361175537
logits torch.Size([457, 4, 1024]) labels torch.Size([457, 4]) 0 1022
Curr loss timestep torch.Size([457, 4]) tensor([250, 263, 283, 225], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.029998324811458588
bi 1 loss 0.05319595709443092
bi 2 loss 0.02697684057056904
bi 3 loss 0.05305548012256622
Layer  4  loss:  0.05827954411506653 0.0 4.51220178604126
logits torch.Size([457, 4, 1024]) labels torch.Size([457, 4]) 0 1021
Curr loss timestep torch.Size([457, 4]) tensor([251, 265, 291, 313], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.02561805211007595
bi 1 loss 0.06758137047290802
bi 2 loss 0.04450640454888344
bi 3 loss 0.06717164814472198
Layer  5  loss:  0.04079674184322357 0.0 2.6113996505737305
logits torch.Size([457, 4, 1024]) labels torch.Size([457, 4]) 0 1022
Curr loss timestep torch.Size([457, 4]) tensor([260, 263, 205, 340], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.019978731870651245
bi 1 loss 0.05153738707304001
bi 2 loss 0.03369641304016113
bi 3 loss 0.04297880455851555
Layer  6  loss:  0.038061898201704025 0.0 2.5331082344055176
logits torch.Size([457, 4, 1024]) labels torch.Size([457, 4]) 0 1019
Curr loss timestep torch.Size([457, 4]) tensor([263, 263, 269, 395], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.02322593331336975
bi 1 loss 0.03566751256585121
bi 2 loss 0.027485165745019913
bi 3 loss 0.04780843108892441
Epoch 0: :   3%|▎         | 15322/600000 [02:13<1:25:12, v_num=12, reduced_train_loss=1.380, global_step=15320.0, consumed_samples=61284.0, train_step_timing in s=0.362]Epoch 0: :   3%|▎         | 15322/600000 [02:13<1:25:12, v_num=12, reduced_train_loss=0.367, global_step=15321.0, consumed_samples=61288.0, train_step_timing in s=0.327]loss mask original None

First layer loss:  0.20600144565105438 torch.Size([710, 4]) 12.535537719726562 0.0
Max loss timestep torch.Size([710, 4]) tensor([130, 385, 514, 127], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.06926155090332031
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 1 loss 0.15429414808750153
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 2 loss 0.33441925048828125
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
bi 3 loss 0.03328660875558853
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
logits torch.Size([710, 4, 257024]) labels torch.Size([710, 4]) 0 257023
Layer  0  loss:  0.2627985179424286 0.0 12.219148635864258
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([270, 514, 554, 141], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.09357617795467377
bi 1 loss 0.2689332664012909
bi 2 loss 0.3688589632511139
bi 3 loss 0.06299206614494324
Layer  1  loss:  0.2719043791294098 0.0 21.14142608642578
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([291, 384, 494, 147], device='cuda:0') tensor(494, device='cuda:0')
bi 0 loss 0.07573287189006805
bi 1 loss 0.17987926304340363
bi 2 loss 0.46422114968299866
bi 3 loss 0.058146215975284576
Layer  2  loss:  0.27000945806503296 0.0 12.062812805175781
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([286, 514, 589, 141], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.07829722762107849
bi 1 loss 0.26741674542427063
bi 2 loss 0.39968106150627136
bi 3 loss 0.025498658418655396
Layer  3  loss:  0.23864494264125824 0.0 10.779024124145508
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1021
Curr loss timestep torch.Size([710, 4]) tensor([293, 514, 514, 140], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.08015584200620651
bi 1 loss 0.2053511142730713
bi 2 loss 0.3692343533039093
bi 3 loss 0.030966494232416153
Layer  4  loss:  0.2738056480884552 0.0 14.772513389587402
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([286, 322, 514, 117], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.07364565134048462
bi 1 loss 0.19580289721488953
bi 2 loss 0.4512423574924469
bi 3 loss 0.10652413964271545
Layer  5  loss:  0.29619359970092773 0.0 10.880701065063477
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([286, 514, 514, 118], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.09897184371948242
bi 1 loss 0.23482473194599152
bi 2 loss 0.46874359250068665
bi 3 loss 0.06868699193000793
Layer  6  loss:  0.2628243863582611 0.0 11.936132431030273
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([293, 514, 494, 130], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.04833037778735161
bi 1 loss 0.16038040816783905
bi 2 loss 0.46482473611831665
bi 3 loss 0.09631401300430298
Epoch 0: :   3%|▎         | 15323/600000 [02:14<1:25:32, v_num=12, reduced_train_loss=0.367, global_step=15321.0, consumed_samples=61288.0, train_step_timing in s=0.327]Epoch 0: :   3%|▎         | 15323/600000 [02:14<1:25:32, v_num=12, reduced_train_loss=2.080, global_step=15322.0, consumed_samples=61292.0, train_step_timing in s=0.482]loss mask original None

First layer loss:  0.244804248213768 torch.Size([634, 4]) 20.377471923828125 0.0
Max loss timestep torch.Size([634, 4]) tensor([498, 303, 360,  61], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.3673521876335144
speech mask sum tensor(419, device='cuda:0') loss mask sum tensor(419, device='cuda:0')
bi 1 loss 0.10595062375068665
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 2 loss 0.23327669501304626
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
bi 3 loss 0.0946149006485939
speech mask sum tensor(71, device='cuda:0') loss mask sum tensor(71, device='cuda:0')
logits torch.Size([634, 4, 257024]) labels torch.Size([634, 4]) 0 257023
Layer  0  loss:  0.2511269450187683 0.0 11.639724731445312
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([576, 302, 359,  71], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.32019180059432983
bi 1 loss 0.14252741634845734
bi 2 loss 0.3089255094528198
bi 3 loss 0.04233349859714508
Layer  1  loss:  0.2652410864830017 0.0 16.92911720275879
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1022
Curr loss timestep torch.Size([634, 4]) tensor([534, 304, 361,  87], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.31132620573043823
bi 1 loss 0.17944499850273132
bi 2 loss 0.3341886103153229
bi 3 loss 0.06340974569320679
Layer  2  loss:  0.2843247354030609 0.0 19.620071411132812
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([498, 304, 361,  68], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.40024301409721375
bi 1 loss 0.12240617722272873
bi 2 loss 0.3346727192401886
bi 3 loss 0.030352700501680374
Layer  3  loss:  0.284518301486969 0.0 19.34526824951172
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([499, 304, 360,  72], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.37478747963905334
bi 1 loss 0.13877293467521667
bi 2 loss 0.3583236634731293
bi 3 loss 0.03262777999043465
Layer  4  loss:  0.3198167085647583 0.0 17.191265106201172
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1022
Curr loss timestep torch.Size([634, 4]) tensor([295, 294, 360,  53], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.45129990577697754
bi 1 loss 0.13784562051296234
bi 2 loss 0.3725062906742096
bi 3 loss 0.04178830236196518
Layer  5  loss:  0.2710186541080475 0.0 22.92189598083496
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([575, 304, 360,  79], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.35750052332878113
bi 1 loss 0.12870904803276062
bi 2 loss 0.33499693870544434
bi 3 loss 0.06504315882921219
Layer  6  loss:  0.2579720616340637 0.0 11.675738334655762
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1021
Curr loss timestep torch.Size([634, 4]) tensor([498, 302, 361,  73], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.35367918014526367
bi 1 loss 0.12227940559387207
bi 2 loss 0.30580195784568787
bi 3 loss 0.032570503652095795
Epoch 0: :   3%|▎         | 15324/600000 [02:14<1:25:49, v_num=12, reduced_train_loss=2.080, global_step=15322.0, consumed_samples=61292.0, train_step_timing in s=0.482]Epoch 0: :   3%|▎         | 15324/600000 [02:14<1:25:49, v_num=12, reduced_train_loss=2.180, global_step=15323.0, consumed_samples=61296.0, train_step_timing in s=0.430]loss mask original None

First layer loss:  0.12858569622039795 torch.Size([759, 4]) 6.370726108551025 0.0
Max loss timestep torch.Size([759, 4]) tensor([100, 432, 723,  93], device='cuda:0') tensor(723, device='cuda:0')
bi 0 loss 0.055111560970544815
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
bi 1 loss 0.07203245908021927
speech mask sum tensor(331, device='cuda:0') loss mask sum tensor(331, device='cuda:0')
bi 2 loss 0.21627569198608398
speech mask sum tensor(429, device='cuda:0') loss mask sum tensor(429, device='cuda:0')
bi 3 loss 0.027472566813230515
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
logits torch.Size([759, 4, 257024]) labels torch.Size([759, 4]) 0 257022
Layer  0  loss:  0.14403188228607178 0.0 8.425308227539062
logits torch.Size([759, 4, 1024]) labels torch.Size([759, 4]) 0 1023
Curr loss timestep torch.Size([759, 4]) tensor([173, 429, 404, 101], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.07233241200447083
bi 1 loss 0.07909584790468216
bi 2 loss 0.2381230741739273
bi 3 loss 0.040658675134181976
Layer  1  loss:  0.13998942077159882 0.0 5.507317543029785
logits torch.Size([759, 4, 1024]) labels torch.Size([759, 4]) 0 1023
Curr loss timestep torch.Size([759, 4]) tensor([152, 314, 723,  95], device='cuda:0') tensor(723, device='cuda:0')
bi 0 loss 0.06368377059698105
bi 1 loss 0.07304195314645767
bi 2 loss 0.23167532682418823
bi 3 loss 0.061953168362379074
Layer  2  loss:  0.1386307030916214 0.0 7.59051513671875
logits torch.Size([759, 4, 1024]) labels torch.Size([759, 4]) 0 1022
Curr loss timestep torch.Size([759, 4]) tensor([178, 429, 723,  74], device='cuda:0') tensor(723, device='cuda:0')
bi 0 loss 0.03818100690841675
bi 1 loss 0.08457225561141968
bi 2 loss 0.23360000550746918
bi 3 loss 0.0332559272646904
Layer  3  loss:  0.1392998844385147 0.0 8.429771423339844
logits torch.Size([759, 4, 1024]) labels torch.Size([759, 4]) 0 1022
Curr loss timestep torch.Size([759, 4]) tensor([121, 178, 723,  98], device='cuda:0') tensor(723, device='cuda:0')
bi 0 loss 0.05755733698606491
bi 1 loss 0.07799049466848373
bi 2 loss 0.23471513390541077
bi 3 loss 0.03106122836470604
Layer  4  loss:  0.1448252648115158 0.0 7.644520282745361
logits torch.Size([759, 4, 1024]) labels torch.Size([759, 4]) 0 1023
Curr loss timestep torch.Size([759, 4]) tensor([ 87, 416, 723, 106], device='cuda:0') tensor(723, device='cuda:0')
bi 0 loss 0.061381276696920395
bi 1 loss 0.0653437003493309
bi 2 loss 0.24564850330352783
bi 3 loss 0.0796586349606514
Layer  5  loss:  0.15935035049915314 0.0 7.510931015014648
logits torch.Size([759, 4, 1024]) labels torch.Size([759, 4]) 0 1023
Curr loss timestep torch.Size([759, 4]) tensor([196, 271, 404, 102], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.04467505216598511
bi 1 loss 0.07632842659950256
bi 2 loss 0.2838594913482666
bi 3 loss 0.04070143774151802
Layer  6  loss:  0.15360061824321747 0.0 11.813353538513184
logits torch.Size([759, 4, 1024]) labels torch.Size([759, 4]) 0 1023
Curr loss timestep torch.Size([759, 4]) tensor([175, 339, 404,  91], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.05326906219124794
bi 1 loss 0.08316179364919662
bi 2 loss 0.26602962613105774
bi 3 loss 0.02532559260725975
Epoch 0: :   3%|▎         | 15325/600000 [02:15<1:26:11, v_num=12, reduced_train_loss=2.180, global_step=15323.0, consumed_samples=61296.0, train_step_timing in s=0.430]Epoch 0: :   3%|▎         | 15325/600000 [02:15<1:26:11, v_num=12, reduced_train_loss=1.150, global_step=15324.0, consumed_samples=61300.0, train_step_timing in s=0.529]loss mask original None

First layer loss:  3.586045742034912 torch.Size([472, 4]) 11.419058799743652 0.0
Max loss timestep torch.Size([472, 4]) tensor([216, 339, 181, 262], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 3.6386594772338867
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 1 loss 3.764261484146118
speech mask sum tensor(396, device='cuda:0') loss mask sum tensor(396, device='cuda:0')
bi 2 loss 3.3130149841308594
speech mask sum tensor(348, device='cuda:0') loss mask sum tensor(348, device='cuda:0')
bi 3 loss 3.6167311668395996
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
logits torch.Size([472, 4, 257024]) labels torch.Size([472, 4]) 0 257022
Layer  0  loss:  4.243465423583984 0.0 10.869075775146484
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([299, 382, 335, 258], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.481142997741699
bi 1 loss 4.608582973480225
bi 2 loss 3.794109582901001
bi 3 loss 4.078627586364746
Layer  1  loss:  4.460660457611084 0.0 10.102716445922852
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([335, 390, 335, 192], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 4.744696140289307
bi 1 loss 4.783933639526367
bi 2 loss 3.7990834712982178
bi 3 loss 4.5348219871521
Layer  2  loss:  4.78201961517334 0.0 10.281702995300293
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([334, 439,  71, 417], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 4.989010334014893
bi 1 loss 5.209925651550293
bi 2 loss 4.084377765655518
bi 3 loss 4.83250093460083
Layer  3  loss:  4.8839430809021 0.0 10.627983093261719
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([386, 338,  98, 382], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 5.218789577484131
bi 1 loss 5.393120765686035
bi 2 loss 3.959582805633545
bi 3 loss 4.969974994659424
Layer  4  loss:  5.039309501647949 0.0 9.950742721557617
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([347, 107, 238, 143], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 5.322340965270996
bi 1 loss 5.502315044403076
bi 2 loss 4.21664571762085
bi 3 loss 5.116549015045166
Layer  5  loss:  5.097695350646973 0.0 10.142751693725586
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([378,  97,  96, 337], device='cuda:0') tensor(354, device='cuda:0')
bi 0 loss 5.386488914489746
bi 1 loss 5.587182998657227
bi 2 loss 4.260395050048828
bi 3 loss 5.153466701507568
Layer  6  loss:  5.186310768127441 0.0 10.574296951293945
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([247, 344, 139, 406], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 5.428709983825684
bi 1 loss 5.81573486328125
bi 2 loss 4.193751335144043
bi 3 loss 5.27707576751709
Epoch 0: :   3%|▎         | 15326/600000 [02:15<1:26:24, v_num=12, reduced_train_loss=1.150, global_step=15324.0, consumed_samples=61300.0, train_step_timing in s=0.529]Epoch 0: :   3%|▎         | 15326/600000 [02:15<1:26:24, v_num=12, reduced_train_loss=37.30, global_step=15325.0, consumed_samples=61304.0, train_step_timing in s=0.322]loss mask original None

First layer loss:  3.4005677700042725 torch.Size([508, 4]) 11.329540252685547 0.0
Max loss timestep torch.Size([508, 4]) tensor([284, 116, 170, 321], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 3.5859973430633545
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 1 loss 3.7510669231414795
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 2 loss 3.204324960708618
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 3 loss 3.2536799907684326
speech mask sum tensor(295, device='cuda:0') loss mask sum tensor(295, device='cuda:0')
logits torch.Size([508, 4, 257024]) labels torch.Size([508, 4]) 0 257022
Layer  0  loss:  3.896895170211792 0.0 9.908190727233887
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([435, 136, 196, 128], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 4.250062465667725
bi 1 loss 3.7549641132354736
bi 2 loss 3.4832794666290283
bi 3 loss 4.031111717224121
Layer  1  loss:  4.318816184997559 0.0 10.947813034057617
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([427, 137, 195, 131], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 4.734288692474365
bi 1 loss 4.340925693511963
bi 2 loss 3.687954902648926
bi 3 loss 4.505485534667969
Layer  2  loss:  4.622263431549072 0.0 9.849440574645996
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([343, 140, 136, 317], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 4.9172892570495605
bi 1 loss 4.560706615447998
bi 2 loss 4.138449192047119
bi 3 loss 4.820499897003174
Layer  3  loss:  4.6944260597229 0.0 10.774299621582031
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([474,  78, 203, 273], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 5.050692081451416
bi 1 loss 4.482587814331055
bi 2 loss 4.283576011657715
bi 3 loss 4.8569488525390625
Layer  4  loss:  4.7871503829956055 0.0 10.411402702331543
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1021
Curr loss timestep torch.Size([508, 4]) tensor([315,  80, 349, 355], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 5.2572736740112305
bi 1 loss 4.477399826049805
bi 2 loss 4.323383808135986
bi 3 loss 4.95181131362915
Layer  5  loss:  4.887592315673828 0.0 10.39888858795166
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([377, 131, 204, 288], device='cuda:0') tensor(150, device='cuda:0')
bi 0 loss 5.187333583831787
bi 1 loss 4.746971130371094
bi 2 loss 4.352579593658447
bi 3 loss 5.16129732131958
Layer  6  loss:  4.958420276641846 0.0 9.987970352172852
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([493,  90, 191, 166], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 5.339463710784912
bi 1 loss 4.535223007202148
bi 2 loss 4.615674018859863
bi 3 loss 5.145911693572998
Epoch 0: :   3%|▎         | 15327/600000 [02:16<1:26:38, v_num=12, reduced_train_loss=37.30, global_step=15325.0, consumed_samples=61304.0, train_step_timing in s=0.322]Epoch 0: :   3%|▎         | 15327/600000 [02:16<1:26:38, v_num=12, reduced_train_loss=35.60, global_step=15326.0, consumed_samples=61308.0, train_step_timing in s=0.337]loss mask original None

First layer loss:  0.11827980726957321 torch.Size([597, 4]) 6.1287736892700195 0.0
Max loss timestep torch.Size([597, 4]) tensor([169, 193, 331,  92], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.04472878947854042
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 1 loss 0.04090221971273422
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 2 loss 0.2258862406015396
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
bi 3 loss 0.046123359352350235
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
logits torch.Size([597, 4, 257024]) labels torch.Size([597, 4]) 0 257023
Layer  0  loss:  0.09503203630447388 0.0 7.511364936828613
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([147, 205, 330,  75], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.05158296227455139
bi 1 loss 0.03415627032518387
bi 2 loss 0.17096740007400513
bi 3 loss 0.041703782975673676
Layer  1  loss:  0.12924616038799286 0.0 7.845193862915039
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([ 81, 203, 396, 133], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.04668981209397316
bi 1 loss 0.05819672718644142
bi 2 loss 0.2435367852449417
bi 3 loss 0.04864311218261719
Layer  2  loss:  0.16189633309841156 0.0 12.033406257629395
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([181, 213, 330, 137], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.06217185780405998
bi 1 loss 0.03373125195503235
bi 2 loss 0.3257596492767334
bi 3 loss 0.049333397299051285
Layer  3  loss:  0.1272902935743332 0.0 14.375325202941895
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([171, 178, 330,  95], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.048604272305965424
bi 1 loss 0.04808787256479263
bi 2 loss 0.24748583137989044
bi 3 loss 0.0391685850918293
Layer  4  loss:  0.14068730175495148 0.0 12.385427474975586
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([174, 194, 330, 169], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.04248441010713577
bi 1 loss 0.035555724054574966
bi 2 loss 0.2742362916469574
bi 3 loss 0.06259537488222122
Layer  5  loss:  0.1365220695734024 0.0 9.930461883544922
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1018
Curr loss timestep torch.Size([597, 4]) tensor([140, 159, 331, 112], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.03629045560956001
bi 1 loss 0.050926633179187775
bi 2 loss 0.2756863534450531
bi 3 loss 0.03753816708922386
Layer  6  loss:  0.14033888280391693 0.0 10.80648422241211
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([ 79, 157, 330, 121], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.051383696496486664
bi 1 loss 0.026552604511380196
bi 2 loss 0.2801557183265686
bi 3 loss 0.05026005581021309
Epoch 0: :   3%|▎         | 15328/600000 [02:16<1:26:55, v_num=12, reduced_train_loss=35.60, global_step=15326.0, consumed_samples=61308.0, train_step_timing in s=0.337]Epoch 0: :   3%|▎         | 15328/600000 [02:16<1:26:55, v_num=12, reduced_train_loss=1.050, global_step=15327.0, consumed_samples=61312.0, train_step_timing in s=0.409]loss mask original None

First layer loss:  3.8017618656158447 torch.Size([708, 4]) 11.861163139343262 0.0
Max loss timestep torch.Size([708, 4]) tensor([503, 576, 235, 200], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 3.934941053390503
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
bi 1 loss 3.9957275390625
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
bi 2 loss 3.3851332664489746
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
bi 3 loss 3.253338575363159
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
logits torch.Size([708, 4, 257024]) labels torch.Size([708, 4]) 0 257023
Layer  0  loss:  4.414804935455322 0.0 10.524847030639648
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([527, 627, 116, 261], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.350597858428955
bi 1 loss 4.693488597869873
bi 2 loss 4.079423427581787
bi 3 loss 3.943150043487549
Layer  1  loss:  4.731378555297852 0.0 9.8756103515625
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([475, 298, 161, 312], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 4.818112850189209
bi 1 loss 4.9416046142578125
bi 2 loss 4.3878631591796875
bi 3 loss 4.1640944480896
Layer  2  loss:  5.004408359527588 0.0 10.056122779846191
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([267, 471, 161, 306], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 5.102530002593994
bi 1 loss 5.086809158325195
bi 2 loss 5.027599811553955
bi 3 loss 4.499557971954346
Layer  3  loss:  5.10924768447876 0.0 10.70608139038086
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([511, 383, 162, 270], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 5.163944721221924
bi 1 loss 5.244139194488525
bi 2 loss 5.182459354400635
bi 3 loss 4.480923652648926
Layer  4  loss:  5.220379829406738 0.0 9.096880912780762
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1020
Curr loss timestep torch.Size([708, 4]) tensor([526, 438, 132, 318], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 5.2813286781311035
bi 1 loss 5.46468448638916
bi 2 loss 4.919154644012451
bi 3 loss 4.558806419372559
Layer  5  loss:  5.3063435554504395 0.0 10.185643196105957
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([426, 466, 164, 296], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 5.356136322021484
bi 1 loss 5.5295090675354
bi 2 loss 5.165244102478027
bi 3 loss 4.593151569366455
Layer  6  loss:  5.3669633865356445 0.0 9.561394691467285
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([503, 582, 157, 208], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 5.462015151977539
bi 1 loss 5.548201084136963
bi 2 loss 5.209441661834717
bi 3 loss 4.7080888748168945
Epoch 0: :   3%|▎         | 15329/600000 [02:17<1:27:12, v_num=12, reduced_train_loss=1.050, global_step=15327.0, consumed_samples=61312.0, train_step_timing in s=0.409]Epoch 0: :   3%|▎         | 15329/600000 [02:17<1:27:12, v_num=12, reduced_train_loss=39.00, global_step=15328.0, consumed_samples=61316.0, train_step_timing in s=0.426]loss mask original None

First layer loss:  0.05755135416984558 torch.Size([371, 4]) 5.705595016479492 0.0
Max loss timestep torch.Size([371, 4]) tensor([116, 105, 301,  54], device='cuda:0') tensor(116, device='cuda:0')
bi 0 loss 0.060917988419532776
speech mask sum tensor(233, device='cuda:0') loss mask sum tensor(233, device='cuda:0')
bi 1 loss 0.14311003684997559
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 2 loss 0.04337303712964058
speech mask sum tensor(252, device='cuda:0') loss mask sum tensor(252, device='cuda:0')
bi 3 loss 0.0346943624317646
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
logits torch.Size([371, 4, 257024]) labels torch.Size([371, 4]) 0 257023
Layer  0  loss:  0.039703369140625 0.0 0.8913471102714539
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([129, 143, 311,  93], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.03744637966156006
bi 1 loss 0.01928449235856533
bi 2 loss 0.04342954233288765
bi 3 loss 0.04678646847605705
Layer  1  loss:  0.03858470544219017 0.0 1.3559507131576538
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([145, 126, 300, 109], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 0.03772826865315437
bi 1 loss 0.02431902103126049
bi 2 loss 0.04769580811262131
bi 3 loss 0.03186994418501854
Layer  2  loss:  0.0441029854118824 0.0 1.6621270179748535
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([ 46, 117, 126, 148], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 0.03973300755023956
bi 1 loss 0.024540826678276062
bi 2 loss 0.05257164314389229
bi 3 loss 0.046243008226156235
Layer  3  loss:  0.03921498730778694 0.0 1.0429415702819824
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1020
Curr loss timestep torch.Size([371, 4]) tensor([263, 111, 288, 167], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.038786448538303375
bi 1 loss 0.027037324383854866
bi 2 loss 0.04064226895570755
bi 3 loss 0.043352559208869934
Layer  4  loss:  0.032693397253751755 0.0 1.9747816324234009
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([220, 150, 292, 146], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.029677972197532654
bi 1 loss 0.019724266603589058
bi 2 loss 0.04514361917972565
bi 3 loss 0.02317633107304573
Layer  5  loss:  0.03531843423843384 0.0 0.934554934501648
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([235, 121, 359, 123], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 0.030200110748410225
bi 1 loss 0.026231711730360985
bi 2 loss 0.03167282044887543
bi 3 loss 0.05327766016125679
Layer  6  loss:  0.034429676830768585 0.0 1.3271507024765015
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([234, 130, 301, 158], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.03875291347503662
bi 1 loss 0.023985592648386955
bi 2 loss 0.037467602640390396
bi 3 loss 0.02797801047563553
Epoch 0: :   3%|▎         | 15330/600000 [02:17<1:27:24, v_num=12, reduced_train_loss=39.00, global_step=15328.0, consumed_samples=61316.0, train_step_timing in s=0.426]Epoch 0: :   3%|▎         | 15330/600000 [02:17<1:27:24, v_num=12, reduced_train_loss=0.322, global_step=15329.0, consumed_samples=61320.0, train_step_timing in s=0.286]loss mask original None

First layer loss:  0.12790633738040924 torch.Size([637, 4]) 10.36862564086914 0.0
Max loss timestep torch.Size([637, 4]) tensor([360, 573,  58, 159], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.11322352290153503
speech mask sum tensor(257, device='cuda:0') loss mask sum tensor(257, device='cuda:0')
bi 1 loss 0.1720561385154724
speech mask sum tensor(435, device='cuda:0') loss mask sum tensor(435, device='cuda:0')
bi 2 loss 0.11481193453073502
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
bi 3 loss 0.032942648977041245
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
logits torch.Size([637, 4, 257024]) labels torch.Size([637, 4]) 0 257022
Layer  0  loss:  0.13289496302604675 0.0 7.755151748657227
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([292, 256, 297, 144], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 0.16449570655822754
bi 1 loss 0.15374644100666046
bi 2 loss 0.11922484636306763
bi 3 loss 0.02383274957537651
Layer  1  loss:  0.1174803301692009 0.0 10.575671195983887
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1022
Curr loss timestep torch.Size([637, 4]) tensor([292, 572, 296, 177], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.17760832607746124
bi 1 loss 0.10827424377202988
bi 2 loss 0.11104817688465118
bi 3 loss 0.035346586257219315
Layer  2  loss:  0.1352832168340683 0.0 10.534093856811523
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([292, 600, 296, 166], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.2067946195602417
bi 1 loss 0.1265362650156021
bi 2 loss 0.11773032695055008
bi 3 loss 0.06406322866678238
Layer  3  loss:  0.13893146812915802 0.0 12.475390434265137
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([359, 586, 296, 126], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.16920237243175507
bi 1 loss 0.17192673683166504
bi 2 loss 0.10969758778810501
bi 3 loss 0.03994232043623924
Layer  4  loss:  0.14858458936214447 0.0 9.687426567077637
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([293, 573, 297, 179], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.1737285554409027
bi 1 loss 0.19998601078987122
bi 2 loss 0.10660415142774582
bi 3 loss 0.03360125049948692
Layer  5  loss:  0.13239723443984985 0.0 10.161040306091309
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1022
Curr loss timestep torch.Size([637, 4]) tensor([292, 586, 296, 145], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.19603939354419708
bi 1 loss 0.15619777143001556
bi 2 loss 0.0928570032119751
bi 3 loss 0.028106756508350372
Layer  6  loss:  0.14401757717132568 0.0 10.136699676513672
logits torch.Size([637, 4, 1024]) labels torch.Size([637, 4]) 0 1023
Curr loss timestep torch.Size([637, 4]) tensor([292, 573, 296, 120], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.17513224482536316
bi 1 loss 0.15668466687202454
bi 2 loss 0.12991979718208313
bi 3 loss 0.07028643786907196
Epoch 0: :   3%|▎         | 15331/600000 [02:17<1:27:42, v_num=12, reduced_train_loss=0.322, global_step=15329.0, consumed_samples=61320.0, train_step_timing in s=0.286]Epoch 0: :   3%|▎         | 15331/600000 [02:17<1:27:42, v_num=12, reduced_train_loss=1.080, global_step=15330.0, consumed_samples=61324.0, train_step_timing in s=0.438]loss mask original None

First layer loss:  0.043728649616241455 torch.Size([582, 4]) 2.1337780952453613 0.0
Max loss timestep torch.Size([582, 4]) tensor([385, 220, 164, 318], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 0.03495323657989502
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 1 loss 0.032624565064907074
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 2 loss 0.07806763052940369
speech mask sum tensor(63, device='cuda:0') loss mask sum tensor(63, device='cuda:0')
bi 3 loss 0.05228770524263382
speech mask sum tensor(347, device='cuda:0') loss mask sum tensor(347, device='cuda:0')
logits torch.Size([582, 4, 257024]) labels torch.Size([582, 4]) 0 257023
Layer  0  loss:  0.05275365710258484 0.0 5.877910137176514
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([571, 181, 169, 280], device='cuda:0') tensor(571, device='cuda:0')
bi 0 loss 0.05544593185186386
bi 1 loss 0.022742409259080887
bi 2 loss 0.04260988160967827
bi 3 loss 0.06710276007652283
Layer  1  loss:  0.04478498920798302 0.0 2.6972832679748535
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([572, 125, 152, 486], device='cuda:0') tensor(572, device='cuda:0')
bi 0 loss 0.04803508147597313
bi 1 loss 0.026736270636320114
bi 2 loss 0.02782946266233921
bi 3 loss 0.053688544780015945
Layer  2  loss:  0.05992916226387024 0.0 2.3582749366760254
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([413, 221, 182, 281], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.0662912055850029
bi 1 loss 0.031899720430374146
bi 2 loss 0.018694864585995674
bi 3 loss 0.07509421557188034
Layer  3  loss:  0.051387764513492584 0.0 5.698779582977295
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1020
Curr loss timestep torch.Size([582, 4]) tensor([385, 147, 182, 509], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.06264807283878326
bi 1 loss 0.02111971192061901
bi 2 loss 0.04386765882372856
bi 3 loss 0.05647779256105423
Layer  4  loss:  0.058634720742702484 0.0 6.637150764465332
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1020
Curr loss timestep torch.Size([582, 4]) tensor([385, 269, 170, 503], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.07094473391771317
bi 1 loss 0.055122893303632736
bi 2 loss 0.027629977092146873
bi 3 loss 0.053248483687639236
Layer  5  loss:  0.05747522786259651 0.0 3.1216907501220703
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([385, 219, 155, 271], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.05703980103135109
bi 1 loss 0.02350706420838833
bi 2 loss 0.031175242736935616
bi 3 loss 0.08002985268831253
Layer  6  loss:  0.04821884632110596 0.0 1.9971352815628052
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([571, 277, 171, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.05414428189396858
bi 1 loss 0.025800229981541634
bi 2 loss 0.02729964070022106
bi 3 loss 0.0572877861559391
Epoch 0: :   3%|▎         | 15332/600000 [02:18<1:27:58, v_num=12, reduced_train_loss=1.080, global_step=15330.0, consumed_samples=61324.0, train_step_timing in s=0.438]Epoch 0: :   3%|▎         | 15332/600000 [02:18<1:27:58, v_num=12, reduced_train_loss=0.417, global_step=15331.0, consumed_samples=61328.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.07302501052618027 torch.Size([453, 4]) 3.885528802871704 0.0
Max loss timestep torch.Size([453, 4]) tensor([362, 138, 271, 346], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.0847582072019577
speech mask sum tensor(273, device='cuda:0') loss mask sum tensor(273, device='cuda:0')
bi 1 loss 0.02820489928126335
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
bi 2 loss 0.05973171815276146
speech mask sum tensor(334, device='cuda:0') loss mask sum tensor(334, device='cuda:0')
bi 3 loss 0.10919877886772156
speech mask sum tensor(225, device='cuda:0') loss mask sum tensor(225, device='cuda:0')
logits torch.Size([453, 4, 257024]) labels torch.Size([453, 4]) 0 257023
Layer  0  loss:  0.0873737558722496 0.0 5.969665050506592
logits torch.Size([453, 4, 1024]) labels torch.Size([453, 4]) 0 1023
Curr loss timestep torch.Size([453, 4]) tensor([278, 151, 271, 346], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.07802989333868027
bi 1 loss 0.02035543881356716
bi 2 loss 0.12462162226438522
bi 3 loss 0.0892888605594635
Layer  1  loss:  0.07918177545070648 0.0 3.8239474296569824
logits torch.Size([453, 4, 1024]) labels torch.Size([453, 4]) 0 1022
Curr loss timestep torch.Size([453, 4]) tensor([285, 186, 363, 345], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.0650484636425972
bi 1 loss 0.02960238605737686
bi 2 loss 0.09389518946409225
bi 3 loss 0.10842325538396835
Layer  2  loss:  0.10691425949335098 0.0 10.851540565490723
logits torch.Size([453, 4, 1024]) labels torch.Size([453, 4]) 0 1022
Curr loss timestep torch.Size([453, 4]) tensor([362,  94, 271, 347], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.08804923295974731
bi 1 loss 0.01802486926317215
bi 2 loss 0.16740907728672028
bi 3 loss 0.10084250569343567
Layer  3  loss:  0.09319489449262619 0.0 8.555609703063965
logits torch.Size([453, 4, 1024]) labels torch.Size([453, 4]) 0 1022
Curr loss timestep torch.Size([453, 4]) tensor([281, 171, 272, 347], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.06433305144309998
bi 1 loss 0.019353482872247696
bi 2 loss 0.12734195590019226
bi 3 loss 0.128064826130867
Layer  4  loss:  0.08979972451925278 0.0 8.761249542236328
logits torch.Size([453, 4, 1024]) labels torch.Size([453, 4]) 0 1022
Curr loss timestep torch.Size([453, 4]) tensor([278, 179, 296, 281], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.09912174940109253
bi 1 loss 0.026059051975607872
bi 2 loss 0.10755704343318939
bi 3 loss 0.09575620293617249
Layer  5  loss:  0.11342038959264755 0.0 8.805542945861816
logits torch.Size([453, 4, 1024]) labels torch.Size([453, 4]) 0 1022
Curr loss timestep torch.Size([453, 4]) tensor([372, 129, 296, 347], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.08826451003551483
bi 1 loss 0.03523222729563713
bi 2 loss 0.15190060436725616
bi 3 loss 0.1403365433216095
Layer  6  loss:  0.09067538380622864 0.0 6.9212822914123535
logits torch.Size([453, 4, 1024]) labels torch.Size([453, 4]) 0 1022
Curr loss timestep torch.Size([453, 4]) tensor([383, 139, 271, 347], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.0893729031085968
bi 1 loss 0.025191577151417732
bi 2 loss 0.1111120656132698
bi 3 loss 0.1067386195063591
Epoch 0: :   3%|▎         | 15333/600000 [02:18<1:28:12, v_num=12, reduced_train_loss=0.417, global_step=15331.0, consumed_samples=61328.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15333/600000 [02:18<1:28:12, v_num=12, reduced_train_loss=0.734, global_step=15332.0, consumed_samples=61332.0, train_step_timing in s=0.334]loss mask original None

First layer loss:  3.7456376552581787 torch.Size([516, 4]) 12.524198532104492 0.0
Max loss timestep torch.Size([516, 4]) tensor([ 98, 161,  97, 192], device='cuda:0') tensor(97, device='cuda:0')
bi 0 loss 3.958528757095337
speech mask sum tensor(432, device='cuda:0') loss mask sum tensor(432, device='cuda:0')
bi 1 loss 3.8061647415161133
speech mask sum tensor(393, device='cuda:0') loss mask sum tensor(393, device='cuda:0')
bi 2 loss 3.531817674636841
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 3 loss 3.1780076026916504
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
logits torch.Size([516, 4, 257024]) labels torch.Size([516, 4]) 0 257023
Layer  0  loss:  4.221912384033203 0.0 10.236042976379395
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([123, 206, 138, 265], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 4.181411266326904
bi 1 loss 4.453463077545166
bi 2 loss 4.062606334686279
bi 3 loss 3.8766872882843018
Layer  1  loss:  4.610435962677002 0.0 10.814022064208984
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([416, 431, 145, 285], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.7503662109375
bi 1 loss 4.793415069580078
bi 2 loss 4.038273334503174
bi 3 loss 4.173167705535889
Layer  2  loss:  4.821659088134766 0.0 11.81273365020752
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([443, 340, 101, 256], device='cuda:0') tensor(130, device='cuda:0')
bi 0 loss 4.957271099090576
bi 1 loss 5.061612606048584
bi 2 loss 4.198511600494385
bi 3 loss 4.292191982269287
Layer  3  loss:  5.003705024719238 0.0 11.072108268737793
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([179, 260, 115, 209], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 4.984148025512695
bi 1 loss 5.3299031257629395
bi 2 loss 4.666389465332031
bi 3 loss 4.491561412811279
Layer  4  loss:  5.10039758682251 0.0 10.007336616516113
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([236, 352, 142, 175], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 5.193030834197998
bi 1 loss 5.204893112182617
bi 2 loss 4.8535075187683105
bi 3 loss 4.765558242797852
Layer  5  loss:  5.253050804138184 0.0 10.065006256103516
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([287, 393, 167, 309], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 5.283597946166992
bi 1 loss 5.51892614364624
bi 2 loss 4.956448554992676
bi 3 loss 4.727165222167969
Layer  6  loss:  5.250670433044434 0.0 10.197065353393555
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([464, 145,  98, 239], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 5.305844783782959
bi 1 loss 5.50007963180542
bi 2 loss 4.939542293548584
bi 3 loss 4.708759307861328
Epoch 0: :   3%|▎         | 15334/600000 [02:19<1:28:26, v_num=12, reduced_train_loss=0.734, global_step=15332.0, consumed_samples=61332.0, train_step_timing in s=0.334]Epoch 0: :   3%|▎         | 15334/600000 [02:19<1:28:26, v_num=12, reduced_train_loss=38.00, global_step=15333.0, consumed_samples=61336.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  0.03973257169127464 torch.Size([437, 4]) 2.2033615112304688 0.0
Max loss timestep torch.Size([437, 4]) tensor([251, 396, 205, 153], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 0.06099264323711395
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
bi 1 loss 0.04099263995885849
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
bi 2 loss 0.024978380650281906
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 3 loss 0.024954775348305702
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
logits torch.Size([437, 4, 257024]) labels torch.Size([437, 4]) 0 257022
Layer  0  loss:  0.03540723770856857 0.0 1.2416865825653076
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([308, 408, 167, 154], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.05029704049229622
bi 1 loss 0.03021896816790104
bi 2 loss 0.0391538105905056
bi 3 loss 0.01837102137506008
Layer  1  loss:  0.035901401191949844 0.0 1.2060619592666626
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([309, 407, 179, 154], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.04825836792588234
bi 1 loss 0.035469286143779755
bi 2 loss 0.029451100155711174
bi 3 loss 0.027028638869524002
Layer  2  loss:  0.03165425732731819 0.0 1.4870563745498657
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([272, 407, 217, 162], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.030702834948897362
bi 1 loss 0.04048763960599899
bi 2 loss 0.02395983412861824
bi 3 loss 0.02081967145204544
Layer  3  loss:  0.03473550081253052 0.0 1.7203776836395264
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1021
Curr loss timestep torch.Size([437, 4]) tensor([285, 407, 150, 156], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.040004923939704895
bi 1 loss 0.03974956274032593
bi 2 loss 0.033062893897295
bi 3 loss 0.01387790683656931
Layer  4  loss:  0.031104054301977158 0.0 1.705103874206543
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([283, 408, 170, 173], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.0425805039703846
bi 1 loss 0.0330638512969017
bi 2 loss 0.02326340600848198
bi 3 loss 0.01916963793337345
Layer  5  loss:  0.029928790405392647 0.0 1.68585205078125
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([274, 407, 129, 167], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.027187969535589218
bi 1 loss 0.040427111089229584
bi 2 loss 0.0213522557169199
bi 3 loss 0.018845515325665474
Layer  6  loss:  0.040895771235227585 0.0 2.405365467071533
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([302, 362, 165, 157], device='cuda:0') tensor(165, device='cuda:0')
bi 0 loss 0.05485101044178009
bi 1 loss 0.04034891724586487
bi 2 loss 0.040141355246305466
bi 3 loss 0.019712083041667938
Epoch 0: :   3%|▎         | 15335/600000 [02:19<1:28:40, v_num=12, reduced_train_loss=38.00, global_step=15333.0, consumed_samples=61336.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15335/600000 [02:19<1:28:40, v_num=12, reduced_train_loss=0.279, global_step=15334.0, consumed_samples=61340.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.1393287032842636 torch.Size([614, 4]) 10.253011703491211 0.0
Max loss timestep torch.Size([614, 4]) tensor([270, 280, 266, 584], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.07456841319799423
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 1 loss 0.05666285380721092
speech mask sum tensor(257, device='cuda:0') loss mask sum tensor(257, device='cuda:0')
bi 2 loss 0.1451495885848999
speech mask sum tensor(324, device='cuda:0') loss mask sum tensor(324, device='cuda:0')
bi 3 loss 0.21679414808750153
speech mask sum tensor(489, device='cuda:0') loss mask sum tensor(489, device='cuda:0')
logits torch.Size([614, 4, 257024]) labels torch.Size([614, 4]) 0 257022
Layer  0  loss:  0.1877339631319046 0.0 14.954538345336914
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([270, 319, 267, 489], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.08502192050218582
bi 1 loss 0.04715684428811073
bi 2 loss 0.2731262445449829
bi 3 loss 0.26510995626449585
Layer  1  loss:  0.1946202516555786 0.0 12.994790077209473
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([270, 278, 458, 489], device='cuda:0') tensor(489, device='cuda:0')
bi 0 loss 0.10216972976922989
bi 1 loss 0.06190085411071777
bi 2 loss 0.23098312318325043
bi 3 loss 0.29435062408447266
Layer  2  loss:  0.20598852634429932 0.0 19.718767166137695
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([270, 283, 267, 584], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.12920619547367096
bi 1 loss 0.12696956098079681
bi 2 loss 0.2087826132774353
bi 3 loss 0.2905740737915039
Layer  3  loss:  0.18803979456424713 0.0 12.813279151916504
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1020
Curr loss timestep torch.Size([614, 4]) tensor([270, 324, 267, 350], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.09083675593137741
bi 1 loss 0.082684725522995
bi 2 loss 0.20251977443695068
bi 3 loss 0.29066720604896545
Layer  4  loss:  0.17744114995002747 0.0 11.81241226196289
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([270, 319, 267, 562], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.0950622707605362
bi 1 loss 0.06732232123613358
bi 2 loss 0.2093207687139511
bi 3 loss 0.2623734772205353
Layer  5  loss:  0.19007308781147003 0.0 12.032615661621094
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([270, 320, 267, 584], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.10175072401762009
bi 1 loss 0.10971331596374512
bi 2 loss 0.20676539838314056
bi 3 loss 0.27290409803390503
Layer  6  loss:  0.17600110173225403 0.0 16.2806453704834
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([270, 283, 266, 350], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.08215358108282089
bi 1 loss 0.07841267436742783
bi 2 loss 0.1646447330713272
bi 3 loss 0.28970274329185486
Epoch 0: :   3%|▎         | 15336/600000 [02:19<1:28:56, v_num=12, reduced_train_loss=0.279, global_step=15334.0, consumed_samples=61340.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15336/600000 [02:19<1:28:56, v_num=12, reduced_train_loss=1.460, global_step=15335.0, consumed_samples=61344.0, train_step_timing in s=0.415]loss mask original None

First layer loss:  0.15321914851665497 torch.Size([566, 4]) 9.237610816955566 0.0
Max loss timestep torch.Size([566, 4]) tensor([458,  37, 311, 291], device='cuda:0') tensor(458, device='cuda:0')
bi 0 loss 0.1951892226934433
speech mask sum tensor(353, device='cuda:0') loss mask sum tensor(353, device='cuda:0')
bi 1 loss 0.04055578261613846
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
bi 2 loss 0.18311379849910736
speech mask sum tensor(336, device='cuda:0') loss mask sum tensor(336, device='cuda:0')
bi 3 loss 0.10813691467046738
speech mask sum tensor(384, device='cuda:0') loss mask sum tensor(384, device='cuda:0')
logits torch.Size([566, 4, 257024]) labels torch.Size([566, 4]) 0 257022
Layer  0  loss:  0.18860743939876556 0.0 8.93792724609375
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([492,  52, 339, 291], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.22818581759929657
bi 1 loss 0.04256225377321243
bi 2 loss 0.23405574262142181
bi 3 loss 0.13793878257274628
Layer  1  loss:  0.19012004137039185 0.0 13.14178466796875
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([305,  39, 310, 321], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.22923170030117035
bi 1 loss 0.04335208982229233
bi 2 loss 0.25483617186546326
bi 3 loss 0.12314718961715698
Layer  2  loss:  0.20876958966255188 0.0 15.789698600769043
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([305,  70, 363, 291], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.19791120290756226
bi 1 loss 0.03475106507539749
bi 2 loss 0.28859129548072815
bi 3 loss 0.1792699545621872
Layer  3  loss:  0.202850341796875 0.0 10.915888786315918
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([305,  31, 397, 291], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.20500341057777405
bi 1 loss 0.08837207406759262
bi 2 loss 0.2747090458869934
bi 3 loss 0.15796881914138794
Layer  4  loss:  0.20691365003585815 0.0 16.15947151184082
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1020
Curr loss timestep torch.Size([566, 4]) tensor([492,  63, 363, 291], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.2101961374282837
bi 1 loss 0.045641202479600906
bi 2 loss 0.29149341583251953
bi 3 loss 0.15802757441997528
Layer  5  loss:  0.20638328790664673 0.0 11.275784492492676
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([305,  73, 363, 291], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.22775804996490479
bi 1 loss 0.027883505448698997
bi 2 loss 0.26928818225860596
bi 3 loss 0.16283684968948364
Layer  6  loss:  0.18655095994472504 0.0 9.928644180297852
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1021
Curr loss timestep torch.Size([566, 4]) tensor([415,  48, 363, 291], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.20915570855140686
bi 1 loss 0.08145926147699356
bi 2 loss 0.24002434313297272
bi 3 loss 0.1373182088136673
Epoch 0: :   3%|▎         | 15337/600000 [02:20<1:29:12, v_num=12, reduced_train_loss=1.460, global_step=15335.0, consumed_samples=61344.0, train_step_timing in s=0.415]Epoch 0: :   3%|▎         | 15337/600000 [02:20<1:29:12, v_num=12, reduced_train_loss=1.540, global_step=15336.0, consumed_samples=61348.0, train_step_timing in s=0.390]loss mask original None

First layer loss:  3.3224735260009766 torch.Size([576, 4]) 12.504682540893555 0.0
Max loss timestep torch.Size([576, 4]) tensor([140, 374, 240, 219], device='cuda:0') tensor(241, device='cuda:0')
bi 0 loss 3.6899302005767822
speech mask sum tensor(168, device='cuda:0') loss mask sum tensor(168, device='cuda:0')
bi 1 loss 3.066204786300659
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 2 loss 3.307830333709717
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 3 loss 3.7335891723632812
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
logits torch.Size([576, 4, 257024]) labels torch.Size([576, 4]) 0 257022
Layer  0  loss:  3.729438066482544 0.0 9.54056453704834
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([261, 456, 269, 262], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 4.400710582733154
bi 1 loss 3.444720506668091
bi 2 loss 3.491212844848633
bi 3 loss 4.2856621742248535
Layer  1  loss:  4.102759838104248 0.0 10.38592529296875
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([193, 439, 332, 307], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 4.794788837432861
bi 1 loss 3.629903793334961
bi 2 loss 4.127640724182129
bi 3 loss 4.738175392150879
Layer  2  loss:  4.243636608123779 0.0 12.151138305664062
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([258, 425, 233, 222], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.807158470153809
bi 1 loss 3.725651264190674
bi 2 loss 4.460428237915039
bi 3 loss 4.815001964569092
Layer  3  loss:  4.401642799377441 0.0 10.981087684631348
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1023
Curr loss timestep torch.Size([576, 4]) tensor([196, 557, 310, 267], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 4.936343193054199
bi 1 loss 3.8316266536712646
bi 2 loss 4.620599746704102
bi 3 loss 5.18293571472168
Layer  4  loss:  4.416908264160156 0.0 9.744538307189941
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([240, 236, 278, 273], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 5.009592056274414
bi 1 loss 3.8935706615448
bi 2 loss 4.593840599060059
bi 3 loss 5.048163890838623
Layer  5  loss:  4.461982727050781 0.0 11.240174293518066
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1019
Curr loss timestep torch.Size([576, 4]) tensor([261, 154, 279, 266], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 5.099596977233887
bi 1 loss 3.905019760131836
bi 2 loss 4.637289047241211
bi 3 loss 5.150932788848877
Layer  6  loss:  4.510903358459473 0.0 10.355566024780273
logits torch.Size([576, 4, 1024]) labels torch.Size([576, 4]) 0 1022
Curr loss timestep torch.Size([576, 4]) tensor([233, 562, 308, 279], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 5.216765403747559
bi 1 loss 3.891174077987671
bi 2 loss 4.776453971862793
bi 3 loss 5.140174865722656
Epoch 0: :   3%|▎         | 15338/600000 [02:20<1:29:27, v_num=12, reduced_train_loss=1.540, global_step=15336.0, consumed_samples=61348.0, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15338/600000 [02:20<1:29:28, v_num=12, reduced_train_loss=33.20, global_step=15337.0, consumed_samples=61352.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  0.09381511062383652 torch.Size([597, 4]) 6.558793544769287 0.0
Max loss timestep torch.Size([597, 4]) tensor([ 93, 546, 360,  94], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.021633552387356758
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
bi 1 loss 0.15183869004249573
speech mask sum tensor(491, device='cuda:0') loss mask sum tensor(491, device='cuda:0')
bi 2 loss 0.03907181695103645
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
bi 3 loss 0.04047571122646332
speech mask sum tensor(90, device='cuda:0') loss mask sum tensor(90, device='cuda:0')
logits torch.Size([597, 4, 257024]) labels torch.Size([597, 4]) 0 257021
Layer  0  loss:  0.12911701202392578 0.0 19.52463150024414
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([154, 546, 311, 128], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.035760339349508286
bi 1 loss 0.18781450390815735
bi 2 loss 0.09689468890428543
bi 3 loss 0.037862345576286316
Layer  1  loss:  0.09396234154701233 0.0 4.801730155944824
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([106, 360, 147, 102], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.023096423596143723
bi 1 loss 0.135569766163826
bi 2 loss 0.06870126724243164
bi 3 loss 0.043096378445625305
Layer  2  loss:  0.11810038238763809 0.0 10.815970420837402
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([152, 546, 311,  68], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.024289337918162346
bi 1 loss 0.18297307193279266
bi 2 loss 0.07502961158752441
bi 3 loss 0.025157669559121132
Layer  3  loss:  0.13072510063648224 0.0 8.618810653686523
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([123, 520, 311, 109], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.031040068715810776
bi 1 loss 0.202499657869339
bi 2 loss 0.0777437761425972
bi 3 loss 0.03730934113264084
Layer  4  loss:  0.10023292899131775 0.0 5.371250152587891
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([164, 514, 311,  71], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.06261615455150604
bi 1 loss 0.13806568086147308
bi 2 loss 0.0711793601512909
bi 3 loss 0.032520052045583725
Layer  5  loss:  0.1434812843799591 0.0 8.036052703857422
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([159, 546, 311, 134], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.019163828343153
bi 1 loss 0.23158803582191467
bi 2 loss 0.07850024849176407
bi 3 loss 0.03148398920893669
Layer  6  loss:  0.14180141687393188 0.0 11.007131576538086
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([140, 546, 311,  72], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.017727244645357132
bi 1 loss 0.2091182917356491
bi 2 loss 0.1101745069026947
bi 3 loss 0.04651417210698128
Epoch 0: :   3%|▎         | 15339/600000 [02:21<1:29:44, v_num=12, reduced_train_loss=33.20, global_step=15337.0, consumed_samples=61352.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15339/600000 [02:21<1:29:44, v_num=12, reduced_train_loss=0.951, global_step=15338.0, consumed_samples=61356.0, train_step_timing in s=0.412]loss mask original None

First layer loss:  0.21558569371700287 torch.Size([647, 4]) 14.602176666259766 0.0
Max loss timestep torch.Size([647, 4]) tensor([512, 285, 598, 374], device='cuda:0') tensor(598, device='cuda:0')
bi 0 loss 0.13808876276016235
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
bi 1 loss 0.17559699714183807
speech mask sum tensor(505, device='cuda:0') loss mask sum tensor(505, device='cuda:0')
bi 2 loss 0.4198915362358093
speech mask sum tensor(395, device='cuda:0') loss mask sum tensor(395, device='cuda:0')
bi 3 loss 0.11528244614601135
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
logits torch.Size([647, 4, 257024]) labels torch.Size([647, 4]) 0 257023
Layer  0  loss:  0.2589588761329651 0.0 15.714030265808105
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([517, 589, 617, 377], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.213673934340477
bi 1 loss 0.28238773345947266
bi 2 loss 0.3644036650657654
bi 3 loss 0.1440565288066864
Layer  1  loss:  0.27905508875846863 0.0 14.354647636413574
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([517, 423, 584, 377], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.2292659878730774
bi 1 loss 0.2767705023288727
bi 2 loss 0.4017595052719116
bi 3 loss 0.18839892745018005
Layer  2  loss:  0.3086998164653778 0.0 17.358240127563477
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([517, 290, 613, 377], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.22594965994358063
bi 1 loss 0.34046369791030884
bi 2 loss 0.4814136028289795
bi 3 loss 0.140558123588562
Layer  3  loss:  0.32220953702926636 0.0 15.607831001281738
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([402, 423, 371, 376], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.22939708828926086
bi 1 loss 0.3263401687145233
bi 2 loss 0.47103768587112427
bi 3 loss 0.23808103799819946
Layer  4  loss:  0.3232371211051941 0.0 13.870304107666016
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([517, 573, 613, 321], device='cuda:0') tensor(613, device='cuda:0')
bi 0 loss 0.24963659048080444
bi 1 loss 0.3498508036136627
bi 2 loss 0.5083410739898682
bi 3 loss 0.13763019442558289
Layer  5  loss:  0.33768826723098755 0.0 19.532155990600586
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([517, 290, 613, 377], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.22094982862472534
bi 1 loss 0.3614164888858795
bi 2 loss 0.5480200052261353
bi 3 loss 0.1744244247674942
Layer  6  loss:  0.3127252459526062 0.0 12.09555435180664
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([402, 290, 373, 377], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.20035459101200104
bi 1 loss 0.33293014764785767
bi 2 loss 0.49310874938964844
bi 3 loss 0.18678724765777588
Epoch 0: :   3%|▎         | 15340/600000 [02:21<1:30:02, v_num=12, reduced_train_loss=0.951, global_step=15338.0, consumed_samples=61356.0, train_step_timing in s=0.412]Epoch 0: :   3%|▎         | 15340/600000 [02:21<1:30:02, v_num=12, reduced_train_loss=2.360, global_step=15339.0, consumed_samples=61360.0, train_step_timing in s=0.442]loss mask original None

First layer loss:  0.02297932282090187 torch.Size([341, 4]) 0.769658625125885 0.0
Max loss timestep torch.Size([341, 4]) tensor([283, 174, 280, 181], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.02821643464267254
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 1 loss 0.01686779037117958
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 2 loss 0.023952970281243324
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 3 loss 0.021015800535678864
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
logits torch.Size([341, 4, 257024]) labels torch.Size([341, 4]) 0 257022
Layer  0  loss:  0.0383620485663414 0.0 6.082160472869873
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1023
Curr loss timestep torch.Size([341, 4]) tensor([305, 205, 279, 244], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.02560034953057766
bi 1 loss 0.015117603354156017
bi 2 loss 0.07965175062417984
bi 3 loss 0.015430064871907234
Layer  1  loss:  0.029338352382183075 0.0 5.59752893447876
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1023
Curr loss timestep torch.Size([341, 4]) tensor([283, 199, 281,  98], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.023081792518496513
bi 1 loss 0.01041959784924984
bi 2 loss 0.06002166122198105
bi 3 loss 0.010715318843722343
Layer  2  loss:  0.02649541199207306 0.0 4.799789905548096
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1022
Curr loss timestep torch.Size([341, 4]) tensor([315, 224, 281, 166], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.016931653022766113
bi 1 loss 0.01549752987921238
bi 2 loss 0.04743467643857002
bi 3 loss 0.016752230003476143
Layer  3  loss:  0.035404764115810394 0.0 7.018624782562256
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1022
Curr loss timestep torch.Size([341, 4]) tensor([283, 205, 280,  95], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.021458733826875687
bi 1 loss 0.020104967057704926
bi 2 loss 0.07180360704660416
bi 3 loss 0.014711001887917519
Layer  4  loss:  0.03097107633948326 0.0 5.43881893157959
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1022
Curr loss timestep torch.Size([341, 4]) tensor([296, 203, 281, 199], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.020934537053108215
bi 1 loss 0.01629738323390484
bi 2 loss 0.062152035534381866
bi 3 loss 0.012587168253958225
Layer  5  loss:  0.03958943113684654 0.0 6.481100082397461
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1022
Curr loss timestep torch.Size([341, 4]) tensor([278, 175, 280, 182], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.02125686965882778
bi 1 loss 0.011945766396820545
bi 2 loss 0.08640662580728531
bi 3 loss 0.01701633259654045
Layer  6  loss:  0.041374657303094864 0.0 10.850814819335938
logits torch.Size([341, 4, 1024]) labels torch.Size([341, 4]) 0 1023
Curr loss timestep torch.Size([341, 4]) tensor([283, 158, 279, 187], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.022150853648781776
bi 1 loss 0.012308175675570965
bi 2 loss 0.09756329655647278
bi 3 loss 0.010315077379345894
Epoch 0: :   3%|▎         | 15341/600000 [02:22<1:30:13, v_num=12, reduced_train_loss=2.360, global_step=15339.0, consumed_samples=61360.0, train_step_timing in s=0.442]Epoch 0: :   3%|▎         | 15341/600000 [02:22<1:30:13, v_num=12, reduced_train_loss=0.265, global_step=15340.0, consumed_samples=61364.0, train_step_timing in s=0.269]loss mask original None

First layer loss:  0.14877888560295105 torch.Size([558, 4]) 8.917281150817871 0.0
Max loss timestep torch.Size([558, 4]) tensor([276, 227, 321,  70], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.18095067143440247
speech mask sum tensor(445, device='cuda:0') loss mask sum tensor(445, device='cuda:0')
bi 1 loss 0.04119586572051048
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 2 loss 0.18557998538017273
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
bi 3 loss 0.007478320971131325
speech mask sum tensor(63, device='cuda:0') loss mask sum tensor(63, device='cuda:0')
logits torch.Size([558, 4, 257024]) labels torch.Size([558, 4]) 0 257023
Layer  0  loss:  0.16811677813529968 0.0 18.23441505432129
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([277, 169, 320,  75], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.21371638774871826
bi 1 loss 0.04809647798538208
bi 2 loss 0.19512629508972168
bi 3 loss 0.02707263082265854
Layer  1  loss:  0.18340998888015747 0.0 13.476649284362793
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([276, 127, 319,  78], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.25964370369911194
bi 1 loss 0.05453398451209068
bi 2 loss 0.18386757373809814
bi 3 loss 0.012422122061252594
Layer  2  loss:  0.2251838743686676 0.0 13.448100090026855
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([277, 222, 319,  80], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.30657482147216797
bi 1 loss 0.04519317299127579
bi 2 loss 0.2484838217496872
bi 3 loss 0.0261166263371706
Layer  3  loss:  0.18659313023090363 0.0 16.723590850830078
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([276, 128, 257,  74], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.24482101202011108
bi 1 loss 0.07290623337030411
bi 2 loss 0.19689135253429413
bi 3 loss 0.03948185220360756
Layer  4  loss:  0.1829710453748703 0.0 12.616761207580566
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([276, 211, 320,  76], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.2481185495853424
bi 1 loss 0.05429584160447121
bi 2 loss 0.1954967975616455
bi 3 loss 0.01653788611292839
Layer  5  loss:  0.22677119076251984 0.0 13.42856502532959
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([274, 195, 320,  98], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.28903067111968994
bi 1 loss 0.06557878851890564
bi 2 loss 0.2643236815929413
bi 3 loss 0.022411106154322624
Layer  6  loss:  0.2262408286333084 0.0 17.98081398010254
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([276, 201, 320,  76], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.3124310076236725
bi 1 loss 0.060772333294153214
bi 2 loss 0.23774075508117676
bi 3 loss 0.0231007132679224
Epoch 0: :   3%|▎         | 15342/600000 [02:22<1:30:29, v_num=12, reduced_train_loss=0.265, global_step=15340.0, consumed_samples=61364.0, train_step_timing in s=0.269]Epoch 0: :   3%|▎         | 15342/600000 [02:22<1:30:29, v_num=12, reduced_train_loss=1.550, global_step=15341.0, consumed_samples=61368.0, train_step_timing in s=0.378]loss mask original None

First layer loss:  0.12236643582582474 torch.Size([486, 4]) 8.045612335205078 0.0
Max loss timestep torch.Size([486, 4]) tensor([460, 271, 231, 131], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 0.08089590072631836
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
bi 1 loss 0.07633514702320099
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 2 loss 0.269654780626297
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
bi 3 loss 0.0277979988604784
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
logits torch.Size([486, 4, 257024]) labels torch.Size([486, 4]) 0 257022
Layer  0  loss:  0.12133035808801651 0.0 13.656538009643555
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1023
Curr loss timestep torch.Size([486, 4]) tensor([460, 209, 283, 151], device='cuda:0') tensor(460, device='cuda:0')
bi 0 loss 0.1223277673125267
bi 1 loss 0.06032564863562584
bi 2 loss 0.20597387850284576
bi 3 loss 0.039480529725551605
Layer  1  loss:  0.13691376149654388 0.0 10.013616561889648
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1022
Curr loss timestep torch.Size([486, 4]) tensor([460, 288, 432,  84], device='cuda:0') tensor(460, device='cuda:0')
bi 0 loss 0.13465534150600433
bi 1 loss 0.06221063807606697
bi 2 loss 0.24544118344783783
bi 3 loss 0.03848867118358612
Layer  2  loss:  0.15283961594104767 0.0 15.242534637451172
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1023
Curr loss timestep torch.Size([486, 4]) tensor([460, 205, 432, 130], device='cuda:0') tensor(460, device='cuda:0')
bi 0 loss 0.18802818655967712
bi 1 loss 0.06588074564933777
bi 2 loss 0.20427605509757996
bi 3 loss 0.06805792450904846
Layer  3  loss:  0.14258220791816711 0.0 11.445055961608887
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1023
Curr loss timestep torch.Size([486, 4]) tensor([460, 293, 430, 152], device='cuda:0') tensor(460, device='cuda:0')
bi 0 loss 0.15092279016971588
bi 1 loss 0.06309298425912857
bi 2 loss 0.24540981650352478
bi 3 loss 0.026852421462535858
Layer  4  loss:  0.11581431329250336 0.0 11.480688095092773
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1023
Curr loss timestep torch.Size([486, 4]) tensor([460, 271, 430, 136], device='cuda:0') tensor(430, device='cuda:0')
bi 0 loss 0.09557897597551346
bi 1 loss 0.10125526040792465
bi 2 loss 0.19926533102989197
bi 3 loss 0.02891814336180687
Layer  5  loss:  0.1286361813545227 0.0 9.478930473327637
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1023
Curr loss timestep torch.Size([486, 4]) tensor([460, 172, 285, 133], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.12217942625284195
bi 1 loss 0.09124090522527695
bi 2 loss 0.2092006355524063
bi 3 loss 0.039766229689121246
Layer  6  loss:  0.16751639544963837 0.0 12.243104934692383
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1023
Curr loss timestep torch.Size([486, 4]) tensor([460, 271, 430, 127], device='cuda:0') tensor(430, device='cuda:0')
bi 0 loss 0.1596643030643463
bi 1 loss 0.10103855282068253
bi 2 loss 0.2811640799045563
bi 3 loss 0.06291628628969193
Epoch 0: :   3%|▎         | 15343/600000 [02:22<1:30:43, v_num=12, reduced_train_loss=1.550, global_step=15341.0, consumed_samples=61368.0, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15343/600000 [02:22<1:30:43, v_num=12, reduced_train_loss=1.090, global_step=15342.0, consumed_samples=61372.0, train_step_timing in s=0.341]loss mask original None

First layer loss:  0.22439144551753998 torch.Size([678, 4]) 16.562549591064453 0.0
Max loss timestep torch.Size([678, 4]) tensor([ 70, 312, 393, 443], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.030193304643034935
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 1 loss 0.13626696169376373
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
bi 2 loss 0.35035619139671326
speech mask sum tensor(445, device='cuda:0') loss mask sum tensor(445, device='cuda:0')
bi 3 loss 0.2464154064655304
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
logits torch.Size([678, 4, 257024]) labels torch.Size([678, 4]) 0 257022
Layer  0  loss:  0.2584450840950012 0.0 13.783514976501465
logits torch.Size([678, 4, 1024]) labels torch.Size([678, 4]) 0 1023
Curr loss timestep torch.Size([678, 4]) tensor([ 69, 313, 505, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.02082853578031063
bi 1 loss 0.24660339951515198
bi 2 loss 0.34973180294036865
bi 3 loss 0.2733522057533264
Layer  1  loss:  0.2700985074043274 0.0 13.585440635681152
logits torch.Size([678, 4, 1024]) labels torch.Size([678, 4]) 0 1022
Curr loss timestep torch.Size([678, 4]) tensor([144, 312, 305, 295], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.035176727920770645
bi 1 loss 0.281819611787796
bi 2 loss 0.39902493357658386
bi 3 loss 0.2158646285533905
Layer  2  loss:  0.2678367495536804 0.0 10.193506240844727
logits torch.Size([678, 4, 1024]) labels torch.Size([678, 4]) 0 1023
Curr loss timestep torch.Size([678, 4]) tensor([149, 408, 501, 443], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.05084694176912308
bi 1 loss 0.29873040318489075
bi 2 loss 0.35493066906929016
bi 3 loss 0.2382742464542389
Layer  3  loss:  0.29608821868896484 0.0 17.496185302734375
logits torch.Size([678, 4, 1024]) labels torch.Size([678, 4]) 0 1022
Curr loss timestep torch.Size([678, 4]) tensor([111, 313, 505, 295], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.03812943398952484
bi 1 loss 0.35358473658561707
bi 2 loss 0.3528526723384857
bi 3 loss 0.29889655113220215
Layer  4  loss:  0.330529123544693 0.0 18.053255081176758
logits torch.Size([678, 4, 1024]) labels torch.Size([678, 4]) 0 1023
Curr loss timestep torch.Size([678, 4]) tensor([ 96, 313, 646, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.03613166883587837
bi 1 loss 0.40913259983062744
bi 2 loss 0.4382116496562958
bi 3 loss 0.26926615834236145
Layer  5  loss:  0.3010038435459137 0.0 18.331735610961914
logits torch.Size([678, 4, 1024]) labels torch.Size([678, 4]) 0 1023
Curr loss timestep torch.Size([678, 4]) tensor([110, 313, 305, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.04774782806634903
bi 1 loss 0.33090463280677795
bi 2 loss 0.37820085883140564
bi 3 loss 0.30209478735923767
Layer  6  loss:  0.2877734303474426 0.0 13.518238067626953
logits torch.Size([678, 4, 1024]) labels torch.Size([678, 4]) 0 1020
Curr loss timestep torch.Size([678, 4]) tensor([102, 313, 501, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.03755815327167511
bi 1 loss 0.31995517015457153
bi 2 loss 0.39074432849884033
bi 3 loss 0.25376465916633606
Epoch 0: :   3%|▎         | 15344/600000 [02:23<1:31:02, v_num=12, reduced_train_loss=1.090, global_step=15342.0, consumed_samples=61372.0, train_step_timing in s=0.341]Epoch 0: :   3%|▎         | 15344/600000 [02:23<1:31:02, v_num=12, reduced_train_loss=2.240, global_step=15343.0, consumed_samples=61376.0, train_step_timing in s=0.461]loss mask original None

First layer loss:  0.09421709179878235 torch.Size([703, 4]) 7.06203556060791 0.0
Max loss timestep torch.Size([703, 4]) tensor([303, 116, 451, 322], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.09162596613168716
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 1 loss 0.04759693145751953
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 2 loss 0.12489275634288788
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
bi 3 loss 0.05338204652070999
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
logits torch.Size([703, 4, 257024]) labels torch.Size([703, 4]) 0 257023
Layer  0  loss:  0.12377233058214188 0.0 8.01269817352295
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([303,  45, 451, 331], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.10187698900699615
bi 1 loss 0.040644850581884384
bi 2 loss 0.169388085603714
bi 3 loss 0.09595748782157898
Layer  1  loss:  0.10578488558530807 0.0 7.3911566734313965
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([355, 118, 423, 331], device='cuda:0') tensor(423, device='cuda:0')
bi 0 loss 0.09915123134851456
bi 1 loss 0.03804761543869972
bi 2 loss 0.12937845289707184
bi 3 loss 0.09818176925182343
Layer  2  loss:  0.12008275091648102 0.0 10.305206298828125
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([303, 110, 343, 289], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.14953778684139252
bi 1 loss 0.02648928202688694
bi 2 loss 0.14061978459358215
bi 3 loss 0.08255160599946976
Layer  3  loss:  0.1288914829492569 0.0 9.42064380645752
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([355,  51, 409, 331], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.12013133615255356
bi 1 loss 0.0378325954079628
bi 2 loss 0.16135269403457642
bi 3 loss 0.11675640195608139
Layer  4  loss:  0.12415225803852081 0.0 9.448585510253906
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([303,  45, 451, 333], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.11202994734048843
bi 1 loss 0.036720454692840576
bi 2 loss 0.16861273348331451
bi 3 loss 0.08751663565635681
Layer  5  loss:  0.1240653544664383 0.0 8.37680435180664
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([303,  46, 423, 333], device='cuda:0') tensor(423, device='cuda:0')
bi 0 loss 0.07473921030759811
bi 1 loss 0.02976531721651554
bi 2 loss 0.18560385704040527
bi 3 loss 0.10477566719055176
Layer  6  loss:  0.1410244107246399 0.0 14.656349182128906
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([355, 102, 452, 279], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.11218424141407013
bi 1 loss 0.05801393464207649
bi 2 loss 0.18378640711307526
bi 3 loss 0.12942390143871307
Epoch 0: :   3%|▎         | 15345/600000 [02:23<1:31:21, v_num=12, reduced_train_loss=2.240, global_step=15343.0, consumed_samples=61376.0, train_step_timing in s=0.461]Epoch 0: :   3%|▎         | 15345/600000 [02:23<1:31:21, v_num=12, reduced_train_loss=0.962, global_step=15344.0, consumed_samples=61380.0, train_step_timing in s=0.482]loss mask original None

First layer loss:  0.12241792678833008 torch.Size([535, 4]) 10.989453315734863 0.0
Max loss timestep torch.Size([535, 4]) tensor([316, 351, 122, 374], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.17482656240463257
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
bi 1 loss 0.09702419489622116
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
bi 2 loss 0.041311293840408325
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
bi 3 loss 0.11049649864435196
speech mask sum tensor(303, device='cuda:0') loss mask sum tensor(303, device='cuda:0')
logits torch.Size([535, 4, 257024]) labels torch.Size([535, 4]) 0 257022
Layer  0  loss:  0.11847854405641556 0.0 9.551169395446777
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([316, 278, 140, 273], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.15031766891479492
bi 1 loss 0.13291464745998383
bi 2 loss 0.031588032841682434
bi 3 loss 0.11027933657169342
Layer  1  loss:  0.12057556957006454 0.0 10.566017150878906
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([451, 276,  72, 273], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.16152383387088776
bi 1 loss 0.10058014839887619
bi 2 loss 0.05101437866687775
bi 3 loss 0.11518560349941254
Layer  2  loss:  0.14126023650169373 0.0 14.672309875488281
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([452, 276,  86, 335], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.1948697865009308
bi 1 loss 0.10842675715684891
bi 2 loss 0.04506784304976463
bi 3 loss 0.14270782470703125
Layer  3  loss:  0.14410382509231567 0.0 8.799838066101074
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1021
Curr loss timestep torch.Size([535, 4]) tensor([451, 276, 151, 273], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.18244749307632446
bi 1 loss 0.14205007255077362
bi 2 loss 0.05786462128162384
bi 3 loss 0.1385868936777115
Layer  4  loss:  0.1675560623407364 0.0 13.83228874206543
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([451, 351,  81, 273], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.22365215420722961
bi 1 loss 0.15019379556179047
bi 2 loss 0.04297768324613571
bi 3 loss 0.17007194459438324
Layer  5  loss:  0.15060624480247498 0.0 9.439188003540039
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([377, 278, 147, 259], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.2156192809343338
bi 1 loss 0.12246263027191162
bi 2 loss 0.07361254096031189
bi 3 loss 0.11861511319875717
Layer  6  loss:  0.13853275775909424 0.0 11.948827743530273
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1021
Curr loss timestep torch.Size([535, 4]) tensor([451, 351,  98, 273], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.2049599289894104
bi 1 loss 0.09790895879268646
bi 2 loss 0.03642498701810837
bi 3 loss 0.12979130446910858
Epoch 0: :   3%|▎         | 15346/600000 [02:24<1:31:36, v_num=12, reduced_train_loss=0.962, global_step=15344.0, consumed_samples=61380.0, train_step_timing in s=0.482]Epoch 0: :   3%|▎         | 15346/600000 [02:24<1:31:36, v_num=12, reduced_train_loss=1.100, global_step=15345.0, consumed_samples=61384.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  3.890676975250244 torch.Size([696, 4]) 9.8999662399292 0.0
Max loss timestep torch.Size([696, 4]) tensor([157, 360, 372, 199], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 4.278032302856445
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
bi 1 loss 3.9421799182891846
speech mask sum tensor(438, device='cuda:0') loss mask sum tensor(438, device='cuda:0')
bi 2 loss 4.007490634918213
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 3 loss 3.1719863414764404
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
logits torch.Size([696, 4, 257024]) labels torch.Size([696, 4]) 0 257022
Layer  0  loss:  4.3990373611450195 0.0 10.768620491027832
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([329, 628, 151, 299], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 4.045510292053223
bi 1 loss 4.797452449798584
bi 2 loss 4.4031171798706055
bi 3 loss 3.980309009552002
Layer  1  loss:  4.810451030731201 0.0 10.56546688079834
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([272, 321, 323, 332], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 4.767854690551758
bi 1 loss 5.079597473144531
bi 2 loss 4.675352096557617
bi 3 loss 4.484732151031494
Layer  2  loss:  5.118212699890137 0.0 10.25228214263916
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([206, 585, 312, 333], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 4.977351188659668
bi 1 loss 5.342206001281738
bi 2 loss 5.099410057067871
bi 3 loss 4.843621730804443
Layer  3  loss:  5.169242858886719 0.0 9.855420112609863
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([298, 458, 167, 295], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 5.116065502166748
bi 1 loss 5.400918483734131
bi 2 loss 5.071028709411621
bi 3 loss 4.8836989402771
Layer  4  loss:  5.260760307312012 0.0 10.128110885620117
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([117, 389, 316, 380], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 5.360333442687988
bi 1 loss 5.386170387268066
bi 2 loss 5.085363864898682
bi 3 loss 5.121609687805176
Layer  5  loss:  5.306855201721191 0.0 9.568336486816406
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([331, 531, 239, 382], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 5.260483264923096
bi 1 loss 5.5104498863220215
bi 2 loss 5.228013515472412
bi 3 loss 5.045378684997559
Layer  6  loss:  5.362405776977539 0.0 9.923820495605469
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([151, 646, 346, 220], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 5.30516242980957
bi 1 loss 5.615542411804199
bi 2 loss 5.147548198699951
bi 3 loss 5.19517707824707
Epoch 0: :   3%|▎         | 15347/600000 [02:24<1:31:53, v_num=12, reduced_train_loss=1.100, global_step=15345.0, consumed_samples=61384.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15347/600000 [02:24<1:31:53, v_num=12, reduced_train_loss=39.30, global_step=15346.0, consumed_samples=61388.0, train_step_timing in s=0.426]loss mask original None

First layer loss:  0.07629776746034622 torch.Size([505, 4]) 6.852687835693359 0.0
Max loss timestep torch.Size([505, 4]) tensor([303, 279, 318, 195], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.09749884903430939
speech mask sum tensor(454, device='cuda:0') loss mask sum tensor(454, device='cuda:0')
bi 1 loss 0.06170188635587692
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 2 loss 0.07069133222103119
speech mask sum tensor(297, device='cuda:0') loss mask sum tensor(297, device='cuda:0')
bi 3 loss 0.03198278695344925
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
logits torch.Size([505, 4, 257024]) labels torch.Size([505, 4]) 0 257023
Layer  0  loss:  0.09811735898256302 0.0 9.379913330078125
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1023
Curr loss timestep torch.Size([505, 4]) tensor([301, 281, 289, 202], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.11847866326570511
bi 1 loss 0.08066964149475098
bi 2 loss 0.10063787549734116
bi 3 loss 0.041200555860996246
Layer  1  loss:  0.0957881435751915 0.0 6.265683174133301
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1022
Curr loss timestep torch.Size([505, 4]) tensor([305, 281, 363, 144], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.121066153049469
bi 1 loss 0.06077996641397476
bi 2 loss 0.09206639230251312
bi 3 loss 0.06157820671796799
Layer  2  loss:  0.09791021794080734 0.0 9.537710189819336
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1022
Curr loss timestep torch.Size([505, 4]) tensor([302, 278, 319, 164], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.11435551941394806
bi 1 loss 0.11586954444646835
bi 2 loss 0.0898360013961792
bi 3 loss 0.029605325311422348
Layer  3  loss:  0.1090724989771843 0.0 9.715814590454102
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1021
Curr loss timestep torch.Size([505, 4]) tensor([301, 278, 428, 210], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.13999603688716888
bi 1 loss 0.10130175203084946
bi 2 loss 0.08611515909433365
bi 3 loss 0.060826465487480164
Layer  4  loss:  0.09638597071170807 0.0 5.451875686645508
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1021
Curr loss timestep torch.Size([505, 4]) tensor([302, 278, 318, 138], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.12697795033454895
bi 1 loss 0.10674361884593964
bi 2 loss 0.06536422669887543
bi 3 loss 0.0425102598965168
Layer  5  loss:  0.11540399491786957 0.0 6.472733974456787
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1023
Curr loss timestep torch.Size([505, 4]) tensor([303, 278, 393, 126], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.12022631615400314
bi 1 loss 0.12919962406158447
bi 2 loss 0.12859760224819183
bi 3 loss 0.044631559401750565
Layer  6  loss:  0.13180214166641235 0.0 12.215959548950195
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1022
Curr loss timestep torch.Size([505, 4]) tensor([301, 278, 271, 172], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.14952611923217773
bi 1 loss 0.11533083766698837
bi 2 loss 0.14736701548099518
bi 3 loss 0.0513264425098896
Epoch 0: :   3%|▎         | 15348/600000 [02:25<1:32:08, v_num=12, reduced_train_loss=39.30, global_step=15346.0, consumed_samples=61388.0, train_step_timing in s=0.426]Epoch 0: :   3%|▎         | 15348/600000 [02:25<1:32:08, v_num=12, reduced_train_loss=0.821, global_step=15347.0, consumed_samples=61392.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  0.12607839703559875 torch.Size([601, 4]) 9.827897071838379 0.0
Max loss timestep torch.Size([601, 4]) tensor([283, 565, 538, 154], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.07877770066261292
speech mask sum tensor(401, device='cuda:0') loss mask sum tensor(401, device='cuda:0')
bi 1 loss 0.16062785685062408
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
bi 2 loss 0.17313992977142334
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 3 loss 0.056098178029060364
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
logits torch.Size([601, 4, 257024]) labels torch.Size([601, 4]) 0 257023
Layer  0  loss:  0.12344659119844437 0.0 10.460125923156738
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([280, 527, 538,  97], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.06926045566797256
bi 1 loss 0.14314837753772736
bi 2 loss 0.19550631940364838
bi 3 loss 0.04692086949944496
Layer  1  loss:  0.15913358330726624 0.0 10.439239501953125
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([283, 565, 552, 123], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.0676555335521698
bi 1 loss 0.19698581099510193
bi 2 loss 0.2612399756908417
bi 3 loss 0.06939127296209335
Layer  2  loss:  0.17005817592144012 0.0 9.119613647460938
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([264, 565, 456, 152], device='cuda:0') tensor(565, device='cuda:0')
bi 0 loss 0.09614785760641098
bi 1 loss 0.2327103465795517
bi 2 loss 0.2412058264017105
bi 3 loss 0.04462822899222374
Layer  3  loss:  0.15974068641662598 0.0 9.433356285095215
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1019
Curr loss timestep torch.Size([601, 4]) tensor([284, 591, 456,  70], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.08254830539226532
bi 1 loss 0.2255120426416397
bi 2 loss 0.2232866734266281
bi 3 loss 0.056109365075826645
Layer  4  loss:  0.1994367390871048 0.0 13.983824729919434
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([315, 569, 521, 123], device='cuda:0') tensor(569, device='cuda:0')
bi 0 loss 0.09213332831859589
bi 1 loss 0.25214695930480957
bi 2 loss 0.3311120569705963
bi 3 loss 0.041499774903059006
Layer  5  loss:  0.1659475713968277 0.0 19.112491607666016
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([280, 591, 456, 105], device='cuda:0') tensor(591, device='cuda:0')
bi 0 loss 0.07401429116725922
bi 1 loss 0.23859022557735443
bi 2 loss 0.2449195235967636
bi 3 loss 0.04856107756495476
Layer  6  loss:  0.19662539660930634 0.0 13.247424125671387
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([451, 569, 457,  83], device='cuda:0') tensor(457, device='cuda:0')
bi 0 loss 0.09421892464160919
bi 1 loss 0.2428126037120819
bi 2 loss 0.32707148790359497
bi 3 loss 0.0439719520509243
Epoch 0: :   3%|▎         | 15349/600000 [02:25<1:32:25, v_num=12, reduced_train_loss=0.821, global_step=15347.0, consumed_samples=61392.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15349/600000 [02:25<1:32:25, v_num=12, reduced_train_loss=1.300, global_step=15348.0, consumed_samples=61396.0, train_step_timing in s=0.411]loss mask original None

First layer loss:  0.015849053859710693 torch.Size([363, 4]) 0.2690041959285736 0.0
Max loss timestep torch.Size([363, 4]) tensor([260,  81, 298,  93], device='cuda:0') tensor(93, device='cuda:0')
bi 0 loss 0.019144657999277115
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 1 loss 0.013931648805737495
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 2 loss 0.01225807424634695
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 3 loss 0.01698300614953041
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
logits torch.Size([363, 4, 257024]) labels torch.Size([363, 4]) 0 257023
Layer  0  loss:  0.012923858128488064 0.0 0.20451620221138
logits torch.Size([363, 4, 1024]) labels torch.Size([363, 4]) 0 1023
Curr loss timestep torch.Size([363, 4]) tensor([322, 102, 201, 105], device='cuda:0') tensor(102, device='cuda:0')
bi 0 loss 0.012799475342035294
bi 1 loss 0.013136234134435654
bi 2 loss 0.010969909839332104
bi 3 loss 0.015214556828141212
Layer  1  loss:  0.01483867596834898 0.0 0.2180682122707367
logits torch.Size([363, 4, 1024]) labels torch.Size([363, 4]) 0 1023
Curr loss timestep torch.Size([363, 4]) tensor([294, 104, 254,  65], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 0.019499031826853752
bi 1 loss 0.01071050576865673
bi 2 loss 0.011798613704741001
bi 3 loss 0.01497164461761713
Layer  2  loss:  0.014521204866468906 0.0 0.2058396190404892
logits torch.Size([363, 4, 1024]) labels torch.Size([363, 4]) 0 1022
Curr loss timestep torch.Size([363, 4]) tensor([335, 107, 200, 161], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.018235931172966957
bi 1 loss 0.014202898368239403
bi 2 loss 0.012710639275610447
bi 3 loss 0.01204723957926035
Layer  3  loss:  0.01326843537390232 0.0 0.22884824872016907
logits torch.Size([363, 4, 1024]) labels torch.Size([363, 4]) 0 1021
Curr loss timestep torch.Size([363, 4]) tensor([276, 103, 288,  98], device='cuda:0') tensor(103, device='cuda:0')
bi 0 loss 0.018247682601213455
bi 1 loss 0.010885012336075306
bi 2 loss 0.010278929024934769
bi 3 loss 0.011835414916276932
Layer  4  loss:  0.014507566578686237 0.0 0.32587242126464844
logits torch.Size([363, 4, 1024]) labels torch.Size([363, 4]) 0 1021
Curr loss timestep torch.Size([363, 4]) tensor([288,  83, 250, 127], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.01914467103779316
bi 1 loss 0.012833572924137115
bi 2 loss 0.0137372687458992
bi 3 loss 0.010495862923562527
Layer  5  loss:  0.015202690847218037 0.0 0.5093097686767578
logits torch.Size([363, 4, 1024]) labels torch.Size([363, 4]) 0 1020
Curr loss timestep torch.Size([363, 4]) tensor([272, 137, 322, 147], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.022292977198958397
bi 1 loss 0.011140712536871433
bi 2 loss 0.012020502239465714
bi 3 loss 0.012336835265159607
Layer  6  loss:  0.015290358103811741 0.0 0.5519698858261108
logits torch.Size([363, 4, 1024]) labels torch.Size([363, 4]) 0 1022
Curr loss timestep torch.Size([363, 4]) tensor([346,  69, 221, 123], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 0.019800107926130295
bi 1 loss 0.009604503400623798
bi 2 loss 0.012371398508548737
bi 3 loss 0.016456466168165207
Epoch 0: :   3%|▎         | 15350/600000 [02:25<1:32:36, v_num=12, reduced_train_loss=1.300, global_step=15348.0, consumed_samples=61396.0, train_step_timing in s=0.411]Epoch 0: :   3%|▎         | 15350/600000 [02:25<1:32:36, v_num=12, reduced_train_loss=0.116, global_step=15349.0, consumed_samples=61400.0, train_step_timing in s=0.280]loss mask original None

First layer loss:  3.434290647506714 torch.Size([340, 4]) 10.035870552062988 0.0
Max loss timestep torch.Size([340, 4]) tensor([118, 121, 269, 241], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 3.158839702606201
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 1 loss 3.3934731483459473
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 2 loss 3.646427869796753
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 3 loss 3.637491226196289
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
logits torch.Size([340, 4, 257024]) labels torch.Size([340, 4]) 0 257023
Layer  0  loss:  3.979668617248535 0.0 9.91819953918457
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1023
Curr loss timestep torch.Size([340, 4]) tensor([239, 210, 263, 270], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 3.7699778079986572
bi 1 loss 3.8364272117614746
bi 2 loss 3.985016345977783
bi 3 loss 4.271444797515869
Layer  1  loss:  4.321876525878906 0.0 9.693720817565918
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1023
Curr loss timestep torch.Size([340, 4]) tensor([187, 179, 289, 240], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.008157730102539
bi 1 loss 4.172249794006348
bi 2 loss 4.491075038909912
bi 3 loss 4.642539024353027
Layer  2  loss:  4.6616950035095215 0.0 11.299568176269531
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1022
Curr loss timestep torch.Size([340, 4]) tensor([131, 134, 253, 290], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 4.354165554046631
bi 1 loss 4.334836959838867
bi 2 loss 4.770915508270264
bi 3 loss 5.095773696899414
Layer  3  loss:  4.7577948570251465 0.0 10.128372192382812
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1021
Curr loss timestep torch.Size([340, 4]) tensor([181, 135, 216, 143], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.527085304260254
bi 1 loss 4.38874626159668
bi 2 loss 4.77904748916626
bi 3 loss 5.176999568939209
Layer  4  loss:  4.8558125495910645 0.0 9.856228828430176
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1021
Curr loss timestep torch.Size([340, 4]) tensor([251, 218, 274, 255], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.685704231262207
bi 1 loss 4.629862308502197
bi 2 loss 4.863256931304932
bi 3 loss 5.145990371704102
Layer  5  loss:  4.981319904327393 0.0 9.847308158874512
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1021
Curr loss timestep torch.Size([340, 4]) tensor([187, 194, 312, 281], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.784732341766357
bi 1 loss 4.580056667327881
bi 2 loss 4.890322685241699
bi 3 loss 5.438537120819092
Layer  6  loss:  5.030605792999268 0.0 10.15606689453125
logits torch.Size([340, 4, 1024]) labels torch.Size([340, 4]) 0 1021
Curr loss timestep torch.Size([340, 4]) tensor([290, 179, 300,  96], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.915217399597168
bi 1 loss 4.7210469245910645
bi 2 loss 4.817544937133789
bi 3 loss 5.418731212615967
Epoch 0: :   3%|▎         | 15351/600000 [02:26<1:32:48, v_num=12, reduced_train_loss=0.116, global_step=15349.0, consumed_samples=61400.0, train_step_timing in s=0.280]Epoch 0: :   3%|▎         | 15351/600000 [02:26<1:32:48, v_num=12, reduced_train_loss=36.00, global_step=15350.0, consumed_samples=61404.0, train_step_timing in s=0.265]loss mask original None

First layer loss:  3.609356164932251 torch.Size([660, 4]) 10.046391487121582 0.0
Max loss timestep torch.Size([660, 4]) tensor([206, 431, 201, 198], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 2.9785945415496826
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 1 loss 3.9220895767211914
speech mask sum tensor(497, device='cuda:0') loss mask sum tensor(497, device='cuda:0')
bi 2 loss 3.1380481719970703
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 4.104572296142578
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
logits torch.Size([660, 4, 257024]) labels torch.Size([660, 4]) 0 257023
Layer  0  loss:  4.121821403503418 0.0 9.721878051757812
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1023
Curr loss timestep torch.Size([660, 4]) tensor([200, 569, 197, 168], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 3.8140156269073486
bi 1 loss 4.2762274742126465
bi 2 loss 3.62705135345459
bi 3 loss 4.557399272918701
Layer  1  loss:  4.472325801849365 0.0 10.876462936401367
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1023
Curr loss timestep torch.Size([660, 4]) tensor([403, 306, 281, 221], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 3.91113018989563
bi 1 loss 4.821379661560059
bi 2 loss 3.9717302322387695
bi 3 loss 4.775156021118164
Layer  2  loss:  4.66032600402832 0.0 10.137792587280273
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1022
Curr loss timestep torch.Size([660, 4]) tensor([154, 561, 207,  79], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.151803493499756
bi 1 loss 4.964348793029785
bi 2 loss 4.059352874755859
bi 3 loss 5.079920768737793
Layer  3  loss:  4.8000593185424805 0.0 10.276273727416992
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1020
Curr loss timestep torch.Size([660, 4]) tensor([201, 494, 220, 180], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 4.267460346221924
bi 1 loss 5.137778282165527
bi 2 loss 4.179351806640625
bi 3 loss 5.178766250610352
Layer  4  loss:  5.018215179443359 0.0 11.111734390258789
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1023
Curr loss timestep torch.Size([660, 4]) tensor([334, 500, 236, 121], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 4.4570536613464355
bi 1 loss 5.4078688621521
bi 2 loss 4.244692325592041
bi 3 loss 5.412072658538818
Layer  5  loss:  5.035382270812988 0.0 10.229576110839844
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1023
Curr loss timestep torch.Size([660, 4]) tensor([404, 366, 237, 127], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 4.468028545379639
bi 1 loss 5.401185035705566
bi 2 loss 4.30495548248291
bi 3 loss 5.4738335609436035
Layer  6  loss:  5.0487518310546875 0.0 10.817644119262695
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1022
Curr loss timestep torch.Size([660, 4]) tensor([399, 502, 193, 136], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.469363689422607
bi 1 loss 5.430289268493652
bi 2 loss 4.3499932289123535
bi 3 loss 5.43867301940918
Epoch 0: :   3%|▎         | 15352/600000 [02:26<1:33:04, v_num=12, reduced_train_loss=36.00, global_step=15350.0, consumed_samples=61404.0, train_step_timing in s=0.265]Epoch 0: :   3%|▎         | 15352/600000 [02:26<1:33:04, v_num=12, reduced_train_loss=36.80, global_step=15351.0, consumed_samples=61408.0, train_step_timing in s=0.406]loss mask original None

First layer loss:  0.18174229562282562 torch.Size([609, 4]) 9.368234634399414 0.0
Max loss timestep torch.Size([609, 4]) tensor([392, 110, 176, 483], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.35162270069122314
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 1 loss 0.04957405850291252
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 2 loss 0.053717538714408875
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.171011820435524
speech mask sum tensor(434, device='cuda:0') loss mask sum tensor(434, device='cuda:0')
logits torch.Size([609, 4, 257024]) labels torch.Size([609, 4]) 0 257022
Layer  0  loss:  0.18247871100902557 0.0 9.003521919250488
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1023
Curr loss timestep torch.Size([609, 4]) tensor([328, 107, 197, 484], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.35025086998939514
bi 1 loss 0.11676507443189621
bi 2 loss 0.04422156140208244
bi 3 loss 0.1677805632352829
Layer  1  loss:  0.19206315279006958 0.0 9.597234725952148
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1021
Curr loss timestep torch.Size([609, 4]) tensor([327, 120, 247, 484], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.352359801530838
bi 1 loss 0.052274905145168304
bi 2 loss 0.09931305050849915
bi 3 loss 0.17408853769302368
Layer  2  loss:  0.21920417249202728 0.0 13.224379539489746
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1022
Curr loss timestep torch.Size([609, 4]) tensor([393,  99, 182, 483], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.43112170696258545
bi 1 loss 0.047457728534936905
bi 2 loss 0.06499060988426208
bi 3 loss 0.20477895438671112
Layer  3  loss:  0.23634904623031616 0.0 16.497583389282227
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1023
Curr loss timestep torch.Size([609, 4]) tensor([391, 121, 216, 483], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.5089632272720337
bi 1 loss 0.04041215032339096
bi 2 loss 0.05717497318983078
bi 3 loss 0.2079407274723053
Layer  4  loss:  0.23368224501609802 0.0 15.718905448913574
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1022
Curr loss timestep torch.Size([609, 4]) tensor([327, 111, 194, 483], device='cuda:0') tensor(483, device='cuda:0')
bi 0 loss 0.47988224029541016
bi 1 loss 0.0461730882525444
bi 2 loss 0.05151559039950371
bi 3 loss 0.21644574403762817
Layer  5  loss:  0.23047976195812225 0.0 14.742940902709961
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1023
Curr loss timestep torch.Size([609, 4]) tensor([393,  97, 276, 377], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.5257522463798523
bi 1 loss 0.04888419061899185
bi 2 loss 0.04938861355185509
bi 3 loss 0.1913147270679474
Layer  6  loss:  0.24621033668518066 0.0 16.560317993164062
logits torch.Size([609, 4, 1024]) labels torch.Size([609, 4]) 0 1023
Curr loss timestep torch.Size([609, 4]) tensor([392,  96, 279, 483], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.48596426844596863
bi 1 loss 0.030967451632022858
bi 2 loss 0.06291752308607101
bi 3 loss 0.23561321198940277
Epoch 0: :   3%|▎         | 15353/600000 [02:27<1:33:21, v_num=12, reduced_train_loss=36.80, global_step=15351.0, consumed_samples=61408.0, train_step_timing in s=0.406]Epoch 0: :   3%|▎         | 15353/600000 [02:27<1:33:21, v_num=12, reduced_train_loss=1.720, global_step=15352.0, consumed_samples=61412.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.12350986152887344 torch.Size([549, 4]) 9.984980583190918 0.0
Max loss timestep torch.Size([549, 4]) tensor([297, 503, 366,  57], device='cuda:0') tensor(503, device='cuda:0')
bi 0 loss 0.0729207694530487
speech mask sum tensor(371, device='cuda:0') loss mask sum tensor(371, device='cuda:0')
bi 1 loss 0.16344384849071503
speech mask sum tensor(463, device='cuda:0') loss mask sum tensor(463, device='cuda:0')
bi 2 loss 0.17024904489517212
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.02923058532178402
speech mask sum tensor(60, device='cuda:0') loss mask sum tensor(60, device='cuda:0')
logits torch.Size([549, 4, 257024]) labels torch.Size([549, 4]) 0 257023
Layer  0  loss:  0.13902774453163147 0.0 9.012613296508789
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([408, 433, 411,  78], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.07943021506071091
bi 1 loss 0.19986052811145782
bi 2 loss 0.14914476871490479
bi 3 loss 0.016698729246854782
Layer  1  loss:  0.12912768125534058 0.0 5.7585954666137695
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([343, 436, 411,  64], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.08830475807189941
bi 1 loss 0.16787122189998627
bi 2 loss 0.16272318363189697
bi 3 loss 0.011468070559203625
Layer  2  loss:  0.15679411590099335 0.0 9.930477142333984
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1022
Curr loss timestep torch.Size([549, 4]) tensor([292, 433, 337,  64], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.09261129051446915
bi 1 loss 0.20625630021095276
bi 2 loss 0.21537406742572784
bi 3 loss 0.04798036441206932
Layer  3  loss:  0.1566525250673294 0.0 9.25013542175293
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1018
Curr loss timestep torch.Size([549, 4]) tensor([400, 431, 394,  84], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.10442733019590378
bi 1 loss 0.19482013583183289
bi 2 loss 0.23606398701667786
bi 3 loss 0.016964079812169075
Layer  4  loss:  0.132730633020401 0.0 10.720407485961914
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1022
Curr loss timestep torch.Size([549, 4]) tensor([169, 433, 404,  60], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.09111925959587097
bi 1 loss 0.16241487860679626
bi 2 loss 0.20334282517433167
bi 3 loss 0.011501685716211796
Layer  5  loss:  0.15695258975028992 0.0 10.830534934997559
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1022
Curr loss timestep torch.Size([549, 4]) tensor([408, 503, 411,  64], device='cuda:0') tensor(503, device='cuda:0')
bi 0 loss 0.07992646098136902
bi 1 loss 0.21676215529441833
bi 2 loss 0.2198730707168579
bi 3 loss 0.03851863369345665
Layer  6  loss:  0.15840613842010498 0.0 9.266106605529785
logits torch.Size([549, 4, 1024]) labels torch.Size([549, 4]) 0 1023
Curr loss timestep torch.Size([549, 4]) tensor([408, 431, 411,  58], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.1272970587015152
bi 1 loss 0.18978925049304962
bi 2 loss 0.20191381871700287
bi 3 loss 0.016499560326337814
Epoch 0: :   3%|▎         | 15354/600000 [02:27<1:33:36, v_num=12, reduced_train_loss=1.720, global_step=15352.0, consumed_samples=61412.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15354/600000 [02:27<1:33:36, v_num=12, reduced_train_loss=1.150, global_step=15353.0, consumed_samples=61416.0, train_step_timing in s=0.374]loss mask original None

First layer loss:  0.15733064711093903 torch.Size([546, 4]) 13.985393524169922 0.0
Max loss timestep torch.Size([546, 4]) tensor([100, 425, 256, 349], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.04632880166172981
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 1 loss 0.1655529886484146
speech mask sum tensor(399, device='cuda:0') loss mask sum tensor(399, device='cuda:0')
bi 2 loss 0.2099677175283432
speech mask sum tensor(393, device='cuda:0') loss mask sum tensor(393, device='cuda:0')
bi 3 loss 0.12285663187503815
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
logits torch.Size([546, 4, 257024]) labels torch.Size([546, 4]) 0 257022
Layer  0  loss:  0.19373759627342224 0.0 20.35503387451172
logits torch.Size([546, 4, 1024]) labels torch.Size([546, 4]) 0 1023
Curr loss timestep torch.Size([546, 4]) tensor([163, 423, 256, 336], device='cuda:0') tensor(423, device='cuda:0')
bi 0 loss 0.0516931526362896
bi 1 loss 0.1848081648349762
bi 2 loss 0.28421252965927124
bi 3 loss 0.14405907690525055
Layer  1  loss:  0.22222493588924408 0.0 18.848392486572266
logits torch.Size([546, 4, 1024]) labels torch.Size([546, 4]) 0 1022
Curr loss timestep torch.Size([546, 4]) tensor([ 67, 422, 431, 335], device='cuda:0') tensor(422, device='cuda:0')
bi 0 loss 0.06855447590351105
bi 1 loss 0.21063490211963654
bi 2 loss 0.323598176240921
bi 3 loss 0.1659473478794098
Layer  2  loss:  0.23526087403297424 0.0 17.352556228637695
logits torch.Size([546, 4, 1024]) labels torch.Size([546, 4]) 0 1022
Curr loss timestep torch.Size([546, 4]) tensor([150, 423, 257, 336], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.07284808903932571
bi 1 loss 0.21956582367420197
bi 2 loss 0.3692432940006256
bi 3 loss 0.13723503053188324
Layer  3  loss:  0.22233547270298004 0.0 17.404396057128906
logits torch.Size([546, 4, 1024]) labels torch.Size([546, 4]) 0 1022
Curr loss timestep torch.Size([546, 4]) tensor([144, 423, 256, 336], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 0.04274474084377289
bi 1 loss 0.21284905076026917
bi 2 loss 0.33086514472961426
bi 3 loss 0.16617919504642487
Layer  4  loss:  0.2324332743883133 0.0 17.677846908569336
logits torch.Size([546, 4, 1024]) labels torch.Size([546, 4]) 0 1022
Curr loss timestep torch.Size([546, 4]) tensor([ 77, 425, 291, 336], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.04385632276535034
bi 1 loss 0.22697655856609344
bi 2 loss 0.34820353984832764
bi 3 loss 0.16292668879032135
Layer  5  loss:  0.2324860543012619 0.0 13.040451049804688
logits torch.Size([546, 4, 1024]) labels torch.Size([546, 4]) 0 1023
Curr loss timestep torch.Size([546, 4]) tensor([117, 332, 257, 336], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.02514798194169998
bi 1 loss 0.22121185064315796
bi 2 loss 0.3439539968967438
bi 3 loss 0.19103029370307922
Layer  6  loss:  0.24794115126132965 0.0 17.217161178588867
logits torch.Size([546, 4, 1024]) labels torch.Size([546, 4]) 0 1023
Curr loss timestep torch.Size([546, 4]) tensor([157, 423, 256, 336], device='cuda:0') tensor(423, device='cuda:0')
bi 0 loss 0.06473802030086517
bi 1 loss 0.2556394338607788
bi 2 loss 0.32988691329956055
bi 3 loss 0.2090274840593338
Epoch 0: :   3%|▎         | 15355/600000 [02:27<1:33:52, v_num=12, reduced_train_loss=1.150, global_step=15353.0, consumed_samples=61416.0, train_step_timing in s=0.374]Epoch 0: :   3%|▎         | 15355/600000 [02:27<1:33:52, v_num=12, reduced_train_loss=1.740, global_step=15354.0, consumed_samples=61420.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  0.21535131335258484 torch.Size([590, 4]) 13.634008407592773 0.0
Max loss timestep torch.Size([590, 4]) tensor([397, 469, 262, 329], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.2698894739151001
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
bi 1 loss 0.18446242809295654
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 2 loss 0.11718985438346863
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
bi 3 loss 0.2517054080963135
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
logits torch.Size([590, 4, 257024]) labels torch.Size([590, 4]) 0 257023
Layer  0  loss:  0.20217254757881165 0.0 11.717286109924316
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([522, 297, 291, 399], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.24041232466697693
bi 1 loss 0.2658017575740814
bi 2 loss 0.07474249601364136
bi 3 loss 0.1816614717245102
Layer  1  loss:  0.26288843154907227 0.0 15.82241153717041
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([562, 297, 293, 306], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.3317936360836029
bi 1 loss 0.2822663187980652
bi 2 loss 0.10329952836036682
bi 3 loss 0.2738703489303589
Layer  2  loss:  0.2747250497341156 0.0 19.63542366027832
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([525, 268, 262, 399], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.3886656165122986
bi 1 loss 0.2544083893299103
bi 2 loss 0.1663915067911148
bi 3 loss 0.23075729608535767
Layer  3  loss:  0.281878799200058 0.0 12.550216674804688
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([396, 297, 262, 306], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.3673573434352875
bi 1 loss 0.23122529685497284
bi 2 loss 0.11598070710897446
bi 3 loss 0.35033416748046875
Layer  4  loss:  0.2629186809062958 0.0 13.625834465026855
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([287, 297, 262, 306], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.36602866649627686
bi 1 loss 0.24776090681552887
bi 2 loss 0.07135368138551712
bi 3 loss 0.29039326310157776
Layer  5  loss:  0.27687546610832214 0.0 17.68756103515625
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([522, 297, 262, 306], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.4014151096343994
bi 1 loss 0.2192833572626114
bi 2 loss 0.11099057644605637
bi 3 loss 0.3021540343761444
Layer  6  loss:  0.28241392970085144 0.0 21.005393981933594
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([287, 297, 263, 400], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.38785457611083984
bi 1 loss 0.27523571252822876
bi 2 loss 0.11611160635948181
bi 3 loss 0.2793360650539398
Epoch 0: :   3%|▎         | 15356/600000 [02:28<1:34:08, v_num=12, reduced_train_loss=1.740, global_step=15354.0, consumed_samples=61420.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15356/600000 [02:28<1:34:08, v_num=12, reduced_train_loss=2.060, global_step=15355.0, consumed_samples=61424.0, train_step_timing in s=0.401]loss mask original None

First layer loss:  0.11259359866380692 torch.Size([525, 4]) 10.663507461547852 0.0
Max loss timestep torch.Size([525, 4]) tensor([273, 301, 254, 135], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.18305720388889313
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 1 loss 0.07670370489358902
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
bi 2 loss 0.054491087794303894
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 3 loss 0.05265235900878906
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
logits torch.Size([525, 4, 257024]) labels torch.Size([525, 4]) 0 257023
Layer  0  loss:  0.1144220232963562 0.0 13.625423431396484
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([272, 276, 256, 128], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.14176708459854126
bi 1 loss 0.13285568356513977
bi 2 loss 0.1474137157201767
bi 3 loss 0.04216186702251434
Layer  1  loss:  0.11800769716501236 0.0 10.696608543395996
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1022
Curr loss timestep torch.Size([525, 4]) tensor([273, 276, 261, 212], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.16648073494434357
bi 1 loss 0.14793287217617035
bi 2 loss 0.036284323781728745
bi 3 loss 0.032624538987874985
Layer  2  loss:  0.12957197427749634 0.0 12.814308166503906
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([273, 276, 282,  80], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.18672595918178558
bi 1 loss 0.15777969360351562
bi 2 loss 0.043065499514341354
bi 3 loss 0.0333545058965683
Layer  3  loss:  0.14160314202308655 0.0 18.067312240600586
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([272, 276, 283, 151], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.19704888761043549
bi 1 loss 0.17163801193237305
bi 2 loss 0.08571381121873856
bi 3 loss 0.03754768148064613
Layer  4  loss:  0.1379545032978058 0.0 12.062005043029785
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1021
Curr loss timestep torch.Size([525, 4]) tensor([273, 289, 249, 156], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.2111392617225647
bi 1 loss 0.15636159479618073
bi 2 loss 0.031821344047784805
bi 3 loss 0.031600989401340485
Layer  5  loss:  0.1451917141675949 0.0 16.20094871520996
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1021
Curr loss timestep torch.Size([525, 4]) tensor([512, 276, 283,  71], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.20567844808101654
bi 1 loss 0.17740929126739502
bi 2 loss 0.04338981956243515
bi 3 loss 0.04385370388627052
Layer  6  loss:  0.1599125862121582 0.0 10.642409324645996
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([482, 276, 254, 130], device='cuda:0') tensor(482, device='cuda:0')
bi 0 loss 0.2560020685195923
bi 1 loss 0.16494129598140717
bi 2 loss 0.04465905949473381
bi 3 loss 0.03305277228355408
Epoch 0: :   3%|▎         | 15357/600000 [02:28<1:34:23, v_num=12, reduced_train_loss=2.060, global_step=15355.0, consumed_samples=61424.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15357/600000 [02:28<1:34:23, v_num=12, reduced_train_loss=1.060, global_step=15356.0, consumed_samples=61428.0, train_step_timing in s=0.363]loss mask original None

First layer loss:  0.0339580737054348 torch.Size([318, 4]) 3.700479745864868 0.0
Max loss timestep torch.Size([318, 4]) tensor([ 60, 274, 212, 136], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.017988596111536026
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 1 loss 0.0636516734957695
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 2 loss 0.025157814845442772
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 3 loss 0.012434582225978374
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
logits torch.Size([318, 4, 257024]) labels torch.Size([318, 4]) 0 257021
Layer  0  loss:  0.04006090760231018 0.0 11.695795059204102
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1023
Curr loss timestep torch.Size([318, 4]) tensor([106, 276, 296, 113], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.019385119900107384
bi 1 loss 0.08451072871685028
bi 2 loss 0.019615331664681435
bi 3 loss 0.015058849938213825
Layer  1  loss:  0.027185281738638878 0.0 2.242415428161621
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1023
Curr loss timestep torch.Size([318, 4]) tensor([104, 275, 265, 141], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.01654224656522274
bi 1 loss 0.04537448659539223
bi 2 loss 0.022781765088438988
bi 3 loss 0.013830340467393398
Layer  2  loss:  0.04064048081636429 0.0 5.219540596008301
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1022
Curr loss timestep torch.Size([318, 4]) tensor([ 94, 275, 269, 175], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.020933592692017555
bi 1 loss 0.07809742540121078
bi 2 loss 0.025706835091114044
bi 3 loss 0.019716912880539894
Layer  3  loss:  0.03850124031305313 0.0 7.754499435424805
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1021
Curr loss timestep torch.Size([318, 4]) tensor([215, 276, 289, 118], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.018362626433372498
bi 1 loss 0.08001438528299332
bi 2 loss 0.023839272558689117
bi 3 loss 0.008566509932279587
Layer  4  loss:  0.039375413209199905 0.0 7.416332244873047
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1022
Curr loss timestep torch.Size([318, 4]) tensor([ 98, 275, 256, 117], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.01766720600426197
bi 1 loss 0.08023668825626373
bi 2 loss 0.023304222151637077
bi 3 loss 0.016547998413443565
Layer  5  loss:  0.033626750111579895 0.0 5.992743492126465
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1020
Curr loss timestep torch.Size([318, 4]) tensor([110, 276, 166, 138], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.01804541051387787
bi 1 loss 0.05608072504401207
bi 2 loss 0.0314139723777771
bi 3 loss 0.015879882499575615
Layer  6  loss:  0.03158286213874817 0.0 5.691533088684082
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1023
Curr loss timestep torch.Size([318, 4]) tensor([177, 276, 284, 175], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.02608383819460869
bi 1 loss 0.046122826635837555
bi 2 loss 0.02663912996649742
bi 3 loss 0.017765464261174202
Epoch 0: :   3%|▎         | 15358/600000 [02:29<1:34:34, v_num=12, reduced_train_loss=1.060, global_step=15356.0, consumed_samples=61428.0, train_step_timing in s=0.363]Epoch 0: :   3%|▎         | 15358/600000 [02:29<1:34:34, v_num=12, reduced_train_loss=0.285, global_step=15357.0, consumed_samples=61432.0, train_step_timing in s=0.262]loss mask original None

First layer loss:  0.15136456489562988 torch.Size([658, 4]) 9.922858238220215 0.0
Max loss timestep torch.Size([658, 4]) tensor([514, 267, 269, 380], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.11003025621175766
speech mask sum tensor(393, device='cuda:0') loss mask sum tensor(393, device='cuda:0')
bi 1 loss 0.2350851595401764
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
bi 2 loss 0.055994268506765366
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
bi 3 loss 0.08688952773809433
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
logits torch.Size([658, 4, 257024]) labels torch.Size([658, 4]) 0 257023
Layer  0  loss:  0.17198501527309418 0.0 10.936737060546875
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([514, 266, 230, 380], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.17148032784461975
bi 1 loss 0.24667151272296906
bi 2 loss 0.05841796100139618
bi 3 loss 0.0689622312784195
Layer  1  loss:  0.16183732450008392 0.0 11.289545059204102
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([514, 266, 266, 405], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.15181457996368408
bi 1 loss 0.23588937520980835
bi 2 loss 0.06243496015667915
bi 3 loss 0.06943413615226746
Layer  2  loss:  0.2031499445438385 0.0 13.524096488952637
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([514, 525, 204, 380], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.12850716710090637
bi 1 loss 0.3470095694065094
bi 2 loss 0.0837303027510643
bi 3 loss 0.08115365356206894
Layer  3  loss:  0.1716565191745758 0.0 11.214986801147461
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([514, 266, 193, 353], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.12286999821662903
bi 1 loss 0.2790449559688568
bi 2 loss 0.0406670980155468
bi 3 loss 0.08567716926336288
Layer  4  loss:  0.18185336887836456 0.0 12.365312576293945
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([514, 601, 269, 380], device='cuda:0') tensor(601, device='cuda:0')
bi 0 loss 0.18150196969509125
bi 1 loss 0.2544293701648712
bi 2 loss 0.06991256773471832
bi 3 loss 0.0821249783039093
Layer  5  loss:  0.20597566664218903 0.0 15.998335838317871
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1020
Curr loss timestep torch.Size([658, 4]) tensor([514, 267, 269, 380], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.17139576375484467
bi 1 loss 0.3022806644439697
bi 2 loss 0.07928242534399033
bi 3 loss 0.11816564202308655
Layer  6  loss:  0.21150539815425873 0.0 15.765926361083984
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([514, 267, 263, 380], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.17907749116420746
bi 1 loss 0.33492934703826904
bi 2 loss 0.05460132285952568
bi 3 loss 0.07850702852010727
Epoch 0: :   3%|▎         | 15359/600000 [02:29<1:34:52, v_num=12, reduced_train_loss=0.285, global_step=15357.0, consumed_samples=61432.0, train_step_timing in s=0.262]Epoch 0: :   3%|▎         | 15359/600000 [02:29<1:34:52, v_num=12, reduced_train_loss=1.460, global_step=15358.0, consumed_samples=61436.0, train_step_timing in s=0.452]loss mask original None

First layer loss:  0.12440022826194763 torch.Size([529, 4]) 15.6030912399292 0.0
Max loss timestep torch.Size([529, 4]) tensor([268, 190, 113, 469], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.17875483632087708
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
bi 1 loss 0.10254128277301788
speech mask sum tensor(338, device='cuda:0') loss mask sum tensor(338, device='cuda:0')
bi 2 loss 0.02999870665371418
speech mask sum tensor(43, device='cuda:0') loss mask sum tensor(43, device='cuda:0')
bi 3 loss 0.11597461998462677
speech mask sum tensor(467, device='cuda:0') loss mask sum tensor(467, device='cuda:0')
logits torch.Size([529, 4, 257024]) labels torch.Size([529, 4]) 0 257023
Layer  0  loss:  0.12124291062355042 0.0 14.68884563446045
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([266, 294, 122, 469], device='cuda:0') tensor(469, device='cuda:0')
bi 0 loss 0.13120423257350922
bi 1 loss 0.08249036967754364
bi 2 loss 0.015558954328298569
bi 3 loss 0.1529853492975235
Layer  1  loss:  0.12354565411806107 0.0 10.757431030273438
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([267, 270, 115, 517], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.1278012990951538
bi 1 loss 0.07099452614784241
bi 2 loss 0.03964468091726303
bi 3 loss 0.1667269766330719
Layer  2  loss:  0.13749754428863525 0.0 19.026721954345703
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([267, 294, 128, 466], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.17259865999221802
bi 1 loss 0.06216688081622124
bi 2 loss 0.010897770524024963
bi 3 loss 0.18240535259246826
Layer  3  loss:  0.13517026603221893 0.0 15.641797065734863
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([266, 382, 123, 469], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.18958358466625214
bi 1 loss 0.04757963493466377
bi 2 loss 0.009000199846923351
bi 3 loss 0.1772087812423706
Layer  4  loss:  0.13262030482292175 0.0 15.958335876464844
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([266, 295, 119, 469], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.18302001059055328
bi 1 loss 0.04962614178657532
bi 2 loss 0.006376655772328377
bi 3 loss 0.1737709790468216
Layer  5  loss:  0.134200319647789 0.0 15.987133026123047
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1019
Curr loss timestep torch.Size([529, 4]) tensor([266, 266, 120, 469], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.21249206364154816
bi 1 loss 0.05021246522665024
bi 2 loss 0.022948771715164185
bi 3 loss 0.15778735280036926
Layer  6  loss:  0.13719935715198517 0.0 15.528911590576172
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([267, 294, 125, 517], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.1902734637260437
bi 1 loss 0.04953159764409065
bi 2 loss 0.047932498157024384
bi 3 loss 0.17670729756355286
Epoch 0: :   3%|▎         | 15360/600000 [02:29<1:35:07, v_num=12, reduced_train_loss=1.460, global_step=15358.0, consumed_samples=61436.0, train_step_timing in s=0.452]Epoch 0: :   3%|▎         | 15360/600000 [02:29<1:35:07, v_num=12, reduced_train_loss=1.050, global_step=15359.0, consumed_samples=61440.0, train_step_timing in s=0.366]loss mask original None

First layer loss:  4.109729766845703 torch.Size([488, 4]) 10.763009071350098 0.0
Max loss timestep torch.Size([488, 4]) tensor([143, 184, 433, 351], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 3.8999202251434326
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 1 loss 3.1354353427886963
speech mask sum tensor(61, device='cuda:0') loss mask sum tensor(61, device='cuda:0')
bi 2 loss 4.421507835388184
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
bi 3 loss 4.0982794761657715
speech mask sum tensor(383, device='cuda:0') loss mask sum tensor(383, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257023
Layer  0  loss:  4.6224260330200195 0.0 10.770868301391602
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([175, 195, 111, 292], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.402303695678711
bi 1 loss 3.400360584259033
bi 2 loss 4.7166900634765625
bi 3 loss 4.873871326446533
Layer  1  loss:  4.750237941741943 0.0 9.729867935180664
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([238, 187, 407, 337], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.565690994262695
bi 1 loss 3.688861131668091
bi 2 loss 4.887048721313477
bi 3 loss 4.909430980682373
Layer  2  loss:  5.102357387542725 0.0 11.282262802124023
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([158, 218, 221, 172], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 5.051640510559082
bi 1 loss 3.8450045585632324
bi 2 loss 5.302850246429443
bi 3 loss 5.137864112854004
Layer  3  loss:  5.169830799102783 0.0 9.826750755310059
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([376, 208, 257, 422], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 5.2260565757751465
bi 1 loss 3.989365577697754
bi 2 loss 5.442833423614502
bi 3 loss 5.047802925109863
Layer  4  loss:  5.271739482879639 0.0 10.365589141845703
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([350, 219, 364, 246], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 5.241319179534912
bi 1 loss 4.122391700744629
bi 2 loss 5.6077046394348145
bi 3 loss 5.141394138336182
Layer  5  loss:  5.352264404296875 0.0 10.999146461486816
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([252, 222, 216, 177], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 5.402730941772461
bi 1 loss 4.32918119430542
bi 2 loss 5.685413360595703
bi 3 loss 5.14927864074707
Layer  6  loss:  5.278107166290283 0.0 10.405609130859375
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([244, 211, 446, 349], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 5.253199100494385
bi 1 loss 4.124888896942139
bi 2 loss 5.676638603210449
bi 3 loss 5.082367420196533
Epoch 0: :   3%|▎         | 15361/600000 [02:30<1:35:20, v_num=12, reduced_train_loss=1.050, global_step=15359.0, consumed_samples=61440.0, train_step_timing in s=0.366]Epoch 0: :   3%|▎         | 15361/600000 [02:30<1:35:20, v_num=12, reduced_train_loss=39.70, global_step=15360.0, consumed_samples=61444.0, train_step_timing in s=0.330]loss mask original None

First layer loss:  0.1051042452454567 torch.Size([655, 4]) 8.731687545776367 0.0
Max loss timestep torch.Size([655, 4]) tensor([271, 624, 252, 210], device='cuda:0') tensor(624, device='cuda:0')
bi 0 loss 0.07588724792003632
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 1 loss 0.17161151766777039
speech mask sum tensor(360, device='cuda:0') loss mask sum tensor(360, device='cuda:0')
bi 2 loss 0.057195667177438736
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 3 loss 0.04803643748164177
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
logits torch.Size([655, 4, 257024]) labels torch.Size([655, 4]) 0 257022
Layer  0  loss:  0.10651732236146927 0.0 8.755998611450195
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([301, 629, 114, 276], device='cuda:0') tensor(629, device='cuda:0')
bi 0 loss 0.0666835755109787
bi 1 loss 0.19166244566440582
bi 2 loss 0.05423610284924507
bi 3 loss 0.02699347957968712
Layer  1  loss:  0.10086919367313385 0.0 5.8071770668029785
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([288, 624, 138, 260], device='cuda:0') tensor(624, device='cuda:0')
bi 0 loss 0.09536232799291611
bi 1 loss 0.15495531260967255
bi 2 loss 0.05478969216346741
bi 3 loss 0.0346020869910717
Layer  2  loss:  0.0995141863822937 0.0 10.886554718017578
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([300, 517, 119, 255], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.05866609886288643
bi 1 loss 0.17195841670036316
bi 2 loss 0.05299343168735504
bi 3 loss 0.044757530093193054
Layer  3  loss:  0.08572700619697571 0.0 6.903471946716309
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([130, 514, 189, 194], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.05811912938952446
bi 1 loss 0.15580755472183228
bi 2 loss 0.02806573361158371
bi 3 loss 0.02880651317536831
Layer  4  loss:  0.11047915369272232 0.0 5.854328155517578
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([301, 614, 139, 193], device='cuda:0') tensor(614, device='cuda:0')
bi 0 loss 0.06495334208011627
bi 1 loss 0.1926739513874054
bi 2 loss 0.052073750644922256
bi 3 loss 0.053417935967445374
Layer  5  loss:  0.09963846951723099 0.0 7.092840194702148
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([272, 624, 143, 257], device='cuda:0') tensor(624, device='cuda:0')
bi 0 loss 0.05727085843682289
bi 1 loss 0.1745726317167282
bi 2 loss 0.04917922616004944
bi 3 loss 0.04580426216125488
Layer  6  loss:  0.1061784029006958 0.0 5.804079532623291
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([298, 624, 121, 197], device='cuda:0') tensor(624, device='cuda:0')
bi 0 loss 0.06852960586547852
bi 1 loss 0.17797380685806274
bi 2 loss 0.04922115057706833
bi 3 loss 0.059780485928058624
Epoch 0: :   3%|▎         | 15362/600000 [02:30<1:35:38, v_num=12, reduced_train_loss=39.70, global_step=15360.0, consumed_samples=61444.0, train_step_timing in s=0.330]Epoch 0: :   3%|▎         | 15362/600000 [02:30<1:35:38, v_num=12, reduced_train_loss=0.814, global_step=15361.0, consumed_samples=61448.0, train_step_timing in s=0.447]loss mask original None

First layer loss:  0.0794857069849968 torch.Size([615, 4]) 8.651376724243164 0.0
Max loss timestep torch.Size([615, 4]) tensor([274, 554, 146, 265], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.05172266811132431
speech mask sum tensor(207, device='cuda:0') loss mask sum tensor(207, device='cuda:0')
bi 1 loss 0.08887859433889389
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
bi 2 loss 0.1970289796590805
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 3 loss 0.030192958191037178
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
logits torch.Size([615, 4, 257024]) labels torch.Size([615, 4]) 0 257023
Layer  0  loss:  0.06769617646932602 0.0 3.3703811168670654
logits torch.Size([615, 4, 1024]) labels torch.Size([615, 4]) 0 1023
Curr loss timestep torch.Size([615, 4]) tensor([112, 551, 147, 202], device='cuda:0') tensor(551, device='cuda:0')
bi 0 loss 0.05570944398641586
bi 1 loss 0.08200573921203613
bi 2 loss 0.08019314706325531
bi 3 loss 0.03237141668796539
Layer  1  loss:  0.07192648202180862 0.0 10.919371604919434
logits torch.Size([615, 4, 1024]) labels torch.Size([615, 4]) 0 1022
Curr loss timestep torch.Size([615, 4]) tensor([262, 554, 175, 191], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.04050424322485924
bi 1 loss 0.09512195736169815
bi 2 loss 0.05537870526313782
bi 3 loss 0.049592312425374985
Layer  2  loss:  0.06737510114908218 0.0 7.085939407348633
logits torch.Size([615, 4, 1024]) labels torch.Size([615, 4]) 0 1022
Curr loss timestep torch.Size([615, 4]) tensor([225, 554, 176, 198], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.04290887713432312
bi 1 loss 0.08958716690540314
bi 2 loss 0.04635917395353317
bi 3 loss 0.04067196696996689
Layer  3  loss:  0.06128455325961113 0.0 5.339013576507568
logits torch.Size([615, 4, 1024]) labels torch.Size([615, 4]) 0 1021
Curr loss timestep torch.Size([615, 4]) tensor([274, 552, 138, 235], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.06352874636650085
bi 1 loss 0.07239174842834473
bi 2 loss 0.05025184899568558
bi 3 loss 0.027939442545175552
Layer  4  loss:  0.06098131090402603 0.0 4.42909574508667
logits torch.Size([615, 4, 1024]) labels torch.Size([615, 4]) 0 1022
Curr loss timestep torch.Size([615, 4]) tensor([280, 503, 188, 225], device='cuda:0') tensor(503, device='cuda:0')
bi 0 loss 0.048330508172512054
bi 1 loss 0.08128835260868073
bi 2 loss 0.02919798716902733
bi 3 loss 0.02917761169373989
Layer  5  loss:  0.07146629691123962 0.0 7.977501392364502
logits torch.Size([615, 4, 1024]) labels torch.Size([615, 4]) 0 1022
Curr loss timestep torch.Size([615, 4]) tensor([272, 554, 150, 236], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.05029059201478958
bi 1 loss 0.10182694345712662
bi 2 loss 0.023691801354289055
bi 3 loss 0.027206845581531525
Layer  6  loss:  0.07283222675323486 0.0 6.534398078918457
logits torch.Size([615, 4, 1024]) labels torch.Size([615, 4]) 0 1022
Curr loss timestep torch.Size([615, 4]) tensor([252, 554, 159, 136], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.04530319198966026
bi 1 loss 0.0932009145617485
bi 2 loss 0.10624999552965164
bi 3 loss 0.029480064287781715
Epoch 0: :   3%|▎         | 15363/600000 [02:31<1:35:55, v_num=12, reduced_train_loss=0.814, global_step=15361.0, consumed_samples=61448.0, train_step_timing in s=0.447]Epoch 0: :   3%|▎         | 15363/600000 [02:31<1:35:55, v_num=12, reduced_train_loss=0.553, global_step=15362.0, consumed_samples=61452.0, train_step_timing in s=0.418]loss mask original None

First layer loss:  3.6806490421295166 torch.Size([464, 4]) 13.090060234069824 0.0
Max loss timestep torch.Size([464, 4]) tensor([141, 123, 342, 144], device='cuda:0') tensor(141, device='cuda:0')
bi 0 loss 3.7795157432556152
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
bi 1 loss 3.349775552749634
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 2 loss 3.79526686668396
speech mask sum tensor(333, device='cuda:0') loss mask sum tensor(333, device='cuda:0')
bi 3 loss 3.4316627979278564
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
logits torch.Size([464, 4, 257024]) labels torch.Size([464, 4]) 0 257023
Layer  0  loss:  4.27773904800415 0.0 10.339893341064453
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1023
Curr loss timestep torch.Size([464, 4]) tensor([265,  76, 408,  91], device='cuda:0') tensor(133, device='cuda:0')
bi 0 loss 3.979856014251709
bi 1 loss 4.2208991050720215
bi 2 loss 4.59886360168457
bi 3 loss 4.0767388343811035
Layer  1  loss:  4.361973762512207 0.0 9.93307113647461
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1023
Curr loss timestep torch.Size([464, 4]) tensor([256,  65, 193, 106], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 4.319535732269287
bi 1 loss 4.217367172241211
bi 2 loss 4.590466022491455
bi 3 loss 3.935732126235962
Layer  2  loss:  4.767859935760498 0.0 10.549152374267578
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1022
Curr loss timestep torch.Size([464, 4]) tensor([150, 130, 279, 106], device='cuda:0') tensor(143, device='cuda:0')
bi 0 loss 4.700004577636719
bi 1 loss 4.6337738037109375
bi 2 loss 4.911875247955322
bi 3 loss 4.629093647003174
Layer  3  loss:  4.659269332885742 0.0 10.574743270874023
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1022
Curr loss timestep torch.Size([464, 4]) tensor([220, 131, 178, 116], device='cuda:0') tensor(116, device='cuda:0')
bi 0 loss 4.692687511444092
bi 1 loss 4.485617637634277
bi 2 loss 4.756421089172363
bi 3 loss 4.46433687210083
Layer  4  loss:  4.906034469604492 0.0 9.802424430847168
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1021
Curr loss timestep torch.Size([464, 4]) tensor([280, 112, 451,  95], device='cuda:0') tensor(144, device='cuda:0')
bi 0 loss 4.929265975952148
bi 1 loss 4.8803558349609375
bi 2 loss 5.042479038238525
bi 3 loss 4.4891133308410645
Layer  5  loss:  5.031168460845947 0.0 9.593896865844727
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1022
Curr loss timestep torch.Size([464, 4]) tensor([ 59,  96, 224, 100], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 5.089453220367432
bi 1 loss 4.964773178100586
bi 2 loss 5.115311145782471
bi 3 loss 4.721749305725098
Layer  6  loss:  5.032646179199219 0.0 9.820859909057617
logits torch.Size([464, 4, 1024]) labels torch.Size([464, 4]) 0 1020
Curr loss timestep torch.Size([464, 4]) tensor([ 59,  78, 441, 149], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 5.174958229064941
bi 1 loss 4.973900318145752
bi 2 loss 5.078438758850098
bi 3 loss 4.638782501220703
Epoch 0: :   3%|▎         | 15364/600000 [02:31<1:36:09, v_num=12, reduced_train_loss=0.553, global_step=15362.0, consumed_samples=61452.0, train_step_timing in s=0.418]Epoch 0: :   3%|▎         | 15364/600000 [02:31<1:36:09, v_num=12, reduced_train_loss=36.70, global_step=15363.0, consumed_samples=61456.0, train_step_timing in s=0.317]loss mask original None

First layer loss:  0.09978966414928436 torch.Size([587, 4]) 6.5393548011779785 0.0
Max loss timestep torch.Size([587, 4]) tensor([311, 275, 303, 263], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.14708153903484344
speech mask sum tensor(408, device='cuda:0') loss mask sum tensor(408, device='cuda:0')
bi 1 loss 0.06926076859235764
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 2 loss 0.10771617293357849
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 3 loss 0.03622860834002495
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
logits torch.Size([587, 4, 257024]) labels torch.Size([587, 4]) 0 257022
Layer  0  loss:  0.12491971254348755 0.0 7.478916168212891
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([337, 275, 291, 265], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.19358837604522705
bi 1 loss 0.13766245543956757
bi 2 loss 0.057012904435396194
bi 3 loss 0.04962770268321037
Layer  1  loss:  0.11957355588674545 0.0 6.818933486938477
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([559, 275, 187, 263], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.15927654504776
bi 1 loss 0.1718917191028595
bi 2 loss 0.07491781562566757
bi 3 loss 0.039543602615594864
Layer  2  loss:  0.12685959041118622 0.0 10.662521362304688
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([329, 275, 254, 263], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.17276683449745178
bi 1 loss 0.16231778264045715
bi 2 loss 0.08894632011651993
bi 3 loss 0.04529741033911705
Layer  3  loss:  0.14038772881031036 0.0 15.457096099853516
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([458, 276, 304, 115], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.19315563142299652
bi 1 loss 0.1956399828195572
bi 2 loss 0.06285297125577927
bi 3 loss 0.06298589706420898
Layer  4  loss:  0.13065505027770996 0.0 10.744660377502441
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([559, 276, 206, 231], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.18231415748596191
bi 1 loss 0.18436464667320251
bi 2 loss 0.055025387555360794
bi 3 loss 0.05498874559998512
Layer  5  loss:  0.140992671251297 0.0 12.750115394592285
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1022
Curr loss timestep torch.Size([587, 4]) tensor([326, 275, 289, 263], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.18014928698539734
bi 1 loss 0.18059901893138885
bi 2 loss 0.06519561260938644
bi 3 loss 0.10077335685491562
Layer  6  loss:  0.13306348025798798 0.0 7.625563144683838
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1021
Curr loss timestep torch.Size([587, 4]) tensor([323, 276, 190, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.19352290034294128
bi 1 loss 0.16571450233459473
bi 2 loss 0.05748690292239189
bi 3 loss 0.06090661138296127
Epoch 0: :   3%|▎         | 15365/600000 [02:32<1:36:25, v_num=12, reduced_train_loss=36.70, global_step=15363.0, consumed_samples=61456.0, train_step_timing in s=0.317]Epoch 0: :   3%|▎         | 15365/600000 [02:32<1:36:25, v_num=12, reduced_train_loss=1.020, global_step=15364.0, consumed_samples=61460.0, train_step_timing in s=0.409]loss mask original None

First layer loss:  0.08124227821826935 torch.Size([505, 4]) 8.567947387695312 0.0
Max loss timestep torch.Size([505, 4]) tensor([306, 407, 148, 169], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 0.07847759127616882
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 1 loss 0.05971581116318703
speech mask sum tensor(279, device='cuda:0') loss mask sum tensor(279, device='cuda:0')
bi 2 loss 0.05432913079857826
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 3 loss 0.11332949250936508
speech mask sum tensor(346, device='cuda:0') loss mask sum tensor(346, device='cuda:0')
logits torch.Size([505, 4, 257024]) labels torch.Size([505, 4]) 0 257022
Layer  0  loss:  0.08544380217790604 0.0 8.49901294708252
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1023
Curr loss timestep torch.Size([505, 4]) tensor([307, 194, 182, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.12764030694961548
bi 1 loss 0.06492803990840912
bi 2 loss 0.05272955819964409
bi 3 loss 0.09763898700475693
Layer  1  loss:  0.07039612531661987 0.0 9.611140251159668
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1023
Curr loss timestep torch.Size([505, 4]) tensor([307, 186,  62, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.06886197626590729
bi 1 loss 0.06397826969623566
bi 2 loss 0.026503507047891617
bi 3 loss 0.09814000874757767
Layer  2  loss:  0.08074835687875748 0.0 6.427736282348633
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1022
Curr loss timestep torch.Size([505, 4]) tensor([165, 310, 161, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.07965565472841263
bi 1 loss 0.09358569234609604
bi 2 loss 0.03370226174592972
bi 3 loss 0.09431765973567963
Layer  3  loss:  0.08837708085775375 0.0 8.94054889678955
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1020
Curr loss timestep torch.Size([505, 4]) tensor([307, 281,  98, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.0731617733836174
bi 1 loss 0.07081916183233261
bi 2 loss 0.0499727763235569
bi 3 loss 0.12905797362327576
Layer  4  loss:  0.07709281891584396 0.0 7.159653186798096
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1021
Curr loss timestep torch.Size([505, 4]) tensor([307, 303, 115, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.06776025146245956
bi 1 loss 0.08849947154521942
bi 2 loss 0.0387391597032547
bi 3 loss 0.09151934832334518
Layer  5  loss:  0.07972102612257004 0.0 6.344958782196045
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1020
Curr loss timestep torch.Size([505, 4]) tensor([307, 401, 109, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.08287320286035538
bi 1 loss 0.0717705637216568
bi 2 loss 0.0393400713801384
bi 3 loss 0.1046660766005516
Layer  6  loss:  0.08339578658342361 0.0 17.656375885009766
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1022
Curr loss timestep torch.Size([505, 4]) tensor([275, 172, 162, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.06587422639131546
bi 1 loss 0.05881832540035248
bi 2 loss 0.04014832153916359
bi 3 loss 0.1332710087299347
Epoch 0: :   3%|▎         | 15366/600000 [02:32<1:36:40, v_num=12, reduced_train_loss=1.020, global_step=15364.0, consumed_samples=61460.0, train_step_timing in s=0.409]Epoch 0: :   3%|▎         | 15366/600000 [02:32<1:36:40, v_num=12, reduced_train_loss=0.646, global_step=15365.0, consumed_samples=61464.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  3.434318780899048 torch.Size([644, 4]) 11.248527526855469 0.0
Max loss timestep torch.Size([644, 4]) tensor([232, 144, 620, 110], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 3.32314133644104
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 1 loss 3.9293179512023926
speech mask sum tensor(116, device='cuda:0') loss mask sum tensor(116, device='cuda:0')
bi 2 loss 3.283808946609497
speech mask sum tensor(454, device='cuda:0') loss mask sum tensor(454, device='cuda:0')
bi 3 loss 3.7203478813171387
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
logits torch.Size([644, 4, 257024]) labels torch.Size([644, 4]) 0 257022
Layer  0  loss:  3.868514060974121 0.0 11.867351531982422
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([205, 176, 268, 120], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 3.552340507507324
bi 1 loss 4.03429651260376
bi 2 loss 3.8235361576080322
bi 3 loss 4.415496349334717
Layer  1  loss:  4.032096862792969 0.0 9.424592971801758
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([323, 162, 383,  73], device='cuda:0') tensor(208, device='cuda:0')
bi 0 loss 3.8358137607574463
bi 1 loss 4.39152193069458
bi 2 loss 3.926539421081543
bi 3 loss 4.420698165893555
Layer  2  loss:  4.382264614105225 0.0 9.883447647094727
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([337, 185, 557,  56], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 4.003291606903076
bi 1 loss 4.88969612121582
bi 2 loss 4.2993316650390625
bi 3 loss 4.83578634262085
Layer  3  loss:  4.484319686889648 0.0 10.861177444458008
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1021
Curr loss timestep torch.Size([644, 4]) tensor([335, 191, 399,  73], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 4.046276092529297
bi 1 loss 5.008509159088135
bi 2 loss 4.429230213165283
bi 3 loss 4.907828330993652
Layer  4  loss:  4.635222434997559 0.0 9.988703727722168
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([316, 190, 476,  49], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 4.224813461303711
bi 1 loss 5.089064121246338
bi 2 loss 4.659846305847168
bi 3 loss 4.761584281921387
Layer  5  loss:  4.740167140960693 0.0 10.897287368774414
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([218, 236, 261, 105], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.295547008514404
bi 1 loss 5.376276016235352
bi 2 loss 4.701278209686279
bi 3 loss 4.993247032165527
Layer  6  loss:  4.808910846710205 0.0 9.199725151062012
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([213, 238, 419, 109], device='cuda:0') tensor(238, device='cuda:0')
bi 0 loss 4.361442565917969
bi 1 loss 5.105891704559326
bi 2 loss 4.905012607574463
bi 3 loss 4.87086820602417
Epoch 0: :   3%|▎         | 15367/600000 [02:32<1:36:56, v_num=12, reduced_train_loss=0.646, global_step=15365.0, consumed_samples=61464.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15367/600000 [02:32<1:36:56, v_num=12, reduced_train_loss=34.40, global_step=15366.0, consumed_samples=61468.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  0.06575687229633331 torch.Size([421, 4]) 7.4388322830200195 0.0
Max loss timestep torch.Size([421, 4]) tensor([300, 355, 145, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.047847747802734375
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 1 loss 0.06636392325162888
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
bi 2 loss 0.04218214377760887
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 3 loss 0.08123543858528137
speech mask sum tensor(347, device='cuda:0') loss mask sum tensor(347, device='cuda:0')
logits torch.Size([421, 4, 257024]) labels torch.Size([421, 4]) 0 257022
Layer  0  loss:  0.06356427073478699 0.0 7.532481670379639
logits torch.Size([421, 4, 1024]) labels torch.Size([421, 4]) 0 1023
Curr loss timestep torch.Size([421, 4]) tensor([269, 364, 113, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.05889373645186424
bi 1 loss 0.06637144833803177
bi 2 loss 0.030268672853708267
bi 3 loss 0.07468955963850021
Layer  1  loss:  0.08145783096551895 0.0 11.27039623260498
logits torch.Size([421, 4, 1024]) labels torch.Size([421, 4]) 0 1022
Curr loss timestep torch.Size([421, 4]) tensor([264, 355, 110, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.10880883038043976
bi 1 loss 0.07932355999946594
bi 2 loss 0.03095540590584278
bi 3 loss 0.08735767751932144
Layer  2  loss:  0.06571789085865021 0.0 5.585777759552002
logits torch.Size([421, 4, 1024]) labels torch.Size([421, 4]) 0 1022
Curr loss timestep torch.Size([421, 4]) tensor([268, 362, 171, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.05738058686256409
bi 1 loss 0.06950896233320236
bi 2 loss 0.041572291404008865
bi 3 loss 0.07476092875003815
Layer  3  loss:  0.06038402020931244 0.0 7.089340686798096
logits torch.Size([421, 4, 1024]) labels torch.Size([421, 4]) 0 1021
Curr loss timestep torch.Size([421, 4]) tensor([274, 355, 115, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.06010089069604874
bi 1 loss 0.059150535613298416
bi 2 loss 0.03385447710752487
bi 3 loss 0.07019300758838654
Layer  4  loss:  0.07580626010894775 0.0 6.633645057678223
logits torch.Size([421, 4, 1024]) labels torch.Size([421, 4]) 0 1022
Curr loss timestep torch.Size([421, 4]) tensor([267, 364, 111, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.08367806673049927
bi 1 loss 0.08712729811668396
bi 2 loss 0.059877365827560425
bi 3 loss 0.06936732679605484
Layer  5  loss:  0.05205347016453743 0.0 5.887343883514404
logits torch.Size([421, 4, 1024]) labels torch.Size([421, 4]) 0 1023
Curr loss timestep torch.Size([421, 4]) tensor([323, 355, 131, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.04193681478500366
bi 1 loss 0.06307515501976013
bi 2 loss 0.03582974150776863
bi 3 loss 0.054066792130470276
Layer  6  loss:  0.06660769879817963 0.0 4.1482462882995605
logits torch.Size([421, 4, 1024]) labels torch.Size([421, 4]) 0 1022
Curr loss timestep torch.Size([421, 4]) tensor([201, 357, 138, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.045955199748277664
bi 1 loss 0.08211615681648254
bi 2 loss 0.050917819142341614
bi 3 loss 0.0699784904718399
Epoch 0: :   3%|▎         | 15368/600000 [02:33<1:37:08, v_num=12, reduced_train_loss=34.40, global_step=15366.0, consumed_samples=61468.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15368/600000 [02:33<1:37:08, v_num=12, reduced_train_loss=0.531, global_step=15367.0, consumed_samples=61472.0, train_step_timing in s=0.307]loss mask original None

First layer loss:  0.061983928084373474 torch.Size([487, 4]) 7.313852787017822 0.0
Max loss timestep torch.Size([487, 4]) tensor([328, 357, 195, 261], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.08865680545568466
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 1 loss 0.040416937321424484
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
bi 2 loss 0.03731219843029976
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 3 loss 0.0345919132232666
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
logits torch.Size([487, 4, 257024]) labels torch.Size([487, 4]) 0 257023
Layer  0  loss:  0.06332585215568542 0.0 4.289488315582275
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([331, 251, 217, 123], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.07157915830612183
bi 1 loss 0.06874170899391174
bi 2 loss 0.0558144636452198
bi 3 loss 0.04033306986093521
Layer  1  loss:  0.07448280602693558 0.0 3.080249786376953
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([262, 284, 218, 179], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.09284554421901703
bi 1 loss 0.07905514538288116
bi 2 loss 0.057054124772548676
bi 3 loss 0.032664548605680466
Layer  2  loss:  0.06491566449403763 0.0 2.942237377166748
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([403, 303, 187, 126], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.07256783545017242
bi 1 loss 0.07522564381361008
bi 2 loss 0.05096274986863136
bi 3 loss 0.04119745269417763
Layer  3  loss:  0.05974183231592178 0.0 4.748443603515625
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1021
Curr loss timestep torch.Size([487, 4]) tensor([278, 372, 186, 127], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.07460875809192657
bi 1 loss 0.05374934896826744
bi 2 loss 0.03915737196803093
bi 3 loss 0.041102323681116104
Layer  4  loss:  0.06194985657930374 0.0 3.0720114707946777
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([456, 368, 219, 194], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 0.0686601996421814
bi 1 loss 0.07448512315750122
bi 2 loss 0.023498261347413063
bi 3 loss 0.05168139189481735
Layer  5  loss:  0.0783054307103157 0.0 3.3738954067230225
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([258, 297, 221, 154], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.09738242626190186
bi 1 loss 0.06944829225540161
bi 2 loss 0.04592571407556534
bi 3 loss 0.05912989005446434
Layer  6  loss:  0.06022242084145546 0.0 3.0869827270507812
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([331, 294, 250, 204], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.07361602038145065
bi 1 loss 0.043006785213947296
bi 2 loss 0.058426760137081146
bi 3 loss 0.0481572262942791
Epoch 0: :   3%|▎         | 15369/600000 [02:33<1:37:22, v_num=12, reduced_train_loss=0.531, global_step=15367.0, consumed_samples=61472.0, train_step_timing in s=0.307]Epoch 0: :   3%|▎         | 15369/600000 [02:33<1:37:22, v_num=12, reduced_train_loss=0.525, global_step=15368.0, consumed_samples=61476.0, train_step_timing in s=0.340]loss mask original None

First layer loss:  4.146915912628174 torch.Size([604, 4]) 9.942329406738281 0.0
Max loss timestep torch.Size([604, 4]) tensor([329,  71, 257,  43], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 4.601491451263428
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 1 loss 3.2935664653778076
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 2 loss 3.4004669189453125
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 3 loss 3.953772783279419
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
logits torch.Size([604, 4, 257024]) labels torch.Size([604, 4]) 0 257022
Layer  0  loss:  4.57489013671875 0.0 11.198692321777344
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([529,  46, 283, 106], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 4.98284387588501
bi 1 loss 4.018890857696533
bi 2 loss 3.6164708137512207
bi 3 loss 4.341484546661377
Layer  1  loss:  4.785712718963623 0.0 10.06620979309082
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([390, 135, 268,  78], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 5.18690824508667
bi 1 loss 4.087888717651367
bi 2 loss 4.162181854248047
bi 3 loss 4.558365821838379
Layer  2  loss:  4.99884033203125 0.0 12.074051856994629
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([586, 108, 243,  77], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 5.399307727813721
bi 1 loss 4.248765468597412
bi 2 loss 4.203124046325684
bi 3 loss 4.878264427185059
Layer  3  loss:  5.034327507019043 0.0 10.264705657958984
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([228,  50, 263, 181], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 5.37346887588501
bi 1 loss 4.328654766082764
bi 2 loss 4.468284606933594
bi 3 loss 4.94835901260376
Layer  4  loss:  5.2598347663879395 0.0 11.923501968383789
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([556, 113, 245, 149], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 5.6389946937561035
bi 1 loss 4.599246501922607
bi 2 loss 4.794820308685303
bi 3 loss 5.0000224113464355
Layer  5  loss:  5.2886643409729 0.0 9.969533920288086
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1021
Curr loss timestep torch.Size([604, 4]) tensor([583, 160, 265, 196], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 5.6047821044921875
bi 1 loss 4.692852020263672
bi 2 loss 4.748498439788818
bi 3 loss 5.164011478424072
Layer  6  loss:  5.316821098327637 0.0 9.477592468261719
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1021
Curr loss timestep torch.Size([604, 4]) tensor([396,  99, 287, 122], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 5.703542232513428
bi 1 loss 4.477206707000732
bi 2 loss 4.887024879455566
bi 3 loss 5.166991710662842
Epoch 0: :   3%|▎         | 15370/600000 [02:34<1:37:38, v_num=12, reduced_train_loss=0.525, global_step=15368.0, consumed_samples=61476.0, train_step_timing in s=0.340]Epoch 0: :   3%|▎         | 15370/600000 [02:34<1:37:38, v_num=12, reduced_train_loss=39.40, global_step=15369.0, consumed_samples=61480.0, train_step_timing in s=0.392]loss mask original None

First layer loss:  0.0724915862083435 torch.Size([382, 4]) 5.09416389465332 0.0
Max loss timestep torch.Size([382, 4]) tensor([339,  64, 100, 113], device='cuda:0') tensor(100, device='cuda:0')
bi 0 loss 0.09540069103240967
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 1 loss 0.021967532113194466
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 2 loss 0.07855067402124405
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 3 loss 0.060995034873485565
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
logits torch.Size([382, 4, 257024]) labels torch.Size([382, 4]) 0 257022
Layer  0  loss:  0.04777722805738449 0.0 4.752080917358398
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1023
Curr loss timestep torch.Size([382, 4]) tensor([339,  68, 184,  86], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.07772211730480194
bi 1 loss 0.02329414151608944
bi 2 loss 0.04567447677254677
bi 3 loss 0.02110481634736061
Layer  1  loss:  0.0592011958360672 0.0 4.782923221588135
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1022
Curr loss timestep torch.Size([382, 4]) tensor([339,  59, 124,  90], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.10706283152103424
bi 1 loss 0.031264133751392365
bi 2 loss 0.047455672174692154
bi 3 loss 0.032894913107156754
Layer  2  loss:  0.06808356940746307 0.0 2.983241558074951
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1023
Curr loss timestep torch.Size([382, 4]) tensor([345,  89, 347, 108], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.12188717722892761
bi 1 loss 0.04646030813455582
bi 2 loss 0.05192209780216217
bi 3 loss 0.03781948238611221
Layer  3  loss:  0.07158160954713821 0.0 8.80545711517334
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1019
Curr loss timestep torch.Size([382, 4]) tensor([339, 100, 304,  76], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.1379023939371109
bi 1 loss 0.026445360854268074
bi 2 loss 0.05509820953011513
bi 3 loss 0.042946118861436844
Layer  4  loss:  0.062272459268569946 0.0 5.838138103485107
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1019
Curr loss timestep torch.Size([382, 4]) tensor([339,  65, 320, 100], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.10053294897079468
bi 1 loss 0.03360120952129364
bi 2 loss 0.059073928743600845
bi 3 loss 0.027058377861976624
Layer  5  loss:  0.05141725391149521 0.0 4.604794502258301
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1023
Curr loss timestep torch.Size([382, 4]) tensor([339,  90, 304, 115], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.10771460086107254
bi 1 loss 0.027360297739505768
bi 2 loss 0.030745811760425568
bi 3 loss 0.03420909866690636
Layer  6  loss:  0.06492588669061661 0.0 7.535011291503906
logits torch.Size([382, 4, 1024]) labels torch.Size([382, 4]) 0 1022
Curr loss timestep torch.Size([382, 4]) tensor([339, 121, 304, 121], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.14552919566631317
bi 1 loss 0.02278042770922184
bi 2 loss 0.0407562330365181
bi 3 loss 0.03022787719964981
Epoch 0: :   3%|▎         | 15371/600000 [02:34<1:37:51, v_num=12, reduced_train_loss=39.40, global_step=15369.0, consumed_samples=61480.0, train_step_timing in s=0.392]Epoch 0: :   3%|▎         | 15371/600000 [02:34<1:37:51, v_num=12, reduced_train_loss=0.498, global_step=15370.0, consumed_samples=61484.0, train_step_timing in s=0.302]loss mask original None

First layer loss:  0.21271465718746185 torch.Size([577, 4]) 16.731346130371094 0.0
Max loss timestep torch.Size([577, 4]) tensor([396, 265, 436, 113], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.17946897447109222
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
bi 1 loss 0.06244578957557678
speech mask sum tensor(204, device='cuda:0') loss mask sum tensor(204, device='cuda:0')
bi 2 loss 0.44072577357292175
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 3 loss 0.13317295908927917
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
logits torch.Size([577, 4, 257024]) labels torch.Size([577, 4]) 0 257023
Layer  0  loss:  0.23597288131713867 0.0 18.993146896362305
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([272, 264, 437, 271], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.2983752489089966
bi 1 loss 0.06361383199691772
bi 2 loss 0.3816470205783844
bi 3 loss 0.1336435079574585
Layer  1  loss:  0.24479101598262787 0.0 14.765883445739746
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([273, 265, 276, 271], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.2794194221496582
bi 1 loss 0.057575926184654236
bi 2 loss 0.4383813440799713
bi 3 loss 0.1398538202047348
Layer  2  loss:  0.27410322427749634 0.0 18.69931411743164
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([395, 265, 276, 271], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.2896982729434967
bi 1 loss 0.07186516374349594
bi 2 loss 0.5155990123748779
bi 3 loss 0.15665751695632935
Layer  3  loss:  0.2751847207546234 0.0 18.74298095703125
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1018
Curr loss timestep torch.Size([577, 4]) tensor([273, 265, 277, 271], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.2878100275993347
bi 1 loss 0.09812108427286148
bi 2 loss 0.5007809996604919
bi 3 loss 0.16082270443439484
Layer  4  loss:  0.2595570981502533 0.0 18.79416275024414
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([273, 127, 277, 270], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.2464088499546051
bi 1 loss 0.07105626910924911
bi 2 loss 0.5269850492477417
bi 3 loss 0.1437777578830719
Layer  5  loss:  0.2502610385417938 0.0 18.898881912231445
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([395, 265, 436, 271], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.2948372960090637
bi 1 loss 0.08382507413625717
bi 2 loss 0.45066457986831665
bi 3 loss 0.1157756969332695
Layer  6  loss:  0.26001885533332825 0.0 13.622401237487793
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([273, 256, 276, 271], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.2714390158653259
bi 1 loss 0.050548408180475235
bi 2 loss 0.5074031949043274
bi 3 loss 0.14625810086727142
Epoch 0: :   3%|▎         | 15372/600000 [02:34<1:38:07, v_num=12, reduced_train_loss=0.498, global_step=15370.0, consumed_samples=61484.0, train_step_timing in s=0.302]Epoch 0: :   3%|▎         | 15372/600000 [02:34<1:38:07, v_num=12, reduced_train_loss=2.010, global_step=15371.0, consumed_samples=61488.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  0.06892164796590805 torch.Size([507, 4]) 6.321427345275879 0.0
Max loss timestep torch.Size([507, 4]) tensor([179, 179, 193, 158], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 0.03219369798898697
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 1 loss 0.11276010423898697
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 2 loss 0.07491805404424667
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 3 loss 0.05523679032921791
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
logits torch.Size([507, 4, 257024]) labels torch.Size([507, 4]) 0 257023
Layer  0  loss:  0.049308717250823975 0.0 5.6471452713012695
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([204, 184, 195, 150], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 0.036336544901132584
bi 1 loss 0.03493942320346832
bi 2 loss 0.07055306434631348
bi 3 loss 0.027307970449328423
Layer  1  loss:  0.056394513696432114 0.0 5.636521816253662
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([256, 121, 435, 161], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.03034048154950142
bi 1 loss 0.0436234176158905
bi 2 loss 0.07696221768856049
bi 3 loss 0.042957156896591187
Layer  2  loss:  0.04617459326982498 0.0 2.5667977333068848
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1022
Curr loss timestep torch.Size([507, 4]) tensor([195, 153, 418, 142], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.035930335521698
bi 1 loss 0.03387514501810074
bi 2 loss 0.06378113478422165
bi 3 loss 0.027852291241288185
Layer  3  loss:  0.03872957453131676 0.0 0.9340536594390869
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1022
Curr loss timestep torch.Size([507, 4]) tensor([200, 117, 145, 191], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 0.04032420367002487
bi 1 loss 0.025446632876992226
bi 2 loss 0.04506142809987068
bi 3 loss 0.03405328094959259
Layer  4  loss:  0.04129619523882866 0.0 1.6720796823501587
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1021
Curr loss timestep torch.Size([507, 4]) tensor([163, 100, 418, 267], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.041671350598335266
bi 1 loss 0.039795923978090286
bi 2 loss 0.04820404201745987
bi 3 loss 0.029355289414525032
Layer  5  loss:  0.045153357088565826 0.0 4.02351713180542
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([142,  97, 418, 171], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.037169914692640305
bi 1 loss 0.021365873515605927
bi 2 loss 0.05876817926764488
bi 3 loss 0.03948894888162613
Layer  6  loss:  0.04280010610818863 0.0 3.1802892684936523
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([190,  97, 418, 184], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.04365496709942818
bi 1 loss 0.03220999985933304
bi 2 loss 0.05334049463272095
bi 3 loss 0.02932305820286274
Epoch 0: :   3%|▎         | 15373/600000 [02:35<1:38:21, v_num=12, reduced_train_loss=2.010, global_step=15371.0, consumed_samples=61488.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15373/600000 [02:35<1:38:21, v_num=12, reduced_train_loss=0.389, global_step=15372.0, consumed_samples=61492.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  3.719247341156006 torch.Size([784, 4]) 11.663080215454102 0.0
Max loss timestep torch.Size([784, 4]) tensor([169, 370, 224,  61], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 3.431450843811035
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 1 loss 3.65134859085083
speech mask sum tensor(505, device='cuda:0') loss mask sum tensor(505, device='cuda:0')
bi 2 loss 4.080955505371094
speech mask sum tensor(266, device='cuda:0') loss mask sum tensor(266, device='cuda:0')
bi 3 loss 3.5523464679718018
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
logits torch.Size([784, 4, 257024]) labels torch.Size([784, 4]) 0 257022
Layer  0  loss:  4.244126796722412 0.0 11.228833198547363
logits torch.Size([784, 4, 1024]) labels torch.Size([784, 4]) 0 1023
Curr loss timestep torch.Size([784, 4]) tensor([142, 472, 338,  66], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 4.418173313140869
bi 1 loss 4.217742919921875
bi 2 loss 4.382833957672119
bi 3 loss 3.840747117996216
Layer  1  loss:  4.503931522369385 0.0 10.459909439086914
logits torch.Size([784, 4, 1024]) labels torch.Size([784, 4]) 0 1023
Curr loss timestep torch.Size([784, 4]) tensor([239, 469, 236,  71], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 4.867630958557129
bi 1 loss 4.438084125518799
bi 2 loss 4.591198444366455
bi 3 loss 4.151072978973389
Layer  2  loss:  4.719456195831299 0.0 10.189279556274414
logits torch.Size([784, 4, 1024]) labels torch.Size([784, 4]) 0 1022
Curr loss timestep torch.Size([784, 4]) tensor([194, 515, 280, 114], device='cuda:0') tensor(422, device='cuda:0')
bi 0 loss 4.822134494781494
bi 1 loss 4.725368976593018
bi 2 loss 4.802347183227539
bi 3 loss 4.389509201049805
Layer  3  loss:  4.833723545074463 0.0 10.566113471984863
logits torch.Size([784, 4, 1024]) labels torch.Size([784, 4]) 0 1023
Curr loss timestep torch.Size([784, 4]) tensor([251, 581, 368, 123], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.741119384765625
bi 1 loss 4.784994602203369
bi 2 loss 5.105234146118164
bi 3 loss 4.551192760467529
Layer  4  loss:  4.913813591003418 0.0 9.92881965637207
logits torch.Size([784, 4, 1024]) labels torch.Size([784, 4]) 0 1021
Curr loss timestep torch.Size([784, 4]) tensor([214, 618, 448, 117], device='cuda:0') tensor(208, device='cuda:0')
bi 0 loss 5.011598587036133
bi 1 loss 4.755735874176025
bi 2 loss 5.228633880615234
bi 3 loss 4.764292240142822
Layer  5  loss:  4.984379768371582 0.0 13.250783920288086
logits torch.Size([784, 4, 1024]) labels torch.Size([784, 4]) 0 1023
Curr loss timestep torch.Size([784, 4]) tensor([226, 514, 239,  64], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 5.1292901039123535
bi 1 loss 4.880795478820801
bi 2 loss 5.176725387573242
bi 3 loss 4.8201985359191895
Layer  6  loss:  4.968291282653809 0.0 10.745000839233398
logits torch.Size([784, 4, 1024]) labels torch.Size([784, 4]) 0 1019
Curr loss timestep torch.Size([784, 4]) tensor([260, 600, 209, 139], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 4.976686954498291
bi 1 loss 4.848395824432373
bi 2 loss 5.314032554626465
bi 3 loss 4.698557376861572
Epoch 0: :   3%|▎         | 15374/600000 [02:35<1:38:40, v_num=12, reduced_train_loss=0.389, global_step=15372.0, consumed_samples=61492.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15374/600000 [02:35<1:38:40, v_num=12, reduced_train_loss=36.90, global_step=15373.0, consumed_samples=61496.0, train_step_timing in s=0.462]loss mask original None

First layer loss:  0.02899198606610298 torch.Size([415, 4]) 0.6561504006385803 0.0
Max loss timestep torch.Size([415, 4]) tensor([311, 174,  73, 213], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.037819575518369675
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
bi 1 loss 0.026808811351656914
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 2 loss 0.01653142087161541
speech mask sum tensor(114, device='cuda:0') loss mask sum tensor(114, device='cuda:0')
bi 3 loss 0.022486012428998947
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
logits torch.Size([415, 4, 257024]) labels torch.Size([415, 4]) 0 257022
Layer  0  loss:  0.026812225580215454 0.0 1.0671284198760986
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1023
Curr loss timestep torch.Size([415, 4]) tensor([150, 230, 132, 303], device='cuda:0') tensor(150, device='cuda:0')
bi 0 loss 0.03515385463833809
bi 1 loss 0.01754981465637684
bi 2 loss 0.02199975773692131
bi 3 loss 0.021267130970954895
Layer  1  loss:  0.026791229844093323 0.0 0.36476945877075195
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1023
Curr loss timestep torch.Size([415, 4]) tensor([ 80, 184, 128, 247], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 0.03145739808678627
bi 1 loss 0.019309096038341522
bi 2 loss 0.018837960436940193
bi 3 loss 0.027498289942741394
Layer  2  loss:  0.027788516134023666 0.0 0.7949249744415283
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([324, 192, 138, 227], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.03289346024394035
bi 1 loss 0.014898627996444702
bi 2 loss 0.02846035175025463
bi 3 loss 0.02662571519613266
Layer  3  loss:  0.027850627899169922 0.0 0.42105379700660706
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([347, 195,  81, 219], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 0.03403772786259651
bi 1 loss 0.01808851584792137
bi 2 loss 0.023936839774250984
bi 3 loss 0.025497160851955414
Layer  4  loss:  0.027125030755996704 0.0 0.761802613735199
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1020
Curr loss timestep torch.Size([415, 4]) tensor([102, 228, 118, 197], device='cuda:0') tensor(118, device='cuda:0')
bi 0 loss 0.029308510944247246
bi 1 loss 0.019275613129138947
bi 2 loss 0.035118795931339264
bi 3 loss 0.024191973730921745
Layer  5  loss:  0.026077747344970703 0.0 0.47654372453689575
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1023
Curr loss timestep torch.Size([415, 4]) tensor([319, 244,  83, 235], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 0.03316214308142662
bi 1 loss 0.02100871130824089
bi 2 loss 0.020430417731404305
bi 3 loss 0.02058112807571888
Layer  6  loss:  0.025202732533216476 0.0 0.5281053185462952
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([371, 226, 128, 272], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.033155910670757294
bi 1 loss 0.014539615251123905
bi 2 loss 0.020061548799276352
bi 3 loss 0.021192079409956932
Epoch 0: :   3%|▎         | 15375/600000 [02:36<1:38:53, v_num=12, reduced_train_loss=36.90, global_step=15373.0, consumed_samples=61496.0, train_step_timing in s=0.462]Epoch 0: :   3%|▎         | 15375/600000 [02:36<1:38:53, v_num=12, reduced_train_loss=0.217, global_step=15374.0, consumed_samples=61500.0, train_step_timing in s=0.306]loss mask original None

First layer loss:  0.14793504774570465 torch.Size([517, 4]) 14.517537117004395 0.0
Max loss timestep torch.Size([517, 4]) tensor([348, 459, 374, 306], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.16542059183120728
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 1 loss 0.12365643680095673
speech mask sum tensor(409, device='cuda:0') loss mask sum tensor(409, device='cuda:0')
bi 2 loss 0.10253053903579712
speech mask sum tensor(410, device='cuda:0') loss mask sum tensor(410, device='cuda:0')
bi 3 loss 0.20057035982608795
speech mask sum tensor(444, device='cuda:0') loss mask sum tensor(444, device='cuda:0')
logits torch.Size([517, 4, 257024]) labels torch.Size([517, 4]) 0 257023
Layer  0  loss:  0.18098300695419312 0.0 11.166274070739746
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([349, 458, 375, 324], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.13363032042980194
bi 1 loss 0.18922054767608643
bi 2 loss 0.17390605807304382
bi 3 loss 0.21149826049804688
Layer  1  loss:  0.15754610300064087 0.0 10.82531452178955
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([348, 458, 375, 323], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.12294385582208633
bi 1 loss 0.17147508263587952
bi 2 loss 0.14882029592990875
bi 3 loss 0.17584094405174255
Layer  2  loss:  0.1978888213634491 0.0 15.250299453735352
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([349, 458, 374, 324], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.1592416614294052
bi 1 loss 0.18087908625602722
bi 2 loss 0.17813289165496826
bi 3 loss 0.2575654685497284
Layer  3  loss:  0.18035097420215607 0.0 17.203941345214844
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([348, 459, 375, 306], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.1614169329404831
bi 1 loss 0.15939165651798248
bi 2 loss 0.14422449469566345
bi 3 loss 0.2456408590078354
Layer  4  loss:  0.1917671412229538 0.0 16.110427856445312
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([348, 458, 374, 324], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.15087011456489563
bi 1 loss 0.2226531207561493
bi 2 loss 0.1608353704214096
bi 3 loss 0.2191435992717743
Layer  5  loss:  0.18238259851932526 0.0 17.968891143798828
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([348, 458, 374, 322], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.15382763743400574
bi 1 loss 0.19427542388439178
bi 2 loss 0.15806835889816284
bi 3 loss 0.2129162698984146
Layer  6  loss:  0.18236443400382996 0.0 19.813867568969727
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1019
Curr loss timestep torch.Size([517, 4]) tensor([349, 458, 375, 306], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.129130020737648
bi 1 loss 0.17923271656036377
bi 2 loss 0.1424504667520523
bi 3 loss 0.25759634375572205
Epoch 0: :   3%|▎         | 15376/600000 [02:36<1:39:07, v_num=12, reduced_train_loss=0.217, global_step=15374.0, consumed_samples=61500.0, train_step_timing in s=0.306]Epoch 0: :   3%|▎         | 15376/600000 [02:36<1:39:07, v_num=12, reduced_train_loss=1.420, global_step=15375.0, consumed_samples=61504.0, train_step_timing in s=0.361]loss mask original None

First layer loss:  0.08699050545692444 torch.Size([601, 4]) 9.157208442687988 0.0
Max loss timestep torch.Size([601, 4]) tensor([136, 519, 279, 211], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.019061794504523277
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 1 loss 0.06684120744466782
speech mask sum tensor(371, device='cuda:0') loss mask sum tensor(371, device='cuda:0')
bi 2 loss 0.15770971775054932
speech mask sum tensor(308, device='cuda:0') loss mask sum tensor(308, device='cuda:0')
bi 3 loss 0.01439289003610611
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
logits torch.Size([601, 4, 257024]) labels torch.Size([601, 4]) 0 257022
Layer  0  loss:  0.1190277561545372 0.0 17.059541702270508
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([209, 403, 279, 219], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.03750533238053322
bi 1 loss 0.09026385843753815
bi 2 loss 0.21350595355033875
bi 3 loss 0.013113315217196941
Layer  1  loss:  0.10061921179294586 0.0 10.62536907196045
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([187, 261, 278, 219], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.029991842806339264
bi 1 loss 0.10110552608966827
bi 2 loss 0.15077294409275055
bi 3 loss 0.013894390314817429
Layer  2  loss:  0.09250569343566895 0.0 9.417160987854004
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([185, 366, 278, 181], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.057860832661390305
bi 1 loss 0.0736936628818512
bi 2 loss 0.14913591742515564
bi 3 loss 0.008219039067626
Layer  3  loss:  0.09485514461994171 0.0 11.87519645690918
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1021
Curr loss timestep torch.Size([601, 4]) tensor([183, 519, 280, 216], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.02748969756066799
bi 1 loss 0.06061943620443344
bi 2 loss 0.18050776422023773
bi 3 loss 0.030440792441368103
Layer  4  loss:  0.09332562983036041 0.0 10.146200180053711
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([210, 519, 279, 202], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.029418757185339928
bi 1 loss 0.09107016772031784
bi 2 loss 0.14332164824008942
bi 3 loss 0.008565489202737808
Layer  5  loss:  0.11103075742721558 0.0 14.332962989807129
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([185, 590, 278, 220], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.038143012672662735
bi 1 loss 0.102333664894104
bi 2 loss 0.1644311249256134
bi 3 loss 0.06492199748754501
Layer  6  loss:  0.11906969547271729 0.0 10.911108016967773
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([116, 546, 280, 189], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.04176325723528862
bi 1 loss 0.109601691365242
bi 2 loss 0.18950435519218445
bi 3 loss 0.008089758455753326
Epoch 0: :   3%|▎         | 15377/600000 [02:36<1:39:24, v_num=12, reduced_train_loss=1.420, global_step=15375.0, consumed_samples=61504.0, train_step_timing in s=0.361]Epoch 0: :   3%|▎         | 15377/600000 [02:36<1:39:24, v_num=12, reduced_train_loss=0.817, global_step=15376.0, consumed_samples=61508.0, train_step_timing in s=0.412]loss mask original None

First layer loss:  0.10298868268728256 torch.Size([685, 4]) 10.750202178955078 0.0
Max loss timestep torch.Size([685, 4]) tensor([287, 337, 216, 566], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.08223844319581985
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
bi 1 loss 0.07033675909042358
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 2 loss 0.03429831936955452
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 3 loss 0.13824450969696045
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
logits torch.Size([685, 4, 257024]) labels torch.Size([685, 4]) 0 257022
Layer  0  loss:  0.09473419934511185 0.0 5.812841892242432
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([287, 281, 194, 649], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.0789501741528511
bi 1 loss 0.0684557855129242
bi 2 loss 0.06162775680422783
bi 3 loss 0.11771491914987564
Layer  1  loss:  0.09912076592445374 0.0 6.58665657043457
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([276, 255, 236, 647], device='cuda:0') tensor(647, device='cuda:0')
bi 0 loss 0.08986111730337143
bi 1 loss 0.04595130681991577
bi 2 loss 0.03174377977848053
bi 3 loss 0.13871005177497864
Layer  2  loss:  0.09700112044811249 0.0 12.563103675842285
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([288, 317, 213, 566], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.06058534234762192
bi 1 loss 0.05749211087822914
bi 2 loss 0.03191886097192764
bi 3 loss 0.13899466395378113
Layer  3  loss:  0.12009241431951523 0.0 5.888804912567139
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([288, 256, 267, 567], device='cuda:0') tensor(567, device='cuda:0')
bi 0 loss 0.08730484545230865
bi 1 loss 0.08583250641822815
bi 2 loss 0.07969821244478226
bi 3 loss 0.15318329632282257
Layer  4  loss:  0.10627657175064087 0.0 7.398744583129883
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([278, 325, 231, 562], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.10254772007465363
bi 1 loss 0.05165202543139458
bi 2 loss 0.07283381372690201
bi 3 loss 0.13691875338554382
Layer  5  loss:  0.09575528651475906 0.0 6.718960762023926
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([291, 337, 267, 547], device='cuda:0') tensor(547, device='cuda:0')
bi 0 loss 0.05559726059436798
bi 1 loss 0.07832127809524536
bi 2 loss 0.07759744673967361
bi 3 loss 0.11928604543209076
Layer  6  loss:  0.12306958436965942 0.0 11.25772476196289
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([286, 335, 178, 647], device='cuda:0') tensor(647, device='cuda:0')
bi 0 loss 0.08633933216333389
bi 1 loss 0.06967247277498245
bi 2 loss 0.03311159089207649
bi 3 loss 0.17643161118030548
Epoch 0: :   3%|▎         | 15378/600000 [02:37<1:39:43, v_num=12, reduced_train_loss=0.817, global_step=15376.0, consumed_samples=61508.0, train_step_timing in s=0.412]Epoch 0: :   3%|▎         | 15378/600000 [02:37<1:39:43, v_num=12, reduced_train_loss=0.839, global_step=15377.0, consumed_samples=61512.0, train_step_timing in s=0.468]loss mask original None

First layer loss:  3.5429039001464844 torch.Size([440, 4]) 11.032885551452637 0.0
Max loss timestep torch.Size([440, 4]) tensor([218, 228, 295, 206], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 4.303523540496826
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 1 loss 3.419782876968384
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 2 loss 3.255091905593872
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 3 loss 3.5028774738311768
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
logits torch.Size([440, 4, 257024]) labels torch.Size([440, 4]) 0 257023
Layer  0  loss:  4.149171352386475 0.0 10.882525444030762
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([ 92, 157, 342, 405], device='cuda:0') tensor(157, device='cuda:0')
bi 0 loss 4.565639972686768
bi 1 loss 3.9847121238708496
bi 2 loss 3.6621885299682617
bi 3 loss 4.579843521118164
Layer  1  loss:  4.443387985229492 0.0 9.740337371826172
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([158, 332, 200, 177], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 4.905067443847656
bi 1 loss 4.4720778465271
bi 2 loss 4.006320953369141
bi 3 loss 4.656269550323486
Layer  2  loss:  4.675837993621826 0.0 11.73383617401123
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([210, 253, 195, 147], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 5.35275411605835
bi 1 loss 4.636903762817383
bi 2 loss 4.140708923339844
bi 3 loss 4.919256210327148
Layer  3  loss:  4.804202556610107 0.0 12.25501823425293
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([ 95, 232, 269, 359], device='cuda:0') tensor(208, device='cuda:0')
bi 0 loss 5.307024002075195
bi 1 loss 4.712177753448486
bi 2 loss 4.372128009796143
bi 3 loss 5.068632125854492
Layer  4  loss:  4.934640407562256 0.0 11.165225982666016
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([ 97, 305, 394, 351], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 5.600986957550049
bi 1 loss 4.851536750793457
bi 2 loss 4.385774612426758
bi 3 loss 5.2307257652282715
Layer  5  loss:  5.081873893737793 0.0 10.741593360900879
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([232, 159, 299, 250], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 5.6535186767578125
bi 1 loss 5.026538372039795
bi 2 loss 4.569474220275879
bi 3 loss 5.373714923858643
Layer  6  loss:  5.1055192947387695 0.0 9.936659812927246
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([176, 334,  57, 256], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 5.682411193847656
bi 1 loss 5.0610270500183105
bi 2 loss 4.5698113441467285
bi 3 loss 5.414116382598877
Epoch 0: :   3%|▎         | 15379/600000 [02:37<1:39:56, v_num=12, reduced_train_loss=0.839, global_step=15377.0, consumed_samples=61512.0, train_step_timing in s=0.468]Epoch 0: :   3%|▎         | 15379/600000 [02:37<1:39:56, v_num=12, reduced_train_loss=36.70, global_step=15378.0, consumed_samples=61516.0, train_step_timing in s=0.309]loss mask original None

First layer loss:  0.05059525743126869 torch.Size([569, 4]) 3.591806173324585 0.0
Max loss timestep torch.Size([569, 4]) tensor([522, 113,  62, 279], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.06540381908416748
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
bi 1 loss 0.011190834455192089
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 2 loss 0.016035037115216255
speech mask sum tensor(60, device='cuda:0') loss mask sum tensor(60, device='cuda:0')
bi 3 loss 0.043102823197841644
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
logits torch.Size([569, 4, 257024]) labels torch.Size([569, 4]) 0 257023
Layer  0  loss:  0.05933428928256035 0.0 7.189136981964111
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([522,  91,  71, 244], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.08243358135223389
bi 1 loss 0.013077761977910995
bi 2 loss 0.025294777005910873
bi 3 loss 0.032290756702423096
Layer  1  loss:  0.06196286529302597 0.0 4.901569366455078
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([522, 109,  52, 267], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.07531722635030746
bi 1 loss 0.014361951500177383
bi 2 loss 0.07418017089366913
bi 3 loss 0.042572155594825745
Layer  2  loss:  0.0562857948243618 0.0 9.1561918258667
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([522, 110,  62, 260], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.07545893639326096
bi 1 loss 0.019344566389918327
bi 2 loss 0.028973961248993874
bi 3 loss 0.03277285769581795
Layer  3  loss:  0.05903752148151398 0.0 9.771194458007812
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1021
Curr loss timestep torch.Size([569, 4]) tensor([522, 140,  57, 292], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.08108807355165482
bi 1 loss 0.020401379093527794
bi 2 loss 0.02294175699353218
bi 3 loss 0.03218516707420349
Layer  4  loss:  0.05143735930323601 0.0 5.026187896728516
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([522,  96,  42, 291], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.06508411467075348
bi 1 loss 0.026506636291742325
bi 2 loss 0.02444002591073513
bi 3 loss 0.03724384680390358
Layer  5  loss:  0.06090696528553963 0.0 7.567023277282715
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1020
Curr loss timestep torch.Size([569, 4]) tensor([522, 109,  46, 226], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.08279570192098618
bi 1 loss 0.019619420170783997
bi 2 loss 0.023740610107779503
bi 3 loss 0.03616665303707123
Layer  6  loss:  0.054862406104803085 0.0 5.3978729248046875
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([522, 105,  58, 205], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.07447118312120438
bi 1 loss 0.023502346128225327
bi 2 loss 0.014033057726919651
bi 3 loss 0.03326325863599777
Epoch 0: :   3%|▎         | 15380/600000 [02:38<1:40:12, v_num=12, reduced_train_loss=36.70, global_step=15378.0, consumed_samples=61516.0, train_step_timing in s=0.309]Epoch 0: :   3%|▎         | 15380/600000 [02:38<1:40:12, v_num=12, reduced_train_loss=0.454, global_step=15379.0, consumed_samples=61520.0, train_step_timing in s=0.396]loss mask original None

First layer loss:  3.070850372314453 torch.Size([644, 4]) 10.424957275390625 0.0
Max loss timestep torch.Size([644, 4]) tensor([378, 153, 489, 188], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 2.755680561065674
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
bi 1 loss 3.215757131576538
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 2 loss 3.2920329570770264
speech mask sum tensor(294, device='cuda:0') loss mask sum tensor(294, device='cuda:0')
bi 3 loss 3.6083483695983887
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
logits torch.Size([644, 4, 257024]) labels torch.Size([644, 4]) 0 257022
Layer  0  loss:  3.713263750076294 0.0 9.725015640258789
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([385, 150, 299, 218], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 3.142996072769165
bi 1 loss 4.0174360275268555
bi 2 loss 4.123976707458496
bi 3 loss 4.592474460601807
Layer  1  loss:  3.9725961685180664 0.0 9.948934555053711
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([346, 233, 438, 193], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 3.5184483528137207
bi 1 loss 4.166031360626221
bi 2 loss 4.4486823081970215
bi 3 loss 4.312005519866943
Layer  2  loss:  4.127316474914551 0.0 10.978658676147461
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([438, 244, 315, 203], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 3.599277973175049
bi 1 loss 4.416982650756836
bi 2 loss 4.578169822692871
bi 3 loss 4.724055767059326
Layer  3  loss:  4.27410888671875 0.0 10.643226623535156
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1017
Curr loss timestep torch.Size([644, 4]) tensor([439, 220, 287, 192], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 3.7237112522125244
bi 1 loss 4.531236171722412
bi 2 loss 4.8244452476501465
bi 3 loss 4.729093551635742
Layer  4  loss:  4.39288854598999 0.0 9.860621452331543
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([552, 242, 453, 171], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 3.772298574447632
bi 1 loss 4.800448894500732
bi 2 loss 4.979587078094482
bi 3 loss 4.828465461730957
Layer  5  loss:  4.436347007751465 0.0 9.620145797729492
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([474, 159, 434, 205], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 3.9159185886383057
bi 1 loss 4.685395240783691
bi 2 loss 4.9324493408203125
bi 3 loss 4.928341865539551
Layer  6  loss:  4.403998374938965 0.0 9.443202018737793
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1021
Curr loss timestep torch.Size([644, 4]) tensor([436, 256, 290, 196], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 3.8128585815429688
bi 1 loss 4.864958763122559
bi 2 loss 4.920469284057617
bi 3 loss 4.833531379699707
Epoch 0: :   3%|▎         | 15381/600000 [02:38<1:40:28, v_num=12, reduced_train_loss=0.454, global_step=15379.0, consumed_samples=61520.0, train_step_timing in s=0.396]Epoch 0: :   3%|▎         | 15381/600000 [02:38<1:40:28, v_num=12, reduced_train_loss=32.40, global_step=15380.0, consumed_samples=61524.0, train_step_timing in s=0.408]loss mask original None

First layer loss:  0.08269323408603668 torch.Size([626, 4]) 7.319085597991943 0.0
Max loss timestep torch.Size([626, 4]) tensor([519, 486, 439,  96], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.0820673406124115
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
bi 1 loss 0.07899362593889236
speech mask sum tensor(342, device='cuda:0') loss mask sum tensor(342, device='cuda:0')
bi 2 loss 0.09878905117511749
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
bi 3 loss 0.05236971750855446
speech mask sum tensor(200, device='cuda:0') loss mask sum tensor(200, device='cuda:0')
logits torch.Size([626, 4, 257024]) labels torch.Size([626, 4]) 0 257022
Layer  0  loss:  0.10065104812383652 0.0 8.569296836853027
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1023
Curr loss timestep torch.Size([626, 4]) tensor([527, 322, 438,  86], device='cuda:0') tensor(438, device='cuda:0')
bi 0 loss 0.07879994809627533
bi 1 loss 0.08805905282497406
bi 2 loss 0.14882400631904602
bi 3 loss 0.05514722689986229
Layer  1  loss:  0.11433061957359314 0.0 9.917044639587402
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1022
Curr loss timestep torch.Size([626, 4]) tensor([508, 314, 438, 133], device='cuda:0') tensor(438, device='cuda:0')
bi 0 loss 0.11539711058139801
bi 1 loss 0.11589079350233078
bi 2 loss 0.13957132399082184
bi 3 loss 0.0498177707195282
Layer  2  loss:  0.12325695902109146 0.0 14.18242073059082
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1022
Curr loss timestep torch.Size([626, 4]) tensor([135, 315, 439,  91], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.08924967795610428
bi 1 loss 0.13309864699840546
bi 2 loss 0.18280772864818573
bi 3 loss 0.03849345073103905
Layer  3  loss:  0.1496860384941101 0.0 19.179697036743164
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1020
Curr loss timestep torch.Size([626, 4]) tensor([331, 322, 438,  57], device='cuda:0') tensor(438, device='cuda:0')
bi 0 loss 0.10552821308374405
bi 1 loss 0.1900300830602646
bi 2 loss 0.1979185789823532
bi 3 loss 0.06114579737186432
Layer  4  loss:  0.13577944040298462 0.0 14.887505531311035
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1021
Curr loss timestep torch.Size([626, 4]) tensor([508, 315, 439,  61], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.11844486743211746
bi 1 loss 0.1313595026731491
bi 2 loss 0.1996823102235794
bi 3 loss 0.02953610010445118
Layer  5  loss:  0.13520047068595886 0.0 13.047492980957031
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1023
Curr loss timestep torch.Size([626, 4]) tensor([403, 315, 439, 122], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.10678799450397491
bi 1 loss 0.13768813014030457
bi 2 loss 0.1915850043296814
bi 3 loss 0.0585397444665432
Layer  6  loss:  0.126359224319458 0.0 9.80944538116455
logits torch.Size([626, 4, 1024]) labels torch.Size([626, 4]) 0 1023
Curr loss timestep torch.Size([626, 4]) tensor([508, 315, 439, 146], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.09060773998498917
bi 1 loss 0.12895502150058746
bi 2 loss 0.18678496778011322
bi 3 loss 0.05564504116773605
Epoch 0: :   3%|▎         | 15382/600000 [02:39<1:40:46, v_num=12, reduced_train_loss=32.40, global_step=15380.0, consumed_samples=61524.0, train_step_timing in s=0.408]Epoch 0: :   3%|▎         | 15382/600000 [02:39<1:40:46, v_num=12, reduced_train_loss=0.968, global_step=15381.0, consumed_samples=61528.0, train_step_timing in s=0.429]loss mask original None

First layer loss:  0.16370034217834473 torch.Size([613, 4]) 9.124088287353516 0.0
Max loss timestep torch.Size([613, 4]) tensor([533, 139, 359, 212], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.23777559399604797
speech mask sum tensor(450, device='cuda:0') loss mask sum tensor(450, device='cuda:0')
bi 1 loss 0.03746351972222328
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 2 loss 0.1153266653418541
speech mask sum tensor(237, device='cuda:0') loss mask sum tensor(237, device='cuda:0')
bi 3 loss 0.05083760619163513
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
logits torch.Size([613, 4, 257024]) labels torch.Size([613, 4]) 0 257022
Layer  0  loss:  0.21846042573451996 0.0 13.31368350982666
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([345, 145, 182, 228], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.315538614988327
bi 1 loss 0.07802712917327881
bi 2 loss 0.1578853875398636
bi 3 loss 0.04785841703414917
Layer  1  loss:  0.20686665177345276 0.0 11.72287654876709
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([344, 119, 316, 248], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.30282315611839294
bi 1 loss 0.04294346645474434
bi 2 loss 0.15571630001068115
bi 3 loss 0.036348771303892136
Layer  2  loss:  0.23315630853176117 0.0 17.669452667236328
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1022
Curr loss timestep torch.Size([613, 4]) tensor([343, 123, 299, 192], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.361774742603302
bi 1 loss 0.08128060400485992
bi 2 loss 0.10238607972860336
bi 3 loss 0.0921928659081459
Layer  3  loss:  0.23023036122322083 0.0 16.369775772094727
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1020
Curr loss timestep torch.Size([613, 4]) tensor([344, 149, 303, 245], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.35502922534942627
bi 1 loss 0.05941416695713997
bi 2 loss 0.12193317711353302
bi 3 loss 0.06939570605754852
Layer  4  loss:  0.2165209949016571 0.0 17.978328704833984
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1022
Curr loss timestep torch.Size([613, 4]) tensor([343, 114, 336, 234], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.3274385929107666
bi 1 loss 0.0835721492767334
bi 2 loss 0.12504814565181732
bi 3 loss 0.05079452693462372
Layer  5  loss:  0.22831769287586212 0.0 20.938323974609375
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([344, 133, 312, 170], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.33206766843795776
bi 1 loss 0.048445481806993484
bi 2 loss 0.1758507937192917
bi 3 loss 0.03964826092123985
Layer  6  loss:  0.2221636325120926 0.0 14.5800199508667
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1022
Curr loss timestep torch.Size([613, 4]) tensor([345, 124, 383, 231], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.32860344648361206
bi 1 loss 0.04576180502772331
bi 2 loss 0.14681784808635712
bi 3 loss 0.0691254660487175
Epoch 0: :   3%|▎         | 15383/600000 [02:39<1:41:03, v_num=12, reduced_train_loss=0.968, global_step=15381.0, consumed_samples=61528.0, train_step_timing in s=0.429]Epoch 0: :   3%|▎         | 15383/600000 [02:39<1:41:03, v_num=12, reduced_train_loss=1.720, global_step=15382.0, consumed_samples=61532.0, train_step_timing in s=0.420]loss mask original None

First layer loss:  3.5875661373138428 torch.Size([664, 4]) 11.20713996887207 0.0
Max loss timestep torch.Size([664, 4]) tensor([248, 347,  97,  76], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 3.404784917831421
speech mask sum tensor(504, device='cuda:0') loss mask sum tensor(504, device='cuda:0')
bi 1 loss 4.037187576293945
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
bi 2 loss 3.1024155616760254
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
bi 3 loss 3.7007737159729004
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
logits torch.Size([664, 4, 257024]) labels torch.Size([664, 4]) 0 257022
Layer  0  loss:  4.31003475189209 0.0 12.987112998962402
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([202, 347,  81,  99], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.132107734680176
bi 1 loss 5.001049041748047
bi 2 loss 3.4591171741485596
bi 3 loss 4.113167762756348
Layer  1  loss:  4.535555839538574 0.0 9.670205116271973
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([584, 401,  72, 125], device='cuda:0') tensor(81, device='cuda:0')
bi 0 loss 4.350122928619385
bi 1 loss 5.078210353851318
bi 2 loss 3.8952133655548096
bi 3 loss 4.562865257263184
Layer  2  loss:  4.908873558044434 0.0 10.079598426818848
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([221, 272, 109, 138], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.852036952972412
bi 1 loss 5.191916465759277
bi 2 loss 4.315340518951416
bi 3 loss 4.9805192947387695
Layer  3  loss:  5.02364444732666 0.0 10.440389633178711
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1021
Curr loss timestep torch.Size([664, 4]) tensor([523, 400, 109, 123], device='cuda:0') tensor(93, device='cuda:0')
bi 0 loss 5.008360862731934
bi 1 loss 5.297351360321045
bi 2 loss 4.555972099304199
bi 3 loss 4.815099716186523
Layer  4  loss:  5.153968811035156 0.0 10.665864944458008
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([373, 286,  88, 104], device='cuda:0') tensor(88, device='cuda:0')
bi 0 loss 5.07551383972168
bi 1 loss 5.475846767425537
bi 2 loss 4.687848091125488
bi 3 loss 5.106280326843262
Layer  5  loss:  5.162850379943848 0.0 9.948591232299805
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1019
Curr loss timestep torch.Size([664, 4]) tensor([365, 293, 111,  89], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 5.070586681365967
bi 1 loss 5.477148056030273
bi 2 loss 4.720490455627441
bi 3 loss 5.175633430480957
Layer  6  loss:  5.218217849731445 0.0 10.019856452941895
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1021
Curr loss timestep torch.Size([664, 4]) tensor([314, 197,  67,  98], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 5.19534969329834
bi 1 loss 5.502851486206055
bi 2 loss 4.789882183074951
bi 3 loss 4.979715347290039
Epoch 0: :   3%|▎         | 15384/600000 [02:39<1:41:19, v_num=12, reduced_train_loss=1.720, global_step=15382.0, consumed_samples=61532.0, train_step_timing in s=0.420]Epoch 0: :   3%|▎         | 15384/600000 [02:39<1:41:19, v_num=12, reduced_train_loss=37.90, global_step=15383.0, consumed_samples=61536.0, train_step_timing in s=0.414]loss mask original None

First layer loss:  0.0801905170083046 torch.Size([545, 4]) 12.605829238891602 0.0
Max loss timestep torch.Size([545, 4]) tensor([213, 333, 144, 332], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.02532579004764557
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
bi 1 loss 0.10270753502845764
speech mask sum tensor(502, device='cuda:0') loss mask sum tensor(502, device='cuda:0')
bi 2 loss 0.03166430816054344
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 3 loss 0.0717027336359024
speech mask sum tensor(311, device='cuda:0') loss mask sum tensor(311, device='cuda:0')
logits torch.Size([545, 4, 257024]) labels torch.Size([545, 4]) 0 257022
Layer  0  loss:  0.0956454649567604 0.0 15.500028610229492
logits torch.Size([545, 4, 1024]) labels torch.Size([545, 4]) 0 1023
Curr loss timestep torch.Size([545, 4]) tensor([172, 331, 180, 332], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.032400548458099365
bi 1 loss 0.12255097180604935
bi 2 loss 0.03539377450942993
bi 3 loss 0.08529999852180481
Layer  1  loss:  0.10037429630756378 0.0 15.637086868286133
logits torch.Size([545, 4, 1024]) labels torch.Size([545, 4]) 0 1023
Curr loss timestep torch.Size([545, 4]) tensor([165, 331, 172, 332], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.027826527133584023
bi 1 loss 0.12839604914188385
bi 2 loss 0.050101280212402344
bi 3 loss 0.08885268867015839
Layer  2  loss:  0.10303817689418793 0.0 12.891432762145996
logits torch.Size([545, 4, 1024]) labels torch.Size([545, 4]) 0 1022
Curr loss timestep torch.Size([545, 4]) tensor([165, 330, 149, 332], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.035933416336774826
bi 1 loss 0.1314379870891571
bi 2 loss 0.0162733793258667
bi 3 loss 0.0974397212266922
Layer  3  loss:  0.09185270220041275 0.0 11.40084457397461
logits torch.Size([545, 4, 1024]) labels torch.Size([545, 4]) 0 1023
Curr loss timestep torch.Size([545, 4]) tensor([202, 333, 178, 332], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.027357444167137146
bi 1 loss 0.12118596583604813
bi 2 loss 0.02993130311369896
bi 3 loss 0.0783502459526062
Layer  4  loss:  0.10158463567495346 0.0 12.21630573272705
logits torch.Size([545, 4, 1024]) labels torch.Size([545, 4]) 0 1022
Curr loss timestep torch.Size([545, 4]) tensor([181, 333, 137, 332], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.03816007450222969
bi 1 loss 0.13950657844543457
bi 2 loss 0.034897975623607635
bi 3 loss 0.07496088743209839
Layer  5  loss:  0.10902799665927887 0.0 10.729232788085938
logits torch.Size([545, 4, 1024]) labels torch.Size([545, 4]) 0 1023
Curr loss timestep torch.Size([545, 4]) tensor([202, 333, 167, 332], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.03171997889876366
bi 1 loss 0.13695155084133148
bi 2 loss 0.0392383448779583
bi 3 loss 0.10352710634469986
Layer  6  loss:  0.09843633323907852 0.0 18.171905517578125
logits torch.Size([545, 4, 1024]) labels torch.Size([545, 4]) 0 1022
Curr loss timestep torch.Size([545, 4]) tensor([202, 331, 141, 332], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.01373098324984312
bi 1 loss 0.12489648908376694
bi 2 loss 0.08021602779626846
bi 3 loss 0.08597378432750702
Epoch 0: :   3%|▎         | 15385/600000 [02:40<1:41:35, v_num=12, reduced_train_loss=37.90, global_step=15383.0, consumed_samples=61536.0, train_step_timing in s=0.414]Epoch 0: :   3%|▎         | 15385/600000 [02:40<1:41:35, v_num=12, reduced_train_loss=0.780, global_step=15384.0, consumed_samples=61540.0, train_step_timing in s=0.375]loss mask original None

First layer loss:  0.11706912517547607 torch.Size([630, 4]) 11.130517959594727 0.0
Max loss timestep torch.Size([630, 4]) tensor([336, 307, 344, 150], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.17066866159439087
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
bi 1 loss 0.1042659729719162
speech mask sum tensor(465, device='cuda:0') loss mask sum tensor(465, device='cuda:0')
bi 2 loss 0.13744908571243286
speech mask sum tensor(389, device='cuda:0') loss mask sum tensor(389, device='cuda:0')
bi 3 loss 0.0401611402630806
speech mask sum tensor(110, device='cuda:0') loss mask sum tensor(110, device='cuda:0')
logits torch.Size([630, 4, 257024]) labels torch.Size([630, 4]) 0 257022
Layer  0  loss:  0.13293026387691498 0.0 7.326896667480469
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([283, 593, 344, 134], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.2116589993238449
bi 1 loss 0.13749773800373077
bi 2 loss 0.12479720264673233
bi 3 loss 0.05578205734491348
Layer  1  loss:  0.16935060918331146 0.0 13.067741394042969
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([283, 307, 344, 164], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.2489347904920578
bi 1 loss 0.17785918712615967
bi 2 loss 0.1689857542514801
bi 3 loss 0.04713026434183121
Layer  2  loss:  0.13772141933441162 0.0 14.141861915588379
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1022
Curr loss timestep torch.Size([630, 4]) tensor([283, 582, 422, 130], device='cuda:0') tensor(582, device='cuda:0')
bi 0 loss 0.18931442499160767
bi 1 loss 0.16956524550914764
bi 2 loss 0.11366542428731918
bi 3 loss 0.03142733499407768
Layer  3  loss:  0.16128624975681305 0.0 8.93805980682373
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1021
Curr loss timestep torch.Size([630, 4]) tensor([283, 593, 337, 112], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.24490532279014587
bi 1 loss 0.1787518560886383
bi 2 loss 0.14836110174655914
bi 3 loss 0.0411812923848629
Layer  4  loss:  0.17048367857933044 0.0 11.650003433227539
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1020
Curr loss timestep torch.Size([630, 4]) tensor([283, 582, 344, 164], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.3092811703681946
bi 1 loss 0.16368591785430908
bi 2 loss 0.17165504395961761
bi 3 loss 0.042400117963552475
Layer  5  loss:  0.18594741821289062 0.0 15.548686981201172
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([324, 582, 344, 154], device='cuda:0') tensor(582, device='cuda:0')
bi 0 loss 0.32478708028793335
bi 1 loss 0.22176891565322876
bi 2 loss 0.14516355097293854
bi 3 loss 0.02602311410009861
Layer  6  loss:  0.17020635306835175 0.0 14.713727951049805
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1021
Curr loss timestep torch.Size([630, 4]) tensor([283, 307, 344, 108], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.2972785234451294
bi 1 loss 0.1975780874490738
bi 2 loss 0.1313050240278244
bi 3 loss 0.052288565784692764
Epoch 0: :   3%|▎         | 15386/600000 [02:40<1:41:52, v_num=12, reduced_train_loss=0.780, global_step=15384.0, consumed_samples=61540.0, train_step_timing in s=0.375]Epoch 0: :   3%|▎         | 15386/600000 [02:40<1:41:52, v_num=12, reduced_train_loss=1.240, global_step=15385.0, consumed_samples=61544.0, train_step_timing in s=0.428]loss mask original None

First layer loss:  0.1387360692024231 torch.Size([533, 4]) 12.886889457702637 0.0
Max loss timestep torch.Size([533, 4]) tensor([325, 264, 389, 514], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.08422224968671799
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
bi 1 loss 0.10333328694105148
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
bi 2 loss 0.15377706289291382
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
bi 3 loss 0.18026454746723175
speech mask sum tensor(290, device='cuda:0') loss mask sum tensor(290, device='cuda:0')
logits torch.Size([533, 4, 257024]) labels torch.Size([533, 4]) 0 257022
Layer  0  loss:  0.1467188000679016 0.0 9.726767539978027
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([325, 264, 405, 514], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.11528665572404861
bi 1 loss 0.18284021317958832
bi 2 loss 0.13198374211788177
bi 3 loss 0.16760726273059845
Layer  1  loss:  0.14268694818019867 0.0 9.229120254516602
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([271, 313, 405, 484], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 0.09601952880620956
bi 1 loss 0.1381184309720993
bi 2 loss 0.14814171195030212
bi 3 loss 0.17325395345687866
Layer  2  loss:  0.1335366815328598 0.0 7.945552349090576
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([325, 264, 405, 514], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.08474817126989365
bi 1 loss 0.16833354532718658
bi 2 loss 0.13520318269729614
bi 3 loss 0.149642214179039
Layer  3  loss:  0.1628340631723404 0.0 8.542616844177246
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([325, 264, 389, 514], device='cuda:0') tensor(389, device='cuda:0')
bi 0 loss 0.07973626255989075
bi 1 loss 0.20927533507347107
bi 2 loss 0.14575468003749847
bi 3 loss 0.21897076070308685
Layer  4  loss:  0.14976856112480164 0.0 8.049764633178711
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([325, 278, 405, 484], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 0.11437965929508209
bi 1 loss 0.09891553968191147
bi 2 loss 0.17366397380828857
bi 3 loss 0.17535686492919922
Layer  5  loss:  0.14176449179649353 0.0 11.06454849243164
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([325, 297, 389, 484], device='cuda:0') tensor(389, device='cuda:0')
bi 0 loss 0.09423273056745529
bi 1 loss 0.13112923502922058
bi 2 loss 0.1597464382648468
bi 3 loss 0.16217392683029175
Layer  6  loss:  0.13047996163368225 0.0 12.05203914642334
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([325, 294, 389, 514], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.12878751754760742
bi 1 loss 0.07380882650613785
bi 2 loss 0.09653035551309586
bi 3 loss 0.19853602349758148
Epoch 0: :   3%|▎         | 15387/600000 [02:41<1:42:07, v_num=12, reduced_train_loss=1.240, global_step=15385.0, consumed_samples=61544.0, train_step_timing in s=0.428]Epoch 0: :   3%|▎         | 15387/600000 [02:41<1:42:07, v_num=12, reduced_train_loss=1.150, global_step=15386.0, consumed_samples=61548.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  0.2802606225013733 torch.Size([738, 4]) 12.973526954650879 0.0
Max loss timestep torch.Size([738, 4]) tensor([416, 280, 594, 472], device='cuda:0') tensor(472, device='cuda:0')
bi 0 loss 0.11665651947259903
speech mask sum tensor(414, device='cuda:0') loss mask sum tensor(414, device='cuda:0')
bi 1 loss 0.08254927396774292
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 2 loss 0.5908732414245605
speech mask sum tensor(474, device='cuda:0') loss mask sum tensor(474, device='cuda:0')
bi 3 loss 0.1640900820493698
speech mask sum tensor(395, device='cuda:0') loss mask sum tensor(395, device='cuda:0')
logits torch.Size([738, 4, 257024]) labels torch.Size([738, 4]) 0 257023
Layer  0  loss:  0.35059165954589844 0.0 18.233078002929688
logits torch.Size([738, 4, 1024]) labels torch.Size([738, 4]) 0 1023
Curr loss timestep torch.Size([738, 4]) tensor([536, 291, 717, 556], device='cuda:0') tensor(717, device='cuda:0')
bi 0 loss 0.16246595978736877
bi 1 loss 0.0980631560087204
bi 2 loss 0.7183077931404114
bi 3 loss 0.21519020199775696
Layer  1  loss:  0.3990378975868225 0.0 11.223553657531738
logits torch.Size([738, 4, 1024]) labels torch.Size([738, 4]) 0 1023
Curr loss timestep torch.Size([738, 4]) tensor([538, 289, 449, 557], device='cuda:0') tensor(449, device='cuda:0')
bi 0 loss 0.17104637622833252
bi 1 loss 0.09559466689825058
bi 2 loss 0.8318884968757629
bi 3 loss 0.24917124211788177
Layer  2  loss:  0.4010848104953766 0.0 18.609859466552734
logits torch.Size([738, 4, 1024]) labels torch.Size([738, 4]) 0 1022
Curr loss timestep torch.Size([738, 4]) tensor([416, 282, 689, 556], device='cuda:0') tensor(689, device='cuda:0')
bi 0 loss 0.18991826474666595
bi 1 loss 0.04722598195075989
bi 2 loss 0.8454258441925049
bi 3 loss 0.2414931356906891
Layer  3  loss:  0.3888002038002014 0.0 13.146281242370605
logits torch.Size([738, 4, 1024]) labels torch.Size([738, 4]) 0 1022
Curr loss timestep torch.Size([738, 4]) tensor([416, 231, 578, 556], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.21829433739185333
bi 1 loss 0.06427375227212906
bi 2 loss 0.7543624639511108
bi 3 loss 0.26850250363349915
Layer  4  loss:  0.4383374750614166 0.0 16.384910583496094
logits torch.Size([738, 4, 1024]) labels torch.Size([738, 4]) 0 1023
Curr loss timestep torch.Size([738, 4]) tensor([416, 258, 602, 556], device='cuda:0') tensor(602, device='cuda:0')
bi 0 loss 0.20898853242397308
bi 1 loss 0.09991820901632309
bi 2 loss 0.904543936252594
bi 3 loss 0.2649194598197937
Layer  5  loss:  0.3919832408428192 0.0 16.12076759338379
logits torch.Size([738, 4, 1024]) labels torch.Size([738, 4]) 0 1022
Curr loss timestep torch.Size([738, 4]) tensor([530, 290, 594, 557], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.21371793746948242
bi 1 loss 0.05732816830277443
bi 2 loss 0.7870859503746033
bi 3 loss 0.24872884154319763
Layer  6  loss:  0.41955187916755676 0.0 16.30876350402832
logits torch.Size([738, 4, 1024]) labels torch.Size([738, 4]) 0 1023
Curr loss timestep torch.Size([738, 4]) tensor([416, 289, 718, 556], device='cuda:0') tensor(718, device='cuda:0')
bi 0 loss 0.18907813727855682
bi 1 loss 0.08987375348806381
bi 2 loss 0.8670340776443481
bi 3 loss 0.2660199999809265
Epoch 0: :   3%|▎         | 15388/600000 [02:41<1:42:27, v_num=12, reduced_train_loss=1.150, global_step=15386.0, consumed_samples=61548.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15388/600000 [02:41<1:42:27, v_num=12, reduced_train_loss=3.070, global_step=15387.0, consumed_samples=61552.0, train_step_timing in s=0.498]loss mask original None

First layer loss:  0.07086095958948135 torch.Size([514, 4]) 4.035292148590088 0.0
Max loss timestep torch.Size([514, 4]) tensor([ 88, 265, 321, 125], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.022634921595454216
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 1 loss 0.05663963779807091
speech mask sum tensor(167, device='cuda:0') loss mask sum tensor(167, device='cuda:0')
bi 2 loss 0.1255740225315094
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 3 loss 0.035472266376018524
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
logits torch.Size([514, 4, 257024]) labels torch.Size([514, 4]) 0 257022
Layer  0  loss:  0.0863460898399353 0.0 5.709229946136475
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([154, 308, 288, 119], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.02835904434323311
bi 1 loss 0.055787742137908936
bi 2 loss 0.1615094393491745
bi 3 loss 0.04172573983669281
Layer  1  loss:  0.07028734683990479 0.0 8.437856674194336
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1022
Curr loss timestep torch.Size([514, 4]) tensor([ 56, 168, 289, 189], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.020996885374188423
bi 1 loss 0.042879048734903336
bi 2 loss 0.13440048694610596
bi 3 loss 0.03341043367981911
Layer  2  loss:  0.10499241203069687 0.0 11.813004493713379
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1022
Curr loss timestep torch.Size([514, 4]) tensor([ 90, 308, 289, 217], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.02505982480943203
bi 1 loss 0.06369931250810623
bi 2 loss 0.20524169504642487
bi 3 loss 0.048172250390052795
Layer  3  loss:  0.10964587330818176 0.0 8.150330543518066
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1022
Curr loss timestep torch.Size([514, 4]) tensor([ 61, 242, 288, 133], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.012777459807693958
bi 1 loss 0.06216657906770706
bi 2 loss 0.22959905862808228
bi 3 loss 0.040772877633571625
Layer  4  loss:  0.10565365850925446 0.0 13.152986526489258
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1023
Curr loss timestep torch.Size([514, 4]) tensor([ 66, 282, 289, 165], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.018595654517412186
bi 1 loss 0.04796559736132622
bi 2 loss 0.21923387050628662
bi 3 loss 0.049129221588373184
Layer  5  loss:  0.10362382978200912 0.0 16.978017807006836
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1021
Curr loss timestep torch.Size([514, 4]) tensor([119, 207, 289, 206], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.011675197631120682
bi 1 loss 0.04565192759037018
bi 2 loss 0.22137273848056793
bi 3 loss 0.044627539813518524
Layer  6  loss:  0.09419340640306473 0.0 10.964190483093262
logits torch.Size([514, 4, 1024]) labels torch.Size([514, 4]) 0 1022
Curr loss timestep torch.Size([514, 4]) tensor([ 44, 256, 288, 200], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.015534808859229088
bi 1 loss 0.04072292521595955
bi 2 loss 0.1853192299604416
bi 3 loss 0.06329742074012756
Epoch 0: :   3%|▎         | 15389/600000 [02:42<1:42:42, v_num=12, reduced_train_loss=3.070, global_step=15387.0, consumed_samples=61552.0, train_step_timing in s=0.498]Epoch 0: :   3%|▎         | 15389/600000 [02:42<1:42:42, v_num=12, reduced_train_loss=0.746, global_step=15388.0, consumed_samples=61556.0, train_step_timing in s=0.358]loss mask original None

First layer loss:  0.08741571754217148 torch.Size([658, 4]) 10.94225788116455 0.0
Max loss timestep torch.Size([658, 4]) tensor([474, 156, 357, 220], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.11893574893474579
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 1 loss 0.02922932803630829
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 2 loss 0.11440331488847733
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 3 loss 0.028395814821124077
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
logits torch.Size([658, 4, 257024]) labels torch.Size([658, 4]) 0 257023
Layer  0  loss:  0.1219475269317627 0.0 9.878124237060547
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([395, 198, 541, 218], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.17075861990451813
bi 1 loss 0.046742506325244904
bi 2 loss 0.15930971503257751
bi 3 loss 0.03133354336023331
Layer  1  loss:  0.1348085105419159 0.0 11.107580184936523
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([461, 130, 541,  62], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.20903560519218445
bi 1 loss 0.033104464411735535
bi 2 loss 0.1631607711315155
bi 3 loss 0.05047266557812691
Layer  2  loss:  0.12538576126098633 0.0 12.830199241638184
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1023
Curr loss timestep torch.Size([658, 4]) tensor([395, 204, 541,  59], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.20598997175693512
bi 1 loss 0.029009968042373657
bi 2 loss 0.15417322516441345
bi 3 loss 0.02988094463944435
Layer  3  loss:  0.1424293965101242 0.0 13.62818431854248
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1017
Curr loss timestep torch.Size([658, 4]) tensor([461, 125, 541, 201], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.18776194751262665
bi 1 loss 0.034627869725227356
bi 2 loss 0.1960984468460083
bi 3 loss 0.03985287621617317
Layer  4  loss:  0.13129675388336182 0.0 13.787642478942871
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1018
Curr loss timestep torch.Size([658, 4]) tensor([461, 215, 541,  79], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.14434826374053955
bi 1 loss 0.03146997466683388
bi 2 loss 0.18694588541984558
bi 3 loss 0.05594499409198761
Layer  5  loss:  0.13710105419158936 0.0 10.722644805908203
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1017
Curr loss timestep torch.Size([658, 4]) tensor([461, 167, 357,  71], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.2123156040906906
bi 1 loss 0.036425042897462845
bi 2 loss 0.16821715235710144
bi 3 loss 0.0451539121568203
Layer  6  loss:  0.13771043717861176 0.0 12.583861351013184
logits torch.Size([658, 4, 1024]) labels torch.Size([658, 4]) 0 1022
Curr loss timestep torch.Size([658, 4]) tensor([461, 200, 541, 124], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.17173048853874207
bi 1 loss 0.05828174948692322
bi 2 loss 0.18683196604251862
bi 3 loss 0.04096730053424835
Epoch 0: :   3%|▎         | 15390/600000 [02:42<1:43:00, v_num=12, reduced_train_loss=0.746, global_step=15388.0, consumed_samples=61556.0, train_step_timing in s=0.358]Epoch 0: :   3%|▎         | 15390/600000 [02:42<1:43:00, v_num=12, reduced_train_loss=1.020, global_step=15389.0, consumed_samples=61560.0, train_step_timing in s=0.451]loss mask original None

First layer loss:  0.08250590413808823 torch.Size([446, 4]) 11.388124465942383 0.0
Max loss timestep torch.Size([446, 4]) tensor([189, 347, 396, 344], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.04175515100359917
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 1 loss 0.13136276602745056
speech mask sum tensor(350, device='cuda:0') loss mask sum tensor(350, device='cuda:0')
bi 2 loss 0.05002009496092796
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
bi 3 loss 0.06291805952787399
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
logits torch.Size([446, 4, 257024]) labels torch.Size([446, 4]) 0 257023
Layer  0  loss:  0.11713860929012299 0.0 7.511460781097412
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1023
Curr loss timestep torch.Size([446, 4]) tensor([138, 347, 396, 268], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.040157679468393326
bi 1 loss 0.1259693056344986
bi 2 loss 0.1067136824131012
bi 3 loss 0.15195754170417786
Layer  1  loss:  0.09869877994060516 0.0 7.511314392089844
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1022
Curr loss timestep torch.Size([446, 4]) tensor([147, 347, 264, 272], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.09045184403657913
bi 1 loss 0.11164774000644684
bi 2 loss 0.08636884391307831
bi 3 loss 0.09744003415107727
Layer  2  loss:  0.11702878773212433 0.0 12.097764015197754
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1022
Curr loss timestep torch.Size([446, 4]) tensor([146, 347, 264, 341], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.03536628931760788
bi 1 loss 0.12936638295650482
bi 2 loss 0.1053730696439743
bi 3 loss 0.14973920583724976
Layer  3  loss:  0.08872046321630478 0.0 11.454739570617676
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1023
Curr loss timestep torch.Size([446, 4]) tensor([145, 347, 264, 341], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.026974055916070938
bi 1 loss 0.08324310183525085
bi 2 loss 0.09721094369888306
bi 3 loss 0.11483783274888992
Layer  4  loss:  0.08671459555625916 0.0 8.224493026733398
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1023
Curr loss timestep torch.Size([446, 4]) tensor([161, 347, 264, 341], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.03413193300366402
bi 1 loss 0.10164091736078262
bi 2 loss 0.07093007117509842
bi 3 loss 0.10728819668292999
Layer  5  loss:  0.1124575063586235 0.0 9.487648010253906
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1023
Curr loss timestep torch.Size([446, 4]) tensor([206, 347, 264, 338], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.059643201529979706
bi 1 loss 0.10310675203800201
bi 2 loss 0.09224911779165268
bi 3 loss 0.1804627925157547
Layer  6  loss:  0.09997984766960144 0.0 9.41648006439209
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1022
Curr loss timestep torch.Size([446, 4]) tensor([173, 347, 396, 264], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.03597820922732353
bi 1 loss 0.09481262415647507
bi 2 loss 0.08430828899145126
bi 3 loss 0.15980377793312073
Epoch 0: :   3%|▎         | 15391/600000 [02:43<1:43:13, v_num=12, reduced_train_loss=1.020, global_step=15389.0, consumed_samples=61560.0, train_step_timing in s=0.451]Epoch 0: :   3%|▎         | 15391/600000 [02:43<1:43:13, v_num=12, reduced_train_loss=0.803, global_step=15390.0, consumed_samples=61564.0, train_step_timing in s=0.323]loss mask original None

First layer loss:  0.2207329124212265 torch.Size([643, 4]) 17.25829315185547 0.0
Max loss timestep torch.Size([643, 4]) tensor([493, 226, 264, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.32213324308395386
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 1 loss 0.09735807776451111
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 2 loss 0.08851876109838486
speech mask sum tensor(201, device='cuda:0') loss mask sum tensor(201, device='cuda:0')
bi 3 loss 0.24257104098796844
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
logits torch.Size([643, 4, 257024]) labels torch.Size([643, 4]) 0 257023
Layer  0  loss:  0.2725410759449005 0.0 11.155405044555664
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1023
Curr loss timestep torch.Size([643, 4]) tensor([516, 178, 264, 393], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.36302781105041504
bi 1 loss 0.10629409551620483
bi 2 loss 0.09304646402597427
bi 3 loss 0.33226051926612854
Layer  1  loss:  0.28214314579963684 0.0 18.76388168334961
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1022
Curr loss timestep torch.Size([643, 4]) tensor([297, 220, 264, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.353874146938324
bi 1 loss 0.13872799277305603
bi 2 loss 0.06624153256416321
bi 3 loss 0.3637385070323944
Layer  2  loss:  0.2959861755371094 0.0 15.285629272460938
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1023
Curr loss timestep torch.Size([643, 4]) tensor([517, 264, 264, 390], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.38726964592933655
bi 1 loss 0.11603955179452896
bi 2 loss 0.10077035427093506
bi 3 loss 0.36531224846839905
Layer  3  loss:  0.27235543727874756 0.0 13.173287391662598
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1023
Curr loss timestep torch.Size([643, 4]) tensor([517, 262, 264, 391], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.3748667240142822
bi 1 loss 0.11249320954084396
bi 2 loss 0.08389456570148468
bi 3 loss 0.3265523612499237
Layer  4  loss:  0.2954714298248291 0.0 11.66781234741211
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1022
Curr loss timestep torch.Size([643, 4]) tensor([516, 264, 264, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.3722667098045349
bi 1 loss 0.0690741240978241
bi 2 loss 0.10996340215206146
bi 3 loss 0.3816075026988983
Layer  5  loss:  0.28789809346199036 0.0 12.127455711364746
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1023
Curr loss timestep torch.Size([643, 4]) tensor([517, 264, 264, 549], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.3256613612174988
bi 1 loss 0.15757465362548828
bi 2 loss 0.11565569788217545
bi 3 loss 0.3695058524608612
Layer  6  loss:  0.30094194412231445 0.0 14.156163215637207
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1023
Curr loss timestep torch.Size([643, 4]) tensor([516, 263, 264, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.3996433615684509
bi 1 loss 0.06964293867349625
bi 2 loss 0.09946927428245544
bi 3 loss 0.3809928894042969
Epoch 0: :   3%|▎         | 15392/600000 [02:43<1:43:31, v_num=12, reduced_train_loss=0.803, global_step=15390.0, consumed_samples=61564.0, train_step_timing in s=0.323]Epoch 0: :   3%|▎         | 15392/600000 [02:43<1:43:31, v_num=12, reduced_train_loss=2.230, global_step=15391.0, consumed_samples=61568.0, train_step_timing in s=0.440]loss mask original None

First layer loss:  0.02334747649729252 torch.Size([354, 4]) 0.33138909935951233 0.0
Max loss timestep torch.Size([354, 4]) tensor([308,  96, 286, 105], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.02310367301106453
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
bi 1 loss 0.021355748176574707
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
bi 2 loss 0.026435550302267075
speech mask sum tensor(249, device='cuda:0') loss mask sum tensor(249, device='cuda:0')
bi 3 loss 0.021911267191171646
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
logits torch.Size([354, 4, 257024]) labels torch.Size([354, 4]) 0 257022
Layer  0  loss:  0.027051042765378952 0.0 0.9833695888519287
logits torch.Size([354, 4, 1024]) labels torch.Size([354, 4]) 0 1023
Curr loss timestep torch.Size([354, 4]) tensor([274, 126, 323, 303], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.028615396469831467
bi 1 loss 0.02035273239016533
bi 2 loss 0.03294169902801514
bi 3 loss 0.025218641385436058
Layer  1  loss:  0.02299913391470909 0.0 0.7300141453742981
logits torch.Size([354, 4, 1024]) labels torch.Size([354, 4]) 0 1022
Curr loss timestep torch.Size([354, 4]) tensor([275, 134, 298, 131], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.029040049761533737
bi 1 loss 0.01810184307396412
bi 2 loss 0.021620947867631912
bi 3 loss 0.024445513263344765
Layer  2  loss:  0.02326512336730957 0.0 0.48310211300849915
logits torch.Size([354, 4, 1024]) labels torch.Size([354, 4]) 0 1023
Curr loss timestep torch.Size([354, 4]) tensor([228, 118, 326, 158], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 0.020769214257597923
bi 1 loss 0.019353438168764114
bi 2 loss 0.026593118906021118
bi 3 loss 0.024123365059494972
Layer  3  loss:  0.022890465334057808 0.0 0.740126371383667
logits torch.Size([354, 4, 1024]) labels torch.Size([354, 4]) 0 1018
Curr loss timestep torch.Size([354, 4]) tensor([316, 122, 167, 276], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.027561144903302193
bi 1 loss 0.021510664373636246
bi 2 loss 0.02094128541648388
bi 3 loss 0.02319510467350483
Layer  4  loss:  0.025735246017575264 0.0 2.818692684173584
logits torch.Size([354, 4, 1024]) labels torch.Size([354, 4]) 0 1022
Curr loss timestep torch.Size([354, 4]) tensor([316, 115, 323, 305], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.042674675583839417
bi 1 loss 0.016490750014781952
bi 2 loss 0.026888342574238777
bi 3 loss 0.02193894237279892
Layer  5  loss:  0.025311853736639023 0.0 2.940094470977783
logits torch.Size([354, 4, 1024]) labels torch.Size([354, 4]) 0 1023
Curr loss timestep torch.Size([354, 4]) tensor([229, 169, 323, 240], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.023364610970020294
bi 1 loss 0.013504545204341412
bi 2 loss 0.040944669395685196
bi 3 loss 0.019607117399573326
Layer  6  loss:  0.02034967951476574 0.0 0.4334065616130829
logits torch.Size([354, 4, 1024]) labels torch.Size([354, 4]) 0 1023
Curr loss timestep torch.Size([354, 4]) tensor([305, 115, 314, 189], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.022780301049351692
bi 1 loss 0.01663774810731411
bi 2 loss 0.022818587720394135
bi 3 loss 0.019254645332694054
Epoch 0: :   3%|▎         | 15393/600000 [02:43<1:43:42, v_num=12, reduced_train_loss=2.230, global_step=15391.0, consumed_samples=61568.0, train_step_timing in s=0.440]Epoch 0: :   3%|▎         | 15393/600000 [02:43<1:43:42, v_num=12, reduced_train_loss=0.191, global_step=15392.0, consumed_samples=61572.0, train_step_timing in s=0.276]loss mask original None

First layer loss:  0.06633058190345764 torch.Size([518, 4]) 5.102313041687012 0.0
Max loss timestep torch.Size([518, 4]) tensor([237, 461, 136, 164], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.03148697689175606
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 1 loss 0.09378658980131149
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
bi 2 loss 0.022757787257432938
speech mask sum tensor(83, device='cuda:0') loss mask sum tensor(83, device='cuda:0')
bi 3 loss 0.03813750296831131
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
logits torch.Size([518, 4, 257024]) labels torch.Size([518, 4]) 0 257023
Layer  0  loss:  0.0583607517182827 0.0 5.772068023681641
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([240, 461,  87, 265], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.027777211740612984
bi 1 loss 0.06989765912294388
bi 2 loss 0.02430340088903904
bi 3 loss 0.06316622346639633
Layer  1  loss:  0.05420638248324394 0.0 4.273528099060059
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([232, 460, 125, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.030628856271505356
bi 1 loss 0.05451129376888275
bi 2 loss 0.02749512903392315
bi 3 loss 0.07987097650766373
Layer  2  loss:  0.07095272839069366 0.0 9.36776351928711
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1022
Curr loss timestep torch.Size([518, 4]) tensor([234, 461, 105, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.04335677996277809
bi 1 loss 0.07440251111984253
bi 2 loss 0.029833490028977394
bi 3 loss 0.09838077425956726
Layer  3  loss:  0.07138094305992126 0.0 9.306471824645996
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1022
Curr loss timestep torch.Size([518, 4]) tensor([231, 461,  92, 264], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.03385980427265167
bi 1 loss 0.07230652123689651
bi 2 loss 0.019639331847429276
bi 3 loss 0.11599133908748627
Layer  4  loss:  0.0748622789978981 0.0 12.781906127929688
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1022
Curr loss timestep torch.Size([518, 4]) tensor([253, 461, 139, 264], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.030223852023482323
bi 1 loss 0.08360374718904495
bi 2 loss 0.041537050157785416
bi 3 loss 0.0936901643872261
Layer  5  loss:  0.058716267347335815 0.0 9.807944297790527
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1019
Curr loss timestep torch.Size([518, 4]) tensor([213, 461,  89, 264], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.01817018911242485
bi 1 loss 0.07344324141740799
bi 2 loss 0.011947314254939556
bi 3 loss 0.06737865507602692
Layer  6  loss:  0.07442373782396317 0.0 11.813218116760254
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([245, 461, 111, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.043289508670568466
bi 1 loss 0.07196228206157684
bi 2 loss 0.01888297311961651
bi 3 loss 0.12627141177654266
Epoch 0: :   3%|▎         | 15394/600000 [02:44<1:43:57, v_num=12, reduced_train_loss=0.191, global_step=15392.0, consumed_samples=61572.0, train_step_timing in s=0.276]Epoch 0: :   3%|▎         | 15394/600000 [02:44<1:43:57, v_num=12, reduced_train_loss=0.529, global_step=15393.0, consumed_samples=61576.0, train_step_timing in s=0.358]loss mask original None

First layer loss:  0.06193142011761665 torch.Size([429, 4]) 4.997879981994629 0.0
Max loss timestep torch.Size([429, 4]) tensor([184, 193, 108, 375], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 0.05846184492111206
speech mask sum tensor(282, device='cuda:0') loss mask sum tensor(282, device='cuda:0')
bi 1 loss 0.07944914698600769
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 2 loss 0.037204112857580185
speech mask sum tensor(63, device='cuda:0') loss mask sum tensor(63, device='cuda:0')
bi 3 loss 0.06977793574333191
speech mask sum tensor(129, device='cuda:0') loss mask sum tensor(129, device='cuda:0')
logits torch.Size([429, 4, 257024]) labels torch.Size([429, 4]) 0 257022
Layer  0  loss:  0.05653269216418266 0.0 2.410637855529785
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1023
Curr loss timestep torch.Size([429, 4]) tensor([383, 216,  81, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.055451709777116776
bi 1 loss 0.03512559458613396
bi 2 loss 0.019098885357379913
bi 3 loss 0.09161471575498581
Layer  1  loss:  0.043830785900354385 0.0 1.1449178457260132
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([294, 202, 100, 323], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.051142022013664246
bi 1 loss 0.016504259780049324
bi 2 loss 0.03870772570371628
bi 3 loss 0.048779554665088654
Layer  2  loss:  0.044490937143564224 0.0 1.2455919981002808
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1023
Curr loss timestep torch.Size([429, 4]) tensor([279, 196,  91, 319], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 0.0475958026945591
bi 1 loss 0.02951500378549099
bi 2 loss 0.028923600912094116
bi 3 loss 0.055406276136636734
Layer  3  loss:  0.04914131015539169 0.0 1.1546440124511719
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1019
Curr loss timestep torch.Size([429, 4]) tensor([188, 223,  84, 318], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.04867810010910034
bi 1 loss 0.02495134063065052
bi 2 loss 0.03132235258817673
bi 3 loss 0.0751703530550003
Layer  4  loss:  0.03872654214501381 0.0 0.6390491127967834
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1020
Curr loss timestep torch.Size([429, 4]) tensor([310, 206,  81, 286], device='cuda:0') tensor(81, device='cuda:0')
bi 0 loss 0.04120626673102379
bi 1 loss 0.02382674440741539
bi 2 loss 0.04522189870476723
bi 3 loss 0.040182311087846756
Layer  5  loss:  0.03907894715666771 0.0 0.9829418659210205
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1023
Curr loss timestep torch.Size([429, 4]) tensor([391, 242,  81, 323], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.03800210356712341
bi 1 loss 0.029594572260975838
bi 2 loss 0.025807442143559456
bi 3 loss 0.054310835897922516
Layer  6  loss:  0.05147875100374222 0.0 2.0357022285461426
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([315, 198, 108, 351], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.053161147981882095
bi 1 loss 0.01580127887427807
bi 2 loss 0.02452603541314602
bi 3 loss 0.08502547442913055
Epoch 0: :   3%|▎         | 15395/600000 [02:44<1:44:10, v_num=12, reduced_train_loss=0.529, global_step=15393.0, consumed_samples=61576.0, train_step_timing in s=0.358]Epoch 0: :   3%|▎         | 15395/600000 [02:44<1:44:10, v_num=12, reduced_train_loss=0.385, global_step=15394.0, consumed_samples=61580.0, train_step_timing in s=0.314]loss mask original None

First layer loss:  0.12985803186893463 torch.Size([585, 4]) 9.818706512451172 0.0
Max loss timestep torch.Size([585, 4]) tensor([268, 191, 435, 411], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.121480792760849
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 1 loss 0.018671225756406784
speech mask sum tensor(159, device='cuda:0') loss mask sum tensor(159, device='cuda:0')
bi 2 loss 0.18831153213977814
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 3 loss 0.1288181096315384
speech mask sum tensor(434, device='cuda:0') loss mask sum tensor(434, device='cuda:0')
logits torch.Size([585, 4, 257024]) labels torch.Size([585, 4]) 0 257022
Layer  0  loss:  0.15415868163108826 0.0 8.808928489685059
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([433, 158, 435, 396], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.11859700828790665
bi 1 loss 0.031887102872133255
bi 2 loss 0.19578492641448975
bi 3 loss 0.18768595159053802
Layer  1  loss:  0.15475906431674957 0.0 9.512459754943848
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1021
Curr loss timestep torch.Size([585, 4]) tensor([267, 195, 434, 411], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.07069408893585205
bi 1 loss 0.037574272602796555
bi 2 loss 0.2101588398218155
bi 3 loss 0.20563344657421112
Layer  2  loss:  0.1502397656440735 0.0 13.894464492797852
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([433, 133, 434, 517], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.11966477334499359
bi 1 loss 0.02466086857020855
bi 2 loss 0.19876828789710999
bi 3 loss 0.17631442844867706
Layer  3  loss:  0.1700735092163086 0.0 16.187673568725586
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1021
Curr loss timestep torch.Size([585, 4]) tensor([431, 204, 436, 411], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.11631503701210022
bi 1 loss 0.035616062581539154
bi 2 loss 0.2147878259420395
bi 3 loss 0.2169443964958191
Layer  4  loss:  0.15251833200454712 0.0 13.37588119506836
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([268, 173, 434, 517], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.10236668586730957
bi 1 loss 0.027417585253715515
bi 2 loss 0.19207938015460968
bi 3 loss 0.19785311818122864
Layer  5  loss:  0.17515341937541962 0.0 10.92786693572998
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([269, 163, 425, 411], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.06943923234939575
bi 1 loss 0.03221161663532257
bi 2 loss 0.2642570734024048
bi 3 loss 0.2218794971704483
Layer  6  loss:  0.15098361670970917 0.0 12.688634872436523
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([431, 179, 434, 517], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.12282873690128326
bi 1 loss 0.03471599519252777
bi 2 loss 0.20949260890483856
bi 3 loss 0.16411009430885315
Epoch 0: :   3%|▎         | 15396/600000 [02:45<1:44:26, v_num=12, reduced_train_loss=0.385, global_step=15394.0, consumed_samples=61580.0, train_step_timing in s=0.314]Epoch 0: :   3%|▎         | 15396/600000 [02:45<1:44:26, v_num=12, reduced_train_loss=1.240, global_step=15395.0, consumed_samples=61584.0, train_step_timing in s=0.404]loss mask original None

First layer loss:  0.06615886092185974 torch.Size([334, 4]) 8.818453788757324 0.0
Max loss timestep torch.Size([334, 4]) tensor([173, 274, 173,  38], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.0254297386854887
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 1 loss 0.10914172977209091
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
bi 2 loss 0.042403027415275574
speech mask sum tensor(129, device='cuda:0') loss mask sum tensor(129, device='cuda:0')
bi 3 loss 0.031245870515704155
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
logits torch.Size([334, 4, 257024]) labels torch.Size([334, 4]) 0 257023
Layer  0  loss:  0.07566224783658981 0.0 12.800736427307129
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1023
Curr loss timestep torch.Size([334, 4]) tensor([172, 275, 146,  56], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.050851400941610336
bi 1 loss 0.1155281513929367
bi 2 loss 0.04345698654651642
bi 3 loss 0.03130942955613136
Layer  1  loss:  0.060712993144989014 0.0 9.911454200744629
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1022
Curr loss timestep torch.Size([334, 4]) tensor([140, 274, 121,  47], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.03460770472884178
bi 1 loss 0.09456829726696014
bi 2 loss 0.03732011839747429
bi 3 loss 0.027682200074195862
Layer  2  loss:  0.07350043952465057 0.0 6.75819730758667
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1023
Curr loss timestep torch.Size([334, 4]) tensor([124, 275, 138,  43], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.03650318458676338
bi 1 loss 0.1300707310438156
bi 2 loss 0.026775991544127464
bi 3 loss 0.01791430078446865
Layer  3  loss:  0.08954532444477081 0.0 13.734865188598633
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1020
Curr loss timestep torch.Size([334, 4]) tensor([219, 274, 174,  59], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.03309980034828186
bi 1 loss 0.16306571662425995
bi 2 loss 0.03493385761976242
bi 3 loss 0.026078008115291595
Layer  4  loss:  0.08164732903242111 0.0 13.066448211669922
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1022
Curr loss timestep torch.Size([334, 4]) tensor([117, 274, 146,  60], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.037473808974027634
bi 1 loss 0.14670008420944214
bi 2 loss 0.032138608396053314
bi 3 loss 0.012325211428105831
Layer  5  loss:  0.08169196546077728 0.0 12.686713218688965
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1017
Curr loss timestep torch.Size([334, 4]) tensor([193, 276, 171,  44], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.019885040819644928
bi 1 loss 0.1549229621887207
bi 2 loss 0.03414223715662956
bi 3 loss 0.017846666276454926
Layer  6  loss:  0.10021872818470001 0.0 13.766131401062012
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1023
Curr loss timestep torch.Size([334, 4]) tensor([160, 274, 102,  46], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.04505442455410957
bi 1 loss 0.17686158418655396
bi 2 loss 0.03865760937333107
bi 3 loss 0.034749921411275864
Epoch 0: :   3%|▎         | 15397/600000 [02:45<1:44:37, v_num=12, reduced_train_loss=1.240, global_step=15395.0, consumed_samples=61584.0, train_step_timing in s=0.404]Epoch 0: :   3%|▎         | 15397/600000 [02:45<1:44:37, v_num=12, reduced_train_loss=0.629, global_step=15396.0, consumed_samples=61588.0, train_step_timing in s=0.270]loss mask original None

First layer loss:  0.21394884586334229 torch.Size([691, 4]) 13.886460304260254 0.0
Max loss timestep torch.Size([691, 4]) tensor([381, 154, 519, 619], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.12816107273101807
speech mask sum tensor(248, device='cuda:0') loss mask sum tensor(248, device='cuda:0')
bi 1 loss 0.029749080538749695
speech mask sum tensor(122, device='cuda:0') loss mask sum tensor(122, device='cuda:0')
bi 2 loss 0.25172847509384155
speech mask sum tensor(500, device='cuda:0') loss mask sum tensor(500, device='cuda:0')
bi 3 loss 0.3050035834312439
speech mask sum tensor(273, device='cuda:0') loss mask sum tensor(273, device='cuda:0')
logits torch.Size([691, 4, 257024]) labels torch.Size([691, 4]) 0 257022
Layer  0  loss:  0.29962751269340515 0.0 16.349449157714844
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([287, 121, 331, 626], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.1895698755979538
bi 1 loss 0.03531016781926155
bi 2 loss 0.3008938729763031
bi 3 loss 0.515407145023346
Layer  1  loss:  0.2979828417301178 0.0 13.605565071105957
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([329,  84, 331, 621], device='cuda:0') tensor(621, device='cuda:0')
bi 0 loss 0.12510517239570618
bi 1 loss 0.12892583012580872
bi 2 loss 0.29432252049446106
bi 3 loss 0.5372825264930725
Layer  2  loss:  0.3266603350639343 0.0 13.265931129455566
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([285, 112, 333, 497], device='cuda:0') tensor(443, device='cuda:0')
bi 0 loss 0.1521933674812317
bi 1 loss 0.049744464457035065
bi 2 loss 0.37647345662117004
bi 3 loss 0.5176676511764526
Layer  3  loss:  0.310595840215683 0.0 20.08730697631836
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([381, 139, 442, 621], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.12867583334445953
bi 1 loss 0.04032273218035698
bi 2 loss 0.35184723138809204
bi 3 loss 0.5210859775543213
Layer  4  loss:  0.3484959006309509 0.0 16.805767059326172
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([268,  99, 443, 626], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.16301403939723969
bi 1 loss 0.04741893708705902
bi 2 loss 0.33345410227775574
bi 3 loss 0.6790885329246521
Layer  5  loss:  0.3598293364048004 0.0 16.14578628540039
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1021
Curr loss timestep torch.Size([691, 4]) tensor([381,  90, 519, 621], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.208225280046463
bi 1 loss 0.053306374698877335
bi 2 loss 0.38127729296684265
bi 3 loss 0.5952494144439697
Layer  6  loss:  0.3437911570072174 0.0 18.5795955657959
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([381, 118, 442, 494], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.18048490583896637
bi 1 loss 0.03109888732433319
bi 2 loss 0.3667711615562439
bi 3 loss 0.5897927284240723
Epoch 0: :   3%|▎         | 15398/600000 [02:45<1:44:56, v_num=12, reduced_train_loss=0.629, global_step=15396.0, consumed_samples=61588.0, train_step_timing in s=0.270]Epoch 0: :   3%|▎         | 15398/600000 [02:45<1:44:56, v_num=12, reduced_train_loss=2.500, global_step=15397.0, consumed_samples=61592.0, train_step_timing in s=0.479]loss mask original None

First layer loss:  3.4957568645477295 torch.Size([360, 4]) 10.046182632446289 0.0
Max loss timestep torch.Size([360, 4]) tensor([107, 219, 125,  45], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 3.7608301639556885
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
bi 1 loss 3.5725812911987305
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 2 loss 3.414348602294922
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 3 loss 3.097184181213379
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
logits torch.Size([360, 4, 257024]) labels torch.Size([360, 4]) 0 257019
Layer  0  loss:  4.009127140045166 0.0 11.687478065490723
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1023
Curr loss timestep torch.Size([360, 4]) tensor([157, 323, 174,  94], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 4.31195592880249
bi 1 loss 4.044722080230713
bi 2 loss 3.924819231033325
bi 3 loss 3.626967668533325
Layer  1  loss:  4.286630153656006 0.0 10.279916763305664
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1023
Curr loss timestep torch.Size([360, 4]) tensor([120, 277, 131,  78], device='cuda:0') tensor(120, device='cuda:0')
bi 0 loss 4.494162559509277
bi 1 loss 4.546286582946777
bi 2 loss 4.022967338562012
bi 3 loss 3.927361249923706
Layer  2  loss:  4.535294532775879 0.0 10.171789169311523
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1022
Curr loss timestep torch.Size([360, 4]) tensor([ 89, 335, 222, 106], device='cuda:0') tensor(120, device='cuda:0')
bi 0 loss 4.809632778167725
bi 1 loss 4.76391077041626
bi 2 loss 4.292051315307617
bi 3 loss 4.100863933563232
Layer  3  loss:  4.671850204467773 0.0 9.646591186523438
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1019
Curr loss timestep torch.Size([360, 4]) tensor([139, 291, 205,  70], device='cuda:0') tensor(122, device='cuda:0')
bi 0 loss 5.034914016723633
bi 1 loss 4.804303169250488
bi 2 loss 4.437117099761963
bi 3 loss 4.25341272354126
Layer  4  loss:  4.721879959106445 0.0 9.803853034973145
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1022
Curr loss timestep torch.Size([360, 4]) tensor([176, 327, 120,  62], device='cuda:0') tensor(122, device='cuda:0')
bi 0 loss 4.888698101043701
bi 1 loss 4.76904821395874
bi 2 loss 4.704770088195801
bi 3 loss 4.425346851348877
Layer  5  loss:  4.905786514282227 0.0 9.496058464050293
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1023
Curr loss timestep torch.Size([360, 4]) tensor([108, 287, 121,  49], device='cuda:0') tensor(117, device='cuda:0')
bi 0 loss 5.075198650360107
bi 1 loss 4.868600845336914
bi 2 loss 4.926747798919678
bi 3 loss 4.690282821655273
Layer  6  loss:  4.844387531280518 0.0 9.838251113891602
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1021
Curr loss timestep torch.Size([360, 4]) tensor([ 77, 296, 166,  64], device='cuda:0') tensor(122, device='cuda:0')
bi 0 loss 4.919496536254883
bi 1 loss 4.984757900238037
bi 2 loss 4.748692512512207
bi 3 loss 4.638862609863281
Epoch 0: :   3%|▎         | 15399/600000 [02:46<1:45:08, v_num=12, reduced_train_loss=2.500, global_step=15397.0, consumed_samples=61592.0, train_step_timing in s=0.479]Epoch 0: :   3%|▎         | 15399/600000 [02:46<1:45:08, v_num=12, reduced_train_loss=35.50, global_step=15398.0, consumed_samples=61596.0, train_step_timing in s=0.276]loss mask original None

First layer loss:  0.07324311882257462 torch.Size([449, 4]) 9.988445281982422 0.0
Max loss timestep torch.Size([449, 4]) tensor([302, 264, 103, 302], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.041576825082302094
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 1 loss 0.13864023983478546
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 2 loss 0.04327379912137985
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 3 loss 0.053579527884721756
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
logits torch.Size([449, 4, 257024]) labels torch.Size([449, 4]) 0 257022
Layer  0  loss:  0.0909971222281456 0.0 10.275345802307129
logits torch.Size([449, 4, 1024]) labels torch.Size([449, 4]) 0 1023
Curr loss timestep torch.Size([449, 4]) tensor([290, 263, 130, 289], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.07919415831565857
bi 1 loss 0.13696210086345673
bi 2 loss 0.0634143278002739
bi 3 loss 0.07084845751523972
Layer  1  loss:  0.10487561672925949 0.0 13.270041465759277
logits torch.Size([449, 4, 1024]) labels torch.Size([449, 4]) 0 1022
Curr loss timestep torch.Size([449, 4]) tensor([290, 264,  76, 307], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.13346125185489655
bi 1 loss 0.1548849195241928
bi 2 loss 0.04332065209746361
bi 3 loss 0.060538824647665024
Layer  2  loss:  0.09231601655483246 0.0 11.14694595336914
logits torch.Size([449, 4, 1024]) labels torch.Size([449, 4]) 0 1023
Curr loss timestep torch.Size([449, 4]) tensor([290, 263, 133, 150], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.07841076701879501
bi 1 loss 0.17605280876159668
bi 2 loss 0.04127325117588043
bi 3 loss 0.04917486011981964
Layer  3  loss:  0.08824006468057632 0.0 8.624281883239746
logits torch.Size([449, 4, 1024]) labels torch.Size([449, 4]) 0 1019
Curr loss timestep torch.Size([449, 4]) tensor([290, 263, 166, 324], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.09095027297735214
bi 1 loss 0.13644565641880035
bi 2 loss 0.06582804769277573
bi 3 loss 0.05055860057473183
Layer  4  loss:  0.10115606337785721 0.0 18.621671676635742
logits torch.Size([449, 4, 1024]) labels torch.Size([449, 4]) 0 1022
Curr loss timestep torch.Size([449, 4]) tensor([290, 263, 155, 307], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.09398388862609863
bi 1 loss 0.18073049187660217
bi 2 loss 0.03801783174276352
bi 3 loss 0.061563074588775635
Layer  5  loss:  0.08699265122413635 0.0 8.086051940917969
logits torch.Size([449, 4, 1024]) labels torch.Size([449, 4]) 0 1023
Curr loss timestep torch.Size([449, 4]) tensor([290, 263,  96,  82], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.0807901918888092
bi 1 loss 0.14480888843536377
bi 2 loss 0.03619195520877838
bi 3 loss 0.06140846386551857
Layer  6  loss:  0.11382703483104706 0.0 17.62716293334961
logits torch.Size([449, 4, 1024]) labels torch.Size([449, 4]) 0 1023
Curr loss timestep torch.Size([449, 4]) tensor([290, 264, 170, 288], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.11609981209039688
bi 1 loss 0.19120703637599945
bi 2 loss 0.04022670164704323
bi 3 loss 0.07272688299417496
Epoch 0: :   3%|▎         | 15400/600000 [02:46<1:45:21, v_num=12, reduced_train_loss=35.50, global_step=15398.0, consumed_samples=61596.0, train_step_timing in s=0.276]Epoch 0: :   3%|▎         | 15400/600000 [02:46<1:45:21, v_num=12, reduced_train_loss=0.752, global_step=15399.0, consumed_samples=61600.0, train_step_timing in s=0.324]loss mask original None

First layer loss:  3.385586738586426 torch.Size([436, 4]) 9.694738388061523 0.0
Max loss timestep torch.Size([436, 4]) tensor([ 89, 174, 372, 374], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 2.819547653198242
speech mask sum tensor(61, device='cuda:0') loss mask sum tensor(61, device='cuda:0')
bi 1 loss 3.228973627090454
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
bi 2 loss 3.6667590141296387
speech mask sum tensor(212, device='cuda:0') loss mask sum tensor(212, device='cuda:0')
bi 3 loss 3.4736733436584473
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
logits torch.Size([436, 4, 257024]) labels torch.Size([436, 4]) 0 257022
Layer  0  loss:  4.009549140930176 0.0 10.710601806640625
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([110, 298, 258, 163], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 3.4023470878601074
bi 1 loss 3.938473701477051
bi 2 loss 4.095991611480713
bi 3 loss 4.149179458618164
Layer  1  loss:  4.526832580566406 0.0 10.304049491882324
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([113, 126, 245, 228], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 3.6202166080474854
bi 1 loss 4.684460163116455
bi 2 loss 4.434921741485596
bi 3 loss 4.602235794067383
Layer  2  loss:  4.773979187011719 0.0 10.671243667602539
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([114, 333, 345, 359], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 3.930668592453003
bi 1 loss 4.735177040100098
bi 2 loss 4.922039031982422
bi 3 loss 4.882781028747559
Layer  3  loss:  4.8214216232299805 0.0 10.977169036865234
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([115, 386, 376, 275], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 3.8424062728881836
bi 1 loss 4.825493335723877
bi 2 loss 4.94774055480957
bi 3 loss 4.926045894622803
Layer  4  loss:  4.951995372772217 0.0 10.044265747070312
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([109, 269, 327, 315], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 3.833160161972046
bi 1 loss 5.057048797607422
bi 2 loss 4.956355094909668
bi 3 loss 5.060128688812256
Layer  5  loss:  5.188370704650879 0.0 11.270963668823242
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([124, 214, 378, 211], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 3.772674083709717
bi 1 loss 5.349179744720459
bi 2 loss 5.127274513244629
bi 3 loss 5.341494083404541
Layer  6  loss:  5.213138580322266 0.0 10.35170841217041
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1019
Curr loss timestep torch.Size([436, 4]) tensor([109, 330, 412, 207], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 4.0067877769470215
bi 1 loss 5.285098552703857
bi 2 loss 5.239227771759033
bi 3 loss 5.359859466552734
Epoch 0: :   3%|▎         | 15401/600000 [02:46<1:45:34, v_num=12, reduced_train_loss=0.752, global_step=15399.0, consumed_samples=61600.0, train_step_timing in s=0.324]Epoch 0: :   3%|▎         | 15401/600000 [02:46<1:45:34, v_num=12, reduced_train_loss=36.90, global_step=15400.0, consumed_samples=61604.0, train_step_timing in s=0.307]loss mask original None

First layer loss:  3.1984879970550537 torch.Size([584, 4]) 11.91051197052002 0.0
Max loss timestep torch.Size([584, 4]) tensor([241, 408, 142, 211], device='cuda:0') tensor(401, device='cuda:0')
bi 0 loss 3.2634479999542236
speech mask sum tensor(387, device='cuda:0') loss mask sum tensor(387, device='cuda:0')
bi 1 loss 3.8857598304748535
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 2 loss 3.0703330039978027
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 3 loss 2.7432281970977783
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
logits torch.Size([584, 4, 257024]) labels torch.Size([584, 4]) 0 257023
Layer  0  loss:  3.8183703422546387 0.0 10.45714282989502
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([165, 432, 198, 197], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 4.159548759460449
bi 1 loss 4.481602668762207
bi 2 loss 3.3884456157684326
bi 3 loss 3.193465232849121
Layer  1  loss:  4.157927989959717 0.0 10.263544082641602
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([193, 439, 173, 175], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 4.430016040802002
bi 1 loss 5.159996509552002
bi 2 loss 3.8546853065490723
bi 3 loss 3.3583247661590576
Layer  2  loss:  4.36115837097168 0.0 11.032903671264648
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([400, 302, 177, 196], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 4.663449764251709
bi 1 loss 5.079284191131592
bi 2 loss 4.117945194244385
bi 3 loss 3.6959919929504395
Layer  3  loss:  4.462942600250244 0.0 9.954398155212402
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([202, 436, 198, 420], device='cuda:0') tensor(332, device='cuda:0')
bi 0 loss 4.904665946960449
bi 1 loss 5.4004669189453125
bi 2 loss 4.2312445640563965
bi 3 loss 3.532360792160034
Layer  4  loss:  4.614752292633057 0.0 9.826194763183594
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([173, 323, 206, 407], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 5.051959991455078
bi 1 loss 5.473494052886963
bi 2 loss 4.0595855712890625
bi 3 loss 3.809448719024658
Layer  5  loss:  4.697106838226318 0.0 9.819281578063965
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1021
Curr loss timestep torch.Size([584, 4]) tensor([299, 297, 194, 560], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 5.039937973022461
bi 1 loss 5.676229000091553
bi 2 loss 4.49417781829834
bi 3 loss 3.824636697769165
Layer  6  loss:  4.724338531494141 0.0 10.35830307006836
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1021
Curr loss timestep torch.Size([584, 4]) tensor([435, 334, 152, 308], device='cuda:0') tensor(406, device='cuda:0')
bi 0 loss 5.160845756530762
bi 1 loss 5.636240482330322
bi 2 loss 4.651177406311035
bi 3 loss 3.7788281440734863
Epoch 0: :   3%|▎         | 15402/600000 [02:47<1:45:49, v_num=12, reduced_train_loss=36.90, global_step=15400.0, consumed_samples=61604.0, train_step_timing in s=0.307]Epoch 0: :   3%|▎         | 15402/600000 [02:47<1:45:49, v_num=12, reduced_train_loss=34.00, global_step=15401.0, consumed_samples=61608.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  3.777988910675049 torch.Size([620, 4]) 10.695661544799805 0.0
Max loss timestep torch.Size([620, 4]) tensor([362, 275, 346, 107], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 3.7732737064361572
speech mask sum tensor(422, device='cuda:0') loss mask sum tensor(422, device='cuda:0')
bi 1 loss 4.0581488609313965
speech mask sum tensor(434, device='cuda:0') loss mask sum tensor(434, device='cuda:0')
bi 2 loss 3.3775386810302734
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
bi 3 loss 3.801035165786743
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
logits torch.Size([620, 4, 257024]) labels torch.Size([620, 4]) 0 257023
Layer  0  loss:  4.182503700256348 0.0 11.37232780456543
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([209, 191, 472, 341], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 4.436183929443359
bi 1 loss 4.055643558502197
bi 2 loss 4.239529609680176
bi 3 loss 4.033901691436768
Layer  1  loss:  4.533550262451172 0.0 11.959148406982422
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([452, 334, 371, 204], device='cuda:0') tensor(469, device='cuda:0')
bi 0 loss 4.767988204956055
bi 1 loss 4.61396598815918
bi 2 loss 4.402548789978027
bi 3 loss 4.341704368591309
Layer  2  loss:  4.90349006652832 0.0 9.632282257080078
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([467, 292, 306, 136], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 5.070615291595459
bi 1 loss 4.9470977783203125
bi 2 loss 4.744333267211914
bi 3 loss 4.824400901794434
Layer  3  loss:  4.993419170379639 0.0 10.63286018371582
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1021
Curr loss timestep torch.Size([620, 4]) tensor([525, 370, 226, 125], device='cuda:0') tensor(370, device='cuda:0')
bi 0 loss 5.141965389251709
bi 1 loss 5.121088027954102
bi 2 loss 4.7343974113464355
bi 3 loss 4.922571659088135
Layer  4  loss:  5.063929557800293 0.0 9.820696830749512
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([313, 284, 226, 334], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 5.148229122161865
bi 1 loss 5.223341464996338
bi 2 loss 4.877940654754639
bi 3 loss 4.97103214263916
Layer  5  loss:  5.227772235870361 0.0 11.33304214477539
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([220, 390, 225, 338], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 5.347540378570557
bi 1 loss 5.256211757659912
bi 2 loss 5.0252556800842285
bi 3 loss 5.234374046325684
Layer  6  loss:  5.221984386444092 0.0 10.869468688964844
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([238, 579, 399, 291], device='cuda:0') tensor(457, device='cuda:0')
bi 0 loss 5.348406791687012
bi 1 loss 5.341193199157715
bi 2 loss 5.05231237411499
bi 3 loss 5.117199420928955
Epoch 0: :   3%|▎         | 15403/600000 [02:47<1:46:04, v_num=12, reduced_train_loss=34.00, global_step=15401.0, consumed_samples=61608.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15403/600000 [02:47<1:46:04, v_num=12, reduced_train_loss=37.90, global_step=15402.0, consumed_samples=61612.0, train_step_timing in s=0.388]loss mask original None

First layer loss:  0.3616154193878174 torch.Size([638, 4]) 12.369673728942871 0.0
Max loss timestep torch.Size([638, 4]) tensor([487, 412, 313, 267], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.3961241841316223
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
bi 1 loss 0.4899466633796692
speech mask sum tensor(306, device='cuda:0') loss mask sum tensor(306, device='cuda:0')
bi 2 loss 0.2982819080352783
speech mask sum tensor(76, device='cuda:0') loss mask sum tensor(76, device='cuda:0')
bi 3 loss 0.1292123794555664
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
logits torch.Size([638, 4, 257024]) labels torch.Size([638, 4]) 0 257022
Layer  0  loss:  0.40002673864364624 0.0 17.277328491210938
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([421, 407, 313, 267], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.5055720210075378
bi 1 loss 0.4368346035480499
bi 2 loss 0.412462055683136
bi 3 loss 0.12666523456573486
Layer  1  loss:  0.41588708758354187 0.0 14.312865257263184
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([421, 298, 299, 267], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.5150074362754822
bi 1 loss 0.4848291873931885
bi 2 loss 0.45297548174858093
bi 3 loss 0.10071590542793274
Layer  2  loss:  0.47027137875556946 0.0 15.961882591247559
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([420, 298, 299, 267], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.5843697786331177
bi 1 loss 0.49743717908859253
bi 2 loss 0.6316598653793335
bi 3 loss 0.14010630548000336
Layer  3  loss:  0.47032630443573 0.0 15.453557968139648
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([418, 412, 298, 267], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.5902292728424072
bi 1 loss 0.5192212462425232
bi 2 loss 0.4885621964931488
bi 3 loss 0.14814099669456482
Layer  4  loss:  0.528282642364502 0.0 15.610010147094727
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([484, 407, 313, 267], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.642333447933197
bi 1 loss 0.5892366170883179
bi 2 loss 0.6003053784370422
bi 3 loss 0.1815609633922577
Layer  5  loss:  0.5636589527130127 0.0 19.09685707092285
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([421, 407, 298, 267], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.727104663848877
bi 1 loss 0.6166572570800781
bi 2 loss 0.5659376978874207
bi 3 loss 0.15214255452156067
Layer  6  loss:  0.4787151515483856 0.0 14.590550422668457
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([485, 409, 299, 267], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.6348177194595337
bi 1 loss 0.4894264042377472
bi 2 loss 0.5204976201057434
bi 3 loss 0.1288852095603943
Epoch 0: :   3%|▎         | 15404/600000 [02:48<1:46:22, v_num=12, reduced_train_loss=37.90, global_step=15402.0, consumed_samples=61612.0, train_step_timing in s=0.388]Epoch 0: :   3%|▎         | 15404/600000 [02:48<1:46:22, v_num=12, reduced_train_loss=3.690, global_step=15403.0, consumed_samples=61616.0, train_step_timing in s=0.438]loss mask original None

First layer loss:  0.11830577999353409 torch.Size([706, 4]) 10.687850952148438 0.0
Max loss timestep torch.Size([706, 4]) tensor([212, 291, 687, 201], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.060958944261074066
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 1 loss 0.0953315868973732
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
bi 2 loss 0.16608776152133942
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 3 loss 0.0412011556327343
speech mask sum tensor(56, device='cuda:0') loss mask sum tensor(56, device='cuda:0')
logits torch.Size([706, 4, 257024]) labels torch.Size([706, 4]) 0 257023
Layer  0  loss:  0.166358083486557 0.0 14.900140762329102
logits torch.Size([706, 4, 1024]) labels torch.Size([706, 4]) 0 1023
Curr loss timestep torch.Size([706, 4]) tensor([204, 291, 687, 189], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.041371140629053116
bi 1 loss 0.12492364645004272
bi 2 loss 0.2617829740047455
bi 3 loss 0.01865055225789547
Layer  1  loss:  0.14363615214824677 0.0 7.83638858795166
logits torch.Size([706, 4, 1024]) labels torch.Size([706, 4]) 0 1023
Curr loss timestep torch.Size([706, 4]) tensor([218, 290, 687, 197], device='cuda:0') tensor(687, device='cuda:0')
bi 0 loss 0.05995234102010727
bi 1 loss 0.08129324018955231
bi 2 loss 0.2295427918434143
bi 3 loss 0.062287695705890656
Layer  2  loss:  0.17740832269191742 0.0 16.737709045410156
logits torch.Size([706, 4, 1024]) labels torch.Size([706, 4]) 0 1023
Curr loss timestep torch.Size([706, 4]) tensor([165, 291, 535, 186], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.06718764454126358
bi 1 loss 0.13036389648914337
bi 2 loss 0.26966142654418945
bi 3 loss 0.04159298911690712
Layer  3  loss:  0.1555682271718979 0.0 13.607218742370605
logits torch.Size([706, 4, 1024]) labels torch.Size([706, 4]) 0 1023
Curr loss timestep torch.Size([706, 4]) tensor([206, 291, 687, 190], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.05556932091712952
bi 1 loss 0.11344251781702042
bi 2 loss 0.23835083842277527
bi 3 loss 0.03637632727622986
Layer  4  loss:  0.1745089590549469 0.0 13.810528755187988
logits torch.Size([706, 4, 1024]) labels torch.Size([706, 4]) 0 1022
Curr loss timestep torch.Size([706, 4]) tensor([121, 291, 336, 191], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.0809575617313385
bi 1 loss 0.10578933358192444
bi 2 loss 0.27474528551101685
bi 3 loss 0.04606326296925545
Layer  5  loss:  0.15367524325847626 0.0 13.76693344116211
logits torch.Size([706, 4, 1024]) labels torch.Size([706, 4]) 0 1022
Curr loss timestep torch.Size([706, 4]) tensor([198, 291, 687, 187], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.05469578877091408
bi 1 loss 0.10743546485900879
bi 2 loss 0.23700354993343353
bi 3 loss 0.04953078553080559
Layer  6  loss:  0.15870128571987152 0.0 13.944332122802734
logits torch.Size([706, 4, 1024]) labels torch.Size([706, 4]) 0 1021
Curr loss timestep torch.Size([706, 4]) tensor([121, 290, 535, 211], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.052587732672691345
bi 1 loss 0.08301367610692978
bi 2 loss 0.25983574986457825
bi 3 loss 0.09727699309587479
Epoch 0: :   3%|▎         | 15405/600000 [02:48<1:46:41, v_num=12, reduced_train_loss=3.690, global_step=15403.0, consumed_samples=61616.0, train_step_timing in s=0.438]Epoch 0: :   3%|▎         | 15405/600000 [02:48<1:46:41, v_num=12, reduced_train_loss=1.250, global_step=15404.0, consumed_samples=61620.0, train_step_timing in s=0.479]loss mask original None

First layer loss:  0.12713642418384552 torch.Size([510, 4]) 7.30021333694458 0.0
Max loss timestep torch.Size([510, 4]) tensor([324, 361, 334, 314], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.13259375095367432
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 1 loss 0.07715097069740295
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 2 loss 0.1759941279888153
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 3 loss 0.11074208468198776
speech mask sum tensor(295, device='cuda:0') loss mask sum tensor(295, device='cuda:0')
logits torch.Size([510, 4, 257024]) labels torch.Size([510, 4]) 0 257022
Layer  0  loss:  0.13391095399856567 0.0 12.195244789123535
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([366, 361, 357, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.11992721259593964
bi 1 loss 0.0753583088517189
bi 2 loss 0.18881230056285858
bi 3 loss 0.1437915712594986
Layer  1  loss:  0.1293889880180359 0.0 8.609752655029297
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([366, 299, 357, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.14955522119998932
bi 1 loss 0.06202571466565132
bi 2 loss 0.14963066577911377
bi 3 loss 0.13096925616264343
Layer  2  loss:  0.1361217349767685 0.0 10.50642204284668
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([479, 361, 357, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.13366644084453583
bi 1 loss 0.09695550799369812
bi 2 loss 0.1804499477148056
bi 3 loss 0.12680798768997192
Layer  3  loss:  0.12227252125740051 0.0 14.30810832977295
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([366, 361, 356, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.10451507568359375
bi 1 loss 0.10391997545957565
bi 2 loss 0.1666123867034912
bi 3 loss 0.11890760809183121
Layer  4  loss:  0.12612949311733246 0.0 8.940110206604004
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([366, 332, 383, 265], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.11109885573387146
bi 1 loss 0.11080218851566315
bi 2 loss 0.1491636037826538
bi 3 loss 0.13606326282024384
Layer  5  loss:  0.1486075520515442 0.0 11.023101806640625
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([366, 361, 334, 262], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.15198440849781036
bi 1 loss 0.11432395875453949
bi 2 loss 0.19372613728046417
bi 3 loss 0.12749920785427094
Layer  6  loss:  0.1273072063922882 0.0 7.857409477233887
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([428, 318, 383, 262], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.14755867421627045
bi 1 loss 0.061326634138822556
bi 2 loss 0.15961503982543945
bi 3 loss 0.11706572771072388
Epoch 0: :   3%|▎         | 15406/600000 [02:49<1:46:56, v_num=12, reduced_train_loss=1.250, global_step=15404.0, consumed_samples=61620.0, train_step_timing in s=0.479]Epoch 0: :   3%|▎         | 15406/600000 [02:49<1:46:56, v_num=12, reduced_train_loss=1.050, global_step=15405.0, consumed_samples=61624.0, train_step_timing in s=0.356]loss mask original None

First layer loss:  0.07888337224721909 torch.Size([541, 4]) 5.6477484703063965 0.0
Max loss timestep torch.Size([541, 4]) tensor([274, 289, 109, 399], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.038285497575998306
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
bi 1 loss 0.11347655206918716
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
bi 2 loss 0.07472729682922363
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
bi 3 loss 0.06461595743894577
speech mask sum tensor(389, device='cuda:0') loss mask sum tensor(389, device='cuda:0')
logits torch.Size([541, 4, 257024]) labels torch.Size([541, 4]) 0 257023
Layer  0  loss:  0.06974904984235764 0.0 4.760257720947266
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([302, 289, 381, 303], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.05559856444597244
bi 1 loss 0.09790819138288498
bi 2 loss 0.05759844556450844
bi 3 loss 0.055408332496881485
Layer  1  loss:  0.09043797850608826 0.0 14.209562301635742
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([130, 289, 304, 265], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.05613862723112106
bi 1 loss 0.11911025643348694
bi 2 loss 0.07612209767103195
bi 3 loss 0.08798351883888245
Layer  2  loss:  0.08212629705667496 0.0 11.180191993713379
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([133, 289, 304, 265], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.05266891419887543
bi 1 loss 0.10015483945608139
bi 2 loss 0.08476836234331131
bi 3 loss 0.07509351521730423
Layer  3  loss:  0.09993186593055725 0.0 14.33055591583252
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([194, 289, 304, 315], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.057566650211811066
bi 1 loss 0.14079366624355316
bi 2 loss 0.09624816477298737
bi 3 loss 0.07910154014825821
Layer  4  loss:  0.09024696797132492 0.0 10.83961296081543
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([153, 289, 304, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.05954675003886223
bi 1 loss 0.10431589931249619
bi 2 loss 0.09057629853487015
bi 3 loss 0.09028161317110062
Layer  5  loss:  0.09356113523244858 0.0 9.007993698120117
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([286, 289, 382, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.05767147243022919
bi 1 loss 0.12822608649730682
bi 2 loss 0.08107729256153107
bi 3 loss 0.0836339145898819
Layer  6  loss:  0.084125816822052 0.0 12.336365699768066
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([160, 445, 368, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.06395158171653748
bi 1 loss 0.09331869333982468
bi 2 loss 0.07415922731161118
bi 3 loss 0.09266317635774612
Epoch 0: :   3%|▎         | 15407/600000 [02:49<1:47:11, v_num=12, reduced_train_loss=1.050, global_step=15405.0, consumed_samples=61624.0, train_step_timing in s=0.356]Epoch 0: :   3%|▎         | 15407/600000 [02:49<1:47:11, v_num=12, reduced_train_loss=0.689, global_step=15406.0, consumed_samples=61628.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  0.05605100840330124 torch.Size([403, 4]) 8.396347045898438 0.0
Max loss timestep torch.Size([403, 4]) tensor([174, 272, 223, 327], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.014725041575729847
speech mask sum tensor(62, device='cuda:0') loss mask sum tensor(62, device='cuda:0')
bi 1 loss 0.08770014345645905
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
bi 2 loss 0.032755766063928604
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 3 loss 0.04705635830760002
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
logits torch.Size([403, 4, 257024]) labels torch.Size([403, 4]) 0 257022
Layer  0  loss:  0.05227818340063095 0.0 5.654177665710449
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1023
Curr loss timestep torch.Size([403, 4]) tensor([163, 273, 306, 300], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.01258381363004446
bi 1 loss 0.10010209679603577
bi 2 loss 0.03360554948449135
bi 3 loss 0.024766555055975914
Layer  1  loss:  0.031010035425424576 0.0 1.617540955543518
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1022
Curr loss timestep torch.Size([403, 4]) tensor([169, 355, 306, 181], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.013627439737319946
bi 1 loss 0.041443418711423874
bi 2 loss 0.025854269042611122
bi 3 loss 0.02750404365360737
Layer  2  loss:  0.049593355506658554 0.0 9.017796516418457
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1022
Curr loss timestep torch.Size([403, 4]) tensor([175, 273, 306, 245], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.01841636374592781
bi 1 loss 0.09726987779140472
bi 2 loss 0.017366353422403336
bi 3 loss 0.02768642269074917
Layer  3  loss:  0.04652705043554306 0.0 11.657743453979492
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1020
Curr loss timestep torch.Size([403, 4]) tensor([167, 273, 306, 101], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.019412193447351456
bi 1 loss 0.08704659342765808
bi 2 loss 0.027192873880267143
bi 3 loss 0.02368922531604767
Layer  4  loss:  0.05118308216333389 0.0 5.69167423248291
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1022
Curr loss timestep torch.Size([403, 4]) tensor([167, 356, 200, 299], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.018344512209296227
bi 1 loss 0.09933564811944962
bi 2 loss 0.028106657788157463
bi 3 loss 0.024232130497694016
Layer  5  loss:  0.04994255676865578 0.0 7.302724361419678
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1022
Curr loss timestep torch.Size([403, 4]) tensor([175, 355, 306, 284], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.013033746741712093
bi 1 loss 0.09264057129621506
bi 2 loss 0.037428148090839386
bi 3 loss 0.023454202339053154
Layer  6  loss:  0.049341943114995956 0.0 10.161515235900879
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1021
Curr loss timestep torch.Size([403, 4]) tensor([175, 273, 260, 149], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.02961871773004532
bi 1 loss 0.09117621928453445
bi 2 loss 0.029097380116581917
bi 3 loss 0.024104014039039612
Epoch 0: :   3%|▎         | 15408/600000 [02:49<1:47:23, v_num=12, reduced_train_loss=0.689, global_step=15406.0, consumed_samples=61628.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15408/600000 [02:49<1:47:23, v_num=12, reduced_train_loss=0.386, global_step=15407.0, consumed_samples=61632.0, train_step_timing in s=0.301]loss mask original None

First layer loss:  0.04715714603662491 torch.Size([539, 4]) 2.3670854568481445 0.0
Max loss timestep torch.Size([539, 4]) tensor([503, 169, 104, 114], device='cuda:0') tensor(503, device='cuda:0')
bi 0 loss 0.05998764559626579
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
bi 1 loss 0.03703659772872925
speech mask sum tensor(171, device='cuda:0') loss mask sum tensor(171, device='cuda:0')
bi 2 loss 0.027539221569895744
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 3 loss 0.034509848803281784
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
logits torch.Size([539, 4, 257024]) labels torch.Size([539, 4]) 0 257023
Layer  0  loss:  0.05330731347203255 0.0 2.767256259918213
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([292, 191,  92, 137], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.06980892270803452
bi 1 loss 0.049474623054265976
bi 2 loss 0.009542103856801987
bi 3 loss 0.03500400483608246
Layer  1  loss:  0.047630418092012405 0.0 3.795365810394287
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1021
Curr loss timestep torch.Size([539, 4]) tensor([504, 166,  98, 153], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.06483175605535507
bi 1 loss 0.03263990953564644
bi 2 loss 0.02789166569709778
bi 3 loss 0.02906165085732937
Layer  2  loss:  0.052830785512924194 0.0 3.6499838829040527
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([292, 155,  93, 188], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.06850635260343552
bi 1 loss 0.03429728373885155
bi 2 loss 0.03925615921616554
bi 3 loss 0.039821747690439224
Layer  3  loss:  0.055301517248153687 0.0 4.39166259765625
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([505, 148,  92, 107], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.07490359246730804
bi 1 loss 0.03691933676600456
bi 2 loss 0.015250982716679573
bi 3 loss 0.0449710451066494
Layer  4  loss:  0.055785685777664185 0.0 7.920564651489258
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1021
Curr loss timestep torch.Size([539, 4]) tensor([505, 151,  78, 153], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.07901210337877274
bi 1 loss 0.03273433446884155
bi 2 loss 0.023914817720651627
bi 3 loss 0.03702494129538536
Layer  5  loss:  0.056021615862846375 0.0 2.1765899658203125
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([292, 179,  87, 153], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.07895080000162125
bi 1 loss 0.028246205300092697
bi 2 loss 0.023152558133006096
bi 3 loss 0.04464039206504822
Layer  6  loss:  0.06456512212753296 0.0 6.444061279296875
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1021
Curr loss timestep torch.Size([539, 4]) tensor([292, 196, 100, 121], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.09656506031751633
bi 1 loss 0.041314903646707535
bi 2 loss 0.019636930897831917
bi 3 loss 0.028391893953084946
Epoch 0: :   3%|▎         | 15409/600000 [02:50<1:47:38, v_num=12, reduced_train_loss=0.386, global_step=15407.0, consumed_samples=61632.0, train_step_timing in s=0.301]Epoch 0: :   3%|▎         | 15409/600000 [02:50<1:47:38, v_num=12, reduced_train_loss=0.433, global_step=15408.0, consumed_samples=61636.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  0.02909843996167183 torch.Size([331, 4]) 1.890566110610962 0.0
Max loss timestep torch.Size([331, 4]) tensor([311, 135, 218, 103], device='cuda:0') tensor(103, device='cuda:0')
bi 0 loss 0.031681038439273834
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 1 loss 0.01859397254884243
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 2 loss 0.015949038788676262
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
bi 3 loss 0.04163854569196701
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
logits torch.Size([331, 4, 257024]) labels torch.Size([331, 4]) 0 257023
Layer  0  loss:  0.02590779960155487 0.0 0.8569996356964111
logits torch.Size([331, 4, 1024]) labels torch.Size([331, 4]) 0 1023
Curr loss timestep torch.Size([331, 4]) tensor([312, 154, 189,  51], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.03183333948254585
bi 1 loss 0.017039883881807327
bi 2 loss 0.018096448853611946
bi 3 loss 0.028254983946681023
Layer  1  loss:  0.024755138903856277 0.0 0.6744771599769592
logits torch.Size([331, 4, 1024]) labels torch.Size([331, 4]) 0 1022
Curr loss timestep torch.Size([331, 4]) tensor([311, 114, 183, 114], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.03324329853057861
bi 1 loss 0.0213918536901474
bi 2 loss 0.020431162789463997
bi 3 loss 0.017163986340165138
Layer  2  loss:  0.02573459781706333 0.0 0.6472845077514648
logits torch.Size([331, 4, 1024]) labels torch.Size([331, 4]) 0 1023
Curr loss timestep torch.Size([331, 4]) tensor([251, 151, 245, 116], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 0.02774169109761715
bi 1 loss 0.0192764550447464
bi 2 loss 0.02458573505282402
bi 3 loss 0.027485372498631477
Layer  3  loss:  0.024076145142316818 0.0 1.1184873580932617
logits torch.Size([331, 4, 1024]) labels torch.Size([331, 4]) 0 1022
Curr loss timestep torch.Size([331, 4]) tensor([311, 110, 201, 116], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.029778653755784035
bi 1 loss 0.021499259397387505
bi 2 loss 0.023003997281193733
bi 3 loss 0.017763951793313026
Layer  4  loss:  0.023956872522830963 0.0 0.2696354389190674
logits torch.Size([331, 4, 1024]) labels torch.Size([331, 4]) 0 1022
Curr loss timestep torch.Size([331, 4]) tensor([317, 154, 211,  65], device='cuda:0') tensor(114, device='cuda:0')
bi 0 loss 0.022189408540725708
bi 1 loss 0.02569402940571308
bi 2 loss 0.01747048646211624
bi 3 loss 0.03057112731039524
Layer  5  loss:  0.024810856208205223 0.0 0.3044298589229584
logits torch.Size([331, 4, 1024]) labels torch.Size([331, 4]) 0 1022
Curr loss timestep torch.Size([331, 4]) tensor([259, 126, 185,  62], device='cuda:0') tensor(62, device='cuda:0')
bi 0 loss 0.026620564982295036
bi 1 loss 0.02144623175263405
bi 2 loss 0.019881734624505043
bi 3 loss 0.02787802927196026
Layer  6  loss:  0.022607341408729553 0.0 0.3663528263568878
logits torch.Size([331, 4, 1024]) labels torch.Size([331, 4]) 0 1022
Curr loss timestep torch.Size([331, 4]) tensor([312, 153, 224, 135], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.020885532721877098
bi 1 loss 0.019932763651013374
bi 2 loss 0.017889726907014847
bi 3 loss 0.030482269823551178
Epoch 0: :   3%|▎         | 15410/600000 [02:50<1:47:50, v_num=12, reduced_train_loss=0.433, global_step=15408.0, consumed_samples=61636.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15410/600000 [02:50<1:47:50, v_num=12, reduced_train_loss=0.201, global_step=15409.0, consumed_samples=61640.0, train_step_timing in s=0.276]loss mask original None

First layer loss:  0.09813009947538376 torch.Size([605, 4]) 6.991347789764404 0.0
Max loss timestep torch.Size([605, 4]) tensor([315, 132, 118, 315], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.14970344305038452
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
bi 1 loss 0.05739213898777962
speech mask sum tensor(108, device='cuda:0') loss mask sum tensor(108, device='cuda:0')
bi 2 loss 0.03349265456199646
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 3 loss 0.05431312695145607
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
logits torch.Size([605, 4, 257024]) labels torch.Size([605, 4]) 0 257022
Layer  0  loss:  0.0792788714170456 0.0 12.125738143920898
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1023
Curr loss timestep torch.Size([605, 4]) tensor([539, 184, 109, 393], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.11228711903095245
bi 1 loss 0.03205283358693123
bi 2 loss 0.04251030832529068
bi 3 loss 0.056872934103012085
Layer  1  loss:  0.08796150982379913 0.0 4.6971282958984375
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1023
Curr loss timestep torch.Size([605, 4]) tensor([539, 130, 136, 391], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.1089034229516983
bi 1 loss 0.04204002022743225
bi 2 loss 0.041320569813251495
bi 3 loss 0.08892527967691422
Layer  2  loss:  0.08811166137456894 0.0 6.7857866287231445
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1022
Curr loss timestep torch.Size([605, 4]) tensor([334, 169, 117, 411], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.12970291078090668
bi 1 loss 0.04270348325371742
bi 2 loss 0.034621067345142365
bi 3 loss 0.057792212814092636
Layer  3  loss:  0.07858147472143173 0.0 3.761274814605713
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1021
Curr loss timestep torch.Size([605, 4]) tensor([372, 159, 185, 231], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.09891244769096375
bi 1 loss 0.03956088796257973
bi 2 loss 0.05614287033677101
bi 3 loss 0.06822440028190613
Layer  4  loss:  0.08211816847324371 0.0 7.443256855010986
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1023
Curr loss timestep torch.Size([605, 4]) tensor([539, 190, 173, 392], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.10905398428440094
bi 1 loss 0.045140720903873444
bi 2 loss 0.06252855807542801
bi 3 loss 0.0590316504240036
Layer  5  loss:  0.08973059058189392 0.0 5.980416774749756
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1023
Curr loss timestep torch.Size([605, 4]) tensor([278, 160, 181, 270], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.12468916922807693
bi 1 loss 0.041585665196180344
bi 2 loss 0.017285935580730438
bi 3 loss 0.07900184392929077
Layer  6  loss:  0.09792532026767731 0.0 6.081943988800049
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1023
Curr loss timestep torch.Size([605, 4]) tensor([539, 160, 128, 316], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.12051733583211899
bi 1 loss 0.028780588880181313
bi 2 loss 0.04945792630314827
bi 3 loss 0.10517589747905731
Epoch 0: :   3%|▎         | 15411/600000 [02:51<1:48:07, v_num=12, reduced_train_loss=0.201, global_step=15409.0, consumed_samples=61640.0, train_step_timing in s=0.276]Epoch 0: :   3%|▎         | 15411/600000 [02:51<1:48:07, v_num=12, reduced_train_loss=0.702, global_step=15410.0, consumed_samples=61644.0, train_step_timing in s=0.417]loss mask original None

First layer loss:  0.1864210069179535 torch.Size([657, 4]) 10.578018188476562 0.0
Max loss timestep torch.Size([657, 4]) tensor([313, 182, 223, 327], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 0.23597051203250885
speech mask sum tensor(267, device='cuda:0') loss mask sum tensor(267, device='cuda:0')
bi 1 loss 0.020432446151971817
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 2 loss 0.23735374212265015
speech mask sum tensor(465, device='cuda:0') loss mask sum tensor(465, device='cuda:0')
bi 3 loss 0.09209080040454865
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
logits torch.Size([657, 4, 257024]) labels torch.Size([657, 4]) 0 257023
Layer  0  loss:  0.1743289977312088 0.0 9.948955535888672
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([313, 153, 607, 259], device='cuda:0') tensor(607, device='cuda:0')
bi 0 loss 0.24839399755001068
bi 1 loss 0.028756894171237946
bi 2 loss 0.2087959498167038
bi 3 loss 0.07410456985235214
Layer  1  loss:  0.19070672988891602 0.0 9.967764854431152
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([313, 217, 607, 259], device='cuda:0') tensor(607, device='cuda:0')
bi 0 loss 0.2334080934524536
bi 1 loss 0.029127752408385277
bi 2 loss 0.24064193665981293
bi 3 loss 0.10557474195957184
Layer  2  loss:  0.1956455260515213 0.0 9.824956893920898
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1022
Curr loss timestep torch.Size([657, 4]) tensor([312, 178, 608, 259], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.26652979850769043
bi 1 loss 0.018120303750038147
bi 2 loss 0.2313874214887619
bi 3 loss 0.11482509225606918
Layer  3  loss:  0.20776140689849854 0.0 10.398387908935547
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1018
Curr loss timestep torch.Size([657, 4]) tensor([312, 233, 578, 268], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.2559928894042969
bi 1 loss 0.029884180054068565
bi 2 loss 0.280156672000885
bi 3 loss 0.07104085385799408
Layer  4  loss:  0.19580918550491333 0.0 9.715621948242188
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([312, 224, 607, 179], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.28047552704811096
bi 1 loss 0.027442526072263718
bi 2 loss 0.232929527759552
bi 3 loss 0.08775722980499268
Layer  5  loss:  0.23033247888088226 0.0 12.187640190124512
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1022
Curr loss timestep torch.Size([657, 4]) tensor([424, 225, 533, 191], device='cuda:0') tensor(424, device='cuda:0')
bi 0 loss 0.3467983305454254
bi 1 loss 0.04123619943857193
bi 2 loss 0.2808995544910431
bi 3 loss 0.058799970895051956
Layer  6  loss:  0.21900434792041779 0.0 10.503791809082031
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([313, 200, 608, 259], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.3377559781074524
bi 1 loss 0.053581349551677704
bi 2 loss 0.2537171244621277
bi 3 loss 0.06856463104486465
Epoch 0: :   3%|▎         | 15412/600000 [02:51<1:48:25, v_num=12, reduced_train_loss=0.702, global_step=15410.0, consumed_samples=61644.0, train_step_timing in s=0.417]Epoch 0: :   3%|▎         | 15412/600000 [02:51<1:48:25, v_num=12, reduced_train_loss=1.600, global_step=15411.0, consumed_samples=61648.0, train_step_timing in s=0.454]loss mask original None

First layer loss:  0.13761399686336517 torch.Size([485, 4]) 14.2188138961792 0.0
Max loss timestep torch.Size([485, 4]) tensor([333, 371, 344,  75], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.06600737571716309
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 1 loss 0.15315672755241394
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 2 loss 0.20852921903133392
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
bi 3 loss 0.038116779178380966
speech mask sum tensor(107, device='cuda:0') loss mask sum tensor(107, device='cuda:0')
logits torch.Size([485, 4, 257024]) labels torch.Size([485, 4]) 0 257022
Layer  0  loss:  0.1359451860189438 0.0 8.234006881713867
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1023
Curr loss timestep torch.Size([485, 4]) tensor([333, 371, 344,  79], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.11468302458524704
bi 1 loss 0.19507502019405365
bi 2 loss 0.13655497133731842
bi 3 loss 0.03903597965836525
Layer  1  loss:  0.13434788584709167 0.0 8.229798316955566
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1023
Curr loss timestep torch.Size([485, 4]) tensor([333, 372, 344, 111], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.10082456469535828
bi 1 loss 0.18699239194393158
bi 2 loss 0.14300189912319183
bi 3 loss 0.057177480310201645
Layer  2  loss:  0.13256612420082092 0.0 11.219171524047852
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1023
Curr loss timestep torch.Size([485, 4]) tensor([333, 371, 381, 104], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.1314573585987091
bi 1 loss 0.1442956179380417
bi 2 loss 0.1492677479982376
bi 3 loss 0.04946018010377884
Layer  3  loss:  0.1629037708044052 0.0 8.959904670715332
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1021
Curr loss timestep torch.Size([485, 4]) tensor([333, 372, 448,  63], device='cuda:0') tensor(448, device='cuda:0')
bi 0 loss 0.12970030307769775
bi 1 loss 0.23901954293251038
bi 2 loss 0.16538168489933014
bi 3 loss 0.04703930392861366
Layer  4  loss:  0.17489685118198395 0.0 9.076619148254395
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([333, 372, 448,  73], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.11502691358327866
bi 1 loss 0.2575480043888092
bi 2 loss 0.19780685007572174
bi 3 loss 0.04032881557941437
Layer  5  loss:  0.12695856392383575 0.0 6.588352680206299
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([305, 371, 448, 126], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.07593508064746857
bi 1 loss 0.17088279128074646
bi 2 loss 0.15328966081142426
bi 3 loss 0.05565712973475456
Layer  6  loss:  0.16818366944789886 0.0 12.760257720947266
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([333, 371, 344, 130], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.16607829928398132
bi 1 loss 0.2144111841917038
bi 2 loss 0.17675498127937317
bi 3 loss 0.028673894703388214
Epoch 0: :   3%|▎         | 15413/600000 [02:51<1:48:39, v_num=12, reduced_train_loss=1.600, global_step=15411.0, consumed_samples=61648.0, train_step_timing in s=0.454]Epoch 0: :   3%|▎         | 15413/600000 [02:51<1:48:39, v_num=12, reduced_train_loss=1.170, global_step=15412.0, consumed_samples=61652.0, train_step_timing in s=0.345]loss mask original None

First layer loss:  0.18708303570747375 torch.Size([673, 4]) 10.666805267333984 0.0
Max loss timestep torch.Size([673, 4]) tensor([284, 468, 602, 397], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.11524070054292679
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 1 loss 0.10531197488307953
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
bi 2 loss 0.280003160238266
speech mask sum tensor(495, device='cuda:0') loss mask sum tensor(495, device='cuda:0')
bi 3 loss 0.14055374264717102
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
logits torch.Size([673, 4, 257024]) labels torch.Size([673, 4]) 0 257022
Layer  0  loss:  0.19710023701190948 0.0 13.173137664794922
logits torch.Size([673, 4, 1024]) labels torch.Size([673, 4]) 0 1023
Curr loss timestep torch.Size([673, 4]) tensor([284, 367, 587, 397], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.12686526775360107
bi 1 loss 0.18579918146133423
bi 2 loss 0.2521575689315796
bi 3 loss 0.1463751494884491
Layer  1  loss:  0.19935369491577148 0.0 12.786124229431152
logits torch.Size([673, 4, 1024]) labels torch.Size([673, 4]) 0 1023
Curr loss timestep torch.Size([673, 4]) tensor([273, 447, 272, 397], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.04940181225538254
bi 1 loss 0.1601034551858902
bi 2 loss 0.30700284242630005
bi 3 loss 0.13432475924491882
Layer  2  loss:  0.22617262601852417 0.0 9.211833953857422
logits torch.Size([673, 4, 1024]) labels torch.Size([673, 4]) 0 1023
Curr loss timestep torch.Size([673, 4]) tensor([284, 367, 648, 397], device='cuda:0') tensor(648, device='cuda:0')
bi 0 loss 0.08120857179164886
bi 1 loss 0.20010285079479218
bi 2 loss 0.32935577630996704
bi 3 loss 0.14983545243740082
Layer  3  loss:  0.23087584972381592 0.0 16.482810974121094
logits torch.Size([673, 4, 1024]) labels torch.Size([673, 4]) 0 1023
Curr loss timestep torch.Size([673, 4]) tensor([284, 367, 530, 397], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.10462427884340286
bi 1 loss 0.165938138961792
bi 2 loss 0.3682474195957184
bi 3 loss 0.10724209249019623
Layer  4  loss:  0.2081538587808609 0.0 11.511418342590332
logits torch.Size([673, 4, 1024]) labels torch.Size([673, 4]) 0 1022
Curr loss timestep torch.Size([673, 4]) tensor([284, 367, 602, 397], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.1632637232542038
bi 1 loss 0.18326961994171143
bi 2 loss 0.2709933817386627
bi 3 loss 0.13340029120445251
Layer  5  loss:  0.22709587216377258 0.0 12.769733428955078
logits torch.Size([673, 4, 1024]) labels torch.Size([673, 4]) 0 1022
Curr loss timestep torch.Size([673, 4]) tensor([284, 367, 282, 396], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.1249573826789856
bi 1 loss 0.14646969735622406
bi 2 loss 0.3349880576133728
bi 3 loss 0.17158231139183044
Layer  6  loss:  0.22667305171489716 0.0 12.020716667175293
logits torch.Size([673, 4, 1024]) labels torch.Size([673, 4]) 0 1023
Curr loss timestep torch.Size([673, 4]) tensor([284, 367, 587, 357], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.1128242015838623
bi 1 loss 0.17045244574546814
bi 2 loss 0.3398338258266449
bi 3 loss 0.13749928772449493
Epoch 0: :   3%|▎         | 15414/600000 [02:52<1:48:57, v_num=12, reduced_train_loss=1.170, global_step=15412.0, consumed_samples=61652.0, train_step_timing in s=0.345]Epoch 0: :   3%|▎         | 15414/600000 [02:52<1:48:57, v_num=12, reduced_train_loss=1.700, global_step=15413.0, consumed_samples=61656.0, train_step_timing in s=0.467]loss mask original None

First layer loss:  0.01349857822060585 torch.Size([342, 4]) 0.21025945246219635 0.0
Max loss timestep torch.Size([342, 4]) tensor([100, 136,  89, 222], device='cuda:0') tensor(89, device='cuda:0')
bi 0 loss 0.016589000821113586
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 1 loss 0.01049075834453106
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 2 loss 0.01366446167230606
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 3 loss 0.014490139670670033
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([342, 4, 257024]) labels torch.Size([342, 4]) 0 257022
Layer  0  loss:  0.013033037073910236 0.0 0.13579246401786804
logits torch.Size([342, 4, 1024]) labels torch.Size([342, 4]) 0 1023
Curr loss timestep torch.Size([342, 4]) tensor([103, 135,  62, 187], device='cuda:0') tensor(103, device='cuda:0')
bi 0 loss 0.014401130378246307
bi 1 loss 0.013329144567251205
bi 2 loss 0.01353920716792345
bi 3 loss 0.009356942027807236
Layer  1  loss:  0.012179736979305744 0.0 0.16962873935699463
logits torch.Size([342, 4, 1024]) labels torch.Size([342, 4]) 0 1022
Curr loss timestep torch.Size([342, 4]) tensor([125,  73, 249, 237], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 0.013834141194820404
bi 1 loss 0.01222161389887333
bi 2 loss 0.01245004404336214
bi 3 loss 0.009317235089838505
Layer  2  loss:  0.01151024829596281 0.0 0.3051403760910034
logits torch.Size([342, 4, 1024]) labels torch.Size([342, 4]) 0 1022
Curr loss timestep torch.Size([342, 4]) tensor([114, 136,  68, 221], device='cuda:0') tensor(114, device='cuda:0')
bi 0 loss 0.014965576119720936
bi 1 loss 0.011294497177004814
bi 2 loss 0.010526214726269245
bi 3 loss 0.010760963894426823
Layer  3  loss:  0.011792582459747791 0.0 0.13908334076404572
logits torch.Size([342, 4, 1024]) labels torch.Size([342, 4]) 0 1020
Curr loss timestep torch.Size([342, 4]) tensor([185,  58,  55, 179], device='cuda:0') tensor(55, device='cuda:0')
bi 0 loss 0.014499138109385967
bi 1 loss 0.011091746389865875
bi 2 loss 0.011220881715416908
bi 3 loss 0.011515188962221146
Layer  4  loss:  0.01351117342710495 0.0 0.17226015031337738
logits torch.Size([342, 4, 1024]) labels torch.Size([342, 4]) 0 1022
Curr loss timestep torch.Size([342, 4]) tensor([172,  51, 306, 224], device='cuda:0') tensor(51, device='cuda:0')
bi 0 loss 0.015348801389336586
bi 1 loss 0.01241675391793251
bi 2 loss 0.012404085136950016
bi 3 loss 0.016572341322898865
Layer  5  loss:  0.012573239393532276 0.0 0.2260507047176361
logits torch.Size([342, 4, 1024]) labels torch.Size([342, 4]) 0 1022
Curr loss timestep torch.Size([342, 4]) tensor([ 97,  72,  51, 234], device='cuda:0') tensor(51, device='cuda:0')
bi 0 loss 0.012180105783045292
bi 1 loss 0.013372886925935745
bi 2 loss 0.01185899693518877
bi 3 loss 0.013836970552802086
Layer  6  loss:  0.011610791087150574 0.0 0.20050086081027985
logits torch.Size([342, 4, 1024]) labels torch.Size([342, 4]) 0 1023
Curr loss timestep torch.Size([342, 4]) tensor([179,  51, 270, 176], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.010927536524832249
bi 1 loss 0.010255676694214344
bi 2 loss 0.01258500013500452
bi 3 loss 0.011793072335422039
Epoch 0: :   3%|▎         | 15415/600000 [02:52<1:49:09, v_num=12, reduced_train_loss=1.700, global_step=15413.0, consumed_samples=61656.0, train_step_timing in s=0.467]Epoch 0: :   3%|▎         | 15415/600000 [02:52<1:49:09, v_num=12, reduced_train_loss=0.0997, global_step=15414.0, consumed_samples=61660.0, train_step_timing in s=0.273]loss mask original None

First layer loss:  0.05407949909567833 torch.Size([474, 4]) 4.581066131591797 0.0
Max loss timestep torch.Size([474, 4]) tensor([257, 123, 453, 269], device='cuda:0') tensor(453, device='cuda:0')
bi 0 loss 0.046126801520586014
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 1 loss 0.018797440454363823
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 2 loss 0.06408585608005524
speech mask sum tensor(369, device='cuda:0') loss mask sum tensor(369, device='cuda:0')
bi 3 loss 0.08335772901773453
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
logits torch.Size([474, 4, 257024]) labels torch.Size([474, 4]) 0 257023
Layer  0  loss:  0.06610927730798721 0.0 4.778229713439941
logits torch.Size([474, 4, 1024]) labels torch.Size([474, 4]) 0 1023
Curr loss timestep torch.Size([474, 4]) tensor([257, 102, 452, 259], device='cuda:0') tensor(102, device='cuda:0')
bi 0 loss 0.05090373009443283
bi 1 loss 0.06253398954868317
bi 2 loss 0.07942453026771545
bi 3 loss 0.06490923464298248
Layer  1  loss:  0.05759244039654732 0.0 4.404603958129883
logits torch.Size([474, 4, 1024]) labels torch.Size([474, 4]) 0 1022
Curr loss timestep torch.Size([474, 4]) tensor([349, 145, 257, 265], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.05264369770884514
bi 1 loss 0.029417583718895912
bi 2 loss 0.06636960059404373
bi 3 loss 0.07412958145141602
Layer  2  loss:  0.0600941926240921 0.0 4.233180999755859
logits torch.Size([474, 4, 1024]) labels torch.Size([474, 4]) 0 1022
Curr loss timestep torch.Size([474, 4]) tensor([276, 139, 371, 241], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.058161575347185135
bi 1 loss 0.03402559086680412
bi 2 loss 0.07000697404146194
bi 3 loss 0.06135578081011772
Layer  3  loss:  0.06558042019605637 0.0 3.549983024597168
logits torch.Size([474, 4, 1024]) labels torch.Size([474, 4]) 0 1022
Curr loss timestep torch.Size([474, 4]) tensor([336, 109, 451, 269], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.02852724678814411
bi 1 loss 0.040810756385326385
bi 2 loss 0.09199120849370956
bi 3 loss 0.1044226884841919
Layer  4  loss:  0.05829419195652008 0.0 2.077787399291992
logits torch.Size([474, 4, 1024]) labels torch.Size([474, 4]) 0 1021
Curr loss timestep torch.Size([474, 4]) tensor([266,  67, 403, 280], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.030766427516937256
bi 1 loss 0.06104979291558266
bi 2 loss 0.0718376412987709
bi 3 loss 0.08338043838739395
Layer  5  loss:  0.05363193899393082 0.0 2.132781982421875
logits torch.Size([474, 4, 1024]) labels torch.Size([474, 4]) 0 1022
Curr loss timestep torch.Size([474, 4]) tensor([255,  57, 256, 258], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 0.03282967209815979
bi 1 loss 0.028881726786494255
bi 2 loss 0.06883279234170914
bi 3 loss 0.08738799393177032
Layer  6  loss:  0.05580814182758331 0.0 3.537553548812866
logits torch.Size([474, 4, 1024]) labels torch.Size([474, 4]) 0 1022
Curr loss timestep torch.Size([474, 4]) tensor([113,  58, 372, 272], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.043603282421827316
bi 1 loss 0.01853097416460514
bi 2 loss 0.08048367500305176
bi 3 loss 0.04598327726125717
Epoch 0: :   3%|▎         | 15416/600000 [02:53<1:49:23, v_num=12, reduced_train_loss=0.0997, global_step=15414.0, consumed_samples=61660.0, train_step_timing in s=0.273]Epoch 0: :   3%|▎         | 15416/600000 [02:53<1:49:23, v_num=12, reduced_train_loss=0.471, global_step=15415.0, consumed_samples=61664.0, train_step_timing in s=0.340] loss mask original None

First layer loss:  0.08296442031860352 torch.Size([515, 4]) 9.287635803222656 0.0
Max loss timestep torch.Size([515, 4]) tensor([340, 495, 267, 292], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.15099866688251495
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
bi 1 loss 0.09131041169166565
speech mask sum tensor(167, device='cuda:0') loss mask sum tensor(167, device='cuda:0')
bi 2 loss 0.03240760788321495
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
bi 3 loss 0.0512843132019043
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
logits torch.Size([515, 4, 257024]) labels torch.Size([515, 4]) 0 257023
Layer  0  loss:  0.07887912541627884 0.0 8.66378116607666
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([300, 472, 268, 320], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.04498572647571564
bi 1 loss 0.1154584065079689
bi 2 loss 0.08273399621248245
bi 3 loss 0.07818544656038284
Layer  1  loss:  0.05860596522688866 0.0 2.828739643096924
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1022
Curr loss timestep torch.Size([515, 4]) tensor([306, 446, 233, 297], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 0.0519823282957077
bi 1 loss 0.08899210393428802
bi 2 loss 0.04130621254444122
bi 3 loss 0.0638752356171608
Layer  2  loss:  0.07285492867231369 0.0 3.6823365688323975
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1022
Curr loss timestep torch.Size([515, 4]) tensor([324, 371, 268, 293], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.06893397867679596
bi 1 loss 0.11077549308538437
bi 2 loss 0.053882114589214325
bi 3 loss 0.0636214092373848
Layer  3  loss:  0.07320813089609146 0.0 5.587968826293945
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([328, 390, 263, 259], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.08308105170726776
bi 1 loss 0.09675328433513641
bi 2 loss 0.0523759089410305
bi 3 loss 0.06410712003707886
Layer  4  loss:  0.07641627639532089 0.0 2.7403275966644287
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([260, 468, 271, 291], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.06715704500675201
bi 1 loss 0.11562881618738174
bi 2 loss 0.05606399476528168
bi 3 loss 0.07976540923118591
Layer  5  loss:  0.07900533080101013 0.0 3.4737327098846436
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([320, 495, 268, 295], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.09260243922472
bi 1 loss 0.07655215263366699
bi 2 loss 0.05954138934612274
bi 3 loss 0.10331336408853531
Layer  6  loss:  0.0839156061410904 0.0 5.015183448791504
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([224, 495, 268, 295], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.0772252231836319
bi 1 loss 0.12729978561401367
bi 2 loss 0.07807798683643341
bi 3 loss 0.03811599686741829
Epoch 0: :   3%|▎         | 15417/600000 [02:53<1:49:37, v_num=12, reduced_train_loss=0.471, global_step=15415.0, consumed_samples=61664.0, train_step_timing in s=0.340]Epoch 0: :   3%|▎         | 15417/600000 [02:53<1:49:37, v_num=12, reduced_train_loss=0.606, global_step=15416.0, consumed_samples=61668.0, train_step_timing in s=0.356]loss mask original None

First layer loss:  0.08893541991710663 torch.Size([494, 4]) 7.791972637176514 0.0
Max loss timestep torch.Size([494, 4]) tensor([254, 174, 355, 259], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.08062204718589783
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 1 loss 0.0768488347530365
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 2 loss 0.07188741862773895
speech mask sum tensor(299, device='cuda:0') loss mask sum tensor(299, device='cuda:0')
bi 3 loss 0.11411073803901672
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
logits torch.Size([494, 4, 257024]) labels torch.Size([494, 4]) 0 257022
Layer  0  loss:  0.11022365838289261 0.0 9.410430908203125
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1023
Curr loss timestep torch.Size([494, 4]) tensor([279, 191, 354, 259], device='cuda:0') tensor(354, device='cuda:0')
bi 0 loss 0.15283788740634918
bi 1 loss 0.03745982050895691
bi 2 loss 0.10244698077440262
bi 3 loss 0.15370358526706696
Layer  1  loss:  0.08615442365407944 0.0 6.214015007019043
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1022
Curr loss timestep torch.Size([494, 4]) tensor([279, 218, 355, 258], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.10578407347202301
bi 1 loss 0.04027058556675911
bi 2 loss 0.08736099302768707
bi 3 loss 0.10957738012075424
Layer  2  loss:  0.1172601729631424 0.0 8.221283912658691
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1023
Curr loss timestep torch.Size([494, 4]) tensor([279, 259, 354, 259], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.12567570805549622
bi 1 loss 0.06688746809959412
bi 2 loss 0.1282457709312439
bi 3 loss 0.13703672587871552
Layer  3  loss:  0.12305311113595963 0.0 14.169574737548828
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1022
Curr loss timestep torch.Size([494, 4]) tensor([279, 172, 356, 258], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.1423957496881485
bi 1 loss 0.05717596039175987
bi 2 loss 0.11348313838243484
bi 3 loss 0.16906613111495972
Layer  4  loss:  0.09805993735790253 0.0 7.158945083618164
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1022
Curr loss timestep torch.Size([494, 4]) tensor([292, 270, 354, 259], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.049797024577856064
bi 1 loss 0.04423060640692711
bi 2 loss 0.0974956527352333
bi 3 loss 0.1433735489845276
Layer  5  loss:  0.10883299261331558 0.0 9.337345123291016
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1023
Curr loss timestep torch.Size([494, 4]) tensor([279, 207, 356, 258], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.17919030785560608
bi 1 loss 0.043585631996393204
bi 2 loss 0.10197015106678009
bi 3 loss 0.14049948751926422
Layer  6  loss:  0.10494527220726013 0.0 7.299543380737305
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1023
Curr loss timestep torch.Size([494, 4]) tensor([279,  95, 356, 259], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.1398105025291443
bi 1 loss 0.04717292636632919
bi 2 loss 0.09512901306152344
bi 3 loss 0.14258599281311035
Epoch 0: :   3%|▎         | 15418/600000 [02:53<1:49:51, v_num=12, reduced_train_loss=0.606, global_step=15416.0, consumed_samples=61668.0, train_step_timing in s=0.356]Epoch 0: :   3%|▎         | 15418/600000 [02:53<1:49:51, v_num=12, reduced_train_loss=0.837, global_step=15417.0, consumed_samples=61672.0, train_step_timing in s=0.344]loss mask original None

First layer loss:  0.14522682130336761 torch.Size([541, 4]) 10.251163482666016 0.0
Max loss timestep torch.Size([541, 4]) tensor([403, 348, 216, 369], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.13424229621887207
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
bi 1 loss 0.17241765558719635
speech mask sum tensor(251, device='cuda:0') loss mask sum tensor(251, device='cuda:0')
bi 2 loss 0.04299177974462509
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
bi 3 loss 0.19253136217594147
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
logits torch.Size([541, 4, 257024]) labels torch.Size([541, 4]) 0 257023
Layer  0  loss:  0.21369245648384094 0.0 11.033556938171387
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([437, 348, 143, 322], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.1519816815853119
bi 1 loss 0.2273636907339096
bi 2 loss 0.05505158379673958
bi 3 loss 0.36560550332069397
Layer  1  loss:  0.23857168853282928 0.0 16.79694938659668
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([402, 349, 260, 299], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.18296262621879578
bi 1 loss 0.3066636025905609
bi 2 loss 0.07209108024835587
bi 3 loss 0.3361908793449402
Layer  2  loss:  0.20824678242206573 0.0 10.191030502319336
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([403, 500, 189, 322], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.16731052100658417
bi 1 loss 0.2435372918844223
bi 2 loss 0.05503738671541214
bi 3 loss 0.31245020031929016
Layer  3  loss:  0.23394104838371277 0.0 11.136659622192383
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([403, 348, 229, 325], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.23606868088245392
bi 1 loss 0.2845627963542938
bi 2 loss 0.09197470545768738
bi 3 loss 0.26739415526390076
Layer  4  loss:  0.2680181860923767 0.0 11.53764820098877
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([305, 349, 213, 317], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.2351430207490921
bi 1 loss 0.38248297572135925
bi 2 loss 0.07297533005475998
bi 3 loss 0.3122170865535736
Layer  5  loss:  0.23569834232330322 0.0 9.513506889343262
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([403, 348, 221, 377], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.2396206110715866
bi 1 loss 0.2225993275642395
bi 2 loss 0.059684306383132935
bi 3 loss 0.3480994999408722
Layer  6  loss:  0.2967120110988617 0.0 14.76301383972168
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1021
Curr loss timestep torch.Size([541, 4]) tensor([403, 500, 218, 322], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.2523864805698395
bi 1 loss 0.3122785985469818
bi 2 loss 0.05948938429355621
bi 3 loss 0.4734642207622528
Epoch 0: :   3%|▎         | 15419/600000 [02:54<1:50:06, v_num=12, reduced_train_loss=0.837, global_step=15417.0, consumed_samples=61672.0, train_step_timing in s=0.344]Epoch 0: :   3%|▎         | 15419/600000 [02:54<1:50:06, v_num=12, reduced_train_loss=1.840, global_step=15418.0, consumed_samples=61676.0, train_step_timing in s=0.371]loss mask original None

First layer loss:  4.258295059204102 torch.Size([532, 4]) 11.325143814086914 0.0
Max loss timestep torch.Size([532, 4]) tensor([160, 224,  78, 254], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 4.223818778991699
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
bi 1 loss 4.122304916381836
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 2 loss 4.448994159698486
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 3 loss 4.181858062744141
speech mask sum tensor(376, device='cuda:0') loss mask sum tensor(376, device='cuda:0')
logits torch.Size([532, 4, 257024]) labels torch.Size([532, 4]) 0 257022
Layer  0  loss:  4.929864406585693 0.0 11.17205810546875
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1023
Curr loss timestep torch.Size([532, 4]) tensor([363, 336, 110, 362], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 5.129523277282715
bi 1 loss 4.791807651519775
bi 2 loss 4.951064586639404
bi 3 loss 4.842811584472656
Layer  1  loss:  5.145815372467041 0.0 10.033613204956055
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1022
Curr loss timestep torch.Size([532, 4]) tensor([314, 361, 203, 439], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 5.258419990539551
bi 1 loss 4.888408660888672
bi 2 loss 5.2234206199646
bi 3 loss 5.1503095626831055
Layer  2  loss:  5.325963973999023 0.0 10.414278030395508
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1022
Curr loss timestep torch.Size([532, 4]) tensor([164, 293, 132, 477], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 5.43118953704834
bi 1 loss 5.07912015914917
bi 2 loss 5.476288318634033
bi 3 loss 5.2547407150268555
Layer  3  loss:  5.4153008460998535 0.0 10.16153335571289
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1022
Curr loss timestep torch.Size([532, 4]) tensor([336, 235,  96, 327], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 5.552386283874512
bi 1 loss 5.138924598693848
bi 2 loss 5.631445407867432
bi 3 loss 5.271302223205566
Layer  4  loss:  5.480233669281006 0.0 10.638023376464844
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1022
Curr loss timestep torch.Size([532, 4]) tensor([170, 394, 425, 466], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 5.554039001464844
bi 1 loss 5.306448459625244
bi 2 loss 5.642196178436279
bi 3 loss 5.372834205627441
Layer  5  loss:  5.487611770629883 0.0 9.746922492980957
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1022
Curr loss timestep torch.Size([532, 4]) tensor([267, 196, 334, 371], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 5.619150638580322
bi 1 loss 5.130861282348633
bi 2 loss 5.723938465118408
bi 3 loss 5.381424903869629
Layer  6  loss:  5.559489727020264 0.0 10.569372177124023
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1023
Curr loss timestep torch.Size([532, 4]) tensor([258, 238, 302, 483], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 5.792093276977539
bi 1 loss 5.206262588500977
bi 2 loss 5.7342753410339355
bi 3 loss 5.433845520019531
High loss detected
Logging training audio
Epoch 0: :   3%|▎         | 15420/600000 [02:54<1:50:30, v_num=12, reduced_train_loss=1.840, global_step=15418.0, consumed_samples=61676.0, train_step_timing in s=0.371]Epoch 0: :   3%|▎         | 15420/600000 [02:54<1:50:30, v_num=12, reduced_train_loss=41.60, global_step=15419.0, consumed_samples=61680.0, train_step_timing in s=0.605]loss mask original None

First layer loss:  0.25016894936561584 torch.Size([749, 4]) 12.287641525268555 0.0
Max loss timestep torch.Size([749, 4]) tensor([532, 318, 673, 202], device='cuda:0') tensor(532, device='cuda:0')
bi 0 loss 0.2533082664012909
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
bi 1 loss 0.11581389605998993
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
bi 2 loss 0.40499481558799744
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 3 loss 0.06344348192214966
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
logits torch.Size([749, 4, 257024]) labels torch.Size([749, 4]) 0 257022
Layer  0  loss:  0.29315680265426636 0.0 15.239672660827637
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1023
Curr loss timestep torch.Size([749, 4]) tensor([433, 318, 471, 140], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.20291830599308014
bi 1 loss 0.20780809223651886
bi 2 loss 0.4757841229438782
bi 3 loss 0.07792676985263824
Layer  1  loss:  0.3251863420009613 0.0 14.375816345214844
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([533, 321, 532, 169], device='cuda:0') tensor(532, device='cuda:0')
bi 0 loss 0.26307743787765503
bi 1 loss 0.2633712887763977
bi 2 loss 0.48670199513435364
bi 3 loss 0.03461071103811264
Layer  2  loss:  0.3552330732345581 0.0 15.02082347869873
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([429, 320, 317, 209], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.2749987542629242
bi 1 loss 0.21801158785820007
bi 2 loss 0.5929463505744934
bi 3 loss 0.06278815120458603
Layer  3  loss:  0.3826614022254944 0.0 18.102519989013672
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([532, 318, 673, 214], device='cuda:0') tensor(532, device='cuda:0')
bi 0 loss 0.28492262959480286
bi 1 loss 0.333351194858551
bi 2 loss 0.5676386952400208
bi 3 loss 0.048513829708099365
Layer  4  loss:  0.340452641248703 0.0 14.484800338745117
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([429, 458, 532, 185], device='cuda:0') tensor(532, device='cuda:0')
bi 0 loss 0.29013967514038086
bi 1 loss 0.2593095004558563
bi 2 loss 0.5044107437133789
bi 3 loss 0.07547371834516525
Layer  5  loss:  0.3537387549877167 0.0 14.058443069458008
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([533, 321, 314, 173], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.2840104401111603
bi 1 loss 0.25191476941108704
bi 2 loss 0.5404026508331299
bi 3 loss 0.12194611132144928
Layer  6  loss:  0.34194135665893555 0.0 15.680095672607422
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([533, 321, 674, 158], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.2315680831670761
bi 1 loss 0.28897351026535034
bi 2 loss 0.5254126787185669
bi 3 loss 0.06373638659715652
Epoch 0: :   3%|▎         | 15421/600000 [02:55<1:50:50, v_num=12, reduced_train_loss=41.60, global_step=15419.0, consumed_samples=61680.0, train_step_timing in s=0.605]Epoch 0: :   3%|▎         | 15421/600000 [02:55<1:50:50, v_num=12, reduced_train_loss=2.640, global_step=15420.0, consumed_samples=61684.0, train_step_timing in s=0.504]loss mask original None

First layer loss:  0.07802031189203262 torch.Size([569, 4]) 10.096071243286133 0.0
Max loss timestep torch.Size([569, 4]) tensor([265, 392, 153, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.050911858677864075
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 1 loss 0.09059092402458191
speech mask sum tensor(359, device='cuda:0') loss mask sum tensor(359, device='cuda:0')
bi 2 loss 0.03522031381726265
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 3 loss 0.08606886118650436
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
logits torch.Size([569, 4, 257024]) labels torch.Size([569, 4]) 0 257023
Layer  0  loss:  0.0922180786728859 0.0 5.514002323150635
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([183, 361, 177, 533], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.05898279696702957
bi 1 loss 0.09996133297681808
bi 2 loss 0.03297428414225578
bi 3 loss 0.10962064564228058
Layer  1  loss:  0.09270761907100677 0.0 4.859592437744141
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([249, 361, 169, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.055720750242471695
bi 1 loss 0.07008110731840134
bi 2 loss 0.04395134001970291
bi 3 loss 0.13201649487018585
Layer  2  loss:  0.1053021177649498 0.0 7.169305324554443
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([238, 361, 148, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.07714158296585083
bi 1 loss 0.11402825266122818
bi 2 loss 0.03832331672310829
bi 3 loss 0.12241261452436447
Layer  3  loss:  0.08969353139400482 0.0 8.41397762298584
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([218, 361, 154, 439], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.06255330890417099
bi 1 loss 0.07104611396789551
bi 2 loss 0.05068635940551758
bi 3 loss 0.12088919430971146
Layer  4  loss:  0.09285056591033936 0.0 7.040053844451904
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([208, 361, 152, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.06871998310089111
bi 1 loss 0.06586253643035889
bi 2 loss 0.041693393141031265
bi 3 loss 0.1325651854276657
Layer  5  loss:  0.10090161859989166 0.0 8.364832878112793
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([159, 361, 160, 439], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.053352415561676025
bi 1 loss 0.10128703713417053
bi 2 loss 0.03183761239051819
bi 3 loss 0.1302645057439804
Layer  6  loss:  0.0987635925412178 0.0 5.825324058532715
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1021
Curr loss timestep torch.Size([569, 4]) tensor([259, 361, 127, 530], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.0856325775384903
bi 1 loss 0.07193300127983093
bi 2 loss 0.03132113069295883
bi 3 loss 0.13924965262413025
Epoch 0: :   3%|▎         | 15422/600000 [02:55<1:51:06, v_num=12, reduced_train_loss=2.640, global_step=15420.0, consumed_samples=61684.0, train_step_timing in s=0.504]Epoch 0: :   3%|▎         | 15422/600000 [02:55<1:51:06, v_num=12, reduced_train_loss=0.750, global_step=15421.0, consumed_samples=61688.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  0.11430075764656067 torch.Size([506, 4]) 9.238836288452148 0.0
Max loss timestep torch.Size([506, 4]) tensor([441, 309, 183, 339], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.09932290762662888
speech mask sum tensor(336, device='cuda:0') loss mask sum tensor(336, device='cuda:0')
bi 1 loss 0.13250455260276794
speech mask sum tensor(371, device='cuda:0') loss mask sum tensor(371, device='cuda:0')
bi 2 loss 0.04953815042972565
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.13174253702163696
speech mask sum tensor(462, device='cuda:0') loss mask sum tensor(462, device='cuda:0')
logits torch.Size([506, 4, 257024]) labels torch.Size([506, 4]) 0 257023
Layer  0  loss:  0.1291957050561905 0.0 7.6047468185424805
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([439, 286, 115, 341], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 0.167394757270813
bi 1 loss 0.1288679838180542
bi 2 loss 0.07685217261314392
bi 3 loss 0.11878567934036255
Layer  1  loss:  0.14485572278499603 0.0 17.19539451599121
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([441, 289,  95, 338], device='cuda:0') tensor(441, device='cuda:0')
bi 0 loss 0.15608882904052734
bi 1 loss 0.15333746373653412
bi 2 loss 0.05380606651306152
bi 3 loss 0.15963374078273773
Layer  2  loss:  0.1563372015953064 0.0 9.270176887512207
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([439, 309, 182, 339], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.185482919216156
bi 1 loss 0.16700081527233124
bi 2 loss 0.043438348919153214
bi 3 loss 0.16347691416740417
Layer  3  loss:  0.16006143391132355 0.0 10.937620162963867
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([438, 289, 160, 338], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.18248578906059265
bi 1 loss 0.19028852880001068
bi 2 loss 0.07608034461736679
bi 3 loss 0.14692792296409607
Layer  4  loss:  0.16208526492118835 0.0 11.371540069580078
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([439, 368, 102, 338], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.175350159406662
bi 1 loss 0.1813683956861496
bi 2 loss 0.05408957600593567
bi 3 loss 0.1722504198551178
Layer  5  loss:  0.15593881905078888 0.0 8.958026885986328
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1021
Curr loss timestep torch.Size([506, 4]) tensor([439, 309, 107, 339], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.18933534622192383
bi 1 loss 0.20473021268844604
bi 2 loss 0.06094059720635414
bi 3 loss 0.1235186904668808
Layer  6  loss:  0.15936195850372314 0.0 15.887413024902344
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1021
Curr loss timestep torch.Size([506, 4]) tensor([439, 289, 175, 339], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.21610520780086517
bi 1 loss 0.1998170167207718
bi 2 loss 0.04001781344413757
bi 3 loss 0.12461397051811218
Epoch 0: :   3%|▎         | 15423/600000 [02:56<1:51:21, v_num=12, reduced_train_loss=0.750, global_step=15421.0, consumed_samples=61688.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15423/600000 [02:56<1:51:21, v_num=12, reduced_train_loss=1.180, global_step=15422.0, consumed_samples=61692.0, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.04365326091647148 torch.Size([358, 4]) 6.859786033630371 0.0
Max loss timestep torch.Size([358, 4]) tensor([178,  52, 202, 225], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 0.02496124617755413
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 1 loss 0.025269655510783195
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
bi 2 loss 0.1281060427427292
speech mask sum tensor(144, device='cuda:0') loss mask sum tensor(144, device='cuda:0')
bi 3 loss 0.024888930842280388
speech mask sum tensor(200, device='cuda:0') loss mask sum tensor(200, device='cuda:0')
logits torch.Size([358, 4, 257024]) labels torch.Size([358, 4]) 0 257023
Layer  0  loss:  0.029646912589669228 0.0 1.3929579257965088
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1023
Curr loss timestep torch.Size([358, 4]) tensor([196, 101, 274, 237], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 0.03271549567580223
bi 1 loss 0.025954511016607285
bi 2 loss 0.05218340456485748
bi 3 loss 0.01702055148780346
Layer  1  loss:  0.02685127966105938 0.0 1.0501943826675415
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([187, 318, 272, 151], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.02690550684928894
bi 1 loss 0.025542553514242172
bi 2 loss 0.039540715515613556
bi 3 loss 0.019724536687135696
Layer  2  loss:  0.027526048943400383 0.0 0.5893663167953491
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([174, 321, 231, 216], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 0.022100776433944702
bi 1 loss 0.022513875737786293
bi 2 loss 0.04610911384224892
bi 3 loss 0.02584224008023739
Layer  3  loss:  0.029062464833259583 0.0 0.9887382388114929
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1023
Curr loss timestep torch.Size([358, 4]) tensor([173,  82, 218,  95], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 0.02401491068303585
bi 1 loss 0.027047764509916306
bi 2 loss 0.045440658926963806
bi 3 loss 0.024006931111216545
Layer  4  loss:  0.027573563158512115 0.0 0.5417250990867615
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([ 96, 198, 276, 124], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 0.030346877872943878
bi 1 loss 0.028283201158046722
bi 2 loss 0.032610222697257996
bi 3 loss 0.02086753211915493
Layer  5  loss:  0.026572711765766144 0.0 0.33531931042671204
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([192, 108, 314, 168], device='cuda:0') tensor(156, device='cuda:0')
bi 0 loss 0.01936470717191696
bi 1 loss 0.025987839326262474
bi 2 loss 0.04272015392780304
bi 3 loss 0.020979560911655426
Layer  6  loss:  0.027009660378098488 0.0 0.43830811977386475
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1023
Curr loss timestep torch.Size([358, 4]) tensor([115, 250, 272, 103], device='cuda:0') tensor(103, device='cuda:0')
bi 0 loss 0.026065461337566376
bi 1 loss 0.025115426629781723
bi 2 loss 0.03361758962273598
bi 3 loss 0.02588680200278759
Epoch 0: :   3%|▎         | 15424/600000 [02:56<1:51:32, v_num=12, reduced_train_loss=1.180, global_step=15422.0, consumed_samples=61692.0, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15424/600000 [02:56<1:51:32, v_num=12, reduced_train_loss=0.238, global_step=15423.0, consumed_samples=61696.0, train_step_timing in s=0.277]loss mask original None

First layer loss:  0.0129325482994318 torch.Size([379, 4]) 0.14439164102077484 0.0
Max loss timestep torch.Size([379, 4]) tensor([191, 242, 172, 121], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 0.012742743827402592
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 1 loss 0.014423106797039509
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
bi 2 loss 0.012821593321859837
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 3 loss 0.012388021685183048
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
logits torch.Size([379, 4, 257024]) labels torch.Size([379, 4]) 0 257022
Layer  0  loss:  0.012704803608357906 0.0 0.17262433469295502
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1023
Curr loss timestep torch.Size([379, 4]) tensor([344, 194, 109, 153], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 0.015062319114804268
bi 1 loss 0.011605323292315006
bi 2 loss 0.00962824933230877
bi 3 loss 0.011552893556654453
Layer  1  loss:  0.011518592946231365 0.0 0.24248717725276947
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1023
Curr loss timestep torch.Size([379, 4]) tensor([ 78, 188, 135, 238], device='cuda:0') tensor(135, device='cuda:0')
bi 0 loss 0.013408477418124676
bi 1 loss 0.0095078619197011
bi 2 loss 0.01105150394141674
bi 3 loss 0.010207521729171276
Layer  2  loss:  0.013049566186964512 0.0 0.2907932698726654
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1023
Curr loss timestep torch.Size([379, 4]) tensor([304, 208, 171, 117], device='cuda:0') tensor(117, device='cuda:0')
bi 0 loss 0.013696637935936451
bi 1 loss 0.014571163803339005
bi 2 loss 0.009684261865913868
bi 3 loss 0.012986870482563972
Layer  3  loss:  0.011571355164051056 0.0 0.2720443308353424
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1022
Curr loss timestep torch.Size([379, 4]) tensor([340, 201, 104, 276], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.013194750063121319
bi 1 loss 0.012466393411159515
bi 2 loss 0.009622614830732346
bi 3 loss 0.009715115651488304
Layer  4  loss:  0.01205506268888712 0.0 0.21033644676208496
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1023
Curr loss timestep torch.Size([379, 4]) tensor([304, 223, 100, 191], device='cuda:0') tensor(151, device='cuda:0')
bi 0 loss 0.01330638024955988
bi 1 loss 0.01394115574657917
bi 2 loss 0.007942883297801018
bi 3 loss 0.01129432674497366
Layer  5  loss:  0.012857112102210522 0.0 0.24740873277187347
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1022
Curr loss timestep torch.Size([379, 4]) tensor([339, 177, 102, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.014884951524436474
bi 1 loss 0.014351323246955872
bi 2 loss 0.008943513035774231
bi 3 loss 0.0110960453748703
Layer  6  loss:  0.011651985347270966 0.0 0.34022068977355957
logits torch.Size([379, 4, 1024]) labels torch.Size([379, 4]) 0 1020
Curr loss timestep torch.Size([379, 4]) tensor([263, 212, 111, 278], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.01357019692659378
bi 1 loss 0.013021075166761875
bi 2 loss 0.010744329541921616
bi 3 loss 0.008540221489965916
Epoch 0: :   3%|▎         | 15425/600000 [02:56<1:51:44, v_num=12, reduced_train_loss=0.238, global_step=15423.0, consumed_samples=61696.0, train_step_timing in s=0.277]Epoch 0: :   3%|▎         | 15425/600000 [02:56<1:51:44, v_num=12, reduced_train_loss=0.0983, global_step=15424.0, consumed_samples=61700.0, train_step_timing in s=0.290]loss mask original None

First layer loss:  0.08249442279338837 torch.Size([482, 4]) 9.574955940246582 0.0
Max loss timestep torch.Size([482, 4]) tensor([ 97, 331, 285, 285], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.03401371091604233
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 0.12344219535589218
speech mask sum tensor(363, device='cuda:0') loss mask sum tensor(363, device='cuda:0')
bi 2 loss 0.05421735718846321
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 3 loss 0.07020574808120728
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
logits torch.Size([482, 4, 257024]) labels torch.Size([482, 4]) 0 257022
Layer  0  loss:  0.050445325672626495 0.0 5.278883457183838
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([ 48, 388, 251, 285], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.03255762159824371
bi 1 loss 0.036946430802345276
bi 2 loss 0.050766244530677795
bi 3 loss 0.09536755830049515
Layer  1  loss:  0.05128674954175949 0.0 2.9093127250671387
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([ 58, 343, 331, 285], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.03252246603369713
bi 1 loss 0.052063945680856705
bi 2 loss 0.043844208121299744
bi 3 loss 0.07629144936800003
Layer  2  loss:  0.049803316593170166 0.0 6.791543006896973
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([ 91, 316, 312, 282], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.023326244205236435
bi 1 loss 0.0337822325527668
bi 2 loss 0.04938129335641861
bi 3 loss 0.10843788087368011
Layer  3  loss:  0.05586251989006996 0.0 4.124927043914795
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([ 86, 271, 350, 285], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.019356006756424904
bi 1 loss 0.062378477305173874
bi 2 loss 0.04055584594607353
bi 3 loss 0.09405407309532166
Layer  4  loss:  0.04968491569161415 0.0 4.160945415496826
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([ 52, 451, 378, 282], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.031758587807416916
bi 1 loss 0.05500972270965576
bi 2 loss 0.02963174320757389
bi 3 loss 0.08486499637365341
Layer  5  loss:  0.049657534807920456 0.0 5.2937331199646
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([118, 161, 308, 282], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.032483942806720734
bi 1 loss 0.03941929712891579
bi 2 loss 0.04410798102617264
bi 3 loss 0.09635964035987854
Layer  6  loss:  0.051211997866630554 0.0 5.621307373046875
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([ 84, 319, 246, 282], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.03080151602625847
bi 1 loss 0.05214976891875267
bi 2 loss 0.03929406404495239
bi 3 loss 0.08473680168390274
Epoch 0: :   3%|▎         | 15426/600000 [02:57<1:51:58, v_num=12, reduced_train_loss=0.0983, global_step=15424.0, consumed_samples=61700.0, train_step_timing in s=0.290]Epoch 0: :   3%|▎         | 15426/600000 [02:57<1:51:58, v_num=12, reduced_train_loss=0.440, global_step=15425.0, consumed_samples=61704.0, train_step_timing in s=0.337] loss mask original None

First layer loss:  0.024475222453475 torch.Size([467, 4]) 0.5543868541717529 0.0
Max loss timestep torch.Size([467, 4]) tensor([415, 201, 180, 198], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.03642183169722557
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 1 loss 0.014914997853338718
speech mask sum tensor(54, device='cuda:0') loss mask sum tensor(54, device='cuda:0')
bi 2 loss 0.0240734051913023
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 3 loss 0.016206545755267143
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
logits torch.Size([467, 4, 257024]) labels torch.Size([467, 4]) 0 257022
Layer  0  loss:  0.028014957904815674 0.0 1.1038291454315186
logits torch.Size([467, 4, 1024]) labels torch.Size([467, 4]) 0 1023
Curr loss timestep torch.Size([467, 4]) tensor([344, 226, 117, 131], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.04307492449879646
bi 1 loss 0.025702886283397675
bi 2 loss 0.024625005200505257
bi 3 loss 0.018183071166276932
Layer  1  loss:  0.02900467813014984 0.0 0.7925090789794922
logits torch.Size([467, 4, 1024]) labels torch.Size([467, 4]) 0 1023
Curr loss timestep torch.Size([467, 4]) tensor([329, 204, 215, 204], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.04392772912979126
bi 1 loss 0.020030943676829338
bi 2 loss 0.027372997254133224
bi 3 loss 0.01920495182275772
Layer  2  loss:  0.02674287185072899 0.0 0.8427178859710693
logits torch.Size([467, 4, 1024]) labels torch.Size([467, 4]) 0 1022
Curr loss timestep torch.Size([467, 4]) tensor([339, 216, 300, 190], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.04068632796406746
bi 1 loss 0.01662709005177021
bi 2 loss 0.02643425203859806
bi 3 loss 0.01650373637676239
Layer  3  loss:  0.023325923830270767 0.0 0.4645315408706665
logits torch.Size([467, 4, 1024]) labels torch.Size([467, 4]) 0 1023
Curr loss timestep torch.Size([467, 4]) tensor([389, 213, 300, 218], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 0.02874460071325302
bi 1 loss 0.018961437046527863
bi 2 loss 0.021176796406507492
bi 3 loss 0.022318536415696144
Layer  4  loss:  0.0268686693161726 0.0 0.9399734139442444
logits torch.Size([467, 4, 1024]) labels torch.Size([467, 4]) 0 1011
Curr loss timestep torch.Size([467, 4]) tensor([342, 209, 279, 210], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.031595584005117416
bi 1 loss 0.020594093948602676
bi 2 loss 0.03383782505989075
bi 3 loss 0.014565430581569672
Layer  5  loss:  0.02204238437116146 0.0 0.46888789534568787
logits torch.Size([467, 4, 1024]) labels torch.Size([467, 4]) 0 1023
Curr loss timestep torch.Size([467, 4]) tensor([364, 212, 248, 210], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.03520165756344795
bi 1 loss 0.012758119963109493
bi 2 loss 0.021083027124404907
bi 3 loss 0.013215411454439163
Layer  6  loss:  0.023906134068965912 0.0 0.38754570484161377
logits torch.Size([467, 4, 1024]) labels torch.Size([467, 4]) 0 1022
Curr loss timestep torch.Size([467, 4]) tensor([416, 195, 185, 242], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 0.034443944692611694
bi 1 loss 0.01788950525224209
bi 2 loss 0.024488935247063637
bi 3 loss 0.014462904073297977
Epoch 0: :   3%|▎         | 15427/600000 [02:57<1:52:12, v_num=12, reduced_train_loss=0.440, global_step=15425.0, consumed_samples=61704.0, train_step_timing in s=0.337]Epoch 0: :   3%|▎         | 15427/600000 [02:57<1:52:12, v_num=12, reduced_train_loss=0.204, global_step=15426.0, consumed_samples=61708.0, train_step_timing in s=0.345]loss mask original None

First layer loss:  0.05132819712162018 torch.Size([663, 4]) 3.108238697052002 0.0
Max loss timestep torch.Size([663, 4]) tensor([296, 216, 256, 630], device='cuda:0') tensor(630, device='cuda:0')
bi 0 loss 0.04289074242115021
speech mask sum tensor(188, device='cuda:0') loss mask sum tensor(188, device='cuda:0')
bi 1 loss 0.022084621712565422
speech mask sum tensor(116, device='cuda:0') loss mask sum tensor(116, device='cuda:0')
bi 2 loss 0.029468920081853867
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 3 loss 0.06465896964073181
speech mask sum tensor(503, device='cuda:0') loss mask sum tensor(503, device='cuda:0')
logits torch.Size([663, 4, 257024]) labels torch.Size([663, 4]) 0 257022
Layer  0  loss:  0.052987273782491684 0.0 2.7054429054260254
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1023
Curr loss timestep torch.Size([663, 4]) tensor([201, 230, 241, 572], device='cuda:0') tensor(572, device='cuda:0')
bi 0 loss 0.04879502207040787
bi 1 loss 0.027945462614297867
bi 2 loss 0.03233566880226135
bi 3 loss 0.06357268989086151
Layer  1  loss:  0.06831373274326324 0.0 5.753485202789307
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1022
Curr loss timestep torch.Size([663, 4]) tensor([304, 159, 239, 443], device='cuda:0') tensor(443, device='cuda:0')
bi 0 loss 0.05902761220932007
bi 1 loss 0.040222153067588806
bi 2 loss 0.04269126057624817
bi 3 loss 0.08228708058595657
Layer  2  loss:  0.07070554047822952 0.0 4.68840217590332
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1023
Curr loss timestep torch.Size([663, 4]) tensor([181, 161, 253, 630], device='cuda:0') tensor(630, device='cuda:0')
bi 0 loss 0.050739895552396774
bi 1 loss 0.017748234793543816
bi 2 loss 0.03729976713657379
bi 3 loss 0.0956273004412651
Layer  3  loss:  0.06759889423847198 0.0 7.1687517166137695
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1021
Curr loss timestep torch.Size([663, 4]) tensor([298, 226, 227, 630], device='cuda:0') tensor(630, device='cuda:0')
bi 0 loss 0.04264378920197487
bi 1 loss 0.024987397715449333
bi 2 loss 0.02555117942392826
bi 3 loss 0.09335687011480331
Layer  4  loss:  0.0714138075709343 0.0 2.6304616928100586
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1022
Curr loss timestep torch.Size([663, 4]) tensor([286, 144, 225, 568], device='cuda:0') tensor(568, device='cuda:0')
bi 0 loss 0.09135493636131287
bi 1 loss 0.036035940051078796
bi 2 loss 0.020904963836073875
bi 3 loss 0.08005218207836151
Layer  5  loss:  0.06952914595603943 0.0 7.789498805999756
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1022
Curr loss timestep torch.Size([663, 4]) tensor([267, 194, 261, 630], device='cuda:0') tensor(630, device='cuda:0')
bi 0 loss 0.05585680529475212
bi 1 loss 0.04085038602352142
bi 2 loss 0.044690441340208054
bi 3 loss 0.08515419811010361
Layer  6  loss:  0.050272177904844284 0.0 3.0942349433898926
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1022
Curr loss timestep torch.Size([663, 4]) tensor([202, 200, 238, 499], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.04959261044859886
bi 1 loss 0.02110336907207966
bi 2 loss 0.014849810861051083
bi 3 loss 0.062816321849823
Epoch 0: :   3%|▎         | 15428/600000 [02:58<1:52:30, v_num=12, reduced_train_loss=0.204, global_step=15426.0, consumed_samples=61708.0, train_step_timing in s=0.345]Epoch 0: :   3%|▎         | 15428/600000 [02:58<1:52:30, v_num=12, reduced_train_loss=0.502, global_step=15427.0, consumed_samples=61712.0, train_step_timing in s=0.459]loss mask original None

First layer loss:  0.14479057490825653 torch.Size([561, 4]) 9.522561073303223 0.0
Max loss timestep torch.Size([561, 4]) tensor([376, 206, 542, 333], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.17945267260074615
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 1 loss 0.03580859676003456
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 2 loss 0.15970337390899658
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
bi 3 loss 0.13212253153324127
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257022
Layer  0  loss:  0.15768393874168396 0.0 14.582064628601074
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([376, 207, 542, 333], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.2172573357820511
bi 1 loss 0.04136567562818527
bi 2 loss 0.17181900143623352
bi 3 loss 0.10893850028514862
Layer  1  loss:  0.16818749904632568 0.0 10.413980484008789
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([352, 237, 542, 332], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.2461158186197281
bi 1 loss 0.05341673642396927
bi 2 loss 0.18906466662883759
bi 3 loss 0.0764838233590126
Layer  2  loss:  0.17740368843078613 0.0 10.565631866455078
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([375, 145, 527, 331], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.24073410034179688
bi 1 loss 0.02920834720134735
bi 2 loss 0.17890937626361847
bi 3 loss 0.16337403655052185
Layer  3  loss:  0.18027852475643158 0.0 9.656152725219727
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([376, 176, 542, 285], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.2704774737358093
bi 1 loss 0.04684467241168022
bi 2 loss 0.15034069120883942
bi 3 loss 0.16254280507564545
Layer  4  loss:  0.21785862743854523 0.0 14.158154487609863
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([376, 149, 542, 332], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.3194665312767029
bi 1 loss 0.02653166651725769
bi 2 loss 0.21199627220630646
bi 3 loss 0.17893745005130768
Layer  5  loss:  0.22413188219070435 0.0 13.556042671203613
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([344, 182, 542, 287], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.3237236440181732
bi 1 loss 0.047497499734163284
bi 2 loss 0.21137301623821259
bi 3 loss 0.1903822124004364
Layer  6  loss:  0.19682247936725616 0.0 13.862281799316406
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([376, 148, 542, 331], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.27120324969291687
bi 1 loss 0.03473713621497154
bi 2 loss 0.184001624584198
bi 3 loss 0.19638152420520782
Epoch 0: :   3%|▎         | 15429/600000 [02:58<1:52:46, v_num=12, reduced_train_loss=0.502, global_step=15427.0, consumed_samples=61712.0, train_step_timing in s=0.459]Epoch 0: :   3%|▎         | 15429/600000 [02:58<1:52:46, v_num=12, reduced_train_loss=1.470, global_step=15428.0, consumed_samples=61716.0, train_step_timing in s=0.388]loss mask original None

First layer loss:  0.18853886425495148 torch.Size([530, 4]) 10.813331604003906 0.0
Max loss timestep torch.Size([530, 4]) tensor([119, 341, 132, 311], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 0.07963994890451431
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 1 loss 0.33681902289390564
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
bi 2 loss 0.05267312005162239
speech mask sum tensor(83, device='cuda:0') loss mask sum tensor(83, device='cuda:0')
bi 3 loss 0.16440440714359283
speech mask sum tensor(428, device='cuda:0') loss mask sum tensor(428, device='cuda:0')
logits torch.Size([530, 4, 257024]) labels torch.Size([530, 4]) 0 257020
Layer  0  loss:  0.1892012655735016 0.0 13.759810447692871
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([ 71, 259, 179, 454], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.034053340554237366
bi 1 loss 0.26664167642593384
bi 2 loss 0.04659721255302429
bi 3 loss 0.22309622168540955
Layer  1  loss:  0.21016734838485718 0.0 12.076859474182129
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([168, 356, 189, 455], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.054411597549915314
bi 1 loss 0.3135717213153839
bi 2 loss 0.06400260329246521
bi 3 loss 0.2297886162996292
Layer  2  loss:  0.2044885903596878 0.0 11.942359924316406
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([140, 306, 151, 456], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.05669447407126427
bi 1 loss 0.33241894841194153
bi 2 loss 0.0532502681016922
bi 3 loss 0.20812635123729706
Layer  3  loss:  0.2094428539276123 0.0 13.977869033813477
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1019
Curr loss timestep torch.Size([530, 4]) tensor([ 69, 259, 175, 444], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.046415768563747406
bi 1 loss 0.3682100176811218
bi 2 loss 0.03050701878964901
bi 3 loss 0.20549359917640686
Layer  4  loss:  0.22495386004447937 0.0 13.13109302520752
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([125, 306, 140, 456], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.05312151461839676
bi 1 loss 0.33439844846725464
bi 2 loss 0.033423908054828644
bi 3 loss 0.25517821311950684
Layer  5  loss:  0.24053844809532166 0.0 14.588316917419434
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([177, 355, 197, 444], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.050311118364334106
bi 1 loss 0.38846009969711304
bi 2 loss 0.07398008555173874
bi 3 loss 0.2495482861995697
Layer  6  loss:  0.25160831212997437 0.0 13.49930191040039
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([126, 259, 152, 444], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.15221397578716278
bi 1 loss 0.37379246950149536
bi 2 loss 0.06169850006699562
bi 3 loss 0.2500440180301666
Epoch 0: :   3%|▎         | 15430/600000 [02:58<1:53:01, v_num=12, reduced_train_loss=1.470, global_step=15428.0, consumed_samples=61716.0, train_step_timing in s=0.388]Epoch 0: :   3%|▎         | 15430/600000 [02:58<1:53:01, v_num=12, reduced_train_loss=1.720, global_step=15429.0, consumed_samples=61720.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  3.6325180530548096 torch.Size([600, 4]) 12.406113624572754 0.0
Max loss timestep torch.Size([600, 4]) tensor([339, 189, 449, 183], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 3.226785182952881
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 1 loss 3.1942710876464844
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 2 loss 3.7057442665100098
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
bi 3 loss 3.9083828926086426
speech mask sum tensor(453, device='cuda:0') loss mask sum tensor(453, device='cuda:0')
logits torch.Size([600, 4, 257024]) labels torch.Size([600, 4]) 0 257022
Layer  0  loss:  4.2795305252075195 0.0 11.175509452819824
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([353, 200, 254, 379], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 3.659240245819092
bi 1 loss 4.038218975067139
bi 2 loss 4.344773769378662
bi 3 loss 4.631069183349609
Layer  1  loss:  4.662938594818115 0.0 10.541898727416992
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([361, 237, 470,  87], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 3.9682400226593018
bi 1 loss 4.282954216003418
bi 2 loss 4.760893821716309
bi 3 loss 5.061829090118408
Layer  2  loss:  4.908743858337402 0.0 10.628561019897461
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([274, 177, 201, 477], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 4.09883975982666
bi 1 loss 4.662565231323242
bi 2 loss 4.963035583496094
bi 3 loss 5.379589557647705
Layer  3  loss:  5.059462547302246 0.0 10.032493591308594
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([406, 227, 266, 291], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 4.311436653137207
bi 1 loss 4.769322872161865
bi 2 loss 5.105926990509033
bi 3 loss 5.515016078948975
Layer  4  loss:  5.166921138763428 0.0 9.860079765319824
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([251, 202, 321,  99], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 4.321564674377441
bi 1 loss 4.825018882751465
bi 2 loss 5.205559730529785
bi 3 loss 5.699272632598877
Layer  5  loss:  5.222460746765137 0.0 9.954038619995117
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1020
Curr loss timestep torch.Size([600, 4]) tensor([187, 205, 545, 443], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 4.422529697418213
bi 1 loss 4.991402626037598
bi 2 loss 5.200649738311768
bi 3 loss 5.758826732635498
Layer  6  loss:  5.255145072937012 0.0 11.07866096496582
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([416, 160, 397, 389], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.477805137634277
bi 1 loss 5.014115333557129
bi 2 loss 5.209465980529785
bi 3 loss 5.805057048797607
Epoch 0: :   3%|▎         | 15431/600000 [02:59<1:53:16, v_num=12, reduced_train_loss=1.720, global_step=15429.0, consumed_samples=61720.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15431/600000 [02:59<1:53:16, v_num=12, reduced_train_loss=38.20, global_step=15430.0, consumed_samples=61724.0, train_step_timing in s=0.381]loss mask original None

First layer loss:  0.07447391748428345 torch.Size([477, 4]) 3.512312889099121 0.0
Max loss timestep torch.Size([477, 4]) tensor([243, 193, 349, 259], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.08035159111022949
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
bi 1 loss 0.03409795090556145
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
bi 2 loss 0.06949520111083984
speech mask sum tensor(264, device='cuda:0') loss mask sum tensor(264, device='cuda:0')
bi 3 loss 0.09703486412763596
speech mask sum tensor(239, device='cuda:0') loss mask sum tensor(239, device='cuda:0')
logits torch.Size([477, 4, 257024]) labels torch.Size([477, 4]) 0 257023
Layer  0  loss:  0.09333304315805435 0.0 6.626843452453613
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([223, 150, 328, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.07859119027853012
bi 1 loss 0.04851902648806572
bi 2 loss 0.07988617569208145
bi 3 loss 0.14607548713684082
Layer  1  loss:  0.09342259913682938 0.0 12.87507438659668
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([261, 166, 437, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.05550495162606239
bi 1 loss 0.06969376653432846
bi 2 loss 0.07571486383676529
bi 3 loss 0.15988078713417053
Layer  2  loss:  0.0861089825630188 0.0 5.144815921783447
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1022
Curr loss timestep torch.Size([477, 4]) tensor([330, 259, 315, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.0845947116613388
bi 1 loss 0.05180766060948372
bi 2 loss 0.07347927987575531
bi 3 loss 0.12035400420427322
Layer  3  loss:  0.09354332089424133 0.0 7.705873489379883
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1021
Curr loss timestep torch.Size([477, 4]) tensor([353, 241, 437, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.07855498790740967
bi 1 loss 0.05631373077630997
bi 2 loss 0.07129193842411041
bi 3 loss 0.15204201638698578
Layer  4  loss:  0.08946609497070312 0.0 7.983333110809326
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1022
Curr loss timestep torch.Size([477, 4]) tensor([251, 166, 437, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.06985944509506226
bi 1 loss 0.05328613892197609
bi 2 loss 0.08384548872709274
bi 3 loss 0.13313059508800507
Layer  5  loss:  0.09867300093173981 0.0 9.158143997192383
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([200, 224, 349, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.07662605494260788
bi 1 loss 0.04724068194627762
bi 2 loss 0.09211745113134384
bi 3 loss 0.153968945145607
Layer  6  loss:  0.09464523196220398 0.0 11.563590049743652
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1022
Curr loss timestep torch.Size([477, 4]) tensor([293, 157, 268, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.05232587456703186
bi 1 loss 0.04927444085478783
bi 2 loss 0.08049802482128143
bi 3 loss 0.17304620146751404
Epoch 0: :   3%|▎         | 15432/600000 [02:59<1:53:30, v_num=12, reduced_train_loss=38.20, global_step=15430.0, consumed_samples=61724.0, train_step_timing in s=0.381]Epoch 0: :   3%|▎         | 15432/600000 [02:59<1:53:30, v_num=12, reduced_train_loss=0.724, global_step=15431.0, consumed_samples=61728.0, train_step_timing in s=0.339]loss mask original None

First layer loss:  3.8265023231506348 torch.Size([448, 4]) 11.432822227478027 0.0
Max loss timestep torch.Size([448, 4]) tensor([ 63, 195, 170, 178], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 4.24078369140625
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 1 loss 4.040972709655762
speech mask sum tensor(365, device='cuda:0') loss mask sum tensor(365, device='cuda:0')
bi 2 loss 3.7642815113067627
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
bi 3 loss 3.2258853912353516
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
logits torch.Size([448, 4, 257024]) labels torch.Size([448, 4]) 0 257022
Layer  0  loss:  4.296167850494385 0.0 10.51281452178955
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([108, 151, 234, 166], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 4.242325782775879
bi 1 loss 4.516717910766602
bi 2 loss 4.276276111602783
bi 3 loss 3.8509984016418457
Layer  1  loss:  4.600451946258545 0.0 10.62938117980957
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([ 62, 173, 244, 109], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 4.773346900939941
bi 1 loss 4.74399471282959
bi 2 loss 4.369859218597412
bi 3 loss 4.519611358642578
Layer  2  loss:  4.834205627441406 0.0 10.50749397277832
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([ 59, 292, 312, 176], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.682281970977783
bi 1 loss 5.092405319213867
bi 2 loss 4.681487560272217
bi 3 loss 4.541561603546143
Layer  3  loss:  4.911725997924805 0.0 9.69748306274414
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1017
Curr loss timestep torch.Size([448, 4]) tensor([ 84, 325, 236, 139], device='cuda:0') tensor(152, device='cuda:0')
bi 0 loss 4.717787265777588
bi 1 loss 5.086030006408691
bi 2 loss 4.690271854400635
bi 3 loss 4.9280900955200195
Layer  4  loss:  5.109816074371338 0.0 11.33431339263916
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1022
Curr loss timestep torch.Size([448, 4]) tensor([ 79, 104, 261, 203], device='cuda:0') tensor(104, device='cuda:0')
bi 0 loss 4.953095436096191
bi 1 loss 5.313292026519775
bi 2 loss 4.9766693115234375
bi 3 loss 4.915626525878906
Layer  5  loss:  5.120142459869385 0.0 9.32434368133545
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1021
Curr loss timestep torch.Size([448, 4]) tensor([103, 404, 206, 178], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 4.910754203796387
bi 1 loss 5.42120885848999
bi 2 loss 4.943958282470703
bi 3 loss 4.79203462600708
Layer  6  loss:  5.259873390197754 0.0 10.02358627319336
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([ 79, 397, 160, 201], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 5.041685581207275
bi 1 loss 5.483119487762451
bi 2 loss 4.99600887298584
bi 3 loss 5.237765312194824
Epoch 0: :   3%|▎         | 15433/600000 [03:00<1:53:43, v_num=12, reduced_train_loss=0.724, global_step=15431.0, consumed_samples=61728.0, train_step_timing in s=0.339]Epoch 0: :   3%|▎         | 15433/600000 [03:00<1:53:43, v_num=12, reduced_train_loss=38.00, global_step=15432.0, consumed_samples=61732.0, train_step_timing in s=0.317]loss mask original None

First layer loss:  0.1905306875705719 torch.Size([745, 4]) 8.875456809997559 0.0
Max loss timestep torch.Size([745, 4]) tensor([260, 149, 145, 538], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.08009480684995651
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 1 loss 0.0699632316827774
speech mask sum tensor(98, device='cuda:0') loss mask sum tensor(98, device='cuda:0')
bi 2 loss 0.07483864575624466
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
bi 3 loss 0.2910940647125244
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
logits torch.Size([745, 4, 257024]) labels torch.Size([745, 4]) 0 257022
Layer  0  loss:  0.1780964732170105 0.0 8.047062873840332
logits torch.Size([745, 4, 1024]) labels torch.Size([745, 4]) 0 1023
Curr loss timestep torch.Size([745, 4]) tensor([158, 171, 153, 538], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.06652310490608215
bi 1 loss 0.04501684382557869
bi 2 loss 0.05935215577483177
bi 3 loss 0.28267961740493774
Layer  1  loss:  0.16619087755680084 0.0 8.166080474853516
logits torch.Size([745, 4, 1024]) labels torch.Size([745, 4]) 0 1022
Curr loss timestep torch.Size([745, 4]) tensor([112, 144, 192, 538], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.06497412174940109
bi 1 loss 0.041531387716531754
bi 2 loss 0.046467822045087814
bi 3 loss 0.2646418809890747
Layer  2  loss:  0.1615956574678421 0.0 8.620098114013672
logits torch.Size([745, 4, 1024]) labels torch.Size([745, 4]) 0 1023
Curr loss timestep torch.Size([745, 4]) tensor([187, 171, 169, 626], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.09380589425563812
bi 1 loss 0.05943942442536354
bi 2 loss 0.07267389446496964
bi 3 loss 0.2337377965450287
Layer  3  loss:  0.17198576033115387 0.0 7.120190143585205
logits torch.Size([745, 4, 1024]) labels torch.Size([745, 4]) 0 1023
Curr loss timestep torch.Size([745, 4]) tensor([261, 137, 164, 538], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.06256888061761856
bi 1 loss 0.03380242735147476
bi 2 loss 0.045042216777801514
bi 3 loss 0.2786398231983185
Layer  4  loss:  0.18552158772945404 0.0 7.878857135772705
logits torch.Size([745, 4, 1024]) labels torch.Size([745, 4]) 0 1023
Curr loss timestep torch.Size([745, 4]) tensor([191, 132, 159, 527], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.05372605100274086
bi 1 loss 0.049438513815402985
bi 2 loss 0.05326475575566292
bi 3 loss 0.302459180355072
Layer  5  loss:  0.1689441055059433 0.0 13.046211242675781
logits torch.Size([745, 4, 1024]) labels torch.Size([745, 4]) 0 1022
Curr loss timestep torch.Size([745, 4]) tensor([126, 174, 190, 538], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.08167261630296707
bi 1 loss 0.029318688437342644
bi 2 loss 0.06420344859361649
bi 3 loss 0.2614937424659729
Layer  6  loss:  0.1668737679719925 0.0 8.305171966552734
logits torch.Size([745, 4, 1024]) labels torch.Size([745, 4]) 0 1023
Curr loss timestep torch.Size([745, 4]) tensor([258, 130, 187, 593], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.0871264636516571
bi 1 loss 0.043502867221832275
bi 2 loss 0.058131054043769836
bi 3 loss 0.2533927261829376
Epoch 0: :   3%|▎         | 15434/600000 [03:00<1:54:03, v_num=12, reduced_train_loss=38.00, global_step=15432.0, consumed_samples=61732.0, train_step_timing in s=0.317]Epoch 0: :   3%|▎         | 15434/600000 [03:00<1:54:03, v_num=12, reduced_train_loss=1.390, global_step=15433.0, consumed_samples=61736.0, train_step_timing in s=0.507]loss mask original None

First layer loss:  3.364945650100708 torch.Size([548, 4]) 8.58073616027832 0.0
Max loss timestep torch.Size([548, 4]) tensor([251, 242, 181, 197], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 3.336177110671997
speech mask sum tensor(438, device='cuda:0') loss mask sum tensor(438, device='cuda:0')
bi 1 loss 3.2912423610687256
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 2 loss 3.869410276412964
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 3 loss 2.7673935890197754
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
logits torch.Size([548, 4, 257024]) labels torch.Size([548, 4]) 0 257022
Layer  0  loss:  3.934248208999634 0.0 9.093778610229492
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([188, 181, 150, 149], device='cuda:0') tensor(150, device='cuda:0')
bi 0 loss 4.020580291748047
bi 1 loss 3.8223066329956055
bi 2 loss 4.40465784072876
bi 3 loss 2.768212080001831
Layer  1  loss:  4.218663215637207 0.0 9.42370319366455
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([191, 205, 190, 171], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 4.213076591491699
bi 1 loss 4.1333818435668945
bi 2 loss 4.683409690856934
bi 3 loss 3.584080457687378
Layer  2  loss:  4.402035236358643 0.0 10.129639625549316
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([252, 251, 231, 181], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 4.466259479522705
bi 1 loss 4.480190753936768
bi 2 loss 4.605299472808838
bi 3 loss 3.3388559818267822
Layer  3  loss:  4.53256893157959 0.0 9.520963668823242
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([250, 190, 217, 157], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 4.564685344696045
bi 1 loss 4.5611891746521
bi 2 loss 4.960290908813477
bi 3 loss 3.3804492950439453
Layer  4  loss:  4.687333583831787 0.0 9.937774658203125
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([253, 226, 168, 154], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 4.69627046585083
bi 1 loss 4.71619987487793
bi 2 loss 5.0384087562561035
bi 3 loss 3.83929705619812
Layer  5  loss:  4.7423014640808105 0.0 9.551159858703613
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([255, 264, 244, 187], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.8265275955200195
bi 1 loss 4.597980976104736
bi 2 loss 5.181416034698486
bi 3 loss 3.7507338523864746
Layer  6  loss:  4.785759925842285 0.0 9.929252624511719
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([493, 271, 186, 162], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 4.88748025894165
bi 1 loss 4.730254650115967
bi 2 loss 5.233314514160156
bi 3 loss 3.3938472270965576
Epoch 0: :   3%|▎         | 15435/600000 [03:01<1:54:18, v_num=12, reduced_train_loss=1.390, global_step=15433.0, consumed_samples=61736.0, train_step_timing in s=0.507]Epoch 0: :   3%|▎         | 15435/600000 [03:01<1:54:18, v_num=12, reduced_train_loss=34.70, global_step=15434.0, consumed_samples=61740.0, train_step_timing in s=0.363]loss mask original None

First layer loss:  0.03920542076230049 torch.Size([390, 4]) 1.0570570230484009 0.0
Max loss timestep torch.Size([390, 4]) tensor([331, 150, 116, 308], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.04562932997941971
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 1 loss 0.009705756790935993
speech mask sum tensor(52, device='cuda:0') loss mask sum tensor(52, device='cuda:0')
bi 2 loss 0.03499285876750946
speech mask sum tensor(76, device='cuda:0') loss mask sum tensor(76, device='cuda:0')
bi 3 loss 0.041104819625616074
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
logits torch.Size([390, 4, 257024]) labels torch.Size([390, 4]) 0 257022
Layer  0  loss:  0.03997405245900154 0.0 3.197514057159424
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1023
Curr loss timestep torch.Size([390, 4]) tensor([304, 159, 114, 329], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.05109517276287079
bi 1 loss 0.012528687715530396
bi 2 loss 0.03369607403874397
bi 3 loss 0.0359274186193943
Layer  1  loss:  0.04466193541884422 0.0 1.8557125329971313
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1023
Curr loss timestep torch.Size([390, 4]) tensor([270, 148,  99, 329], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.06251746416091919
bi 1 loss 0.010950683616101742
bi 2 loss 0.027367843315005302
bi 3 loss 0.03822055086493492
Layer  2  loss:  0.04429237172007561 0.0 1.240005373954773
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1022
Curr loss timestep torch.Size([390, 4]) tensor([360, 164, 112, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.047940585762262344
bi 1 loss 0.006919628009200096
bi 2 loss 0.03065565414726734
bi 3 loss 0.0561956986784935
Layer  3  loss:  0.04404492303729057 0.0 2.544633150100708
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1021
Curr loss timestep torch.Size([390, 4]) tensor([304, 167, 146, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.056911591440439224
bi 1 loss 0.013568931259214878
bi 2 loss 0.021801939234137535
bi 3 loss 0.045385852456092834
Layer  4  loss:  0.048462968319654465 0.0 1.9546263217926025
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1020
Curr loss timestep torch.Size([390, 4]) tensor([304, 151, 127, 254], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.05807270109653473
bi 1 loss 0.029007554054260254
bi 2 loss 0.03218062222003937
bi 3 loss 0.04835759475827217
Layer  5  loss:  0.04711084067821503 0.0 1.3192064762115479
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1022
Curr loss timestep torch.Size([390, 4]) tensor([356, 143, 116, 316], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.0507279671728611
bi 1 loss 0.02926645800471306
bi 2 loss 0.035135041922330856
bi 3 loss 0.05264132097363472
Layer  6  loss:  0.06049290671944618 0.0 7.103559494018555
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1021
Curr loss timestep torch.Size([390, 4]) tensor([304, 164, 138, 329], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.10097786039113998
bi 1 loss 0.006752043031156063
bi 2 loss 0.021958183497190475
bi 3 loss 0.03896883875131607
Epoch 0: :   3%|▎         | 15436/600000 [03:01<1:54:30, v_num=12, reduced_train_loss=34.70, global_step=15434.0, consumed_samples=61740.0, train_step_timing in s=0.363]Epoch 0: :   3%|▎         | 15436/600000 [03:01<1:54:30, v_num=12, reduced_train_loss=0.368, global_step=15435.0, consumed_samples=61744.0, train_step_timing in s=0.294]loss mask original None

First layer loss:  3.5037665367126465 torch.Size([520, 4]) 9.900720596313477 0.0
Max loss timestep torch.Size([520, 4]) tensor([184, 211, 349, 183], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 3.4520843029022217
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
bi 1 loss 3.7093894481658936
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 2 loss 3.4630467891693115
speech mask sum tensor(354, device='cuda:0') loss mask sum tensor(354, device='cuda:0')
bi 3 loss 3.544065237045288
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
logits torch.Size([520, 4, 257024]) labels torch.Size([520, 4]) 0 257023
Layer  0  loss:  3.999577045440674 0.0 10.33524227142334
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([ 77, 207, 354, 249], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 3.4322636127471924
bi 1 loss 4.134655475616455
bi 2 loss 4.021711826324463
bi 3 loss 4.32423734664917
Layer  1  loss:  4.259415149688721 0.0 10.258517265319824
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([178, 225, 338, 185], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 4.145056247711182
bi 1 loss 4.302814960479736
bi 2 loss 4.2346320152282715
bi 3 loss 4.366875648498535
Layer  2  loss:  4.473346710205078 0.0 11.024105072021484
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1022
Curr loss timestep torch.Size([520, 4]) tensor([ 66, 204, 459, 132], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 4.086846828460693
bi 1 loss 4.250482559204102
bi 2 loss 4.4291462898254395
bi 3 loss 4.883528232574463
Layer  3  loss:  4.715599536895752 0.0 9.426728248596191
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1022
Curr loss timestep torch.Size([520, 4]) tensor([168, 209, 249, 204], device='cuda:0') tensor(191, device='cuda:0')
bi 0 loss 4.495785713195801
bi 1 loss 4.356129169464111
bi 2 loss 4.704617977142334
bi 3 loss 4.995707988739014
Layer  4  loss:  4.790971279144287 0.0 11.590500831604004
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([100, 211, 466, 179], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.400566577911377
bi 1 loss 4.495267868041992
bi 2 loss 4.788738250732422
bi 3 loss 5.1584367752075195
Layer  5  loss:  4.804881572723389 0.0 9.807577133178711
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1022
Curr loss timestep torch.Size([520, 4]) tensor([149, 211, 343, 304], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.559338092803955
bi 1 loss 4.303905487060547
bi 2 loss 4.787906169891357
bi 3 loss 5.155011177062988
Layer  6  loss:  4.841800689697266 0.0 10.255732536315918
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1021
Curr loss timestep torch.Size([520, 4]) tensor([160, 195, 391, 188], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.513243675231934
bi 1 loss 4.77625036239624
bi 2 loss 4.755573749542236
bi 3 loss 5.231418132781982
Epoch 0: :   3%|▎         | 15437/600000 [03:01<1:54:44, v_num=12, reduced_train_loss=0.368, global_step=15435.0, consumed_samples=61744.0, train_step_timing in s=0.294]Epoch 0: :   3%|▎         | 15437/600000 [03:01<1:54:44, v_num=12, reduced_train_loss=35.40, global_step=15436.0, consumed_samples=61748.0, train_step_timing in s=0.337]loss mask original None

First layer loss:  0.1613370031118393 torch.Size([629, 4]) 10.594969749450684 0.0
Max loss timestep torch.Size([629, 4]) tensor([543, 413, 372, 262], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.20594759285449982
speech mask sum tensor(491, device='cuda:0') loss mask sum tensor(491, device='cuda:0')
bi 1 loss 0.23758642375469208
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 2 loss 0.07963293790817261
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 3 loss 0.11209160834550858
speech mask sum tensor(294, device='cuda:0') loss mask sum tensor(294, device='cuda:0')
logits torch.Size([629, 4, 257024]) labels torch.Size([629, 4]) 0 257023
Layer  0  loss:  0.1864577978849411 0.0 11.951631546020508
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([600, 312, 370, 262], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.2540740370750427
bi 1 loss 0.20290587842464447
bi 2 loss 0.07735203951597214
bi 3 loss 0.1633068323135376
Layer  1  loss:  0.1896672397851944 0.0 15.529191970825195
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1022
Curr loss timestep torch.Size([629, 4]) tensor([543, 312, 371, 262], device='cuda:0') tensor(543, device='cuda:0')
bi 0 loss 0.24972887337207794
bi 1 loss 0.2317965030670166
bi 2 loss 0.09052292257547379
bi 3 loss 0.15309205651283264
Layer  2  loss:  0.22979716956615448 0.0 13.740229606628418
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1022
Curr loss timestep torch.Size([629, 4]) tensor([542, 413, 350, 263], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.3148607313632965
bi 1 loss 0.2687859535217285
bi 2 loss 0.10764994472265244
bi 3 loss 0.17473207414150238
Layer  3  loss:  0.2088349461555481 0.0 13.437539100646973
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1021
Curr loss timestep torch.Size([629, 4]) tensor([486, 413, 370, 369], device='cuda:0') tensor(486, device='cuda:0')
bi 0 loss 0.27068302035331726
bi 1 loss 0.22528253495693207
bi 2 loss 0.1130586639046669
bi 3 loss 0.18303072452545166
Layer  4  loss:  0.20537780225276947 0.0 15.02427864074707
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1022
Curr loss timestep torch.Size([629, 4]) tensor([544, 413, 368, 369], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.29693201184272766
bi 1 loss 0.19095900654792786
bi 2 loss 0.07872404903173447
bi 3 loss 0.17868690192699432
Layer  5  loss:  0.20981957018375397 0.0 15.05999755859375
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1022
Curr loss timestep torch.Size([629, 4]) tensor([600, 413, 372, 369], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.29849526286125183
bi 1 loss 0.20633448660373688
bi 2 loss 0.12405243515968323
bi 3 loss 0.14307045936584473
Layer  6  loss:  0.21188385784626007 0.0 10.72030258178711
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1022
Curr loss timestep torch.Size([629, 4]) tensor([543, 413, 370, 369], device='cuda:0') tensor(543, device='cuda:0')
bi 0 loss 0.2692137360572815
bi 1 loss 0.26174819469451904
bi 2 loss 0.10231074690818787
bi 3 loss 0.1844061017036438
Epoch 0: :   3%|▎         | 15438/600000 [03:02<1:55:01, v_num=12, reduced_train_loss=35.40, global_step=15436.0, consumed_samples=61748.0, train_step_timing in s=0.337]Epoch 0: :   3%|▎         | 15438/600000 [03:02<1:55:01, v_num=12, reduced_train_loss=1.600, global_step=15437.0, consumed_samples=61752.0, train_step_timing in s=0.432]loss mask original None

First layer loss:  0.0760396271944046 torch.Size([639, 4]) 3.1182684898376465 0.0
Max loss timestep torch.Size([639, 4]) tensor([129, 260, 583, 250], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.038599204272031784
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 1 loss 0.042338766157627106
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
bi 2 loss 0.10555395483970642
speech mask sum tensor(505, device='cuda:0') loss mask sum tensor(505, device='cuda:0')
bi 3 loss 0.054314740002155304
speech mask sum tensor(219, device='cuda:0') loss mask sum tensor(219, device='cuda:0')
logits torch.Size([639, 4, 257024]) labels torch.Size([639, 4]) 0 257023
Layer  0  loss:  0.10791125893592834 0.0 4.767960548400879
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1023
Curr loss timestep torch.Size([639, 4]) tensor([153, 258, 618, 212], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.07007784396409988
bi 1 loss 0.06566958874464035
bi 2 loss 0.15509948134422302
bi 3 loss 0.051151566207408905
Layer  1  loss:  0.12701579928398132 0.0 5.4188947677612305
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([ 80, 262, 622, 297], device='cuda:0') tensor(622, device='cuda:0')
bi 0 loss 0.05552595853805542
bi 1 loss 0.07412594556808472
bi 2 loss 0.18804840743541718
bi 3 loss 0.06742274761199951
Layer  2  loss:  0.13994033634662628 0.0 13.1563138961792
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([147, 218, 275, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.062654510140419
bi 1 loss 0.050154004245996475
bi 2 loss 0.16703596711158752
bi 3 loss 0.18602818250656128
Layer  3  loss:  0.13857318460941315 0.0 8.819540977478027
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([134, 179, 357, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.046465806663036346
bi 1 loss 0.06659606844186783
bi 2 loss 0.1755361407995224
bi 3 loss 0.16033604741096497
Layer  4  loss:  0.12463885545730591 0.0 7.447291374206543
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([ 85, 231, 276, 297], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.035869769752025604
bi 1 loss 0.04096127301454544
bi 2 loss 0.1947961449623108
bi 3 loss 0.07512720674276352
Layer  5  loss:  0.14341740310192108 0.0 10.25166130065918
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1022
Curr loss timestep torch.Size([639, 4]) tensor([113, 268, 276, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.044316913932561874
bi 1 loss 0.07142309099435806
bi 2 loss 0.19765721261501312
bi 3 loss 0.1299820840358734
Layer  6  loss:  0.14037278294563293 0.0 10.094127655029297
logits torch.Size([639, 4, 1024]) labels torch.Size([639, 4]) 0 1020
Curr loss timestep torch.Size([639, 4]) tensor([153, 264, 275, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.04214557632803917
bi 1 loss 0.05740263685584068
bi 2 loss 0.19342955946922302
bi 3 loss 0.1361037790775299
Epoch 0: :   3%|▎         | 15439/600000 [03:02<1:55:18, v_num=12, reduced_train_loss=1.600, global_step=15437.0, consumed_samples=61752.0, train_step_timing in s=0.432]Epoch 0: :   3%|▎         | 15439/600000 [03:02<1:55:18, v_num=12, reduced_train_loss=0.998, global_step=15438.0, consumed_samples=61756.0, train_step_timing in s=0.439]loss mask original None

First layer loss:  0.12749634683132172 torch.Size([462, 4]) 14.483235359191895 0.0
Max loss timestep torch.Size([462, 4]) tensor([308, 447, 272, 291], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.07610286772251129
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 1 loss 0.1265457719564438
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
bi 2 loss 0.3164837956428528
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
bi 3 loss 0.029738888144493103
speech mask sum tensor(248, device='cuda:0') loss mask sum tensor(248, device='cuda:0')
logits torch.Size([462, 4, 257024]) labels torch.Size([462, 4]) 0 257022
Layer  0  loss:  0.14445248246192932 0.0 14.813104629516602
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1023
Curr loss timestep torch.Size([462, 4]) tensor([308, 388, 273, 292], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.07090907543897629
bi 1 loss 0.14710892736911774
bi 2 loss 0.3433034121990204
bi 3 loss 0.05720821022987366
Layer  1  loss:  0.11668366938829422 0.0 11.845442771911621
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([308, 389, 273, 221], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.07958630472421646
bi 1 loss 0.12200846523046494
bi 2 loss 0.24021363258361816
bi 3 loss 0.04661978781223297
Layer  2  loss:  0.1295962631702423 0.0 12.781579971313477
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([187, 447, 271, 292], device='cuda:0') tensor(447, device='cuda:0')
bi 0 loss 0.061535295099020004
bi 1 loss 0.1596110612154007
bi 2 loss 0.2695063650608063
bi 3 loss 0.038722265511751175
Layer  3  loss:  0.1356298327445984 0.0 13.082781791687012
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1018
Curr loss timestep torch.Size([462, 4]) tensor([308, 447, 273, 292], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.07254210114479065
bi 1 loss 0.13594010472297668
bi 2 loss 0.2907613217830658
bi 3 loss 0.07696326076984406
Layer  4  loss:  0.1267707794904709 0.0 14.759008407592773
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([308, 447, 272, 292], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.06462033838033676
bi 1 loss 0.14441362023353577
bi 2 loss 0.25750818848609924
bi 3 loss 0.057892851531505585
Layer  5  loss:  0.1461438089609146 0.0 12.470784187316895
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([335, 447, 272, 292], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.07369016855955124
bi 1 loss 0.12470600754022598
bi 2 loss 0.33114093542099
bi 3 loss 0.11008746922016144
Layer  6  loss:  0.12780077755451202 0.0 12.204022407531738
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1020
Curr loss timestep torch.Size([462, 4]) tensor([312, 447, 272, 291], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.061187971383333206
bi 1 loss 0.17236092686653137
bi 2 loss 0.2456388622522354
bi 3 loss 0.028945498168468475
Epoch 0: :   3%|▎         | 15440/600000 [03:03<1:55:32, v_num=12, reduced_train_loss=0.998, global_step=15438.0, consumed_samples=61756.0, train_step_timing in s=0.439]Epoch 0: :   3%|▎         | 15440/600000 [03:03<1:55:32, v_num=12, reduced_train_loss=1.050, global_step=15439.0, consumed_samples=61760.0, train_step_timing in s=0.327]loss mask original None

First layer loss:  0.11817485094070435 torch.Size([619, 4]) 8.70390510559082 0.0
Max loss timestep torch.Size([619, 4]) tensor([589, 346, 282, 307], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.20979520678520203
speech mask sum tensor(446, device='cuda:0') loss mask sum tensor(446, device='cuda:0')
bi 1 loss 0.042297784239053726
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 2 loss 0.06165800616145134
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 3 loss 0.06462646275758743
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
logits torch.Size([619, 4, 257024]) labels torch.Size([619, 4]) 0 257022
Layer  0  loss:  0.14080724120140076 0.0 10.25042724609375
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([550, 320, 209, 130], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.26331257820129395
bi 1 loss 0.04918697848916054
bi 2 loss 0.06475790590047836
bi 3 loss 0.06199124455451965
Layer  1  loss:  0.15772143006324768 0.0 10.148441314697266
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([552, 312, 257, 287], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.3083130717277527
bi 1 loss 0.04479029402136803
bi 2 loss 0.06912969797849655
bi 3 loss 0.05769365280866623
Layer  2  loss:  0.1643744260072708 0.0 9.968413352966309
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([550, 320, 238, 236], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.3163526952266693
bi 1 loss 0.06279035657644272
bi 2 loss 0.06328268349170685
bi 3 loss 0.061980877071619034
Layer  3  loss:  0.17898625135421753 0.0 17.313289642333984
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1021
Curr loss timestep torch.Size([619, 4]) tensor([552, 358, 279, 307], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.3398716449737549
bi 1 loss 0.05059089884161949
bi 2 loss 0.06944238394498825
bi 3 loss 0.08834444731473923
Layer  4  loss:  0.17068710923194885 0.0 16.493913650512695
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([550, 360, 256, 307], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.31657034158706665
bi 1 loss 0.06606997549533844
bi 2 loss 0.08527267724275589
bi 3 loss 0.06983448565006256
Layer  5  loss:  0.19240202009677887 0.0 15.426993370056152
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([550, 359, 283, 307], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.3650329113006592
bi 1 loss 0.07440364360809326
bi 2 loss 0.07100262492895126
bi 3 loss 0.08263066411018372
Layer  6  loss:  0.19223318994045258 0.0 15.703298568725586
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([552, 359, 280, 307], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.353614866733551
bi 1 loss 0.09255513548851013
bi 2 loss 0.08722366392612457
bi 3 loss 0.07560434192419052
Epoch 0: :   3%|▎         | 15441/600000 [03:03<1:55:48, v_num=12, reduced_train_loss=1.050, global_step=15439.0, consumed_samples=61760.0, train_step_timing in s=0.327]Epoch 0: :   3%|▎         | 15441/600000 [03:03<1:55:48, v_num=12, reduced_train_loss=1.320, global_step=15440.0, consumed_samples=61764.0, train_step_timing in s=0.418]loss mask original None

First layer loss:  0.1665973961353302 torch.Size([654, 4]) 11.744035720825195 0.0
Max loss timestep torch.Size([654, 4]) tensor([189, 320, 408, 558], device='cuda:0') tensor(558, device='cuda:0')
bi 0 loss 0.044499948620796204
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 1 loss 0.1147373765707016
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 2 loss 0.2650555372238159
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
bi 3 loss 0.14118537306785583
speech mask sum tensor(481, device='cuda:0') loss mask sum tensor(481, device='cuda:0')
logits torch.Size([654, 4, 257024]) labels torch.Size([654, 4]) 0 257022
Layer  0  loss:  0.15444962680339813 0.0 12.66610050201416
logits torch.Size([654, 4, 1024]) labels torch.Size([654, 4]) 0 1023
Curr loss timestep torch.Size([654, 4]) tensor([203, 310, 408, 329], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.07908176630735397
bi 1 loss 0.08832699805498123
bi 2 loss 0.26726260781288147
bi 3 loss 0.10644611716270447
Layer  1  loss:  0.21190044283866882 0.0 14.875751495361328
logits torch.Size([654, 4, 1024]) labels torch.Size([654, 4]) 0 1022
Curr loss timestep torch.Size([654, 4]) tensor([213, 320, 625, 552], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.07422006875276566
bi 1 loss 0.12056545168161392
bi 2 loss 0.3285534977912903
bi 3 loss 0.19272561371326447
Layer  2  loss:  0.20961040258407593 0.0 14.555484771728516
logits torch.Size([654, 4, 1024]) labels torch.Size([654, 4]) 0 1022
Curr loss timestep torch.Size([654, 4]) tensor([163, 320, 408, 558], device='cuda:0') tensor(558, device='cuda:0')
bi 0 loss 0.06851094216108322
bi 1 loss 0.10596540570259094
bi 2 loss 0.30741560459136963
bi 3 loss 0.21427305042743683
Layer  3  loss:  0.21549701690673828 0.0 11.940423965454102
logits torch.Size([654, 4, 1024]) labels torch.Size([654, 4]) 0 1022
Curr loss timestep torch.Size([654, 4]) tensor([266, 320, 583, 546], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.06131378188729286
bi 1 loss 0.11341539025306702
bi 2 loss 0.3401350975036621
bi 3 loss 0.1994081437587738
Layer  4  loss:  0.22133676707744598 0.0 13.10224437713623
logits torch.Size([654, 4, 1024]) labels torch.Size([654, 4]) 0 1022
Curr loss timestep torch.Size([654, 4]) tensor([268, 348, 623, 552], device='cuda:0') tensor(623, device='cuda:0')
bi 0 loss 0.06652846932411194
bi 1 loss 0.10679369419813156
bi 2 loss 0.3347647190093994
bi 3 loss 0.22123506665229797
Layer  5  loss:  0.201687753200531 0.0 13.261031150817871
logits torch.Size([654, 4, 1024]) labels torch.Size([654, 4]) 0 1023
Curr loss timestep torch.Size([654, 4]) tensor([266, 319, 408, 552], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.07466740161180496
bi 1 loss 0.1329953372478485
bi 2 loss 0.32077157497406006
bi 3 loss 0.1666080802679062
Layer  6  loss:  0.1918005496263504 0.0 17.435932159423828
logits torch.Size([654, 4, 1024]) labels torch.Size([654, 4]) 0 1023
Curr loss timestep torch.Size([654, 4]) tensor([167, 320, 623, 558], device='cuda:0') tensor(623, device='cuda:0')
bi 0 loss 0.05892886966466904
bi 1 loss 0.10458281636238098
bi 2 loss 0.29138606786727905
bi 3 loss 0.18474158644676208
Epoch 0: :   3%|▎         | 15442/600000 [03:04<1:56:06, v_num=12, reduced_train_loss=1.320, global_step=15440.0, consumed_samples=61764.0, train_step_timing in s=0.418]Epoch 0: :   3%|▎         | 15442/600000 [03:04<1:56:06, v_num=12, reduced_train_loss=1.570, global_step=15441.0, consumed_samples=61768.0, train_step_timing in s=0.448]loss mask original None

First layer loss:  0.05349757894873619 torch.Size([515, 4]) 4.562208652496338 0.0
Max loss timestep torch.Size([515, 4]) tensor([152, 239, 409, 432], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.03705879673361778
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 1 loss 0.038776565343141556
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 2 loss 0.06672580540180206
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 3 loss 0.057128410786390305
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
logits torch.Size([515, 4, 257024]) labels torch.Size([515, 4]) 0 257022
Layer  0  loss:  0.061341091990470886 0.0 3.583221673965454
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([171, 111, 268, 433], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.02539203129708767
bi 1 loss 0.045804303139448166
bi 2 loss 0.07927854359149933
bi 3 loss 0.06658639013767242
Layer  1  loss:  0.07098124176263809 0.0 3.205097198486328
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1022
Curr loss timestep torch.Size([515, 4]) tensor([138, 199, 268, 495], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.04756796732544899
bi 1 loss 0.04950205236673355
bi 2 loss 0.08096492290496826
bi 3 loss 0.08195780217647552
Layer  2  loss:  0.0656885877251625 0.0 3.1840152740478516
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1022
Curr loss timestep torch.Size([515, 4]) tensor([152, 274, 409, 327], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.0459287129342556
bi 1 loss 0.03398542106151581
bi 2 loss 0.084095798432827
bi 3 loss 0.07651195675134659
Layer  3  loss:  0.06349758803844452 0.0 2.664628505706787
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1020
Curr loss timestep torch.Size([515, 4]) tensor([149, 198, 198, 392], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 0.025978511199355125
bi 1 loss 0.0548505038022995
bi 2 loss 0.05332498252391815
bi 3 loss 0.08262073248624802
Layer  4  loss:  0.053070567548274994 0.0 4.501283168792725
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1022
Curr loss timestep torch.Size([515, 4]) tensor([152,  86, 268, 495], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.024237217381596565
bi 1 loss 0.03388829901814461
bi 2 loss 0.0596734881401062
bi 3 loss 0.06596912443637848
Layer  5  loss:  0.07413548231124878 0.0 4.661272048950195
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([171, 118, 409, 495], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.03564906492829323
bi 1 loss 0.03586243838071823
bi 2 loss 0.08209286630153656
bi 3 loss 0.0991373211145401
Layer  6  loss:  0.06623479723930359 0.0 4.949387073516846
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1019
Curr loss timestep torch.Size([515, 4]) tensor([180, 269, 287, 495], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.02651241607964039
bi 1 loss 0.04936930909752846
bi 2 loss 0.06604248285293579
bi 3 loss 0.0843120664358139
Epoch 0: :   3%|▎         | 15443/600000 [03:04<1:56:21, v_num=12, reduced_train_loss=1.570, global_step=15441.0, consumed_samples=61768.0, train_step_timing in s=0.448]Epoch 0: :   3%|▎         | 15443/600000 [03:04<1:56:21, v_num=12, reduced_train_loss=0.508, global_step=15442.0, consumed_samples=61772.0, train_step_timing in s=0.356]loss mask original None

First layer loss:  0.1810685694217682 torch.Size([689, 4]) 10.036538124084473 0.0
Max loss timestep torch.Size([689, 4]) tensor([444, 541, 447, 193], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.17975753545761108
speech mask sum tensor(478, device='cuda:0') loss mask sum tensor(478, device='cuda:0')
bi 1 loss 0.26585033535957336
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
bi 2 loss 0.11867900937795639
speech mask sum tensor(406, device='cuda:0') loss mask sum tensor(406, device='cuda:0')
bi 3 loss 0.036184463649988174
speech mask sum tensor(83, device='cuda:0') loss mask sum tensor(83, device='cuda:0')
logits torch.Size([689, 4, 257024]) labels torch.Size([689, 4]) 0 257022
Layer  0  loss:  0.24577629566192627 0.0 13.216164588928223
logits torch.Size([689, 4, 1024]) labels torch.Size([689, 4]) 0 1023
Curr loss timestep torch.Size([689, 4]) tensor([445, 657, 447, 214], device='cuda:0') tensor(445, device='cuda:0')
bi 0 loss 0.24572952091693878
bi 1 loss 0.368751585483551
bi 2 loss 0.15603812038898468
bi 3 loss 0.021236354485154152
Layer  1  loss:  0.23018795251846313 0.0 12.373344421386719
logits torch.Size([689, 4, 1024]) labels torch.Size([689, 4]) 0 1023
Curr loss timestep torch.Size([689, 4]) tensor([299, 592, 449, 196], device='cuda:0') tensor(449, device='cuda:0')
bi 0 loss 0.20286427438259125
bi 1 loss 0.3501541316509247
bi 2 loss 0.16883735358715057
bi 3 loss 0.04011833667755127
Layer  2  loss:  0.2777376174926758 0.0 15.390762329101562
logits torch.Size([689, 4, 1024]) labels torch.Size([689, 4]) 0 1022
Curr loss timestep torch.Size([689, 4]) tensor([444, 653, 447, 198], device='cuda:0') tensor(447, device='cuda:0')
bi 0 loss 0.2605269253253937
bi 1 loss 0.40104708075523376
bi 2 loss 0.19920998811721802
bi 3 loss 0.09540366381406784
Layer  3  loss:  0.30427056550979614 0.0 19.071062088012695
logits torch.Size([689, 4, 1024]) labels torch.Size([689, 4]) 0 1022
Curr loss timestep torch.Size([689, 4]) tensor([444, 647, 348, 200], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.3024219870567322
bi 1 loss 0.4539833664894104
bi 2 loss 0.1946837455034256
bi 3 loss 0.0428791381418705
Layer  4  loss:  0.29279452562332153 0.0 18.38347816467285
logits torch.Size([689, 4, 1024]) labels torch.Size([689, 4]) 0 1022
Curr loss timestep torch.Size([689, 4]) tensor([444, 492, 348, 187], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.30593425035476685
bi 1 loss 0.40507248044013977
bi 2 loss 0.2048097550868988
bi 3 loss 0.04147554188966751
Layer  5  loss:  0.27260661125183105 0.0 15.234808921813965
logits torch.Size([689, 4, 1024]) labels torch.Size([689, 4]) 0 1022
Curr loss timestep torch.Size([689, 4]) tensor([444, 657, 348, 237], device='cuda:0') tensor(445, device='cuda:0')
bi 0 loss 0.2474779486656189
bi 1 loss 0.43708065152168274
bi 2 loss 0.1730271577835083
bi 3 loss 0.01665940321981907
Layer  6  loss:  0.3094828426837921 0.0 16.2698917388916
logits torch.Size([689, 4, 1024]) labels torch.Size([689, 4]) 0 1022
Curr loss timestep torch.Size([689, 4]) tensor([445, 657, 447, 190], device='cuda:0') tensor(445, device='cuda:0')
bi 0 loss 0.2880728542804718
bi 1 loss 0.48871898651123047
bi 2 loss 0.19491344690322876
bi 3 loss 0.025764046236872673
Epoch 0: :   3%|▎         | 15444/600000 [03:04<1:56:40, v_num=12, reduced_train_loss=0.508, global_step=15442.0, consumed_samples=61772.0, train_step_timing in s=0.356]Epoch 0: :   3%|▎         | 15444/600000 [03:04<1:56:40, v_num=12, reduced_train_loss=2.110, global_step=15443.0, consumed_samples=61776.0, train_step_timing in s=0.478]loss mask original None

First layer loss:  0.15086239576339722 torch.Size([594, 4]) 13.945395469665527 0.0
Max loss timestep torch.Size([594, 4]) tensor([456, 203, 139, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.18399375677108765
speech mask sum tensor(366, device='cuda:0') loss mask sum tensor(366, device='cuda:0')
bi 1 loss 0.03920767828822136
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 0.07030583173036575
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 3 loss 0.18735134601593018
speech mask sum tensor(461, device='cuda:0') loss mask sum tensor(461, device='cuda:0')
logits torch.Size([594, 4, 257024]) labels torch.Size([594, 4]) 0 257022
Layer  0  loss:  0.1519376039505005 0.0 13.351629257202148
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([456, 143, 135, 549], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.22957353293895721
bi 1 loss 0.03827492520213127
bi 2 loss 0.04510544240474701
bi 3 loss 0.16364696621894836
Layer  1  loss:  0.16682566702365875 0.0 15.30235481262207
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1022
Curr loss timestep torch.Size([594, 4]) tensor([455, 173,  86, 547], device='cuda:0') tensor(547, device='cuda:0')
bi 0 loss 0.22942852973937988
bi 1 loss 0.05880296975374222
bi 2 loss 0.057398829609155655
bi 3 loss 0.18982796370983124
Layer  2  loss:  0.1939747929573059 0.0 19.4536190032959
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([456, 150, 114, 547], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.28037363290786743
bi 1 loss 0.05256205052137375
bi 2 loss 0.05598935857415199
bi 3 loss 0.218559131026268
Layer  3  loss:  0.16333790123462677 0.0 11.778420448303223
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([557, 124,  83, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.21321304142475128
bi 1 loss 0.051123201847076416
bi 2 loss 0.042189888656139374
bi 3 loss 0.20210400223731995
Layer  4  loss:  0.1789746731519699 0.0 16.660493850708008
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([455, 141, 149, 549], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.2739066481590271
bi 1 loss 0.025616858154535294
bi 2 loss 0.04293684661388397
bi 3 loss 0.19949118793010712
Layer  5  loss:  0.18396304547786713 0.0 16.74476432800293
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([456, 148,  99, 547], device='cuda:0') tensor(547, device='cuda:0')
bi 0 loss 0.2499612420797348
bi 1 loss 0.0378759428858757
bi 2 loss 0.05405503883957863
bi 3 loss 0.22302623093128204
Layer  6  loss:  0.18592849373817444 0.0 16.250476837158203
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([457, 166, 156, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.27012649178504944
bi 1 loss 0.031645238399505615
bi 2 loss 0.05326852574944496
bi 3 loss 0.2139517217874527
Epoch 0: :   3%|▎         | 15445/600000 [03:05<1:56:56, v_num=12, reduced_train_loss=2.110, global_step=15443.0, consumed_samples=61776.0, train_step_timing in s=0.478]Epoch 0: :   3%|▎         | 15445/600000 [03:05<1:56:56, v_num=12, reduced_train_loss=1.380, global_step=15444.0, consumed_samples=61780.0, train_step_timing in s=0.409]loss mask original None

First layer loss:  0.17432008683681488 torch.Size([566, 4]) 12.423521995544434 0.0
Max loss timestep torch.Size([566, 4]) tensor([ 93, 449, 528, 418], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.07598567008972168
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 1 loss 0.1412680745124817
speech mask sum tensor(428, device='cuda:0') loss mask sum tensor(428, device='cuda:0')
bi 2 loss 0.2801867723464966
speech mask sum tensor(468, device='cuda:0') loss mask sum tensor(468, device='cuda:0')
bi 3 loss 0.11909900605678558
speech mask sum tensor(479, device='cuda:0') loss mask sum tensor(479, device='cuda:0')
logits torch.Size([566, 4, 257024]) labels torch.Size([566, 4]) 0 257023
Layer  0  loss:  0.18807312846183777 0.0 12.516731262207031
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([115, 448, 528, 419], device='cuda:0') tensor(419, device='cuda:0')
bi 0 loss 0.05694543570280075
bi 1 loss 0.14806433022022247
bi 2 loss 0.2929367423057556
bi 3 loss 0.14627820253372192
Layer  1  loss:  0.20302873849868774 0.0 14.47275447845459
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([126, 557, 387, 418], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.04468313232064247
bi 1 loss 0.14508718252182007
bi 2 loss 0.33820128440856934
bi 3 loss 0.15281514823436737
Layer  2  loss:  0.20811781287193298 0.0 17.785863876342773
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([129, 448, 386, 418], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.08346503973007202
bi 1 loss 0.16277574002742767
bi 2 loss 0.32930922508239746
bi 3 loss 0.15390539169311523
Layer  3  loss:  0.2000061273574829 0.0 10.68901538848877
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([ 81, 448, 498, 418], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.03278445824980736
bi 1 loss 0.15906263887882233
bi 2 loss 0.32583504915237427
bi 3 loss 0.14541956782341003
Layer  4  loss:  0.21995283663272858 0.0 16.422374725341797
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([118, 449, 388, 418], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.06336907297372818
bi 1 loss 0.19381004571914673
bi 2 loss 0.34650593996047974
bi 3 loss 0.14941294491291046
Layer  5  loss:  0.1953584998846054 0.0 11.210783958435059
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([136, 449, 498, 418], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.0198118444532156
bi 1 loss 0.18361392617225647
bi 2 loss 0.30461135506629944
bi 3 loss 0.1324588656425476
Layer  6  loss:  0.22430387139320374 0.0 14.70273494720459
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([111, 449, 386, 418], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.06046733260154724
bi 1 loss 0.19025559723377228
bi 2 loss 0.36732780933380127
bi 3 loss 0.14611300826072693
Epoch 0: :   3%|▎         | 15446/600000 [03:05<1:57:12, v_num=12, reduced_train_loss=1.380, global_step=15444.0, consumed_samples=61780.0, train_step_timing in s=0.409]Epoch 0: :   3%|▎         | 15446/600000 [03:05<1:57:12, v_num=12, reduced_train_loss=1.610, global_step=15445.0, consumed_samples=61784.0, train_step_timing in s=0.393]loss mask original None

First layer loss:  0.07340268045663834 torch.Size([531, 4]) 8.265172958374023 0.0
Max loss timestep torch.Size([531, 4]) tensor([426,  48, 348, 181], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 0.07602375000715256
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 1 loss 0.05680747702717781
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
bi 2 loss 0.13065344095230103
speech mask sum tensor(114, device='cuda:0') loss mask sum tensor(114, device='cuda:0')
bi 3 loss 0.020362231880426407
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
logits torch.Size([531, 4, 257024]) labels torch.Size([531, 4]) 0 257022
Layer  0  loss:  0.05914326012134552 0.0 6.9451799392700195
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1023
Curr loss timestep torch.Size([531, 4]) tensor([498, 224, 348, 167], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.05120567977428436
bi 1 loss 0.03524687886238098
bi 2 loss 0.13766884803771973
bi 3 loss 0.060174427926540375
Layer  1  loss:  0.0704173818230629 0.0 9.034235954284668
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1023
Curr loss timestep torch.Size([531, 4]) tensor([426, 129, 347, 187], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.07198634743690491
bi 1 loss 0.04068249836564064
bi 2 loss 0.16279195249080658
bi 3 loss 0.010164061561226845
Layer  2  loss:  0.08417089283466339 0.0 10.001304626464844
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1022
Curr loss timestep torch.Size([531, 4]) tensor([426, 240, 348, 175], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.07738397270441055
bi 1 loss 0.04432738199830055
bi 2 loss 0.23260919749736786
bi 3 loss 0.019620256498456
Layer  3  loss:  0.07400312274694443 0.0 13.42794132232666
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1023
Curr loss timestep torch.Size([531, 4]) tensor([427, 188, 348, 184], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.060120318084955215
bi 1 loss 0.03597011789679527
bi 2 loss 0.23597678542137146
bi 3 loss 0.026268931105732918
Layer  4  loss:  0.08271750062704086 0.0 9.990028381347656
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1022
Curr loss timestep torch.Size([531, 4]) tensor([426, 111, 348, 184], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.09202156215906143
bi 1 loss 0.027368521317839622
bi 2 loss 0.19613264501094818
bi 3 loss 0.02182712033390999
Layer  5  loss:  0.08260534703731537 0.0 13.102736473083496
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1023
Curr loss timestep torch.Size([531, 4]) tensor([428, 133, 348, 194], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.06343141943216324
bi 1 loss 0.054777272045612335
bi 2 loss 0.24669678509235382
bi 3 loss 0.03241365775465965
Layer  6  loss:  0.07061970978975296 0.0 9.969953536987305
logits torch.Size([531, 4, 1024]) labels torch.Size([531, 4]) 0 1022
Curr loss timestep torch.Size([531, 4]) tensor([426,  95, 349, 197], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 0.07894279807806015
bi 1 loss 0.02835654839873314
bi 2 loss 0.15114563703536987
bi 3 loss 0.026056606322526932
Epoch 0: :   3%|▎         | 15447/600000 [03:06<1:57:27, v_num=12, reduced_train_loss=1.610, global_step=15445.0, consumed_samples=61784.0, train_step_timing in s=0.393]Epoch 0: :   3%|▎         | 15447/600000 [03:06<1:57:27, v_num=12, reduced_train_loss=0.597, global_step=15446.0, consumed_samples=61788.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  3.5607666969299316 torch.Size([456, 4]) 11.933852195739746 0.0
Max loss timestep torch.Size([456, 4]) tensor([363, 173, 117, 133], device='cuda:0') tensor(156, device='cuda:0')
bi 0 loss 3.782071352005005
speech mask sum tensor(317, device='cuda:0') loss mask sum tensor(317, device='cuda:0')
bi 1 loss 3.7697536945343018
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
bi 2 loss 3.4239375591278076
speech mask sum tensor(107, device='cuda:0') loss mask sum tensor(107, device='cuda:0')
bi 3 loss 2.96293044090271
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([456, 4, 257024]) labels torch.Size([456, 4]) 0 257022
Layer  0  loss:  3.9608137607574463 0.0 11.345688819885254
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([383, 179, 154, 105], device='cuda:0') tensor(146, device='cuda:0')
bi 0 loss 4.281270980834961
bi 1 loss 4.169634819030762
bi 2 loss 3.569197654724121
bi 3 loss 3.333141803741455
Layer  1  loss:  4.391442775726318 0.0 11.130561828613281
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1022
Curr loss timestep torch.Size([456, 4]) tensor([362, 191, 115,  94], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 4.566877365112305
bi 1 loss 4.608069896697998
bi 2 loss 3.9173858165740967
bi 3 loss 4.150554656982422
Layer  2  loss:  4.862697124481201 0.0 11.783187866210938
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1022
Curr loss timestep torch.Size([456, 4]) tensor([161, 121, 163,  99], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 5.123095512390137
bi 1 loss 4.921994209289551
bi 2 loss 4.483798503875732
bi 3 loss 4.5041985511779785
Layer  3  loss:  4.848021507263184 0.0 10.21126937866211
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([282, 140, 129,  81], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 4.887080669403076
bi 1 loss 5.1106085777282715
bi 2 loss 4.867614269256592
bi 3 loss 4.49450159072876
Layer  4  loss:  5.033901691436768 0.0 11.006322860717773
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1022
Curr loss timestep torch.Size([456, 4]) tensor([438, 193, 179, 125], device='cuda:0') tensor(156, device='cuda:0')
bi 0 loss 5.18337345123291
bi 1 loss 5.324326992034912
bi 2 loss 4.751293659210205
bi 3 loss 4.634765625
Layer  5  loss:  5.052107810974121 0.0 11.06972885131836
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1020
Curr loss timestep torch.Size([456, 4]) tensor([243, 195, 154, 163], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 5.255391597747803
bi 1 loss 5.185895919799805
bi 2 loss 4.768058776855469
bi 3 loss 4.680109024047852
Layer  6  loss:  5.111488342285156 0.0 10.201257705688477
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([350, 212, 113, 175], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 5.268187522888184
bi 1 loss 5.144920825958252
bi 2 loss 4.970594882965088
bi 3 loss 4.830832481384277
Epoch 0: :   3%|▎         | 15448/600000 [03:06<1:57:40, v_num=12, reduced_train_loss=0.597, global_step=15446.0, consumed_samples=61788.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15448/600000 [03:06<1:57:40, v_num=12, reduced_train_loss=36.80, global_step=15447.0, consumed_samples=61792.0, train_step_timing in s=0.312]loss mask original None

First layer loss:  0.08362942188978195 torch.Size([550, 4]) 8.240951538085938 0.0
Max loss timestep torch.Size([550, 4]) tensor([292, 258, 400, 484], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.04519651457667351
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
bi 1 loss 0.11466659605503082
speech mask sum tensor(379, device='cuda:0') loss mask sum tensor(379, device='cuda:0')
bi 2 loss 0.12901321053504944
speech mask sum tensor(384, device='cuda:0') loss mask sum tensor(384, device='cuda:0')
bi 3 loss 0.029609743505716324
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
logits torch.Size([550, 4, 257024]) labels torch.Size([550, 4]) 0 257022
Layer  0  loss:  0.10740549117326736 0.0 14.375946998596191
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([351, 258, 403, 298], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.06996505707502365
bi 1 loss 0.14680227637290955
bi 2 loss 0.1529269516468048
bi 3 loss 0.04434783756732941
Layer  1  loss:  0.1125461757183075 0.0 13.000129699707031
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1022
Curr loss timestep torch.Size([550, 4]) tensor([319, 258, 402, 276], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.10321153700351715
bi 1 loss 0.154412642121315
bi 2 loss 0.16092906892299652
bi 3 loss 0.027623729780316353
Layer  2  loss:  0.12350771576166153 0.0 10.94502067565918
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([318, 258, 402, 318], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.09527498483657837
bi 1 loss 0.15553072094917297
bi 2 loss 0.17768065631389618
bi 3 loss 0.05365210399031639
Layer  3  loss:  0.11052393913269043 0.0 9.644731521606445
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([327, 258, 403, 208], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.07402081042528152
bi 1 loss 0.130792498588562
bi 2 loss 0.16976208984851837
bi 3 loss 0.052118316292762756
Layer  4  loss:  0.12099142372608185 0.0 12.645633697509766
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([352, 477, 402, 304], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.07334943860769272
bi 1 loss 0.17211942374706268
bi 2 loss 0.18433670699596405
bi 3 loss 0.03429776802659035
Layer  5  loss:  0.12172029912471771 0.0 10.945073127746582
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([286, 258, 442, 432], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.07995878159999847
bi 1 loss 0.1326567679643631
bi 2 loss 0.20869265496730804
bi 3 loss 0.047736771404743195
Layer  6  loss:  0.10945124924182892 0.0 13.541423797607422
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([309, 326, 403, 299], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.09339196979999542
bi 1 loss 0.1384214162826538
bi 2 loss 0.16058452427387238
bi 3 loss 0.03853893652558327
Epoch 0: :   3%|▎         | 15449/600000 [03:06<1:57:55, v_num=12, reduced_train_loss=36.80, global_step=15447.0, consumed_samples=61792.0, train_step_timing in s=0.312]Epoch 0: :   3%|▎         | 15449/600000 [03:06<1:57:55, v_num=12, reduced_train_loss=0.890, global_step=15448.0, consumed_samples=61796.0, train_step_timing in s=0.376]loss mask original None

First layer loss:  0.15907703340053558 torch.Size([703, 4]) 14.556721687316895 0.0
Max loss timestep torch.Size([703, 4]) tensor([ 90, 103, 468, 246], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.04035080969333649
speech mask sum tensor(267, device='cuda:0') loss mask sum tensor(267, device='cuda:0')
bi 1 loss 0.03248956799507141
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
bi 2 loss 0.272163987159729
speech mask sum tensor(501, device='cuda:0') loss mask sum tensor(501, device='cuda:0')
bi 3 loss 0.06268112361431122
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([703, 4, 257024]) labels torch.Size([703, 4]) 0 257022
Layer  0  loss:  0.16029345989227295 0.0 13.5186185836792
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([279, 142, 468, 290], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.05402490124106407
bi 1 loss 0.05770484730601311
bi 2 loss 0.25292831659317017
bi 3 loss 0.1040620505809784
Layer  1  loss:  0.17134279012680054 0.0 12.815656661987305
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([288,  90, 469, 265], device='cuda:0') tensor(469, device='cuda:0')
bi 0 loss 0.056952960789203644
bi 1 loss 0.02457372657954693
bi 2 loss 0.2771139144897461
bi 3 loss 0.12444079667329788
Layer  2  loss:  0.17020587623119354 0.0 14.985682487487793
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([236,  81, 550, 208], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.04697804152965546
bi 1 loss 0.03476433455944061
bi 2 loss 0.29004764556884766
bi 3 loss 0.06270120292901993
Layer  3  loss:  0.17313221096992493 0.0 13.61107063293457
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1021
Curr loss timestep torch.Size([703, 4]) tensor([251,  94, 467, 275], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.057819705456495285
bi 1 loss 0.023842018097639084
bi 2 loss 0.29258787631988525
bi 3 loss 0.06318484991788864
Layer  4  loss:  0.1741657257080078 0.0 19.63292121887207
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([292, 118, 638, 272], device='cuda:0') tensor(638, device='cuda:0')
bi 0 loss 0.05172300338745117
bi 1 loss 0.03391085937619209
bi 2 loss 0.29540959000587463
bi 3 loss 0.06336449831724167
Layer  5  loss:  0.1629188060760498 0.0 14.058004379272461
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1023
Curr loss timestep torch.Size([703, 4]) tensor([216,  79, 638, 290], device='cuda:0') tensor(638, device='cuda:0')
bi 0 loss 0.05243832245469093
bi 1 loss 0.07907523959875107
bi 2 loss 0.24184821546077728
bi 3 loss 0.1639159768819809
Layer  6  loss:  0.164686381816864 0.0 15.609552383422852
logits torch.Size([703, 4, 1024]) labels torch.Size([703, 4]) 0 1022
Curr loss timestep torch.Size([703, 4]) tensor([ 87, 137, 467, 290], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.03956398740410805
bi 1 loss 0.02910098433494568
bi 2 loss 0.2732737958431244
bi 3 loss 0.11879847198724747
Epoch 0: :   3%|▎         | 15450/600000 [03:07<1:58:14, v_num=12, reduced_train_loss=0.890, global_step=15448.0, consumed_samples=61796.0, train_step_timing in s=0.376]Epoch 0: :   3%|▎         | 15450/600000 [03:07<1:58:14, v_num=12, reduced_train_loss=1.340, global_step=15449.0, consumed_samples=61800.0, train_step_timing in s=0.482]loss mask original None

First layer loss:  0.01446278765797615 torch.Size([317, 4]) 0.1739465445280075 0.0
Max loss timestep torch.Size([317, 4]) tensor([108, 164, 160, 292], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 0.014891321770846844
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 1 loss 0.012500543147325516
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 2 loss 0.012987082824110985
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 3 loss 0.016166141256690025
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
logits torch.Size([317, 4, 257024]) labels torch.Size([317, 4]) 0 257022
Layer  0  loss:  0.013939943164587021 0.0 0.2002800852060318
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1023
Curr loss timestep torch.Size([317, 4]) tensor([139, 220, 117, 285], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.014262234792113304
bi 1 loss 0.011388692073523998
bi 2 loss 0.011239796876907349
bi 3 loss 0.016784120351076126
Layer  1  loss:  0.010946288704872131 0.0 0.13410267233848572
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1022
Curr loss timestep torch.Size([317, 4]) tensor([198, 201, 144, 287], device='cuda:0') tensor(144, device='cuda:0')
bi 0 loss 0.011519303545355797
bi 1 loss 0.012494601309299469
bi 2 loss 0.006198205053806305
bi 3 loss 0.012322131544351578
Layer  2  loss:  0.01415213756263256 0.0 0.5593817234039307
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1023
Curr loss timestep torch.Size([317, 4]) tensor([150, 169, 121, 289], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.010340242646634579
bi 1 loss 0.015438706614077091
bi 2 loss 0.01290221232920885
bi 3 loss 0.016998618841171265
Layer  3  loss:  0.013361906632781029 0.0 0.29401445388793945
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1023
Curr loss timestep torch.Size([317, 4]) tensor([155, 179,  92, 245], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 0.015684980899095535
bi 1 loss 0.01134162861853838
bi 2 loss 0.011966374702751637
bi 3 loss 0.013613956980407238
Layer  4  loss:  0.012765958905220032 0.0 0.2378835678100586
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1022
Curr loss timestep torch.Size([317, 4]) tensor([ 98, 226, 131, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.015100224874913692
bi 1 loss 0.011199397034943104
bi 2 loss 0.00906530674546957
bi 3 loss 0.014067658223211765
Layer  5  loss:  0.012825875543057919 0.0 0.14286111295223236
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1017
Curr loss timestep torch.Size([317, 4]) tensor([134, 190, 130, 263], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 0.012542669661343098
bi 1 loss 0.0142649682238698
bi 2 loss 0.01091407798230648
bi 3 loss 0.013281037099659443
Layer  6  loss:  0.013760360889136791 0.0 0.19381442666053772
logits torch.Size([317, 4, 1024]) labels torch.Size([317, 4]) 0 1023
Curr loss timestep torch.Size([317, 4]) tensor([108, 219, 114, 225], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 0.01570611633360386
bi 1 loss 0.013827802613377571
bi 2 loss 0.009449394419789314
bi 3 loss 0.014729167334735394
Epoch 0: :   3%|▎         | 15451/600000 [03:07<1:58:25, v_num=12, reduced_train_loss=1.340, global_step=15449.0, consumed_samples=61800.0, train_step_timing in s=0.482]Epoch 0: :   3%|▎         | 15451/600000 [03:07<1:58:25, v_num=12, reduced_train_loss=0.106, global_step=15450.0, consumed_samples=61804.0, train_step_timing in s=0.261]loss mask original None

First layer loss:  3.746410846710205 torch.Size([484, 4]) 10.580191612243652 0.0
Max loss timestep torch.Size([484, 4]) tensor([282, 456, 385, 178], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 3.8956310749053955
speech mask sum tensor(189, device='cuda:0') loss mask sum tensor(189, device='cuda:0')
bi 1 loss 3.985511541366577
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
bi 2 loss 3.4250152111053467
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 3 loss 3.4572489261627197
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
logits torch.Size([484, 4, 257024]) labels torch.Size([484, 4]) 0 257022
Layer  0  loss:  4.332240581512451 0.0 10.570146560668945
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1023
Curr loss timestep torch.Size([484, 4]) tensor([265, 339, 300, 206], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 4.585267543792725
bi 1 loss 4.763426780700684
bi 2 loss 3.5497090816497803
bi 3 loss 4.13350772857666
Layer  1  loss:  4.594499588012695 0.0 11.658897399902344
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1023
Curr loss timestep torch.Size([484, 4]) tensor([170, 411, 310, 168], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.464273929595947
bi 1 loss 5.0138468742370605
bi 2 loss 4.241987705230713
bi 3 loss 4.35969352722168
Layer  2  loss:  4.945839881896973 0.0 11.081169128417969
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1022
Curr loss timestep torch.Size([484, 4]) tensor([193, 461, 296, 153], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 4.831484317779541
bi 1 loss 5.329651832580566
bi 2 loss 4.474746227264404
bi 3 loss 4.942324161529541
Layer  3  loss:  5.041036605834961 0.0 10.535404205322266
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1022
Curr loss timestep torch.Size([484, 4]) tensor([290, 460, 428, 172], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 5.029699325561523
bi 1 loss 5.472718238830566
bi 2 loss 4.447990417480469
bi 3 loss 4.955601692199707
Layer  4  loss:  5.29972505569458 0.0 10.523465156555176
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1022
Curr loss timestep torch.Size([484, 4]) tensor([261, 471, 286, 117], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 5.273540019989014
bi 1 loss 5.739697456359863
bi 2 loss 4.757019519805908
bi 3 loss 5.143527030944824
Layer  5  loss:  5.283761978149414 0.0 9.792871475219727
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1021
Curr loss timestep torch.Size([484, 4]) tensor([279, 471, 384, 193], device='cuda:0') tensor(208, device='cuda:0')
bi 0 loss 5.4505791664123535
bi 1 loss 5.775561809539795
bi 2 loss 4.644724369049072
bi 3 loss 4.865060329437256
Layer  6  loss:  5.3232421875 0.0 10.159404754638672
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1019
Curr loss timestep torch.Size([484, 4]) tensor([175, 431, 378, 119], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 5.314391613006592
bi 1 loss 5.779385566711426
bi 2 loss 4.870934963226318
bi 3 loss 4.9715986251831055
Epoch 0: :   3%|▎         | 15452/600000 [03:08<1:58:38, v_num=12, reduced_train_loss=0.106, global_step=15450.0, consumed_samples=61804.0, train_step_timing in s=0.261]Epoch 0: :   3%|▎         | 15452/600000 [03:08<1:58:38, v_num=12, reduced_train_loss=38.60, global_step=15451.0, consumed_samples=61808.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  0.05550375208258629 torch.Size([373, 4]) 2.94185471534729 0.0
Max loss timestep torch.Size([373, 4]) tensor([146, 331, 181, 340], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.019949600100517273
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 1 loss 0.09315543621778488
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 2 loss 0.014317246153950691
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 3 loss 0.05491149052977562
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
logits torch.Size([373, 4, 257024]) labels torch.Size([373, 4]) 0 257022
Layer  0  loss:  0.0538128986954689 0.0 2.1344056129455566
logits torch.Size([373, 4, 1024]) labels torch.Size([373, 4]) 0 1023
Curr loss timestep torch.Size([373, 4]) tensor([129, 269, 164, 340], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.019315659999847412
bi 1 loss 0.07146842777729034
bi 2 loss 0.027104254812002182
bi 3 loss 0.06538789719343185
Layer  1  loss:  0.05228983610868454 0.0 2.4133048057556152
logits torch.Size([373, 4, 1024]) labels torch.Size([373, 4]) 0 1022
Curr loss timestep torch.Size([373, 4]) tensor([154, 276, 187, 279], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.012482747435569763
bi 1 loss 0.08422543853521347
bi 2 loss 0.036282017827034
bi 3 loss 0.049803487956523895
Layer  2  loss:  0.06209962069988251 0.0 3.1950135231018066
logits torch.Size([373, 4, 1024]) labels torch.Size([373, 4]) 0 1022
Curr loss timestep torch.Size([373, 4]) tensor([127, 300, 167, 196], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.024851437658071518
bi 1 loss 0.10445725917816162
bi 2 loss 0.032029662281274796
bi 3 loss 0.05406400188803673
Layer  3  loss:  0.06155019253492355 0.0 3.7373011112213135
logits torch.Size([373, 4, 1024]) labels torch.Size([373, 4]) 0 1020
Curr loss timestep torch.Size([373, 4]) tensor([151, 340, 212, 316], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.02335486002266407
bi 1 loss 0.10293332487344742
bi 2 loss 0.034668415784835815
bi 3 loss 0.053710196167230606
Layer  4  loss:  0.051966939121484756 0.0 2.777308940887451
logits torch.Size([373, 4, 1024]) labels torch.Size([373, 4]) 0 1022
Curr loss timestep torch.Size([373, 4]) tensor([ 95, 272, 182, 339], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.02399597316980362
bi 1 loss 0.08005800098180771
bi 2 loss 0.02597193419933319
bi 3 loss 0.05053196847438812
Layer  5  loss:  0.05177601799368858 0.0 2.3314266204833984
logits torch.Size([373, 4, 1024]) labels torch.Size([373, 4]) 0 1023
Curr loss timestep torch.Size([373, 4]) tensor([162, 275, 218, 259], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.024007946252822876
bi 1 loss 0.06233933940529823
bi 2 loss 0.02866501174867153
bi 3 loss 0.06497041881084442
Layer  6  loss:  0.05523190647363663 0.0 6.123553276062012
logits torch.Size([373, 4, 1024]) labels torch.Size([373, 4]) 0 1023
Curr loss timestep torch.Size([373, 4]) tensor([158, 275, 197, 166], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.02894870564341545
bi 1 loss 0.08227453380823135
bi 2 loss 0.02477402053773403
bi 3 loss 0.05551084503531456
Epoch 0: :   3%|▎         | 15453/600000 [03:08<1:58:50, v_num=12, reduced_train_loss=38.60, global_step=15451.0, consumed_samples=61808.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15453/600000 [03:08<1:58:50, v_num=12, reduced_train_loss=0.444, global_step=15452.0, consumed_samples=61812.0, train_step_timing in s=0.288]loss mask original None

First layer loss:  3.7050116062164307 torch.Size([468, 4]) 11.272363662719727 0.0
Max loss timestep torch.Size([468, 4]) tensor([188, 184, 231, 206], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 3.416682004928589
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 1 loss 3.4875288009643555
speech mask sum tensor(340, device='cuda:0') loss mask sum tensor(340, device='cuda:0')
bi 2 loss 4.122618198394775
speech mask sum tensor(285, device='cuda:0') loss mask sum tensor(285, device='cuda:0')
bi 3 loss 3.6351189613342285
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
logits torch.Size([468, 4, 257024]) labels torch.Size([468, 4]) 0 257022
Layer  0  loss:  4.243625164031982 0.0 10.592890739440918
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([190, 299, 242, 265], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 3.8753185272216797
bi 1 loss 3.677107572555542
bi 2 loss 4.944968223571777
bi 3 loss 4.330253601074219
Layer  1  loss:  4.532614231109619 0.0 10.450150489807129
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([226, 347, 157, 252], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.11648416519165
bi 1 loss 4.202849864959717
bi 2 loss 5.121056079864502
bi 3 loss 4.464841842651367
Layer  2  loss:  4.856060981750488 0.0 10.210221290588379
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([242, 309, 219, 345], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 4.453009128570557
bi 1 loss 4.51824951171875
bi 2 loss 5.351574897766113
bi 3 loss 4.886480808258057
Layer  3  loss:  4.877711296081543 0.0 11.482380867004395
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1021
Curr loss timestep torch.Size([468, 4]) tensor([195, 123, 213, 315], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 4.573740005493164
bi 1 loss 4.477333068847656
bi 2 loss 5.35827112197876
bi 3 loss 4.967274188995361
Layer  4  loss:  5.0022873878479 0.0 11.413177490234375
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([233, 209, 394, 386], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.254651069641113
bi 1 loss 4.662752628326416
bi 2 loss 5.481581687927246
bi 3 loss 5.1557393074035645
Layer  5  loss:  5.126586437225342 0.0 10.294902801513672
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([254, 187, 281, 187], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.588194370269775
bi 1 loss 4.875537872314453
bi 2 loss 5.4847822189331055
bi 3 loss 5.231870651245117
Layer  6  loss:  5.189206123352051 0.0 10.625207901000977
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([204, 119, 160, 296], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 4.610890865325928
bi 1 loss 4.874448299407959
bi 2 loss 5.5134406089782715
bi 3 loss 5.4162139892578125
Epoch 0: :   3%|▎         | 15454/600000 [03:08<1:59:03, v_num=12, reduced_train_loss=0.444, global_step=15452.0, consumed_samples=61812.0, train_step_timing in s=0.288]Epoch 0: :   3%|▎         | 15454/600000 [03:08<1:59:03, v_num=12, reduced_train_loss=37.50, global_step=15453.0, consumed_samples=61816.0, train_step_timing in s=0.319]loss mask original None

First layer loss:  0.16098466515541077 torch.Size([645, 4]) 6.488492488861084 0.0
Max loss timestep torch.Size([645, 4]) tensor([475, 289, 330, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.17389357089996338
speech mask sum tensor(463, device='cuda:0') loss mask sum tensor(463, device='cuda:0')
bi 1 loss 0.10024341195821762
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 2 loss 0.17594195902347565
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 3 loss 0.13411200046539307
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
logits torch.Size([645, 4, 257024]) labels torch.Size([645, 4]) 0 257023
Layer  0  loss:  0.1734413504600525 0.0 10.065248489379883
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1023
Curr loss timestep torch.Size([645, 4]) tensor([386, 286, 330, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.18166092038154602
bi 1 loss 0.07579532265663147
bi 2 loss 0.18865138292312622
bi 3 loss 0.17948134243488312
Layer  1  loss:  0.19124183058738708 0.0 13.365300178527832
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1023
Curr loss timestep torch.Size([645, 4]) tensor([408, 292, 330, 280], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.24809107184410095
bi 1 loss 0.08407417684793472
bi 2 loss 0.15304656326770782
bi 3 loss 0.1822701394557953
Layer  2  loss:  0.19981388747692108 0.0 15.42049789428711
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([386, 228, 330, 280], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.20422063767910004
bi 1 loss 0.09762097150087357
bi 2 loss 0.21229366958141327
bi 3 loss 0.22355449199676514
Layer  3  loss:  0.21186323463916779 0.0 13.392657279968262
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1019
Curr loss timestep torch.Size([645, 4]) tensor([386, 289, 382, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.24002161622047424
bi 1 loss 0.08948852121829987
bi 2 loss 0.21341826021671295
bi 3 loss 0.20780044794082642
Layer  4  loss:  0.21200117468833923 0.0 15.00169563293457
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([409, 273, 330, 279], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.22458083927631378
bi 1 loss 0.08854929357767105
bi 2 loss 0.2405562400817871
bi 3 loss 0.19590559601783752
Layer  5  loss:  0.21082884073257446 0.0 14.989501953125
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1022
Curr loss timestep torch.Size([645, 4]) tensor([386, 289, 382, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.2184772491455078
bi 1 loss 0.0688648521900177
bi 2 loss 0.2236250936985016
bi 3 loss 0.24873340129852295
Layer  6  loss:  0.2437695413827896 0.0 15.405783653259277
logits torch.Size([645, 4, 1024]) labels torch.Size([645, 4]) 0 1021
Curr loss timestep torch.Size([645, 4]) tensor([409, 289, 382, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.2838241755962372
bi 1 loss 0.10725045204162598
bi 2 loss 0.252517968416214
bi 3 loss 0.2034919559955597
Epoch 0: :   3%|▎         | 15455/600000 [03:09<1:59:21, v_num=12, reduced_train_loss=37.50, global_step=15453.0, consumed_samples=61816.0, train_step_timing in s=0.319]Epoch 0: :   3%|▎         | 15455/600000 [03:09<1:59:21, v_num=12, reduced_train_loss=1.600, global_step=15454.0, consumed_samples=61820.0, train_step_timing in s=0.445]loss mask original None

First layer loss:  3.5094220638275146 torch.Size([376, 4]) 10.441093444824219 0.0
Max loss timestep torch.Size([376, 4]) tensor([268, 154, 291, 238], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 3.5450267791748047
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 1 loss 3.8776605129241943
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
bi 2 loss 3.462578058242798
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 2.94419002532959
speech mask sum tensor(65, device='cuda:0') loss mask sum tensor(65, device='cuda:0')
logits torch.Size([376, 4, 257024]) labels torch.Size([376, 4]) 0 257022
Layer  0  loss:  3.9276223182678223 0.0 10.157791137695312
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1023
Curr loss timestep torch.Size([376, 4]) tensor([223,  85, 344, 232], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 4.142662525177002
bi 1 loss 3.787456512451172
bi 2 loss 3.742603063583374
bi 3 loss 3.8052382469177246
Layer  1  loss:  4.3297119140625 0.0 10.014849662780762
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([197,  86, 316, 237], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 4.353320598602295
bi 1 loss 4.362072467803955
bi 2 loss 4.354356288909912
bi 3 loss 4.153763294219971
Layer  2  loss:  4.427705764770508 0.0 9.415755271911621
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([161, 127, 347, 258], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.549997329711914
bi 1 loss 4.681839942932129
bi 2 loss 4.255050182342529
bi 3 loss 4.003023147583008
Layer  3  loss:  4.616746425628662 0.0 9.283074378967285
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([275, 159, 264, 249], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 4.774904727935791
bi 1 loss 4.680606842041016
bi 2 loss 4.5313920974731445
bi 3 loss 4.176370143890381
Layer  4  loss:  4.7123494148254395 0.0 11.342975616455078
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([261, 156, 257, 245], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 4.8786187171936035
bi 1 loss 4.702402591705322
bi 2 loss 4.5989251136779785
bi 3 loss 4.411715984344482
Layer  5  loss:  4.762851238250732 0.0 11.033449172973633
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([130,  91, 253, 241], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 5.007424831390381
bi 1 loss 4.782369613647461
bi 2 loss 4.520857334136963
bi 3 loss 4.4239654541015625
Layer  6  loss:  4.87298059463501 0.0 11.006881713867188
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1019
Curr loss timestep torch.Size([376, 4]) tensor([284, 111, 318, 273], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 5.1488823890686035
bi 1 loss 4.784465312957764
bi 2 loss 4.678657531738281
bi 3 loss 4.492973327636719
Epoch 0: :   3%|▎         | 15456/600000 [03:09<1:59:32, v_num=12, reduced_train_loss=1.600, global_step=15454.0, consumed_samples=61820.0, train_step_timing in s=0.445]Epoch 0: :   3%|▎         | 15456/600000 [03:09<1:59:32, v_num=12, reduced_train_loss=35.20, global_step=15455.0, consumed_samples=61824.0, train_step_timing in s=0.285]loss mask original None

First layer loss:  0.2981090843677521 torch.Size([683, 4]) 15.48830795288086 0.0
Max loss timestep torch.Size([683, 4]) tensor([435, 542, 427, 574], device='cuda:0') tensor(574, device='cuda:0')
bi 0 loss 0.2118857204914093
speech mask sum tensor(483, device='cuda:0') loss mask sum tensor(483, device='cuda:0')
bi 1 loss 0.3691955804824829
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
bi 2 loss 0.3220716714859009
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 3 loss 0.31951597332954407
speech mask sum tensor(487, device='cuda:0') loss mask sum tensor(487, device='cuda:0')
logits torch.Size([683, 4, 257024]) labels torch.Size([683, 4]) 0 257022
Layer  0  loss:  0.32817208766937256 0.0 14.45622730255127
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([435, 568, 427, 574], device='cuda:0') tensor(574, device='cuda:0')
bi 0 loss 0.24986910820007324
bi 1 loss 0.3608110845088959
bi 2 loss 0.33595848083496094
bi 3 loss 0.3779090642929077
Layer  1  loss:  0.3451462686061859 0.0 13.864551544189453
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([519, 520, 429, 399], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.22132235765457153
bi 1 loss 0.41731783747673035
bi 2 loss 0.4178343117237091
bi 3 loss 0.3801262676715851
Layer  2  loss:  0.37186142802238464 0.0 14.427072525024414
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([435, 520, 427, 575], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.24337802827358246
bi 1 loss 0.39945879578590393
bi 2 loss 0.4333733320236206
bi 3 loss 0.44985127449035645
Layer  3  loss:  0.3732362687587738 0.0 13.392768859863281
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([435, 520, 427, 575], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.28314530849456787
bi 1 loss 0.4356285631656647
bi 2 loss 0.4302273690700531
bi 3 loss 0.3894107937812805
Layer  4  loss:  0.3756096363067627 0.0 18.32061767578125
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([524, 574, 427, 574], device='cuda:0') tensor(574, device='cuda:0')
bi 0 loss 0.23412513732910156
bi 1 loss 0.44471219182014465
bi 2 loss 0.534410834312439
bi 3 loss 0.38989388942718506
Layer  5  loss:  0.38390058279037476 0.0 17.231895446777344
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([529, 542, 427, 573], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.2668423652648926
bi 1 loss 0.5137932896614075
bi 2 loss 0.34224700927734375
bi 3 loss 0.4230312407016754
Layer  6  loss:  0.38592925667762756 0.0 15.812304496765137
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([261, 520, 427, 574], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.27632787823677063
bi 1 loss 0.4376693665981293
bi 2 loss 0.44143146276474
bi 3 loss 0.43007203936576843
Epoch 0: :   3%|▎         | 15457/600000 [03:10<1:59:51, v_num=12, reduced_train_loss=35.20, global_step=15455.0, consumed_samples=61824.0, train_step_timing in s=0.285]Epoch 0: :   3%|▎         | 15457/600000 [03:10<1:59:51, v_num=12, reduced_train_loss=2.860, global_step=15456.0, consumed_samples=61828.0, train_step_timing in s=0.465]loss mask original None

First layer loss:  3.7501118183135986 torch.Size([612, 4]) 11.74440860748291 0.0
Max loss timestep torch.Size([612, 4]) tensor([298, 578, 323, 139], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 3.186060667037964
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 1 loss 3.880810022354126
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
bi 2 loss 3.9281275272369385
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
bi 3 loss 3.6553590297698975
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
logits torch.Size([612, 4, 257024]) labels torch.Size([612, 4]) 0 257022
Layer  0  loss:  4.239614963531494 0.0 11.467185974121094
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1023
Curr loss timestep torch.Size([612, 4]) tensor([300, 522, 280,  83], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.068892002105713
bi 1 loss 4.344524383544922
bi 2 loss 4.176817893981934
bi 3 loss 4.23051118850708
Layer  1  loss:  4.421565532684326 0.0 10.168574333190918
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1023
Curr loss timestep torch.Size([612, 4]) tensor([240, 214, 171, 185], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.097346782684326
bi 1 loss 4.521482944488525
bi 2 loss 4.513278007507324
bi 3 loss 4.313096523284912
Layer  2  loss:  4.7547454833984375 0.0 10.264131546020508
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1023
Curr loss timestep torch.Size([612, 4]) tensor([269, 597, 291, 172], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.578413963317871
bi 1 loss 4.906092643737793
bi 2 loss 4.594674587249756
bi 3 loss 4.791909217834473
Layer  3  loss:  4.876965522766113 0.0 10.830785751342773
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1019
Curr loss timestep torch.Size([612, 4]) tensor([257, 383, 393, 172], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 4.635120391845703
bi 1 loss 4.973409652709961
bi 2 loss 4.930568695068359
bi 3 loss 4.758231163024902
Layer  4  loss:  4.9528021812438965 0.0 10.721396446228027
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1022
Curr loss timestep torch.Size([612, 4]) tensor([202, 561, 254,  94], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.678142070770264
bi 1 loss 5.033305644989014
bi 2 loss 4.984407424926758
bi 3 loss 4.957302570343018
Layer  5  loss:  5.043012619018555 0.0 10.378019332885742
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1022
Curr loss timestep torch.Size([612, 4]) tensor([210, 421, 414,  95], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.805827617645264
bi 1 loss 5.0999226570129395
bi 2 loss 5.069786071777344
bi 3 loss 5.085167407989502
Layer  6  loss:  5.124956130981445 0.0 10.684663772583008
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1023
Curr loss timestep torch.Size([612, 4]) tensor([285, 276, 267,  72], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.731498718261719
bi 1 loss 5.173050880432129
bi 2 loss 5.189373970031738
bi 3 loss 5.295439720153809
Epoch 0: :   3%|▎         | 15458/600000 [03:10<2:00:06, v_num=12, reduced_train_loss=2.860, global_step=15456.0, consumed_samples=61828.0, train_step_timing in s=0.465]Epoch 0: :   3%|▎         | 15458/600000 [03:10<2:00:06, v_num=12, reduced_train_loss=37.20, global_step=15457.0, consumed_samples=61832.0, train_step_timing in s=0.382]loss mask original None

First layer loss:  0.03292107954621315 torch.Size([389, 4]) 5.106633186340332 0.0
Max loss timestep torch.Size([389, 4]) tensor([131, 180, 147, 220], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 0.025177013128995895
speech mask sum tensor(185, device='cuda:0') loss mask sum tensor(185, device='cuda:0')
bi 1 loss 0.01665169931948185
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
bi 2 loss 0.03464694693684578
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
bi 3 loss 0.052129391580820084
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
logits torch.Size([389, 4, 257024]) labels torch.Size([389, 4]) 0 257022
Layer  0  loss:  0.01880066655576229 0.0 0.2465323656797409
logits torch.Size([389, 4, 1024]) labels torch.Size([389, 4]) 0 1023
Curr loss timestep torch.Size([389, 4]) tensor([ 76, 175, 176, 347], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 0.016094185411930084
bi 1 loss 0.015925297513604164
bi 2 loss 0.01598954014480114
bi 3 loss 0.025267982855439186
Layer  1  loss:  0.01901792734861374 0.0 0.6144859194755554
logits torch.Size([389, 4, 1024]) labels torch.Size([389, 4]) 0 1023
Curr loss timestep torch.Size([389, 4]) tensor([109, 118, 171, 320], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.01779179275035858
bi 1 loss 0.0192230436950922
bi 2 loss 0.013042154721915722
bi 3 loss 0.02340731956064701
Layer  2  loss:  0.017542485147714615 0.0 0.1991705447435379
logits torch.Size([389, 4, 1024]) labels torch.Size([389, 4]) 0 1022
Curr loss timestep torch.Size([389, 4]) tensor([ 79, 119, 128, 318], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.01656363159418106
bi 1 loss 0.010528989136219025
bi 2 loss 0.012998735532164574
bi 3 loss 0.026381826028227806
Layer  3  loss:  0.016000179573893547 0.0 0.18375486135482788
logits torch.Size([389, 4, 1024]) labels torch.Size([389, 4]) 0 1018
Curr loss timestep torch.Size([389, 4]) tensor([ 86, 133, 129, 302], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 0.014725987799465656
bi 1 loss 0.01467395294457674
bi 2 loss 0.011278330348432064
bi 3 loss 0.0209079310297966
Layer  4  loss:  0.015980971977114677 0.0 0.14911803603172302
logits torch.Size([389, 4, 1024]) labels torch.Size([389, 4]) 0 1018
Curr loss timestep torch.Size([389, 4]) tensor([ 99, 127, 150, 349], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 0.013357529416680336
bi 1 loss 0.015461989678442478
bi 2 loss 0.016982998698949814
bi 3 loss 0.018458077684044838
Layer  5  loss:  0.017218442633748055 0.0 0.3049870431423187
logits torch.Size([389, 4, 1024]) labels torch.Size([389, 4]) 0 1022
Curr loss timestep torch.Size([389, 4]) tensor([189, 183, 173, 340], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 0.015516300685703754
bi 1 loss 0.017204880714416504
bi 2 loss 0.01484296377748251
bi 3 loss 0.020256996154785156
Layer  6  loss:  0.016761694103479385 0.0 0.19134356081485748
logits torch.Size([389, 4, 1024]) labels torch.Size([389, 4]) 0 1022
Curr loss timestep torch.Size([389, 4]) tensor([114, 167, 117, 267], device='cuda:0') tensor(114, device='cuda:0')
bi 0 loss 0.01736835204064846
bi 1 loss 0.014707078225910664
bi 2 loss 0.011954639106988907
bi 3 loss 0.0203798096626997
Epoch 0: :   3%|▎         | 15459/600000 [03:10<2:00:18, v_num=12, reduced_train_loss=37.20, global_step=15457.0, consumed_samples=61832.0, train_step_timing in s=0.382]Epoch 0: :   3%|▎         | 15459/600000 [03:10<2:00:18, v_num=12, reduced_train_loss=0.154, global_step=15458.0, consumed_samples=61836.0, train_step_timing in s=0.291]loss mask original None

First layer loss:  0.06410940736532211 torch.Size([477, 4]) 6.9688849449157715 0.0
Max loss timestep torch.Size([477, 4]) tensor([ 85, 322, 357, 191], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.037902601063251495
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 1 loss 0.06325823068618774
speech mask sum tensor(264, device='cuda:0') loss mask sum tensor(264, device='cuda:0')
bi 2 loss 0.09597762674093246
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
bi 3 loss 0.024734364822506905
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
logits torch.Size([477, 4, 257024]) labels torch.Size([477, 4]) 0 257022
Layer  0  loss:  0.07270018011331558 0.0 4.983426094055176
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([131, 323, 264, 150], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.047656260430812836
bi 1 loss 0.04992210119962692
bi 2 loss 0.13184121251106262
bi 3 loss 0.0238810982555151
Layer  1  loss:  0.07829087227582932 0.0 8.938014030456543
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1022
Curr loss timestep torch.Size([477, 4]) tensor([123, 310, 264, 143], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.04649154096841812
bi 1 loss 0.054072096943855286
bi 2 loss 0.14075016975402832
bi 3 loss 0.0326424278318882
Layer  2  loss:  0.08961348235607147 0.0 6.269150733947754
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1022
Curr loss timestep torch.Size([477, 4]) tensor([ 72, 344, 357, 195], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.036864686757326126
bi 1 loss 0.08350219577550888
bi 2 loss 0.1476367712020874
bi 3 loss 0.0336025208234787
Layer  3  loss:  0.08837249875068665 0.0 8.209425926208496
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([147, 344, 357, 192], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.0432247668504715
bi 1 loss 0.07552787661552429
bi 2 loss 0.15351538360118866
bi 3 loss 0.024661727249622345
Layer  4  loss:  0.07975158840417862 0.0 10.364389419555664
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1021
Curr loss timestep torch.Size([477, 4]) tensor([150, 421, 264, 127], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.036271147429943085
bi 1 loss 0.06001642346382141
bi 2 loss 0.14725562930107117
bi 3 loss 0.02506258524954319
Layer  5  loss:  0.0892791822552681 0.0 8.359696388244629
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([112, 322, 264, 149], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.04703829437494278
bi 1 loss 0.07388142496347427
bi 2 loss 0.1558050513267517
bi 3 loss 0.025451278313994408
Layer  6  loss:  0.07760889828205109 0.0 4.860410690307617
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([130, 436, 354, 144], device='cuda:0') tensor(354, device='cuda:0')
bi 0 loss 0.03258753567934036
bi 1 loss 0.07090450078248978
bi 2 loss 0.10887927561998367
bi 3 loss 0.07242384552955627
Epoch 0: :   3%|▎         | 15460/600000 [03:11<2:00:32, v_num=12, reduced_train_loss=0.154, global_step=15458.0, consumed_samples=61836.0, train_step_timing in s=0.291]Epoch 0: :   3%|▎         | 15460/600000 [03:11<2:00:32, v_num=12, reduced_train_loss=0.640, global_step=15459.0, consumed_samples=61840.0, train_step_timing in s=0.338]loss mask original None

First layer loss:  0.026927180588245392 torch.Size([369, 4]) 5.473110675811768 0.0
Max loss timestep torch.Size([369, 4]) tensor([265,  91, 155, 312], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.055001839995384216
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
bi 1 loss 0.01669888198375702
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 2 loss 0.02132234536111355
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 3 loss 0.016740962862968445
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
logits torch.Size([369, 4, 257024]) labels torch.Size([369, 4]) 0 257022
Layer  0  loss:  0.01804841309785843 0.0 0.5900282859802246
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([265, 107, 155, 295], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.02310432866215706
bi 1 loss 0.017002558335661888
bi 2 loss 0.019329871982336044
bi 3 loss 0.014513053931295872
Layer  1  loss:  0.020929651334881783 0.0 3.4696903228759766
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([265,  92, 186, 202], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.03799813985824585
bi 1 loss 0.015738751739263535
bi 2 loss 0.018824739381670952
bi 3 loss 0.0136039350181818
Layer  2  loss:  0.015962939709424973 0.0 0.22170810401439667
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1022
Curr loss timestep torch.Size([369, 4]) tensor([265, 136, 152,  94], device='cuda:0') tensor(94, device='cuda:0')
bi 0 loss 0.021578945219516754
bi 1 loss 0.014910691417753696
bi 2 loss 0.01837611012160778
bi 3 loss 0.011368601582944393
Layer  3  loss:  0.01922350749373436 0.0 2.238772392272949
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([265, 114, 245, 276], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.028312401846051216
bi 1 loss 0.010974797420203686
bi 2 loss 0.022988609969615936
bi 3 loss 0.013763931579887867
Layer  4  loss:  0.01869872771203518 0.0 1.5389598608016968
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1022
Curr loss timestep torch.Size([369, 4]) tensor([265, 118, 120, 264], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.02579406090080738
bi 1 loss 0.014423049986362457
bi 2 loss 0.01944168098270893
bi 3 loss 0.01522419136017561
Layer  5  loss:  0.02146122232079506 0.0 3.495810031890869
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([265, 145, 183, 264], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.03623092547059059
bi 1 loss 0.019029812887310982
bi 2 loss 0.020324790850281715
bi 3 loss 0.014088551513850689
Layer  6  loss:  0.021079756319522858 0.0 3.7162926197052
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1021
Curr loss timestep torch.Size([369, 4]) tensor([265,  96,  94, 264], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.03775594383478165
bi 1 loss 0.014757531695067883
bi 2 loss 0.018099190667271614
bi 3 loss 0.014876279048621655
Epoch 0: :   3%|▎         | 15461/600000 [03:11<2:00:43, v_num=12, reduced_train_loss=0.640, global_step=15459.0, consumed_samples=61840.0, train_step_timing in s=0.338]Epoch 0: :   3%|▎         | 15461/600000 [03:11<2:00:43, v_num=12, reduced_train_loss=0.162, global_step=15460.0, consumed_samples=61844.0, train_step_timing in s=0.284]loss mask original None

First layer loss:  0.17581559717655182 torch.Size([458, 4]) 14.974058151245117 0.0
Max loss timestep torch.Size([458, 4]) tensor([119, 149, 368, 376], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.083499476313591
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 1 loss 0.16233579814434052
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 2 loss 0.12837070226669312
speech mask sum tensor(380, device='cuda:0') loss mask sum tensor(380, device='cuda:0')
bi 3 loss 0.29997190833091736
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
logits torch.Size([458, 4, 257024]) labels torch.Size([458, 4]) 0 257023
Layer  0  loss:  0.14765828847885132 0.0 9.863341331481934
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([118, 157, 367, 376], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.0436432920396328
bi 1 loss 0.04669385403394699
bi 2 loss 0.14704109728336334
bi 3 loss 0.2354775071144104
Layer  1  loss:  0.1839657425880432 0.0 14.962026596069336
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([130, 183, 369, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.038266852498054504
bi 1 loss 0.05634426698088646
bi 2 loss 0.20169661939144135
bi 3 loss 0.26655423641204834
Layer  2  loss:  0.170037642121315 0.0 14.789750099182129
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([ 92, 181, 367, 376], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.07049371302127838
bi 1 loss 0.050309281796216965
bi 2 loss 0.17627567052841187
bi 3 loss 0.2533905506134033
Layer  3  loss:  0.1498662829399109 0.0 14.764999389648438
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1022
Curr loss timestep torch.Size([458, 4]) tensor([ 91, 123, 367, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.0187158714979887
bi 1 loss 0.06651707738637924
bi 2 loss 0.1345060169696808
bi 3 loss 0.2647757828235626
Layer  4  loss:  0.17392010986804962 0.0 16.509395599365234
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([109, 185, 368, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.03752652928233147
bi 1 loss 0.06102081015706062
bi 2 loss 0.15541179478168488
bi 3 loss 0.31115809082984924
Layer  5  loss:  0.13937252759933472 0.0 13.848405838012695
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([ 98, 132, 368, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.018639318645000458
bi 1 loss 0.06732732057571411
bi 2 loss 0.12850649654865265
bi 3 loss 0.23690524697303772
Layer  6  loss:  0.16817821562290192 0.0 16.907180786132812
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1019
Curr loss timestep torch.Size([458, 4]) tensor([114, 154, 367, 376], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.044135626405477524
bi 1 loss 0.06679224967956543
bi 2 loss 0.17603516578674316
bi 3 loss 0.24787665903568268
Epoch 0: :   3%|▎         | 15462/600000 [03:11<2:00:57, v_num=12, reduced_train_loss=0.162, global_step=15460.0, consumed_samples=61844.0, train_step_timing in s=0.284]Epoch 0: :   3%|▎         | 15462/600000 [03:11<2:00:57, v_num=12, reduced_train_loss=1.310, global_step=15461.0, consumed_samples=61848.0, train_step_timing in s=0.325]loss mask original None

First layer loss:  0.11877844482660294 torch.Size([682, 4]) 6.477602481842041 0.0
Max loss timestep torch.Size([682, 4]) tensor([294,  71, 379, 597], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.0578157976269722
speech mask sum tensor(297, device='cuda:0') loss mask sum tensor(297, device='cuda:0')
bi 1 loss 0.05289459228515625
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 2 loss 0.13055233657360077
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 3 loss 0.16509540379047394
speech mask sum tensor(502, device='cuda:0') loss mask sum tensor(502, device='cuda:0')
logits torch.Size([682, 4, 257024]) labels torch.Size([682, 4]) 0 257022
Layer  0  loss:  0.16356849670410156 0.0 11.375876426696777
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([291, 157, 323, 591], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.040182773023843765
bi 1 loss 0.06692013889551163
bi 2 loss 0.2352282851934433
bi 3 loss 0.21346639096736908
Layer  1  loss:  0.16275283694267273 0.0 13.680180549621582
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([219, 123, 378, 597], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.049903158098459244
bi 1 loss 0.03434836491942406
bi 2 loss 0.21288777887821198
bi 3 loss 0.23042985796928406
Layer  2  loss:  0.1874246746301651 0.0 9.625724792480469
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1022
Curr loss timestep torch.Size([682, 4]) tensor([294, 160, 378, 597], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.05210643261671066
bi 1 loss 0.05111993849277496
bi 2 loss 0.27227646112442017
bi 3 loss 0.24627061188220978
Layer  3  loss:  0.21004356443881989 0.0 14.929808616638184
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([ 94, 162, 323, 597], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.059840843081474304
bi 1 loss 0.06225702166557312
bi 2 loss 0.28660839796066284
bi 3 loss 0.28673142194747925
Layer  4  loss:  0.17895899713039398 0.0 12.982834815979004
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1022
Curr loss timestep torch.Size([682, 4]) tensor([294, 138, 322, 482], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.05352503061294556
bi 1 loss 0.03569469228386879
bi 2 loss 0.2668188214302063
bi 3 loss 0.23180262744426727
Layer  5  loss:  0.2126300036907196 0.0 16.607139587402344
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1018
Curr loss timestep torch.Size([682, 4]) tensor([294, 145, 334, 591], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.07320244610309601
bi 1 loss 0.07180232554674149
bi 2 loss 0.28932735323905945
bi 3 loss 0.2808953523635864
Layer  6  loss:  0.2068922221660614 0.0 13.021245002746582
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1022
Curr loss timestep torch.Size([682, 4]) tensor([294,  80, 335, 482], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.06920013576745987
bi 1 loss 0.030589120462536812
bi 2 loss 0.318283349275589
bi 3 loss 0.25976794958114624
Epoch 0: :   3%|▎         | 15463/600000 [03:12<2:01:15, v_num=12, reduced_train_loss=1.310, global_step=15461.0, consumed_samples=61848.0, train_step_timing in s=0.325]Epoch 0: :   3%|▎         | 15463/600000 [03:12<2:01:15, v_num=12, reduced_train_loss=1.440, global_step=15462.0, consumed_samples=61852.0, train_step_timing in s=0.466]loss mask original None

First layer loss:  0.034213948994874954 torch.Size([365, 4]) 1.4439483880996704 0.0
Max loss timestep torch.Size([365, 4]) tensor([127,  53, 188, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.027181081473827362
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 1 loss 0.019222799688577652
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 2 loss 0.035068027675151825
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 3 loss 0.048212677240371704
speech mask sum tensor(192, device='cuda:0') loss mask sum tensor(192, device='cuda:0')
logits torch.Size([365, 4, 257024]) labels torch.Size([365, 4]) 0 257022
Layer  0  loss:  0.04560312256217003 0.0 8.341096878051758
logits torch.Size([365, 4, 1024]) labels torch.Size([365, 4]) 0 1023
Curr loss timestep torch.Size([365, 4]) tensor([ 39,  45, 266, 213], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.02049276977777481
bi 1 loss 0.015538916923105717
bi 2 loss 0.07444450259208679
bi 3 loss 0.044980406761169434
Layer  1  loss:  0.03338925167918205 0.0 1.1664445400238037
logits torch.Size([365, 4, 1024]) labels torch.Size([365, 4]) 0 1022
Curr loss timestep torch.Size([365, 4]) tensor([119,  98, 255, 282], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.024259056895971298
bi 1 loss 0.018314341083168983
bi 2 loss 0.044917382299900055
bi 3 loss 0.034725628793239594
Layer  2  loss:  0.04216328635811806 0.0 2.448272705078125
logits torch.Size([365, 4, 1024]) labels torch.Size([365, 4]) 0 1022
Curr loss timestep torch.Size([365, 4]) tensor([ 86,  77, 257, 197], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 0.022869812324643135
bi 1 loss 0.023118266835808754
bi 2 loss 0.04446987807750702
bi 3 loss 0.06497397273778915
Layer  3  loss:  0.03786696493625641 0.0 1.3820775747299194
logits torch.Size([365, 4, 1024]) labels torch.Size([365, 4]) 0 1018
Curr loss timestep torch.Size([365, 4]) tensor([122, 124,  74, 203], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 0.016528872773051262
bi 1 loss 0.03046162612736225
bi 2 loss 0.04546753317117691
bi 3 loss 0.04676680266857147
Layer  4  loss:  0.032628681510686874 0.0 1.1178460121154785
logits torch.Size([365, 4, 1024]) labels torch.Size([365, 4]) 0 1022
Curr loss timestep torch.Size([365, 4]) tensor([ 87, 141, 290, 319], device='cuda:0') tensor(87, device='cuda:0')
bi 0 loss 0.02813120372593403
bi 1 loss 0.025170985609292984
bi 2 loss 0.0328458771109581
bi 3 loss 0.04050619900226593
Layer  5  loss:  0.04150473698973656 0.0 1.3652414083480835
logits torch.Size([365, 4, 1024]) labels torch.Size([365, 4]) 0 1023
Curr loss timestep torch.Size([365, 4]) tensor([ 91, 126, 163, 316], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 0.032125357538461685
bi 1 loss 0.029078228399157524
bi 2 loss 0.041681427508592606
bi 3 loss 0.05608266592025757
Layer  6  loss:  0.03405873104929924 0.0 1.1360867023468018
logits torch.Size([365, 4, 1024]) labels torch.Size([365, 4]) 0 1023
Curr loss timestep torch.Size([365, 4]) tensor([ 37,  80, 294, 285], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 0.015965931117534637
bi 1 loss 0.031698305159807205
bi 2 loss 0.04262378439307213
bi 3 loss 0.03603515774011612
Epoch 0: :   3%|▎         | 15464/600000 [03:12<2:01:27, v_num=12, reduced_train_loss=1.440, global_step=15462.0, consumed_samples=61852.0, train_step_timing in s=0.466]Epoch 0: :   3%|▎         | 15464/600000 [03:12<2:01:27, v_num=12, reduced_train_loss=0.301, global_step=15463.0, consumed_samples=61856.0, train_step_timing in s=0.285]loss mask original None

First layer loss:  3.5855906009674072 torch.Size([436, 4]) 11.727771759033203 0.0
Max loss timestep torch.Size([436, 4]) tensor([323, 168, 118, 386], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 3.5667619705200195
speech mask sum tensor(359, device='cuda:0') loss mask sum tensor(359, device='cuda:0')
bi 1 loss 3.742007255554199
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 2 loss 2.8454668521881104
speech mask sum tensor(65, device='cuda:0') loss mask sum tensor(65, device='cuda:0')
bi 3 loss 3.7878270149230957
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
logits torch.Size([436, 4, 257024]) labels torch.Size([436, 4]) 0 257023
Layer  0  loss:  4.11200475692749 0.0 9.420392036437988
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([ 87, 212, 129, 266], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 4.058135986328125
bi 1 loss 4.027853965759277
bi 2 loss 3.321361541748047
bi 3 loss 4.539295673370361
Layer  1  loss:  4.460347652435303 0.0 11.924591064453125
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([160, 186, 114, 354], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 4.576879501342773
bi 1 loss 4.107078552246094
bi 2 loss 3.4727706909179688
bi 3 loss 4.785824775695801
Layer  2  loss:  4.806304454803467 0.0 9.58669662475586
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([336, 204, 112, 345], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 4.814857006072998
bi 1 loss 4.956793785095215
bi 2 loss 4.253909111022949
bi 3 loss 4.894176959991455
Layer  3  loss:  4.852956295013428 0.0 9.156875610351562
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([351, 190, 110, 339], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 4.877449035644531
bi 1 loss 5.059919834136963
bi 2 loss 4.256582736968994
bi 3 loss 4.892594337463379
Layer  4  loss:  4.889346122741699 0.0 9.917244911193848
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([103, 230, 130, 297], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.914213180541992
bi 1 loss 5.045979976654053
bi 2 loss 3.934475898742676
bi 3 loss 5.082215309143066
Layer  5  loss:  5.079143047332764 0.0 9.645244598388672
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([ 88, 246, 126, 319], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 5.1203179359436035
bi 1 loss 5.243710517883301
bi 2 loss 4.464574337005615
bi 3 loss 5.117791175842285
Layer  6  loss:  5.028207778930664 0.0 9.823235511779785
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1021
Curr loss timestep torch.Size([436, 4]) tensor([393, 238, 115, 408], device='cuda:0') tensor(238, device='cuda:0')
bi 0 loss 5.1136956214904785
bi 1 loss 5.05716609954834
bi 2 loss 4.269627094268799
bi 3 loss 5.11088752746582
Epoch 0: :   3%|▎         | 15465/600000 [03:13<2:01:39, v_num=12, reduced_train_loss=0.301, global_step=15463.0, consumed_samples=61856.0, train_step_timing in s=0.285]Epoch 0: :   3%|▎         | 15465/600000 [03:13<2:01:39, v_num=12, reduced_train_loss=36.80, global_step=15464.0, consumed_samples=61860.0, train_step_timing in s=0.309]loss mask original None

First layer loss:  0.11104157567024231 torch.Size([638, 4]) 7.439541816711426 0.0
Max loss timestep torch.Size([638, 4]) tensor([260, 572, 116, 144], device='cuda:0') tensor(572, device='cuda:0')
bi 0 loss 0.0643724873661995
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 1 loss 0.17664597928524017
speech mask sum tensor(340, device='cuda:0') loss mask sum tensor(340, device='cuda:0')
bi 2 loss 0.02108035236597061
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 3 loss 0.02501673251390457
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
logits torch.Size([638, 4, 257024]) labels torch.Size([638, 4]) 0 257023
Layer  0  loss:  0.13593018054962158 0.0 13.026607513427734
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([261, 610, 103, 141], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.05328703299164772
bi 1 loss 0.21217891573905945
bi 2 loss 0.02128455601632595
bi 3 loss 0.095502108335495
Layer  1  loss:  0.14148305356502533 0.0 15.861471176147461
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([261, 572, 145, 146], device='cuda:0') tensor(572, device='cuda:0')
bi 0 loss 0.056523434817790985
bi 1 loss 0.23753085732460022
bi 2 loss 0.02634294517338276
bi 3 loss 0.020260684192180634
Layer  2  loss:  0.17166593670845032 0.0 9.483028411865234
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([257, 573, 117, 163], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.05051809176802635
bi 1 loss 0.29251888394355774
bi 2 loss 0.046612225472927094
bi 3 loss 0.01562297809869051
Layer  3  loss:  0.15702670812606812 0.0 10.748896598815918
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1018
Curr loss timestep torch.Size([638, 4]) tensor([260, 573, 120, 139], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.07623046636581421
bi 1 loss 0.260532945394516
bi 2 loss 0.02582310512661934
bi 3 loss 0.01851251721382141
Layer  4  loss:  0.1527208685874939 0.0 12.478667259216309
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([189, 610, 161, 162], device='cuda:0') tensor(610, device='cuda:0')
bi 0 loss 0.02669079229235649
bi 1 loss 0.2688528299331665
bi 2 loss 0.031888507306575775
bi 3 loss 0.01924269273877144
Layer  5  loss:  0.18026933073997498 0.0 12.424359321594238
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1018
Curr loss timestep torch.Size([638, 4]) tensor([232, 573,  87, 166], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.06257587671279907
bi 1 loss 0.3060998022556305
bi 2 loss 0.03289450705051422
bi 3 loss 0.027157092466950417
Layer  6  loss:  0.1573927253484726 0.0 9.787785530090332
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([265, 575, 160, 172], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.05300199240446091
bi 1 loss 0.2632928490638733
bi 2 loss 0.050643984228372574
bi 3 loss 0.013991962186992168
Epoch 0: :   3%|▎         | 15466/600000 [03:13<2:01:57, v_num=12, reduced_train_loss=36.80, global_step=15464.0, consumed_samples=61860.0, train_step_timing in s=0.309]Epoch 0: :   3%|▎         | 15466/600000 [03:13<2:01:57, v_num=12, reduced_train_loss=1.210, global_step=15465.0, consumed_samples=61864.0, train_step_timing in s=0.437]loss mask original None

First layer loss:  0.17202749848365784 torch.Size([627, 4]) 7.570049285888672 0.0
Max loss timestep torch.Size([627, 4]) tensor([439, 565, 264, 278], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.14044071733951569
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 1 loss 0.22401933372020721
speech mask sum tensor(341, device='cuda:0') loss mask sum tensor(341, device='cuda:0')
bi 2 loss 0.14218994975090027
speech mask sum tensor(185, device='cuda:0') loss mask sum tensor(185, device='cuda:0')
bi 3 loss 0.15967854857444763
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
logits torch.Size([627, 4, 257024]) labels torch.Size([627, 4]) 0 257023
Layer  0  loss:  0.23627135157585144 0.0 13.642337799072266
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([442, 480, 264, 278], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.16229325532913208
bi 1 loss 0.36415404081344604
bi 2 loss 0.16411474347114563
bi 3 loss 0.1900145262479782
Layer  1  loss:  0.21451148390769958 0.0 15.965096473693848
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([444, 570, 264, 278], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.1826581507921219
bi 1 loss 0.24075865745544434
bi 2 loss 0.20079250633716583
bi 3 loss 0.2635171413421631
Layer  2  loss:  0.21174544095993042 0.0 15.876957893371582
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([442, 480, 264, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.1255546659231186
bi 1 loss 0.30755117535591125
bi 2 loss 0.1683586835861206
bi 3 loss 0.2683846652507782
Layer  3  loss:  0.2059360146522522 0.0 10.59378719329834
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([439, 570, 264, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.15034836530685425
bi 1 loss 0.2688520848751068
bi 2 loss 0.12929631769657135
bi 3 loss 0.3322281539440155
Layer  4  loss:  0.2188587337732315 0.0 11.074528694152832
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([444, 368, 262, 279], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.19314438104629517
bi 1 loss 0.2947075664997101
bi 2 loss 0.14176300168037415
bi 3 loss 0.19148971140384674
Layer  5  loss:  0.22671665251255035 0.0 14.594054222106934
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([444, 376, 264, 278], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.1658460646867752
bi 1 loss 0.31655600666999817
bi 2 loss 0.1749284863471985
bi 3 loss 0.22868986427783966
Layer  6  loss:  0.2384144514799118 0.0 15.979888916015625
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([442, 538, 264, 278], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.197894886136055
bi 1 loss 0.3043893873691559
bi 2 loss 0.1699499636888504
bi 3 loss 0.2833082973957062
Epoch 0: :   3%|▎         | 15467/600000 [03:14<2:02:14, v_num=12, reduced_train_loss=1.210, global_step=15465.0, consumed_samples=61864.0, train_step_timing in s=0.437]Epoch 0: :   3%|▎         | 15467/600000 [03:14<2:02:14, v_num=12, reduced_train_loss=1.720, global_step=15466.0, consumed_samples=61868.0, train_step_timing in s=0.428]loss mask original None

First layer loss:  0.08557427674531937 torch.Size([649, 4]) 6.694450378417969 0.0
Max loss timestep torch.Size([649, 4]) tensor([301, 273,  63, 228], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.11667919158935547
speech mask sum tensor(484, device='cuda:0') loss mask sum tensor(484, device='cuda:0')
bi 1 loss 0.08320362865924835
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
bi 2 loss 0.02221677638590336
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
bi 3 loss 0.040495119988918304
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
logits torch.Size([649, 4, 257024]) labels torch.Size([649, 4]) 0 257022
Layer  0  loss:  0.09438901394605637 0.0 10.110603332519531
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([300, 312,  90, 205], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.1520911455154419
bi 1 loss 0.06253085285425186
bi 2 loss 0.02336779423058033
bi 3 loss 0.03813241422176361
Layer  1  loss:  0.09287519752979279 0.0 12.750753402709961
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([300, 340,  70, 221], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.1405562162399292
bi 1 loss 0.08181597292423248
bi 2 loss 0.018774868920445442
bi 3 loss 0.02563401125371456
Layer  2  loss:  0.11480939388275146 0.0 7.694326877593994
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([625, 340,  58, 183], device='cuda:0') tensor(625, device='cuda:0')
bi 0 loss 0.1614638715982437
bi 1 loss 0.10636243224143982
bi 2 loss 0.024799516424536705
bi 3 loss 0.053801003843545914
Layer  3  loss:  0.10197573900222778 0.0 10.275978088378906
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([299, 312,  68,  83], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.16015154123306274
bi 1 loss 0.06892871856689453
bi 2 loss 0.015791399404406548
bi 3 loss 0.05474775657057762
Layer  4  loss:  0.10290873050689697 0.0 9.674548149108887
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1021
Curr loss timestep torch.Size([649, 4]) tensor([300, 314,  81, 213], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.16631370782852173
bi 1 loss 0.07400408387184143
bi 2 loss 0.023288168013095856
bi 3 loss 0.03036651387810707
Layer  5  loss:  0.09159396588802338 0.0 7.148874759674072
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([518, 470,  84, 206], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.13173075020313263
bi 1 loss 0.07920428365468979
bi 2 loss 0.03289791941642761
bi 3 loss 0.03887728229165077
Layer  6  loss:  0.10406282544136047 0.0 7.694946765899658
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([299, 428,  98, 104], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.17065516114234924
bi 1 loss 0.06965028494596481
bi 2 loss 0.014477844350039959
bi 3 loss 0.03872014209628105
Epoch 0: :   3%|▎         | 15468/600000 [03:14<2:02:32, v_num=12, reduced_train_loss=1.720, global_step=15466.0, consumed_samples=61868.0, train_step_timing in s=0.428]Epoch 0: :   3%|▎         | 15468/600000 [03:14<2:02:32, v_num=12, reduced_train_loss=0.788, global_step=15467.0, consumed_samples=61872.0, train_step_timing in s=0.447]loss mask original None

First layer loss:  0.019894087687134743 torch.Size([409, 4]) 0.899571418762207 0.0
Max loss timestep torch.Size([409, 4]) tensor([103, 263, 396, 108], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.009727795608341694
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
bi 1 loss 0.01972390152513981
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
bi 2 loss 0.025479892268776894
speech mask sum tensor(270, device='cuda:0') loss mask sum tensor(270, device='cuda:0')
bi 3 loss 0.0127290403470397
speech mask sum tensor(116, device='cuda:0') loss mask sum tensor(116, device='cuda:0')
logits torch.Size([409, 4, 257024]) labels torch.Size([409, 4]) 0 257023
Layer  0  loss:  0.01756339706480503 0.0 0.35477593541145325
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([ 78, 176, 304, 143], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.013527335599064827
bi 1 loss 0.017848728224635124
bi 2 loss 0.019880609586834908
bi 3 loss 0.014015416614711285
Layer  1  loss:  0.015396871604025364 0.0 0.17113766074180603
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1022
Curr loss timestep torch.Size([409, 4]) tensor([ 89, 218, 295, 165], device='cuda:0') tensor(156, device='cuda:0')
bi 0 loss 0.013688136823475361
bi 1 loss 0.015784695744514465
bi 2 loss 0.016488835215568542
bi 3 loss 0.013279776088893414
Layer  2  loss:  0.019239677116274834 0.0 0.30442678928375244
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([112, 151, 308,  96], device='cuda:0') tensor(96, device='cuda:0')
bi 0 loss 0.022628754377365112
bi 1 loss 0.017777545377612114
bi 2 loss 0.021062562242150307
bi 3 loss 0.015080642886459827
Layer  3  loss:  0.016777196899056435 0.0 0.29598960280418396
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1021
Curr loss timestep torch.Size([409, 4]) tensor([112, 164, 303, 170], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.011177096515893936
bi 1 loss 0.018268099054694176
bi 2 loss 0.01940014399588108
bi 3 loss 0.01176962349563837
Layer  4  loss:  0.017321642488241196 0.0 1.4337210655212402
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1021
Curr loss timestep torch.Size([409, 4]) tensor([ 94, 263, 339, 119], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.011330457404255867
bi 1 loss 0.023863360285758972
bi 2 loss 0.01666363887488842
bi 3 loss 0.013417591340839863
Layer  5  loss:  0.016626175493001938 0.0 0.2887893319129944
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([ 90, 167, 347, 143], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.010091746225953102
bi 1 loss 0.017208421602845192
bi 2 loss 0.019168853759765625
bi 3 loss 0.01353506464511156
Layer  6  loss:  0.016898734495043755 0.0 0.22156932950019836
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1021
Curr loss timestep torch.Size([409, 4]) tensor([ 78, 161, 344, 174], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 0.014123438857495785
bi 1 loss 0.015419049188494682
bi 2 loss 0.018992187455296516
bi 3 loss 0.015534404665231705
Epoch 0: :   3%|▎         | 15469/600000 [03:14<2:02:45, v_num=12, reduced_train_loss=0.788, global_step=15467.0, consumed_samples=61872.0, train_step_timing in s=0.447]Epoch 0: :   3%|▎         | 15469/600000 [03:14<2:02:45, v_num=12, reduced_train_loss=0.140, global_step=15468.0, consumed_samples=61876.0, train_step_timing in s=0.317]loss mask original None

First layer loss:  3.5032269954681396 torch.Size([600, 4]) 11.374284744262695 0.0
Max loss timestep torch.Size([600, 4]) tensor([425, 182, 432, 208], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 3.736210584640503
speech mask sum tensor(380, device='cuda:0') loss mask sum tensor(380, device='cuda:0')
bi 1 loss 3.5273685455322266
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 2 loss 3.295191764831543
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 3 loss 3.4302003383636475
speech mask sum tensor(78, device='cuda:0') loss mask sum tensor(78, device='cuda:0')
logits torch.Size([600, 4, 257024]) labels torch.Size([600, 4]) 0 257022
Layer  0  loss:  3.9501841068267822 0.0 11.957460403442383
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([437, 269, 575, 174], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 3.9772846698760986
bi 1 loss 4.004250526428223
bi 2 loss 4.000617027282715
bi 3 loss 3.469280958175659
Layer  1  loss:  4.19681453704834 0.0 10.26460075378418
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([277, 241, 213, 214], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.319888591766357
bi 1 loss 4.476224422454834
bi 2 loss 4.146259784698486
bi 3 loss 3.437971830368042
Layer  2  loss:  4.3932881355285645 0.0 9.746504783630371
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([425, 259, 306, 180], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 4.530147075653076
bi 1 loss 4.499699115753174
bi 2 loss 4.431295871734619
bi 3 loss 3.3634345531463623
Layer  3  loss:  4.713074207305908 0.0 11.065425872802734
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([271, 269, 456, 203], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 4.822935581207275
bi 1 loss 4.764269828796387
bi 2 loss 4.740878105163574
bi 3 loss 3.9528820514678955
Layer  4  loss:  4.786159515380859 0.0 9.269391059875488
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([426, 202, 395, 207], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 4.986279487609863
bi 1 loss 4.750328063964844
bi 2 loss 4.809530258178711
bi 3 loss 3.742436408996582
Layer  5  loss:  4.862054824829102 0.0 10.302995681762695
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([475, 187, 363, 206], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 5.09390926361084
bi 1 loss 4.693191051483154
bi 2 loss 4.875162601470947
bi 3 loss 3.9209015369415283
Layer  6  loss:  4.901808738708496 0.0 9.194365501403809
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([358, 272, 537, 179], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 5.150954723358154
bi 1 loss 4.7548828125
bi 2 loss 4.889061450958252
bi 3 loss 3.979508638381958
Epoch 0: :   3%|▎         | 15470/600000 [03:15<2:03:00, v_num=12, reduced_train_loss=0.140, global_step=15468.0, consumed_samples=61876.0, train_step_timing in s=0.317]Epoch 0: :   3%|▎         | 15470/600000 [03:15<2:03:00, v_num=12, reduced_train_loss=35.30, global_step=15469.0, consumed_samples=61880.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  0.04543114826083183 torch.Size([510, 4]) 5.360671520233154 0.0
Max loss timestep torch.Size([510, 4]) tensor([421, 265, 253, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.03407552093267441
speech mask sum tensor(315, device='cuda:0') loss mask sum tensor(315, device='cuda:0')
bi 1 loss 0.04267197102308273
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 2 loss 0.06139744073152542
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 3 loss 0.05518144369125366
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
logits torch.Size([510, 4, 257024]) labels torch.Size([510, 4]) 0 257022
Layer  0  loss:  0.05314376577734947 0.0 7.0317487716674805
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([263, 265, 193, 268], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.04449816793203354
bi 1 loss 0.06748182326555252
bi 2 loss 0.028518617153167725
bi 3 loss 0.0632791519165039
Layer  1  loss:  0.05187935009598732 0.0 6.667537689208984
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([263, 262, 223, 268], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.03526704013347626
bi 1 loss 0.07853538542985916
bi 2 loss 0.03232022747397423
bi 3 loss 0.055284351110458374
Layer  2  loss:  0.06367018818855286 0.0 12.059045791625977
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([263, 265, 245, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.04080556705594063
bi 1 loss 0.06969346851110458
bi 2 loss 0.05205731466412544
bi 3 loss 0.09624958783388138
Layer  3  loss:  0.0550590343773365 0.0 10.878701210021973
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([263, 265, 220, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.04924950376152992
bi 1 loss 0.04750977084040642
bi 2 loss 0.055195294320583344
bi 3 loss 0.07248933613300323
Layer  4  loss:  0.05680900812149048 0.0 6.383995532989502
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([263, 262, 240, 268], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.04920559376478195
bi 1 loss 0.08592502027750015
bi 2 loss 0.02970942296087742
bi 3 loss 0.04897958040237427
Layer  5  loss:  0.05388021469116211 0.0 8.501983642578125
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1023
Curr loss timestep torch.Size([510, 4]) tensor([263, 265, 175, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.0394439660012722
bi 1 loss 0.05399706959724426
bi 2 loss 0.05258314311504364
bi 3 loss 0.07520978897809982
Layer  6  loss:  0.06829328089952469 0.0 11.457967758178711
logits torch.Size([510, 4, 1024]) labels torch.Size([510, 4]) 0 1022
Curr loss timestep torch.Size([510, 4]) tensor([263, 265, 211, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.056749287992715836
bi 1 loss 0.09206384420394897
bi 2 loss 0.03434246405959129
bi 3 loss 0.07685307413339615
Epoch 0: :   3%|▎         | 15471/600000 [03:15<2:03:14, v_num=12, reduced_train_loss=35.30, global_step=15469.0, consumed_samples=61880.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15471/600000 [03:15<2:03:14, v_num=12, reduced_train_loss=0.448, global_step=15470.0, consumed_samples=61884.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  3.229623556137085 torch.Size([564, 4]) 12.453133583068848 0.0
Max loss timestep torch.Size([564, 4]) tensor([ 85, 367, 256, 123], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 2.40980863571167
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 1 loss 3.7225542068481445
speech mask sum tensor(198, device='cuda:0') loss mask sum tensor(198, device='cuda:0')
bi 2 loss 2.3863959312438965
speech mask sum tensor(410, device='cuda:0') loss mask sum tensor(410, device='cuda:0')
bi 3 loss 3.9425148963928223
speech mask sum tensor(478, device='cuda:0') loss mask sum tensor(478, device='cuda:0')
logits torch.Size([564, 4, 257024]) labels torch.Size([564, 4]) 0 257022
Layer  0  loss:  3.6540770530700684 0.0 10.550857543945312
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([ 58, 287, 246, 294], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 3.077523946762085
bi 1 loss 4.4344892501831055
bi 2 loss 2.7016210556030273
bi 3 loss 4.284069061279297
Layer  1  loss:  4.0855183601379395 0.0 11.119544982910156
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([ 64, 269, 169, 143], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 4.061413764953613
bi 1 loss 4.826645374298096
bi 2 loss 3.18774151802063
bi 3 loss 4.554283142089844
Layer  2  loss:  4.298220634460449 0.0 11.084627151489258
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([136, 405, 392, 365], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 4.422760963439941
bi 1 loss 4.985041618347168
bi 2 loss 3.3847296237945557
bi 3 loss 4.767819404602051
Layer  3  loss:  4.376040935516357 0.0 9.694520950317383
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([ 97, 338, 249, 345], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 4.46776008605957
bi 1 loss 5.228024482727051
bi 2 loss 3.3048362731933594
bi 3 loss 4.920259952545166
Layer  4  loss:  4.485982418060303 0.0 9.510149955749512
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([ 86, 438, 487, 434], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 4.954885482788086
bi 1 loss 5.188553810119629
bi 2 loss 3.43796706199646
bi 3 loss 4.983035087585449
Layer  5  loss:  4.589165210723877 0.0 11.344890594482422
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([118, 392, 474, 163], device='cuda:0') tensor(131, device='cuda:0')
bi 0 loss 4.9968366622924805
bi 1 loss 5.368032932281494
bi 2 loss 3.5255532264709473
bi 3 loss 5.082467555999756
Layer  6  loss:  4.547056674957275 0.0 9.313821792602539
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([ 74, 343, 489, 390], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 4.8809685707092285
bi 1 loss 5.282851696014404
bi 2 loss 3.4763972759246826
bi 3 loss 5.081681251525879
Epoch 0: :   3%|▎         | 15472/600000 [03:16<2:03:29, v_num=12, reduced_train_loss=0.448, global_step=15470.0, consumed_samples=61884.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15472/600000 [03:16<2:03:29, v_num=12, reduced_train_loss=33.30, global_step=15471.0, consumed_samples=61888.0, train_step_timing in s=0.366]loss mask original None

First layer loss:  3.8864669799804688 torch.Size([500, 4]) 11.849639892578125 0.0
Max loss timestep torch.Size([500, 4]) tensor([313, 284, 160, 312], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 3.781724691390991
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 1 loss 3.755566120147705
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
bi 2 loss 4.188075065612793
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 3 loss 3.8762454986572266
speech mask sum tensor(336, device='cuda:0') loss mask sum tensor(336, device='cuda:0')
logits torch.Size([500, 4, 257024]) labels torch.Size([500, 4]) 0 257023
Layer  0  loss:  4.222012519836426 0.0 9.525209426879883
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([326, 230, 177, 286], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.354622840881348
bi 1 loss 3.826754331588745
bi 2 loss 4.538051605224609
bi 3 loss 4.138932228088379
Layer  1  loss:  4.61103630065918 0.0 9.768735885620117
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([283, 180, 118, 462], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 4.584482669830322
bi 1 loss 4.587528228759766
bi 2 loss 5.185883522033691
bi 3 loss 4.357926845550537
Layer  2  loss:  4.77303409576416 0.0 10.313736915588379
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([291, 269, 132, 252], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 4.789849758148193
bi 1 loss 4.794240951538086
bi 2 loss 4.883962631225586
bi 3 loss 4.695862770080566
Layer  3  loss:  4.97655725479126 0.0 10.38167953491211
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([425, 224, 107, 252], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 4.921571254730225
bi 1 loss 4.902641773223877
bi 2 loss 5.3537397384643555
bi 3 loss 4.8653740882873535
Layer  4  loss:  5.1054606437683105 0.0 9.522778511047363
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([288, 204, 206, 465], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.856977462768555
bi 1 loss 5.259366035461426
bi 2 loss 5.459347724914551
bi 3 loss 5.0539140701293945
Layer  5  loss:  5.257240295410156 0.0 9.546609878540039
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1017
Curr loss timestep torch.Size([500, 4]) tensor([381, 300, 106, 291], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 5.121361255645752
bi 1 loss 5.288121223449707
bi 2 loss 5.466213226318359
bi 3 loss 5.245044708251953
Layer  6  loss:  5.235983848571777 0.0 10.002641677856445
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([379, 231, 219, 336], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 5.05376672744751
bi 1 loss 5.311796188354492
bi 2 loss 5.5847039222717285
bi 3 loss 5.170539379119873
Epoch 0: :   3%|▎         | 15473/600000 [03:16<2:03:42, v_num=12, reduced_train_loss=33.30, global_step=15471.0, consumed_samples=61888.0, train_step_timing in s=0.366]Epoch 0: :   3%|▎         | 15473/600000 [03:16<2:03:42, v_num=12, reduced_train_loss=38.10, global_step=15472.0, consumed_samples=61892.0, train_step_timing in s=0.335]loss mask original None

First layer loss:  3.322718858718872 torch.Size([536, 4]) 11.868529319763184 0.0
Max loss timestep torch.Size([536, 4]) tensor([ 84, 302, 453, 128], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 3.340284585952759
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 1 loss 3.0681815147399902
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
bi 2 loss 3.1376686096191406
speech mask sum tensor(371, device='cuda:0') loss mask sum tensor(371, device='cuda:0')
bi 3 loss 4.332056522369385
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
logits torch.Size([536, 4, 257024]) labels torch.Size([536, 4]) 0 257022
Layer  0  loss:  3.8180246353149414 0.0 9.779154777526855
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1023
Curr loss timestep torch.Size([536, 4]) tensor([119, 304, 454, 142], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 3.887303113937378
bi 1 loss 3.435737133026123
bi 2 loss 3.743628740310669
bi 3 loss 4.528286933898926
Layer  1  loss:  4.073766708374023 0.0 9.821735382080078
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1022
Curr loss timestep torch.Size([536, 4]) tensor([165, 266, 466, 112], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.198220729827881
bi 1 loss 3.7957215309143066
bi 2 loss 3.960279703140259
bi 3 loss 4.664718151092529
Layer  2  loss:  4.348767280578613 0.0 9.586517333984375
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1022
Curr loss timestep torch.Size([536, 4]) tensor([134, 321, 492, 104], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.516310691833496
bi 1 loss 4.155557155609131
bi 2 loss 4.212578773498535
bi 3 loss 4.813486576080322
Layer  3  loss:  4.456781387329102 0.0 10.700754165649414
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1020
Curr loss timestep torch.Size([536, 4]) tensor([ 63, 227, 298, 139], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.656627655029297
bi 1 loss 3.9524481296539307
bi 2 loss 4.3592352867126465
bi 3 loss 5.1903886795043945
Layer  4  loss:  4.564980983734131 0.0 10.871063232421875
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1023
Curr loss timestep torch.Size([536, 4]) tensor([109, 222, 485, 120], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.772721290588379
bi 1 loss 4.108293533325195
bi 2 loss 4.421304702758789
bi 3 loss 5.3770294189453125
Layer  5  loss:  4.668621063232422 0.0 10.820962905883789
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1020
Curr loss timestep torch.Size([536, 4]) tensor([201, 274, 479, 185], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.817383289337158
bi 1 loss 4.200196743011475
bi 2 loss 4.540074825286865
bi 3 loss 5.5537519454956055
Layer  6  loss:  4.6395792961120605 0.0 10.068410873413086
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1020
Curr loss timestep torch.Size([536, 4]) tensor([ 91, 216, 261,  95], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.979708671569824
bi 1 loss 4.095871448516846
bi 2 loss 4.485372543334961
bi 3 loss 5.374044418334961
Epoch 0: :   3%|▎         | 15474/600000 [03:16<2:03:57, v_num=12, reduced_train_loss=38.10, global_step=15472.0, consumed_samples=61892.0, train_step_timing in s=0.335]Epoch 0: :   3%|▎         | 15474/600000 [03:16<2:03:57, v_num=12, reduced_train_loss=33.90, global_step=15473.0, consumed_samples=61896.0, train_step_timing in s=0.360]loss mask original None

First layer loss:  0.08441294729709625 torch.Size([619, 4]) 4.994936943054199 0.0
Max loss timestep torch.Size([619, 4]) tensor([354, 395,  65,  61], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.09339600801467896
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 1 loss 0.11289644986391068
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
bi 2 loss 0.032142408192157745
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 3 loss 0.0395049974322319
speech mask sum tensor(219, device='cuda:0') loss mask sum tensor(219, device='cuda:0')
logits torch.Size([619, 4, 257024]) labels torch.Size([619, 4]) 0 257023
Layer  0  loss:  0.11264084279537201 0.0 7.069092273712158
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([315, 578,  97, 158], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.10443224012851715
bi 1 loss 0.17506858706474304
bi 2 loss 0.02317662537097931
bi 3 loss 0.03601483628153801
Layer  1  loss:  0.1234382838010788 0.0 5.121279716491699
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([359, 541,  58,  60], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.0775538757443428
bi 1 loss 0.20151188969612122
bi 2 loss 0.06038158759474754
bi 3 loss 0.047700680792331696
Layer  2  loss:  0.11866331100463867 0.0 7.112775802612305
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([181, 395, 102, 119], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.10829388350248337
bi 1 loss 0.1761293113231659
bi 2 loss 0.037825748324394226
bi 3 loss 0.05079394951462746
Layer  3  loss:  0.12754414975643158 0.0 11.010674476623535
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([336, 578,  50,  91], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.08656901121139526
bi 1 loss 0.2167559564113617
bi 2 loss 0.036621399223804474
bi 3 loss 0.03599981591105461
Layer  4  loss:  0.13262949883937836 0.0 11.250033378601074
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([315, 578, 108,  81], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.08989804238080978
bi 1 loss 0.21868287026882172
bi 2 loss 0.028091510757803917
bi 3 loss 0.05592656135559082
Layer  5  loss:  0.1206577867269516 0.0 10.334183692932129
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([315, 578,  60, 163], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.09332550317049026
bi 1 loss 0.19335199892520905
bi 2 loss 0.0317995660007
bi 3 loss 0.04562915116548538
Layer  6  loss:  0.1063530221581459 0.0 8.038597106933594
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([359, 578, 112,  90], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.08322012424468994
bi 1 loss 0.167480006814003
bi 2 loss 0.04217888414859772
bi 3 loss 0.0385790690779686
Epoch 0: :   3%|▎         | 15475/600000 [03:17<2:04:14, v_num=12, reduced_train_loss=33.90, global_step=15473.0, consumed_samples=61896.0, train_step_timing in s=0.360]Epoch 0: :   3%|▎         | 15475/600000 [03:17<2:04:14, v_num=12, reduced_train_loss=0.926, global_step=15474.0, consumed_samples=61900.0, train_step_timing in s=0.424]loss mask original None

First layer loss:  3.698559522628784 torch.Size([560, 4]) 13.192997932434082 0.0
Max loss timestep torch.Size([560, 4]) tensor([234, 430, 277, 382], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 4.1041693687438965
speech mask sum tensor(129, device='cuda:0') loss mask sum tensor(129, device='cuda:0')
bi 1 loss 3.9290034770965576
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 2 loss 3.0078461170196533
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 3 loss 4.020495891571045
speech mask sum tensor(227, device='cuda:0') loss mask sum tensor(227, device='cuda:0')
logits torch.Size([560, 4, 257024]) labels torch.Size([560, 4]) 0 257022
Layer  0  loss:  4.22609281539917 0.0 10.070956230163574
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([258, 407, 309, 311], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 4.215323448181152
bi 1 loss 4.11534309387207
bi 2 loss 4.165182590484619
bi 3 loss 4.494570255279541
Layer  1  loss:  4.604371547698975 0.0 12.535472869873047
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([297, 497, 238, 215], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 4.597331523895264
bi 1 loss 4.661442756652832
bi 2 loss 4.1797308921813965
bi 3 loss 5.08590030670166
Layer  2  loss:  4.900515079498291 0.0 10.449294090270996
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([327, 511, 357, 385], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 4.568545818328857
bi 1 loss 4.993729114532471
bi 2 loss 4.620288372039795
bi 3 loss 5.313749313354492
Layer  3  loss:  4.991332054138184 0.0 10.279045104980469
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([312, 248, 495, 386], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 5.0085129737854
bi 1 loss 4.961089134216309
bi 2 loss 4.782464504241943
bi 3 loss 5.311501979827881
Layer  4  loss:  5.12330436706543 0.0 10.32282543182373
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([226, 459, 325, 313], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 5.148956298828125
bi 1 loss 5.165643692016602
bi 2 loss 4.817438125610352
bi 3 loss 5.450681209564209
Layer  5  loss:  5.234409809112549 0.0 9.832286834716797
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([278, 399, 267, 317], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 5.186400413513184
bi 1 loss 5.118733882904053
bi 2 loss 5.058683395385742
bi 3 loss 5.686347007751465
Layer  6  loss:  5.194733142852783 0.0 9.646282196044922
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1021
Curr loss timestep torch.Size([560, 4]) tensor([264, 453, 322, 401], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 5.085315704345703
bi 1 loss 5.100307941436768
bi 2 loss 5.021426200866699
bi 3 loss 5.643679141998291
Epoch 0: :   3%|▎         | 15476/600000 [03:17<2:04:28, v_num=12, reduced_train_loss=0.926, global_step=15474.0, consumed_samples=61900.0, train_step_timing in s=0.424]Epoch 0: :   3%|▎         | 15476/600000 [03:17<2:04:28, v_num=12, reduced_train_loss=38.00, global_step=15475.0, consumed_samples=61904.0, train_step_timing in s=0.351]loss mask original None

First layer loss:  0.06373964995145798 torch.Size([417, 4]) 6.830272674560547 0.0
Max loss timestep torch.Size([417, 4]) tensor([308, 149, 202, 186], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 0.04572667181491852
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 1 loss 0.040255941450595856
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 2 loss 0.05186368152499199
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 3 loss 0.21897611021995544
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
logits torch.Size([417, 4, 257024]) labels torch.Size([417, 4]) 0 257023
Layer  0  loss:  0.04083774611353874 0.0 0.9625288844108582
logits torch.Size([417, 4, 1024]) labels torch.Size([417, 4]) 0 1023
Curr loss timestep torch.Size([417, 4]) tensor([195, 213, 256, 206], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 0.04589291289448738
bi 1 loss 0.03432350605726242
bi 2 loss 0.03311432898044586
bi 3 loss 0.05246618390083313
Layer  1  loss:  0.0457342304289341 0.0 1.364672064781189
logits torch.Size([417, 4, 1024]) labels torch.Size([417, 4]) 0 1022
Curr loss timestep torch.Size([417, 4]) tensor([327, 223, 197, 187], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.06656681001186371
bi 1 loss 0.03747998923063278
bi 2 loss 0.02454652450978756
bi 3 loss 0.028468890115618706
Layer  2  loss:  0.04020872339606285 0.0 2.7439966201782227
logits torch.Size([417, 4, 1024]) labels torch.Size([417, 4]) 0 1022
Curr loss timestep torch.Size([417, 4]) tensor([297, 135, 205, 203], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.05143125727772713
bi 1 loss 0.05161524564027786
bi 2 loss 0.018108630552887917
bi 3 loss 0.026697678491473198
Layer  3  loss:  0.046043358743190765 0.0 1.3856688737869263
logits torch.Size([417, 4, 1024]) labels torch.Size([417, 4]) 0 1014
Curr loss timestep torch.Size([417, 4]) tensor([299, 221, 237, 185], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.052300117909908295
bi 1 loss 0.03481639176607132
bi 2 loss 0.0492749847471714
bi 3 loss 0.033565767109394073
Layer  4  loss:  0.052641358226537704 0.0 4.886801242828369
logits torch.Size([417, 4, 1024]) labels torch.Size([417, 4]) 0 1022
Curr loss timestep torch.Size([417, 4]) tensor([290, 139, 222, 193], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.07089049369096756
bi 1 loss 0.05074014142155647
bi 2 loss 0.031986985355615616
bi 3 loss 0.03220614418387413
Layer  5  loss:  0.046979278326034546 0.0 3.2763891220092773
logits torch.Size([417, 4, 1024]) labels torch.Size([417, 4]) 0 1020
Curr loss timestep torch.Size([417, 4]) tensor([387, 211, 232, 181], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.06340351700782776
bi 1 loss 0.0561516135931015
bi 2 loss 0.020908288657665253
bi 3 loss 0.02607615664601326
Layer  6  loss:  0.04255406931042671 0.0 1.9098186492919922
logits torch.Size([417, 4, 1024]) labels torch.Size([417, 4]) 0 1019
Curr loss timestep torch.Size([417, 4]) tensor([297, 189, 278, 188], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.058936357498168945
bi 1 loss 0.04181021451950073
bi 2 loss 0.020364155992865562
bi 3 loss 0.03175202012062073
Epoch 0: :   3%|▎         | 15477/600000 [03:18<2:04:40, v_num=12, reduced_train_loss=38.00, global_step=15475.0, consumed_samples=61904.0, train_step_timing in s=0.351]Epoch 0: :   3%|▎         | 15477/600000 [03:18<2:04:40, v_num=12, reduced_train_loss=0.379, global_step=15476.0, consumed_samples=61908.0, train_step_timing in s=0.305]loss mask original None

First layer loss:  0.15726225078105927 torch.Size([767, 4]) 9.536142349243164 0.0
Max loss timestep torch.Size([767, 4]) tensor([ 97, 325, 271, 527], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.028112901374697685
speech mask sum tensor(61, device='cuda:0') loss mask sum tensor(61, device='cuda:0')
bi 1 loss 0.08236869424581528
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
bi 2 loss 0.11858650296926498
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
bi 3 loss 0.2224643975496292
speech mask sum tensor(497, device='cuda:0') loss mask sum tensor(497, device='cuda:0')
logits torch.Size([767, 4, 257024]) labels torch.Size([767, 4]) 0 257023
Layer  0  loss:  0.20626604557037354 0.0 12.969454765319824
logits torch.Size([767, 4, 1024]) labels torch.Size([767, 4]) 0 1023
Curr loss timestep torch.Size([767, 4]) tensor([111, 272, 277, 528], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 0.025338299572467804
bi 1 loss 0.19749964773654938
bi 2 loss 0.10681711882352829
bi 3 loss 0.28658023476600647
Layer  1  loss:  0.23795808851718903 0.0 18.06280517578125
logits torch.Size([767, 4, 1024]) labels torch.Size([767, 4]) 0 1023
Curr loss timestep torch.Size([767, 4]) tensor([123, 315, 277, 567], device='cuda:0') tensor(567, device='cuda:0')
bi 0 loss 0.02847001515328884
bi 1 loss 0.16824135184288025
bi 2 loss 0.13499410450458527
bi 3 loss 0.3465259373188019
Layer  2  loss:  0.2541224956512451 0.0 14.029894828796387
logits torch.Size([767, 4, 1024]) labels torch.Size([767, 4]) 0 1023
Curr loss timestep torch.Size([767, 4]) tensor([134, 319, 271, 566], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.04236651957035065
bi 1 loss 0.1739407777786255
bi 2 loss 0.09628430753946304
bi 3 loss 0.39713773131370544
Layer  3  loss:  0.24109695851802826 0.0 15.313163757324219
logits torch.Size([767, 4, 1024]) labels torch.Size([767, 4]) 0 1021
Curr loss timestep torch.Size([767, 4]) tensor([124, 267, 277, 567], device='cuda:0') tensor(567, device='cuda:0')
bi 0 loss 0.06138814985752106
bi 1 loss 0.15130513906478882
bi 2 loss 0.1033497154712677
bi 3 loss 0.3726990818977356
Layer  4  loss:  0.24320317804813385 0.0 15.763970375061035
logits torch.Size([767, 4, 1024]) labels torch.Size([767, 4]) 0 1022
Curr loss timestep torch.Size([767, 4]) tensor([ 95, 267, 277, 567], device='cuda:0') tensor(567, device='cuda:0')
bi 0 loss 0.02341509982943535
bi 1 loss 0.13724355399608612
bi 2 loss 0.12234029173851013
bi 3 loss 0.3764667510986328
Layer  5  loss:  0.26626577973365784 0.0 13.395942687988281
logits torch.Size([767, 4, 1024]) labels torch.Size([767, 4]) 0 1022
Curr loss timestep torch.Size([767, 4]) tensor([ 99, 319, 277, 648], device='cuda:0') tensor(648, device='cuda:0')
bi 0 loss 0.04800960794091225
bi 1 loss 0.16602478921413422
bi 2 loss 0.12285115569829941
bi 3 loss 0.4096341133117676
Layer  6  loss:  0.2446744740009308 0.0 13.412954330444336
logits torch.Size([767, 4, 1024]) labels torch.Size([767, 4]) 0 1021
Curr loss timestep torch.Size([767, 4]) tensor([129, 315, 277, 567], device='cuda:0') tensor(567, device='cuda:0')
bi 0 loss 0.03446199372410774
bi 1 loss 0.1315111368894577
bi 2 loss 0.13726069033145905
bi 3 loss 0.3720441162586212
Epoch 0: :   3%|▎         | 15478/600000 [03:18<2:05:01, v_num=12, reduced_train_loss=0.379, global_step=15476.0, consumed_samples=61908.0, train_step_timing in s=0.305]Epoch 0: :   3%|▎         | 15478/600000 [03:18<2:05:01, v_num=12, reduced_train_loss=1.850, global_step=15477.0, consumed_samples=61912.0, train_step_timing in s=0.531]loss mask original None

First layer loss:  0.18397364020347595 torch.Size([719, 4]) 12.084303855895996 0.0
Max loss timestep torch.Size([719, 4]) tensor([307, 341, 128, 656], device='cuda:0') tensor(656, device='cuda:0')
bi 0 loss 0.0853751003742218
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 1 loss 0.05390165373682976
speech mask sum tensor(417, device='cuda:0') loss mask sum tensor(417, device='cuda:0')
bi 2 loss 0.0434432290494442
speech mask sum tensor(98, device='cuda:0') loss mask sum tensor(98, device='cuda:0')
bi 3 loss 0.37668201327323914
speech mask sum tensor(444, device='cuda:0') loss mask sum tensor(444, device='cuda:0')
logits torch.Size([719, 4, 257024]) labels torch.Size([719, 4]) 0 257023
Layer  0  loss:  0.24854232370853424 0.0 12.032115936279297
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([278, 330, 114, 313], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.14943759143352509
bi 1 loss 0.12846899032592773
bi 2 loss 0.04272386431694031
bi 3 loss 0.44647353887557983
Layer  1  loss:  0.296918123960495 0.0 16.3701171875
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([278, 521, 103, 665], device='cuda:0') tensor(665, device='cuda:0')
bi 0 loss 0.11892061680555344
bi 1 loss 0.158002108335495
bi 2 loss 0.05671587586402893
bi 3 loss 0.5517635345458984
Layer  2  loss:  0.34317895770072937 0.0 18.172239303588867
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1022
Curr loss timestep torch.Size([719, 4]) tensor([278, 326,  78, 666], device='cuda:0') tensor(666, device='cuda:0')
bi 0 loss 0.1273801028728485
bi 1 loss 0.21742230653762817
bi 2 loss 0.094262033700943
bi 3 loss 0.6027432680130005
Layer  3  loss:  0.3378991186618805 0.0 18.02958106994629
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([278, 333, 118, 665], device='cuda:0') tensor(665, device='cuda:0')
bi 0 loss 0.1288154423236847
bi 1 loss 0.17787770926952362
bi 2 loss 0.08005069196224213
bi 3 loss 0.6289238333702087
Layer  4  loss:  0.3683198094367981 0.0 17.04070472717285
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1022
Curr loss timestep torch.Size([719, 4]) tensor([278, 521, 116, 665], device='cuda:0') tensor(665, device='cuda:0')
bi 0 loss 0.15274132788181305
bi 1 loss 0.23586538434028625
bi 2 loss 0.06517265737056732
bi 3 loss 0.6460561156272888
Layer  5  loss:  0.38964855670928955 0.0 16.663972854614258
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([278, 519, 134, 658], device='cuda:0') tensor(658, device='cuda:0')
bi 0 loss 0.14670251309871674
bi 1 loss 0.20318901538848877
bi 2 loss 0.060592032968997955
bi 3 loss 0.7347962260246277
Layer  6  loss:  0.33992981910705566 0.0 13.40658187866211
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([278, 261,  70, 666], device='cuda:0') tensor(666, device='cuda:0')
bi 0 loss 0.17319849133491516
bi 1 loss 0.19046922028064728
bi 2 loss 0.049538448452949524
bi 3 loss 0.6112397909164429
Epoch 0: :   3%|▎         | 15479/600000 [03:19<2:05:21, v_num=12, reduced_train_loss=1.850, global_step=15477.0, consumed_samples=61912.0, train_step_timing in s=0.531]Epoch 0: :   3%|▎         | 15479/600000 [03:19<2:05:21, v_num=12, reduced_train_loss=2.510, global_step=15478.0, consumed_samples=61916.0, train_step_timing in s=0.492]loss mask original None

First layer loss:  0.12210911512374878 torch.Size([571, 4]) 7.596267223358154 0.0
Max loss timestep torch.Size([571, 4]) tensor([545, 270, 124, 519], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.15063200891017914
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
bi 1 loss 0.11527285724878311
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 2 loss 0.05174015462398529
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 3 loss 0.11441356688737869
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
logits torch.Size([571, 4, 257024]) labels torch.Size([571, 4]) 0 257023
Layer  0  loss:  0.171902135014534 0.0 11.34839916229248
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1023
Curr loss timestep torch.Size([571, 4]) tensor([417, 258, 187, 519], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.20548106729984283
bi 1 loss 0.17094069719314575
bi 2 loss 0.0402013324201107
bi 3 loss 0.17864960432052612
Layer  1  loss:  0.1862819641828537 0.0 10.659494400024414
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1023
Curr loss timestep torch.Size([571, 4]) tensor([393, 323, 131, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.23005658388137817
bi 1 loss 0.1395554393529892
bi 2 loss 0.038338661193847656
bi 3 loss 0.1962437480688095
Layer  2  loss:  0.1701752096414566 0.0 9.564287185668945
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1022
Curr loss timestep torch.Size([571, 4]) tensor([399, 282, 106, 299], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.1980939656496048
bi 1 loss 0.14646373689174652
bi 2 loss 0.04580778628587723
bi 3 loss 0.1858726441860199
Layer  3  loss:  0.1929629147052765 0.0 12.945368766784668
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1021
Curr loss timestep torch.Size([571, 4]) tensor([417, 259,  92, 519], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.24517592787742615
bi 1 loss 0.18323269486427307
bi 2 loss 0.06161290407180786
bi 3 loss 0.17918722331523895
Layer  4  loss:  0.1811748892068863 0.0 11.581657409667969
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1023
Curr loss timestep torch.Size([571, 4]) tensor([539, 323, 134, 520], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.22664083540439606
bi 1 loss 0.1535627245903015
bi 2 loss 0.05406542867422104
bi 3 loss 0.1777169406414032
Layer  5  loss:  0.18738815188407898 0.0 13.291891098022461
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1023
Curr loss timestep torch.Size([571, 4]) tensor([417, 258, 154, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.20891080796718597
bi 1 loss 0.16550302505493164
bi 2 loss 0.06861493736505508
bi 3 loss 0.2083558738231659
Layer  6  loss:  0.1692149043083191 0.0 11.61027717590332
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1022
Curr loss timestep torch.Size([571, 4]) tensor([545, 316, 125, 299], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.21375872194766998
bi 1 loss 0.1803550273180008
bi 2 loss 0.033048659563064575
bi 3 loss 0.16190604865550995
Epoch 0: :   3%|▎         | 15480/600000 [03:19<2:05:37, v_num=12, reduced_train_loss=2.510, global_step=15478.0, consumed_samples=61916.0, train_step_timing in s=0.492]Epoch 0: :   3%|▎         | 15480/600000 [03:19<2:05:37, v_num=12, reduced_train_loss=1.380, global_step=15479.0, consumed_samples=61920.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  0.08000160753726959 torch.Size([458, 4]) 10.352282524108887 0.0
Max loss timestep torch.Size([458, 4]) tensor([ 81, 135, 300, 436], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.03520882502198219
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 1 loss 0.052699845284223557
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 2 loss 0.18525786697864532
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.07872731983661652
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
logits torch.Size([458, 4, 257024]) labels torch.Size([458, 4]) 0 257022
Layer  0  loss:  0.07537999004125595 0.0 10.213640213012695
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([134, 286, 301, 435], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.02693912945687771
bi 1 loss 0.04879538342356682
bi 2 loss 0.2118954062461853
bi 3 loss 0.0614151768386364
Layer  1  loss:  0.09180913865566254 0.0 12.48715877532959
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([ 89, 292, 300, 435], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.040152408182621
bi 1 loss 0.07134827971458435
bi 2 loss 0.23495405912399292
bi 3 loss 0.07248853147029877
Layer  2  loss:  0.08256731927394867 0.0 11.326558113098145
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1022
Curr loss timestep torch.Size([458, 4]) tensor([198, 289, 300, 435], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.026483425870537758
bi 1 loss 0.07436845451593399
bi 2 loss 0.24816282093524933
bi 3 loss 0.04699895903468132
Layer  3  loss:  0.09637336432933807 0.0 10.854118347167969
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1016
Curr loss timestep torch.Size([458, 4]) tensor([ 98, 292, 300, 255], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.04034942016005516
bi 1 loss 0.06931190192699432
bi 2 loss 0.2779132127761841
bi 3 loss 0.06666332483291626
Layer  4  loss:  0.09617198258638382 0.0 9.833088874816895
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1022
Curr loss timestep torch.Size([458, 4]) tensor([198, 289, 300, 435], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.04591275751590729
bi 1 loss 0.08429504185914993
bi 2 loss 0.24185508489608765
bi 3 loss 0.06874620914459229
Layer  5  loss:  0.08512916415929794 0.0 9.703413009643555
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1022
Curr loss timestep torch.Size([458, 4]) tensor([141, 290, 300, 435], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.043939266353845596
bi 1 loss 0.07637935131788254
bi 2 loss 0.19029685854911804
bi 3 loss 0.06855350732803345
Layer  6  loss:  0.08709797263145447 0.0 13.953163146972656
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([113, 290, 300, 435], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.022605763748288155
bi 1 loss 0.049203041940927505
bi 2 loss 0.22976456582546234
bi 3 loss 0.08838342875242233
Epoch 0: :   3%|▎         | 15481/600000 [03:19<2:05:50, v_num=12, reduced_train_loss=1.380, global_step=15479.0, consumed_samples=61920.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15481/600000 [03:19<2:05:50, v_num=12, reduced_train_loss=0.695, global_step=15480.0, consumed_samples=61924.0, train_step_timing in s=0.329]loss mask original None

First layer loss:  3.9392995834350586 torch.Size([468, 4]) 11.347043991088867 0.0
Max loss timestep torch.Size([468, 4]) tensor([138, 254, 310, 239], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 4.23391056060791
speech mask sum tensor(207, device='cuda:0') loss mask sum tensor(207, device='cuda:0')
bi 1 loss 4.026630401611328
speech mask sum tensor(252, device='cuda:0') loss mask sum tensor(252, device='cuda:0')
bi 2 loss 4.181030750274658
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
bi 3 loss 3.413984537124634
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
logits torch.Size([468, 4, 257024]) labels torch.Size([468, 4]) 0 257023
Layer  0  loss:  4.3752288818359375 0.0 11.336393356323242
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([ 85, 352, 216, 250], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 4.515650272369385
bi 1 loss 4.490623950958252
bi 2 loss 4.906987190246582
bi 3 loss 3.705653667449951
Layer  1  loss:  4.66357946395874 0.0 11.016839027404785
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([239, 356, 292, 118], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 4.986754894256592
bi 1 loss 4.895136833190918
bi 2 loss 4.83249568939209
bi 3 loss 4.033779144287109
Layer  2  loss:  4.866471767425537 0.0 11.099150657653809
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([261, 320, 208, 313], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 5.243283271789551
bi 1 loss 5.246422290802002
bi 2 loss 5.1672682762146
bi 3 loss 3.937499761581421
Layer  3  loss:  5.000969409942627 0.0 10.202704429626465
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([246, 299, 284, 328], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 5.220827102661133
bi 1 loss 5.332039833068848
bi 2 loss 5.368165016174316
bi 3 loss 4.191778182983398
Layer  4  loss:  5.031435012817383 0.0 10.828573226928711
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([236, 384, 376, 264], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 5.215414524078369
bi 1 loss 5.288151264190674
bi 2 loss 5.332086086273193
bi 3 loss 4.379814147949219
Layer  5  loss:  5.170572280883789 0.0 10.023063659667969
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([132, 462, 241, 119], device='cuda:0') tensor(241, device='cuda:0')
bi 0 loss 5.402474880218506
bi 1 loss 5.486857891082764
bi 2 loss 5.427761077880859
bi 3 loss 4.457722187042236
Layer  6  loss:  5.227062702178955 0.0 10.38772201538086
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([118, 381, 331, 159], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 5.552383899688721
bi 1 loss 5.562943935394287
bi 2 loss 5.368636131286621
bi 3 loss 4.515585422515869
Epoch 0: :   3%|▎         | 15482/600000 [03:20<2:06:03, v_num=12, reduced_train_loss=0.695, global_step=15480.0, consumed_samples=61924.0, train_step_timing in s=0.329]Epoch 0: :   3%|▎         | 15482/600000 [03:20<2:06:03, v_num=12, reduced_train_loss=38.30, global_step=15481.0, consumed_samples=61928.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  0.17941898107528687 torch.Size([793, 4]) 10.548637390136719 0.0
Max loss timestep torch.Size([793, 4]) tensor([557, 178, 104,  46], device='cuda:0') tensor(557, device='cuda:0')
bi 0 loss 0.3072395920753479
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
bi 1 loss 0.02300960011780262
speech mask sum tensor(71, device='cuda:0') loss mask sum tensor(71, device='cuda:0')
bi 2 loss 0.03222072869539261
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
bi 3 loss 0.0252926554530859
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
logits torch.Size([793, 4, 257024]) labels torch.Size([793, 4]) 0 257022
Layer  0  loss:  0.20460684597492218 0.0 10.089448928833008
logits torch.Size([793, 4, 1024]) labels torch.Size([793, 4]) 0 1023
Curr loss timestep torch.Size([793, 4]) tensor([640, 173,  88,  54], device='cuda:0') tensor(640, device='cuda:0')
bi 0 loss 0.33873459696769714
bi 1 loss 0.04180073365569115
bi 2 loss 0.06337752938270569
bi 3 loss 0.030959444120526314
Layer  1  loss:  0.19288422167301178 0.0 8.534180641174316
logits torch.Size([793, 4, 1024]) labels torch.Size([793, 4]) 0 1023
Curr loss timestep torch.Size([793, 4]) tensor([546, 147,  78, 100], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.31144601106643677
bi 1 loss 0.026269197463989258
bi 2 loss 0.0822654590010643
bi 3 loss 0.03665826842188835
Layer  2  loss:  0.2074974924325943 0.0 11.297303199768066
logits torch.Size([793, 4, 1024]) labels torch.Size([793, 4]) 0 1022
Curr loss timestep torch.Size([793, 4]) tensor([677, 156, 112, 110], device='cuda:0') tensor(677, device='cuda:0')
bi 0 loss 0.3494811952114105
bi 1 loss 0.03582875430583954
bi 2 loss 0.04702321067452431
bi 3 loss 0.032822296023368835
Layer  3  loss:  0.21686361730098724 0.0 11.487569808959961
logits torch.Size([793, 4, 1024]) labels torch.Size([793, 4]) 0 1023
Curr loss timestep torch.Size([793, 4]) tensor([545, 148, 123, 139], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.36716198921203613
bi 1 loss 0.02333183027803898
bi 2 loss 0.049535397440195084
bi 3 loss 0.034707315266132355
Layer  4  loss:  0.2521149218082428 0.0 15.89071273803711
logits torch.Size([793, 4, 1024]) labels torch.Size([793, 4]) 0 1023
Curr loss timestep torch.Size([793, 4]) tensor([663, 147, 114, 156], device='cuda:0') tensor(663, device='cuda:0')
bi 0 loss 0.4352770745754242
bi 1 loss 0.04339984431862831
bi 2 loss 0.04044158011674881
bi 3 loss 0.025458969175815582
Layer  5  loss:  0.24434494972229004 0.0 11.0938138961792
logits torch.Size([793, 4, 1024]) labels torch.Size([793, 4]) 0 1018
Curr loss timestep torch.Size([793, 4]) tensor([663, 160, 152, 109], device='cuda:0') tensor(663, device='cuda:0')
bi 0 loss 0.4127136170864105
bi 1 loss 0.03658870980143547
bi 2 loss 0.05593153461813927
bi 3 loss 0.03734184801578522
Layer  6  loss:  0.26870518922805786 0.0 13.880941390991211
logits torch.Size([793, 4, 1024]) labels torch.Size([793, 4]) 0 1023
Curr loss timestep torch.Size([793, 4]) tensor([546, 143, 130, 127], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.447628915309906
bi 1 loss 0.07211349159479141
bi 2 loss 0.06953126937150955
bi 3 loss 0.037719838321208954
Epoch 0: :   3%|▎         | 15483/600000 [03:20<2:06:24, v_num=12, reduced_train_loss=38.30, global_step=15481.0, consumed_samples=61928.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15483/600000 [03:20<2:06:24, v_num=12, reduced_train_loss=1.770, global_step=15482.0, consumed_samples=61932.0, train_step_timing in s=0.546]loss mask original None

First layer loss:  0.2644496560096741 torch.Size([894, 4]) 9.287090301513672 0.0
Max loss timestep torch.Size([894, 4]) tensor([ 87, 183, 152, 846], device='cuda:0') tensor(846, device='cuda:0')
bi 0 loss 0.027808990329504013
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 1 loss 0.07974694669246674
speech mask sum tensor(80, device='cuda:0') loss mask sum tensor(80, device='cuda:0')
bi 2 loss 0.03286489471793175
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 3 loss 0.4206549823284149
speech mask sum tensor(492, device='cuda:0') loss mask sum tensor(492, device='cuda:0')
logits torch.Size([894, 4, 257024]) labels torch.Size([894, 4]) 0 257022
Layer  0  loss:  0.41494715213775635 0.0 12.193075180053711
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1023
Curr loss timestep torch.Size([894, 4]) tensor([144, 164, 141, 638], device='cuda:0') tensor(638, device='cuda:0')
bi 0 loss 0.03421560674905777
bi 1 loss 0.060261886566877365
bi 2 loss 0.05669034272432327
bi 3 loss 0.6706051826477051
Layer  1  loss:  0.34424176812171936 0.0 13.981307983398438
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1023
Curr loss timestep torch.Size([894, 4]) tensor([ 91, 188, 113, 727], device='cuda:0') tensor(727, device='cuda:0')
bi 0 loss 0.0409022755920887
bi 1 loss 0.07642468810081482
bi 2 loss 0.025755444541573524
bi 3 loss 0.5570850968360901
Layer  2  loss:  0.4121759831905365 0.0 11.768058776855469
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1022
Curr loss timestep torch.Size([894, 4]) tensor([ 93, 182,  90, 639], device='cuda:0') tensor(639, device='cuda:0')
bi 0 loss 0.0490022674202919
bi 1 loss 0.03307996317744255
bi 2 loss 0.049876391887664795
bi 3 loss 0.6698620319366455
Layer  3  loss:  0.38763362169265747 0.0 13.433606147766113
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1022
Curr loss timestep torch.Size([894, 4]) tensor([145, 162, 140, 874], device='cuda:0') tensor(874, device='cuda:0')
bi 0 loss 0.059209033846855164
bi 1 loss 0.06122107431292534
bi 2 loss 0.04945479333400726
bi 3 loss 0.6216816306114197
Layer  4  loss:  0.44110026955604553 0.0 16.670610427856445
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1022
Curr loss timestep torch.Size([894, 4]) tensor([148, 160, 108, 638], device='cuda:0') tensor(638, device='cuda:0')
bi 0 loss 0.0380181260406971
bi 1 loss 0.04580264538526535
bi 2 loss 0.05684374272823334
bi 3 loss 0.7167215943336487
Layer  5  loss:  0.47867652773857117 0.0 19.648395538330078
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1022
Curr loss timestep torch.Size([894, 4]) tensor([143, 181,  84, 638], device='cuda:0') tensor(638, device='cuda:0')
bi 0 loss 0.07991419732570648
bi 1 loss 0.027703534811735153
bi 2 loss 0.06370657682418823
bi 3 loss 0.7732624411582947
Layer  6  loss:  0.43829789757728577 0.0 11.581504821777344
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1023
Curr loss timestep torch.Size([894, 4]) tensor([144, 154, 142, 562], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.05917615070939064
bi 1 loss 0.02447727508842945
bi 2 loss 0.03791026771068573
bi 3 loss 0.7179925441741943
Epoch 0: :   3%|▎         | 15484/600000 [03:21<2:06:49, v_num=12, reduced_train_loss=1.770, global_step=15482.0, consumed_samples=61932.0, train_step_timing in s=0.546]Epoch 0: :   3%|▎         | 15484/600000 [03:21<2:06:49, v_num=12, reduced_train_loss=3.180, global_step=15483.0, consumed_samples=61936.0, train_step_timing in s=0.627]loss mask original None

First layer loss:  3.878264904022217 torch.Size([568, 4]) 11.48310661315918 0.0
Max loss timestep torch.Size([568, 4]) tensor([182, 212, 270, 426], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 4.09427547454834
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 1 loss 3.8138465881347656
speech mask sum tensor(384, device='cuda:0') loss mask sum tensor(384, device='cuda:0')
bi 2 loss 4.228238105773926
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 3 loss 3.654921054840088
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
logits torch.Size([568, 4, 257024]) labels torch.Size([568, 4]) 0 257023
Layer  0  loss:  4.317094326019287 0.0 11.4807767868042
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([276, 431, 264, 288], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 4.410371780395508
bi 1 loss 4.3587212562561035
bi 2 loss 4.862563610076904
bi 3 loss 4.028141975402832
Layer  1  loss:  4.6221489906311035 0.0 10.527587890625
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([139, 330, 205, 520], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 4.743826389312744
bi 1 loss 4.695706844329834
bi 2 loss 4.562065601348877
bi 3 loss 4.46089506149292
Layer  2  loss:  4.935125350952148 0.0 10.319079399108887
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([220, 276, 227, 252], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 5.176954746246338
bi 1 loss 4.867242336273193
bi 2 loss 4.935976982116699
bi 3 loss 4.800089359283447
Layer  3  loss:  5.123676300048828 0.0 11.08134651184082
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([342, 247, 224, 558], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 5.334239482879639
bi 1 loss 5.135383129119873
bi 2 loss 5.000884532928467
bi 3 loss 4.970333099365234
Layer  4  loss:  5.241508483886719 0.0 11.737174987792969
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([351, 339, 208, 318], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 5.522281169891357
bi 1 loss 5.152904033660889
bi 2 loss 5.234170913696289
bi 3 loss 5.0974297523498535
Layer  5  loss:  5.323971271514893 0.0 12.048467636108398
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([283, 460, 226, 514], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 5.629528999328613
bi 1 loss 5.134269714355469
bi 2 loss 5.311863899230957
bi 3 loss 5.265236854553223
Layer  6  loss:  5.3674421310424805 0.0 10.622915267944336
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([278, 461, 211, 217], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 5.75629186630249
bi 1 loss 5.240139007568359
bi 2 loss 5.0456461906433105
bi 3 loss 5.267844200134277
Epoch 0: :   3%|▎         | 15485/600000 [03:21<2:07:04, v_num=12, reduced_train_loss=3.180, global_step=15483.0, consumed_samples=61936.0, train_step_timing in s=0.627]Epoch 0: :   3%|▎         | 15485/600000 [03:21<2:07:04, v_num=12, reduced_train_loss=38.80, global_step=15484.0, consumed_samples=61940.0, train_step_timing in s=0.368]loss mask original None

First layer loss:  0.07108557224273682 torch.Size([517, 4]) 10.739240646362305 0.0
Max loss timestep torch.Size([517, 4]) tensor([501, 265, 265, 335], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.11337500810623169
speech mask sum tensor(358, device='cuda:0') loss mask sum tensor(358, device='cuda:0')
bi 1 loss 0.06414054334163666
speech mask sum tensor(395, device='cuda:0') loss mask sum tensor(395, device='cuda:0')
bi 2 loss 0.0647759884595871
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 3 loss 0.0342087484896183
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
logits torch.Size([517, 4, 257024]) labels torch.Size([517, 4]) 0 257023
Layer  0  loss:  0.1171051487326622 0.0 13.562666893005371
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([501, 263, 262, 371], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.17549346387386322
bi 1 loss 0.08460773527622223
bi 2 loss 0.06110544502735138
bi 3 loss 0.1319420337677002
Layer  1  loss:  0.12016752362251282 0.0 9.346551895141602
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([500, 402, 152, 373], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.17764165997505188
bi 1 loss 0.08024917542934418
bi 2 loss 0.07368871569633484
bi 3 loss 0.13881444931030273
Layer  2  loss:  0.12122044712305069 0.0 10.026081085205078
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([501, 263, 149, 371], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.17042064666748047
bi 1 loss 0.10042222589254379
bi 2 loss 0.05243239924311638
bi 3 loss 0.14115789532661438
Layer  3  loss:  0.11251535266637802 0.0 9.375570297241211
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1021
Curr loss timestep torch.Size([517, 4]) tensor([500, 394,  80, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.14786942303180695
bi 1 loss 0.09955374896526337
bi 2 loss 0.0386514887213707
bi 3 loss 0.14249765872955322
Layer  4  loss:  0.14010801911354065 0.0 16.42197036743164
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([500, 265, 262, 372], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.20540376007556915
bi 1 loss 0.10549727082252502
bi 2 loss 0.0718575045466423
bi 3 loss 0.15861552953720093
Layer  5  loss:  0.12290266901254654 0.0 11.429411888122559
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([406, 412, 265, 373], device='cuda:0') tensor(406, device='cuda:0')
bi 0 loss 0.19450201094150543
bi 1 loss 0.09960810095071793
bi 2 loss 0.05412930250167847
bi 3 loss 0.11922898888587952
Layer  6  loss:  0.135231152176857 0.0 12.094817161560059
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1022
Curr loss timestep torch.Size([517, 4]) tensor([500, 263, 265, 372], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.2100636214017868
bi 1 loss 0.08663675934076309
bi 2 loss 0.05789608508348465
bi 3 loss 0.1676153689622879
Epoch 0: :   3%|▎         | 15486/600000 [03:22<2:07:18, v_num=12, reduced_train_loss=38.80, global_step=15484.0, consumed_samples=61940.0, train_step_timing in s=0.368]Epoch 0: :   3%|▎         | 15486/600000 [03:22<2:07:18, v_num=12, reduced_train_loss=0.940, global_step=15485.0, consumed_samples=61944.0, train_step_timing in s=0.358]loss mask original None

First layer loss:  3.497034788131714 torch.Size([500, 4]) 12.078089714050293 0.0
Max loss timestep torch.Size([500, 4]) tensor([385,  55, 376,  69], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 3.8309433460235596
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 1 loss 3.965574264526367
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 2 loss 2.690793037414551
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 3 loss 3.823997974395752
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
logits torch.Size([500, 4, 257024]) labels torch.Size([500, 4]) 0 257023
Layer  0  loss:  4.075369358062744 0.0 10.944570541381836
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([427, 111, 394, 118], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 4.514516830444336
bi 1 loss 4.16988468170166
bi 2 loss 3.3888282775878906
bi 3 loss 4.417007923126221
Layer  1  loss:  4.455936908721924 0.0 9.869009971618652
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([365,  49, 265, 160], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 4.911584377288818
bi 1 loss 4.619540214538574
bi 2 loss 3.75313138961792
bi 3 loss 4.724620819091797
Layer  2  loss:  4.754668235778809 0.0 11.017322540283203
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([294,  56, 467, 147], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 5.261424541473389
bi 1 loss 4.900373458862305
bi 2 loss 4.077946662902832
bi 3 loss 4.911942005157471
Layer  3  loss:  4.911581993103027 0.0 11.007915496826172
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1020
Curr loss timestep torch.Size([500, 4]) tensor([410,  54, 451, 153], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 5.506192684173584
bi 1 loss 4.744848728179932
bi 2 loss 4.27806282043457
bi 3 loss 5.178616523742676
Layer  4  loss:  4.950325012207031 0.0 10.293936729431152
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1021
Curr loss timestep torch.Size([500, 4]) tensor([230, 170, 263, 140], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 5.597557067871094
bi 1 loss 4.85692834854126
bi 2 loss 4.3199872970581055
bi 3 loss 5.0460286140441895
Layer  5  loss:  5.047047138214111 0.0 10.685873031616211
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([313,  88, 382, 150], device='cuda:0') tensor(111, device='cuda:0')
bi 0 loss 5.595860481262207
bi 1 loss 4.994904518127441
bi 2 loss 4.423544883728027
bi 3 loss 5.252215385437012
Layer  6  loss:  5.105952262878418 0.0 11.97906494140625
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([302,  65, 413, 108], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 5.589564800262451
bi 1 loss 5.1244354248046875
bi 2 loss 4.408112049102783
bi 3 loss 5.4730329513549805
Epoch 0: :   3%|▎         | 15487/600000 [03:22<2:07:32, v_num=12, reduced_train_loss=0.940, global_step=15485.0, consumed_samples=61944.0, train_step_timing in s=0.358]Epoch 0: :   3%|▎         | 15487/600000 [03:22<2:07:32, v_num=12, reduced_train_loss=36.80, global_step=15486.0, consumed_samples=61948.0, train_step_timing in s=0.332]loss mask original None

First layer loss:  0.1255945861339569 torch.Size([629, 4]) 10.78148078918457 0.0
Max loss timestep torch.Size([629, 4]) tensor([605, 476,  98, 261], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.20162327587604523
speech mask sum tensor(463, device='cuda:0') loss mask sum tensor(463, device='cuda:0')
bi 1 loss 0.12492794543504715
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
bi 2 loss 0.04005757346749306
speech mask sum tensor(338, device='cuda:0') loss mask sum tensor(338, device='cuda:0')
bi 3 loss 0.09608998149633408
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
logits torch.Size([629, 4, 257024]) labels torch.Size([629, 4]) 0 257022
Layer  0  loss:  0.11718910932540894 0.0 10.851940155029297
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([584, 439, 281, 273], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.15628886222839355
bi 1 loss 0.15349848568439484
bi 2 loss 0.04994939640164375
bi 3 loss 0.0756274089217186
Layer  1  loss:  0.16441459953784943 0.0 11.69926643371582
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([605, 439, 311, 258], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.24490709602832794
bi 1 loss 0.16017314791679382
bi 2 loss 0.06919350475072861
bi 3 loss 0.14710783958435059
Layer  2  loss:  0.1710764467716217 0.0 12.7952241897583
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([605, 439, 372, 258], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.27884918451309204
bi 1 loss 0.1658935546875
bi 2 loss 0.05996857210993767
bi 3 loss 0.12001253664493561
Layer  3  loss:  0.17266812920570374 0.0 11.965290069580078
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([605, 476, 149, 258], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.2746233344078064
bi 1 loss 0.17153538763523102
bi 2 loss 0.055579811334609985
bi 3 loss 0.13745172321796417
Layer  4  loss:  0.16217869520187378 0.0 10.798471450805664
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([605, 476, 285, 258], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.26441627740859985
bi 1 loss 0.15607105195522308
bi 2 loss 0.056427452713251114
bi 3 loss 0.11641716212034225
Layer  5  loss:  0.16898122429847717 0.0 11.689014434814453
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([605, 440, 370, 258], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.2584335505962372
bi 1 loss 0.1517346203327179
bi 2 loss 0.05832670256495476
bi 3 loss 0.17984987795352936
Layer  6  loss:  0.16410838067531586 0.0 12.032425880432129
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([584, 474, 377, 258], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.2610962688922882
bi 1 loss 0.15406467020511627
bi 2 loss 0.036008089780807495
bi 3 loss 0.1740027815103531
Epoch 0: :   3%|▎         | 15488/600000 [03:23<2:07:49, v_num=12, reduced_train_loss=36.80, global_step=15486.0, consumed_samples=61948.0, train_step_timing in s=0.332]Epoch 0: :   3%|▎         | 15488/600000 [03:23<2:07:49, v_num=12, reduced_train_loss=1.250, global_step=15487.0, consumed_samples=6.2e+4, train_step_timing in s=0.430] loss mask original None

First layer loss:  0.1037674993276596 torch.Size([465, 4]) 13.829635620117188 0.0
Max loss timestep torch.Size([465, 4]) tensor([436, 295, 343,  92], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.11185284703969955
speech mask sum tensor(402, device='cuda:0') loss mask sum tensor(402, device='cuda:0')
bi 1 loss 0.13866026699543
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
bi 2 loss 0.07198500633239746
speech mask sum tensor(320, device='cuda:0') loss mask sum tensor(320, device='cuda:0')
bi 3 loss 0.036562200635671616
speech mask sum tensor(72, device='cuda:0') loss mask sum tensor(72, device='cuda:0')
logits torch.Size([465, 4, 257024]) labels torch.Size([465, 4]) 0 257023
Layer  0  loss:  0.10999730974435806 0.0 14.678059577941895
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([437, 295, 185,  69], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.119639553129673
bi 1 loss 0.11817554384469986
bi 2 loss 0.11047248542308807
bi 3 loss 0.015770912170410156
Layer  1  loss:  0.08765970915555954 0.0 9.798076629638672
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([436, 295, 324,  99], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.09289324283599854
bi 1 loss 0.10402636229991913
bi 2 loss 0.08053692430257797
bi 3 loss 0.013490932062268257
Layer  2  loss:  0.12668150663375854 0.0 20.796924591064453
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([436, 295, 342, 102], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.1561000496149063
bi 1 loss 0.12154938280582428
bi 2 loss 0.11821458488702774
bi 3 loss 0.024079829454421997
Layer  3  loss:  0.1111682802438736 0.0 16.765636444091797
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1021
Curr loss timestep torch.Size([465, 4]) tensor([436, 296, 344,  70], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.13710199296474457
bi 1 loss 0.10666824132204056
bi 2 loss 0.09144729375839233
bi 3 loss 0.0750831663608551
Layer  4  loss:  0.11451797932386398 0.0 14.53909683227539
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([435, 296, 342,  86], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.14421914517879486
bi 1 loss 0.11955228447914124
bi 2 loss 0.09426046907901764
bi 3 loss 0.015156666748225689
Layer  5  loss:  0.11248164623975754 0.0 12.505631446838379
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([437, 295, 342,  99], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.11116325110197067
bi 1 loss 0.1339789777994156
bi 2 loss 0.10822689533233643
bi 3 loss 0.03813335672020912
Layer  6  loss:  0.10567893832921982 0.0 13.956323623657227
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([435, 295, 343,  61], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.12698990106582642
bi 1 loss 0.0821242481470108
bi 2 loss 0.11340875923633575
bi 3 loss 0.06258712708950043
Epoch 0: :   3%|▎         | 15489/600000 [03:23<2:08:03, v_num=12, reduced_train_loss=1.250, global_step=15487.0, consumed_samples=6.2e+4, train_step_timing in s=0.430]Epoch 0: :   3%|▎         | 15489/600000 [03:23<2:08:03, v_num=12, reduced_train_loss=0.872, global_step=15488.0, consumed_samples=6.2e+4, train_step_timing in s=0.364]loss mask original None

First layer loss:  0.12806610763072968 torch.Size([710, 4]) 8.883810043334961 0.0
Max loss timestep torch.Size([710, 4]) tensor([423, 662, 249, 105], device='cuda:0') tensor(662, device='cuda:0')
bi 0 loss 0.09351080656051636
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 1 loss 0.19548320770263672
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
bi 2 loss 0.07478803396224976
speech mask sum tensor(339, device='cuda:0') loss mask sum tensor(339, device='cuda:0')
bi 3 loss 0.04947274178266525
speech mask sum tensor(62, device='cuda:0') loss mask sum tensor(62, device='cuda:0')
logits torch.Size([710, 4, 257024]) labels torch.Size([710, 4]) 0 257023
Layer  0  loss:  0.1850401908159256 0.0 13.031404495239258
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([423, 661, 341, 103], device='cuda:0') tensor(423, device='cuda:0')
bi 0 loss 0.14966827630996704
bi 1 loss 0.2768404483795166
bi 2 loss 0.1113554835319519
bi 3 loss 0.026963548734784126
Layer  1  loss:  0.21922405064105988 0.0 11.509847640991211
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([423, 662, 362, 102], device='cuda:0') tensor(662, device='cuda:0')
bi 0 loss 0.0978347435593605
bi 1 loss 0.3203699588775635
bi 2 loss 0.21342076361179352
bi 3 loss 0.03698690980672836
Layer  2  loss:  0.22041553258895874 0.0 13.100101470947266
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([423, 377, 333, 105], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.10632286220788956
bi 1 loss 0.33625441789627075
bi 2 loss 0.19040273129940033
bi 3 loss 0.017228705808520317
Layer  3  loss:  0.197441965341568 0.0 14.172982215881348
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([423, 377, 310, 110], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.07800769060850143
bi 1 loss 0.33825910091400146
bi 2 loss 0.12791384756565094
bi 3 loss 0.036679890006780624
Layer  4  loss:  0.24970340728759766 0.0 13.827446937561035
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([423, 439, 339,  96], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.10356128960847855
bi 1 loss 0.37034767866134644
bi 2 loss 0.24018609523773193
bi 3 loss 0.0531550869345665
Layer  5  loss:  0.2562897801399231 0.0 9.283687591552734
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1021
Curr loss timestep torch.Size([710, 4]) tensor([423, 661, 444, 104], device='cuda:0') tensor(661, device='cuda:0')
bi 0 loss 0.16069240868091583
bi 1 loss 0.3585081100463867
bi 2 loss 0.23540182411670685
bi 3 loss 0.021488260477781296
Layer  6  loss:  0.2800827622413635 0.0 10.58558177947998
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([423, 441, 311,  93], device='cuda:0') tensor(441, device='cuda:0')
bi 0 loss 0.13238778710365295
bi 1 loss 0.39533135294914246
bi 2 loss 0.29283377528190613
bi 3 loss 0.01255696453154087
Epoch 0: :   3%|▎         | 15490/600000 [03:24<2:08:22, v_num=12, reduced_train_loss=0.872, global_step=15488.0, consumed_samples=6.2e+4, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15490/600000 [03:24<2:08:22, v_num=12, reduced_train_loss=1.740, global_step=15489.0, consumed_samples=6.2e+4, train_step_timing in s=0.479]loss mask original None

First layer loss:  0.08103479444980621 torch.Size([509, 4]) 7.102446556091309 0.0
Max loss timestep torch.Size([509, 4]) tensor([258, 387, 340, 325], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.07441673427820206
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 1 loss 0.051157593727111816
speech mask sum tensor(339, device='cuda:0') loss mask sum tensor(339, device='cuda:0')
bi 2 loss 0.24614468216896057
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 3 loss 0.06601190567016602
speech mask sum tensor(309, device='cuda:0') loss mask sum tensor(309, device='cuda:0')
logits torch.Size([509, 4, 257024]) labels torch.Size([509, 4]) 0 257022
Layer  0  loss:  0.1395832598209381 0.0 12.20333194732666
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([258, 387, 339, 287], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.0819031372666359
bi 1 loss 0.12308711558580399
bi 2 loss 0.39459705352783203
bi 3 loss 0.12424572557210922
Layer  1  loss:  0.15011164546012878 0.0 15.101944923400879
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([258, 387, 339, 324], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.10299498587846756
bi 1 loss 0.14723892509937286
bi 2 loss 0.4319908916950226
bi 3 loss 0.10214276611804962
Layer  2  loss:  0.18186864256858826 0.0 12.912303924560547
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([258, 387, 339, 325], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.09624694287776947
bi 1 loss 0.22628338634967804
bi 2 loss 0.39551734924316406
bi 3 loss 0.13687528669834137
Layer  3  loss:  0.1650213599205017 0.0 14.149982452392578
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1021
Curr loss timestep torch.Size([509, 4]) tensor([258, 387, 338, 338], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.08691439032554626
bi 1 loss 0.20115812122821808
bi 2 loss 0.43483006954193115
bi 3 loss 0.10453882813453674
Layer  4  loss:  0.1517678052186966 0.0 10.625923156738281
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([372, 387, 339, 287], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.07733161002397537
bi 1 loss 0.1827959269285202
bi 2 loss 0.409368097782135
bi 3 loss 0.09771654009819031
Layer  5  loss:  0.15806527435779572 0.0 11.11337661743164
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([258, 387, 339, 325], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.08798833936452866
bi 1 loss 0.21373237669467926
bi 2 loss 0.29641395807266235
bi 3 loss 0.11186526715755463
Layer  6  loss:  0.15827970206737518 0.0 11.687463760375977
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([347, 387, 340, 287], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.10642216354608536
bi 1 loss 0.19194498658180237
bi 2 loss 0.36082687973976135
bi 3 loss 0.09993438422679901
Epoch 0: :   3%|▎         | 15491/600000 [03:24<2:08:37, v_num=12, reduced_train_loss=1.740, global_step=15489.0, consumed_samples=6.2e+4, train_step_timing in s=0.479]Epoch 0: :   3%|▎         | 15491/600000 [03:24<2:08:37, v_num=12, reduced_train_loss=1.190, global_step=15490.0, consumed_samples=6.2e+4, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.06895393878221512 torch.Size([543, 4]) 5.374259948730469 0.0
Max loss timestep torch.Size([543, 4]) tensor([214, 521, 348,  50], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.038497406989336014
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 1 loss 0.08433528989553452
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
bi 2 loss 0.04757646471261978
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 3 loss 0.03542061522603035
speech mask sum tensor(84, device='cuda:0') loss mask sum tensor(84, device='cuda:0')
logits torch.Size([543, 4, 257024]) labels torch.Size([543, 4]) 0 257022
Layer  0  loss:  0.10865268111228943 0.0 13.48451042175293
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([192, 521, 359,  70], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.0187055766582489
bi 1 loss 0.14037121832370758
bi 2 loss 0.07890602201223373
bi 3 loss 0.044997669756412506
Layer  1  loss:  0.08503727614879608 0.0 7.498579978942871
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1021
Curr loss timestep torch.Size([543, 4]) tensor([227, 522, 334,  85], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.02514931932091713
bi 1 loss 0.11454082280397415
bi 2 loss 0.027210179716348648
bi 3 loss 0.0432194285094738
Layer  2  loss:  0.0994126945734024 0.0 11.57648754119873
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1022
Curr loss timestep torch.Size([543, 4]) tensor([212, 521, 343,  55], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.032747648656368256
bi 1 loss 0.13052396476268768
bi 2 loss 0.06251779943704605
bi 3 loss 0.02797882817685604
Layer  3  loss:  0.09002814441919327 0.0 7.606331825256348
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1022
Curr loss timestep torch.Size([543, 4]) tensor([223, 522, 360,  57], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.027861082926392555
bi 1 loss 0.11600758135318756
bi 2 loss 0.05533994734287262
bi 3 loss 0.0409199558198452
Layer  4  loss:  0.1292542815208435 0.0 12.806567192077637
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1022
Curr loss timestep torch.Size([543, 4]) tensor([216, 521, 359,  57], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.03957362473011017
bi 1 loss 0.16039787232875824
bi 2 loss 0.1317804753780365
bi 3 loss 0.027893617749214172
Layer  5  loss:  0.07396668195724487 0.0 6.6170735359191895
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([201, 521, 359,  73], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.03047785349190235
bi 1 loss 0.0878867357969284
bi 2 loss 0.06420372426509857
bi 3 loss 0.04536588117480278
Layer  6  loss:  0.0856344923377037 0.0 6.983241081237793
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([225, 521, 359,  59], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.02175198867917061
bi 1 loss 0.11009979248046875
bi 2 loss 0.0711774006485939
bi 3 loss 0.02104947157204151
Epoch 0: :   3%|▎         | 15492/600000 [03:24<2:08:52, v_num=12, reduced_train_loss=1.190, global_step=15490.0, consumed_samples=6.2e+4, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15492/600000 [03:24<2:08:52, v_num=12, reduced_train_loss=0.741, global_step=15491.0, consumed_samples=6.2e+4, train_step_timing in s=0.375]loss mask original None

First layer loss:  0.06042615324258804 torch.Size([523, 4]) 6.288712024688721 0.0
Max loss timestep torch.Size([523, 4]) tensor([279, 324, 348, 268], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.048815175890922546
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 1 loss 0.043939899653196335
speech mask sum tensor(204, device='cuda:0') loss mask sum tensor(204, device='cuda:0')
bi 2 loss 0.08642540872097015
speech mask sum tensor(360, device='cuda:0') loss mask sum tensor(360, device='cuda:0')
bi 3 loss 0.044791631400585175
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
logits torch.Size([523, 4, 257024]) labels torch.Size([523, 4]) 0 257023
Layer  0  loss:  0.07686186581850052 0.0 4.036152362823486
logits torch.Size([523, 4, 1024]) labels torch.Size([523, 4]) 0 1023
Curr loss timestep torch.Size([523, 4]) tensor([364, 179, 317, 334], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.11024187505245209
bi 1 loss 0.06683995574712753
bi 2 loss 0.08192295581102371
bi 3 loss 0.0625171884894371
Layer  1  loss:  0.07874717563390732 0.0 5.248913764953613
logits torch.Size([523, 4, 1024]) labels torch.Size([523, 4]) 0 1023
Curr loss timestep torch.Size([523, 4]) tensor([302, 320, 412, 138], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.1207587942481041
bi 1 loss 0.08990030735731125
bi 2 loss 0.06647677719593048
bi 3 loss 0.067181296646595
Layer  2  loss:  0.06460319459438324 0.0 6.474120616912842
logits torch.Size([523, 4, 1024]) labels torch.Size([523, 4]) 0 1022
Curr loss timestep torch.Size([523, 4]) tensor([352, 293, 348, 334], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.083986297249794
bi 1 loss 0.039254263043403625
bi 2 loss 0.0719040036201477
bi 3 loss 0.06468362361192703
Layer  3  loss:  0.07089979946613312 0.0 5.402750492095947
logits torch.Size([523, 4, 1024]) labels torch.Size([523, 4]) 0 1023
Curr loss timestep torch.Size([523, 4]) tensor([304, 301, 471, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.10679102689027786
bi 1 loss 0.06469743698835373
bi 2 loss 0.06194136291742325
bi 3 loss 0.07028816640377045
Layer  4  loss:  0.06759271770715714 0.0 6.5718770027160645
logits torch.Size([523, 4, 1024]) labels torch.Size([523, 4]) 0 1023
Curr loss timestep torch.Size([523, 4]) tensor([339, 278, 506, 266], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.07172305881977081
bi 1 loss 0.037391334772109985
bi 2 loss 0.08350802212953568
bi 3 loss 0.06722559034824371
Layer  5  loss:  0.06802777200937271 0.0 3.5371155738830566
logits torch.Size([523, 4, 1024]) labels torch.Size([523, 4]) 0 1022
Curr loss timestep torch.Size([523, 4]) tensor([279, 299, 411, 335], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.08265247195959091
bi 1 loss 0.07511872053146362
bi 2 loss 0.06555310636758804
bi 3 loss 0.05946720764040947
Layer  6  loss:  0.07308047264814377 0.0 5.8648505210876465
logits torch.Size([523, 4, 1024]) labels torch.Size([523, 4]) 0 1022
Curr loss timestep torch.Size([523, 4]) tensor([365, 297, 444, 181], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 0.07289442420005798
bi 1 loss 0.06794313341379166
bi 2 loss 0.06390047818422318
bi 3 loss 0.08833133429288864
Epoch 0: :   3%|▎         | 15493/600000 [03:25<2:09:06, v_num=12, reduced_train_loss=0.741, global_step=15491.0, consumed_samples=6.2e+4, train_step_timing in s=0.375]Epoch 0: :   3%|▎         | 15493/600000 [03:25<2:09:06, v_num=12, reduced_train_loss=0.560, global_step=15492.0, consumed_samples=6.2e+4, train_step_timing in s=0.362]loss mask original None

First layer loss:  3.75905442237854 torch.Size([380, 4]) 10.763917922973633 0.0
Max loss timestep torch.Size([380, 4]) tensor([207, 176, 121, 100], device='cuda:0') tensor(112, device='cuda:0')
bi 0 loss 3.4558849334716797
speech mask sum tensor(189, device='cuda:0') loss mask sum tensor(189, device='cuda:0')
bi 1 loss 3.6862552165985107
speech mask sum tensor(294, device='cuda:0') loss mask sum tensor(294, device='cuda:0')
bi 2 loss 3.9741220474243164
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 3 loss 3.9950695037841797
speech mask sum tensor(215, device='cuda:0') loss mask sum tensor(215, device='cuda:0')
logits torch.Size([380, 4, 257024]) labels torch.Size([380, 4]) 0 257022
Layer  0  loss:  4.194748401641846 0.0 11.15318489074707
logits torch.Size([380, 4, 1024]) labels torch.Size([380, 4]) 0 1023
Curr loss timestep torch.Size([380, 4]) tensor([170, 243, 132,  96], device='cuda:0') tensor(91, device='cuda:0')
bi 0 loss 3.998170852661133
bi 1 loss 4.2864766120910645
bi 2 loss 4.2790632247924805
bi 3 loss 4.191138744354248
Layer  1  loss:  4.452810287475586 0.0 10.18419075012207
logits torch.Size([380, 4, 1024]) labels torch.Size([380, 4]) 0 1022
Curr loss timestep torch.Size([380, 4]) tensor([201, 221, 140, 216], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 4.263150215148926
bi 1 loss 4.524153709411621
bi 2 loss 4.283708572387695
bi 3 loss 4.624222755432129
Layer  2  loss:  4.663615703582764 0.0 9.41490364074707
logits torch.Size([380, 4, 1024]) labels torch.Size([380, 4]) 0 1022
Curr loss timestep torch.Size([380, 4]) tensor([ 73, 111,  53, 135], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 4.538539886474609
bi 1 loss 4.76676607131958
bi 2 loss 4.404433727264404
bi 3 loss 4.789227485656738
Layer  3  loss:  4.839535713195801 0.0 9.588127136230469
logits torch.Size([380, 4, 1024]) labels torch.Size([380, 4]) 0 1019
Curr loss timestep torch.Size([380, 4]) tensor([123, 332, 153,  99], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 4.587976455688477
bi 1 loss 4.969387531280518
bi 2 loss 4.29388427734375
bi 3 loss 5.213038444519043
Layer  4  loss:  5.004863739013672 0.0 12.400242805480957
logits torch.Size([380, 4, 1024]) labels torch.Size([380, 4]) 0 1020
Curr loss timestep torch.Size([380, 4]) tensor([134, 306, 135, 207], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 4.61719274520874
bi 1 loss 5.129139423370361
bi 2 loss 4.74178409576416
bi 3 loss 5.334787368774414
Layer  5  loss:  5.1245293617248535 0.0 11.021102905273438
logits torch.Size([380, 4, 1024]) labels torch.Size([380, 4]) 0 1021
Curr loss timestep torch.Size([380, 4]) tensor([130, 255, 109, 178], device='cuda:0') tensor(99, device='cuda:0')
bi 0 loss 5.010622024536133
bi 1 loss 5.133682727813721
bi 2 loss 4.723569869995117
bi 3 loss 5.454585075378418
Layer  6  loss:  5.180192470550537 0.0 10.635711669921875
logits torch.Size([380, 4, 1024]) labels torch.Size([380, 4]) 0 1021
Curr loss timestep torch.Size([380, 4]) tensor([202, 176, 142, 209], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 4.973734378814697
bi 1 loss 5.181379795074463
bi 2 loss 4.897241592407227
bi 3 loss 5.531145095825195
Epoch 0: :   3%|▎         | 15494/600000 [03:25<2:09:18, v_num=12, reduced_train_loss=0.560, global_step=15492.0, consumed_samples=6.2e+4, train_step_timing in s=0.362]Epoch 0: :   3%|▎         | 15494/600000 [03:25<2:09:18, v_num=12, reduced_train_loss=37.20, global_step=15493.0, consumed_samples=6.2e+4, train_step_timing in s=0.285]loss mask original None

First layer loss:  0.17648960649967194 torch.Size([635, 4]) 8.008505821228027 0.0
Max loss timestep torch.Size([635, 4]) tensor([601, 103, 531, 396], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.19999165832996368
speech mask sum tensor(401, device='cuda:0') loss mask sum tensor(401, device='cuda:0')
bi 1 loss 0.050674304366111755
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 2 loss 0.21758247911930084
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 3 loss 0.11219797283411026
speech mask sum tensor(266, device='cuda:0') loss mask sum tensor(266, device='cuda:0')
logits torch.Size([635, 4, 257024]) labels torch.Size([635, 4]) 0 257022
Layer  0  loss:  0.2342052459716797 0.0 15.268924713134766
logits torch.Size([635, 4, 1024]) labels torch.Size([635, 4]) 0 1023
Curr loss timestep torch.Size([635, 4]) tensor([600, 107, 575, 440], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.26967087388038635
bi 1 loss 0.02167755924165249
bi 2 loss 0.30452364683151245
bi 3 loss 0.1303107589483261
Layer  1  loss:  0.2608237564563751 0.0 18.023456573486328
logits torch.Size([635, 4, 1024]) labels torch.Size([635, 4]) 0 1023
Curr loss timestep torch.Size([635, 4]) tensor([344, 121, 531, 261], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.38378435373306274
bi 1 loss 0.04951705411076546
bi 2 loss 0.24380598962306976
bi 3 loss 0.18643741309642792
Layer  2  loss:  0.3165103495121002 0.0 12.45419692993164
logits torch.Size([635, 4, 1024]) labels torch.Size([635, 4]) 0 1022
Curr loss timestep torch.Size([635, 4]) tensor([344,  95, 328, 395], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.3899763226509094
bi 1 loss 0.048041243106126785
bi 2 loss 0.34668904542922974
bi 3 loss 0.2507545053958893
Layer  3  loss:  0.25837334990501404 0.0 14.010868072509766
logits torch.Size([635, 4, 1024]) labels torch.Size([635, 4]) 0 1022
Curr loss timestep torch.Size([635, 4]) tensor([345,  66, 327, 396], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.29875418543815613
bi 1 loss 0.05103229358792305
bi 2 loss 0.2917866110801697
bi 3 loss 0.21351858973503113
Layer  4  loss:  0.2651810050010681 0.0 12.358195304870605
logits torch.Size([635, 4, 1024]) labels torch.Size([635, 4]) 0 1021
Curr loss timestep torch.Size([635, 4]) tensor([344,  94, 328, 396], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.34776294231414795
bi 1 loss 0.03751813992857933
bi 2 loss 0.28782564401626587
bi 3 loss 0.18430551886558533
Layer  5  loss:  0.2673410475254059 0.0 12.751450538635254
logits torch.Size([635, 4, 1024]) labels torch.Size([635, 4]) 0 1023
Curr loss timestep torch.Size([635, 4]) tensor([344,  59, 328, 440], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.3445300757884979
bi 1 loss 0.0479142963886261
bi 2 loss 0.2988274395465851
bi 3 loss 0.17511224746704102
Layer  6  loss:  0.292121559381485 0.0 12.535833358764648
logits torch.Size([635, 4, 1024]) labels torch.Size([635, 4]) 0 1019
Curr loss timestep torch.Size([635, 4]) tensor([344, 115, 326, 395], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.38404521346092224
bi 1 loss 0.04247694090008736
bi 2 loss 0.28729814291000366
bi 3 loss 0.2563360035419464
Epoch 0: :   3%|▎         | 15495/600000 [03:26<2:09:35, v_num=12, reduced_train_loss=37.20, global_step=15493.0, consumed_samples=6.2e+4, train_step_timing in s=0.285]Epoch 0: :   3%|▎         | 15495/600000 [03:26<2:09:35, v_num=12, reduced_train_loss=2.070, global_step=15494.0, consumed_samples=6.2e+4, train_step_timing in s=0.435]loss mask original None

First layer loss:  0.06394943594932556 torch.Size([605, 4]) 5.0113654136657715 0.0
Max loss timestep torch.Size([605, 4]) tensor([ 65, 291, 277, 591], device='cuda:0') tensor(591, device='cuda:0')
bi 0 loss 0.020213982090353966
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 1 loss 0.061122868210077286
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 2 loss 0.04624268785119057
speech mask sum tensor(251, device='cuda:0') loss mask sum tensor(251, device='cuda:0')
bi 3 loss 0.0834757536649704
speech mask sum tensor(470, device='cuda:0') loss mask sum tensor(470, device='cuda:0')
logits torch.Size([605, 4, 257024]) labels torch.Size([605, 4]) 0 257023
Layer  0  loss:  0.08944395929574966 0.0 6.8664350509643555
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1023
Curr loss timestep torch.Size([605, 4]) tensor([ 60, 309, 262, 591], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.019283050671219826
bi 1 loss 0.11129821091890335
bi 2 loss 0.0371377132833004
bi 3 loss 0.12118025124073029
Layer  1  loss:  0.08178374916315079 0.0 5.708234786987305
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1022
Curr loss timestep torch.Size([605, 4]) tensor([103, 309, 280, 444], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.03865987807512283
bi 1 loss 0.07058209180831909
bi 2 loss 0.05885246396064758
bi 3 loss 0.10789813101291656
Layer  2  loss:  0.08924535661935806 0.0 11.345466613769531
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1022
Curr loss timestep torch.Size([605, 4]) tensor([ 68, 309, 258, 594], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.025585729628801346
bi 1 loss 0.11509411036968231
bi 2 loss 0.04185456782579422
bi 3 loss 0.11518654972314835
Layer  3  loss:  0.09741243720054626 0.0 7.75935697555542
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1021
Curr loss timestep torch.Size([605, 4]) tensor([104, 309, 280, 444], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.024355707690119743
bi 1 loss 0.12820270657539368
bi 2 loss 0.06082962453365326
bi 3 loss 0.11714809387922287
Layer  4  loss:  0.08701077103614807 0.0 7.259379863739014
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1022
Curr loss timestep torch.Size([605, 4]) tensor([ 60, 309, 216, 508], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.01967192441225052
bi 1 loss 0.09039970487356186
bi 2 loss 0.04228588566184044
bi 3 loss 0.12277721613645554
Layer  5  loss:  0.10030336678028107 0.0 7.559528827667236
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1023
Curr loss timestep torch.Size([605, 4]) tensor([100, 309, 120, 557], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.021095197647809982
bi 1 loss 0.1098250150680542
bi 2 loss 0.04329317435622215
bi 3 loss 0.1421339362859726
Layer  6  loss:  0.09448006004095078 0.0 7.014763832092285
logits torch.Size([605, 4, 1024]) labels torch.Size([605, 4]) 0 1023
Curr loss timestep torch.Size([605, 4]) tensor([ 69, 309, 113, 508], device='cuda:0') tensor(508, device='cuda:0')
bi 0 loss 0.01567879319190979
bi 1 loss 0.10613061487674713
bi 2 loss 0.051558028906583786
bi 3 loss 0.1277090609073639
Epoch 0: :   3%|▎         | 15496/600000 [03:26<2:09:52, v_num=12, reduced_train_loss=2.070, global_step=15494.0, consumed_samples=6.2e+4, train_step_timing in s=0.435]Epoch 0: :   3%|▎         | 15496/600000 [03:26<2:09:52, v_num=12, reduced_train_loss=0.704, global_step=15495.0, consumed_samples=6.2e+4, train_step_timing in s=0.422]loss mask original None

First layer loss:  0.11233360320329666 torch.Size([622, 4]) 11.666478157043457 0.0
Max loss timestep torch.Size([622, 4]) tensor([ 55, 449, 171, 530], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.033946696668863297
speech mask sum tensor(62, device='cuda:0') loss mask sum tensor(62, device='cuda:0')
bi 1 loss 0.07604433596134186
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 2 loss 0.060103949159383774
speech mask sum tensor(276, device='cuda:0') loss mask sum tensor(276, device='cuda:0')
bi 3 loss 0.17474772036075592
speech mask sum tensor(435, device='cuda:0') loss mask sum tensor(435, device='cuda:0')
logits torch.Size([622, 4, 257024]) labels torch.Size([622, 4]) 0 257022
Layer  0  loss:  0.13944125175476074 0.0 11.22030258178711
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([ 77, 438, 320, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.07336989045143127
bi 1 loss 0.12088664621114731
bi 2 loss 0.10497592389583588
bi 3 loss 0.17998196184635162
Layer  1  loss:  0.14143586158752441 0.0 11.21212100982666
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([ 60, 374, 351, 530], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.13789841532707214
bi 1 loss 0.1058536097407341
bi 2 loss 0.07755313068628311
bi 3 loss 0.20022276043891907
Layer  2  loss:  0.1561376452445984 0.0 8.086202621459961
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([ 69, 438, 351, 529], device='cuda:0') tensor(529, device='cuda:0')
bi 0 loss 0.06787820160388947
bi 1 loss 0.13101454079151154
bi 2 loss 0.07633619755506516
bi 3 loss 0.2318824827671051
Layer  3  loss:  0.1808239221572876 0.0 11.735763549804688
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1021
Curr loss timestep torch.Size([622, 4]) tensor([ 72, 374, 162, 529], device='cuda:0') tensor(529, device='cuda:0')
bi 0 loss 0.026905037462711334
bi 1 loss 0.14412181079387665
bi 2 loss 0.07957503199577332
bi 3 loss 0.28531134128570557
Layer  4  loss:  0.14445160329341888 0.0 12.038268089294434
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([ 73, 416, 288, 529], device='cuda:0') tensor(529, device='cuda:0')
bi 0 loss 0.021292390301823616
bi 1 loss 0.13252244889736176
bi 2 loss 0.05682133138179779
bi 3 loss 0.2235560566186905
Layer  5  loss:  0.17570850253105164 0.0 10.459238052368164
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([ 49, 438, 332, 529], device='cuda:0') tensor(529, device='cuda:0')
bi 0 loss 0.03920247405767441
bi 1 loss 0.14115896821022034
bi 2 loss 0.08388158679008484
bi 3 loss 0.27066221833229065
Layer  6  loss:  0.1718570590019226 0.0 13.279407501220703
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1019
Curr loss timestep torch.Size([622, 4]) tensor([ 80, 377, 294, 530], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.021348169073462486
bi 1 loss 0.127173513174057
bi 2 loss 0.05497295781970024
bi 3 loss 0.2897602617740631
Epoch 0: :   3%|▎         | 15497/600000 [03:27<2:10:09, v_num=12, reduced_train_loss=0.704, global_step=15495.0, consumed_samples=6.2e+4, train_step_timing in s=0.422]Epoch 0: :   3%|▎         | 15497/600000 [03:27<2:10:09, v_num=12, reduced_train_loss=1.220, global_step=15496.0, consumed_samples=6.2e+4, train_step_timing in s=0.422]loss mask original None

First layer loss:  3.5787105560302734 torch.Size([452, 4]) 9.636012077331543 0.0
Max loss timestep torch.Size([452, 4]) tensor([168, 206, 356,  45], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 3.6774916648864746
speech mask sum tensor(120, device='cuda:0') loss mask sum tensor(120, device='cuda:0')
bi 1 loss 3.4077913761138916
speech mask sum tensor(269, device='cuda:0') loss mask sum tensor(269, device='cuda:0')
bi 2 loss 3.664642095565796
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 3 loss 3.7062857151031494
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
logits torch.Size([452, 4, 257024]) labels torch.Size([452, 4]) 0 257022
Layer  0  loss:  4.134100914001465 0.0 9.872461318969727
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1023
Curr loss timestep torch.Size([452, 4]) tensor([179, 317, 253,  63], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 4.302402973175049
bi 1 loss 3.847973108291626
bi 2 loss 4.388382434844971
bi 3 loss 4.025864601135254
Layer  1  loss:  4.366326808929443 0.0 10.25383186340332
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1023
Curr loss timestep torch.Size([452, 4]) tensor([241, 136, 301,  45], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 4.412459373474121
bi 1 loss 3.9642584323883057
bi 2 loss 4.744006633758545
bi 3 loss 4.406637191772461
Layer  2  loss:  4.593045711517334 0.0 10.2370023727417
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1022
Curr loss timestep torch.Size([452, 4]) tensor([214, 368, 277,  98], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.81906795501709
bi 1 loss 4.259622097015381
bi 2 loss 4.799637317657471
bi 3 loss 4.6858062744140625
Layer  3  loss:  4.755245208740234 0.0 10.253172874450684
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1019
Curr loss timestep torch.Size([452, 4]) tensor([230, 351, 371,  79], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.701035499572754
bi 1 loss 4.453938961029053
bi 2 loss 5.125665187835693
bi 3 loss 4.6509246826171875
Layer  4  loss:  4.847962379455566 0.0 9.566703796386719
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1022
Curr loss timestep torch.Size([452, 4]) tensor([217, 310, 388,  71], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 4.809330463409424
bi 1 loss 4.524073123931885
bi 2 loss 5.19419527053833
bi 3 loss 4.85949182510376
Layer  5  loss:  4.939486503601074 0.0 9.843140602111816
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1022
Curr loss timestep torch.Size([452, 4]) tensor([206, 149, 388,  33], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.936940670013428
bi 1 loss 4.573379993438721
bi 2 loss 5.291983604431152
bi 3 loss 5.010188102722168
Layer  6  loss:  4.903954029083252 0.0 10.314857482910156
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1019
Curr loss timestep torch.Size([452, 4]) tensor([266, 240, 314,  93], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.809512138366699
bi 1 loss 4.51533317565918
bi 2 loss 5.308160305023193
bi 3 loss 5.013514995574951
Epoch 0: :   3%|▎         | 15498/600000 [03:27<2:10:21, v_num=12, reduced_train_loss=1.220, global_step=15496.0, consumed_samples=6.2e+4, train_step_timing in s=0.422]Epoch 0: :   3%|▎         | 15498/600000 [03:27<2:10:21, v_num=12, reduced_train_loss=36.10, global_step=15497.0, consumed_samples=6.2e+4, train_step_timing in s=0.312]loss mask original None

First layer loss:  0.034245382994413376 torch.Size([423, 4]) 1.1338896751403809 0.0
Max loss timestep torch.Size([423, 4]) tensor([291, 362, 198, 108], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.03386057913303375
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
bi 1 loss 0.034768253564834595
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 2 loss 0.039791278541088104
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 3 loss 0.028891270980238914
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
logits torch.Size([423, 4, 257024]) labels torch.Size([423, 4]) 0 257023
Layer  0  loss:  0.038747210055589676 0.0 2.9899935722351074
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([371, 283, 213, 165], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 0.03442764654755592
bi 1 loss 0.03730977699160576
bi 2 loss 0.05406034365296364
bi 3 loss 0.032966598868370056
Layer  1  loss:  0.031016958877444267 0.0 0.6908881664276123
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([341, 277, 284, 108], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.03316200524568558
bi 1 loss 0.030367465689778328
bi 2 loss 0.032140061259269714
bi 3 loss 0.028834359720349312
Layer  2  loss:  0.0344824343919754 0.0 0.9383342862129211
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([337, 277, 209, 189], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.04258016496896744
bi 1 loss 0.040038712322711945
bi 2 loss 0.026150096207857132
bi 3 loss 0.022316034883260727
Layer  3  loss:  0.04741588234901428 0.0 3.6498618125915527
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([317, 347, 274, 165], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.055326059460639954
bi 1 loss 0.06081259623169899
bi 2 loss 0.03220617398619652
bi 3 loss 0.02689780294895172
Layer  4  loss:  0.03818134963512421 0.0 2.8066673278808594
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([343, 361, 221, 156], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.044612593948841095
bi 1 loss 0.04785221442580223
bi 2 loss 0.01813899539411068
bi 3 loss 0.030431218445301056
Layer  5  loss:  0.03734559193253517 0.0 2.5042996406555176
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([304, 285, 255,  92], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.04503307119011879
bi 1 loss 0.04539657384157181
bi 2 loss 0.02498638816177845
bi 3 loss 0.02451292797923088
Layer  6  loss:  0.03600749745965004 0.0 1.7535940408706665
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([382, 290, 268, 197], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.03898201137781143
bi 1 loss 0.048056744039058685
bi 2 loss 0.025207698345184326
bi 3 loss 0.01970524527132511
Epoch 0: :   3%|▎         | 15499/600000 [03:27<2:10:34, v_num=12, reduced_train_loss=36.10, global_step=15497.0, consumed_samples=6.2e+4, train_step_timing in s=0.312]Epoch 0: :   3%|▎         | 15499/600000 [03:27<2:10:34, v_num=12, reduced_train_loss=0.297, global_step=15498.0, consumed_samples=6.2e+4, train_step_timing in s=0.310]loss mask original None

First layer loss:  0.09007951617240906 torch.Size([547, 4]) 9.212282180786133 0.0
Max loss timestep torch.Size([547, 4]) tensor([305,  96, 177, 505], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.10939723253250122
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
bi 1 loss 0.028836535289883614
speech mask sum tensor(114, device='cuda:0') loss mask sum tensor(114, device='cuda:0')
bi 2 loss 0.023859448730945587
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 3 loss 0.12217820435762405
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
logits torch.Size([547, 4, 257024]) labels torch.Size([547, 4]) 0 257022
Layer  0  loss:  0.09616601467132568 0.0 8.030948638916016
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([305,  92, 258, 505], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.07666613161563873
bi 1 loss 0.02007637359201908
bi 2 loss 0.041548892855644226
bi 3 loss 0.16122311353683472
Layer  1  loss:  0.11699620634317398 0.0 6.155575752258301
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([305,  88, 271, 499], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.11897163838148117
bi 1 loss 0.023633137345314026
bi 2 loss 0.05255317687988281
bi 3 loss 0.17355461418628693
Layer  2  loss:  0.09382881224155426 0.0 3.797025680541992
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([324,  89, 264, 345], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.10212288796901703
bi 1 loss 0.031072985380887985
bi 2 loss 0.0361650213599205
bi 3 loss 0.1321248710155487
Layer  3  loss:  0.10053125768899918 0.0 7.167971134185791
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1019
Curr loss timestep torch.Size([547, 4]) tensor([324, 123, 270, 348], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.11874346435070038
bi 1 loss 0.02286374382674694
bi 2 loss 0.04034186899662018
bi 3 loss 0.13627329468727112
Layer  4  loss:  0.1057363823056221 0.0 6.294154644012451
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([312,  97, 270, 347], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.13710972666740417
bi 1 loss 0.017085131257772446
bi 2 loss 0.04119301214814186
bi 3 loss 0.1356738954782486
Layer  5  loss:  0.09956260025501251 0.0 5.317741870880127
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([324, 156, 157, 380], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.10664134472608566
bi 1 loss 0.026821278035640717
bi 2 loss 0.05638721585273743
bi 3 loss 0.13583433628082275
Layer  6  loss:  0.07820843905210495 0.0 3.138958692550659
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([361,  84, 270, 505], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.0613008551299572
bi 1 loss 0.019530070945620537
bi 2 loss 0.02758646570146084
bi 3 loss 0.13367342948913574
Epoch 0: :   3%|▎         | 15500/600000 [03:28<2:10:49, v_num=12, reduced_train_loss=0.297, global_step=15498.0, consumed_samples=6.2e+4, train_step_timing in s=0.310]Epoch 0: :   3%|▎         | 15500/600000 [03:28<2:10:49, v_num=12, reduced_train_loss=0.781, global_step=15499.0, consumed_samples=6.2e+4, train_step_timing in s=0.375]loss mask original None

First layer loss:  0.01791488006711006 torch.Size([375, 4]) 0.18492451310157776 0.0
Max loss timestep torch.Size([375, 4]) tensor([259,  82, 262, 101], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 0.017072537913918495
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 1 loss 0.013029651716351509
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 2 loss 0.023954542353749275
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 3 loss 0.014449377544224262
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
logits torch.Size([375, 4, 257024]) labels torch.Size([375, 4]) 0 257022
Layer  0  loss:  0.013232839293777943 0.0 0.11437112092971802
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([261,  97, 356, 131], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 0.012545611709356308
bi 1 loss 0.013660209253430367
bi 2 loss 0.013678065501153469
bi 3 loss 0.012710843235254288
Layer  1  loss:  0.013793304562568665 0.0 0.21561886370182037
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([249,  69, 354, 161], device='cuda:0') tensor(354, device='cuda:0')
bi 0 loss 0.013732477091252804
bi 1 loss 0.013162258081138134
bi 2 loss 0.01539776660501957
bi 3 loss 0.012133440934121609
Layer  2  loss:  0.013057047501206398 0.0 0.19878756999969482
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([201, 114, 339, 162], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.009119654074311256
bi 1 loss 0.010051246732473373
bi 2 loss 0.016134673729538918
bi 3 loss 0.014372910372912884
Layer  3  loss:  0.012670318596065044 0.0 0.2489631026983261
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1021
Curr loss timestep torch.Size([375, 4]) tensor([250, 127, 350, 154], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.012958314269781113
bi 1 loss 0.012351423501968384
bi 2 loss 0.013923161663115025
bi 3 loss 0.010964062996208668
Layer  4  loss:  0.013108590617775917 0.0 0.1714838743209839
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1021
Curr loss timestep torch.Size([375, 4]) tensor([212,  59, 291, 201], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 0.010757310315966606
bi 1 loss 0.011360610835254192
bi 2 loss 0.015311685390770435
bi 3 loss 0.01332945842295885
Layer  5  loss:  0.015087132342159748 0.0 0.40761786699295044
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([256,  87, 347, 185], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.012519733048975468
bi 1 loss 0.01230686530470848
bi 2 loss 0.0186990424990654
bi 3 loss 0.014414745382964611
Layer  6  loss:  0.013580919243395329 0.0 0.20643560588359833
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([258, 126, 286, 209], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.011906703002750874
bi 1 loss 0.012519161216914654
bi 2 loss 0.01522168330848217
bi 3 loss 0.013465712778270245
Epoch 0: :   3%|▎         | 15501/600000 [03:28<2:11:01, v_num=12, reduced_train_loss=0.781, global_step=15499.0, consumed_samples=6.2e+4, train_step_timing in s=0.375]Epoch 0: :   3%|▎         | 15501/600000 [03:28<2:11:01, v_num=12, reduced_train_loss=0.112, global_step=15500.0, consumed_samples=6.2e+4, train_step_timing in s=0.289]loss mask original None

First layer loss:  0.05881431698799133 torch.Size([487, 4]) 11.427790641784668 0.0
Max loss timestep torch.Size([487, 4]) tensor([ 82, 206, 110, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.03217152878642082
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 1 loss 0.01805580034852028
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 2 loss 0.02564661204814911
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 3 loss 0.1088617816567421
speech mask sum tensor(419, device='cuda:0') loss mask sum tensor(419, device='cuda:0')
logits torch.Size([487, 4, 257024]) labels torch.Size([487, 4]) 0 257022
Layer  0  loss:  0.053180545568466187 0.0 6.816300392150879
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([102,  56, 117, 398], device='cuda:0') tensor(398, device='cuda:0')
bi 0 loss 0.021204296499490738
bi 1 loss 0.02148456685245037
bi 2 loss 0.02711232751607895
bi 3 loss 0.09605657309293747
Layer  1  loss:  0.062345169484615326 0.0 14.159710884094238
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([156,  72, 335, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.022304721176624298
bi 1 loss 0.025668147951364517
bi 2 loss 0.03561395779252052
bi 3 loss 0.11088401824235916
Layer  2  loss:  0.057846713811159134 0.0 7.3194146156311035
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1022
Curr loss timestep torch.Size([487, 4]) tensor([103, 171, 127, 351], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.01471809670329094
bi 1 loss 0.02619830332696438
bi 2 loss 0.02951243706047535
bi 3 loss 0.10583590716123581
Layer  3  loss:  0.054341331124305725 0.0 9.576598167419434
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1020
Curr loss timestep torch.Size([487, 4]) tensor([156, 189, 336, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.023809991776943207
bi 1 loss 0.022932494059205055
bi 2 loss 0.034457262605428696
bi 3 loss 0.09280607849359512
Layer  4  loss:  0.04498911276459694 0.0 6.045796871185303
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1020
Curr loss timestep torch.Size([487, 4]) tensor([103, 135, 335, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.026129478588700294
bi 1 loss 0.027695313096046448
bi 2 loss 0.032326459884643555
bi 3 loss 0.06790491938591003
Layer  5  loss:  0.058353353291749954 0.0 7.980006694793701
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1023
Curr loss timestep torch.Size([487, 4]) tensor([106,  69, 335, 351], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.01824861578643322
bi 1 loss 0.024014990776777267
bi 2 loss 0.03497965261340141
bi 3 loss 0.10366801917552948
Layer  6  loss:  0.05174084007740021 0.0 12.01725959777832
logits torch.Size([487, 4, 1024]) labels torch.Size([487, 4]) 0 1019
Curr loss timestep torch.Size([487, 4]) tensor([115,  68, 103, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.014253620058298111
bi 1 loss 0.025937752798199654
bi 2 loss 0.035788312554359436
bi 3 loss 0.08728118240833282
Epoch 0: :   3%|▎         | 15502/600000 [03:28<2:11:16, v_num=12, reduced_train_loss=0.112, global_step=15500.0, consumed_samples=6.2e+4, train_step_timing in s=0.289]Epoch 0: :   3%|▎         | 15502/600000 [03:28<2:11:16, v_num=12, reduced_train_loss=0.442, global_step=15501.0, consumed_samples=6.2e+4, train_step_timing in s=0.378]loss mask original None

First layer loss:  0.12804944813251495 torch.Size([554, 4]) 9.875188827514648 0.0
Max loss timestep torch.Size([554, 4]) tensor([343, 324, 439, 182], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.0690816193819046
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 1 loss 0.35973265767097473
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 2 loss 0.14758019149303436
speech mask sum tensor(440, device='cuda:0') loss mask sum tensor(440, device='cuda:0')
bi 3 loss 0.028198935091495514
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
logits torch.Size([554, 4, 257024]) labels torch.Size([554, 4]) 0 257022
Layer  0  loss:  0.15449225902557373 0.0 14.699986457824707
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([343, 324, 440, 147], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.07447484135627747
bi 1 loss 0.43333369493484497
bi 2 loss 0.18236379325389862
bi 3 loss 0.040292467921972275
Layer  1  loss:  0.15644621849060059 0.0 14.494217872619629
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([344, 325, 439, 150], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.07008665800094604
bi 1 loss 0.41780906915664673
bi 2 loss 0.1934901624917984
bi 3 loss 0.04166274890303612
Layer  2  loss:  0.1755291223526001 0.0 13.975638389587402
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([344, 323, 440,  72], device='cuda:0') tensor(440, device='cuda:0')
bi 0 loss 0.11857043951749802
bi 1 loss 0.40192243456840515
bi 2 loss 0.19948428869247437
bi 3 loss 0.06297510117292404
Layer  3  loss:  0.15078316628932953 0.0 12.630416870117188
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([344, 325, 439,  90], device='cuda:0') tensor(439, device='cuda:0')
bi 0 loss 0.09620729088783264
bi 1 loss 0.31829676032066345
bi 2 loss 0.18482868373394012
bi 3 loss 0.046782735735177994
Layer  4  loss:  0.16758830845355988 0.0 14.301029205322266
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([343, 324, 439, 119], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.10404178500175476
bi 1 loss 0.4178968071937561
bi 2 loss 0.1919889599084854
bi 3 loss 0.05013716593384743
Layer  5  loss:  0.1723770648241043 0.0 13.000518798828125
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([344, 325, 439, 160], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.09975896030664444
bi 1 loss 0.3677522540092468
bi 2 loss 0.22306792438030243
bi 3 loss 0.03834331035614014
Layer  6  loss:  0.1703941822052002 0.0 16.35957145690918
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([343, 325, 440,  82], device='cuda:0') tensor(440, device='cuda:0')
bi 0 loss 0.10774257779121399
bi 1 loss 0.34973251819610596
bi 2 loss 0.21865816414356232
bi 3 loss 0.03443998470902443
Epoch 0: :   3%|▎         | 15503/600000 [03:29<2:11:31, v_num=12, reduced_train_loss=0.442, global_step=15501.0, consumed_samples=6.2e+4, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15503/600000 [03:29<2:11:31, v_num=12, reduced_train_loss=1.280, global_step=15502.0, consumed_samples=6.2e+4, train_step_timing in s=0.377]loss mask original None

First layer loss:  0.11731884628534317 torch.Size([638, 4]) 8.771993637084961 0.0
Max loss timestep torch.Size([638, 4]) tensor([ 93, 618, 184, 328], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.03034215234220028
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 1 loss 0.16023285686969757
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
bi 2 loss 0.13285955786705017
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 3 loss 0.08643179386854172
speech mask sum tensor(297, device='cuda:0') loss mask sum tensor(297, device='cuda:0')
logits torch.Size([638, 4, 257024]) labels torch.Size([638, 4]) 0 257022
Layer  0  loss:  0.12041082233190536 0.0 8.497681617736816
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([ 83, 436, 164, 339], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.032624393701553345
bi 1 loss 0.17746973037719727
bi 2 loss 0.12147390097379684
bi 3 loss 0.0748417004942894
Layer  1  loss:  0.1160900816321373 0.0 6.675166606903076
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([ 98, 435, 283, 327], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.03288542851805687
bi 1 loss 0.16323882341384888
bi 2 loss 0.07912196964025497
bi 3 loss 0.10642219334840775
Layer  2  loss:  0.1312318742275238 0.0 8.388802528381348
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([ 64, 613, 283, 377], device='cuda:0') tensor(613, device='cuda:0')
bi 0 loss 0.036310795694589615
bi 1 loss 0.20089589059352875
bi 2 loss 0.12273464351892471
bi 3 loss 0.07429303973913193
Layer  3  loss:  0.13090422749519348 0.0 7.164691925048828
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([ 56, 437, 283, 228], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.045415110886096954
bi 1 loss 0.18495963513851166
bi 2 loss 0.13303452730178833
bi 3 loss 0.08840550482273102
Layer  4  loss:  0.13880743086338043 0.0 7.873855113983154
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([113, 436, 283, 365], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.05148620158433914
bi 1 loss 0.18010622262954712
bi 2 loss 0.16308782994747162
bi 3 loss 0.10574162006378174
Layer  5  loss:  0.15116362273693085 0.0 12.837890625
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([ 95, 436, 282, 376], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.029483042657375336
bi 1 loss 0.20352089405059814
bi 2 loss 0.22277477383613586
bi 3 loss 0.09184514731168747
Layer  6  loss:  0.14488336443901062 0.0 12.282485008239746
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([ 79, 436, 283, 206], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.05315175652503967
bi 1 loss 0.22038835287094116
bi 2 loss 0.128824383020401
bi 3 loss 0.08079352229833603
Epoch 0: :   3%|▎         | 15504/600000 [03:29<2:11:48, v_num=12, reduced_train_loss=1.280, global_step=15502.0, consumed_samples=6.2e+4, train_step_timing in s=0.377]Epoch 0: :   3%|▎         | 15504/600000 [03:29<2:11:48, v_num=12, reduced_train_loss=1.050, global_step=15503.0, consumed_samples=6.2e+4, train_step_timing in s=0.438]loss mask original None

First layer loss:  0.06257770210504532 torch.Size([442, 4]) 3.0486583709716797 0.0
Max loss timestep torch.Size([442, 4]) tensor([281, 334, 365, 206], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.08881348371505737
speech mask sum tensor(242, device='cuda:0') loss mask sum tensor(242, device='cuda:0')
bi 1 loss 0.08072071522474289
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 2 loss 0.04697166755795479
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 3 loss 0.03064301423728466
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
logits torch.Size([442, 4, 257024]) labels torch.Size([442, 4]) 0 257023
Layer  0  loss:  0.05044340342283249 0.0 3.1420679092407227
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1023
Curr loss timestep torch.Size([442, 4]) tensor([307, 331, 325, 149], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 0.045654021203517914
bi 1 loss 0.06029199808835983
bi 2 loss 0.035145338624715805
bi 3 loss 0.06557242572307587
Layer  1  loss:  0.06608543545007706 0.0 7.535209655761719
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1023
Curr loss timestep torch.Size([442, 4]) tensor([333, 335, 331, 142], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.07927526533603668
bi 1 loss 0.10301686823368073
bi 2 loss 0.04447973892092705
bi 3 loss 0.03327794745564461
Layer  2  loss:  0.059969451278448105 0.0 5.729564666748047
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1023
Curr loss timestep torch.Size([442, 4]) tensor([294, 330, 243,  70], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.06065493822097778
bi 1 loss 0.09751597791910172
bi 2 loss 0.04536759853363037
bi 3 loss 0.030660632997751236
Layer  3  loss:  0.0752432718873024 0.0 3.1315765380859375
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1021
Curr loss timestep torch.Size([442, 4]) tensor([333, 335, 329, 244], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.1081557422876358
bi 1 loss 0.08976268768310547
bi 2 loss 0.05602535977959633
bi 3 loss 0.04565009847283363
Layer  4  loss:  0.06780433654785156 0.0 3.3087921142578125
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1022
Curr loss timestep torch.Size([442, 4]) tensor([333, 384, 329,  70], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.1033693328499794
bi 1 loss 0.06646176427602768
bi 2 loss 0.06668365001678467
bi 3 loss 0.02947564795613289
Layer  5  loss:  0.08475688099861145 0.0 4.067340850830078
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1019
Curr loss timestep torch.Size([442, 4]) tensor([332, 335, 344,  80], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.10091360658407211
bi 1 loss 0.08436448872089386
bi 2 loss 0.10769764333963394
bi 3 loss 0.032334767282009125
Layer  6  loss:  0.06587626785039902 0.0 7.78400993347168
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1023
Curr loss timestep torch.Size([442, 4]) tensor([324, 335, 397, 209], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.08792360126972198
bi 1 loss 0.0968032255768776
bi 2 loss 0.04338680952787399
bi 3 loss 0.0319875106215477
Epoch 0: :   3%|▎         | 15505/600000 [03:30<2:12:01, v_num=12, reduced_train_loss=1.050, global_step=15503.0, consumed_samples=6.2e+4, train_step_timing in s=0.438]Epoch 0: :   3%|▎         | 15505/600000 [03:30<2:12:01, v_num=12, reduced_train_loss=0.533, global_step=15504.0, consumed_samples=6.2e+4, train_step_timing in s=0.321]loss mask original None

First layer loss:  3.671952486038208 torch.Size([584, 4]) 11.140247344970703 0.0
Max loss timestep torch.Size([584, 4]) tensor([396, 541, 151, 110], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 2.9478278160095215
speech mask sum tensor(126, device='cuda:0') loss mask sum tensor(126, device='cuda:0')
bi 1 loss 3.384921073913574
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 2 loss 3.903020143508911
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
bi 3 loss 3.959754228591919
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
logits torch.Size([584, 4, 257024]) labels torch.Size([584, 4]) 0 257022
Layer  0  loss:  4.230163097381592 0.0 11.762274742126465
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([415, 362, 170, 307], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 3.588987112045288
bi 1 loss 4.112367153167725
bi 2 loss 4.589887619018555
bi 3 loss 4.160007476806641
Layer  1  loss:  4.514274597167969 0.0 11.062566757202148
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([419, 465, 214, 161], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 4.0336761474609375
bi 1 loss 4.311985492706299
bi 2 loss 4.743006229400635
bi 3 loss 4.621201038360596
Layer  2  loss:  4.8169660568237305 0.0 10.796401977539062
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([384, 541, 331, 143], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 4.4406418800354
bi 1 loss 4.824709892272949
bi 2 loss 5.038980960845947
bi 3 loss 4.689314365386963
Layer  3  loss:  5.006166458129883 0.0 11.062865257263184
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([386, 411, 334, 197], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 4.5343828201293945
bi 1 loss 4.960458755493164
bi 2 loss 5.229498386383057
bi 3 loss 4.968047142028809
Layer  4  loss:  5.1128363609313965 0.0 9.870392799377441
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([358, 314, 129, 272], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 4.832852840423584
bi 1 loss 5.047181129455566
bi 2 loss 5.314671993255615
bi 3 loss 5.039104461669922
Layer  5  loss:  5.194396018981934 0.0 10.404995918273926
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([362, 571, 331, 317], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 4.660088062286377
bi 1 loss 5.146453857421875
bi 2 loss 5.401008605957031
bi 3 loss 5.206130504608154
Layer  6  loss:  5.267045021057129 0.0 12.355867385864258
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([333, 485, 213, 199], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 4.811363697052002
bi 1 loss 5.16192626953125
bi 2 loss 5.46449613571167
bi 3 loss 5.310972690582275
Epoch 0: :   3%|▎         | 15506/600000 [03:30<2:12:16, v_num=12, reduced_train_loss=0.533, global_step=15504.0, consumed_samples=6.2e+4, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15506/600000 [03:30<2:12:16, v_num=12, reduced_train_loss=37.80, global_step=15505.0, consumed_samples=6.2e+4, train_step_timing in s=0.370]loss mask original None

First layer loss:  0.1691243052482605 torch.Size([621, 4]) 13.331350326538086 0.0
Max loss timestep torch.Size([621, 4]) tensor([284, 483, 154, 297], device='cuda:0') tensor(483, device='cuda:0')
bi 0 loss 0.17756713926792145
speech mask sum tensor(411, device='cuda:0') loss mask sum tensor(411, device='cuda:0')
bi 1 loss 0.29854339361190796
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
bi 2 loss 0.04718288779258728
speech mask sum tensor(129, device='cuda:0') loss mask sum tensor(129, device='cuda:0')
bi 3 loss 0.05312911421060562
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
logits torch.Size([621, 4, 257024]) labels torch.Size([621, 4]) 0 257022
Layer  0  loss:  0.20418104529380798 0.0 13.558808326721191
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([285, 482, 145, 278], device='cuda:0') tensor(482, device='cuda:0')
bi 0 loss 0.14975488185882568
bi 1 loss 0.40611883997917175
bi 2 loss 0.04961460456252098
bi 3 loss 0.07944583147764206
Layer  1  loss:  0.1940508931875229 0.0 15.00895881652832
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([285, 483, 151, 278], device='cuda:0') tensor(483, device='cuda:0')
bi 0 loss 0.15082117915153503
bi 1 loss 0.38352248072624207
bi 2 loss 0.0563911534845829
bi 3 loss 0.0668923556804657
Layer  2  loss:  0.21233049035072327 0.0 16.780744552612305
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([285, 483, 221, 261], device='cuda:0') tensor(483, device='cuda:0')
bi 0 loss 0.22972632944583893
bi 1 loss 0.3515743315219879
bi 2 loss 0.03342573717236519
bi 3 loss 0.0941748395562172
Layer  3  loss:  0.21153311431407928 0.0 13.569002151489258
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([285, 483, 199, 278], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.21406783163547516
bi 1 loss 0.34112441539764404
bi 2 loss 0.05261014774441719
bi 3 loss 0.11281692981719971
Layer  4  loss:  0.2276875525712967 0.0 22.047008514404297
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([284, 483, 223, 261], device='cuda:0') tensor(483, device='cuda:0')
bi 0 loss 0.19140443205833435
bi 1 loss 0.4279325306415558
bi 2 loss 0.0656391903758049
bi 3 loss 0.0891023650765419
Layer  5  loss:  0.21117784082889557 0.0 14.342281341552734
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([285, 483, 196, 320], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.19196774065494537
bi 1 loss 0.39282286167144775
bi 2 loss 0.07071167230606079
bi 3 loss 0.06975119560956955
Layer  6  loss:  0.20307616889476776 0.0 14.73619556427002
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([284, 549, 156, 427], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.17391400039196014
bi 1 loss 0.39027345180511475
bi 2 loss 0.04329672455787659
bi 3 loss 0.07137145102024078
Epoch 0: :   3%|▎         | 15507/600000 [03:31<2:12:33, v_num=12, reduced_train_loss=37.80, global_step=15505.0, consumed_samples=6.2e+4, train_step_timing in s=0.370]Epoch 0: :   3%|▎         | 15507/600000 [03:31<2:12:33, v_num=12, reduced_train_loss=1.630, global_step=15506.0, consumed_samples=6.2e+4, train_step_timing in s=0.422]loss mask original None

First layer loss:  0.04446083679795265 torch.Size([537, 4]) 1.5569018125534058 0.0
Max loss timestep torch.Size([537, 4]) tensor([146, 228,  34, 343], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 0.02173885516822338
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
bi 1 loss 0.05403432250022888
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 2 loss 0.017109913751482964
speech mask sum tensor(51, device='cuda:0') loss mask sum tensor(51, device='cuda:0')
bi 3 loss 0.05474720895290375
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
logits torch.Size([537, 4, 257024]) labels torch.Size([537, 4]) 0 257022
Layer  0  loss:  0.04658966884016991 0.0 2.581418752670288
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([251, 278,  47, 381], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.03927042707800865
bi 1 loss 0.044827431440353394
bi 2 loss 0.013534012250602245
bi 3 loss 0.058369945734739304
Layer  1  loss:  0.04869818314909935 0.0 4.483885765075684
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1022
Curr loss timestep torch.Size([537, 4]) tensor([118, 172,  45, 368], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.028002053499221802
bi 1 loss 0.034386664628982544
bi 2 loss 0.02145814709365368
bi 3 loss 0.07885445654392242
Layer  2  loss:  0.0389164499938488 0.0 2.0876400470733643
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1022
Curr loss timestep torch.Size([537, 4]) tensor([187, 270,  37, 518], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.01718340814113617
bi 1 loss 0.04156740382313728
bi 2 loss 0.01479200180619955
bi 3 loss 0.054162874817848206
Layer  3  loss:  0.051954250782728195 0.0 5.308486461639404
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1022
Curr loss timestep torch.Size([537, 4]) tensor([124, 272,  52, 368], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.024617044255137444
bi 1 loss 0.05469302833080292
bi 2 loss 0.025310179218649864
bi 3 loss 0.07102181762456894
Layer  4  loss:  0.04278937354683876 0.0 1.3235876560211182
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([121, 259,  36, 461], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.0313364714384079
bi 1 loss 0.0480126291513443
bi 2 loss 0.007388516794890165
bi 3 loss 0.05134623125195503
Layer  5  loss:  0.05049251765012741 0.0 2.463047742843628
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([161, 180,  37, 367], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.03566768392920494
bi 1 loss 0.037236738950014114
bi 2 loss 0.013923226855695248
bi 3 loss 0.07769181579351425
Layer  6  loss:  0.04478953033685684 0.0 1.7736624479293823
logits torch.Size([537, 4, 1024]) labels torch.Size([537, 4]) 0 1023
Curr loss timestep torch.Size([537, 4]) tensor([110, 310,  37, 367], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.03426117077469826
bi 1 loss 0.034650128334760666
bi 2 loss 0.008658373728394508
bi 3 loss 0.06649865955114365
Epoch 0: :   3%|▎         | 15508/600000 [03:31<2:12:48, v_num=12, reduced_train_loss=1.630, global_step=15506.0, consumed_samples=6.2e+4, train_step_timing in s=0.422]Epoch 0: :   3%|▎         | 15508/600000 [03:31<2:12:48, v_num=12, reduced_train_loss=0.369, global_step=15507.0, consumed_samples=6.2e+4, train_step_timing in s=0.376]loss mask original None

First layer loss:  0.041774749755859375 torch.Size([475, 4]) 3.835209608078003 0.0
Max loss timestep torch.Size([475, 4]) tensor([ 86, 439, 351, 169], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.01341440249234438
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
bi 1 loss 0.04729541763663292
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
bi 2 loss 0.047113049775362015
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 3 loss 0.03905823081731796
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
logits torch.Size([475, 4, 257024]) labels torch.Size([475, 4]) 0 257022
Layer  0  loss:  0.06415779888629913 0.0 9.739378929138184
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1023
Curr loss timestep torch.Size([475, 4]) tensor([101, 400, 351,  95], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.035674624145030975
bi 1 loss 0.050233494490385056
bi 2 loss 0.10943351686000824
bi 3 loss 0.04020240530371666
Layer  1  loss:  0.055099017918109894 0.0 8.564180374145508
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1023
Curr loss timestep torch.Size([475, 4]) tensor([119, 426, 350, 167], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.027653485536575317
bi 1 loss 0.04986552894115448
bi 2 loss 0.08996178209781647
bi 3 loss 0.028698327019810677
Layer  2  loss:  0.05342932417988777 0.0 5.8796892166137695
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1022
Curr loss timestep torch.Size([475, 4]) tensor([127, 260, 350, 116], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.036843542009592056
bi 1 loss 0.046346742659807205
bi 2 loss 0.08315657824277878
bi 3 loss 0.03224993497133255
Layer  3  loss:  0.05423285812139511 0.0 8.541662216186523
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1020
Curr loss timestep torch.Size([475, 4]) tensor([106, 379, 350,  86], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.025393754243850708
bi 1 loss 0.03835573419928551
bi 2 loss 0.10115829855203629
bi 3 loss 0.03195321559906006
Layer  4  loss:  0.05731396749615669 0.0 9.000425338745117
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1022
Curr loss timestep torch.Size([475, 4]) tensor([105, 427, 351, 157], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.033820390701293945
bi 1 loss 0.04824955016374588
bi 2 loss 0.09513536840677261
bi 3 loss 0.031885720789432526
Layer  5  loss:  0.06976302713155746 0.0 12.468812942504883
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1023
Curr loss timestep torch.Size([475, 4]) tensor([104, 288, 350, 135], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.014543461613357067
bi 1 loss 0.054826460778713226
bi 2 loss 0.13988037407398224
bi 3 loss 0.025679506361484528
Layer  6  loss:  0.06233685463666916 0.0 7.690592288970947
logits torch.Size([475, 4, 1024]) labels torch.Size([475, 4]) 0 1022
Curr loss timestep torch.Size([475, 4]) tensor([ 93, 288, 350, 100], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.02524859644472599
bi 1 loss 0.04865015298128128
bi 2 loss 0.11594720184803009
bi 3 loss 0.030234934762120247
Epoch 0: :   3%|▎         | 15509/600000 [03:31<2:13:02, v_num=12, reduced_train_loss=0.369, global_step=15507.0, consumed_samples=6.2e+4, train_step_timing in s=0.376]Epoch 0: :   3%|▎         | 15509/600000 [03:31<2:13:02, v_num=12, reduced_train_loss=0.458, global_step=15508.0, consumed_samples=6.2e+4, train_step_timing in s=0.362]loss mask original None

First layer loss:  0.08071713894605637 torch.Size([598, 4]) 14.040241241455078 0.0
Max loss timestep torch.Size([598, 4]) tensor([318, 282, 535, 203], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.10845471173524857
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
bi 1 loss 0.05076448246836662
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 2 loss 0.10753825306892395
speech mask sum tensor(311, device='cuda:0') loss mask sum tensor(311, device='cuda:0')
bi 3 loss 0.052216872572898865
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
logits torch.Size([598, 4, 257024]) labels torch.Size([598, 4]) 0 257022
Layer  0  loss:  0.08069129288196564 0.0 6.0789899826049805
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([342, 217, 534,  95], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.06151129677891731
bi 1 loss 0.05815484747290611
bi 2 loss 0.14480488002300262
bi 3 loss 0.05625595524907112
Layer  1  loss:  0.07409685850143433 0.0 10.964981079101562
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1022
Curr loss timestep torch.Size([598, 4]) tensor([342, 285, 535, 129], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.06161121279001236
bi 1 loss 0.04962831735610962
bi 2 loss 0.1451961100101471
bi 3 loss 0.03751884773373604
Layer  2  loss:  0.0867985263466835 0.0 8.370826721191406
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([279, 358, 535,  87], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.09878439456224442
bi 1 loss 0.046286579221487045
bi 2 loss 0.16141925752162933
bi 3 loss 0.035971980541944504
Layer  3  loss:  0.09577129036188126 0.0 7.503021240234375
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([343, 223, 353,  67], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.08487976342439651
bi 1 loss 0.05966828763484955
bi 2 loss 0.19551703333854675
bi 3 loss 0.03925260528922081
Layer  4  loss:  0.08351291716098785 0.0 7.5749711990356445
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1022
Curr loss timestep torch.Size([598, 4]) tensor([187, 285, 535, 201], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.07729943096637726
bi 1 loss 0.06794343888759613
bi 2 loss 0.13604572415351868
bi 3 loss 0.05114680156111717
Layer  5  loss:  0.08891559392213821 0.0 7.14039945602417
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1021
Curr loss timestep torch.Size([598, 4]) tensor([131, 284, 535,  63], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.05445890501141548
bi 1 loss 0.06668989360332489
bi 2 loss 0.17669852077960968
bi 3 loss 0.05612682178616524
Layer  6  loss:  0.08678685128688812 0.0 5.784518241882324
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([345, 285, 535, 263], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.06935640424489975
bi 1 loss 0.07741948962211609
bi 2 loss 0.1471584290266037
bi 3 loss 0.05250120908021927
Epoch 0: :   3%|▎         | 15510/600000 [03:32<2:13:19, v_num=12, reduced_train_loss=0.458, global_step=15508.0, consumed_samples=6.2e+4, train_step_timing in s=0.362]Epoch 0: :   3%|▎         | 15510/600000 [03:32<2:13:19, v_num=12, reduced_train_loss=0.677, global_step=15509.0, consumed_samples=6.2e+4, train_step_timing in s=0.413]loss mask original None

First layer loss:  0.1019245833158493 torch.Size([638, 4]) 7.735734462738037 0.0
Max loss timestep torch.Size([638, 4]) tensor([546, 375, 108, 139], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.16073793172836304
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
bi 1 loss 0.04945353791117668
speech mask sum tensor(311, device='cuda:0') loss mask sum tensor(311, device='cuda:0')
bi 2 loss 0.08807064592838287
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
bi 3 loss 0.034695450216531754
speech mask sum tensor(168, device='cuda:0') loss mask sum tensor(168, device='cuda:0')
logits torch.Size([638, 4, 257024]) labels torch.Size([638, 4]) 0 257022
Layer  0  loss:  0.09400308132171631 0.0 10.133339881896973
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([603, 342,  67, 110], device='cuda:0') tensor(603, device='cuda:0')
bi 0 loss 0.14550597965717316
bi 1 loss 0.051584288477897644
bi 2 loss 0.0669575110077858
bi 3 loss 0.03782782703638077
Layer  1  loss:  0.0871482715010643 0.0 14.267071723937988
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([546, 378,  82, 218], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.14153046905994415
bi 1 loss 0.040753770619630814
bi 2 loss 0.04290163889527321
bi 3 loss 0.04051452502608299
Layer  2  loss:  0.10559434443712234 0.0 10.516192436218262
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([603, 145, 138, 191], device='cuda:0') tensor(603, device='cuda:0')
bi 0 loss 0.162755087018013
bi 1 loss 0.057298291474580765
bi 2 loss 0.06566151976585388
bi 3 loss 0.05164000019431114
Layer  3  loss:  0.09366509318351746 0.0 10.604413032531738
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([546, 366, 144, 222], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.14863725006580353
bi 1 loss 0.038162533193826675
bi 2 loss 0.06443014740943909
bi 3 loss 0.052864380180835724
Layer  4  loss:  0.10498396307229996 0.0 10.868599891662598
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([546, 271,  84, 160], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.1731126308441162
bi 1 loss 0.04318876191973686
bi 2 loss 0.0314963273704052
bi 3 loss 0.06454027444124222
Layer  5  loss:  0.08668610453605652 0.0 9.86947250366211
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([603, 279,  99, 144], device='cuda:0') tensor(603, device='cuda:0')
bi 0 loss 0.12660150229930878
bi 1 loss 0.05603713169693947
bi 2 loss 0.05959188938140869
bi 3 loss 0.042825501412153244
Layer  6  loss:  0.11181318759918213 0.0 14.26606559753418
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([603, 279,  71, 188], device='cuda:0') tensor(603, device='cuda:0')
bi 0 loss 0.17459607124328613
bi 1 loss 0.06906797736883163
bi 2 loss 0.05082700029015541
bi 3 loss 0.04408454895019531
Epoch 0: :   3%|▎         | 15511/600000 [03:32<2:13:36, v_num=12, reduced_train_loss=0.677, global_step=15509.0, consumed_samples=6.2e+4, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15511/600000 [03:32<2:13:36, v_num=12, reduced_train_loss=0.786, global_step=15510.0, consumed_samples=6.2e+4, train_step_timing in s=0.436]loss mask original None

First layer loss:  0.09033377468585968 torch.Size([590, 4]) 9.665628433227539 0.0
Max loss timestep torch.Size([590, 4]) tensor([319, 175, 407, 223], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.09341204911470413
speech mask sum tensor(243, device='cuda:0') loss mask sum tensor(243, device='cuda:0')
bi 1 loss 0.049524784088134766
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 2 loss 0.12378174811601639
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 3 loss 0.05178476497530937
speech mask sum tensor(257, device='cuda:0') loss mask sum tensor(257, device='cuda:0')
logits torch.Size([590, 4, 257024]) labels torch.Size([590, 4]) 0 257022
Layer  0  loss:  0.1359679251909256 0.0 9.736989974975586
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([342, 159, 407, 277], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.13615424931049347
bi 1 loss 0.05965472757816315
bi 2 loss 0.20712940394878387
bi 3 loss 0.05473589524626732
Layer  1  loss:  0.1326744258403778 0.0 16.313186645507812
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([373, 262, 407, 197], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.14182783663272858
bi 1 loss 0.05686907097697258
bi 2 loss 0.19441837072372437
bi 3 loss 0.05846787989139557
Layer  2  loss:  0.13172733783721924 0.0 8.43850326538086
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([373, 265, 407, 268], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.17105618119239807
bi 1 loss 0.06866445392370224
bi 2 loss 0.1733984649181366
bi 3 loss 0.05622752383351326
Layer  3  loss:  0.14156700670719147 0.0 15.736044883728027
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1021
Curr loss timestep torch.Size([590, 4]) tensor([400, 174, 407, 284], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.11010776460170746
bi 1 loss 0.06779035180807114
bi 2 loss 0.21390050649642944
bi 3 loss 0.08703240007162094
Layer  4  loss:  0.1347658783197403 0.0 8.076420783996582
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([342, 264, 407, 289], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.15799905359745026
bi 1 loss 0.02711918018758297
bi 2 loss 0.2053009271621704
bi 3 loss 0.048396434634923935
Layer  5  loss:  0.15891873836517334 0.0 12.781686782836914
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1018
Curr loss timestep torch.Size([590, 4]) tensor([370, 264, 407, 208], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.15359537303447723
bi 1 loss 0.06006618216633797
bi 2 loss 0.24843551218509674
bi 3 loss 0.0634109228849411
Layer  6  loss:  0.1331796944141388 0.0 13.782369613647461
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([373, 159, 527, 245], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.1081390380859375
bi 1 loss 0.042277440428733826
bi 2 loss 0.20957769453525543
bi 3 loss 0.07430503517389297
Epoch 0: :   3%|▎         | 15512/600000 [03:33<2:13:52, v_num=12, reduced_train_loss=0.786, global_step=15510.0, consumed_samples=6.2e+4, train_step_timing in s=0.436]Epoch 0: :   3%|▎         | 15512/600000 [03:33<2:13:52, v_num=12, reduced_train_loss=1.060, global_step=15511.0, consumed_samples=6.2e+4, train_step_timing in s=0.404]loss mask original None

First layer loss:  0.11934088170528412 torch.Size([709, 4]) 8.315974235534668 0.0
Max loss timestep torch.Size([709, 4]) tensor([316, 326, 304, 621], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.08158154785633087
speech mask sum tensor(159, device='cuda:0') loss mask sum tensor(159, device='cuda:0')
bi 1 loss 0.0968361422419548
speech mask sum tensor(227, device='cuda:0') loss mask sum tensor(227, device='cuda:0')
bi 2 loss 0.11524899303913116
speech mask sum tensor(440, device='cuda:0') loss mask sum tensor(440, device='cuda:0')
bi 3 loss 0.15023261308670044
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
logits torch.Size([709, 4, 257024]) labels torch.Size([709, 4]) 0 257023
Layer  0  loss:  0.1459653377532959 0.0 10.993694305419922
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([255, 225, 304, 671], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.07988446950912476
bi 1 loss 0.08387203514575958
bi 2 loss 0.19548651576042175
bi 3 loss 0.15269434452056885
Layer  1  loss:  0.1448153257369995 0.0 12.455957412719727
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([314, 294, 356, 582], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.06163749471306801
bi 1 loss 0.08776436746120453
bi 2 loss 0.16125276684761047
bi 3 loss 0.19013440608978271
Layer  2  loss:  0.169601708650589 0.0 15.538193702697754
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1022
Curr loss timestep torch.Size([709, 4]) tensor([314, 344, 357, 582], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.07279523462057114
bi 1 loss 0.0918370708823204
bi 2 loss 0.18981729447841644
bi 3 loss 0.22737668454647064
Layer  3  loss:  0.17875903844833374 0.0 16.449426651000977
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1020
Curr loss timestep torch.Size([709, 4]) tensor([316, 295, 356, 582], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.08086781203746796
bi 1 loss 0.10943936556577682
bi 2 loss 0.19856713712215424
bi 3 loss 0.23278945684432983
Layer  4  loss:  0.16697633266448975 0.0 15.83072280883789
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([316, 275, 305, 671], device='cuda:0') tensor(671, device='cuda:0')
bi 0 loss 0.13511915504932404
bi 1 loss 0.06722521781921387
bi 2 loss 0.1944822072982788
bi 3 loss 0.20431171357631683
Layer  5  loss:  0.16262106597423553 0.0 18.039587020874023
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([244, 374, 356, 671], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.06860267370939255
bi 1 loss 0.09572166949510574
bi 2 loss 0.21278613805770874
bi 3 loss 0.1819092184305191
Layer  6  loss:  0.16826185584068298 0.0 11.284707069396973
logits torch.Size([709, 4, 1024]) labels torch.Size([709, 4]) 0 1023
Curr loss timestep torch.Size([709, 4]) tensor([316, 290, 356, 674], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.09704631567001343
bi 1 loss 0.09431713074445724
bi 2 loss 0.17936453223228455
bi 3 loss 0.22382059693336487
Epoch 0: :   3%|▎         | 15513/600000 [03:33<2:14:11, v_num=12, reduced_train_loss=1.060, global_step=15511.0, consumed_samples=6.2e+4, train_step_timing in s=0.404]Epoch 0: :   3%|▎         | 15513/600000 [03:33<2:14:11, v_num=12, reduced_train_loss=1.260, global_step=15512.0, consumed_samples=62052.0, train_step_timing in s=0.482]loss mask original None

First layer loss:  0.07488633692264557 torch.Size([347, 4]) 8.169011116027832 0.0
Max loss timestep torch.Size([347, 4]) tensor([ 64,  98, 289, 261], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.06132325530052185
speech mask sum tensor(90, device='cuda:0') loss mask sum tensor(90, device='cuda:0')
bi 1 loss 0.03284590691328049
speech mask sum tensor(237, device='cuda:0') loss mask sum tensor(237, device='cuda:0')
bi 2 loss 0.10610407590866089
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 3 loss 0.11401776224374771
speech mask sum tensor(76, device='cuda:0') loss mask sum tensor(76, device='cuda:0')
logits torch.Size([347, 4, 257024]) labels torch.Size([347, 4]) 0 257023
Layer  0  loss:  0.057828519493341446 0.0 9.47255802154541
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1023
Curr loss timestep torch.Size([347, 4]) tensor([ 81, 304, 288, 259], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.029878022149205208
bi 1 loss 0.02803949825465679
bi 2 loss 0.08943231403827667
bi 3 loss 0.07445675134658813
Layer  1  loss:  0.07512128353118896 0.0 8.602449417114258
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1022
Curr loss timestep torch.Size([347, 4]) tensor([ 66, 273, 289, 261], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.03481757268309593
bi 1 loss 0.03660058602690697
bi 2 loss 0.10764409601688385
bi 3 loss 0.13042709231376648
Layer  2  loss:  0.07130492478609085 0.0 10.637925148010254
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1022
Curr loss timestep torch.Size([347, 4]) tensor([ 70, 230, 288, 260], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.03351845592260361
bi 1 loss 0.03758063539862633
bi 2 loss 0.1126060038805008
bi 3 loss 0.07829511910676956
Layer  3  loss:  0.07342733442783356 0.0 9.474743843078613
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1021
Curr loss timestep torch.Size([347, 4]) tensor([ 54, 273, 288, 260], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.017860323190689087
bi 1 loss 0.030795127153396606
bi 2 loss 0.1261599361896515
bi 3 loss 0.08969304710626602
Layer  4  loss:  0.06891798973083496 0.0 8.962932586669922
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1022
Curr loss timestep torch.Size([347, 4]) tensor([ 95, 121, 289, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.039572857320308685
bi 1 loss 0.022397005930542946
bi 2 loss 0.09557761996984482
bi 3 loss 0.1564844697713852
Layer  5  loss:  0.07684765011072159 0.0 8.912034034729004
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1021
Curr loss timestep torch.Size([347, 4]) tensor([ 65, 280, 277, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.02965136617422104
bi 1 loss 0.03977850452065468
bi 2 loss 0.10444609075784683
bi 3 loss 0.1528300940990448
Layer  6  loss:  0.09238412976264954 0.0 11.107291221618652
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1022
Curr loss timestep torch.Size([347, 4]) tensor([ 99, 233, 288, 260], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.0512959286570549
bi 1 loss 0.04567086696624756
bi 2 loss 0.1271423101425171
bi 3 loss 0.16643135249614716
Epoch 0: :   3%|▎         | 15514/600000 [03:34<2:14:23, v_num=12, reduced_train_loss=1.260, global_step=15512.0, consumed_samples=62052.0, train_step_timing in s=0.482]Epoch 0: :   3%|▎         | 15514/600000 [03:34<2:14:23, v_num=12, reduced_train_loss=0.591, global_step=15513.0, consumed_samples=62056.0, train_step_timing in s=0.277]loss mask original None

First layer loss:  0.07757996022701263 torch.Size([499, 4]) 6.2109055519104 0.0
Max loss timestep torch.Size([499, 4]) tensor([181, 275, 275, 458], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.03246074914932251
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 1 loss 0.09553711861371994
speech mask sum tensor(249, device='cuda:0') loss mask sum tensor(249, device='cuda:0')
bi 2 loss 0.08067993819713593
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 3 loss 0.0840621367096901
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
logits torch.Size([499, 4, 257024]) labels torch.Size([499, 4]) 0 257023
Layer  0  loss:  0.08094429224729538 0.0 5.419099807739258
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([194, 275, 354, 381], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.02936459146440029
bi 1 loss 0.0763743445277214
bi 2 loss 0.0976206362247467
bi 3 loss 0.10134078562259674
Layer  1  loss:  0.08449508249759674 0.0 5.640249252319336
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([ 84, 275, 354, 461], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.06930635124444962
bi 1 loss 0.0706183910369873
bi 2 loss 0.06625313311815262
bi 3 loss 0.11809978634119034
Layer  2  loss:  0.10747012495994568 0.0 8.567137718200684
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([104, 275, 274, 381], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.03463783487677574
bi 1 loss 0.1034836396574974
bi 2 loss 0.13590386509895325
bi 3 loss 0.13060462474822998
Layer  3  loss:  0.10267724096775055 0.0 9.254923820495605
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([202, 275, 323, 456], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.033255208283662796
bi 1 loss 0.11766502261161804
bi 2 loss 0.09236646443605423
bi 3 loss 0.13461102545261383
Layer  4  loss:  0.102410688996315 0.0 11.624598503112793
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([177, 275, 380, 459], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.052958518266677856
bi 1 loss 0.14221982657909393
bi 2 loss 0.07881839573383331
bi 3 loss 0.11079847067594528
Layer  5  loss:  0.08790316432714462 0.0 8.194003105163574
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([205, 275, 274, 381], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.023529469966888428
bi 1 loss 0.10060279071331024
bi 2 loss 0.06853561103343964
bi 3 loss 0.12555000185966492
Layer  6  loss:  0.08038811385631561 0.0 6.403806686401367
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([172, 275, 275, 464], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.03094901517033577
bi 1 loss 0.08100536465644836
bi 2 loss 0.08949755132198334
bi 3 loss 0.10037992149591446
Epoch 0: :   3%|▎         | 15515/600000 [03:34<2:14:37, v_num=12, reduced_train_loss=0.591, global_step=15513.0, consumed_samples=62056.0, train_step_timing in s=0.277]Epoch 0: :   3%|▎         | 15515/600000 [03:34<2:14:37, v_num=12, reduced_train_loss=0.724, global_step=15514.0, consumed_samples=62060.0, train_step_timing in s=0.356]loss mask original None

First layer loss:  0.09810971468687057 torch.Size([502, 4]) 9.846317291259766 0.0
Max loss timestep torch.Size([502, 4]) tensor([309, 368, 364, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.07021236419677734
speech mask sum tensor(297, device='cuda:0') loss mask sum tensor(297, device='cuda:0')
bi 1 loss 0.0866694375872612
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 2 loss 0.12121659517288208
speech mask sum tensor(414, device='cuda:0') loss mask sum tensor(414, device='cuda:0')
bi 3 loss 0.10093666613101959
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
logits torch.Size([502, 4, 257024]) labels torch.Size([502, 4]) 0 257023
Layer  0  loss:  0.11077875643968582 0.0 8.417827606201172
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([441, 365, 364, 360], device='cuda:0') tensor(441, device='cuda:0')
bi 0 loss 0.1219743937253952
bi 1 loss 0.14216363430023193
bi 2 loss 0.09927184134721756
bi 3 loss 0.09669791162014008
Layer  1  loss:  0.10669667273759842 0.0 8.013280868530273
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([309, 364, 345, 351], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.10025879740715027
bi 1 loss 0.10736449807882309
bi 2 loss 0.12633028626441956
bi 3 loss 0.08735169470310211
Layer  2  loss:  0.1282607913017273 0.0 9.131860733032227
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1022
Curr loss timestep torch.Size([502, 4]) tensor([441, 348, 364, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.1360202580690384
bi 1 loss 0.09676793217658997
bi 2 loss 0.13133402168750763
bi 3 loss 0.1358865648508072
Layer  3  loss:  0.146236389875412 0.0 14.4032621383667
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([441, 348, 345, 351], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.12668775022029877
bi 1 loss 0.12311383336782455
bi 2 loss 0.1559046506881714
bi 3 loss 0.16533976793289185
Layer  4  loss:  0.11596939712762833 0.0 7.440053939819336
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1022
Curr loss timestep torch.Size([502, 4]) tensor([309, 335, 353, 360], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.10983821004629135
bi 1 loss 0.0830853283405304
bi 2 loss 0.146126851439476
bi 3 loss 0.10280600190162659
Layer  5  loss:  0.12843911349773407 0.0 10.531920433044434
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([441, 304, 345, 360], device='cuda:0') tensor(441, device='cuda:0')
bi 0 loss 0.142984539270401
bi 1 loss 0.12045647948980331
bi 2 loss 0.14699944853782654
bi 3 loss 0.0965387150645256
Layer  6  loss:  0.13391388952732086 0.0 10.771025657653809
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([441, 339, 345, 360], device='cuda:0') tensor(441, device='cuda:0')
bi 0 loss 0.16758541762828827
bi 1 loss 0.12785100936889648
bi 2 loss 0.15318149328231812
bi 3 loss 0.08267272263765335
Epoch 0: :   3%|▎         | 15516/600000 [03:34<2:14:51, v_num=12, reduced_train_loss=0.724, global_step=15514.0, consumed_samples=62060.0, train_step_timing in s=0.356]Epoch 0: :   3%|▎         | 15516/600000 [03:34<2:14:51, v_num=12, reduced_train_loss=0.968, global_step=15515.0, consumed_samples=62064.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  3.230792284011841 torch.Size([572, 4]) 12.516576766967773 0.0
Max loss timestep torch.Size([572, 4]) tensor([478, 316, 130,  72], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 2.6208908557891846
speech mask sum tensor(420, device='cuda:0') loss mask sum tensor(420, device='cuda:0')
bi 1 loss 3.513084650039673
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 2 loss 3.677719831466675
speech mask sum tensor(122, device='cuda:0') loss mask sum tensor(122, device='cuda:0')
bi 3 loss 3.920917272567749
speech mask sum tensor(185, device='cuda:0') loss mask sum tensor(185, device='cuda:0')
logits torch.Size([572, 4, 257024]) labels torch.Size([572, 4]) 0 257023
Layer  0  loss:  3.7031359672546387 0.0 10.762227058410645
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([480, 170,  83, 116], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 2.8851184844970703
bi 1 loss 4.023116111755371
bi 2 loss 4.503664016723633
bi 3 loss 4.579178333282471
Layer  1  loss:  4.282320499420166 0.0 9.835416793823242
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([438, 345,  79,  80], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 4.065885543823242
bi 1 loss 4.174323081970215
bi 2 loss 4.659233570098877
bi 3 loss 4.678071975708008
Layer  2  loss:  4.578157424926758 0.0 9.92044734954834
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([223, 264, 113, 216], device='cuda:0') tensor(207, device='cuda:0')
bi 0 loss 4.428318500518799
bi 1 loss 4.427643775939941
bi 2 loss 5.132726669311523
bi 3 loss 4.765776634216309
Layer  3  loss:  4.608497619628906 0.0 10.543449401855469
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1021
Curr loss timestep torch.Size([572, 4]) tensor([195, 398, 140, 114], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.401838779449463
bi 1 loss 4.577535152435303
bi 2 loss 4.908507823944092
bi 3 loss 4.923674583435059
Layer  4  loss:  4.855790615081787 0.0 9.627226829528809
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([517, 388, 132,  77], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 4.778126239776611
bi 1 loss 4.808602333068848
bi 2 loss 4.851444244384766
bi 3 loss 5.101805210113525
Layer  5  loss:  4.91259241104126 0.0 9.386427879333496
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([519, 348, 121,  87], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 4.790245532989502
bi 1 loss 4.882751941680908
bi 2 loss 5.166521072387695
bi 3 loss 5.065157890319824
Layer  6  loss:  4.859395503997803 0.0 10.210775375366211
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([522, 188,  84, 130], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 4.795373439788818
bi 1 loss 4.767942428588867
bi 2 loss 5.013543128967285
bi 3 loss 5.032608509063721
Epoch 0: :   3%|▎         | 15517/600000 [03:35<2:15:16, v_num=12, reduced_train_loss=0.968, global_step=15515.0, consumed_samples=62064.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15517/600000 [03:35<2:15:16, v_num=12, reduced_train_loss=35.00, global_step=15516.0, consumed_samples=62068.0, train_step_timing in s=0.643]loss mask original None

First layer loss:  0.06873467564582825 torch.Size([347, 4]) 9.94738483428955 0.0
Max loss timestep torch.Size([347, 4]) tensor([174, 315, 131, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.022941121831536293
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 1 loss 0.15188443660736084
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 2 loss 0.037866219878196716
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 3 loss 0.09039264917373657
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
logits torch.Size([347, 4, 257024]) labels torch.Size([347, 4]) 0 257019
Layer  0  loss:  0.0526953749358654 0.0 7.779548645019531
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1023
Curr loss timestep torch.Size([347, 4]) tensor([101, 315, 128, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.03209530562162399
bi 1 loss 0.06946573406457901
bi 2 loss 0.027958929538726807
bi 3 loss 0.07987135648727417
Layer  1  loss:  0.06818878650665283 0.0 15.250029563903809
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1023
Curr loss timestep torch.Size([347, 4]) tensor([225, 315, 128, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.03214462101459503
bi 1 loss 0.09855546057224274
bi 2 loss 0.0304942075163126
bi 3 loss 0.11224883049726486
Layer  2  loss:  0.044927049428224564 0.0 8.162388801574707
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1022
Curr loss timestep torch.Size([347, 4]) tensor([129, 315, 100, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.02310067228972912
bi 1 loss 0.06119421869516373
bi 2 loss 0.019904853776097298
bi 3 loss 0.07396166771650314
Layer  3  loss:  0.07649552077054977 0.0 11.57611083984375
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1021
Curr loss timestep torch.Size([347, 4]) tensor([181, 316,  99, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.02446538209915161
bi 1 loss 0.15815860033035278
bi 2 loss 0.01977526769042015
bi 3 loss 0.11968040466308594
Layer  4  loss:  0.07893901318311691 0.0 9.05293083190918
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1018
Curr loss timestep torch.Size([347, 4]) tensor([248, 315,  85, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.036445505917072296
bi 1 loss 0.14614072442054749
bi 2 loss 0.03062346763908863
bi 3 loss 0.11495460569858551
Layer  5  loss:  0.06315076351165771 0.0 7.056004524230957
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1022
Curr loss timestep torch.Size([347, 4]) tensor([106, 315,  99, 293], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.03251306340098381
bi 1 loss 0.12462436407804489
bi 2 loss 0.016597401350736618
bi 3 loss 0.08777046948671341
Layer  6  loss:  0.06940697878599167 0.0 10.600552558898926
logits torch.Size([347, 4, 1024]) labels torch.Size([347, 4]) 0 1022
Curr loss timestep torch.Size([347, 4]) tensor([244, 315,  95, 293], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.02524510771036148
bi 1 loss 0.1557989865541458
bi 2 loss 0.026361366733908653
bi 3 loss 0.09365161508321762
Epoch 0: :   3%|▎         | 15518/600000 [03:35<2:15:27, v_num=12, reduced_train_loss=35.00, global_step=15516.0, consumed_samples=62068.0, train_step_timing in s=0.643]Epoch 0: :   3%|▎         | 15518/600000 [03:35<2:15:27, v_num=12, reduced_train_loss=0.523, global_step=15517.0, consumed_samples=62072.0, train_step_timing in s=0.274]loss mask original None

First layer loss:  0.04861745238304138 torch.Size([346, 4]) 7.1999287605285645 0.0
Max loss timestep torch.Size([346, 4]) tensor([268, 310, 164, 300], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.08383651077747345
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 1 loss 0.053328584879636765
speech mask sum tensor(242, device='cuda:0') loss mask sum tensor(242, device='cuda:0')
bi 2 loss 0.028613578528165817
speech mask sum tensor(125, device='cuda:0') loss mask sum tensor(125, device='cuda:0')
bi 3 loss 0.02337869442999363
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
logits torch.Size([346, 4, 257024]) labels torch.Size([346, 4]) 0 257023
Layer  0  loss:  0.036774858832359314 0.0 3.9709322452545166
logits torch.Size([346, 4, 1024]) labels torch.Size([346, 4]) 0 1023
Curr loss timestep torch.Size([346, 4]) tensor([268, 310, 210, 137], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.06090312823653221
bi 1 loss 0.03220804035663605
bi 2 loss 0.021693089976906776
bi 3 loss 0.02879803255200386
Layer  1  loss:  0.03833502158522606 0.0 5.566430568695068
logits torch.Size([346, 4, 1024]) labels torch.Size([346, 4]) 0 1023
Curr loss timestep torch.Size([346, 4]) tensor([268, 310, 180, 293], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.05940201133489609
bi 1 loss 0.04165752977132797
bi 2 loss 0.023741668090224266
bi 3 loss 0.024171773344278336
Layer  2  loss:  0.02967073768377304 0.0 1.569309949874878
logits torch.Size([346, 4, 1024]) labels torch.Size([346, 4]) 0 1022
Curr loss timestep torch.Size([346, 4]) tensor([268, 141, 230, 158], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.03723333403468132
bi 1 loss 0.02803160808980465
bi 2 loss 0.021202217787504196
bi 3 loss 0.02951418235898018
Layer  3  loss:  0.03875521942973137 0.0 8.300626754760742
logits torch.Size([346, 4, 1024]) labels torch.Size([346, 4]) 0 1022
Curr loss timestep torch.Size([346, 4]) tensor([268, 310, 208, 267], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.07328622043132782
bi 1 loss 0.03214525803923607
bi 2 loss 0.023603150621056557
bi 3 loss 0.02378242462873459
Layer  4  loss:  0.036051731556653976 0.0 4.134803771972656
logits torch.Size([346, 4, 1024]) labels torch.Size([346, 4]) 0 1021
Curr loss timestep torch.Size([346, 4]) tensor([268, 306, 259, 303], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.05316406115889549
bi 1 loss 0.035401634871959686
bi 2 loss 0.024008428677916527
bi 3 loss 0.02832145430147648
Layer  5  loss:  0.028981897979974747 0.0 1.9899688959121704
logits torch.Size([346, 4, 1024]) labels torch.Size([346, 4]) 0 1017
Curr loss timestep torch.Size([346, 4]) tensor([268, 310, 212, 223], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.031008105725049973
bi 1 loss 0.03626624122262001
bi 2 loss 0.02292589098215103
bi 3 loss 0.022624546661973
Layer  6  loss:  0.03119988925755024 0.0 1.9210550785064697
logits torch.Size([346, 4, 1024]) labels torch.Size([346, 4]) 0 1023
Curr loss timestep torch.Size([346, 4]) tensor([268, 310, 228, 286], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.03577332943677902
bi 1 loss 0.030985118821263313
bi 2 loss 0.03162869065999985
bi 3 loss 0.027115754783153534
Epoch 0: :   3%|▎         | 15519/600000 [03:36<2:15:39, v_num=12, reduced_train_loss=0.523, global_step=15517.0, consumed_samples=62072.0, train_step_timing in s=0.274]Epoch 0: :   3%|▎         | 15519/600000 [03:36<2:15:39, v_num=12, reduced_train_loss=0.288, global_step=15518.0, consumed_samples=62076.0, train_step_timing in s=0.280]loss mask original None

First layer loss:  0.19209939241409302 torch.Size([655, 4]) 9.70583438873291 0.0
Max loss timestep torch.Size([655, 4]) tensor([194, 264, 191, 533], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.025680450722575188
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
bi 1 loss 0.07646577060222626
speech mask sum tensor(233, device='cuda:0') loss mask sum tensor(233, device='cuda:0')
bi 2 loss 0.05682417005300522
speech mask sum tensor(47, device='cuda:0') loss mask sum tensor(47, device='cuda:0')
bi 3 loss 0.3304249942302704
speech mask sum tensor(497, device='cuda:0') loss mask sum tensor(497, device='cuda:0')
logits torch.Size([655, 4, 257024]) labels torch.Size([655, 4]) 0 257023
Layer  0  loss:  0.22227267920970917 0.0 15.106364250183105
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([165, 342, 208, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.04901966452598572
bi 1 loss 0.13474734127521515
bi 2 loss 0.043697670102119446
bi 3 loss 0.35444435477256775
Layer  1  loss:  0.2551291584968567 0.0 13.68355941772461
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1023
Curr loss timestep torch.Size([655, 4]) tensor([ 90, 291, 191, 577], device='cuda:0') tensor(577, device='cuda:0')
bi 0 loss 0.04274417459964752
bi 1 loss 0.13628539443016052
bi 2 loss 0.04410811513662338
bi 3 loss 0.4218224883079529
Layer  2  loss:  0.2120957374572754 0.0 9.353699684143066
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([160, 273, 185, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.032013777643442154
bi 1 loss 0.128180131316185
bi 2 loss 0.03038390725851059
bi 3 loss 0.3457984924316406
Layer  3  loss:  0.2770463526248932 0.0 15.157353401184082
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1020
Curr loss timestep torch.Size([655, 4]) tensor([ 82, 342, 193, 577], device='cuda:0') tensor(577, device='cuda:0')
bi 0 loss 0.0638076663017273
bi 1 loss 0.15124419331550598
bi 2 loss 0.06788872927427292
bi 3 loss 0.4471915364265442
Layer  4  loss:  0.2619886100292206 0.0 14.856383323669434
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([221, 342, 197, 304], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.049147624522447586
bi 1 loss 0.14150410890579224
bi 2 loss 0.034724198281764984
bi 3 loss 0.4311826527118683
Layer  5  loss:  0.27702298760414124 0.0 13.764777183532715
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1022
Curr loss timestep torch.Size([655, 4]) tensor([113, 342, 194, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.07152014970779419
bi 1 loss 0.13259556889533997
bi 2 loss 0.05352649465203285
bi 3 loss 0.4539405107498169
Layer  6  loss:  0.25759002566337585 0.0 15.83652114868164
logits torch.Size([655, 4, 1024]) labels torch.Size([655, 4]) 0 1019
Curr loss timestep torch.Size([655, 4]) tensor([ 85, 342, 193, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.048722993582487106
bi 1 loss 0.12594865262508392
bi 2 loss 0.013002662919461727
bi 3 loss 0.4319496750831604
Epoch 0: :   3%|▎         | 15520/600000 [03:36<2:15:56, v_num=12, reduced_train_loss=0.288, global_step=15518.0, consumed_samples=62076.0, train_step_timing in s=0.280]Epoch 0: :   3%|▎         | 15520/600000 [03:36<2:15:56, v_num=12, reduced_train_loss=1.960, global_step=15519.0, consumed_samples=62080.0, train_step_timing in s=0.450]loss mask original None

First layer loss:  0.20357370376586914 torch.Size([726, 4]) 9.383852005004883 0.0
Max loss timestep torch.Size([726, 4]) tensor([303, 681, 323, 308], device='cuda:0') tensor(681, device='cuda:0')
bi 0 loss 0.1003355085849762
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 1 loss 0.23275761306285858
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 2 loss 0.31371626257896423
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
bi 3 loss 0.21006618440151215
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
logits torch.Size([726, 4, 257024]) labels torch.Size([726, 4]) 0 257023
Layer  0  loss:  0.24109727144241333 0.0 15.23442554473877
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1023
Curr loss timestep torch.Size([726, 4]) tensor([374, 562, 394, 309], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.14588753879070282
bi 1 loss 0.3221158981323242
bi 2 loss 0.2830733060836792
bi 3 loss 0.20924977958202362
Layer  1  loss:  0.2468498796224594 0.0 11.623013496398926
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1022
Curr loss timestep torch.Size([726, 4]) tensor([371, 639, 395, 518], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.16097170114517212
bi 1 loss 0.3121053874492645
bi 2 loss 0.2722156047821045
bi 3 loss 0.23008370399475098
Layer  2  loss:  0.25758126378059387 0.0 14.148004531860352
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1023
Curr loss timestep torch.Size([726, 4]) tensor([371, 562, 348, 311], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.11730363219976425
bi 1 loss 0.2965807318687439
bi 2 loss 0.3370908498764038
bi 3 loss 0.2886446714401245
Layer  3  loss:  0.27369844913482666 0.0 14.338788032531738
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1022
Curr loss timestep torch.Size([726, 4]) tensor([371, 319, 394, 309], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.12041071802377701
bi 1 loss 0.370929092168808
bi 2 loss 0.3524805009365082
bi 3 loss 0.2534492313861847
Layer  4  loss:  0.2714758515357971 0.0 11.608987808227539
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1022
Curr loss timestep torch.Size([726, 4]) tensor([371, 685, 394, 308], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.12909424304962158
bi 1 loss 0.36015594005584717
bi 2 loss 0.317926287651062
bi 3 loss 0.2625768482685089
Layer  5  loss:  0.29957640171051025 0.0 13.03549575805664
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1023
Curr loss timestep torch.Size([726, 4]) tensor([374, 563, 394, 309], device='cuda:0') tensor(563, device='cuda:0')
bi 0 loss 0.11840563267469406
bi 1 loss 0.3721259534358978
bi 2 loss 0.41535472869873047
bi 3 loss 0.3126498758792877
Layer  6  loss:  0.2789362072944641 0.0 13.9874849319458
logits torch.Size([726, 4, 1024]) labels torch.Size([726, 4]) 0 1023
Curr loss timestep torch.Size([726, 4]) tensor([371, 639, 394, 309], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.13327829539775848
bi 1 loss 0.37758079171180725
bi 2 loss 0.31136101484298706
bi 3 loss 0.2662478983402252
Epoch 0: :   3%|▎         | 15521/600000 [03:37<2:16:16, v_num=12, reduced_train_loss=1.960, global_step=15519.0, consumed_samples=62080.0, train_step_timing in s=0.450]Epoch 0: :   3%|▎         | 15521/600000 [03:37<2:16:16, v_num=12, reduced_train_loss=2.070, global_step=15520.0, consumed_samples=62084.0, train_step_timing in s=0.497]loss mask original None

First layer loss:  0.08883686363697052 torch.Size([455, 4]) 9.26181697845459 0.0
Max loss timestep torch.Size([455, 4]) tensor([ 74, 384, 343,  98], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.0742577612400055
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 1 loss 0.0784168466925621
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
bi 2 loss 0.11150303483009338
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
bi 3 loss 0.012221225537359715
speech mask sum tensor(28, device='cuda:0') loss mask sum tensor(28, device='cuda:0')
logits torch.Size([455, 4, 257024]) labels torch.Size([455, 4]) 0 257022
Layer  0  loss:  0.07248064875602722 0.0 5.188838005065918
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1023
Curr loss timestep torch.Size([455, 4]) tensor([112, 382, 180,  97], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 0.04275716096162796
bi 1 loss 0.058238685131073
bi 2 loss 0.10167024284601212
bi 3 loss 0.01710650511085987
Layer  1  loss:  0.08749663084745407 0.0 7.675196170806885
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([ 65, 384, 419,  90], device='cuda:0') tensor(419, device='cuda:0')
bi 0 loss 0.04591323062777519
bi 1 loss 0.08515560626983643
bi 2 loss 0.10796476900577545
bi 3 loss 0.005100203212350607
Layer  2  loss:  0.10460008680820465 0.0 13.714497566223145
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([112, 384, 343,  95], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.09243086725473404
bi 1 loss 0.09995222091674805
bi 2 loss 0.12139381468296051
bi 3 loss 0.00992104597389698
Layer  3  loss:  0.08965688198804855 0.0 10.877776145935059
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([ 67, 384, 343,  90], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.047067463397979736
bi 1 loss 0.08672637492418289
bi 2 loss 0.10866278409957886
bi 3 loss 0.03511681407690048
Layer  4  loss:  0.09711635857820511 0.0 10.600630760192871
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([ 90, 384, 432,  88], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.05208442732691765
bi 1 loss 0.08739858865737915
bi 2 loss 0.1272820681333542
bi 3 loss 0.013590892776846886
Layer  5  loss:  0.10516396909952164 0.0 9.813048362731934
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([106, 383, 343,  86], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.06574635207653046
bi 1 loss 0.11314669996500015
bi 2 loss 0.11381258070468903
bi 3 loss 0.011926078237593174
Layer  6  loss:  0.11180747300386429 0.0 7.554246425628662
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1021
Curr loss timestep torch.Size([455, 4]) tensor([ 80, 383, 419,  98], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 0.05958930402994156
bi 1 loss 0.11415185779333115
bi 2 loss 0.13160784542560577
bi 3 loss 0.004336864687502384
Epoch 0: :   3%|▎         | 15522/600000 [03:37<2:16:29, v_num=12, reduced_train_loss=2.070, global_step=15520.0, consumed_samples=62084.0, train_step_timing in s=0.497]Epoch 0: :   3%|▎         | 15522/600000 [03:37<2:16:29, v_num=12, reduced_train_loss=0.757, global_step=15521.0, consumed_samples=62088.0, train_step_timing in s=0.325]loss mask original None

First layer loss:  0.22388821840286255 torch.Size([598, 4]) 10.583304405212402 0.0
Max loss timestep torch.Size([598, 4]) tensor([559, 368, 518, 441], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.23518963158130646
speech mask sum tensor(471, device='cuda:0') loss mask sum tensor(471, device='cuda:0')
bi 1 loss 0.13289684057235718
speech mask sum tensor(342, device='cuda:0') loss mask sum tensor(342, device='cuda:0')
bi 2 loss 0.22685319185256958
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
bi 3 loss 0.31700047850608826
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
logits torch.Size([598, 4, 257024]) labels torch.Size([598, 4]) 0 257022
Layer  0  loss:  0.2671535313129425 0.0 15.078315734863281
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([412, 396, 523, 412], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.29235315322875977
bi 1 loss 0.18285425007343292
bi 2 loss 0.2951522767543793
bi 3 loss 0.28469693660736084
Layer  1  loss:  0.2936585545539856 0.0 18.47283363342285
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([330, 333, 428, 332], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.36528757214546204
bi 1 loss 0.2004302442073822
bi 2 loss 0.29260584712028503
bi 3 loss 0.28837746381759644
Layer  2  loss:  0.3036978542804718 0.0 13.728494644165039
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([412, 368, 523, 441], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.35465008020401
bi 1 loss 0.19538362324237823
bi 2 loss 0.30790674686431885
bi 3 loss 0.34624093770980835
Layer  3  loss:  0.3046274781227112 0.0 14.508804321289062
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([412, 396, 365, 412], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.3010387420654297
bi 1 loss 0.2894724905490875
bi 2 loss 0.3281121253967285
bi 3 loss 0.29138246178627014
Layer  4  loss:  0.31381648778915405 0.0 18.261926651000977
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([413, 368, 523, 332], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.3809970021247864
bi 1 loss 0.2133294641971588
bi 2 loss 0.2991715669631958
bi 3 loss 0.3487328290939331
Layer  5  loss:  0.32598960399627686 0.0 19.281362533569336
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([412, 368, 365, 342], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.3722037971019745
bi 1 loss 0.24250946938991547
bi 2 loss 0.3442802131175995
bi 3 loss 0.3211119472980499
Layer  6  loss:  0.2871733605861664 0.0 18.159149169921875
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1022
Curr loss timestep torch.Size([598, 4]) tensor([412, 368, 523, 332], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.34270498156547546
bi 1 loss 0.198796808719635
bi 2 loss 0.2456560879945755
bi 3 loss 0.3722625970840454
Epoch 0: :   3%|▎         | 15523/600000 [03:37<2:16:45, v_num=12, reduced_train_loss=0.757, global_step=15521.0, consumed_samples=62088.0, train_step_timing in s=0.325]Epoch 0: :   3%|▎         | 15523/600000 [03:37<2:16:45, v_num=12, reduced_train_loss=2.320, global_step=15522.0, consumed_samples=62092.0, train_step_timing in s=0.410]loss mask original None

First layer loss:  0.06418872624635696 torch.Size([493, 4]) 6.501841068267822 0.0
Max loss timestep torch.Size([493, 4]) tensor([280, 372, 466, 310], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.02228282205760479
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 1 loss 0.05651573836803436
speech mask sum tensor(292, device='cuda:0') loss mask sum tensor(292, device='cuda:0')
bi 2 loss 0.13880272209644318
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 3 loss 0.07677064090967178
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
logits torch.Size([493, 4, 257024]) labels torch.Size([493, 4]) 0 257022
Layer  0  loss:  0.055706918239593506 0.0 4.352219104766846
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1023
Curr loss timestep torch.Size([493, 4]) tensor([199, 354, 419, 314], device='cuda:0') tensor(419, device='cuda:0')
bi 0 loss 0.029366999864578247
bi 1 loss 0.0655147060751915
bi 2 loss 0.10451657325029373
bi 3 loss 0.03957385942339897
Layer  1  loss:  0.06642322242259979 0.0 6.567806720733643
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1023
Curr loss timestep torch.Size([493, 4]) tensor([280, 372, 477, 243], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.06568147242069244
bi 1 loss 0.0736834928393364
bi 2 loss 0.08938820660114288
bi 3 loss 0.04155479744076729
Layer  2  loss:  0.06715840846300125 0.0 6.316696643829346
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1022
Curr loss timestep torch.Size([493, 4]) tensor([280, 372, 466, 310], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.057691771537065506
bi 1 loss 0.07922281324863434
bi 2 loss 0.07723239809274673
bi 3 loss 0.05269849672913551
Layer  3  loss:  0.06417244672775269 0.0 6.302718162536621
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1023
Curr loss timestep torch.Size([493, 4]) tensor([280, 372, 466, 310], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 0.05377216637134552
bi 1 loss 0.07187549024820328
bi 2 loss 0.10513471812009811
bi 3 loss 0.038250457495450974
Layer  4  loss:  0.055552225559949875 0.0 4.047664642333984
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1023
Curr loss timestep torch.Size([493, 4]) tensor([280, 264, 466, 316], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.044340647757053375
bi 1 loss 0.051697585731744766
bi 2 loss 0.10427650064229965
bi 3 loss 0.04373648390173912
Layer  5  loss:  0.058701369911432266 0.0 4.878139019012451
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1022
Curr loss timestep torch.Size([493, 4]) tensor([280, 372, 466, 312], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.04702921584248543
bi 1 loss 0.06292835623025894
bi 2 loss 0.08434122055768967
bi 3 loss 0.04922909289598465
Layer  6  loss:  0.06582405418157578 0.0 5.675776958465576
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1021
Curr loss timestep torch.Size([493, 4]) tensor([280, 372, 477, 312], device='cuda:0') tensor(477, device='cuda:0')
bi 0 loss 0.03869054093956947
bi 1 loss 0.07330074906349182
bi 2 loss 0.11549581587314606
bi 3 loss 0.053687091916799545
Epoch 0: :   3%|▎         | 15524/600000 [03:38<2:16:59, v_num=12, reduced_train_loss=2.320, global_step=15522.0, consumed_samples=62092.0, train_step_timing in s=0.410]Epoch 0: :   3%|▎         | 15524/600000 [03:38<2:16:59, v_num=12, reduced_train_loss=0.498, global_step=15523.0, consumed_samples=62096.0, train_step_timing in s=0.343]loss mask original None

First layer loss:  0.3095223605632782 torch.Size([894, 4]) 12.625154495239258 0.0
Max loss timestep torch.Size([894, 4]) tensor([685, 594, 564, 213], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.31800970435142517
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
bi 1 loss 0.2670454680919647
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
bi 2 loss 0.42987552285194397
speech mask sum tensor(463, device='cuda:0') loss mask sum tensor(463, device='cuda:0')
bi 3 loss 0.05513616278767586
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
logits torch.Size([894, 4, 257024]) labels torch.Size([894, 4]) 0 257022
Layer  0  loss:  0.36854174733161926 0.0 12.600699424743652
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1023
Curr loss timestep torch.Size([894, 4]) tensor([692, 531, 606, 129], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.41741159558296204
bi 1 loss 0.3059130609035492
bi 2 loss 0.48776769638061523
bi 3 loss 0.053214434534311295
Layer  1  loss:  0.3824847936630249 0.0 12.688764572143555
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1023
Curr loss timestep torch.Size([894, 4]) tensor([685, 384, 533, 152], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.41001734137535095
bi 1 loss 0.3573139011859894
bi 2 loss 0.4928901493549347
bi 3 loss 0.05662744864821434
Layer  2  loss:  0.4240891635417938 0.0 14.615788459777832
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1022
Curr loss timestep torch.Size([894, 4]) tensor([370, 260, 679, 101], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.44204181432724
bi 1 loss 0.38567522168159485
bi 2 loss 0.5744106769561768
bi 3 loss 0.04735171049833298
Layer  3  loss:  0.43004879355430603 0.0 15.84410572052002
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1023
Curr loss timestep torch.Size([894, 4]) tensor([597, 383, 565, 180], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.47859030961990356
bi 1 loss 0.38962119817733765
bi 2 loss 0.5466980338096619
bi 3 loss 0.06554309278726578
Layer  4  loss:  0.4437550902366638 0.0 14.844024658203125
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1023
Curr loss timestep torch.Size([894, 4]) tensor([322, 531, 565, 162], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.4675738513469696
bi 1 loss 0.38741758465766907
bi 2 loss 0.6075150966644287
bi 3 loss 0.05853455886244774
Layer  5  loss:  0.45712852478027344 0.0 12.284348487854004
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1022
Curr loss timestep torch.Size([894, 4]) tensor([549, 554, 533, 135], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.4315977990627289
bi 1 loss 0.4491872191429138
bi 2 loss 0.6336262822151184
bi 3 loss 0.05285513028502464
Layer  6  loss:  0.471782922744751 0.0 16.884998321533203
logits torch.Size([894, 4, 1024]) labels torch.Size([894, 4]) 0 1023
Curr loss timestep torch.Size([894, 4]) tensor([709, 594, 533, 173], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.4388687014579773
bi 1 loss 0.42616307735443115
bi 2 loss 0.7001057863235474
bi 3 loss 0.03986099734902382
Epoch 0: :   3%|▎         | 15525/600000 [03:38<2:17:23, v_num=12, reduced_train_loss=0.498, global_step=15523.0, consumed_samples=62096.0, train_step_timing in s=0.343]Epoch 0: :   3%|▎         | 15525/600000 [03:38<2:17:23, v_num=12, reduced_train_loss=3.290, global_step=15524.0, consumed_samples=62100.0, train_step_timing in s=0.623]loss mask original None

First layer loss:  3.715360641479492 torch.Size([708, 4]) 11.173433303833008 0.0
Max loss timestep torch.Size([708, 4]) tensor([344, 169, 306, 281], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 3.872387409210205
speech mask sum tensor(248, device='cuda:0') loss mask sum tensor(248, device='cuda:0')
bi 1 loss 3.6213839054107666
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 2 loss 3.551363468170166
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 3 loss 3.786426305770874
speech mask sum tensor(457, device='cuda:0') loss mask sum tensor(457, device='cuda:0')
logits torch.Size([708, 4, 257024]) labels torch.Size([708, 4]) 0 257023
Layer  0  loss:  4.377562999725342 0.0 11.410083770751953
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([322, 157, 517, 379], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 4.6133856773376465
bi 1 loss 4.30092191696167
bi 2 loss 4.252110481262207
bi 3 loss 4.370489120483398
Layer  1  loss:  4.61968994140625 0.0 10.849348068237305
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([273, 155, 483, 291], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 5.113731861114502
bi 1 loss 4.548349380493164
bi 2 loss 4.45827054977417
bi 3 loss 4.499393463134766
Layer  2  loss:  4.837040424346924 0.0 10.43260669708252
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([306, 194, 433, 507], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 5.425619602203369
bi 1 loss 4.663639545440674
bi 2 loss 4.608613967895508
bi 3 loss 4.747405052185059
Layer  3  loss:  5.037290573120117 0.0 11.031485557556152
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([329, 163, 544, 263], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 5.416359901428223
bi 1 loss 4.782200336456299
bi 2 loss 4.939388751983643
bi 3 loss 4.981482028961182
Layer  4  loss:  5.158269882202148 0.0 10.583732604980469
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([343, 109, 499, 522], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 5.369597434997559
bi 1 loss 5.067569732666016
bi 2 loss 5.086575984954834
bi 3 loss 5.1260247230529785
Layer  5  loss:  5.266129016876221 0.0 11.377670288085938
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([339, 132, 436, 412], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 5.652267932891846
bi 1 loss 5.105299949645996
bi 2 loss 5.074066162109375
bi 3 loss 5.254050254821777
Layer  6  loss:  5.269703388214111 0.0 10.45811653137207
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([341, 168, 310, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 5.499222755432129
bi 1 loss 5.020556926727295
bi 2 loss 5.196980953216553
bi 3 loss 5.273470401763916
Epoch 0: :   3%|▎         | 15526/600000 [03:39<2:17:40, v_num=12, reduced_train_loss=3.290, global_step=15524.0, consumed_samples=62100.0, train_step_timing in s=0.623]Epoch 0: :   3%|▎         | 15526/600000 [03:39<2:17:40, v_num=12, reduced_train_loss=38.30, global_step=15525.0, consumed_samples=62104.0, train_step_timing in s=0.428]loss mask original None

First layer loss:  0.1763656735420227 torch.Size([697, 4]) 10.187714576721191 0.0
Max loss timestep torch.Size([697, 4]) tensor([647, 167, 296, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.22682183980941772
speech mask sum tensor(476, device='cuda:0') loss mask sum tensor(476, device='cuda:0')
bi 1 loss 0.09570721536874771
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 2 loss 0.222441166639328
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 3 loss 0.10531052201986313
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
logits torch.Size([697, 4, 257024]) labels torch.Size([697, 4]) 0 257022
Layer  0  loss:  0.17381234467029572 0.0 9.113752365112305
logits torch.Size([697, 4, 1024]) labels torch.Size([697, 4]) 0 1023
Curr loss timestep torch.Size([697, 4]) tensor([589, 125, 328, 387], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.25515928864479065
bi 1 loss 0.024725986644625664
bi 2 loss 0.20551697909832
bi 3 loss 0.08828897029161453
Layer  1  loss:  0.20429645478725433 0.0 10.94443130493164
logits torch.Size([697, 4, 1024]) labels torch.Size([697, 4]) 0 1023
Curr loss timestep torch.Size([697, 4]) tensor([647, 155, 296, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.2563507556915283
bi 1 loss 0.03217186778783798
bi 2 loss 0.2812868356704712
bi 3 loss 0.14981180429458618
Layer  2  loss:  0.24616947770118713 0.0 12.812626838684082
logits torch.Size([697, 4, 1024]) labels torch.Size([697, 4]) 0 1022
Curr loss timestep torch.Size([697, 4]) tensor([280, 166, 297, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.3304233253002167
bi 1 loss 0.05505002662539482
bi 2 loss 0.2722615897655487
bi 3 loss 0.17502829432487488
Layer  3  loss:  0.24646377563476562 0.0 10.30301570892334
logits torch.Size([697, 4, 1024]) labels torch.Size([697, 4]) 0 1021
Curr loss timestep torch.Size([697, 4]) tensor([589, 183, 297, 329], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.3103126585483551
bi 1 loss 0.058431174606084824
bi 2 loss 0.37583526968955994
bi 3 loss 0.15296670794487
Layer  4  loss:  0.22343578934669495 0.0 9.264336585998535
logits torch.Size([697, 4, 1024]) labels torch.Size([697, 4]) 0 1022
Curr loss timestep torch.Size([697, 4]) tensor([602, 182, 422, 329], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.28818216919898987
bi 1 loss 0.022083772346377373
bi 2 loss 0.29371047019958496
bi 3 loss 0.1638455092906952
Layer  5  loss:  0.24300993978977203 0.0 13.594234466552734
logits torch.Size([697, 4, 1024]) labels torch.Size([697, 4]) 0 1022
Curr loss timestep torch.Size([697, 4]) tensor([280, 137, 421, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.3193919062614441
bi 1 loss 0.08086717873811722
bi 2 loss 0.25929534435272217
bi 3 loss 0.17804615199565887
Layer  6  loss:  0.21209198236465454 0.0 9.634855270385742
logits torch.Size([697, 4, 1024]) labels torch.Size([697, 4]) 0 1022
Curr loss timestep torch.Size([697, 4]) tensor([280, 139, 297, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.28021740913391113
bi 1 loss 0.044881924986839294
bi 2 loss 0.23141521215438843
bi 3 loss 0.160307377576828
Epoch 0: :   3%|▎         | 15527/600000 [03:39<2:17:59, v_num=12, reduced_train_loss=38.30, global_step=15525.0, consumed_samples=62104.0, train_step_timing in s=0.428]Epoch 0: :   3%|▎         | 15527/600000 [03:39<2:17:59, v_num=12, reduced_train_loss=1.730, global_step=15526.0, consumed_samples=62108.0, train_step_timing in s=0.481]loss mask original None

First layer loss:  3.8098974227905273 torch.Size([644, 4]) 11.956033706665039 0.0
Max loss timestep torch.Size([644, 4]) tensor([262, 354, 522, 181], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 3.2001988887786865
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 1 loss 4.006975173950195
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 2 loss 3.957064390182495
speech mask sum tensor(479, device='cuda:0') loss mask sum tensor(479, device='cuda:0')
bi 3 loss 2.906445264816284
speech mask sum tensor(68, device='cuda:0') loss mask sum tensor(68, device='cuda:0')
logits torch.Size([644, 4, 257024]) labels torch.Size([644, 4]) 0 257023
Layer  0  loss:  4.442626953125 0.0 10.167865753173828
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([217, 270, 323, 195], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 3.4968957901000977
bi 1 loss 4.627777576446533
bi 2 loss 4.720487117767334
bi 3 loss 3.252162218093872
Layer  1  loss:  4.60474967956543 0.0 9.92898178100586
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1023
Curr loss timestep torch.Size([644, 4]) tensor([265, 271, 496, 168], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 3.816528797149658
bi 1 loss 4.7940545082092285
bi 2 loss 4.832973957061768
bi 3 loss 3.473601818084717
Layer  2  loss:  4.915091514587402 0.0 10.128105163574219
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([237, 343, 558, 176], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 3.8924953937530518
bi 1 loss 5.087170124053955
bi 2 loss 5.171116352081299
bi 3 loss 4.071427822113037
Layer  3  loss:  5.063687324523926 0.0 10.145719528198242
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1021
Curr loss timestep torch.Size([644, 4]) tensor([249, 163, 198, 176], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.186422348022461
bi 1 loss 5.259025573730469
bi 2 loss 5.291501045227051
bi 3 loss 4.060609817504883
Layer  4  loss:  5.188389778137207 0.0 11.000864028930664
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([259, 398, 352, 185], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 4.369408130645752
bi 1 loss 5.467078685760498
bi 2 loss 5.332414627075195
bi 3 loss 4.2879109382629395
Layer  5  loss:  5.285931587219238 0.0 9.9893798828125
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([278, 322, 517, 184], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 4.386327266693115
bi 1 loss 5.532941818237305
bi 2 loss 5.477684497833252
bi 3 loss 4.3351850509643555
Layer  6  loss:  5.319521427154541 0.0 9.612797737121582
logits torch.Size([644, 4, 1024]) labels torch.Size([644, 4]) 0 1022
Curr loss timestep torch.Size([644, 4]) tensor([239, 275, 637, 193], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 4.396964073181152
bi 1 loss 5.497337818145752
bi 2 loss 5.561080455780029
bi 3 loss 4.378976345062256
Epoch 0: :   3%|▎         | 15528/600000 [03:40<2:18:15, v_num=12, reduced_train_loss=1.730, global_step=15526.0, consumed_samples=62108.0, train_step_timing in s=0.481]Epoch 0: :   3%|▎         | 15528/600000 [03:40<2:18:15, v_num=12, reduced_train_loss=38.60, global_step=15527.0, consumed_samples=62112.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.0222772266715765 torch.Size([513, 4]) 0.7894920110702515 0.0
Max loss timestep torch.Size([513, 4]) tensor([385,  46, 131,  56], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.02605454996228218
speech mask sum tensor(353, device='cuda:0') loss mask sum tensor(353, device='cuda:0')
bi 1 loss 0.017070595175027847
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 2 loss 0.01763986423611641
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 3 loss 0.017680518329143524
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([513, 4, 257024]) labels torch.Size([513, 4]) 0 257022
Layer  0  loss:  0.03510575369000435 0.0 2.811629056930542
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([352,  65, 108,  90], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.042285237461328506
bi 1 loss 0.012859238311648369
bi 2 loss 0.019212089478969574
bi 3 loss 0.03573772311210632
Layer  1  loss:  0.038830988109111786 0.0 3.601069927215576
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1021
Curr loss timestep torch.Size([513, 4]) tensor([263,  56, 127, 128], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.050267044454813004
bi 1 loss 0.017745185643434525
bi 2 loss 0.03125329315662384
bi 3 loss 0.02292904630303383
Layer  2  loss:  0.04438060149550438 0.0 2.4226014614105225
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([355,  59, 142,  95], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.06671353429555893
bi 1 loss 0.008722880855202675
bi 2 loss 0.012023266404867172
bi 3 loss 0.02225898765027523
Layer  3  loss:  0.023249464109539986 0.0 0.9061117172241211
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1019
Curr loss timestep torch.Size([513, 4]) tensor([377,  75, 159, 124], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.02766292542219162
bi 1 loss 0.022824499756097794
bi 2 loss 0.0178038589656353
bi 3 loss 0.01565690152347088
Layer  4  loss:  0.046422407031059265 0.0 4.084156513214111
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([352,  55, 118, 160], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.07043576240539551
bi 1 loss 0.005072359461337328
bi 2 loss 0.015273376367986202
bi 3 loss 0.021520601585507393
Layer  5  loss:  0.04013035073876381 0.0 3.4754693508148193
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([346,  66, 122,  91], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 0.05512496829032898
bi 1 loss 0.01876465603709221
bi 2 loss 0.024959634989500046
bi 3 loss 0.020109012722969055
Layer  6  loss:  0.03963719680905342 0.0 3.4363160133361816
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1021
Curr loss timestep torch.Size([513, 4]) tensor([352,  51, 167,  76], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.05504840612411499
bi 1 loss 0.011656121350824833
bi 2 loss 0.023950831964612007
bi 3 loss 0.021501969546079636
Epoch 0: :   3%|▎         | 15529/600000 [03:40<2:18:29, v_num=12, reduced_train_loss=38.60, global_step=15527.0, consumed_samples=62112.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15529/600000 [03:40<2:18:29, v_num=12, reduced_train_loss=0.290, global_step=15528.0, consumed_samples=62116.0, train_step_timing in s=0.360]loss mask original None

First layer loss:  3.641378164291382 torch.Size([572, 4]) 11.091371536254883 0.0
Max loss timestep torch.Size([572, 4]) tensor([ 50, 147, 243, 296], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 2.4569926261901855
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
bi 1 loss 4.0241780281066895
speech mask sum tensor(449, device='cuda:0') loss mask sum tensor(449, device='cuda:0')
bi 2 loss 3.977266550064087
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 3 loss 3.553619861602783
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
logits torch.Size([572, 4, 257024]) labels torch.Size([572, 4]) 0 257022
Layer  0  loss:  4.100389003753662 0.0 10.531423568725586
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([ 70, 209, 223, 306], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 3.47493577003479
bi 1 loss 4.371109485626221
bi 2 loss 4.025285243988037
bi 3 loss 4.0441083908081055
Layer  1  loss:  4.496127128601074 0.0 11.29200267791748
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([ 95, 442, 212, 286], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 3.990137815475464
bi 1 loss 4.596602439880371
bi 2 loss 4.299220561981201
bi 3 loss 4.696408271789551
Layer  2  loss:  4.750575542449951 0.0 9.743185997009277
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([132, 329, 239, 174], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 4.065312385559082
bi 1 loss 4.838122367858887
bi 2 loss 4.914665699005127
bi 3 loss 4.928196430206299
Layer  3  loss:  4.820770740509033 0.0 10.51810073852539
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([153, 443, 238, 314], device='cuda:0') tensor(172, device='cuda:0')
bi 0 loss 4.338155746459961
bi 1 loss 4.8133344650268555
bi 2 loss 4.80502986907959
bi 3 loss 5.10988712310791
Layer  4  loss:  4.945135593414307 0.0 10.495599746704102
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([118, 397, 267, 322], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 4.454309940338135
bi 1 loss 4.959807395935059
bi 2 loss 4.815141677856445
bi 3 loss 5.248767852783203
Layer  5  loss:  5.011894702911377 0.0 10.445097923278809
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([178, 183, 213, 329], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.401174545288086
bi 1 loss 5.105011940002441
bi 2 loss 4.926449775695801
bi 3 loss 5.238322734832764
Layer  6  loss:  5.041916370391846 0.0 10.409509658813477
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([ 54, 357, 297, 398], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.489123821258545
bi 1 loss 5.100532531738281
bi 2 loss 5.000010967254639
bi 3 loss 5.2741780281066895
Epoch 0: :   3%|▎         | 15530/600000 [03:41<2:18:44, v_num=12, reduced_train_loss=0.290, global_step=15528.0, consumed_samples=62116.0, train_step_timing in s=0.360]Epoch 0: :   3%|▎         | 15530/600000 [03:41<2:18:44, v_num=12, reduced_train_loss=36.80, global_step=15529.0, consumed_samples=62120.0, train_step_timing in s=0.370]loss mask original None

First layer loss:  3.5318520069122314 torch.Size([448, 4]) 12.694164276123047 0.0
Max loss timestep torch.Size([448, 4]) tensor([ 64, 299, 132, 229], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 2.7772068977355957
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
bi 1 loss 4.022137641906738
speech mask sum tensor(225, device='cuda:0') loss mask sum tensor(225, device='cuda:0')
bi 2 loss 3.916874647140503
speech mask sum tensor(295, device='cuda:0') loss mask sum tensor(295, device='cuda:0')
bi 3 loss 3.669259786605835
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([448, 4, 257024]) labels torch.Size([448, 4]) 0 257022
Layer  0  loss:  3.960944414138794 0.0 10.023420333862305
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([ 69, 382, 140, 183], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 3.0177268981933594
bi 1 loss 4.435631275177002
bi 2 loss 4.469963073730469
bi 3 loss 4.2972822189331055
Layer  1  loss:  4.215770721435547 0.0 10.79819393157959
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([354, 317, 169, 153], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 3.536005735397339
bi 1 loss 4.4023919105529785
bi 2 loss 4.6686835289001465
bi 3 loss 4.527177810668945
Layer  2  loss:  4.389211654663086 0.0 10.679985046386719
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1022
Curr loss timestep torch.Size([448, 4]) tensor([168, 243, 182, 169], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 3.6919567584991455
bi 1 loss 4.529197692871094
bi 2 loss 4.824660778045654
bi 3 loss 4.8536834716796875
Layer  3  loss:  4.497377395629883 0.0 11.274231910705566
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1022
Curr loss timestep torch.Size([448, 4]) tensor([160, 441, 149, 195], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 3.77091121673584
bi 1 loss 4.732228755950928
bi 2 loss 4.974287986755371
bi 3 loss 4.787966728210449
Layer  4  loss:  4.632053852081299 0.0 10.237616539001465
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([153, 428, 362, 163], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 3.844204902648926
bi 1 loss 4.975562572479248
bi 2 loss 5.11605978012085
bi 3 loss 4.873899936676025
Layer  5  loss:  4.7216033935546875 0.0 10.348203659057617
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([102, 305, 280, 184], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 3.9016287326812744
bi 1 loss 5.125865936279297
bi 2 loss 5.229307174682617
bi 3 loss 4.889231204986572
Layer  6  loss:  4.793076038360596 0.0 9.54704761505127
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1021
Curr loss timestep torch.Size([448, 4]) tensor([172, 419, 350, 230], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.115211486816406
bi 1 loss 5.067023754119873
bi 2 loss 5.260809421539307
bi 3 loss 4.927270889282227
Epoch 0: :   3%|▎         | 15531/600000 [03:41<2:18:57, v_num=12, reduced_train_loss=36.80, global_step=15529.0, consumed_samples=62120.0, train_step_timing in s=0.370]Epoch 0: :   3%|▎         | 15531/600000 [03:41<2:18:57, v_num=12, reduced_train_loss=34.70, global_step=15530.0, consumed_samples=62124.0, train_step_timing in s=0.313]loss mask original None

First layer loss:  0.12885236740112305 torch.Size([682, 4]) 8.38129997253418 0.0
Max loss timestep torch.Size([682, 4]) tensor([574, 358, 212, 211], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 0.16338033974170685
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 1 loss 0.16632981598377228
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
bi 2 loss 0.04741823300719261
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 3 loss 0.0316249243915081
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
logits torch.Size([682, 4, 257024]) labels torch.Size([682, 4]) 0 257022
Layer  0  loss:  0.16245071589946747 0.0 14.215716361999512
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([567, 358, 212,  55], device='cuda:0') tensor(567, device='cuda:0')
bi 0 loss 0.21310964226722717
bi 1 loss 0.20307473838329315
bi 2 loss 0.0580938458442688
bi 3 loss 0.03494780510663986
Layer  1  loss:  0.17783428728580475 0.0 14.661680221557617
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([518, 359, 208,  56], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.20407015085220337
bi 1 loss 0.2574475109577179
bi 2 loss 0.04070991277694702
bi 3 loss 0.055743467062711716
Layer  2  loss:  0.17316921055316925 0.0 17.69182014465332
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1022
Curr loss timestep torch.Size([682, 4]) tensor([573, 358, 205, 262], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 0.18870536983013153
bi 1 loss 0.2685829997062683
bi 2 loss 0.07605155557394028
bi 3 loss 0.04063434898853302
Layer  3  loss:  0.17052426934242249 0.0 12.01134967803955
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([573, 543, 233, 262], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.22382330894470215
bi 1 loss 0.21374700963497162
bi 2 loss 0.03358630836009979
bi 3 loss 0.042985688894987106
Layer  4  loss:  0.1746036857366562 0.0 18.390827178955078
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1022
Curr loss timestep torch.Size([682, 4]) tensor([520, 541, 212, 210], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.17605164647102356
bi 1 loss 0.2976745069026947
bi 2 loss 0.03207263723015785
bi 3 loss 0.045372188091278076
Layer  5  loss:  0.17343835532665253 0.0 11.083799362182617
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1023
Curr loss timestep torch.Size([682, 4]) tensor([574, 359, 202,  60], device='cuda:0') tensor(574, device='cuda:0')
bi 0 loss 0.21692128479480743
bi 1 loss 0.23178650438785553
bi 2 loss 0.023924853652715683
bi 3 loss 0.0486445315182209
Layer  6  loss:  0.1728184074163437 0.0 10.966673851013184
logits torch.Size([682, 4, 1024]) labels torch.Size([682, 4]) 0 1019
Curr loss timestep torch.Size([682, 4]) tensor([574, 543, 217, 150], device='cuda:0') tensor(543, device='cuda:0')
bi 0 loss 0.2008974701166153
bi 1 loss 0.2557178735733032
bi 2 loss 0.03126007318496704
bi 3 loss 0.043842919170856476
Epoch 0: :   3%|▎         | 15532/600000 [03:42<2:19:15, v_num=12, reduced_train_loss=34.70, global_step=15530.0, consumed_samples=62124.0, train_step_timing in s=0.313]Epoch 0: :   3%|▎         | 15532/600000 [03:42<2:19:15, v_num=12, reduced_train_loss=1.330, global_step=15531.0, consumed_samples=62128.0, train_step_timing in s=0.465]loss mask original None

First layer loss:  0.04357471689581871 torch.Size([441, 4]) 6.334754943847656 0.0
Max loss timestep torch.Size([441, 4]) tensor([291,  88, 225, 275], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.07325178384780884
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 1 loss 0.02413303218781948
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 2 loss 0.026598727330565453
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 3 loss 0.03650612756609917
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
logits torch.Size([441, 4, 257024]) labels torch.Size([441, 4]) 0 257022
Layer  0  loss:  0.045265909284353256 0.0 5.343826770782471
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([291,  99, 206, 275], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.061691246926784515
bi 1 loss 0.03350038826465607
bi 2 loss 0.03941778466105461
bi 3 loss 0.04024375602602959
Layer  1  loss:  0.059522971510887146 0.0 14.063116073608398
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([291,  65, 177, 176], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.11765275150537491
bi 1 loss 0.015545026399195194
bi 2 loss 0.03402736037969589
bi 3 loss 0.04416777566075325
Layer  2  loss:  0.045540351420640945 0.0 6.038059234619141
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1022
Curr loss timestep torch.Size([441, 4]) tensor([291,  75, 178, 276], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.06446044147014618
bi 1 loss 0.03206130117177963
bi 2 loss 0.019249508157372475
bi 3 loss 0.04722850024700165
Layer  3  loss:  0.048071153461933136 0.0 6.938518047332764
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1021
Curr loss timestep torch.Size([441, 4]) tensor([291,  73, 224, 338], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.0763777643442154
bi 1 loss 0.01960093528032303
bi 2 loss 0.037777941673994064
bi 3 loss 0.04152975603938103
Layer  4  loss:  0.04915793240070343 0.0 5.0305328369140625
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([291,  91, 161, 146], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.07677821069955826
bi 1 loss 0.021263055503368378
bi 2 loss 0.0396360382437706
bi 3 loss 0.0426037535071373
Layer  5  loss:  0.04556436836719513 0.0 4.479646682739258
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1022
Curr loss timestep torch.Size([441, 4]) tensor([291,  88, 228, 282], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.06521091610193253
bi 1 loss 0.018608763813972473
bi 2 loss 0.03111286088824272
bi 3 loss 0.04560735076665878
Layer  6  loss:  0.0542709119617939 0.0 13.568034172058105
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1022
Curr loss timestep torch.Size([441, 4]) tensor([291,  73, 254, 365], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.09613543748855591
bi 1 loss 0.026385456323623657
bi 2 loss 0.03188791871070862
bi 3 loss 0.0438140444457531
Epoch 0: :   3%|▎         | 15533/600000 [03:42<2:19:29, v_num=12, reduced_train_loss=1.330, global_step=15531.0, consumed_samples=62128.0, train_step_timing in s=0.465]Epoch 0: :   3%|▎         | 15533/600000 [03:42<2:19:29, v_num=12, reduced_train_loss=0.391, global_step=15532.0, consumed_samples=62132.0, train_step_timing in s=0.333]loss mask original None

First layer loss:  0.13222789764404297 torch.Size([502, 4]) 11.06434440612793 0.0
Max loss timestep torch.Size([502, 4]) tensor([381, 269, 188, 251], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.16352225840091705
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 1 loss 0.09569807350635529
speech mask sum tensor(174, device='cuda:0') loss mask sum tensor(174, device='cuda:0')
bi 2 loss 0.1456698477268219
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 3 loss 0.05923141911625862
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
logits torch.Size([502, 4, 257024]) labels torch.Size([502, 4]) 0 257022
Layer  0  loss:  0.11009205877780914 0.0 9.752008438110352
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([380, 276, 329, 257], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.15936914086341858
bi 1 loss 0.07727465033531189
bi 2 loss 0.07471182197332382
bi 3 loss 0.07675967365503311
Layer  1  loss:  0.1216856986284256 0.0 9.76602554321289
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([381, 149, 308, 285], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.18317697942256927
bi 1 loss 0.06324455887079239
bi 2 loss 0.06349028646945953
bi 3 loss 0.13914404809474945
Layer  2  loss:  0.10891726613044739 0.0 11.150699615478516
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1022
Curr loss timestep torch.Size([502, 4]) tensor([339, 276, 309, 254], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.15593671798706055
bi 1 loss 0.06748659908771515
bi 2 loss 0.08590999245643616
bi 3 loss 0.07049039751291275
Layer  3  loss:  0.11032864451408386 0.0 7.501364707946777
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1023
Curr loss timestep torch.Size([502, 4]) tensor([381, 276, 309, 263], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.14676089584827423
bi 1 loss 0.07019319385290146
bi 2 loss 0.101599782705307
bi 3 loss 0.07408656924962997
Layer  4  loss:  0.11457449197769165 0.0 7.5099639892578125
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1022
Curr loss timestep torch.Size([502, 4]) tensor([380, 173, 271, 251], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.1597122997045517
bi 1 loss 0.05944070219993591
bi 2 loss 0.09034367650747299
bi 3 loss 0.10753319412469864
Layer  5  loss:  0.11928931623697281 0.0 8.067039489746094
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1022
Curr loss timestep torch.Size([502, 4]) tensor([380, 227, 271, 292], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.16120153665542603
bi 1 loss 0.06058073043823242
bi 2 loss 0.11480071395635605
bi 3 loss 0.08617687970399857
Layer  6  loss:  0.12078914791345596 0.0 8.882438659667969
logits torch.Size([502, 4, 1024]) labels torch.Size([502, 4]) 0 1020
Curr loss timestep torch.Size([502, 4]) tensor([339, 274, 308, 305], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.1723281294107437
bi 1 loss 0.0657065287232399
bi 2 loss 0.09427043795585632
bi 3 loss 0.09734995663166046
Epoch 0: :   3%|▎         | 15534/600000 [03:42<2:19:43, v_num=12, reduced_train_loss=0.391, global_step=15532.0, consumed_samples=62132.0, train_step_timing in s=0.333]Epoch 0: :   3%|▎         | 15534/600000 [03:42<2:19:43, v_num=12, reduced_train_loss=0.938, global_step=15533.0, consumed_samples=62136.0, train_step_timing in s=0.351]loss mask original None

First layer loss:  0.06488689035177231 torch.Size([463, 4]) 8.688950538635254 0.0
Max loss timestep torch.Size([463, 4]) tensor([152, 254, 340, 256], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.032614465802907944
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
bi 1 loss 0.050398994237184525
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 2 loss 0.12115342170000076
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 3 loss 0.021434661000967026
speech mask sum tensor(234, device='cuda:0') loss mask sum tensor(234, device='cuda:0')
logits torch.Size([463, 4, 257024]) labels torch.Size([463, 4]) 0 257021
Layer  0  loss:  0.09144167602062225 0.0 7.662655830383301
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([194, 298, 312, 256], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.04368329793214798
bi 1 loss 0.07362335175275803
bi 2 loss 0.15887565910816193
bi 3 loss 0.04395723715424538
Layer  1  loss:  0.09246846288442612 0.0 9.397696495056152
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([187, 275, 340, 257], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.04858515039086342
bi 1 loss 0.05166128650307655
bi 2 loss 0.17024406790733337
bi 3 loss 0.0574820339679718
Layer  2  loss:  0.10656311362981796 0.0 16.045917510986328
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([164, 300, 340, 257], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.04155730456113815
bi 1 loss 0.06391778588294983
bi 2 loss 0.1886819303035736
bi 3 loss 0.07738301157951355
Layer  3  loss:  0.08894108235836029 0.0 10.182106018066406
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1020
Curr loss timestep torch.Size([463, 4]) tensor([150, 298, 340, 257], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.05044317990541458
bi 1 loss 0.05216751992702484
bi 2 loss 0.1444115936756134
bi 3 loss 0.07656193524599075
Layer  4  loss:  0.10479672253131866 0.0 12.56035327911377
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([172, 298, 340, 257], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.03609658032655716
bi 1 loss 0.08948037773370743
bi 2 loss 0.1602635532617569
bi 3 loss 0.07962022721767426
Layer  5  loss:  0.10985492169857025 0.0 9.086628913879395
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([177, 298, 340, 257], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.0739302933216095
bi 1 loss 0.06219910457730293
bi 2 loss 0.19476176798343658
bi 3 loss 0.07013260573148727
Layer  6  loss:  0.09247518330812454 0.0 10.469064712524414
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([150, 298, 311, 128], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.05073756352066994
bi 1 loss 0.062421366572380066
bi 2 loss 0.1721106767654419
bi 3 loss 0.04089638218283653
Epoch 0: :   3%|▎         | 15535/600000 [03:43<2:19:56, v_num=12, reduced_train_loss=0.938, global_step=15533.0, consumed_samples=62136.0, train_step_timing in s=0.351]Epoch 0: :   3%|▎         | 15535/600000 [03:43<2:19:56, v_num=12, reduced_train_loss=0.751, global_step=15534.0, consumed_samples=62140.0, train_step_timing in s=0.330]loss mask original None

First layer loss:  3.43284273147583 torch.Size([680, 4]) 14.830053329467773 0.0
Max loss timestep torch.Size([680, 4]) tensor([487, 660, 289, 506], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 2.8597946166992188
speech mask sum tensor(485, device='cuda:0') loss mask sum tensor(485, device='cuda:0')
bi 1 loss 3.5256340503692627
speech mask sum tensor(488, device='cuda:0') loss mask sum tensor(488, device='cuda:0')
bi 2 loss 3.676330804824829
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 3 loss 3.7967536449432373
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
logits torch.Size([680, 4, 257024]) labels torch.Size([680, 4]) 0 257023
Layer  0  loss:  4.006262302398682 0.0 10.859596252441406
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([212, 347, 133, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 3.6862552165985107
bi 1 loss 4.213442802429199
bi 2 loss 4.322569370269775
bi 3 loss 3.946554660797119
Layer  1  loss:  4.484981060028076 0.0 11.782744407653809
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([656, 366, 150, 365], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 4.304021835327148
bi 1 loss 4.8164873123168945
bi 2 loss 4.596240520477295
bi 3 loss 4.264324188232422
Layer  2  loss:  4.75498628616333 0.0 11.960594177246094
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([391, 364, 186, 322], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 4.579794883728027
bi 1 loss 4.933600902557373
bi 2 loss 4.964407444000244
bi 3 loss 4.6338791847229
Layer  3  loss:  4.89702033996582 0.0 10.816170692443848
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1022
Curr loss timestep torch.Size([680, 4]) tensor([512, 243, 275, 510], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 4.893523693084717
bi 1 loss 5.1301469802856445
bi 2 loss 4.9835991859436035
bi 3 loss 4.608405590057373
Layer  4  loss:  4.989259719848633 0.0 11.262714385986328
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([664, 216, 275, 291], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 5.062255382537842
bi 1 loss 5.202345371246338
bi 2 loss 5.046663761138916
bi 3 loss 4.6582350730896
Layer  5  loss:  5.135186672210693 0.0 12.498146057128906
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([410, 252, 195, 503], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 5.155351161956787
bi 1 loss 5.372231483459473
bi 2 loss 5.111262321472168
bi 3 loss 4.879260540008545
Layer  6  loss:  5.169946193695068 0.0 10.935781478881836
logits torch.Size([680, 4, 1024]) labels torch.Size([680, 4]) 0 1023
Curr loss timestep torch.Size([680, 4]) tensor([417, 276, 125, 514], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 5.239657402038574
bi 1 loss 5.440757751464844
bi 2 loss 5.15885591506958
bi 3 loss 4.819960117340088
Epoch 0: :   3%|▎         | 15536/600000 [03:43<2:20:12, v_num=12, reduced_train_loss=0.751, global_step=15534.0, consumed_samples=62140.0, train_step_timing in s=0.330]Epoch 0: :   3%|▎         | 15536/600000 [03:43<2:20:12, v_num=12, reduced_train_loss=36.90, global_step=15535.0, consumed_samples=62144.0, train_step_timing in s=0.411]loss mask original None

First layer loss:  0.10216225683689117 torch.Size([633, 4]) 7.733882427215576 0.0
Max loss timestep torch.Size([633, 4]) tensor([114, 276, 600, 292], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.022481394931674004
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 1 loss 0.06432642787694931
speech mask sum tensor(290, device='cuda:0') loss mask sum tensor(290, device='cuda:0')
bi 2 loss 0.1854846328496933
speech mask sum tensor(371, device='cuda:0') loss mask sum tensor(371, device='cuda:0')
bi 3 loss 0.05989427492022514
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
logits torch.Size([633, 4, 257024]) labels torch.Size([633, 4]) 0 257022
Layer  0  loss:  0.12397149950265884 0.0 8.261905670166016
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([142, 363, 382, 304], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 0.04340192675590515
bi 1 loss 0.060472507029771805
bi 2 loss 0.2343912422657013
bi 3 loss 0.07119680196046829
Layer  1  loss:  0.13620266318321228 0.0 11.221871376037598
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([200, 388, 514, 410], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.03279678151011467
bi 1 loss 0.048332951962947845
bi 2 loss 0.2749914824962616
bi 3 loss 0.08079889416694641
Layer  2  loss:  0.14745135605335236 0.0 9.787737846374512
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([122, 387, 537, 319], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.025250686332583427
bi 1 loss 0.0577155202627182
bi 2 loss 0.30110928416252136
bi 3 loss 0.08093538880348206
Layer  3  loss:  0.14747834205627441 0.0 12.384578704833984
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([113, 389, 514, 418], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.037188805639743805
bi 1 loss 0.06667396426200867
bi 2 loss 0.2940097153186798
bi 3 loss 0.07498271763324738
Layer  4  loss:  0.1367979347705841 0.0 10.046000480651855
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([198, 389, 538, 309], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.03202640637755394
bi 1 loss 0.08414869755506516
bi 2 loss 0.25718992948532104
bi 3 loss 0.06786737591028214
Layer  5  loss:  0.16782556474208832 0.0 13.941668510437012
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([136, 375, 514, 333], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.09223111718893051
bi 1 loss 0.07505946606397629
bi 2 loss 0.3174740970134735
bi 3 loss 0.08696956932544708
Layer  6  loss:  0.16303636133670807 0.0 10.295199394226074
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([147, 389, 514, 333], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.030171334743499756
bi 1 loss 0.08205433934926987
bi 2 loss 0.3175036311149597
bi 3 loss 0.09014847874641418
Epoch 0: :   3%|▎         | 15537/600000 [03:44<2:20:29, v_num=12, reduced_train_loss=36.90, global_step=15535.0, consumed_samples=62144.0, train_step_timing in s=0.411]Epoch 0: :   3%|▎         | 15537/600000 [03:44<2:20:29, v_num=12, reduced_train_loss=1.120, global_step=15536.0, consumed_samples=62148.0, train_step_timing in s=0.433]loss mask original None

First layer loss:  3.5409388542175293 torch.Size([620, 4]) 10.676820755004883 0.0
Max loss timestep torch.Size([620, 4]) tensor([130, 440, 143, 595], device='cuda:0') tensor(135, device='cuda:0')
bi 0 loss 4.202859401702881
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
bi 1 loss 3.387361526489258
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 2 loss 3.7192628383636475
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 3 loss 3.4233903884887695
speech mask sum tensor(336, device='cuda:0') loss mask sum tensor(336, device='cuda:0')
logits torch.Size([620, 4, 257024]) labels torch.Size([620, 4]) 0 257022
Layer  0  loss:  4.063963413238525 0.0 10.855669021606445
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([194, 321, 123, 466], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 4.558725833892822
bi 1 loss 3.947176933288574
bi 2 loss 3.466660737991333
bi 3 loss 4.176163673400879
Layer  1  loss:  4.39801549911499 0.0 9.46354866027832
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([166, 212, 158, 438], device='cuda:0') tensor(151, device='cuda:0')
bi 0 loss 4.7615556716918945
bi 1 loss 4.314817905426025
bi 2 loss 3.941995143890381
bi 3 loss 4.482219696044922
Layer  2  loss:  4.600531101226807 0.0 10.05920124053955
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([132, 288, 141, 462], device='cuda:0') tensor(141, device='cuda:0')
bi 0 loss 4.859255313873291
bi 1 loss 4.666613578796387
bi 2 loss 4.067359447479248
bi 3 loss 4.578990936279297
Layer  3  loss:  4.812257289886475 0.0 11.151554107666016
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([153, 353, 167, 419], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 4.9785661697387695
bi 1 loss 4.8354010581970215
bi 2 loss 4.272097110748291
bi 3 loss 4.87317419052124
Layer  4  loss:  4.932902812957764 0.0 9.853289604187012
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([133, 263, 160, 294], device='cuda:0') tensor(140, device='cuda:0')
bi 0 loss 5.016713619232178
bi 1 loss 5.047697067260742
bi 2 loss 4.600203037261963
bi 3 loss 4.866417407989502
Layer  5  loss:  4.979060649871826 0.0 11.052892684936523
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([216, 350, 166, 301], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 5.143374919891357
bi 1 loss 5.062161445617676
bi 2 loss 4.463565826416016
bi 3 loss 4.967991828918457
Layer  6  loss:  5.048832416534424 0.0 11.028879165649414
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([173, 285, 170, 550], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 5.246593952178955
bi 1 loss 5.074047088623047
bi 2 loss 4.649200916290283
bi 3 loss 5.05808162689209
Epoch 0: :   3%|▎         | 15538/600000 [03:44<2:20:45, v_num=12, reduced_train_loss=1.120, global_step=15536.0, consumed_samples=62148.0, train_step_timing in s=0.433]Epoch 0: :   3%|▎         | 15538/600000 [03:44<2:20:45, v_num=12, reduced_train_loss=36.40, global_step=15537.0, consumed_samples=62152.0, train_step_timing in s=0.382]loss mask original None

First layer loss:  3.7944841384887695 torch.Size([624, 4]) 12.572367668151855 0.0
Max loss timestep torch.Size([624, 4]) tensor([226, 115, 382, 451], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 3.7752363681793213
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 1 loss 4.036589622497559
speech mask sum tensor(398, device='cuda:0') loss mask sum tensor(398, device='cuda:0')
bi 2 loss 3.8750452995300293
speech mask sum tensor(459, device='cuda:0') loss mask sum tensor(459, device='cuda:0')
bi 3 loss 3.2948315143585205
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
logits torch.Size([624, 4, 257024]) labels torch.Size([624, 4]) 0 257022
Layer  0  loss:  4.286481857299805 0.0 10.901836395263672
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1023
Curr loss timestep torch.Size([624, 4]) tensor([242, 153, 442, 474], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 4.230689525604248
bi 1 loss 4.4525251388549805
bi 2 loss 4.385278224945068
bi 3 loss 3.8960909843444824
Layer  1  loss:  4.485345840454102 0.0 10.165000915527344
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1023
Curr loss timestep torch.Size([624, 4]) tensor([245, 173, 487, 390], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 4.4883904457092285
bi 1 loss 4.704274654388428
bi 2 loss 4.475381851196289
bi 3 loss 4.16572380065918
Layer  2  loss:  4.789895534515381 0.0 10.584559440612793
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1022
Curr loss timestep torch.Size([624, 4]) tensor([280, 387, 506, 470], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 4.526583194732666
bi 1 loss 5.063577175140381
bi 2 loss 4.783718585968018
bi 3 loss 4.562123775482178
Layer  3  loss:  4.905941486358643 0.0 10.49842643737793
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1022
Curr loss timestep torch.Size([624, 4]) tensor([343, 124, 326, 255], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 4.710363388061523
bi 1 loss 5.127685546875
bi 2 loss 4.867763042449951
bi 3 loss 4.767796993255615
Layer  4  loss:  5.049015998840332 0.0 11.592785835266113
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1022
Curr loss timestep torch.Size([624, 4]) tensor([337, 114, 401, 326], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 4.886558532714844
bi 1 loss 5.199657917022705
bi 2 loss 5.073837757110596
bi 3 loss 4.885820388793945
Layer  5  loss:  5.169131755828857 0.0 10.281557083129883
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1023
Curr loss timestep torch.Size([624, 4]) tensor([242, 313, 530, 492], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 4.851803779602051
bi 1 loss 5.392161846160889
bi 2 loss 5.188048362731934
bi 3 loss 5.011576175689697
Layer  6  loss:  5.160747528076172 0.0 10.592962265014648
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1020
Curr loss timestep torch.Size([624, 4]) tensor([350, 119, 472, 278], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 4.904804229736328
bi 1 loss 5.376086235046387
bi 2 loss 5.143389701843262
bi 3 loss 5.036977291107178
Epoch 0: :   3%|▎         | 15539/600000 [03:44<2:21:00, v_num=12, reduced_train_loss=36.40, global_step=15537.0, consumed_samples=62152.0, train_step_timing in s=0.382]Epoch 0: :   3%|▎         | 15539/600000 [03:44<2:21:00, v_num=12, reduced_train_loss=37.60, global_step=15538.0, consumed_samples=62156.0, train_step_timing in s=0.383]loss mask original None

First layer loss:  0.09318629652261734 torch.Size([482, 4]) 10.899251937866211 0.0
Max loss timestep torch.Size([482, 4]) tensor([278, 290, 347, 278], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.06246769428253174
speech mask sum tensor(356, device='cuda:0') loss mask sum tensor(356, device='cuda:0')
bi 1 loss 0.19931718707084656
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 2 loss 0.08693696558475494
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 3 loss 0.045969415456056595
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
logits torch.Size([482, 4, 257024]) labels torch.Size([482, 4]) 0 257022
Layer  0  loss:  0.09719695895910263 0.0 8.66634750366211
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([294, 290, 347, 301], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.0841212123632431
bi 1 loss 0.18482300639152527
bi 2 loss 0.08530855923891068
bi 3 loss 0.045673735439777374
Layer  1  loss:  0.0988001823425293 0.0 10.900906562805176
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([278, 290, 347, 263], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.06677081435918808
bi 1 loss 0.24110549688339233
bi 2 loss 0.06929004937410355
bi 3 loss 0.05124690383672714
Layer  2  loss:  0.11845671385526657 0.0 12.813855171203613
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([268, 290, 347, 278], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.0678967759013176
bi 1 loss 0.3076646625995636
bi 2 loss 0.08725951611995697
bi 3 loss 0.057646580040454865
Layer  3  loss:  0.11351746320724487 0.0 12.959893226623535
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([371, 290, 350, 296], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.06118307262659073
bi 1 loss 0.20952486991882324
bi 2 loss 0.1458679437637329
bi 3 loss 0.05758996307849884
Layer  4  loss:  0.11805906146764755 0.0 11.47259521484375
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([267, 290, 347, 301], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.0673871859908104
bi 1 loss 0.2344391644001007
bi 2 loss 0.09799829125404358
bi 3 loss 0.11868669837713242
Layer  5  loss:  0.08982162922620773 0.0 8.813886642456055
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1021
Curr loss timestep torch.Size([482, 4]) tensor([ 97, 293, 347, 278], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.0644507110118866
bi 1 loss 0.2191258817911148
bi 2 loss 0.05412747338414192
bi 3 loss 0.053453896194696426
Layer  6  loss:  0.08321330696344376 0.0 8.72419548034668
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([280, 290, 347, 278], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.05839848145842552
bi 1 loss 0.16635683178901672
bi 2 loss 0.08258716762065887
bi 3 loss 0.04097643867135048
Epoch 0: :   3%|▎         | 15540/600000 [03:45<2:21:13, v_num=12, reduced_train_loss=37.60, global_step=15538.0, consumed_samples=62156.0, train_step_timing in s=0.383]Epoch 0: :   3%|▎         | 15540/600000 [03:45<2:21:13, v_num=12, reduced_train_loss=0.812, global_step=15539.0, consumed_samples=62160.0, train_step_timing in s=0.338]loss mask original None

First layer loss:  3.8024542331695557 torch.Size([636, 4]) 10.080977439880371 0.0
Max loss timestep torch.Size([636, 4]) tensor([150, 112, 174, 557], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 3.8698630332946777
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 1 loss 4.029270648956299
speech mask sum tensor(468, device='cuda:0') loss mask sum tensor(468, device='cuda:0')
bi 2 loss 3.5754928588867188
speech mask sum tensor(306, device='cuda:0') loss mask sum tensor(306, device='cuda:0')
bi 3 loss 3.6744072437286377
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
logits torch.Size([636, 4, 257024]) labels torch.Size([636, 4]) 0 257023
Layer  0  loss:  4.349771976470947 0.0 9.416801452636719
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([ 94, 425, 273, 581], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 4.590973377227783
bi 1 loss 4.648589611053467
bi 2 loss 4.244166374206543
bi 3 loss 3.955195903778076
Layer  1  loss:  4.636640548706055 0.0 10.418615341186523
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([124, 470, 366, 349], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 4.962928295135498
bi 1 loss 4.796205997467041
bi 2 loss 4.526529312133789
bi 3 loss 4.382237911224365
Layer  2  loss:  4.887754917144775 0.0 11.162603378295898
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([148, 514, 179, 487], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 4.999205112457275
bi 1 loss 5.098170280456543
bi 2 loss 4.954639911651611
bi 3 loss 4.520263195037842
Layer  3  loss:  4.995999336242676 0.0 9.446317672729492
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([119, 283, 270, 495], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 5.206067085266113
bi 1 loss 5.141613960266113
bi 2 loss 4.894792079925537
bi 3 loss 4.803351879119873
Layer  4  loss:  5.143405437469482 0.0 13.550654411315918
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([153, 453, 172, 573], device='cuda:0') tensor(405, device='cuda:0')
bi 0 loss 5.311986923217773
bi 1 loss 5.324434757232666
bi 2 loss 5.102537631988525
bi 3 loss 4.875488758087158
Layer  5  loss:  5.276610374450684 0.0 10.079462051391602
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([191, 421, 247, 544], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 5.377522945404053
bi 1 loss 5.4924468994140625
bi 2 loss 5.194578170776367
bi 3 loss 5.028852939605713
Layer  6  loss:  5.2948198318481445 0.0 10.174665451049805
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([ 84, 133, 336, 602], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 5.411292552947998
bi 1 loss 5.4061737060546875
bi 2 loss 5.304433345794678
bi 3 loss 5.095918655395508
Epoch 0: :   3%|▎         | 15541/600000 [03:45<2:21:29, v_num=12, reduced_train_loss=0.812, global_step=15539.0, consumed_samples=62160.0, train_step_timing in s=0.338]Epoch 0: :   3%|▎         | 15541/600000 [03:45<2:21:29, v_num=12, reduced_train_loss=38.40, global_step=15540.0, consumed_samples=62164.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  3.5983011722564697 torch.Size([700, 4]) 12.231440544128418 0.0
Max loss timestep torch.Size([700, 4]) tensor([197, 604, 172, 363], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 3.9351847171783447
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
bi 1 loss 3.4347920417785645
speech mask sum tensor(491, device='cuda:0') loss mask sum tensor(491, device='cuda:0')
bi 2 loss 3.9198193550109863
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 3 loss 3.44677996635437
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
logits torch.Size([700, 4, 257024]) labels torch.Size([700, 4]) 0 257023
Layer  0  loss:  4.141490936279297 0.0 11.80160903930664
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1023
Curr loss timestep torch.Size([700, 4]) tensor([183, 642, 209, 583], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 4.2612433433532715
bi 1 loss 3.9362926483154297
bi 2 loss 4.557106971740723
bi 3 loss 4.1957879066467285
Layer  1  loss:  4.406099319458008 0.0 9.350486755371094
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1023
Curr loss timestep torch.Size([700, 4]) tensor([162, 585, 234, 577], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 4.4085693359375
bi 1 loss 4.25178861618042
bi 2 loss 4.755532264709473
bi 3 loss 4.5075883865356445
Layer  2  loss:  4.800782680511475 0.0 10.425162315368652
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1022
Curr loss timestep torch.Size([700, 4]) tensor([143, 504, 231, 594], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 4.866387367248535
bi 1 loss 4.610614776611328
bi 2 loss 5.049743175506592
bi 3 loss 4.929040431976318
Layer  3  loss:  4.9165496826171875 0.0 10.309139251708984
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1022
Curr loss timestep torch.Size([700, 4]) tensor([362, 476, 250, 346], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.983940601348877
bi 1 loss 4.844510555267334
bi 2 loss 5.080156326293945
bi 3 loss 4.909559726715088
Layer  4  loss:  5.04455041885376 0.0 9.955442428588867
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1022
Curr loss timestep torch.Size([700, 4]) tensor([332, 444, 239, 321], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 5.062204360961914
bi 1 loss 5.0569071769714355
bi 2 loss 5.246332168579102
bi 3 loss 4.953006267547607
Layer  5  loss:  5.151719570159912 0.0 10.93780517578125
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1023
Curr loss timestep torch.Size([700, 4]) tensor([211, 386, 205, 581], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 5.15192174911499
bi 1 loss 5.101291179656982
bi 2 loss 5.378203868865967
bi 3 loss 5.151756286621094
Layer  6  loss:  5.200178623199463 0.0 11.035491943359375
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1023
Curr loss timestep torch.Size([700, 4]) tensor([355, 285, 261, 570], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 5.187857151031494
bi 1 loss 5.210142135620117
bi 2 loss 5.612400531768799
bi 3 loss 5.073387622833252
Epoch 0: :   3%|▎         | 15542/600000 [03:46<2:21:46, v_num=12, reduced_train_loss=38.40, global_step=15540.0, consumed_samples=62164.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15542/600000 [03:46<2:21:46, v_num=12, reduced_train_loss=37.30, global_step=15541.0, consumed_samples=62168.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.19488464295864105 torch.Size([711, 4]) 7.28926420211792 0.0
Max loss timestep torch.Size([711, 4]) tensor([461, 631, 423, 353], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.11881604045629501
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 1 loss 0.32342350482940674
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
bi 2 loss 0.13431903719902039
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 3 loss 0.11916036158800125
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
logits torch.Size([711, 4, 257024]) labels torch.Size([711, 4]) 0 257022
Layer  0  loss:  0.25082626938819885 0.0 16.238494873046875
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1023
Curr loss timestep torch.Size([711, 4]) tensor([461, 348, 355, 381], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.1459316611289978
bi 1 loss 0.4504146873950958
bi 2 loss 0.14891186356544495
bi 3 loss 0.12389738857746124
Layer  1  loss:  0.2871873676776886 0.0 14.414464950561523
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1022
Curr loss timestep torch.Size([711, 4]) tensor([461, 631, 270, 410], device='cuda:0') tensor(631, device='cuda:0')
bi 0 loss 0.18936003744602203
bi 1 loss 0.47347238659858704
bi 2 loss 0.14405860006809235
bi 3 loss 0.22936470806598663
Layer  2  loss:  0.2897486090660095 0.0 14.338007926940918
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1022
Curr loss timestep torch.Size([711, 4]) tensor([461, 533, 278, 410], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.13446494936943054
bi 1 loss 0.4941982626914978
bi 2 loss 0.1858626902103424
bi 3 loss 0.22894729673862457
Layer  3  loss:  0.2716854214668274 0.0 8.629929542541504
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1023
Curr loss timestep torch.Size([711, 4]) tensor([461, 601, 271, 265], device='cuda:0') tensor(601, device='cuda:0')
bi 0 loss 0.14158986508846283
bi 1 loss 0.4836197793483734
bi 2 loss 0.16054897010326385
bi 3 loss 0.1679290235042572
Layer  4  loss:  0.3003261089324951 0.0 16.584375381469727
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1023
Curr loss timestep torch.Size([711, 4]) tensor([461, 348, 355, 419], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.15754032135009766
bi 1 loss 0.5510352253913879
bi 2 loss 0.15098342299461365
bi 3 loss 0.1839769035577774
Layer  5  loss:  0.3051108121871948 0.0 14.453487396240234
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1022
Curr loss timestep torch.Size([711, 4]) tensor([461, 347, 355, 323], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.13637159764766693
bi 1 loss 0.5274252891540527
bi 2 loss 0.17914077639579773
bi 3 loss 0.25529205799102783
Layer  6  loss:  0.33041203022003174 0.0 13.055606842041016
logits torch.Size([711, 4, 1024]) labels torch.Size([711, 4]) 0 1022
Curr loss timestep torch.Size([711, 4]) tensor([461, 600, 423, 265], device='cuda:0') tensor(423, device='cuda:0')
bi 0 loss 0.1536809802055359
bi 1 loss 0.5404074192047119
bi 2 loss 0.23676802217960358
bi 3 loss 0.27660685777664185
Epoch 0: :   3%|▎         | 15543/600000 [03:46<2:22:05, v_num=12, reduced_train_loss=37.30, global_step=15541.0, consumed_samples=62168.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15543/600000 [03:46<2:22:05, v_num=12, reduced_train_loss=2.230, global_step=15542.0, consumed_samples=62172.0, train_step_timing in s=0.487]loss mask original None

First layer loss:  3.7195286750793457 torch.Size([580, 4]) 12.470770835876465 0.0
Max loss timestep torch.Size([580, 4]) tensor([252, 452, 218, 240], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 4.235367298126221
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 1 loss 3.7789289951324463
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
bi 2 loss 2.93407940864563
speech mask sum tensor(188, device='cuda:0') loss mask sum tensor(188, device='cuda:0')
bi 3 loss 3.7120234966278076
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
logits torch.Size([580, 4, 257024]) labels torch.Size([580, 4]) 0 257022
Layer  0  loss:  4.134475231170654 0.0 9.626081466674805
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([408, 500, 231, 146], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 4.61279821395874
bi 1 loss 4.033682346343994
bi 2 loss 3.519087076187134
bi 3 loss 4.439059734344482
Layer  1  loss:  4.478586196899414 0.0 9.742366790771484
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([378, 273, 257, 186], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 4.955946445465088
bi 1 loss 4.555760383605957
bi 2 loss 3.617006778717041
bi 3 loss 4.562425136566162
Layer  2  loss:  4.715368270874023 0.0 9.306121826171875
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([360, 525, 239, 195], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 5.126389503479004
bi 1 loss 4.781874656677246
bi 2 loss 4.048113822937012
bi 3 loss 4.702411651611328
Layer  3  loss:  4.955053806304932 0.0 10.270895957946777
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([274, 210, 147, 242], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 5.265077590942383
bi 1 loss 5.0624680519104
bi 2 loss 4.322860240936279
bi 3 loss 4.930459976196289
Layer  4  loss:  5.124205112457275 0.0 9.576099395751953
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([363, 480, 167, 189], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 5.406771659851074
bi 1 loss 5.259101390838623
bi 2 loss 4.428468704223633
bi 3 loss 5.133502006530762
Layer  5  loss:  5.209470272064209 0.0 10.711715698242188
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1022
Curr loss timestep torch.Size([580, 4]) tensor([263, 310, 172, 196], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 5.629051208496094
bi 1 loss 5.367319107055664
bi 2 loss 4.391079902648926
bi 3 loss 5.098550796508789
Layer  6  loss:  5.2003278732299805 0.0 9.612369537353516
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([350, 203, 224, 152], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 5.655730724334717
bi 1 loss 5.319711685180664
bi 2 loss 4.399974346160889
bi 3 loss 5.126472473144531
Epoch 0: :   3%|▎         | 15544/600000 [03:47<2:22:19, v_num=12, reduced_train_loss=2.230, global_step=15542.0, consumed_samples=62172.0, train_step_timing in s=0.487]Epoch 0: :   3%|▎         | 15544/600000 [03:47<2:22:19, v_num=12, reduced_train_loss=37.50, global_step=15543.0, consumed_samples=62176.0, train_step_timing in s=0.368]loss mask original None

First layer loss:  0.11167612671852112 torch.Size([559, 4]) 7.940715312957764 0.0
Max loss timestep torch.Size([559, 4]) tensor([358, 525, 330, 290], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.07492177933454514
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 0.11727970838546753
speech mask sum tensor(440, device='cuda:0') loss mask sum tensor(440, device='cuda:0')
bi 2 loss 0.15752220153808594
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 3 loss 0.07764510810375214
speech mask sum tensor(378, device='cuda:0') loss mask sum tensor(378, device='cuda:0')
logits torch.Size([559, 4, 257024]) labels torch.Size([559, 4]) 0 257022
Layer  0  loss:  0.14952313899993896 0.0 13.187952995300293
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([391, 529, 333, 386], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.19645418226718903
bi 1 loss 0.17165035009384155
bi 2 loss 0.14481058716773987
bi 3 loss 0.11346563696861267
Layer  1  loss:  0.19419270753860474 0.0 12.236532211303711
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([391, 520, 420, 381], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.19562433660030365
bi 1 loss 0.24915136396884918
bi 2 loss 0.22363482415676117
bi 3 loss 0.10493750125169754
Layer  2  loss:  0.18192020058631897 0.0 11.536197662353516
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([391, 529, 334,  48], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.23662212491035461
bi 1 loss 0.19113950431346893
bi 2 loss 0.2558525800704956
bi 3 loss 0.09215398132801056
Layer  3  loss:  0.2143920361995697 0.0 17.894742965698242
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1021
Curr loss timestep torch.Size([559, 4]) tensor([391, 514, 493, 386], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.32132086157798767
bi 1 loss 0.26505449414253235
bi 2 loss 0.255959689617157
bi 3 loss 0.0878090038895607
Layer  4  loss:  0.22670689225196838 0.0 10.03726863861084
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([391, 518, 475, 381], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.35041436553001404
bi 1 loss 0.2609502077102661
bi 2 loss 0.28227853775024414
bi 3 loss 0.10231336951255798
Layer  5  loss:  0.20317824184894562 0.0 13.814155578613281
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([391, 514, 475, 386], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.3336160480976105
bi 1 loss 0.25669386982917786
bi 2 loss 0.1952541619539261
bi 3 loss 0.10788874328136444
Layer  6  loss:  0.20493124425411224 0.0 18.008224487304688
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([391, 518, 491, 290], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.24600660800933838
bi 1 loss 0.26513198018074036
bi 2 loss 0.20480719208717346
bi 3 loss 0.12246453762054443
Epoch 0: :   3%|▎         | 15545/600000 [03:47<2:22:35, v_num=12, reduced_train_loss=37.50, global_step=15543.0, consumed_samples=62176.0, train_step_timing in s=0.368]Epoch 0: :   3%|▎         | 15545/600000 [03:47<2:22:35, v_num=12, reduced_train_loss=1.490, global_step=15544.0, consumed_samples=62180.0, train_step_timing in s=0.380]loss mask original None

First layer loss:  0.062423836439847946 torch.Size([506, 4]) 4.028767108917236 0.0
Max loss timestep torch.Size([506, 4]) tensor([345, 321, 203,  87], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.07326216995716095
speech mask sum tensor(449, device='cuda:0') loss mask sum tensor(449, device='cuda:0')
bi 1 loss 0.06473278999328613
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 2 loss 0.05866384133696556
speech mask sum tensor(321, device='cuda:0') loss mask sum tensor(321, device='cuda:0')
bi 3 loss 0.04115651920437813
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
logits torch.Size([506, 4, 257024]) labels torch.Size([506, 4]) 0 257022
Layer  0  loss:  0.06219326704740524 0.0 5.136216640472412
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([264, 300, 312, 161], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.06386256217956543
bi 1 loss 0.048746466636657715
bi 2 loss 0.07439285516738892
bi 3 loss 0.052145205438137054
Layer  1  loss:  0.06957417726516724 0.0 4.643544673919678
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([264, 321, 311, 180], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.07998443394899368
bi 1 loss 0.05849060043692589
bi 2 loss 0.08363078534603119
bi 3 loss 0.033762380480766296
Layer  2  loss:  0.06556040793657303 0.0 6.941972255706787
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([264, 282, 311, 207], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.0727897584438324
bi 1 loss 0.054550182074308395
bi 2 loss 0.07532963901758194
bi 3 loss 0.04412825033068657
Layer  3  loss:  0.06490085273981094 0.0 3.859074831008911
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1020
Curr loss timestep torch.Size([506, 4]) tensor([483, 287, 208, 204], device='cuda:0') tensor(483, device='cuda:0')
bi 0 loss 0.08412984013557434
bi 1 loss 0.050026439130306244
bi 2 loss 0.06714697182178497
bi 3 loss 0.032167915254831314
Layer  4  loss:  0.06888772547245026 0.0 5.816436290740967
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([264, 263, 402, 128], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.09459484368562698
bi 1 loss 0.038239311426877975
bi 2 loss 0.06470489501953125
bi 3 loss 0.048223696649074554
Layer  5  loss:  0.07239164412021637 0.0 3.806335687637329
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1019
Curr loss timestep torch.Size([506, 4]) tensor([264, 321, 361, 101], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.07943747192621231
bi 1 loss 0.08201009780168533
bi 2 loss 0.07342537492513657
bi 3 loss 0.04435903951525688
Layer  6  loss:  0.06012185290455818 0.0 4.081063747406006
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([264, 321, 343, 218], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.09216288477182388
bi 1 loss 0.043336573988199234
bi 2 loss 0.0419159010052681
bi 3 loss 0.03356676548719406
Epoch 0: :   3%|▎         | 15546/600000 [03:47<2:22:49, v_num=12, reduced_train_loss=1.490, global_step=15544.0, consumed_samples=62180.0, train_step_timing in s=0.380]Epoch 0: :   3%|▎         | 15546/600000 [03:47<2:22:49, v_num=12, reduced_train_loss=0.526, global_step=15545.0, consumed_samples=62184.0, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.007717599160969257 torch.Size([337, 4]) 0.14898112416267395 0.0
Max loss timestep torch.Size([337, 4]) tensor([ 75, 197, 168, 299], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.007010242436081171
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 1 loss 0.007489036303013563
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 2 loss 0.0064065782353281975
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 3 loss 0.008997587487101555
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
logits torch.Size([337, 4, 257024]) labels torch.Size([337, 4]) 0 257023
Layer  0  loss:  0.006920917890965939 0.0 0.06463713943958282
logits torch.Size([337, 4, 1024]) labels torch.Size([337, 4]) 0 1023
Curr loss timestep torch.Size([337, 4]) tensor([ 73, 130, 156, 170], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 0.006236141547560692
bi 1 loss 0.006347339134663343
bi 2 loss 0.006547410506755114
bi 3 loss 0.007748747244477272
Layer  1  loss:  0.007129041012376547 0.0 0.08131849765777588
logits torch.Size([337, 4, 1024]) labels torch.Size([337, 4]) 0 1022
Curr loss timestep torch.Size([337, 4]) tensor([ 76, 127,  89, 271], device='cuda:0') tensor(76, device='cuda:0')
bi 0 loss 0.009524318389594555
bi 1 loss 0.007008845917880535
bi 2 loss 0.006026619579643011
bi 3 loss 0.007207874208688736
Layer  2  loss:  0.007670291233807802 0.0 0.06895323097705841
logits torch.Size([337, 4, 1024]) labels torch.Size([337, 4]) 0 1023
Curr loss timestep torch.Size([337, 4]) tensor([ 96, 126, 116, 299], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 0.006715781986713409
bi 1 loss 0.007295873947441578
bi 2 loss 0.006853155326098204
bi 3 loss 0.008772890083491802
Layer  3  loss:  0.00658878218382597 0.0 0.10443530976772308
logits torch.Size([337, 4, 1024]) labels torch.Size([337, 4]) 0 1021
Curr loss timestep torch.Size([337, 4]) tensor([ 80, 113, 201, 287], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.006460841745138168
bi 1 loss 0.005539316218346357
bi 2 loss 0.006921077147126198
bi 3 loss 0.00703537929803133
Layer  4  loss:  0.008079014718532562 0.0 0.1666404902935028
logits torch.Size([337, 4, 1024]) labels torch.Size([337, 4]) 0 1021
Curr loss timestep torch.Size([337, 4]) tensor([108, 171, 105, 272], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 0.008051430806517601
bi 1 loss 0.0072248405776917934
bi 2 loss 0.006979578640311956
bi 3 loss 0.009374653920531273
Layer  5  loss:  0.007284463383257389 0.0 0.15506014227867126
logits torch.Size([337, 4, 1024]) labels torch.Size([337, 4]) 0 1021
Curr loss timestep torch.Size([337, 4]) tensor([105, 121, 176, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.006204396020621061
bi 1 loss 0.005575168877840042
bi 2 loss 0.007918131537735462
bi 3 loss 0.008225331082940102
Layer  6  loss:  0.0072011821903288364 0.0 0.1049596518278122
logits torch.Size([337, 4, 1024]) labels torch.Size([337, 4]) 0 1020
Curr loss timestep torch.Size([337, 4]) tensor([ 95, 114, 137, 309], device='cuda:0') tensor(114, device='cuda:0')
bi 0 loss 0.0066369702108204365
bi 1 loss 0.0070959413424134254
bi 2 loss 0.006764931604266167
bi 3 loss 0.007749730255454779
Epoch 0: :   3%|▎         | 15547/600000 [03:48<2:23:01, v_num=12, reduced_train_loss=0.526, global_step=15545.0, consumed_samples=62184.0, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15547/600000 [03:48<2:23:01, v_num=12, reduced_train_loss=0.0586, global_step=15546.0, consumed_samples=62188.0, train_step_timing in s=0.306]loss mask original None

First layer loss:  0.24267728626728058 torch.Size([727, 4]) 9.560115814208984 0.0
Max loss timestep torch.Size([727, 4]) tensor([435, 523, 292, 270], device='cuda:0') tensor(523, device='cuda:0')
bi 0 loss 0.13390305638313293
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
bi 1 loss 0.3802255094051361
speech mask sum tensor(483, device='cuda:0') loss mask sum tensor(483, device='cuda:0')
bi 2 loss 0.163868248462677
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 3 loss 0.22142130136489868
speech mask sum tensor(470, device='cuda:0') loss mask sum tensor(470, device='cuda:0')
logits torch.Size([727, 4, 257024]) labels torch.Size([727, 4]) 0 257023
Layer  0  loss:  0.28659483790397644 0.0 12.032035827636719
logits torch.Size([727, 4, 1024]) labels torch.Size([727, 4]) 0 1023
Curr loss timestep torch.Size([727, 4]) tensor([431, 509, 292, 685], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.14550872147083282
bi 1 loss 0.45683690905570984
bi 2 loss 0.20960620045661926
bi 3 loss 0.25882676243782043
Layer  1  loss:  0.3118014335632324 0.0 11.776811599731445
logits torch.Size([727, 4, 1024]) labels torch.Size([727, 4]) 0 1023
Curr loss timestep torch.Size([727, 4]) tensor([431, 509, 292, 689], device='cuda:0') tensor(509, device='cuda:0')
bi 0 loss 0.15745998919010162
bi 1 loss 0.535629391670227
bi 2 loss 0.16407302021980286
bi 3 loss 0.26441267132759094
Layer  2  loss:  0.2959955334663391 0.0 11.999907493591309
logits torch.Size([727, 4, 1024]) labels torch.Size([727, 4]) 0 1022
Curr loss timestep torch.Size([727, 4]) tensor([431, 525, 292, 654], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.18085680902004242
bi 1 loss 0.39568987488746643
bi 2 loss 0.19417978823184967
bi 3 loss 0.3269297480583191
Layer  3  loss:  0.3216632306575775 0.0 11.614948272705078
logits torch.Size([727, 4, 1024]) labels torch.Size([727, 4]) 0 1022
Curr loss timestep torch.Size([727, 4]) tensor([431, 629, 292, 689], device='cuda:0') tensor(689, device='cuda:0')
bi 0 loss 0.1939023733139038
bi 1 loss 0.467311829328537
bi 2 loss 0.18702825903892517
bi 3 loss 0.3273673951625824
Layer  4  loss:  0.36619094014167786 0.0 12.174459457397461
logits torch.Size([727, 4, 1024]) labels torch.Size([727, 4]) 0 1023
Curr loss timestep torch.Size([727, 4]) tensor([431, 523, 291, 538], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.21207952499389648
bi 1 loss 0.565671443939209
bi 2 loss 0.20516455173492432
bi 3 loss 0.34815263748168945
Layer  5  loss:  0.31289806962013245 0.0 12.377371788024902
logits torch.Size([727, 4, 1024]) labels torch.Size([727, 4]) 0 1023
Curr loss timestep torch.Size([727, 4]) tensor([431, 594, 292, 270], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.1832941472530365
bi 1 loss 0.4653273820877075
bi 2 loss 0.22594287991523743
bi 3 loss 0.29698285460472107
Layer  6  loss:  0.33653345704078674 0.0 14.496779441833496
logits torch.Size([727, 4, 1024]) labels torch.Size([727, 4]) 0 1022
Curr loss timestep torch.Size([727, 4]) tensor([431, 525, 292, 270], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.16804590821266174
bi 1 loss 0.5491166114807129
bi 2 loss 0.22498516738414764
bi 3 loss 0.30051326751708984
Epoch 0: :   3%|▎         | 15548/600000 [03:48<2:23:21, v_num=12, reduced_train_loss=0.0586, global_step=15546.0, consumed_samples=62188.0, train_step_timing in s=0.306]Epoch 0: :   3%|▎         | 15548/600000 [03:48<2:23:21, v_num=12, reduced_train_loss=2.470, global_step=15547.0, consumed_samples=62192.0, train_step_timing in s=0.502] loss mask original None

First layer loss:  0.19040192663669586 torch.Size([657, 4]) 8.097330093383789 0.0
Max loss timestep torch.Size([657, 4]) tensor([188, 345, 256, 281], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.017907224595546722
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 1 loss 0.3349945843219757
speech mask sum tensor(400, device='cuda:0') loss mask sum tensor(400, device='cuda:0')
bi 2 loss 0.023650754243135452
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
bi 3 loss 0.11762665957212448
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
logits torch.Size([657, 4, 257024]) labels torch.Size([657, 4]) 0 257022
Layer  0  loss:  0.2076086699962616 0.0 8.868412017822266
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([159, 594, 290, 281], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.027072912082076073
bi 1 loss 0.365845650434494
bi 2 loss 0.09608925133943558
bi 3 loss 0.07720980048179626
Layer  1  loss:  0.21359843015670776 0.0 10.326486587524414
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([199, 594, 290, 280], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.05553174018859863
bi 1 loss 0.3887910842895508
bi 2 loss 0.05056731775403023
bi 3 loss 0.07984359562397003
Layer  2  loss:  0.2483464926481247 0.0 14.932838439941406
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1022
Curr loss timestep torch.Size([657, 4]) tensor([195, 345, 290, 281], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.047143951058387756
bi 1 loss 0.44046226143836975
bi 2 loss 0.08384919911623001
bi 3 loss 0.10270413011312485
Layer  3  loss:  0.26344481110572815 0.0 12.59557056427002
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1021
Curr loss timestep torch.Size([657, 4]) tensor([155, 594, 290, 281], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.030469780787825584
bi 1 loss 0.4928312599658966
bi 2 loss 0.06589827686548233
bi 3 loss 0.08754412829875946
Layer  4  loss:  0.24070781469345093 0.0 11.738059043884277
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1022
Curr loss timestep torch.Size([657, 4]) tensor([149, 615, 171, 281], device='cuda:0') tensor(615, device='cuda:0')
bi 0 loss 0.03638070449233055
bi 1 loss 0.45004454255104065
bi 2 loss 0.056818775832653046
bi 3 loss 0.07944769412279129
Layer  5  loss:  0.24220731854438782 0.0 9.743500709533691
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([149, 345, 207, 281], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.053606901317834854
bi 1 loss 0.45338958501815796
bi 2 loss 0.04349159821867943
bi 3 loss 0.0817088857293129
Layer  6  loss:  0.26005473732948303 0.0 12.741461753845215
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1022
Curr loss timestep torch.Size([657, 4]) tensor([160, 426, 290, 281], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 0.055128637701272964
bi 1 loss 0.47517678141593933
bi 2 loss 0.0777641162276268
bi 3 loss 0.08793237805366516
Epoch 0: :   3%|▎         | 15549/600000 [03:49<2:23:38, v_num=12, reduced_train_loss=2.470, global_step=15547.0, consumed_samples=62192.0, train_step_timing in s=0.502]Epoch 0: :   3%|▎         | 15549/600000 [03:49<2:23:38, v_num=12, reduced_train_loss=1.870, global_step=15548.0, consumed_samples=62196.0, train_step_timing in s=0.448]loss mask original None

First layer loss:  3.912905693054199 torch.Size([716, 4]) 11.474739074707031 0.0
Max loss timestep torch.Size([716, 4]) tensor([590, 133, 407, 345], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 3.7009100914001465
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
bi 1 loss 3.4293057918548584
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 2 loss 3.9567036628723145
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 3 loss 4.159287929534912
speech mask sum tensor(483, device='cuda:0') loss mask sum tensor(483, device='cuda:0')
logits torch.Size([716, 4, 257024]) labels torch.Size([716, 4]) 0 257023
Layer  0  loss:  4.391883373260498 0.0 10.559511184692383
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([564, 167, 181, 463], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 4.295639991760254
bi 1 loss 3.8416147232055664
bi 2 loss 4.296614170074463
bi 3 loss 4.661534309387207
Layer  1  loss:  4.7052412033081055 0.0 10.756277084350586
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([326, 177, 404, 571], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 4.575128078460693
bi 1 loss 4.2739481925964355
bi 2 loss 4.538716793060303
bi 3 loss 5.045658111572266
Layer  2  loss:  4.992304801940918 0.0 10.402461051940918
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([545, 148, 416, 625], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 4.866745948791504
bi 1 loss 4.3123602867126465
bi 2 loss 4.93237829208374
bi 3 loss 5.2823567390441895
Layer  3  loss:  5.1493916511535645 0.0 10.891798973083496
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([516, 186, 212, 349], device='cuda:0') tensor(453, device='cuda:0')
bi 0 loss 4.972222328186035
bi 1 loss 4.502173900604248
bi 2 loss 5.11173152923584
bi 3 loss 5.462425708770752
Layer  4  loss:  5.336912155151367 0.0 10.31158447265625
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([402, 166, 432, 604], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 5.187623500823975
bi 1 loss 4.756778717041016
bi 2 loss 5.331143379211426
bi 3 loss 5.584799289703369
Layer  5  loss:  5.425792694091797 0.0 11.301836013793945
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([336, 151, 406, 322], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 5.293833255767822
bi 1 loss 4.774359226226807
bi 2 loss 5.488652229309082
bi 3 loss 5.61190938949585
Layer  6  loss:  5.373352527618408 0.0 9.964938163757324
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([575, 166, 253, 544], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 5.218774318695068
bi 1 loss 4.774093151092529
bi 2 loss 5.384649276733398
bi 3 loss 5.615034103393555
Epoch 0: :   3%|▎         | 15550/600000 [03:49<2:23:55, v_num=12, reduced_train_loss=1.870, global_step=15548.0, consumed_samples=62196.0, train_step_timing in s=0.448]Epoch 0: :   3%|▎         | 15550/600000 [03:49<2:23:55, v_num=12, reduced_train_loss=39.30, global_step=15549.0, consumed_samples=62200.0, train_step_timing in s=0.426]loss mask original None

First layer loss:  3.8807320594787598 torch.Size([600, 4]) 13.873404502868652 0.0
Max loss timestep torch.Size([600, 4]) tensor([244, 201,  87, 226], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 3.709597110748291
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 1 loss 4.251104831695557
speech mask sum tensor(456, device='cuda:0') loss mask sum tensor(456, device='cuda:0')
bi 2 loss 3.5577192306518555
speech mask sum tensor(486, device='cuda:0') loss mask sum tensor(486, device='cuda:0')
bi 3 loss 3.9966843128204346
speech mask sum tensor(346, device='cuda:0') loss mask sum tensor(346, device='cuda:0')
logits torch.Size([600, 4, 257024]) labels torch.Size([600, 4]) 0 257023
Layer  0  loss:  4.448974132537842 0.0 10.483304977416992
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([318, 211, 475, 431], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 4.061273097991943
bi 1 loss 4.664000511169434
bi 2 loss 4.412440299987793
bi 3 loss 4.55754280090332
Layer  1  loss:  4.673832416534424 0.0 10.370038032531738
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([281, 344, 144, 403], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 4.2878570556640625
bi 1 loss 4.850374221801758
bi 2 loss 4.665243148803711
bi 3 loss 4.792352199554443
Layer  2  loss:  4.906688690185547 0.0 11.822465896606445
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([190, 425, 528, 237], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 4.514284610748291
bi 1 loss 5.254095554351807
bi 2 loss 4.815342426300049
bi 3 loss 4.921913146972656
Layer  3  loss:  5.046696186065674 0.0 9.763504028320312
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([227, 512, 420, 480], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 4.731959342956543
bi 1 loss 5.544845104217529
bi 2 loss 4.864660739898682
bi 3 loss 4.922399997711182
Layer  4  loss:  5.190023422241211 0.0 9.947275161743164
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([305, 234, 323, 277], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 4.695899486541748
bi 1 loss 5.643166542053223
bi 2 loss 5.136049747467041
bi 3 loss 5.102777004241943
Layer  5  loss:  5.268678665161133 0.0 11.70663070678711
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1023
Curr loss timestep torch.Size([600, 4]) tensor([358, 465, 531, 333], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 4.74505090713501
bi 1 loss 5.837404251098633
bi 2 loss 5.113055229187012
bi 3 loss 5.19780158996582
Layer  6  loss:  5.31205940246582 0.0 10.5596284866333
logits torch.Size([600, 4, 1024]) labels torch.Size([600, 4]) 0 1022
Curr loss timestep torch.Size([600, 4]) tensor([326, 506, 410, 479], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 4.9117255210876465
bi 1 loss 5.858756065368652
bi 2 loss 5.191675186157227
bi 3 loss 5.112391471862793
Epoch 0: :   3%|▎         | 15551/600000 [03:50<2:24:10, v_num=12, reduced_train_loss=39.30, global_step=15549.0, consumed_samples=62200.0, train_step_timing in s=0.426]Epoch 0: :   3%|▎         | 15551/600000 [03:50<2:24:10, v_num=12, reduced_train_loss=38.70, global_step=15550.0, consumed_samples=62204.0, train_step_timing in s=0.382]loss mask original None

First layer loss:  3.7786660194396973 torch.Size([620, 4]) 10.65100383758545 0.0
Max loss timestep torch.Size([620, 4]) tensor([565, 218, 160,  75], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 4.1295390129089355
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 1 loss 3.365161180496216
speech mask sum tensor(393, device='cuda:0') loss mask sum tensor(393, device='cuda:0')
bi 2 loss 3.5752975940704346
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 3 loss 4.292550563812256
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
logits torch.Size([620, 4, 257024]) labels torch.Size([620, 4]) 0 257023
Layer  0  loss:  4.36337947845459 0.0 11.897444725036621
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([450, 328, 202, 189], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 4.672705173492432
bi 1 loss 4.254183769226074
bi 2 loss 4.035886764526367
bi 3 loss 4.5527143478393555
Layer  1  loss:  4.676126480102539 0.0 10.457901954650879
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([378, 457, 336, 195], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 4.977744102478027
bi 1 loss 4.617813587188721
bi 2 loss 4.352313995361328
bi 3 loss 4.77952766418457
Layer  2  loss:  4.922632217407227 0.0 10.308138847351074
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([447, 392, 125,  62], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 5.2019453048706055
bi 1 loss 4.929030895233154
bi 2 loss 4.526748180389404
bi 3 loss 5.037763595581055
Layer  3  loss:  5.044301986694336 0.0 9.74499225616455
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([340, 363, 270,  86], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 5.35825252532959
bi 1 loss 5.077930450439453
bi 2 loss 4.6349101066589355
bi 3 loss 5.0781097412109375
Layer  4  loss:  5.2065110206604 0.0 10.304893493652344
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1022
Curr loss timestep torch.Size([620, 4]) tensor([434, 272, 345, 182], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 5.366595268249512
bi 1 loss 5.2068376541137695
bi 2 loss 4.877749919891357
bi 3 loss 5.41514778137207
Layer  5  loss:  5.222667694091797 0.0 10.017131805419922
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([589, 424, 215, 256], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 5.44847297668457
bi 1 loss 5.221615314483643
bi 2 loss 4.918844699859619
bi 3 loss 5.305264472961426
Layer  6  loss:  5.309647560119629 0.0 10.266046524047852
logits torch.Size([620, 4, 1024]) labels torch.Size([620, 4]) 0 1023
Curr loss timestep torch.Size([620, 4]) tensor([427, 403,  87,  71], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 5.535536289215088
bi 1 loss 5.271553993225098
bi 2 loss 4.996085166931152
bi 3 loss 5.472264766693115
Epoch 0: :   3%|▎         | 15552/600000 [03:50<2:24:26, v_num=12, reduced_train_loss=38.70, global_step=15550.0, consumed_samples=62204.0, train_step_timing in s=0.382]Epoch 0: :   3%|▎         | 15552/600000 [03:50<2:24:26, v_num=12, reduced_train_loss=38.50, global_step=15551.0, consumed_samples=62208.0, train_step_timing in s=0.385]loss mask original None

First layer loss:  3.5070271492004395 torch.Size([700, 4]) 10.634076118469238 0.0
Max loss timestep torch.Size([700, 4]) tensor([101, 145, 199, 625], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 2.9431610107421875
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 1 loss 3.8129942417144775
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 2 loss 3.6470768451690674
speech mask sum tensor(240, device='cuda:0') loss mask sum tensor(240, device='cuda:0')
bi 3 loss 3.5331594944000244
speech mask sum tensor(488, device='cuda:0') loss mask sum tensor(488, device='cuda:0')
logits torch.Size([700, 4, 257024]) labels torch.Size([700, 4]) 0 257023
Layer  0  loss:  4.060705184936523 0.0 11.34327507019043
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1023
Curr loss timestep torch.Size([700, 4]) tensor([155, 114, 232, 656], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 3.8246591091156006
bi 1 loss 4.416949272155762
bi 2 loss 3.979409694671631
bi 3 loss 4.088094711303711
Layer  1  loss:  4.387331485748291 0.0 11.115257263183594
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1022
Curr loss timestep torch.Size([700, 4]) tensor([144, 136, 174, 314], device='cuda:0') tensor(88, device='cuda:0')
bi 0 loss 4.120711326599121
bi 1 loss 4.363433361053467
bi 2 loss 4.394925117492676
bi 3 loss 4.4672112464904785
Layer  2  loss:  4.681941509246826 0.0 9.401555061340332
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1022
Curr loss timestep torch.Size([700, 4]) tensor([170,  72, 214, 479], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 4.558708190917969
bi 1 loss 4.635329246520996
bi 2 loss 4.602908134460449
bi 3 loss 4.767620086669922
Layer  3  loss:  4.815403938293457 0.0 9.442887306213379
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1022
Curr loss timestep torch.Size([700, 4]) tensor([159,  55, 380, 369], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 4.55664587020874
bi 1 loss 4.696333885192871
bi 2 loss 4.820712089538574
bi 3 loss 4.915945529937744
Layer  4  loss:  4.978098392486572 0.0 10.237641334533691
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1023
Curr loss timestep torch.Size([700, 4]) tensor([188, 108, 389, 604], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 4.832951068878174
bi 1 loss 4.9234209060668945
bi 2 loss 4.889143466949463
bi 3 loss 5.076929092407227
Layer  5  loss:  5.019402027130127 0.0 10.811649322509766
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1017
Curr loss timestep torch.Size([700, 4]) tensor([171, 140, 305, 375], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 4.8364787101745605
bi 1 loss 4.9913010597229
bi 2 loss 4.941417217254639
bi 3 loss 5.117806911468506
Layer  6  loss:  5.082649230957031 0.0 11.10032844543457
logits torch.Size([700, 4, 1024]) labels torch.Size([700, 4]) 0 1022
Curr loss timestep torch.Size([700, 4]) tensor([206,  96, 314, 441], device='cuda:0') tensor(96, device='cuda:0')
bi 0 loss 4.957892417907715
bi 1 loss 4.759354114532471
bi 2 loss 4.9813690185546875
bi 3 loss 5.243216037750244
Epoch 0: :   3%|▎         | 15553/600000 [03:51<2:24:43, v_num=12, reduced_train_loss=38.50, global_step=15551.0, consumed_samples=62208.0, train_step_timing in s=0.385]Epoch 0: :   3%|▎         | 15553/600000 [03:51<2:24:43, v_num=12, reduced_train_loss=36.50, global_step=15552.0, consumed_samples=62212.0, train_step_timing in s=0.428]loss mask original None

First layer loss:  0.08007284253835678 torch.Size([390, 4]) 10.63581657409668 0.0
Max loss timestep torch.Size([390, 4]) tensor([ 86, 114, 373, 211], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.0420244000852108
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
bi 1 loss 0.03613332659006119
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 2 loss 0.14853672683238983
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 3 loss 0.04461335390806198
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
logits torch.Size([390, 4, 257024]) labels torch.Size([390, 4]) 0 257022
Layer  0  loss:  0.08223351836204529 0.0 15.22719669342041
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1023
Curr loss timestep torch.Size([390, 4]) tensor([121, 129, 371, 263], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.027203576639294624
bi 1 loss 0.02228417433798313
bi 2 loss 0.17168192565441132
bi 3 loss 0.042949795722961426
Layer  1  loss:  0.0998346358537674 0.0 17.743532180786133
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1023
Curr loss timestep torch.Size([390, 4]) tensor([ 84, 151, 373, 280], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.042180996388196945
bi 1 loss 0.026453860104084015
bi 2 loss 0.20634020864963531
bi 3 loss 0.04724627733230591
Layer  2  loss:  0.0803317055106163 0.0 10.631930351257324
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1022
Curr loss timestep torch.Size([390, 4]) tensor([ 80, 126, 372, 264], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.031403105705976486
bi 1 loss 0.023448416963219643
bi 2 loss 0.15517081320285797
bi 3 loss 0.055563170462846756
Layer  3  loss:  0.09108017385005951 0.0 16.93788719177246
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1023
Curr loss timestep torch.Size([390, 4]) tensor([ 77, 123, 373, 279], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.03958090767264366
bi 1 loss 0.02314796671271324
bi 2 loss 0.19157814979553223
bi 3 loss 0.03767678514122963
Layer  4  loss:  0.10775509476661682 0.0 15.856945037841797
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1022
Curr loss timestep torch.Size([390, 4]) tensor([149, 171, 372, 280], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.035762328654527664
bi 1 loss 0.02074573189020157
bi 2 loss 0.22424668073654175
bi 3 loss 0.06404952704906464
Layer  5  loss:  0.11216340959072113 0.0 19.574386596679688
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1023
Curr loss timestep torch.Size([390, 4]) tensor([ 77, 119, 371, 264], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.020498409867286682
bi 1 loss 0.023178227245807648
bi 2 loss 0.2514175772666931
bi 3 loss 0.05317627638578415
Layer  6  loss:  0.09899919480085373 0.0 16.130666732788086
logits torch.Size([390, 4, 1024]) labels torch.Size([390, 4]) 0 1023
Curr loss timestep torch.Size([390, 4]) tensor([157, 125, 371, 291], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.03001563251018524
bi 1 loss 0.02192501164972782
bi 2 loss 0.21845990419387817
bi 3 loss 0.03989444300532341
Epoch 0: :   3%|▎         | 15554/600000 [03:51<2:24:54, v_num=12, reduced_train_loss=36.50, global_step=15552.0, consumed_samples=62212.0, train_step_timing in s=0.428]Epoch 0: :   3%|▎         | 15554/600000 [03:51<2:24:54, v_num=12, reduced_train_loss=0.752, global_step=15553.0, consumed_samples=62216.0, train_step_timing in s=0.293]loss mask original None

First layer loss:  3.5965960025787354 torch.Size([604, 4]) 15.796656608581543 0.0
Max loss timestep torch.Size([604, 4]) tensor([185, 164, 386, 443], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 2.6874148845672607
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
bi 1 loss 3.0492911338806152
speech mask sum tensor(489, device='cuda:0') loss mask sum tensor(489, device='cuda:0')
bi 2 loss 3.9201390743255615
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 3 loss 4.128932476043701
speech mask sum tensor(440, device='cuda:0') loss mask sum tensor(440, device='cuda:0')
logits torch.Size([604, 4, 257024]) labels torch.Size([604, 4]) 0 257022
Layer  0  loss:  4.173731803894043 0.0 11.219234466552734
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([216, 207, 135, 244], device='cuda:0') tensor(207, device='cuda:0')
bi 0 loss 3.888845205307007
bi 1 loss 3.5954840183258057
bi 2 loss 4.682306289672852
bi 3 loss 4.501999855041504
Layer  1  loss:  4.557705879211426 0.0 10.86434268951416
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([202, 314, 369, 358], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.268657684326172
bi 1 loss 4.009797096252441
bi 2 loss 4.885368347167969
bi 3 loss 4.982069969177246
Layer  2  loss:  4.817600727081299 0.0 10.407356262207031
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([188, 431, 324, 253], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.254790782928467
bi 1 loss 4.470856666564941
bi 2 loss 5.16326379776001
bi 3 loss 5.0522141456604
Layer  3  loss:  4.985574245452881 0.0 10.15233325958252
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1020
Curr loss timestep torch.Size([604, 4]) tensor([192, 253, 233, 110], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 4.634086608886719
bi 1 loss 4.638568878173828
bi 2 loss 5.278696537017822
bi 3 loss 5.22195291519165
Layer  4  loss:  5.081064224243164 0.0 10.689401626586914
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([191, 455, 313,  81], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.6522908210754395
bi 1 loss 4.762559413909912
bi 2 loss 5.367954730987549
bi 3 loss 5.303389072418213
Layer  5  loss:  5.1019744873046875 0.0 9.918834686279297
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([215, 253, 206, 180], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.507870197296143
bi 1 loss 4.885871887207031
bi 2 loss 5.398217678070068
bi 3 loss 5.231998920440674
Layer  6  loss:  5.193269729614258 0.0 9.759594917297363
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([208, 256, 258, 190], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.81179141998291
bi 1 loss 4.899775505065918
bi 2 loss 5.576894283294678
bi 3 loss 5.310704231262207
Epoch 0: :   3%|▎         | 15555/600000 [03:51<2:25:10, v_num=12, reduced_train_loss=0.752, global_step=15553.0, consumed_samples=62216.0, train_step_timing in s=0.293]Epoch 0: :   3%|▎         | 15555/600000 [03:51<2:25:10, v_num=12, reduced_train_loss=37.50, global_step=15554.0, consumed_samples=62220.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  4.081892490386963 torch.Size([704, 4]) 14.20309829711914 0.0
Max loss timestep torch.Size([704, 4]) tensor([354, 413, 108, 513], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 4.216205596923828
speech mask sum tensor(353, device='cuda:0') loss mask sum tensor(353, device='cuda:0')
bi 1 loss 4.0558671951293945
speech mask sum tensor(481, device='cuda:0') loss mask sum tensor(481, device='cuda:0')
bi 2 loss 4.006486415863037
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 3 loss 4.034173488616943
speech mask sum tensor(431, device='cuda:0') loss mask sum tensor(431, device='cuda:0')
logits torch.Size([704, 4, 257024]) labels torch.Size([704, 4]) 0 257023
Layer  0  loss:  4.593603134155273 0.0 10.529507637023926
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1023
Curr loss timestep torch.Size([704, 4]) tensor([227, 334, 195, 526], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 4.775620460510254
bi 1 loss 4.482778549194336
bi 2 loss 4.593103885650635
bi 3 loss 4.568428039550781
Layer  1  loss:  4.831421852111816 0.0 10.733617782592773
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1022
Curr loss timestep torch.Size([704, 4]) tensor([219, 381, 222, 518], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 4.898854732513428
bi 1 loss 4.791587829589844
bi 2 loss 4.533163070678711
bi 3 loss 4.952130317687988
Layer  2  loss:  5.1333465576171875 0.0 9.963090896606445
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1022
Curr loss timestep torch.Size([704, 4]) tensor([443, 295,  99, 527], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 5.250770568847656
bi 1 loss 5.0601654052734375
bi 2 loss 5.041665077209473
bi 3 loss 5.159260272979736
Layer  3  loss:  5.206994533538818 0.0 9.469503402709961
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1022
Curr loss timestep torch.Size([704, 4]) tensor([168, 530, 205, 300], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 5.426810264587402
bi 1 loss 5.0382795333862305
bi 2 loss 5.177548885345459
bi 3 loss 5.22822904586792
Layer  4  loss:  5.252318859100342 0.0 10.276108741760254
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1022
Curr loss timestep torch.Size([704, 4]) tensor([382, 371, 240, 393], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 5.4202985763549805
bi 1 loss 5.083538055419922
bi 2 loss 5.2133660316467285
bi 3 loss 5.3202714920043945
Layer  5  loss:  5.307554244995117 0.0 9.992886543273926
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1023
Curr loss timestep torch.Size([704, 4]) tensor([274, 646, 241, 301], device='cuda:0') tensor(241, device='cuda:0')
bi 0 loss 5.404059410095215
bi 1 loss 5.177091598510742
bi 2 loss 5.192407608032227
bi 3 loss 5.424872875213623
Layer  6  loss:  5.325061798095703 0.0 9.585494995117188
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1019
Curr loss timestep torch.Size([704, 4]) tensor([269, 631, 224, 229], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 5.395794868469238
bi 1 loss 5.181526184082031
bi 2 loss 5.254258155822754
bi 3 loss 5.458529949188232
Epoch 0: :   3%|▎         | 15556/600000 [03:52<2:25:27, v_num=12, reduced_train_loss=37.50, global_step=15554.0, consumed_samples=62220.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15556/600000 [03:52<2:25:27, v_num=12, reduced_train_loss=39.70, global_step=15555.0, consumed_samples=62224.0, train_step_timing in s=0.428]loss mask original None

First layer loss:  0.11524676531553268 torch.Size([551, 4]) 11.41230583190918 0.0
Max loss timestep torch.Size([551, 4]) tensor([528, 270, 111, 375], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 0.18928368389606476
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
bi 1 loss 0.0951247289776802
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
bi 2 loss 0.04792880266904831
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 3 loss 0.10531356930732727
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
logits torch.Size([551, 4, 257024]) labels torch.Size([551, 4]) 0 257023
Layer  0  loss:  0.15793757140636444 0.0 12.04416561126709
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1023
Curr loss timestep torch.Size([551, 4]) tensor([529, 270, 102, 380], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.2548278272151947
bi 1 loss 0.17112436890602112
bi 2 loss 0.0319741927087307
bi 3 loss 0.12274541705846786
Layer  1  loss:  0.14108817279338837 0.0 9.512264251708984
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1022
Curr loss timestep torch.Size([551, 4]) tensor([528, 273,  59, 375], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 0.24343745410442352
bi 1 loss 0.12337267398834229
bi 2 loss 0.043297406286001205
bi 3 loss 0.11917878687381744
Layer  2  loss:  0.15764972567558289 0.0 13.282792091369629
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1022
Curr loss timestep torch.Size([551, 4]) tensor([326, 270, 160, 375], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.19981281459331512
bi 1 loss 0.18109320104122162
bi 2 loss 0.05168959125876427
bi 3 loss 0.1496959924697876
Layer  3  loss:  0.15356166660785675 0.0 11.528249740600586
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1023
Curr loss timestep torch.Size([551, 4]) tensor([327, 271, 104, 375], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.19156423211097717
bi 1 loss 0.17537973821163177
bi 2 loss 0.06787677854299545
bi 3 loss 0.14070206880569458
Layer  4  loss:  0.14701524376869202 0.0 14.742212295532227
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1022
Curr loss timestep torch.Size([551, 4]) tensor([528, 270, 100, 375], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.18293432891368866
bi 1 loss 0.17862020432949066
bi 2 loss 0.03829887509346008
bi 3 loss 0.13740281760692596
Layer  5  loss:  0.16434478759765625 0.0 20.28040313720703
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1021
Curr loss timestep torch.Size([551, 4]) tensor([528, 270,  58, 376], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.22045253217220306
bi 1 loss 0.2057947963476181
bi 2 loss 0.028974121436476707
bi 3 loss 0.140177920460701
Layer  6  loss:  0.1742781549692154 0.0 16.954940795898438
logits torch.Size([551, 4, 1024]) labels torch.Size([551, 4]) 0 1022
Curr loss timestep torch.Size([551, 4]) tensor([326, 271,  51, 375], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.2210858017206192
bi 1 loss 0.22023974359035492
bi 2 loss 0.027288120239973068
bi 3 loss 0.15944507718086243
Epoch 0: :   3%|▎         | 15557/600000 [03:52<2:25:42, v_num=12, reduced_train_loss=39.70, global_step=15555.0, consumed_samples=62224.0, train_step_timing in s=0.428]Epoch 0: :   3%|▎         | 15557/600000 [03:52<2:25:42, v_num=12, reduced_train_loss=1.210, global_step=15556.0, consumed_samples=62228.0, train_step_timing in s=0.378]loss mask original None

First layer loss:  0.12202916294336319 torch.Size([665, 4]) 7.755810737609863 0.0
Max loss timestep torch.Size([665, 4]) tensor([159, 110, 586, 318], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.024498431012034416
speech mask sum tensor(56, device='cuda:0') loss mask sum tensor(56, device='cuda:0')
bi 1 loss 0.045853979885578156
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
bi 2 loss 0.18911483883857727
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
bi 3 loss 0.05660456418991089
speech mask sum tensor(245, device='cuda:0') loss mask sum tensor(245, device='cuda:0')
logits torch.Size([665, 4, 257024]) labels torch.Size([665, 4]) 0 257022
Layer  0  loss:  0.15831756591796875 0.0 7.22835111618042
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1023
Curr loss timestep torch.Size([665, 4]) tensor([170, 153, 632, 321], device='cuda:0') tensor(632, device='cuda:0')
bi 0 loss 0.03135690465569496
bi 1 loss 0.03708864748477936
bi 2 loss 0.24063120782375336
bi 3 loss 0.0894538015127182
Layer  1  loss:  0.19213616847991943 0.0 15.224614143371582
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1023
Curr loss timestep torch.Size([665, 4]) tensor([167, 150, 339, 346], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.04511424899101257
bi 1 loss 0.033630408346652985
bi 2 loss 0.3147723972797394
bi 3 loss 0.07214754074811935
Layer  2  loss:  0.18915215134620667 0.0 9.954778671264648
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1022
Curr loss timestep torch.Size([665, 4]) tensor([149, 109, 549, 279], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.028489764779806137
bi 1 loss 0.07662904262542725
bi 2 loss 0.2845817506313324
bi 3 loss 0.10255833715200424
Layer  3  loss:  0.15655918419361115 0.0 11.600449562072754
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1021
Curr loss timestep torch.Size([665, 4]) tensor([172, 120, 586, 280], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.058638088405132294
bi 1 loss 0.031639907509088516
bi 2 loss 0.2444242686033249
bi 3 loss 0.0728818029165268
Layer  4  loss:  0.1657417118549347 0.0 8.070475578308105
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1022
Curr loss timestep torch.Size([665, 4]) tensor([155, 116, 632, 280], device='cuda:0') tensor(632, device='cuda:0')
bi 0 loss 0.046141915023326874
bi 1 loss 0.06117117032408714
bi 2 loss 0.25258126854896545
bi 3 loss 0.08162626624107361
Layer  5  loss:  0.20006906986236572 0.0 12.119651794433594
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1023
Curr loss timestep torch.Size([665, 4]) tensor([168, 115, 632, 273], device='cuda:0') tensor(632, device='cuda:0')
bi 0 loss 0.059884410351514816
bi 1 loss 0.030738409608602524
bi 2 loss 0.32556721568107605
bi 3 loss 0.07743456214666367
Layer  6  loss:  0.21811792254447937 0.0 13.106219291687012
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1022
Curr loss timestep torch.Size([665, 4]) tensor([173, 146, 586, 273], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.05019113048911095
bi 1 loss 0.03686555102467537
bi 2 loss 0.3493429720401764
bi 3 loss 0.09623850882053375
Epoch 0: :   3%|▎         | 15558/600000 [03:53<2:26:00, v_num=12, reduced_train_loss=1.210, global_step=15556.0, consumed_samples=62228.0, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15558/600000 [03:53<2:26:00, v_num=12, reduced_train_loss=1.400, global_step=15557.0, consumed_samples=62232.0, train_step_timing in s=0.456]loss mask original None

First layer loss:  0.11979574710130692 torch.Size([583, 4]) 12.946438789367676 0.0
Max loss timestep torch.Size([583, 4]) tensor([364, 395, 101, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.10355853289365768
speech mask sum tensor(457, device='cuda:0') loss mask sum tensor(457, device='cuda:0')
bi 1 loss 0.13513773679733276
speech mask sum tensor(350, device='cuda:0') loss mask sum tensor(350, device='cuda:0')
bi 2 loss 0.040844909846782684
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 3 loss 0.13719303905963898
speech mask sum tensor(490, device='cuda:0') loss mask sum tensor(490, device='cuda:0')
logits torch.Size([583, 4, 257024]) labels torch.Size([583, 4]) 0 257022
Layer  0  loss:  0.13099956512451172 0.0 11.826171875
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([364, 260, 100, 319], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.09528350830078125
bi 1 loss 0.11223706603050232
bi 2 loss 0.04474404826760292
bi 3 loss 0.1921466439962387
Layer  1  loss:  0.1223900243639946 0.0 14.019716262817383
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([393, 260, 121, 319], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.08094991743564606
bi 1 loss 0.12936395406723022
bi 2 loss 0.026219487190246582
bi 3 loss 0.17215174436569214
Layer  2  loss:  0.1593339741230011 0.0 13.62531852722168
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([366, 260,  99, 319], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.14300537109375
bi 1 loss 0.1392345279455185
bi 2 loss 0.048965100198984146
bi 3 loss 0.20738954842090607
Layer  3  loss:  0.14406079053878784 0.0 10.774235725402832
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([364, 260, 136, 321], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.13003462553024292
bi 1 loss 0.1373787820339203
bi 2 loss 0.02683672308921814
bi 3 loss 0.18153229355812073
Layer  4  loss:  0.15248830616474152 0.0 14.11313247680664
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([364, 260, 102, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.13036063313484192
bi 1 loss 0.14982368052005768
bi 2 loss 0.03986614942550659
bi 3 loss 0.19387602806091309
Layer  5  loss:  0.17512398958206177 0.0 18.223045349121094
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([364, 260, 126, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.11893521249294281
bi 1 loss 0.17289040982723236
bi 2 loss 0.029132403433322906
bi 3 loss 0.2535552680492401
Layer  6  loss:  0.15083728730678558 0.0 11.626144409179688
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([364, 260,  95, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.12205934524536133
bi 1 loss 0.1339103728532791
bi 2 loss 0.019244737923145294
bi 3 loss 0.21178942918777466
Epoch 0: :   3%|▎         | 15559/600000 [03:53<2:26:16, v_num=12, reduced_train_loss=1.400, global_step=15557.0, consumed_samples=62232.0, train_step_timing in s=0.456]Epoch 0: :   3%|▎         | 15559/600000 [03:53<2:26:16, v_num=12, reduced_train_loss=1.160, global_step=15558.0, consumed_samples=62236.0, train_step_timing in s=0.403]loss mask original None

First layer loss:  3.9953956604003906 torch.Size([708, 4]) 16.428836822509766 0.0
Max loss timestep torch.Size([708, 4]) tensor([378, 623, 335, 302], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 3.5969455242156982
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 1 loss 4.8103251457214355
speech mask sum tensor(484, device='cuda:0') loss mask sum tensor(484, device='cuda:0')
bi 2 loss 3.229243040084839
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
bi 3 loss 2.9791736602783203
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([708, 4, 257024]) labels torch.Size([708, 4]) 0 257021
Layer  0  loss:  4.531200885772705 0.0 10.560914993286133
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([336, 448, 178, 360], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 4.2443342208862305
bi 1 loss 5.113480567932129
bi 2 loss 4.016232013702393
bi 3 loss 3.7206637859344482
Layer  1  loss:  4.61792516708374 0.0 9.753753662109375
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([301, 285, 336, 299], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 4.373366355895996
bi 1 loss 5.186092376708984
bi 2 loss 4.046177864074707
bi 3 loss 3.9432599544525146
Layer  2  loss:  4.853688716888428 0.0 9.689533233642578
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([245, 617, 368, 324], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 4.467879295349121
bi 1 loss 5.309203624725342
bi 2 loss 4.620152950286865
bi 3 loss 4.091366291046143
Layer  3  loss:  4.950286865234375 0.0 10.770528793334961
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([401, 389, 312, 366], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 4.639158725738525
bi 1 loss 5.402745246887207
bi 2 loss 4.639165878295898
bi 3 loss 4.260004043579102
Layer  4  loss:  5.079586029052734 0.0 10.482680320739746
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([252, 688, 388, 349], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 4.834353923797607
bi 1 loss 5.521730422973633
bi 2 loss 4.838195323944092
bi 3 loss 4.111102104187012
Layer  5  loss:  5.1132941246032715 0.0 9.567129135131836
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([305, 460, 194, 324], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 4.83018159866333
bi 1 loss 5.52195930480957
bi 2 loss 4.935863971710205
bi 3 loss 4.210383415222168
Layer  6  loss:  5.216762542724609 0.0 9.758986473083496
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([331, 445, 155, 305], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 4.961563587188721
bi 1 loss 5.664814472198486
bi 2 loss 4.943619251251221
bi 3 loss 4.327415466308594
Epoch 0: :   3%|▎         | 15560/600000 [03:54<2:26:33, v_num=12, reduced_train_loss=1.160, global_step=15558.0, consumed_samples=62236.0, train_step_timing in s=0.403]Epoch 0: :   3%|▎         | 15560/600000 [03:54<2:26:33, v_num=12, reduced_train_loss=38.40, global_step=15559.0, consumed_samples=62240.0, train_step_timing in s=0.435]loss mask original None

First layer loss:  3.8139965534210205 torch.Size([608, 4]) 11.939003944396973 0.0
Max loss timestep torch.Size([608, 4]) tensor([453, 153, 481, 217], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 3.5304765701293945
speech mask sum tensor(470, device='cuda:0') loss mask sum tensor(470, device='cuda:0')
bi 1 loss 3.514049530029297
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 2 loss 4.0032148361206055
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
bi 3 loss 4.223132610321045
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
logits torch.Size([608, 4, 257024]) labels torch.Size([608, 4]) 0 257023
Layer  0  loss:  4.287704944610596 0.0 9.527619361877441
logits torch.Size([608, 4, 1024]) labels torch.Size([608, 4]) 0 1023
Curr loss timestep torch.Size([608, 4]) tensor([324,  97, 396, 250], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 4.13723087310791
bi 1 loss 4.119868278503418
bi 2 loss 4.283702850341797
bi 3 loss 4.766396522521973
Layer  1  loss:  4.7251811027526855 0.0 10.517889022827148
logits torch.Size([608, 4, 1024]) labels torch.Size([608, 4]) 0 1022
Curr loss timestep torch.Size([608, 4]) tensor([436, 164, 331, 141], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 4.631591796875
bi 1 loss 4.415215492248535
bi 2 loss 4.647952556610107
bi 3 loss 5.317795753479004
Layer  2  loss:  5.039229393005371 0.0 10.416958808898926
logits torch.Size([608, 4, 1024]) labels torch.Size([608, 4]) 0 1022
Curr loss timestep torch.Size([608, 4]) tensor([469, 118, 553, 146], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 4.996531009674072
bi 1 loss 4.674379825592041
bi 2 loss 5.008254051208496
bi 3 loss 5.419797897338867
Layer  3  loss:  5.151144981384277 0.0 10.355265617370605
logits torch.Size([608, 4, 1024]) labels torch.Size([608, 4]) 0 1023
Curr loss timestep torch.Size([608, 4]) tensor([346, 159, 527, 242], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 5.083384990692139
bi 1 loss 4.647799968719482
bi 2 loss 5.2072296142578125
bi 3 loss 5.455350875854492
Layer  4  loss:  5.256658554077148 0.0 10.488153457641602
logits torch.Size([608, 4, 1024]) labels torch.Size([608, 4]) 0 1022
Curr loss timestep torch.Size([608, 4]) tensor([495, 120, 256, 220], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 5.160586357116699
bi 1 loss 4.895917892456055
bi 2 loss 5.2771100997924805
bi 3 loss 5.642655372619629
Layer  5  loss:  5.305455684661865 0.0 9.436944961547852
logits torch.Size([608, 4, 1024]) labels torch.Size([608, 4]) 0 1023
Curr loss timestep torch.Size([608, 4]) tensor([430, 142, 275, 269], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 5.191327095031738
bi 1 loss 4.963249683380127
bi 2 loss 5.3283796310424805
bi 3 loss 5.720739841461182
Layer  6  loss:  5.4198832511901855 0.0 10.013704299926758
logits torch.Size([608, 4, 1024]) labels torch.Size([608, 4]) 0 1019
Curr loss timestep torch.Size([608, 4]) tensor([387, 108, 453, 173], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 5.313161849975586
bi 1 loss 4.990370273590088
bi 2 loss 5.43328857421875
bi 3 loss 5.887121677398682
Epoch 0: :   3%|▎         | 15561/600000 [03:54<2:26:48, v_num=12, reduced_train_loss=38.40, global_step=15559.0, consumed_samples=62240.0, train_step_timing in s=0.435]Epoch 0: :   3%|▎         | 15561/600000 [03:54<2:26:48, v_num=12, reduced_train_loss=39.00, global_step=15560.0, consumed_samples=62244.0, train_step_timing in s=0.386]loss mask original None

First layer loss:  0.10663041472434998 torch.Size([565, 4]) 14.965404510498047 0.0
Max loss timestep torch.Size([565, 4]) tensor([133, 501, 105, 255], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.04270968213677406
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 1 loss 0.11849324405193329
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
bi 2 loss 0.19574648141860962
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 3 loss 0.06468547880649567
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([565, 4, 257024]) labels torch.Size([565, 4]) 0 257022
Layer  0  loss:  0.06267111748456955 0.0 6.449756145477295
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([206, 500, 178, 336], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.03164010867476463
bi 1 loss 0.07845966517925262
bi 2 loss 0.04640600457787514
bi 3 loss 0.06594263762235641
Layer  1  loss:  0.09436489641666412 0.0 7.50518798828125
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([189, 501, 128, 274], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.026108836755156517
bi 1 loss 0.12302680313587189
bi 2 loss 0.06890298426151276
bi 3 loss 0.10852114111185074
Layer  2  loss:  0.07795922458171844 0.0 6.731141567230225
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([115, 500, 134, 257], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.041297126561403275
bi 1 loss 0.10693877190351486
bi 2 loss 0.04259243607521057
bi 3 loss 0.06881406158208847
Layer  3  loss:  0.0644504576921463 0.0 5.764181613922119
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([165, 501, 173, 311], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.03474266082048416
bi 1 loss 0.07501576095819473
bi 2 loss 0.05693929269909859
bi 3 loss 0.07253430783748627
Layer  4  loss:  0.09588503837585449 0.0 9.58585262298584
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([200, 539,  96, 311], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.02688983641564846
bi 1 loss 0.1375555396080017
bi 2 loss 0.07194432616233826
bi 3 loss 0.07627718150615692
Layer  5  loss:  0.0833212360739708 0.0 13.812664031982422
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([144, 501, 142, 311], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.03550000488758087
bi 1 loss 0.11163397878408432
bi 2 loss 0.06117243692278862
bi 3 loss 0.07578134536743164
Layer  6  loss:  0.09924991428852081 0.0 10.011543273925781
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1020
Curr loss timestep torch.Size([565, 4]) tensor([166, 501, 116, 280], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.039950598031282425
bi 1 loss 0.1536361426115036
bi 2 loss 0.03197763115167618
bi 3 loss 0.07359954714775085
Epoch 0: :   3%|▎         | 15562/600000 [03:54<2:27:04, v_num=12, reduced_train_loss=39.00, global_step=15560.0, consumed_samples=62244.0, train_step_timing in s=0.386]Epoch 0: :   3%|▎         | 15562/600000 [03:54<2:27:04, v_num=12, reduced_train_loss=0.685, global_step=15561.0, consumed_samples=62248.0, train_step_timing in s=0.391]loss mask original None

First layer loss:  0.06978792697191238 torch.Size([413, 4]) 7.878204822540283 0.0
Max loss timestep torch.Size([413, 4]) tensor([321, 134, 270, 278], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.05883904546499252
speech mask sum tensor(261, device='cuda:0') loss mask sum tensor(261, device='cuda:0')
bi 1 loss 0.014688747003674507
speech mask sum tensor(174, device='cuda:0') loss mask sum tensor(174, device='cuda:0')
bi 2 loss 0.15692947804927826
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 3 loss 0.06426869332790375
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
logits torch.Size([413, 4, 257024]) labels torch.Size([413, 4]) 0 257023
Layer  0  loss:  0.05853697657585144 0.0 5.024782657623291
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1023
Curr loss timestep torch.Size([413, 4]) tensor([363, 221, 270, 219], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.04979277029633522
bi 1 loss 0.0062483204528689384
bi 2 loss 0.12453602999448776
bi 3 loss 0.06308435648679733
Layer  1  loss:  0.06712847948074341 0.0 11.032172203063965
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([328, 222, 270, 172], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.055356334894895554
bi 1 loss 0.024471089243888855
bi 2 loss 0.17345982789993286
bi 3 loss 0.0394538976252079
Layer  2  loss:  0.06699825078248978 0.0 3.110506534576416
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([321, 104, 270, 139], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.06614391505718231
bi 1 loss 0.02726743370294571
bi 2 loss 0.15523606538772583
bi 3 loss 0.0370107963681221
Layer  3  loss:  0.06548752635717392 0.0 4.343556880950928
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1018
Curr loss timestep torch.Size([413, 4]) tensor([204, 134, 270, 283], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.07649625837802887
bi 1 loss 0.014836790971457958
bi 2 loss 0.1552414745092392
bi 3 loss 0.029097259044647217
Layer  4  loss:  0.08352548629045486 0.0 13.04716682434082
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([293, 211, 270, 281], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.05298101529479027
bi 1 loss 0.01763404905796051
bi 2 loss 0.2518099546432495
bi 3 loss 0.05234941467642784
Layer  5  loss:  0.07738376408815384 0.0 9.772092819213867
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([293, 100, 270, 135], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.04853631928563118
bi 1 loss 0.02222394198179245
bi 2 loss 0.22988544404506683
bi 3 loss 0.04695621877908707
Layer  6  loss:  0.08508946001529694 0.0 8.24392318725586
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([324, 124, 270, 135], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.05356075242161751
bi 1 loss 0.019910262897610664
bi 2 loss 0.2619401216506958
bi 3 loss 0.04850292205810547
Epoch 0: :   3%|▎         | 15563/600000 [03:55<2:27:16, v_num=12, reduced_train_loss=0.685, global_step=15561.0, consumed_samples=62248.0, train_step_timing in s=0.391]Epoch 0: :   3%|▎         | 15563/600000 [03:55<2:27:16, v_num=12, reduced_train_loss=0.574, global_step=15562.0, consumed_samples=62252.0, train_step_timing in s=0.306]loss mask original None

First layer loss:  0.1433253288269043 torch.Size([607, 4]) 17.011924743652344 0.0
Max loss timestep torch.Size([607, 4]) tensor([499, 331, 451, 297], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.20577934384346008
speech mask sum tensor(450, device='cuda:0') loss mask sum tensor(450, device='cuda:0')
bi 1 loss 0.1188061460852623
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
bi 2 loss 0.10806279629468918
speech mask sum tensor(479, device='cuda:0') loss mask sum tensor(479, device='cuda:0')
bi 3 loss 0.10617426037788391
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
logits torch.Size([607, 4, 257024]) labels torch.Size([607, 4]) 0 257023
Layer  0  loss:  0.17386719584465027 0.0 18.461273193359375
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([387, 331, 522, 315], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.29875093698501587
bi 1 loss 0.11772491037845612
bi 2 loss 0.11707060784101486
bi 3 loss 0.0672682374715805
Layer  1  loss:  0.16707177460193634 0.0 18.829675674438477
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([499, 293, 521, 246], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.26483625173568726
bi 1 loss 0.07828397303819656
bi 2 loss 0.13608667254447937
bi 3 loss 0.10691802203655243
Layer  2  loss:  0.2040959596633911 0.0 15.811683654785156
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([498, 331, 521, 297], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.2982173264026642
bi 1 loss 0.1446252167224884
bi 2 loss 0.15619446337223053
bi 3 loss 0.16456110775470734
Layer  3  loss:  0.23080535233020782 0.0 18.1647891998291
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1021
Curr loss timestep torch.Size([607, 4]) tensor([260, 331, 461, 297], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.35402923822402954
bi 1 loss 0.15426114201545715
bi 2 loss 0.1854960024356842
bi 3 loss 0.1230023130774498
Layer  4  loss:  0.21533696353435516 0.0 18.205228805541992
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([261, 331, 525, 297], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.32587578892707825
bi 1 loss 0.15471461415290833
bi 2 loss 0.1654212921857834
bi 3 loss 0.1357688158750534
Layer  5  loss:  0.21133378148078918 0.0 14.988268852233887
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([500, 331, 521, 297], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.30822402238845825
bi 1 loss 0.13758447766304016
bi 2 loss 0.17935825884342194
bi 3 loss 0.13494107127189636
Layer  6  loss:  0.21919845044612885 0.0 16.946353912353516
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([261, 331, 521, 297], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.34328749775886536
bi 1 loss 0.13039539754390717
bi 2 loss 0.1805144101381302
bi 3 loss 0.10609136521816254
Epoch 0: :   3%|▎         | 15564/600000 [03:55<2:27:33, v_num=12, reduced_train_loss=0.574, global_step=15562.0, consumed_samples=62252.0, train_step_timing in s=0.306]Epoch 0: :   3%|▎         | 15564/600000 [03:55<2:27:33, v_num=12, reduced_train_loss=1.570, global_step=15563.0, consumed_samples=62256.0, train_step_timing in s=0.421]loss mask original None

First layer loss:  0.3303981125354767 torch.Size([651, 4]) 13.380796432495117 0.0
Max loss timestep torch.Size([651, 4]) tensor([279, 576, 565, 352], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.20290763676166534
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 1 loss 0.5620310306549072
speech mask sum tensor(492, device='cuda:0') loss mask sum tensor(492, device='cuda:0')
bi 2 loss 0.3350374102592468
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 3 loss 0.18196828663349152
speech mask sum tensor(356, device='cuda:0') loss mask sum tensor(356, device='cuda:0')
logits torch.Size([651, 4, 257024]) labels torch.Size([651, 4]) 0 257023
Layer  0  loss:  0.39877352118492126 0.0 19.43839454650879
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([278, 530, 565, 385], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.33123138546943665
bi 1 loss 0.6202064156532288
bi 2 loss 0.3935491144657135
bi 3 loss 0.19175651669502258
Layer  1  loss:  0.46813708543777466 0.0 19.2055606842041
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([278, 390, 570, 352], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.3655105531215668
bi 1 loss 0.733505129814148
bi 2 loss 0.4979369044303894
bi 3 loss 0.21229006350040436
Layer  2  loss:  0.47977349162101746 0.0 15.601975440979004
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([279, 455, 551, 384], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.3776564598083496
bi 1 loss 0.761003315448761
bi 2 loss 0.5027260184288025
bi 3 loss 0.20847375690937042
Layer  3  loss:  0.47137969732284546 0.0 13.770329475402832
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([279, 466, 565, 385], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.37872108817100525
bi 1 loss 0.7046228647232056
bi 2 loss 0.5192423462867737
bi 3 loss 0.22720088064670563
Layer  4  loss:  0.4916021525859833 0.0 15.88385009765625
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([280, 442, 565, 259], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.4609631597995758
bi 1 loss 0.6986007690429688
bi 2 loss 0.5085428953170776
bi 3 loss 0.23020535707473755
Layer  5  loss:  0.45452895760536194 0.0 19.5799560546875
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([280, 455, 558, 385], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.3013054430484772
bi 1 loss 0.7793399095535278
bi 2 loss 0.5255818963050842
bi 3 loss 0.14337565004825592
Layer  6  loss:  0.4863468110561371 0.0 18.161285400390625
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([280, 456, 565, 384], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 0.4323899745941162
bi 1 loss 0.7262209057807922
bi 2 loss 0.5083468556404114
bi 3 loss 0.20650586485862732
Epoch 0: :   3%|▎         | 15565/600000 [03:56<2:27:51, v_num=12, reduced_train_loss=1.570, global_step=15563.0, consumed_samples=62256.0, train_step_timing in s=0.421]Epoch 0: :   3%|▎         | 15565/600000 [03:56<2:27:51, v_num=12, reduced_train_loss=3.580, global_step=15564.0, consumed_samples=62260.0, train_step_timing in s=0.449]loss mask original None

First layer loss:  0.17271478474140167 torch.Size([642, 4]) 10.747357368469238 0.0
Max loss timestep torch.Size([642, 4]) tensor([300, 530, 363, 581], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.09237350523471832
speech mask sum tensor(150, device='cuda:0') loss mask sum tensor(150, device='cuda:0')
bi 1 loss 0.12860353291034698
speech mask sum tensor(431, device='cuda:0') loss mask sum tensor(431, device='cuda:0')
bi 2 loss 0.18033601343631744
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
bi 3 loss 0.2405340075492859
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
logits torch.Size([642, 4, 257024]) labels torch.Size([642, 4]) 0 257022
Layer  0  loss:  0.22318622469902039 0.0 13.435833930969238
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([301, 504, 362, 581], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.07223677635192871
bi 1 loss 0.24495075643062592
bi 2 loss 0.21073265373706818
bi 3 loss 0.266262024641037
Layer  1  loss:  0.24040859937667847 0.0 12.820128440856934
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([201, 505, 348, 582], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.11813369393348694
bi 1 loss 0.2561960816383362
bi 2 loss 0.2092152088880539
bi 3 loss 0.2961854636669159
Layer  2  loss:  0.23426780104637146 0.0 14.500322341918945
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([301, 504, 363, 519], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.0605318658053875
bi 1 loss 0.2503664493560791
bi 2 loss 0.2222006916999817
bi 3 loss 0.2910826504230499
Layer  3  loss:  0.25139784812927246 0.0 13.779189109802246
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1022
Curr loss timestep torch.Size([642, 4]) tensor([287, 504, 363, 519], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.08675174415111542
bi 1 loss 0.27798157930374146
bi 2 loss 0.21897226572036743
bi 3 loss 0.312375009059906
Layer  4  loss:  0.22709636390209198 0.0 14.275148391723633
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([300, 504, 362, 581], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.09814899414777756
bi 1 loss 0.23108232021331787
bi 2 loss 0.2212774157524109
bi 3 loss 0.2746935486793518
Layer  5  loss:  0.23808583617210388 0.0 13.68836498260498
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1023
Curr loss timestep torch.Size([642, 4]) tensor([300, 504, 363, 519], device='cuda:0') tensor(504, device='cuda:0')
bi 0 loss 0.07493516802787781
bi 1 loss 0.2594875991344452
bi 2 loss 0.1831849068403244
bi 3 loss 0.32409876585006714
Layer  6  loss:  0.22589610517024994 0.0 12.609247207641602
logits torch.Size([642, 4, 1024]) labels torch.Size([642, 4]) 0 1022
Curr loss timestep torch.Size([642, 4]) tensor([295, 505, 348, 582], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.08913826942443848
bi 1 loss 0.2730739414691925
bi 2 loss 0.18620222806930542
bi 3 loss 0.2620151937007904
Epoch 0: :   3%|▎         | 15566/600000 [03:56<2:28:08, v_num=12, reduced_train_loss=3.580, global_step=15564.0, consumed_samples=62260.0, train_step_timing in s=0.449]Epoch 0: :   3%|▎         | 15566/600000 [03:56<2:28:08, v_num=12, reduced_train_loss=1.810, global_step=15565.0, consumed_samples=62264.0, train_step_timing in s=0.443]loss mask original None

First layer loss:  0.09868971258401871 torch.Size([598, 4]) 7.819738864898682 0.0
Max loss timestep torch.Size([598, 4]) tensor([279,  50, 435, 485], device='cuda:0') tensor(485, device='cuda:0')
bi 0 loss 0.0468689426779747
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 1 loss 0.05193895846605301
speech mask sum tensor(89, device='cuda:0') loss mask sum tensor(89, device='cuda:0')
bi 2 loss 0.07677826285362244
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
bi 3 loss 0.14216706156730652
speech mask sum tensor(404, device='cuda:0') loss mask sum tensor(404, device='cuda:0')
logits torch.Size([598, 4, 257024]) labels torch.Size([598, 4]) 0 257022
Layer  0  loss:  0.11370914429426193 0.0 4.727825164794922
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([247,  34, 367, 534], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.030024871230125427
bi 1 loss 0.043565455824136734
bi 2 loss 0.0667295828461647
bi 3 loss 0.19086289405822754
Layer  1  loss:  0.10880985856056213 0.0 9.522743225097656
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1023
Curr loss timestep torch.Size([598, 4]) tensor([279,  79, 315, 534], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.06140637397766113
bi 1 loss 0.025709163397550583
bi 2 loss 0.06149580329656601
bi 3 loss 0.17656956613063812
Layer  2  loss:  0.14939342439174652 0.0 8.49536418914795
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1022
Curr loss timestep torch.Size([598, 4]) tensor([281,  76, 308, 534], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.08675672858953476
bi 1 loss 0.03404039889574051
bi 2 loss 0.10615383088588715
bi 3 loss 0.22664521634578705
Layer  3  loss:  0.12878097593784332 0.0 8.793585777282715
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1021
Curr loss timestep torch.Size([598, 4]) tensor([279,  52, 310, 581], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.08812780678272247
bi 1 loss 0.02129705436527729
bi 2 loss 0.05768889933824539
bi 3 loss 0.2162461280822754
Layer  4  loss:  0.1352768987417221 0.0 5.749856472015381
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1022
Curr loss timestep torch.Size([598, 4]) tensor([279,  71, 310, 581], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.07269357889890671
bi 1 loss 0.04216967895627022
bi 2 loss 0.09232841432094574
bi 3 loss 0.20740574598312378
Layer  5  loss:  0.14117754995822906 0.0 7.550654888153076
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1022
Curr loss timestep torch.Size([598, 4]) tensor([279,  57, 346, 534], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.056153036653995514
bi 1 loss 0.033156465739011765
bi 2 loss 0.05940643697977066
bi 3 loss 0.25150805711746216
Layer  6  loss:  0.13488830626010895 0.0 5.066320419311523
logits torch.Size([598, 4, 1024]) labels torch.Size([598, 4]) 0 1021
Curr loss timestep torch.Size([598, 4]) tensor([276,  85, 277, 388], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.026539986953139305
bi 1 loss 0.029683204367756844
bi 2 loss 0.059113021939992905
bi 3 loss 0.24842317402362823
Epoch 0: :   3%|▎         | 15567/600000 [03:57<2:28:24, v_num=12, reduced_train_loss=1.810, global_step=15565.0, consumed_samples=62264.0, train_step_timing in s=0.443]Epoch 0: :   3%|▎         | 15567/600000 [03:57<2:28:24, v_num=12, reduced_train_loss=1.010, global_step=15566.0, consumed_samples=62268.0, train_step_timing in s=0.412]loss mask original None

First layer loss:  0.053046584129333496 torch.Size([529, 4]) 6.004421234130859 0.0
Max loss timestep torch.Size([529, 4]) tensor([ 94, 317, 104, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.018853606656193733
speech mask sum tensor(125, device='cuda:0') loss mask sum tensor(125, device='cuda:0')
bi 1 loss 0.04472338408231735
speech mask sum tensor(261, device='cuda:0') loss mask sum tensor(261, device='cuda:0')
bi 2 loss 0.059849392622709274
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 3 loss 0.06822776049375534
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
logits torch.Size([529, 4, 257024]) labels torch.Size([529, 4]) 0 257022
Layer  0  loss:  0.05411617457866669 0.0 8.116676330566406
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([179, 402, 122, 311], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.011801348999142647
bi 1 loss 0.032285626977682114
bi 2 loss 0.027398480102419853
bi 3 loss 0.09156597405672073
Layer  1  loss:  0.0604826882481575 0.0 5.946178913116455
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1019
Curr loss timestep torch.Size([529, 4]) tensor([142, 291, 139, 357], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.05069606751203537
bi 1 loss 0.04141468554735184
bi 2 loss 0.026487652212381363
bi 3 loss 0.08733166009187698
Layer  2  loss:  0.07507738471031189 0.0 9.920504570007324
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([173, 257, 116, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.026535870507359505
bi 1 loss 0.04356006905436516
bi 2 loss 0.04105720669031143
bi 3 loss 0.12357465922832489
Layer  3  loss:  0.0720873475074768 0.0 10.385311126708984
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([184, 453, 156, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.016328372061252594
bi 1 loss 0.03973674029111862
bi 2 loss 0.030587486922740936
bi 3 loss 0.12583832442760468
Layer  4  loss:  0.06111379340291023 0.0 8.973855972290039
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([179, 461, 146, 357], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.01713874377310276
bi 1 loss 0.03583604842424393
bi 2 loss 0.028113143518567085
bi 3 loss 0.10342247039079666
Layer  5  loss:  0.0793677270412445 0.0 5.7875213623046875
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([126, 405, 112, 357], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.024135772138834
bi 1 loss 0.03584165871143341
bi 2 loss 0.026374686509370804
bi 3 loss 0.14421401917934418
Layer  6  loss:  0.06809558719396591 0.0 8.700491905212402
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([ 93, 383, 118, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.015250379219651222
bi 1 loss 0.03826982527971268
bi 2 loss 0.026218900457024574
bi 3 loss 0.11922457814216614
Epoch 0: :   3%|▎         | 15568/600000 [03:57<2:28:39, v_num=12, reduced_train_loss=1.010, global_step=15566.0, consumed_samples=62268.0, train_step_timing in s=0.412]Epoch 0: :   3%|▎         | 15568/600000 [03:57<2:28:39, v_num=12, reduced_train_loss=0.523, global_step=15567.0, consumed_samples=62272.0, train_step_timing in s=0.384]loss mask original None

First layer loss:  0.0762718990445137 torch.Size([441, 4]) 8.545831680297852 0.0
Max loss timestep torch.Size([441, 4]) tensor([315, 400, 290, 327], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.14593437314033508
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
bi 1 loss 0.10958356410264969
speech mask sum tensor(346, device='cuda:0') loss mask sum tensor(346, device='cuda:0')
bi 2 loss 0.03360041603446007
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 3 loss 0.054536353796720505
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
logits torch.Size([441, 4, 257024]) labels torch.Size([441, 4]) 0 257023
Layer  0  loss:  0.10721108317375183 0.0 9.820642471313477
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([276, 400, 254, 332], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.22123876214027405
bi 1 loss 0.1632106900215149
bi 2 loss 0.0427396222949028
bi 3 loss 0.05633920431137085
Layer  1  loss:  0.09534858167171478 0.0 12.55634880065918
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1022
Curr loss timestep torch.Size([441, 4]) tensor([316, 396, 356, 354], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.10615529865026474
bi 1 loss 0.17056941986083984
bi 2 loss 0.03836693987250328
bi 3 loss 0.04927121102809906
Layer  2  loss:  0.08512096107006073 0.0 12.201787948608398
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1022
Curr loss timestep torch.Size([441, 4]) tensor([316, 396, 286, 329], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.09901916235685349
bi 1 loss 0.14785335958003998
bi 2 loss 0.038784824311733246
bi 3 loss 0.041004180908203125
Layer  3  loss:  0.10470461845397949 0.0 15.500052452087402
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([316, 397, 288, 284], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.13697253167629242
bi 1 loss 0.19184182584285736
bi 2 loss 0.03445253521203995
bi 3 loss 0.048541292548179626
Layer  4  loss:  0.08452944457530975 0.0 10.28346061706543
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([276, 396, 379, 239], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.13689179718494415
bi 1 loss 0.12991952896118164
bi 2 loss 0.04081657901406288
bi 3 loss 0.049091462045907974
Layer  5  loss:  0.11133337765932083 0.0 14.564728736877441
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([316, 396, 374, 361], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.1533564180135727
bi 1 loss 0.19248957931995392
bi 2 loss 0.03784815967082977
bi 3 loss 0.06960300356149673
Layer  6  loss:  0.07787228375673294 0.0 9.454853057861328
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1021
Curr loss timestep torch.Size([441, 4]) tensor([284, 397, 345, 355], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.08259564638137817
bi 1 loss 0.13956330716609955
bi 2 loss 0.03009270690381527
bi 3 loss 0.044999249279499054
Epoch 0: :   3%|▎         | 15569/600000 [03:57<2:28:52, v_num=12, reduced_train_loss=0.523, global_step=15567.0, consumed_samples=62272.0, train_step_timing in s=0.384]Epoch 0: :   3%|▎         | 15569/600000 [03:57<2:28:52, v_num=12, reduced_train_loss=0.742, global_step=15568.0, consumed_samples=62276.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  3.3505172729492188 torch.Size([724, 4]) 11.172776222229004 0.0
Max loss timestep torch.Size([724, 4]) tensor([267, 197, 541, 246], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 3.699188232421875
speech mask sum tensor(273, device='cuda:0') loss mask sum tensor(273, device='cuda:0')
bi 1 loss 3.28822922706604
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
bi 2 loss 3.217629909515381
speech mask sum tensor(483, device='cuda:0') loss mask sum tensor(483, device='cuda:0')
bi 3 loss 3.322542667388916
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
logits torch.Size([724, 4, 257024]) labels torch.Size([724, 4]) 0 257023
Layer  0  loss:  3.886460781097412 0.0 11.5004301071167
logits torch.Size([724, 4, 1024]) labels torch.Size([724, 4]) 0 1023
Curr loss timestep torch.Size([724, 4]) tensor([410, 112, 472, 201], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 4.33513879776001
bi 1 loss 4.019327163696289
bi 2 loss 3.6386284828186035
bi 3 loss 3.781259298324585
Layer  1  loss:  4.235663890838623 0.0 11.64000129699707
logits torch.Size([724, 4, 1024]) labels torch.Size([724, 4]) 0 1023
Curr loss timestep torch.Size([724, 4]) tensor([345, 123, 662, 474], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 4.518609046936035
bi 1 loss 4.1928277015686035
bi 2 loss 4.046374797821045
bi 3 loss 4.301361083984375
Layer  2  loss:  4.496741771697998 0.0 11.190526962280273
logits torch.Size([724, 4, 1024]) labels torch.Size([724, 4]) 0 1022
Curr loss timestep torch.Size([724, 4]) tensor([425, 284, 596, 471], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 4.710116386413574
bi 1 loss 4.504124164581299
bi 2 loss 4.27471923828125
bi 3 loss 4.608456611633301
Layer  3  loss:  4.562446117401123 0.0 10.86821460723877
logits torch.Size([724, 4, 1024]) labels torch.Size([724, 4]) 0 1022
Curr loss timestep torch.Size([724, 4]) tensor([357, 225, 666, 418], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 4.68032169342041
bi 1 loss 4.647254467010498
bi 2 loss 4.392580032348633
bi 3 loss 4.618844032287598
Layer  4  loss:  4.680472373962402 0.0 10.322932243347168
logits torch.Size([724, 4, 1024]) labels torch.Size([724, 4]) 0 1022
Curr loss timestep torch.Size([724, 4]) tensor([403, 327, 534, 404], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 4.913926601409912
bi 1 loss 4.751486778259277
bi 2 loss 4.450709819793701
bi 3 loss 4.740825176239014
Layer  5  loss:  4.905885219573975 0.0 12.692095756530762
logits torch.Size([724, 4, 1024]) labels torch.Size([724, 4]) 0 1022
Curr loss timestep torch.Size([724, 4]) tensor([260, 164, 539, 295], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 5.149068355560303
bi 1 loss 4.8883795738220215
bi 2 loss 4.699516773223877
bi 3 loss 4.998500823974609
Layer  6  loss:  4.829928874969482 0.0 11.611579895019531
logits torch.Size([724, 4, 1024]) labels torch.Size([724, 4]) 0 1022
Curr loss timestep torch.Size([724, 4]) tensor([341, 162, 581, 550], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 5.003620624542236
bi 1 loss 4.72812032699585
bi 2 loss 4.671630382537842
bi 3 loss 4.974907398223877
Epoch 0: :   3%|▎         | 15570/600000 [03:58<2:29:09, v_num=12, reduced_train_loss=0.742, global_step=15568.0, consumed_samples=62276.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15570/600000 [03:58<2:29:10, v_num=12, reduced_train_loss=34.90, global_step=15569.0, consumed_samples=62280.0, train_step_timing in s=0.445]loss mask original None

First layer loss:  0.09900769591331482 torch.Size([621, 4]) 7.149479866027832 0.0
Max loss timestep torch.Size([621, 4]) tensor([ 34, 566, 300, 183], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.021674806252121925
speech mask sum tensor(51, device='cuda:0') loss mask sum tensor(51, device='cuda:0')
bi 1 loss 0.1232394203543663
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
bi 2 loss 0.10221116989850998
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
bi 3 loss 0.06442216038703918
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
logits torch.Size([621, 4, 257024]) labels torch.Size([621, 4]) 0 257021
Layer  0  loss:  0.1017695739865303 0.0 9.135819435119629
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1023
Curr loss timestep torch.Size([621, 4]) tensor([ 45, 590, 300, 256], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.015627816319465637
bi 1 loss 0.12519539892673492
bi 2 loss 0.1203528493642807
bi 3 loss 0.05700855702161789
Layer  1  loss:  0.09764108061790466 0.0 11.341139793395996
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([ 50, 590, 300, 260], device='cuda:0') tensor(590, device='cuda:0')
bi 0 loss 0.020919067785143852
bi 1 loss 0.14392760396003723
bi 2 loss 0.0712028443813324
bi 3 loss 0.041511133313179016
Layer  2  loss:  0.08597750216722488 0.0 9.205821990966797
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([ 44, 593, 301, 248], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.026963116601109505
bi 1 loss 0.11941984295845032
bi 2 loss 0.08393153548240662
bi 3 loss 0.030310746282339096
Layer  3  loss:  0.0857253447175026 0.0 6.575810432434082
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([ 40, 593, 301, 154], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.02859821356832981
bi 1 loss 0.10692423582077026
bi 2 loss 0.08750306069850922
bi 3 loss 0.053336720913648605
Layer  4  loss:  0.10141865909099579 0.0 6.191601276397705
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([ 46, 593, 301, 258], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.021072251722216606
bi 1 loss 0.14489400386810303
bi 2 loss 0.07620541006326675
bi 3 loss 0.05150080472230911
Layer  5  loss:  0.08842979371547699 0.0 6.618996620178223
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([ 41, 593, 301, 293], device='cuda:0') tensor(593, device='cuda:0')
bi 0 loss 0.014547247439622879
bi 1 loss 0.1317046582698822
bi 2 loss 0.07182050496339798
bi 3 loss 0.028899645432829857
Layer  6  loss:  0.08843587338924408 0.0 5.917640209197998
logits torch.Size([621, 4, 1024]) labels torch.Size([621, 4]) 0 1022
Curr loss timestep torch.Size([621, 4]) tensor([ 45, 590, 301, 208], device='cuda:0') tensor(590, device='cuda:0')
bi 0 loss 0.01595703698694706
bi 1 loss 0.1127437874674797
bi 2 loss 0.0999179258942604
bi 3 loss 0.044400595128536224
Epoch 0: :   3%|▎         | 15571/600000 [03:58<2:29:26, v_num=12, reduced_train_loss=34.90, global_step=15569.0, consumed_samples=62280.0, train_step_timing in s=0.445]Epoch 0: :   3%|▎         | 15571/600000 [03:58<2:29:26, v_num=12, reduced_train_loss=0.748, global_step=15570.0, consumed_samples=62284.0, train_step_timing in s=0.421]loss mask original None

First layer loss:  3.5586111545562744 torch.Size([532, 4]) 11.553079605102539 0.0
Max loss timestep torch.Size([532, 4]) tensor([103, 447, 326, 212], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 3.0734684467315674
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 1 loss 4.011263847351074
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
bi 2 loss 3.683061122894287
speech mask sum tensor(242, device='cuda:0') loss mask sum tensor(242, device='cuda:0')
bi 3 loss 3.1402604579925537
speech mask sum tensor(392, device='cuda:0') loss mask sum tensor(392, device='cuda:0')
logits torch.Size([532, 4, 257024]) labels torch.Size([532, 4]) 0 257022
Layer  0  loss:  4.002812385559082 0.0 10.72692584991455
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1023
Curr loss timestep torch.Size([532, 4]) tensor([133, 393, 342, 201], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 3.636630058288574
bi 1 loss 4.785666465759277
bi 2 loss 4.2761735916137695
bi 3 loss 3.155339241027832
Layer  1  loss:  4.274084091186523 0.0 11.615680694580078
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1023
Curr loss timestep torch.Size([532, 4]) tensor([118, 161, 391, 413], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 4.063085079193115
bi 1 loss 4.914697170257568
bi 2 loss 4.508337020874023
bi 3 loss 3.5575664043426514
Layer  2  loss:  4.5218892097473145 0.0 9.934864044189453
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1023
Curr loss timestep torch.Size([532, 4]) tensor([109, 503, 470, 144], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 4.2889227867126465
bi 1 loss 5.151557445526123
bi 2 loss 4.930355548858643
bi 3 loss 3.7123517990112305
Layer  3  loss:  4.6896843910217285 0.0 10.035862922668457
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1017
Curr loss timestep torch.Size([532, 4]) tensor([ 88, 480, 296,  73], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 4.345086097717285
bi 1 loss 5.224427700042725
bi 2 loss 5.04373025894165
bi 3 loss 4.025099754333496
Layer  4  loss:  4.7089314460754395 0.0 10.731929779052734
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1023
Curr loss timestep torch.Size([532, 4]) tensor([110, 383, 469, 369], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 4.209526062011719
bi 1 loss 5.316686153411865
bi 2 loss 5.083859920501709
bi 3 loss 3.9906249046325684
Layer  5  loss:  4.859600067138672 0.0 11.325898170471191
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1022
Curr loss timestep torch.Size([532, 4]) tensor([ 95, 460, 321, 405], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 4.342867851257324
bi 1 loss 5.4124321937561035
bi 2 loss 5.195596694946289
bi 3 loss 4.220953464508057
Layer  6  loss:  4.830866813659668 0.0 11.63935375213623
logits torch.Size([532, 4, 1024]) labels torch.Size([532, 4]) 0 1022
Curr loss timestep torch.Size([532, 4]) tensor([114, 520, 392,  99], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 4.2425456047058105
bi 1 loss 5.436559200286865
bi 2 loss 5.320175647735596
bi 3 loss 4.060473442077637
Epoch 0: :   3%|▎         | 15572/600000 [03:59<2:29:40, v_num=12, reduced_train_loss=0.748, global_step=15570.0, consumed_samples=62284.0, train_step_timing in s=0.421]Epoch 0: :   3%|▎         | 15572/600000 [03:59<2:29:40, v_num=12, reduced_train_loss=35.40, global_step=15571.0, consumed_samples=62288.0, train_step_timing in s=0.353]loss mask original None

First layer loss:  0.1480455994606018 torch.Size([617, 4]) 13.532058715820312 0.0
Max loss timestep torch.Size([617, 4]) tensor([175, 182, 277, 372], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.04324425384402275
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
bi 1 loss 0.1665850430727005
speech mask sum tensor(459, device='cuda:0') loss mask sum tensor(459, device='cuda:0')
bi 2 loss 0.08077404648065567
speech mask sum tensor(288, device='cuda:0') loss mask sum tensor(288, device='cuda:0')
bi 3 loss 0.21223479509353638
speech mask sum tensor(406, device='cuda:0') loss mask sum tensor(406, device='cuda:0')
logits torch.Size([617, 4, 257024]) labels torch.Size([617, 4]) 0 257022
Layer  0  loss:  0.18619856238365173 0.0 14.538265228271484
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([225, 493, 323, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.06343697756528854
bi 1 loss 0.21558760106563568
bi 2 loss 0.13453277945518494
bi 3 loss 0.2334660440683365
Layer  1  loss:  0.19176669418811798 0.0 18.69548225402832
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1023
Curr loss timestep torch.Size([617, 4]) tensor([221, 492, 323, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.053942471742630005
bi 1 loss 0.19416095316410065
bi 2 loss 0.14872905611991882
bi 3 loss 0.268811970949173
Layer  2  loss:  0.19384247064590454 0.0 18.227996826171875
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([209, 492, 323, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.057088978588581085
bi 1 loss 0.23253409564495087
bi 2 loss 0.12824124097824097
bi 3 loss 0.24547535181045532
Layer  3  loss:  0.2046581506729126 0.0 17.796884536743164
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1019
Curr loss timestep torch.Size([617, 4]) tensor([162, 367, 323, 372], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.04650275781750679
bi 1 loss 0.20373143255710602
bi 2 loss 0.16012689471244812
bi 3 loss 0.29377853870391846
Layer  4  loss:  0.2137971669435501 0.0 21.00185203552246
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([220, 367, 438, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.08212476223707199
bi 1 loss 0.21083754301071167
bi 2 loss 0.19340208172798157
bi 3 loss 0.27863645553588867
Layer  5  loss:  0.20635294914245605 0.0 16.68694305419922
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([171, 375, 438, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.05701539292931557
bi 1 loss 0.18082034587860107
bi 2 loss 0.14070448279380798
bi 3 loss 0.33512189984321594
Layer  6  loss:  0.18663929402828217 0.0 11.539528846740723
logits torch.Size([617, 4, 1024]) labels torch.Size([617, 4]) 0 1022
Curr loss timestep torch.Size([617, 4]) tensor([133, 492, 323, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.050547193735837936
bi 1 loss 0.1945190131664276
bi 2 loss 0.17730920016765594
bi 3 loss 0.23295368254184723
Epoch 0: :   3%|▎         | 15573/600000 [03:59<2:29:57, v_num=12, reduced_train_loss=35.40, global_step=15571.0, consumed_samples=62288.0, train_step_timing in s=0.353]Epoch 0: :   3%|▎         | 15573/600000 [03:59<2:29:57, v_num=12, reduced_train_loss=1.530, global_step=15572.0, consumed_samples=62292.0, train_step_timing in s=0.421]loss mask original None

First layer loss:  0.10212118923664093 torch.Size([618, 4]) 7.991178035736084 0.0
Max loss timestep torch.Size([618, 4]) tensor([176, 294, 110, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.03392234072089195
speech mask sum tensor(107, device='cuda:0') loss mask sum tensor(107, device='cuda:0')
bi 1 loss 0.0625859722495079
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
bi 2 loss 0.040693581104278564
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
bi 3 loss 0.1572362780570984
speech mask sum tensor(429, device='cuda:0') loss mask sum tensor(429, device='cuda:0')
logits torch.Size([618, 4, 257024]) labels torch.Size([618, 4]) 0 257022
Layer  0  loss:  0.12825901806354523 0.0 12.535102844238281
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([154, 352, 105, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.03715148940682411
bi 1 loss 0.07088179886341095
bi 2 loss 0.03863917291164398
bi 3 loss 0.20639638602733612
Layer  1  loss:  0.15715456008911133 0.0 14.703859329223633
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1022
Curr loss timestep torch.Size([618, 4]) tensor([120, 338, 155, 436], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.037366293370723724
bi 1 loss 0.09817642718553543
bi 2 loss 0.025884170085191727
bi 3 loss 0.25329992175102234
Layer  2  loss:  0.1358785182237625 0.0 6.880409240722656
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([156, 294, 145, 336], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.025958241894841194
bi 1 loss 0.05022777244448662
bi 2 loss 0.04650546610355377
bi 3 loss 0.23545536398887634
Layer  3  loss:  0.16552110016345978 0.0 18.47971534729004
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1022
Curr loss timestep torch.Size([618, 4]) tensor([106, 336, 102, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.018997089937329292
bi 1 loss 0.06445156782865524
bi 2 loss 0.05409364029765129
bi 3 loss 0.28863629698753357
Layer  4  loss:  0.14421920478343964 0.0 14.09485912322998
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([103, 288, 163, 436], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.03135880455374718
bi 1 loss 0.07113951444625854
bi 2 loss 0.05731338635087013
bi 3 loss 0.23647041618824005
Layer  5  loss:  0.1623823195695877 0.0 10.944043159484863
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([125, 215, 130, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.034730780869722366
bi 1 loss 0.07152338325977325
bi 2 loss 0.0426466129720211
bi 3 loss 0.27669650316238403
Layer  6  loss:  0.1473633050918579 0.0 15.985373497009277
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([148, 339, 137, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.037945814430713654
bi 1 loss 0.05670905113220215
bi 2 loss 0.05273790284991264
bi 3 loss 0.2510376572608948
Epoch 0: :   3%|▎         | 15574/600000 [04:00<2:30:13, v_num=12, reduced_train_loss=1.530, global_step=15572.0, consumed_samples=62292.0, train_step_timing in s=0.421]Epoch 0: :   3%|▎         | 15574/600000 [04:00<2:30:13, v_num=12, reduced_train_loss=1.140, global_step=15573.0, consumed_samples=62296.0, train_step_timing in s=0.419]loss mask original None

First layer loss:  0.1365741342306137 torch.Size([627, 4]) 8.117033958435059 0.0
Max loss timestep torch.Size([627, 4]) tensor([600, 407, 292, 269], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.1797831505537033
speech mask sum tensor(417, device='cuda:0') loss mask sum tensor(417, device='cuda:0')
bi 1 loss 0.19060474634170532
speech mask sum tensor(366, device='cuda:0') loss mask sum tensor(366, device='cuda:0')
bi 2 loss 0.05817412585020065
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 3 loss 0.07002852112054825
speech mask sum tensor(284, device='cuda:0') loss mask sum tensor(284, device='cuda:0')
logits torch.Size([627, 4, 257024]) labels torch.Size([627, 4]) 0 257023
Layer  0  loss:  0.14042948186397552 0.0 9.56546401977539
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([452, 271, 314, 267], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.16584672033786774
bi 1 loss 0.1665988266468048
bi 2 loss 0.12549492716789246
bi 3 loss 0.0820571780204773
Layer  1  loss:  0.14559601247310638 0.0 8.54775619506836
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([347, 271, 262, 269], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.18354855477809906
bi 1 loss 0.19457533955574036
bi 2 loss 0.07937388122081757
bi 3 loss 0.08294416218996048
Layer  2  loss:  0.15759313106536865 0.0 7.741393089294434
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([450, 541, 290, 269], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.22056633234024048
bi 1 loss 0.1884864866733551
bi 2 loss 0.08267936110496521
bi 3 loss 0.08888691663742065
Layer  3  loss:  0.14657169580459595 0.0 9.178163528442383
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([600, 272, 290, 113], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.15662269294261932
bi 1 loss 0.22767937183380127
bi 2 loss 0.11230263113975525
bi 3 loss 0.056368060410022736
Layer  4  loss:  0.16023150086402893 0.0 16.21548080444336
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([530, 541, 290, 269], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.19952392578125
bi 1 loss 0.24508574604988098
bi 2 loss 0.06815027445554733
bi 3 loss 0.0713229700922966
Layer  5  loss:  0.1711118221282959 0.0 14.825976371765137
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([578, 271, 110, 110], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.2147013545036316
bi 1 loss 0.24499711394309998
bi 2 loss 0.09217947721481323
bi 3 loss 0.07887182384729385
Layer  6  loss:  0.15344324707984924 0.0 10.7288179397583
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([600, 541, 292, 275], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.18021897971630096
bi 1 loss 0.21911224722862244
bi 2 loss 0.09277733415365219
bi 3 loss 0.08097899705171585
Epoch 0: :   3%|▎         | 15575/600000 [04:00<2:30:30, v_num=12, reduced_train_loss=1.140, global_step=15573.0, consumed_samples=62296.0, train_step_timing in s=0.419]Epoch 0: :   3%|▎         | 15575/600000 [04:00<2:30:30, v_num=12, reduced_train_loss=1.210, global_step=15574.0, consumed_samples=62300.0, train_step_timing in s=0.432]loss mask original None

First layer loss:  0.14842171967029572 torch.Size([647, 4]) 10.720182418823242 0.0
Max loss timestep torch.Size([647, 4]) tensor([346, 592, 285, 103], device='cuda:0') tensor(592, device='cuda:0')
bi 0 loss 0.062344636768102646
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 1 loss 0.23970456421375275
speech mask sum tensor(501, device='cuda:0') loss mask sum tensor(501, device='cuda:0')
bi 2 loss 0.04021962359547615
speech mask sum tensor(60, device='cuda:0') loss mask sum tensor(60, device='cuda:0')
bi 3 loss 0.02801947295665741
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([647, 4, 257024]) labels torch.Size([647, 4]) 0 257022
Layer  0  loss:  0.19619841873645782 0.0 10.202733993530273
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([331, 616, 278, 162], device='cuda:0') tensor(616, device='cuda:0')
bi 0 loss 0.11504156142473221
bi 1 loss 0.29033294320106506
bi 2 loss 0.1158255785703659
bi 3 loss 0.02926376834511757
Layer  1  loss:  0.23302669823169708 0.0 17.323396682739258
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([331, 289, 275, 118], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.13446453213691711
bi 1 loss 0.334235817193985
bi 2 loss 0.1518644243478775
bi 3 loss 0.08612288534641266
Layer  2  loss:  0.18051615357398987 0.0 9.735824584960938
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([331, 522, 272, 168], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.095552459359169
bi 1 loss 0.27485281229019165
bi 2 loss 0.05293617025017738
bi 3 loss 0.052922721952199936
Layer  3  loss:  0.21717804670333862 0.0 8.745704650878906
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([331, 592, 266, 110], device='cuda:0') tensor(592, device='cuda:0')
bi 0 loss 0.10834185779094696
bi 1 loss 0.3404802978038788
bi 2 loss 0.08067905157804489
bi 3 loss 0.025255410000681877
Layer  4  loss:  0.22029884159564972 0.0 12.36441707611084
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([331, 289, 267, 103], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.12461984902620316
bi 1 loss 0.3307802975177765
bi 2 loss 0.05823182314634323
bi 3 loss 0.06637246906757355
Layer  5  loss:  0.19924858212471008 0.0 14.500478744506836
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([331, 289, 300, 131], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.10950633138418198
bi 1 loss 0.3023402988910675
bi 2 loss 0.09141790121793747
bi 3 loss 0.031042981892824173
Layer  6  loss:  0.21033377945423126 0.0 11.500970840454102
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([331, 592, 267, 120], device='cuda:0') tensor(592, device='cuda:0')
bi 0 loss 0.11889701336622238
bi 1 loss 0.31512391567230225
bi 2 loss 0.09808783233165741
bi 3 loss 0.04162294417619705
Epoch 0: :   3%|▎         | 15576/600000 [04:01<2:30:48, v_num=12, reduced_train_loss=1.210, global_step=15574.0, consumed_samples=62300.0, train_step_timing in s=0.432]Epoch 0: :   3%|▎         | 15576/600000 [04:01<2:30:48, v_num=12, reduced_train_loss=1.610, global_step=15575.0, consumed_samples=62304.0, train_step_timing in s=0.443]loss mask original None

First layer loss:  0.11491040140390396 torch.Size([561, 4]) 16.060548782348633 0.0
Max loss timestep torch.Size([561, 4]) tensor([224, 198, 533, 285], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.030240943655371666
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 1 loss 0.02106456272304058
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 2 loss 0.26664572954177856
speech mask sum tensor(284, device='cuda:0') loss mask sum tensor(284, device='cuda:0')
bi 3 loss 0.053883008658885956
speech mask sum tensor(292, device='cuda:0') loss mask sum tensor(292, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257022
Layer  0  loss:  0.11195440590381622 0.0 14.587693214416504
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([ 87, 195, 431, 412], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.020162787288427353
bi 1 loss 0.03914649412035942
bi 2 loss 0.24060705304145813
bi 3 loss 0.07015500962734222
Layer  1  loss:  0.10282493382692337 0.0 10.427881240844727
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([197, 185, 534, 480], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.04123616963624954
bi 1 loss 0.04231451079249382
bi 2 loss 0.2207401990890503
bi 3 loss 0.0482829287648201
Layer  2  loss:  0.12703682482242584 0.0 15.20338249206543
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([132, 255, 533, 274], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.053282734006643295
bi 1 loss 0.024308830499649048
bi 2 loss 0.27626052498817444
bi 3 loss 0.06491054594516754
Layer  3  loss:  0.12171594798564911 0.0 14.98829174041748
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([203, 167, 533, 411], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.050502318888902664
bi 1 loss 0.02158277854323387
bi 2 loss 0.2511148452758789
bi 3 loss 0.07635468244552612
Layer  4  loss:  0.12643872201442719 0.0 15.648809432983398
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([216, 174, 431, 422], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.03268628939986229
bi 1 loss 0.03583002835512161
bi 2 loss 0.28717225790023804
bi 3 loss 0.06111471727490425
Layer  5  loss:  0.12411484122276306 0.0 12.511626243591309
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([ 97, 208, 432, 361], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.03248324990272522
bi 1 loss 0.027693619951605797
bi 2 loss 0.257894366979599
bi 3 loss 0.08580178022384644
Layer  6  loss:  0.11218470335006714 0.0 9.167017936706543
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([190, 190, 432, 457], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 0.041063230484724045
bi 1 loss 0.06680049002170563
bi 2 loss 0.23105433583259583
bi 3 loss 0.05713241919875145
Epoch 0: :   3%|▎         | 15577/600000 [04:01<2:31:03, v_num=12, reduced_train_loss=1.610, global_step=15575.0, consumed_samples=62304.0, train_step_timing in s=0.443]Epoch 0: :   3%|▎         | 15577/600000 [04:01<2:31:03, v_num=12, reduced_train_loss=0.941, global_step=15576.0, consumed_samples=62308.0, train_step_timing in s=0.390]loss mask original None

First layer loss:  3.4315929412841797 torch.Size([360, 4]) 9.136894226074219 0.0
Max loss timestep torch.Size([360, 4]) tensor([ 73, 146, 201, 197], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 3.4341039657592773
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 1 loss 3.421602725982666
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 2 loss 3.6094977855682373
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 3 loss 3.103536605834961
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
logits torch.Size([360, 4, 257024]) labels torch.Size([360, 4]) 0 257023
Layer  0  loss:  3.8365578651428223 0.0 10.697259902954102
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1023
Curr loss timestep torch.Size([360, 4]) tensor([ 56, 130, 305, 227], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 4.1317830085754395
bi 1 loss 3.7709336280822754
bi 2 loss 3.8199546337127686
bi 3 loss 3.600553512573242
Layer  1  loss:  4.1837029457092285 0.0 10.741558074951172
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1022
Curr loss timestep torch.Size([360, 4]) tensor([ 67, 220, 292, 215], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.323304176330566
bi 1 loss 4.109537124633789
bi 2 loss 4.296484470367432
bi 3 loss 3.953775405883789
Layer  2  loss:  4.334917068481445 0.0 9.743367195129395
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1022
Curr loss timestep torch.Size([360, 4]) tensor([ 50, 253, 312, 210], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 4.736525058746338
bi 1 loss 4.147767066955566
bi 2 loss 4.437344074249268
bi 3 loss 4.039699077606201
Layer  3  loss:  4.570276737213135 0.0 9.772985458374023
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1023
Curr loss timestep torch.Size([360, 4]) tensor([ 57, 257, 231, 187], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.800249099731445
bi 1 loss 4.590717792510986
bi 2 loss 4.509613513946533
bi 3 loss 4.281129837036133
Layer  4  loss:  4.680753231048584 0.0 9.350603103637695
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1022
Curr loss timestep torch.Size([360, 4]) tensor([ 66,  90, 226, 242], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 4.866552829742432
bi 1 loss 4.539133548736572
bi 2 loss 4.787580966949463
bi 3 loss 4.580172538757324
Layer  5  loss:  4.774057865142822 0.0 9.820808410644531
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1022
Curr loss timestep torch.Size([360, 4]) tensor([ 67, 191, 276, 166], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.8548054695129395
bi 1 loss 4.667612075805664
bi 2 loss 4.938504695892334
bi 3 loss 4.622106075286865
Layer  6  loss:  4.8038249015808105 0.0 10.85435676574707
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1021
Curr loss timestep torch.Size([360, 4]) tensor([ 97, 264, 238, 169], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 4.990150451660156
bi 1 loss 4.7004218101501465
bi 2 loss 4.915307521820068
bi 3 loss 4.586537837982178
Epoch 0: :   3%|▎         | 15578/600000 [04:01<2:31:14, v_num=12, reduced_train_loss=0.941, global_step=15576.0, consumed_samples=62308.0, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15578/600000 [04:01<2:31:14, v_num=12, reduced_train_loss=34.60, global_step=15577.0, consumed_samples=62312.0, train_step_timing in s=0.273]loss mask original None

First layer loss:  0.23639337718486786 torch.Size([723, 4]) 11.122457504272461 0.0
Max loss timestep torch.Size([723, 4]) tensor([105, 605, 457, 347], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.04586787521839142
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 1 loss 0.252150297164917
speech mask sum tensor(453, device='cuda:0') loss mask sum tensor(453, device='cuda:0')
bi 2 loss 0.1552305519580841
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
bi 3 loss 0.35194066166877747
speech mask sum tensor(386, device='cuda:0') loss mask sum tensor(386, device='cuda:0')
logits torch.Size([723, 4, 257024]) labels torch.Size([723, 4]) 0 257023
Layer  0  loss:  0.30403032898902893 0.0 14.120792388916016
logits torch.Size([723, 4, 1024]) labels torch.Size([723, 4]) 0 1023
Curr loss timestep torch.Size([723, 4]) tensor([112, 598, 359, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.032548949122428894
bi 1 loss 0.29743921756744385
bi 2 loss 0.15929782390594482
bi 3 loss 0.5281502604484558
Layer  1  loss:  0.3316532075405121 0.0 19.133281707763672
logits torch.Size([723, 4, 1024]) labels torch.Size([723, 4]) 0 1022
Curr loss timestep torch.Size([723, 4]) tensor([162, 598, 360, 348], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.02359483391046524
bi 1 loss 0.31683892011642456
bi 2 loss 0.2760394513607025
bi 3 loss 0.49974697828292847
Layer  2  loss:  0.32736024260520935 0.0 13.767595291137695
logits torch.Size([723, 4, 1024]) labels torch.Size([723, 4]) 0 1022
Curr loss timestep torch.Size([723, 4]) tensor([105, 598, 360, 348], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.04902004450559616
bi 1 loss 0.2710784375667572
bi 2 loss 0.28000324964523315
bi 3 loss 0.5270557999610901
Layer  3  loss:  0.38961896300315857 0.0 18.752582550048828
logits torch.Size([723, 4, 1024]) labels torch.Size([723, 4]) 0 1023
Curr loss timestep torch.Size([723, 4]) tensor([153, 679, 359, 561], device='cuda:0') tensor(561, device='cuda:0')
bi 0 loss 0.10974778234958649
bi 1 loss 0.34361547231674194
bi 2 loss 0.21834909915924072
bi 3 loss 0.6859428286552429
Layer  4  loss:  0.33567380905151367 0.0 15.420539855957031
logits torch.Size([723, 4, 1024]) labels torch.Size([723, 4]) 0 1023
Curr loss timestep torch.Size([723, 4]) tensor([174, 696, 359, 607], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.050838179886341095
bi 1 loss 0.27755776047706604
bi 2 loss 0.30156221985816956
bi 3 loss 0.52811199426651
Layer  5  loss:  0.3831779658794403 0.0 15.173129081726074
logits torch.Size([723, 4, 1024]) labels torch.Size([723, 4]) 0 1023
Curr loss timestep torch.Size([723, 4]) tensor([176, 696, 360, 460], device='cuda:0') tensor(460, device='cuda:0')
bi 0 loss 0.0396413691341877
bi 1 loss 0.336204469203949
bi 2 loss 0.2648501396179199
bi 3 loss 0.655530571937561
Layer  6  loss:  0.3591729700565338 0.0 15.796244621276855
logits torch.Size([723, 4, 1024]) labels torch.Size([723, 4]) 0 1023
Curr loss timestep torch.Size([723, 4]) tensor([ 93, 630, 359, 348], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.04273107275366783
bi 1 loss 0.34001776576042175
bi 2 loss 0.25044378638267517
bi 3 loss 0.5815139412879944
Epoch 0: :   3%|▎         | 15579/600000 [04:02<2:31:34, v_num=12, reduced_train_loss=34.60, global_step=15577.0, consumed_samples=62312.0, train_step_timing in s=0.273]Epoch 0: :   3%|▎         | 15579/600000 [04:02<2:31:34, v_num=12, reduced_train_loss=2.670, global_step=15578.0, consumed_samples=62316.0, train_step_timing in s=0.498]loss mask original None

First layer loss:  0.06597159057855606 torch.Size([454, 4]) 6.1553730964660645 0.0
Max loss timestep torch.Size([454, 4]) tensor([176, 290, 351, 440], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.03237215057015419
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 1 loss 0.17137303948402405
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 2 loss 0.06687432527542114
speech mask sum tensor(246, device='cuda:0') loss mask sum tensor(246, device='cuda:0')
bi 3 loss 0.04272370785474777
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
logits torch.Size([454, 4, 257024]) labels torch.Size([454, 4]) 0 257023
Layer  0  loss:  0.07611341774463654 0.0 8.909077644348145
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([246, 291, 264, 104], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.027115050703287125
bi 1 loss 0.23827651143074036
bi 2 loss 0.05683603510260582
bi 3 loss 0.05308880656957626
Layer  1  loss:  0.0698002278804779 0.0 14.058730125427246
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1021
Curr loss timestep torch.Size([454, 4]) tensor([185, 291, 238, 377], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.03859223797917366
bi 1 loss 0.24417980015277863
bi 2 loss 0.04341962933540344
bi 3 loss 0.04198037460446358
Layer  2  loss:  0.0763777643442154 0.0 12.443039894104004
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([203, 291, 148, 440], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.052399102598428726
bi 1 loss 0.23519626259803772
bi 2 loss 0.050114769488573074
bi 3 loss 0.05110931023955345
Layer  3  loss:  0.07308802008628845 0.0 10.741272926330566
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1021
Curr loss timestep torch.Size([454, 4]) tensor([216, 290, 336, 282], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.05367163568735123
bi 1 loss 0.16827517747879028
bi 2 loss 0.06238194927573204
bi 3 loss 0.05622370168566704
Layer  4  loss:  0.08562950789928436 0.0 8.235864639282227
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([175, 290, 304, 440], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.03538885712623596
bi 1 loss 0.24769805371761322
bi 2 loss 0.05372041463851929
bi 3 loss 0.07133521139621735
Layer  5  loss:  0.06721088290214539 0.0 8.810376167297363
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([163, 291, 347, 440], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.03961209952831268
bi 1 loss 0.2061302810907364
bi 2 loss 0.04352913051843643
bi 3 loss 0.047665100544691086
Layer  6  loss:  0.07165117561817169 0.0 10.373151779174805
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([162, 291, 343, 331], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.045802414417266846
bi 1 loss 0.2324570119380951
bi 2 loss 0.04364657774567604
bi 3 loss 0.047491271048784256
Epoch 0: :   3%|▎         | 15580/600000 [04:02<2:31:47, v_num=12, reduced_train_loss=2.670, global_step=15578.0, consumed_samples=62316.0, train_step_timing in s=0.498]Epoch 0: :   3%|▎         | 15580/600000 [04:02<2:31:47, v_num=12, reduced_train_loss=0.586, global_step=15579.0, consumed_samples=62320.0, train_step_timing in s=0.329]loss mask original None

First layer loss:  0.022855229675769806 torch.Size([394, 4]) 0.9260672330856323 0.0
Max loss timestep torch.Size([394, 4]) tensor([257, 279,  51, 218], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 0.027405481785535812
speech mask sum tensor(311, device='cuda:0') loss mask sum tensor(311, device='cuda:0')
bi 1 loss 0.022571660578250885
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 2 loss 0.015405272133648396
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 3 loss 0.020883485674858093
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
logits torch.Size([394, 4, 257024]) labels torch.Size([394, 4]) 0 257019
Layer  0  loss:  0.01732592284679413 0.0 0.3377276360988617
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1023
Curr loss timestep torch.Size([394, 4]) tensor([320, 269,  98, 147], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 0.018223755061626434
bi 1 loss 0.016194971278309822
bi 2 loss 0.02242601104080677
bi 3 loss 0.011215577833354473
Layer  1  loss:  0.019632169976830482 0.0 0.2629471719264984
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1022
Curr loss timestep torch.Size([394, 4]) tensor([277, 205,  78, 145], device='cuda:0') tensor(146, device='cuda:0')
bi 0 loss 0.024011313915252686
bi 1 loss 0.014930316247045994
bi 2 loss 0.018742354586720467
bi 3 loss 0.015836160629987717
Layer  2  loss:  0.021044215187430382 0.0 0.4504360556602478
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1022
Curr loss timestep torch.Size([394, 4]) tensor([295, 223, 150, 154], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 0.01768149621784687
bi 1 loss 0.027362417429685593
bi 2 loss 0.020496537908911705
bi 3 loss 0.02240038849413395
Layer  3  loss:  0.0192914679646492 0.0 0.48112496733665466
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1021
Curr loss timestep torch.Size([394, 4]) tensor([326, 218, 106, 216], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 0.01792989671230316
bi 1 loss 0.01622934080660343
bi 2 loss 0.019928116351366043
bi 3 loss 0.0248450618237257
Layer  4  loss:  0.020597202703356743 0.0 0.3882797062397003
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1022
Curr loss timestep torch.Size([394, 4]) tensor([201, 211, 108, 170], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 0.021731924265623093
bi 1 loss 0.02177165262401104
bi 2 loss 0.02063390426337719
bi 3 loss 0.016823360696434975
Layer  5  loss:  0.021483417600393295 0.0 0.34603774547576904
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1023
Curr loss timestep torch.Size([394, 4]) tensor([298, 288, 134, 118], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.018223484978079796
bi 1 loss 0.023883603513240814
bi 2 loss 0.028941312804818153
bi 3 loss 0.018379174172878265
Layer  6  loss:  0.024231204763054848 0.0 0.8433139324188232
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1020
Curr loss timestep torch.Size([394, 4]) tensor([256, 288,  67, 167], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 0.02825550176203251
bi 1 loss 0.017124643549323082
bi 2 loss 0.020784851163625717
bi 3 loss 0.026407301425933838
Epoch 0: :   3%|▎         | 15581/600000 [04:03<2:31:59, v_num=12, reduced_train_loss=0.586, global_step=15579.0, consumed_samples=62320.0, train_step_timing in s=0.329]Epoch 0: :   3%|▎         | 15581/600000 [04:03<2:31:59, v_num=12, reduced_train_loss=0.166, global_step=15580.0, consumed_samples=62324.0, train_step_timing in s=0.295]loss mask original None

First layer loss:  0.0542127899825573 torch.Size([439, 4]) 10.405686378479004 0.0
Max loss timestep torch.Size([439, 4]) tensor([314, 193, 129,  77], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.0909176915884018
speech mask sum tensor(376, device='cuda:0') loss mask sum tensor(376, device='cuda:0')
bi 1 loss 0.024043653160333633
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 2 loss 0.02191811241209507
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 3 loss 0.02159113623201847
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
logits torch.Size([439, 4, 257024]) labels torch.Size([439, 4]) 0 257022
Layer  0  loss:  0.06703045964241028 0.0 12.124667167663574
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([314, 192, 113, 137], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.11302782595157623
bi 1 loss 0.025856833904981613
bi 2 loss 0.022054949775338173
bi 3 loss 0.0338195376098156
Layer  1  loss:  0.0659901574254036 0.0 13.28693675994873
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([314, 206, 125, 119], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.11313216388225555
bi 1 loss 0.024639379233121872
bi 2 loss 0.028087778016924858
bi 3 loss 0.022395409643650055
Layer  2  loss:  0.05313115566968918 0.0 12.331424713134766
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([315, 220, 118,  75], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.09007370471954346
bi 1 loss 0.02254699356853962
bi 2 loss 0.026965713128447533
bi 3 loss 0.013632313348352909
Layer  3  loss:  0.0682273879647255 0.0 12.303719520568848
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([315, 155, 137, 166], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.11264155805110931
bi 1 loss 0.030849022790789604
bi 2 loss 0.030419686809182167
bi 3 loss 0.028108133003115654
Layer  4  loss:  0.08057098090648651 0.0 20.314533233642578
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([314, 202, 234, 143], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.14383579790592194
bi 1 loss 0.033163733780384064
bi 2 loss 0.024194762110710144
bi 3 loss 0.021292440593242645
Layer  5  loss:  0.0676940456032753 0.0 16.748254776000977
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1022
Curr loss timestep torch.Size([439, 4]) tensor([315, 159, 211, 132], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.11687673628330231
bi 1 loss 0.018614089116454124
bi 2 loss 0.027439236640930176
bi 3 loss 0.02792387828230858
Layer  6  loss:  0.07706662267446518 0.0 10.851947784423828
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([315, 242, 226,  83], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.13364431262016296
bi 1 loss 0.030766010284423828
bi 2 loss 0.02167688123881817
bi 3 loss 0.03267611935734749
Epoch 0: :   3%|▎         | 15582/600000 [04:03<2:32:12, v_num=12, reduced_train_loss=0.166, global_step=15580.0, consumed_samples=62324.0, train_step_timing in s=0.295]Epoch 0: :   3%|▎         | 15582/600000 [04:03<2:32:12, v_num=12, reduced_train_loss=0.534, global_step=15581.0, consumed_samples=62328.0, train_step_timing in s=0.334]loss mask original None

First layer loss:  0.18510687351226807 torch.Size([667, 4]) 11.691084861755371 0.0
Max loss timestep torch.Size([667, 4]) tensor([174, 297, 631, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.030785810202360153
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 1 loss 0.11210284382104874
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 2 loss 0.10886351764202118
speech mask sum tensor(485, device='cuda:0') loss mask sum tensor(485, device='cuda:0')
bi 3 loss 0.3760219216346741
speech mask sum tensor(447, device='cuda:0') loss mask sum tensor(447, device='cuda:0')
logits torch.Size([667, 4, 257024]) labels torch.Size([667, 4]) 0 257023
Layer  0  loss:  0.2120215892791748 0.0 10.69494915008545
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([270, 296, 355, 449], device='cuda:0') tensor(449, device='cuda:0')
bi 0 loss 0.04973791539669037
bi 1 loss 0.13148616254329681
bi 2 loss 0.16396108269691467
bi 3 loss 0.3792288303375244
Layer  1  loss:  0.21593554317951202 0.0 14.38314437866211
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1022
Curr loss timestep torch.Size([667, 4]) tensor([260, 296, 355, 569], device='cuda:0') tensor(569, device='cuda:0')
bi 0 loss 0.030812455341219902
bi 1 loss 0.15157963335514069
bi 2 loss 0.1883815973997116
bi 3 loss 0.36766889691352844
Layer  2  loss:  0.26207518577575684 0.0 10.909547805786133
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1022
Curr loss timestep torch.Size([667, 4]) tensor([270, 296, 355, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.06346908956766129
bi 1 loss 0.14848758280277252
bi 2 loss 0.2278740406036377
bi 3 loss 0.4451411962509155
Layer  3  loss:  0.2319825291633606 0.0 13.042787551879883
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([258, 297, 355, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.022270966321229935
bi 1 loss 0.10808992385864258
bi 2 loss 0.18085932731628418
bi 3 loss 0.4429239332675934
Layer  4  loss:  0.25089189410209656 0.0 10.189573287963867
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1022
Curr loss timestep torch.Size([667, 4]) tensor([270, 297, 631, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.03491876646876335
bi 1 loss 0.14387011528015137
bi 2 loss 0.2159067839384079
bi 3 loss 0.4419246315956116
Layer  5  loss:  0.2507774829864502 0.0 11.526576042175293
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([260, 296, 355, 265], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.05402044951915741
bi 1 loss 0.1493300497531891
bi 2 loss 0.18356825411319733
bi 3 loss 0.4645054340362549
Layer  6  loss:  0.25044751167297363 0.0 13.987380027770996
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([271, 296, 503, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.02728359028697014
bi 1 loss 0.1821114420890808
bi 2 loss 0.19963282346725464
bi 3 loss 0.44929105043411255
Epoch 0: :   3%|▎         | 15583/600000 [04:03<2:32:30, v_num=12, reduced_train_loss=0.534, global_step=15581.0, consumed_samples=62328.0, train_step_timing in s=0.334]Epoch 0: :   3%|▎         | 15583/600000 [04:03<2:32:30, v_num=12, reduced_train_loss=1.860, global_step=15582.0, consumed_samples=62332.0, train_step_timing in s=0.470]loss mask original None

First layer loss:  0.02417139895260334 torch.Size([462, 4]) 0.7766144275665283 0.0
Max loss timestep torch.Size([462, 4]) tensor([121, 391, 217, 280], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.010470207780599594
speech mask sum tensor(49, device='cuda:0') loss mask sum tensor(49, device='cuda:0')
bi 1 loss 0.030080383643507957
speech mask sum tensor(366, device='cuda:0') loss mask sum tensor(366, device='cuda:0')
bi 2 loss 0.02205495536327362
speech mask sum tensor(150, device='cuda:0') loss mask sum tensor(150, device='cuda:0')
bi 3 loss 0.019791310653090477
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
logits torch.Size([462, 4, 257024]) labels torch.Size([462, 4]) 0 257023
Layer  0  loss:  0.02254013530910015 0.0 1.8535006046295166
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1023
Curr loss timestep torch.Size([462, 4]) tensor([116, 390, 136, 280], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.011243658140301704
bi 1 loss 0.02951899543404579
bi 2 loss 0.019439697265625
bi 3 loss 0.016810022294521332
Layer  1  loss:  0.033339787274599075 0.0 6.127867698669434
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([112, 415, 153, 278], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.014032483100891113
bi 1 loss 0.05499327927827835
bi 2 loss 0.012976374477148056
bi 3 loss 0.01869572140276432
Layer  2  loss:  0.02779616229236126 0.0 3.098897695541382
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([113, 414, 200,  86], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.0024366399738937616
bi 1 loss 0.04335823655128479
bi 2 loss 0.013918536715209484
bi 3 loss 0.018947435542941093
Layer  3  loss:  0.031235286965966225 0.0 4.953664302825928
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1021
Curr loss timestep torch.Size([462, 4]) tensor([117, 415, 128, 281], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.011025971733033657
bi 1 loss 0.04463179036974907
bi 2 loss 0.022465502843260765
bi 3 loss 0.021543502807617188
Layer  4  loss:  0.0302573312073946 0.0 3.0525176525115967
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([114, 415, 157,  90], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.007661210838705301
bi 1 loss 0.04389112442731857
bi 2 loss 0.02352323569357395
bi 3 loss 0.01953851245343685
Layer  5  loss:  0.03187345340847969 0.0 4.9514617919921875
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([121, 415, 186, 281], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.008454824797809124
bi 1 loss 0.04963461682200432
bi 2 loss 0.015541083179414272
bi 3 loss 0.02104055881500244
Layer  6  loss:  0.03659800812602043 0.0 4.3885393142700195
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([120, 415, 233, 281], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.006294021382927895
bi 1 loss 0.05164209008216858
bi 2 loss 0.019539594650268555
bi 3 loss 0.031141014769673347
Epoch 0: :   3%|▎         | 15584/600000 [04:04<2:32:44, v_num=12, reduced_train_loss=1.860, global_step=15582.0, consumed_samples=62332.0, train_step_timing in s=0.470]Epoch 0: :   3%|▎         | 15584/600000 [04:04<2:32:44, v_num=12, reduced_train_loss=0.238, global_step=15583.0, consumed_samples=62336.0, train_step_timing in s=0.332]loss mask original None

First layer loss:  0.036961156874895096 torch.Size([507, 4]) 4.342159748077393 0.0
Max loss timestep torch.Size([507, 4]) tensor([176, 436,  71,  66], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.02063262276351452
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 1 loss 0.05466281995177269
speech mask sum tensor(297, device='cuda:0') loss mask sum tensor(297, device='cuda:0')
bi 2 loss 0.030171621590852737
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 3 loss 0.031207120046019554
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
logits torch.Size([507, 4, 257024]) labels torch.Size([507, 4]) 0 257022
Layer  0  loss:  0.054691821336746216 0.0 5.8545451164245605
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([194, 437,  83, 287], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.03449255973100662
bi 1 loss 0.08704644441604614
bi 2 loss 0.04726063832640648
bi 3 loss 0.037803806364536285
Layer  1  loss:  0.07005579024553299 0.0 11.065508842468262
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1022
Curr loss timestep torch.Size([507, 4]) tensor([231, 437,  47, 304], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.025779150426387787
bi 1 loss 0.1394789218902588
bi 2 loss 0.029889490455389023
bi 3 loss 0.040408018976449966
Layer  2  loss:  0.07037817686796188 0.0 6.724057197570801
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1022
Curr loss timestep torch.Size([507, 4]) tensor([158, 437,  62, 319], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.033974867314100266
bi 1 loss 0.11646828055381775
bi 2 loss 0.03656115382909775
bi 3 loss 0.056212566792964935
Layer  3  loss:  0.06858082860708237 0.0 7.809892654418945
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1020
Curr loss timestep torch.Size([507, 4]) tensor([116, 437,  49, 292], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.036628060042858124
bi 1 loss 0.12716980278491974
bi 2 loss 0.04068801552057266
bi 3 loss 0.03917626664042473
Layer  4  loss:  0.06890377402305603 0.0 11.793034553527832
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1022
Curr loss timestep torch.Size([507, 4]) tensor([112, 437,  72, 239], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.035999834537506104
bi 1 loss 0.1327786147594452
bi 2 loss 0.040612488985061646
bi 3 loss 0.035288553684949875
Layer  5  loss:  0.06977242231369019 0.0 9.727375030517578
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([171, 437,  83, 323], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.03159688785672188
bi 1 loss 0.13408423960208893
bi 2 loss 0.02988259680569172
bi 3 loss 0.04147403687238693
Layer  6  loss:  0.0672219842672348 0.0 8.002309799194336
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1022
Curr loss timestep torch.Size([507, 4]) tensor([149, 437,  97, 346], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.027302516624331474
bi 1 loss 0.11605721712112427
bi 2 loss 0.017872348427772522
bi 3 loss 0.05632835626602173
Epoch 0: :   3%|▎         | 15585/600000 [04:04<2:32:58, v_num=12, reduced_train_loss=0.238, global_step=15583.0, consumed_samples=62336.0, train_step_timing in s=0.332]Epoch 0: :   3%|▎         | 15585/600000 [04:04<2:32:58, v_num=12, reduced_train_loss=0.507, global_step=15584.0, consumed_samples=62340.0, train_step_timing in s=0.362]loss mask original None

First layer loss:  0.06087696924805641 torch.Size([406, 4]) 3.3898398876190186 0.0
Max loss timestep torch.Size([406, 4]) tensor([350, 320, 133, 324], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.06401921808719635
speech mask sum tensor(320, device='cuda:0') loss mask sum tensor(320, device='cuda:0')
bi 1 loss 0.1899634301662445
speech mask sum tensor(83, device='cuda:0') loss mask sum tensor(83, device='cuda:0')
bi 2 loss 0.032027605921030045
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 3 loss 0.04452558606863022
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
logits torch.Size([406, 4, 257024]) labels torch.Size([406, 4]) 0 257023
Layer  0  loss:  0.05749019980430603 0.0 6.356415748596191
logits torch.Size([406, 4, 1024]) labels torch.Size([406, 4]) 0 1023
Curr loss timestep torch.Size([406, 4]) tensor([336, 320, 234, 324], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.0486660972237587
bi 1 loss 0.19708526134490967
bi 2 loss 0.04424203187227249
bi 3 loss 0.03934996947646141
Layer  1  loss:  0.05980025604367256 0.0 8.004704475402832
logits torch.Size([406, 4, 1024]) labels torch.Size([406, 4]) 0 1022
Curr loss timestep torch.Size([406, 4]) tensor([339, 320, 276, 335], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.06953255832195282
bi 1 loss 0.16116832196712494
bi 2 loss 0.039897944778203964
bi 3 loss 0.037693437188863754
Layer  2  loss:  0.07310175150632858 0.0 5.299673080444336
logits torch.Size([406, 4, 1024]) labels torch.Size([406, 4]) 0 1022
Curr loss timestep torch.Size([406, 4]) tensor([287, 360, 207, 324], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.08085186034440994
bi 1 loss 0.24679432809352875
bi 2 loss 0.03966008126735687
bi 3 loss 0.043734751641750336
Layer  3  loss:  0.06209797039628029 0.0 8.8164701461792
logits torch.Size([406, 4, 1024]) labels torch.Size([406, 4]) 0 1019
Curr loss timestep torch.Size([406, 4]) tensor([332, 320, 265, 274], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.04719514399766922
bi 1 loss 0.23476557433605194
bi 2 loss 0.04391315579414368
bi 3 loss 0.04495098441839218
Layer  4  loss:  0.054900314658880234 0.0 6.154726028442383
logits torch.Size([406, 4, 1024]) labels torch.Size([406, 4]) 0 1023
Curr loss timestep torch.Size([406, 4]) tensor([287, 320, 176,  83], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.05376497656106949
bi 1 loss 0.15499606728553772
bi 2 loss 0.03822663426399231
bi 3 loss 0.041767023503780365
Layer  5  loss:  0.07233273983001709 0.0 5.575679779052734
logits torch.Size([406, 4, 1024]) labels torch.Size([406, 4]) 0 1023
Curr loss timestep torch.Size([406, 4]) tensor([330, 319, 156, 325], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.06380338966846466
bi 1 loss 0.2587619125843048
bi 2 loss 0.03153907135128975
bi 3 loss 0.06124827638268471
Layer  6  loss:  0.06805422902107239 0.0 9.280558586120605
logits torch.Size([406, 4, 1024]) labels torch.Size([406, 4]) 0 1021
Curr loss timestep torch.Size([406, 4]) tensor([287, 320, 135, 355], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.04603201895952225
bi 1 loss 0.2315622866153717
bi 2 loss 0.0379355326294899
bi 3 loss 0.06894344836473465
Epoch 0: :   3%|▎         | 15586/600000 [04:05<2:33:10, v_num=12, reduced_train_loss=0.507, global_step=15584.0, consumed_samples=62340.0, train_step_timing in s=0.362]Epoch 0: :   3%|▎         | 15586/600000 [04:05<2:33:10, v_num=12, reduced_train_loss=0.509, global_step=15585.0, consumed_samples=62344.0, train_step_timing in s=0.304]loss mask original None

First layer loss:  3.3299238681793213 torch.Size([540, 4]) 13.559346199035645 0.0
Max loss timestep torch.Size([540, 4]) tensor([313, 332, 196,  81], device='cuda:0') tensor(88, device='cuda:0')
bi 0 loss 2.8176379203796387
speech mask sum tensor(168, device='cuda:0') loss mask sum tensor(168, device='cuda:0')
bi 1 loss 3.4349300861358643
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 2 loss 2.8116443157196045
speech mask sum tensor(69, device='cuda:0') loss mask sum tensor(69, device='cuda:0')
bi 3 loss 4.0752129554748535
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
logits torch.Size([540, 4, 257024]) labels torch.Size([540, 4]) 0 257022
Layer  0  loss:  3.800794839859009 0.0 11.08480167388916
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([358, 284, 203,  84], device='cuda:0') tensor(84, device='cuda:0')
bi 0 loss 3.672715663909912
bi 1 loss 3.747675895690918
bi 2 loss 3.2620644569396973
bi 3 loss 4.7037458419799805
Layer  1  loss:  4.050175666809082 0.0 10.20564079284668
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([349,  82, 187, 110], device='cuda:0') tensor(82, device='cuda:0')
bi 0 loss 3.8338541984558105
bi 1 loss 4.105742454528809
bi 2 loss 3.6248135566711426
bi 3 loss 4.457595348358154
Layer  2  loss:  4.289662837982178 0.0 9.87125015258789
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([380, 399, 218, 150], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 4.012109756469727
bi 1 loss 4.407886981964111
bi 2 loss 3.7217955589294434
bi 3 loss 4.582507610321045
Layer  3  loss:  4.364729881286621 0.0 10.353021621704102
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([392, 136, 192,  94], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 4.017941474914551
bi 1 loss 4.496376991271973
bi 2 loss 3.578495502471924
bi 3 loss 4.871206760406494
Layer  4  loss:  4.534673690795898 0.0 11.123468399047852
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1021
Curr loss timestep torch.Size([540, 4]) tensor([250, 197, 197, 132], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 4.325543403625488
bi 1 loss 4.592029571533203
bi 2 loss 4.034500598907471
bi 3 loss 4.974771976470947
Layer  5  loss:  4.567140102386475 0.0 10.479318618774414
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([388, 468, 206,  86], device='cuda:0') tensor(133, device='cuda:0')
bi 0 loss 4.285648822784424
bi 1 loss 4.6760406494140625
bi 2 loss 4.000333309173584
bi 3 loss 4.915143013000488
Layer  6  loss:  4.650580883026123 0.0 10.25132942199707
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([262, 184, 221,  98], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.290711879730225
bi 1 loss 4.805932521820068
bi 2 loss 3.777409553527832
bi 3 loss 5.119926452636719
Epoch 0: :   3%|▎         | 15587/600000 [04:05<2:33:24, v_num=12, reduced_train_loss=0.509, global_step=15585.0, consumed_samples=62344.0, train_step_timing in s=0.304]Epoch 0: :   3%|▎         | 15587/600000 [04:05<2:33:24, v_num=12, reduced_train_loss=33.60, global_step=15586.0, consumed_samples=62348.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  3.3330929279327393 torch.Size([360, 4]) 13.172157287597656 0.0
Max loss timestep torch.Size([360, 4]) tensor([320, 149,  57,  70], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 3.4736616611480713
speech mask sum tensor(189, device='cuda:0') loss mask sum tensor(189, device='cuda:0')
bi 1 loss 3.5682146549224854
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 2 loss 2.9415600299835205
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 3 loss 2.7221810817718506
speech mask sum tensor(52, device='cuda:0') loss mask sum tensor(52, device='cuda:0')
logits torch.Size([360, 4, 257024]) labels torch.Size([360, 4]) 0 257023
Layer  0  loss:  3.79914927482605 0.0 10.376219749450684
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1023
Curr loss timestep torch.Size([360, 4]) tensor([242, 178,  53,  62], device='cuda:0') tensor(62, device='cuda:0')
bi 0 loss 3.6110787391662598
bi 1 loss 4.3684587478637695
bi 2 loss 3.699582815170288
bi 3 loss 2.9189300537109375
Layer  1  loss:  4.06170129776001 0.0 10.496478080749512
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1023
Curr loss timestep torch.Size([360, 4]) tensor([224, 145,  94,  82], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 4.244609355926514
bi 1 loss 4.27491569519043
bi 2 loss 3.7029800415039062
bi 3 loss 3.311934232711792
Layer  2  loss:  4.334643840789795 0.0 10.385626792907715
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1022
Curr loss timestep torch.Size([360, 4]) tensor([180, 220,  66,  64], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.57617712020874
bi 1 loss 4.642492771148682
bi 2 loss 3.8433384895324707
bi 3 loss 3.292599678039551
Layer  3  loss:  4.430541038513184 0.0 10.003814697265625
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1017
Curr loss timestep torch.Size([360, 4]) tensor([185, 147,  96,  71], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 4.780973434448242
bi 1 loss 4.729510307312012
bi 2 loss 4.024807453155518
bi 3 loss 2.8862059116363525
Layer  4  loss:  4.634346961975098 0.0 9.656869888305664
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1021
Curr loss timestep torch.Size([360, 4]) tensor([224, 251,  61,  74], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 4.875351905822754
bi 1 loss 4.743724822998047
bi 2 loss 4.519297122955322
bi 3 loss 3.60736083984375
Layer  5  loss:  4.575797080993652 0.0 11.831178665161133
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1015
Curr loss timestep torch.Size([360, 4]) tensor([323, 201,  55,  75], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 4.873196125030518
bi 1 loss 4.817565441131592
bi 2 loss 4.153583526611328
bi 3 loss 3.422593593597412
Layer  6  loss:  4.652259349822998 0.0 10.752967834472656
logits torch.Size([360, 4, 1024]) labels torch.Size([360, 4]) 0 1019
Curr loss timestep torch.Size([360, 4]) tensor([347, 141,  83,  81], device='cuda:0') tensor(83, device='cuda:0')
bi 0 loss 5.001040458679199
bi 1 loss 4.756821632385254
bi 2 loss 4.445128440856934
bi 3 loss 3.391517400741577
Epoch 0: :   3%|▎         | 15588/600000 [04:05<2:33:35, v_num=12, reduced_train_loss=33.60, global_step=15586.0, consumed_samples=62348.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15588/600000 [04:05<2:33:35, v_num=12, reduced_train_loss=33.80, global_step=15587.0, consumed_samples=62352.0, train_step_timing in s=0.274]loss mask original None

First layer loss:  3.918771743774414 torch.Size([708, 4]) 11.846240043640137 0.0
Max loss timestep torch.Size([708, 4]) tensor([421, 213, 311,  88], device='cuda:0') tensor(88, device='cuda:0')
bi 0 loss 4.020764350891113
speech mask sum tensor(438, device='cuda:0') loss mask sum tensor(438, device='cuda:0')
bi 1 loss 3.890690565109253
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
bi 2 loss 3.868790864944458
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 3 loss 3.715489387512207
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
logits torch.Size([708, 4, 257024]) labels torch.Size([708, 4]) 0 257023
Layer  0  loss:  4.520445346832275 0.0 10.241619110107422
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([491, 256, 434, 106], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 4.676662445068359
bi 1 loss 4.497629165649414
bi 2 loss 4.550281047821045
bi 3 loss 3.8158600330352783
Layer  1  loss:  4.8789191246032715 0.0 11.167350769042969
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([440,  54, 273, 107], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 5.1326117515563965
bi 1 loss 4.7117600440979
bi 2 loss 4.869162559509277
bi 3 loss 4.269656181335449
Layer  2  loss:  5.123796463012695 0.0 10.414900779724121
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([523, 199, 337, 144], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 5.355672836303711
bi 1 loss 4.939345836639404
bi 2 loss 5.0901103019714355
bi 3 loss 4.730912685394287
Layer  3  loss:  5.198079586029053 0.0 9.89844799041748
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1021
Curr loss timestep torch.Size([708, 4]) tensor([617, 247, 296, 145], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 5.481901168823242
bi 1 loss 5.15727424621582
bi 2 loss 5.06269645690918
bi 3 loss 4.520300388336182
Layer  4  loss:  5.324224948883057 0.0 9.655677795410156
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([552,  48, 197, 110], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 5.615498065948486
bi 1 loss 5.138977527618408
bi 2 loss 5.251471996307373
bi 3 loss 4.802897930145264
Layer  5  loss:  5.393085956573486 0.0 9.858697891235352
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1022
Curr loss timestep torch.Size([708, 4]) tensor([286, 238, 462,  75], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 5.666072845458984
bi 1 loss 5.355142593383789
bi 2 loss 5.286099910736084
bi 3 loss 4.663660526275635
Layer  6  loss:  5.487945079803467 0.0 10.561819076538086
logits torch.Size([708, 4, 1024]) labels torch.Size([708, 4]) 0 1023
Curr loss timestep torch.Size([708, 4]) tensor([337, 297, 350, 124], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 5.70815896987915
bi 1 loss 5.419910430908203
bi 2 loss 5.440959930419922
bi 3 loss 4.874791145324707
Epoch 0: :   3%|▎         | 15589/600000 [04:06<2:33:52, v_num=12, reduced_train_loss=33.80, global_step=15587.0, consumed_samples=62352.0, train_step_timing in s=0.274]Epoch 0: :   3%|▎         | 15589/600000 [04:06<2:33:52, v_num=12, reduced_train_loss=39.80, global_step=15588.0, consumed_samples=62356.0, train_step_timing in s=0.430]loss mask original None

First layer loss:  3.334592580795288 torch.Size([580, 4]) 12.797767639160156 0.0
Max loss timestep torch.Size([580, 4]) tensor([356, 216, 362, 340], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 3.278432846069336
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
bi 1 loss 3.4616496562957764
speech mask sum tensor(126, device='cuda:0') loss mask sum tensor(126, device='cuda:0')
bi 2 loss 3.16148042678833
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
bi 3 loss 3.6138033866882324
speech mask sum tensor(233, device='cuda:0') loss mask sum tensor(233, device='cuda:0')
logits torch.Size([580, 4, 257024]) labels torch.Size([580, 4]) 0 257023
Layer  0  loss:  4.05620813369751 0.0 11.075057983398438
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([398, 197, 221, 367], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 3.981172800064087
bi 1 loss 4.098368167877197
bi 2 loss 3.8042798042297363
bi 3 loss 4.535283088684082
Layer  1  loss:  4.316643238067627 0.0 9.561694145202637
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([322, 199, 518, 371], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 4.177358627319336
bi 1 loss 4.056773662567139
bi 2 loss 4.188014984130859
bi 3 loss 4.7805867195129395
Layer  2  loss:  4.561338901519775 0.0 10.894845962524414
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1022
Curr loss timestep torch.Size([580, 4]) tensor([315, 248, 323, 174], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 4.3780741691589355
bi 1 loss 4.451208591461182
bi 2 loss 4.430167198181152
bi 3 loss 4.978129863739014
Layer  3  loss:  4.629709720611572 0.0 10.089308738708496
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([313, 263, 448, 302], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 4.232572078704834
bi 1 loss 4.547774791717529
bi 2 loss 4.554439067840576
bi 3 loss 5.073243618011475
Layer  4  loss:  4.801164627075195 0.0 9.379215240478516
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1022
Curr loss timestep torch.Size([580, 4]) tensor([413, 224, 295, 240], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 4.542867660522461
bi 1 loss 4.581018924713135
bi 2 loss 4.719139099121094
bi 3 loss 5.239195823669434
Layer  5  loss:  4.8741774559021 0.0 10.146206855773926
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1022
Curr loss timestep torch.Size([580, 4]) tensor([398, 238, 308, 219], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 4.6368513107299805
bi 1 loss 4.598413944244385
bi 2 loss 4.826183319091797
bi 3 loss 5.267281532287598
Layer  6  loss:  4.894533157348633 0.0 10.84811782836914
logits torch.Size([580, 4, 1024]) labels torch.Size([580, 4]) 0 1023
Curr loss timestep torch.Size([580, 4]) tensor([404, 185, 406, 205], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.565123558044434
bi 1 loss 4.730876445770264
bi 2 loss 4.860220909118652
bi 3 loss 5.263725280761719
Epoch 0: :   3%|▎         | 15590/600000 [04:06<2:34:07, v_num=12, reduced_train_loss=39.80, global_step=15588.0, consumed_samples=62356.0, train_step_timing in s=0.430]Epoch 0: :   3%|▎         | 15590/600000 [04:06<2:34:07, v_num=12, reduced_train_loss=35.50, global_step=15589.0, consumed_samples=62360.0, train_step_timing in s=0.367]loss mask original None

First layer loss:  3.3948426246643066 torch.Size([300, 4]) 13.694406509399414 0.0
Max loss timestep torch.Size([300, 4]) tensor([159, 163,  98, 276], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 3.3516716957092285
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 1 loss 2.4201982021331787
speech mask sum tensor(98, device='cuda:0') loss mask sum tensor(98, device='cuda:0')
bi 2 loss 3.3278050422668457
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 3 loss 3.827378034591675
speech mask sum tensor(257, device='cuda:0') loss mask sum tensor(257, device='cuda:0')
logits torch.Size([300, 4, 257024]) labels torch.Size([300, 4]) 0 257022
Layer  0  loss:  3.9705872535705566 0.0 10.47496509552002
logits torch.Size([300, 4, 1024]) labels torch.Size([300, 4]) 0 1023
Curr loss timestep torch.Size([300, 4]) tensor([199, 164, 207,  78], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 3.9097418785095215
bi 1 loss 3.241790771484375
bi 2 loss 3.7731730937957764
bi 3 loss 4.401986122131348
Layer  1  loss:  4.1399712562561035 0.0 9.508594512939453
logits torch.Size([300, 4, 1024]) labels torch.Size([300, 4]) 0 1022
Curr loss timestep torch.Size([300, 4]) tensor([181, 193,  99, 274], device='cuda:0') tensor(146, device='cuda:0')
bi 0 loss 3.821296453475952
bi 1 loss 3.233229637145996
bi 2 loss 4.163361549377441
bi 3 loss 4.594349384307861
Layer  2  loss:  4.357263088226318 0.0 10.700693130493164
logits torch.Size([300, 4, 1024]) labels torch.Size([300, 4]) 0 1022
Curr loss timestep torch.Size([300, 4]) tensor([179, 166, 180, 266], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 4.2474141120910645
bi 1 loss 3.3940324783325195
bi 2 loss 4.353755950927734
bi 3 loss 4.769613742828369
Layer  3  loss:  4.545577526092529 0.0 10.66191577911377
logits torch.Size([300, 4, 1024]) labels torch.Size([300, 4]) 0 1022
Curr loss timestep torch.Size([300, 4]) tensor([190, 180, 202,  75], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.311234951019287
bi 1 loss 3.628178596496582
bi 2 loss 4.636967182159424
bi 3 loss 4.926490783691406
Layer  4  loss:  4.6214985847473145 0.0 10.075794219970703
logits torch.Size([300, 4, 1024]) labels torch.Size([300, 4]) 0 1022
Curr loss timestep torch.Size([300, 4]) tensor([209, 161, 176, 204], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 4.2649245262146
bi 1 loss 3.807161808013916
bi 2 loss 4.741319179534912
bi 3 loss 4.991976737976074
Layer  5  loss:  4.749861240386963 0.0 9.998099327087402
logits torch.Size([300, 4, 1024]) labels torch.Size([300, 4]) 0 1022
Curr loss timestep torch.Size([300, 4]) tensor([165, 159, 165,  56], device='cuda:0') tensor(165, device='cuda:0')
bi 0 loss 4.533509731292725
bi 1 loss 4.1361188888549805
bi 2 loss 4.870919704437256
bi 3 loss 4.988471508026123
Layer  6  loss:  4.819509029388428 0.0 9.150412559509277
logits torch.Size([300, 4, 1024]) labels torch.Size([300, 4]) 0 1019
Curr loss timestep torch.Size([300, 4]) tensor([198, 158, 238, 260], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 4.7563395500183105
bi 1 loss 4.10101318359375
bi 2 loss 4.850832939147949
bi 3 loss 5.097469329833984
Epoch 0: :   3%|▎         | 15591/600000 [04:06<2:34:17, v_num=12, reduced_train_loss=35.50, global_step=15589.0, consumed_samples=62360.0, train_step_timing in s=0.367]Epoch 0: :   3%|▎         | 15591/600000 [04:06<2:34:17, v_num=12, reduced_train_loss=34.60, global_step=15590.0, consumed_samples=62364.0, train_step_timing in s=0.250]loss mask original None

First layer loss:  0.04339369013905525 torch.Size([450, 4]) 2.6025400161743164 0.0
Max loss timestep torch.Size([450, 4]) tensor([308, 298, 282, 195], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.042199715971946716
speech mask sum tensor(383, device='cuda:0') loss mask sum tensor(383, device='cuda:0')
bi 1 loss 0.05249110609292984
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 2 loss 0.04721752926707268
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.03487471491098404
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
logits torch.Size([450, 4, 257024]) labels torch.Size([450, 4]) 0 257023
Layer  0  loss:  0.03628102317452431 0.0 1.0973740816116333
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([310, 191, 268, 220], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 0.043409861624240875
bi 1 loss 0.037427790462970734
bi 2 loss 0.04309272766113281
bi 3 loss 0.017954763025045395
Layer  1  loss:  0.03972616791725159 0.0 1.4781548976898193
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([ 95, 348, 307, 280], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.036610428243875504
bi 1 loss 0.056904442608356476
bi 2 loss 0.04743078351020813
bi 3 loss 0.024823224171996117
Layer  2  loss:  0.0460098534822464 0.0 1.9708871841430664
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([260, 292, 216, 196], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.050640080124139786
bi 1 loss 0.04774031415581703
bi 2 loss 0.057208795100450516
bi 3 loss 0.028529630973935127
Layer  3  loss:  0.038675080984830856 0.0 2.5335519313812256
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1021
Curr loss timestep torch.Size([450, 4]) tensor([310, 290, 276, 114], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 0.05133722350001335
bi 1 loss 0.036139991134405136
bi 2 loss 0.03706767410039902
bi 3 loss 0.01966487057507038
Layer  4  loss:  0.04216423258185387 0.0 1.436340093612671
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1022
Curr loss timestep torch.Size([450, 4]) tensor([261, 234, 331, 201], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 0.04314495995640755
bi 1 loss 0.040164802223443985
bi 2 loss 0.04730886593461037
bi 3 loss 0.038604043424129486
Layer  5  loss:  0.03984345495700836 0.0 1.8701611757278442
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([304, 298, 251, 279], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.04675399512052536
bi 1 loss 0.034072503447532654
bi 2 loss 0.04620520398020744
bi 3 loss 0.028272567316889763
Layer  6  loss:  0.03936179354786873 0.0 0.9412832856178284
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1020
Curr loss timestep torch.Size([450, 4]) tensor([304, 244, 302, 198], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.04249587655067444
bi 1 loss 0.047106221318244934
bi 2 loss 0.034098751842975616
bi 3 loss 0.03071167692542076
Epoch 0: :   3%|▎         | 15592/600000 [04:07<2:34:30, v_num=12, reduced_train_loss=34.60, global_step=15590.0, consumed_samples=62364.0, train_step_timing in s=0.250]Epoch 0: :   3%|▎         | 15592/600000 [04:07<2:34:30, v_num=12, reduced_train_loss=0.325, global_step=15591.0, consumed_samples=62368.0, train_step_timing in s=0.325]loss mask original None

First layer loss:  0.16079236567020416 torch.Size([550, 4]) 14.22074031829834 0.0
Max loss timestep torch.Size([550, 4]) tensor([363, 489, 477, 337], device='cuda:0') tensor(477, device='cuda:0')
bi 0 loss 0.13720782101154327
speech mask sum tensor(376, device='cuda:0') loss mask sum tensor(376, device='cuda:0')
bi 1 loss 0.23434628546237946
speech mask sum tensor(423, device='cuda:0') loss mask sum tensor(423, device='cuda:0')
bi 2 loss 0.15336734056472778
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 3 loss 0.10470114648342133
speech mask sum tensor(350, device='cuda:0') loss mask sum tensor(350, device='cuda:0')
logits torch.Size([550, 4, 257024]) labels torch.Size([550, 4]) 0 257022
Layer  0  loss:  0.1968773603439331 0.0 17.811077117919922
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([363, 276, 379, 415], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.15628957748413086
bi 1 loss 0.33386194705963135
bi 2 loss 0.16085778176784515
bi 3 loss 0.1111498773097992
Layer  1  loss:  0.18898920714855194 0.0 14.176446914672852
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([363, 277, 477, 447], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.18277493119239807
bi 1 loss 0.2538909614086151
bi 2 loss 0.19076305627822876
bi 3 loss 0.11544270068407059
Layer  2  loss:  0.20785991847515106 0.0 20.312923431396484
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1022
Curr loss timestep torch.Size([550, 4]) tensor([363, 274, 477, 376], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.1849994659423828
bi 1 loss 0.34102094173431396
bi 2 loss 0.17936110496520996
bi 3 loss 0.1001456156373024
Layer  3  loss:  0.22789812088012695 0.0 22.066219329833984
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([427, 277, 477, 428], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.1459028124809265
bi 1 loss 0.38125643134117126
bi 2 loss 0.19430924952030182
bi 3 loss 0.16442078351974487
Layer  4  loss:  0.2289789766073227 0.0 15.957133293151855
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([363, 277, 379, 447], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.1963706761598587
bi 1 loss 0.36564797163009644
bi 2 loss 0.1913127899169922
bi 3 loss 0.13671676814556122
Layer  5  loss:  0.23719461262226105 0.0 17.265892028808594
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([363, 276, 477, 447], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.1697675883769989
bi 1 loss 0.37253686785697937
bi 2 loss 0.23195067048072815
bi 3 loss 0.15133363008499146
Layer  6  loss:  0.2086847871541977 0.0 19.828996658325195
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([427, 276, 319, 447], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.16613510251045227
bi 1 loss 0.33891600370407104
bi 2 loss 0.17078514397144318
bi 3 loss 0.13511784374713898
Epoch 0: :   3%|▎         | 15593/600000 [04:07<2:34:44, v_num=12, reduced_train_loss=0.325, global_step=15591.0, consumed_samples=62368.0, train_step_timing in s=0.325]Epoch 0: :   3%|▎         | 15593/600000 [04:07<2:34:44, v_num=12, reduced_train_loss=1.660, global_step=15592.0, consumed_samples=62372.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  0.07707127928733826 torch.Size([583, 4]) 8.591264724731445 0.0
Max loss timestep torch.Size([583, 4]) tensor([129, 510, 319, 124], device='cuda:0') tensor(510, device='cuda:0')
bi 0 loss 0.05640804395079613
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 1 loss 0.14552848041057587
speech mask sum tensor(240, device='cuda:0') loss mask sum tensor(240, device='cuda:0')
bi 2 loss 0.049044426530599594
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 3 loss 0.03236905112862587
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([583, 4, 257024]) labels torch.Size([583, 4]) 0 257022
Layer  0  loss:  0.0748310461640358 0.0 6.895541667938232
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([306, 514, 338, 133], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.030947692692279816
bi 1 loss 0.14094479382038116
bi 2 loss 0.05405212193727493
bi 3 loss 0.06166691705584526
Layer  1  loss:  0.09303442388772964 0.0 7.505973815917969
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([223, 514, 380, 180], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.0316467247903347
bi 1 loss 0.17670154571533203
bi 2 loss 0.08436581492424011
bi 3 loss 0.038666874170303345
Layer  2  loss:  0.09531090408563614 0.0 8.67907428741455
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([186, 514, 380, 141], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.04108703136444092
bi 1 loss 0.15576641261577606
bi 2 loss 0.10176465660333633
bi 3 loss 0.04005275294184685
Layer  3  loss:  0.11560479551553726 0.0 8.315780639648438
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([291, 511, 380, 177], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.04644359275698662
bi 1 loss 0.18773500621318817
bi 2 loss 0.13337396085262299
bi 3 loss 0.030369434505701065
Layer  4  loss:  0.12288583070039749 0.0 9.45384407043457
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([290, 514, 399, 179], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.054104648530483246
bi 1 loss 0.26760104298591614
bi 2 loss 0.07849911600351334
bi 3 loss 0.03672661632299423
Layer  5  loss:  0.10474270582199097 0.0 9.426220893859863
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1023
Curr loss timestep torch.Size([583, 4]) tensor([259, 510, 396, 152], device='cuda:0') tensor(510, device='cuda:0')
bi 0 loss 0.054202910512685776
bi 1 loss 0.216010183095932
bi 2 loss 0.07259970903396606
bi 3 loss 0.02827533334493637
Layer  6  loss:  0.1001565009355545 0.0 7.127335071563721
logits torch.Size([583, 4, 1024]) labels torch.Size([583, 4]) 0 1022
Curr loss timestep torch.Size([583, 4]) tensor([209, 510, 360, 173], device='cuda:0') tensor(510, device='cuda:0')
bi 0 loss 0.051970209926366806
bi 1 loss 0.174466073513031
bi 2 loss 0.09820258617401123
bi 3 loss 0.023175230249762535
Epoch 0: :   3%|▎         | 15594/600000 [04:08<2:35:00, v_num=12, reduced_train_loss=1.660, global_step=15592.0, consumed_samples=62372.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15594/600000 [04:08<2:35:00, v_num=12, reduced_train_loss=0.784, global_step=15593.0, consumed_samples=62376.0, train_step_timing in s=0.400]loss mask original None

First layer loss:  0.08887068182229996 torch.Size([547, 4]) 9.316052436828613 0.0
Max loss timestep torch.Size([547, 4]) tensor([511, 258, 335, 126], device='cuda:0') tensor(511, device='cuda:0')
bi 0 loss 0.12139362841844559
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 1 loss 0.0776081457734108
speech mask sum tensor(383, device='cuda:0') loss mask sum tensor(383, device='cuda:0')
bi 2 loss 0.07212962210178375
speech mask sum tensor(290, device='cuda:0') loss mask sum tensor(290, device='cuda:0')
bi 3 loss 0.030982326716184616
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
logits torch.Size([547, 4, 257024]) labels torch.Size([547, 4]) 0 257022
Layer  0  loss:  0.10668066889047623 0.0 8.735275268554688
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([511, 512, 317, 120], device='cuda:0') tensor(511, device='cuda:0')
bi 0 loss 0.11488288640975952
bi 1 loss 0.13120242953300476
bi 2 loss 0.08180582523345947
bi 3 loss 0.04481389746069908
Layer  1  loss:  0.11282084882259369 0.0 11.77072811126709
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([511, 395, 171, 145], device='cuda:0') tensor(511, device='cuda:0')
bi 0 loss 0.1254550665616989
bi 1 loss 0.13468295335769653
bi 2 loss 0.09079032391309738
bi 3 loss 0.03195365145802498
Layer  2  loss:  0.1289326399564743 0.0 9.009416580200195
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([511, 512, 320, 125], device='cuda:0') tensor(511, device='cuda:0')
bi 0 loss 0.14486342668533325
bi 1 loss 0.1763661503791809
bi 2 loss 0.07558801025152206
bi 3 loss 0.024912862107157707
Layer  3  loss:  0.14102275669574738 0.0 11.34588623046875
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([533, 512, 294, 148], device='cuda:0') tensor(512, device='cuda:0')
bi 0 loss 0.16046316921710968
bi 1 loss 0.18452122807502747
bi 2 loss 0.09166490286588669
bi 3 loss 0.024035584181547165
Layer  4  loss:  0.1268000304698944 0.0 6.516626358032227
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([511, 511, 295, 169], device='cuda:0') tensor(511, device='cuda:0')
bi 0 loss 0.1310252696275711
bi 1 loss 0.18155664205551147
bi 2 loss 0.08217160403728485
bi 3 loss 0.022219916805624962
Layer  5  loss:  0.13838951289653778 0.0 11.448872566223145
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1022
Curr loss timestep torch.Size([547, 4]) tensor([533, 512, 320, 134], device='cuda:0') tensor(512, device='cuda:0')
bi 0 loss 0.1893043965101242
bi 1 loss 0.1642618179321289
bi 2 loss 0.0620386004447937
bi 3 loss 0.02544267475605011
Layer  6  loss:  0.14341309666633606 0.0 12.391433715820312
logits torch.Size([547, 4, 1024]) labels torch.Size([547, 4]) 0 1023
Curr loss timestep torch.Size([547, 4]) tensor([511, 512, 295, 168], device='cuda:0') tensor(512, device='cuda:0')
bi 0 loss 0.16922727227210999
bi 1 loss 0.18399697542190552
bi 2 loss 0.0900929719209671
bi 3 loss 0.020013058558106422
Epoch 0: :   3%|▎         | 15595/600000 [04:08<2:35:15, v_num=12, reduced_train_loss=0.784, global_step=15593.0, consumed_samples=62376.0, train_step_timing in s=0.400]Epoch 0: :   3%|▎         | 15595/600000 [04:08<2:35:15, v_num=12, reduced_train_loss=0.987, global_step=15594.0, consumed_samples=62380.0, train_step_timing in s=0.387]loss mask original None

First layer loss:  0.10420332849025726 torch.Size([638, 4]) 13.907569885253906 0.0
Max loss timestep torch.Size([638, 4]) tensor([141, 284, 285, 544], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.032028745859861374
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
bi 1 loss 0.054502859711647034
speech mask sum tensor(90, device='cuda:0') loss mask sum tensor(90, device='cuda:0')
bi 2 loss 0.21089085936546326
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.10731891542673111
speech mask sum tensor(469, device='cuda:0') loss mask sum tensor(469, device='cuda:0')
logits torch.Size([638, 4, 257024]) labels torch.Size([638, 4]) 0 257023
Layer  0  loss:  0.10750668495893478 0.0 5.026147365570068
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([155, 269, 311, 510], device='cuda:0') tensor(510, device='cuda:0')
bi 0 loss 0.04974109306931496
bi 1 loss 0.03878436237573624
bi 2 loss 0.13891620934009552
bi 3 loss 0.13017146289348602
Layer  1  loss:  0.1152808666229248 0.0 7.382478713989258
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([143, 281, 285, 514], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.037056814879179
bi 1 loss 0.0620696060359478
bi 2 loss 0.17204557359218597
bi 3 loss 0.13447193801403046
Layer  2  loss:  0.11641715466976166 0.0 5.493585586547852
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([126, 256, 285, 514], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.04207617789506912
bi 1 loss 0.05573370307683945
bi 2 loss 0.13288207352161407
bi 3 loss 0.14674605429172516
Layer  3  loss:  0.13523901998996735 0.0 10.473453521728516
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([184, 257, 285, 456], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.047294389456510544
bi 1 loss 0.06223982572555542
bi 2 loss 0.23006941378116608
bi 3 loss 0.15094560384750366
Layer  4  loss:  0.15826918184757233 0.0 6.379056930541992
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([141, 256, 281, 514], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.04687929525971413
bi 1 loss 0.06056546792387962
bi 2 loss 0.13142511248588562
bi 3 loss 0.21896310150623322
Layer  5  loss:  0.13923117518424988 0.0 14.121138572692871
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([124, 260, 285, 525], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.04859938099980354
bi 1 loss 0.07181251794099808
bi 2 loss 0.26154759526252747
bi 3 loss 0.14726045727729797
Layer  6  loss:  0.12420439720153809 0.0 5.147493362426758
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1020
Curr loss timestep torch.Size([638, 4]) tensor([204, 286, 281, 544], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 0.038745466619729996
bi 1 loss 0.05482146888971329
bi 2 loss 0.17845173180103302
bi 3 loss 0.14943267405033112
Epoch 0: :   3%|▎         | 15596/600000 [04:09<2:35:33, v_num=12, reduced_train_loss=0.987, global_step=15594.0, consumed_samples=62380.0, train_step_timing in s=0.387]Epoch 0: :   3%|▎         | 15596/600000 [04:09<2:35:33, v_num=12, reduced_train_loss=1.000, global_step=15595.0, consumed_samples=62384.0, train_step_timing in s=0.436]loss mask original None

First layer loss:  0.10845469683408737 torch.Size([601, 4]) 7.507001876831055 0.0
Max loss timestep torch.Size([601, 4]) tensor([583, 376, 263, 410], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.127391517162323
speech mask sum tensor(353, device='cuda:0') loss mask sum tensor(353, device='cuda:0')
bi 1 loss 0.09888467192649841
speech mask sum tensor(371, device='cuda:0') loss mask sum tensor(371, device='cuda:0')
bi 2 loss 0.06350012123584747
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.12012851983308792
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
logits torch.Size([601, 4, 257024]) labels torch.Size([601, 4]) 0 257022
Layer  0  loss:  0.10848269611597061 0.0 10.636115074157715
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([583, 491, 263, 473], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.16910932958126068
bi 1 loss 0.08138275891542435
bi 2 loss 0.06716731935739517
bi 3 loss 0.09216159582138062
Layer  1  loss:  0.14077211916446686 0.0 10.560567855834961
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([583, 491, 186, 477], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.19436118006706238
bi 1 loss 0.12158630043268204
bi 2 loss 0.05497341230511665
bi 3 loss 0.1444673091173172
Layer  2  loss:  0.14404581487178802 0.0 13.719287872314453
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([583, 491, 263, 477], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.18291784822940826
bi 1 loss 0.13131234049797058
bi 2 loss 0.08435441553592682
bi 3 loss 0.1440960019826889
Layer  3  loss:  0.12214408814907074 0.0 15.875017166137695
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([583, 376, 263, 477], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.16364429891109467
bi 1 loss 0.11415676027536392
bi 2 loss 0.05234801769256592
bi 3 loss 0.11847935616970062
Layer  4  loss:  0.1504218429327011 0.0 12.372808456420898
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([584, 492, 135, 477], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.1993734985589981
bi 1 loss 0.1555931568145752
bi 2 loss 0.09091334044933319
bi 3 loss 0.11779338121414185
Layer  5  loss:  0.1112993061542511 0.0 7.448856830596924
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([581, 492, 265, 410], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.13439859449863434
bi 1 loss 0.08924318850040436
bi 2 loss 0.05581711232662201
bi 3 loss 0.13815738260746002
Layer  6  loss:  0.14630325138568878 0.0 13.329466819763184
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([583, 492, 260, 379], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.18943734467029572
bi 1 loss 0.14486636221408844
bi 2 loss 0.06025995314121246
bi 3 loss 0.1408696174621582
Epoch 0: :   3%|▎         | 15597/600000 [04:09<2:35:49, v_num=12, reduced_train_loss=1.000, global_step=15595.0, consumed_samples=62384.0, train_step_timing in s=0.436]Epoch 0: :   3%|▎         | 15597/600000 [04:09<2:35:49, v_num=12, reduced_train_loss=1.030, global_step=15596.0, consumed_samples=62388.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.11476518958806992 torch.Size([599, 4]) 10.842304229736328 0.0
Max loss timestep torch.Size([599, 4]) tensor([190, 191, 493, 546], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.09011843800544739
speech mask sum tensor(347, device='cuda:0') loss mask sum tensor(347, device='cuda:0')
bi 1 loss 0.020975274965167046
speech mask sum tensor(63, device='cuda:0') loss mask sum tensor(63, device='cuda:0')
bi 2 loss 0.09792937338352203
speech mask sum tensor(443, device='cuda:0') loss mask sum tensor(443, device='cuda:0')
bi 3 loss 0.16336706280708313
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257022
Layer  0  loss:  0.14547869563102722 0.0 6.094735145568848
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([494, 217, 498, 542], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 0.11790540814399719
bi 1 loss 0.12686015665531158
bi 2 loss 0.1613319367170334
bi 3 loss 0.15372242033481598
Layer  1  loss:  0.14143355190753937 0.0 14.586194038391113
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([274, 194, 493, 546], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.12974156439304352
bi 1 loss 0.02995429001748562
bi 2 loss 0.14787094295024872
bi 3 loss 0.15967868268489838
Layer  2  loss:  0.15421396493911743 0.0 9.468249320983887
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([478, 210, 493, 546], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.11243033409118652
bi 1 loss 0.03862224891781807
bi 2 loss 0.18277046084403992
bi 3 loss 0.1744593232870102
Layer  3  loss:  0.1538684070110321 0.0 13.24693775177002
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([494, 224, 372, 546], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.1208299994468689
bi 1 loss 0.017555098980665207
bi 2 loss 0.16434241831302643
bi 3 loss 0.1880415380001068
Layer  4  loss:  0.15443596243858337 0.0 8.49111270904541
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([339, 191, 370, 546], device='cuda:0') tensor(370, device='cuda:0')
bi 0 loss 0.127282977104187
bi 1 loss 0.04201639071106911
bi 2 loss 0.18767927587032318
bi 3 loss 0.1583777219057083
Layer  5  loss:  0.15245367586612701 0.0 9.945540428161621
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([494, 188, 493, 542], device='cuda:0') tensor(493, device='cuda:0')
bi 0 loss 0.14688095450401306
bi 1 loss 0.040834423154592514
bi 2 loss 0.1709062159061432
bi 3 loss 0.1542081981897354
Layer  6  loss:  0.1662425696849823 0.0 11.101900100708008
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([339, 194, 500, 373], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 0.1441432237625122
bi 1 loss 0.02489616349339485
bi 2 loss 0.14932793378829956
bi 3 loss 0.21960504353046417
Epoch 0: :   3%|▎         | 15598/600000 [04:09<2:36:06, v_num=12, reduced_train_loss=1.030, global_step=15596.0, consumed_samples=62388.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15598/600000 [04:09<2:36:06, v_num=12, reduced_train_loss=1.180, global_step=15597.0, consumed_samples=62392.0, train_step_timing in s=0.422]loss mask original None

First layer loss:  0.30415117740631104 torch.Size([685, 4]) 10.060074806213379 0.0
Max loss timestep torch.Size([685, 4]) tensor([582, 321, 148, 103], device='cuda:0') tensor(582, device='cuda:0')
bi 0 loss 0.41786059737205505
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
bi 1 loss 0.21290093660354614
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 2 loss 0.016138818114995956
speech mask sum tensor(71, device='cuda:0') loss mask sum tensor(71, device='cuda:0')
bi 3 loss 0.08711040765047073
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
logits torch.Size([685, 4, 257024]) labels torch.Size([685, 4]) 0 257023
Layer  0  loss:  0.30822107195854187 0.0 12.903610229492188
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([554, 321, 159, 131], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.42722001671791077
bi 1 loss 0.19843533635139465
bi 2 loss 0.019757505506277084
bi 3 loss 0.08810056000947952
Layer  1  loss:  0.3672448396682739 0.0 22.25364112854004
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([331, 318, 175, 168], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.5160436630249023
bi 1 loss 0.20948490500450134
bi 2 loss 0.030827242881059647
bi 3 loss 0.09758792072534561
Layer  2  loss:  0.3635280430316925 0.0 13.957060813903809
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([581, 318, 155, 119], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.4954676330089569
bi 1 loss 0.24617697298526764
bi 2 loss 0.018843986093997955
bi 3 loss 0.13362105190753937
Layer  3  loss:  0.33018428087234497 0.0 13.133645057678223
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([331, 321, 173, 101], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.457188218832016
bi 1 loss 0.22610291838645935
bi 2 loss 0.050869982689619064
bi 3 loss 0.05729913339018822
Layer  4  loss:  0.33586594462394714 0.0 10.780866622924805
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([330, 321, 186, 149], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.4749976396560669
bi 1 loss 0.17630288004875183
bi 2 loss 0.02410280518233776
bi 3 loss 0.0959809273481369
Layer  5  loss:  0.36595526337623596 0.0 22.846067428588867
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([330, 321, 177, 159], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.5205671191215515
bi 1 loss 0.19926290214061737
bi 2 loss 0.024552451446652412
bi 3 loss 0.08271604776382446
Layer  6  loss:  0.3534151017665863 0.0 15.687657356262207
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([332, 321, 185, 101], device='cuda:0') tensor(332, device='cuda:0')
bi 0 loss 0.4982816278934479
bi 1 loss 0.194907546043396
bi 2 loss 0.07916457951068878
bi 3 loss 0.055206041783094406
Epoch 0: :   3%|▎         | 15599/600000 [04:10<2:36:24, v_num=12, reduced_train_loss=1.180, global_step=15597.0, consumed_samples=62392.0, train_step_timing in s=0.422]Epoch 0: :   3%|▎         | 15599/600000 [04:10<2:36:24, v_num=12, reduced_train_loss=2.730, global_step=15598.0, consumed_samples=62396.0, train_step_timing in s=0.464]loss mask original None

First layer loss:  0.08047884702682495 torch.Size([509, 4]) 13.18387222290039 0.0
Max loss timestep torch.Size([509, 4]) tensor([371, 250, 351, 274], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.05590445548295975
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 1 loss 0.04418708756566048
speech mask sum tensor(216, device='cuda:0') loss mask sum tensor(216, device='cuda:0')
bi 2 loss 0.1353817731142044
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 3 loss 0.03561510145664215
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
logits torch.Size([509, 4, 257024]) labels torch.Size([509, 4]) 0 257022
Layer  0  loss:  0.1065109521150589 0.0 14.98739242553711
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([258, 208, 350, 329], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.1074637845158577
bi 1 loss 0.04302097111940384
bi 2 loss 0.16946451365947723
bi 3 loss 0.04437875375151634
Layer  1  loss:  0.1235884577035904 0.0 14.048175811767578
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([371, 330, 350, 182], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.1772705763578415
bi 1 loss 0.06799483299255371
bi 2 loss 0.15602174401283264
bi 3 loss 0.05180992931127548
Layer  2  loss:  0.10388524830341339 0.0 17.909595489501953
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([297, 272, 352, 325], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.11747598648071289
bi 1 loss 0.04245571792125702
bi 2 loss 0.1626206934452057
bi 3 loss 0.03253761678934097
Layer  3  loss:  0.10715088248252869 0.0 14.5939359664917
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([275, 259, 352, 328], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.11613401025533676
bi 1 loss 0.049736183136701584
bi 2 loss 0.14966073632240295
bi 3 loss 0.07196164131164551
Layer  4  loss:  0.10305951535701752 0.0 10.877492904663086
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([276, 198, 352, 334], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.14276279509067535
bi 1 loss 0.05127844214439392
bi 2 loss 0.12832742929458618
bi 3 loss 0.05985679104924202
Layer  5  loss:  0.11770778149366379 0.0 19.562576293945312
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([297, 258, 351, 345], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.12711435556411743
bi 1 loss 0.04596727341413498
bi 2 loss 0.18422839045524597
bi 3 loss 0.047008439898490906
Layer  6  loss:  0.12104560434818268 0.0 13.594149589538574
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1021
Curr loss timestep torch.Size([509, 4]) tensor([297, 248, 350, 272], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.13898137211799622
bi 1 loss 0.057916268706321716
bi 2 loss 0.16485142707824707
bi 3 loss 0.07856841385364532
Epoch 0: :   3%|▎         | 15600/600000 [04:10<2:36:38, v_num=12, reduced_train_loss=2.730, global_step=15598.0, consumed_samples=62396.0, train_step_timing in s=0.464]Epoch 0: :   3%|▎         | 15600/600000 [04:10<2:36:38, v_num=12, reduced_train_loss=0.863, global_step=15599.0, consumed_samples=62400.0, train_step_timing in s=0.356]loss mask original None

First layer loss:  0.14508146047592163 torch.Size([614, 4]) 11.40859603881836 0.0
Max loss timestep torch.Size([614, 4]) tensor([ 70, 381, 395, 159], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.05252591893076897
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 1 loss 0.1974325031042099
speech mask sum tensor(442, device='cuda:0') loss mask sum tensor(442, device='cuda:0')
bi 2 loss 0.147305428981781
speech mask sum tensor(243, device='cuda:0') loss mask sum tensor(243, device='cuda:0')
bi 3 loss 0.023421429097652435
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
logits torch.Size([614, 4, 257024]) labels torch.Size([614, 4]) 0 257023
Layer  0  loss:  0.16419698297977448 0.0 13.541008949279785
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([174, 505, 394, 161], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.043471839278936386
bi 1 loss 0.20803327858448029
bi 2 loss 0.1942729651927948
bi 3 loss 0.05870499089360237
Layer  1  loss:  0.18472476303577423 0.0 9.9705810546875
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([174, 537, 394, 179], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.05612755939364433
bi 1 loss 0.19664494693279266
bi 2 loss 0.28222817182540894
bi 3 loss 0.06554412841796875
Layer  2  loss:  0.2012566179037094 0.0 14.756464958190918
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([147, 537, 394, 137], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.06709964573383331
bi 1 loss 0.2151218056678772
bi 2 loss 0.32160526514053345
bi 3 loss 0.011620075441896915
Layer  3  loss:  0.21342195570468903 0.0 14.88532829284668
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1021
Curr loss timestep torch.Size([614, 4]) tensor([174, 496, 395, 169], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.05287282168865204
bi 1 loss 0.26942184567451477
bi 2 loss 0.2704739570617676
bi 3 loss 0.033521801233291626
Layer  4  loss:  0.24585330486297607 0.0 18.172258377075195
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1022
Curr loss timestep torch.Size([614, 4]) tensor([150, 505, 395, 165], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.07651541382074356
bi 1 loss 0.308765172958374
bi 2 loss 0.30642440915107727
bi 3 loss 0.0333663709461689
Layer  5  loss:  0.22096896171569824 0.0 11.448033332824707
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([154, 505, 395, 158], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.06416910886764526
bi 1 loss 0.29248878359794617
bi 2 loss 0.24703916907310486
bi 3 loss 0.04231996834278107
Layer  6  loss:  0.19600044190883636 0.0 13.625590324401855
logits torch.Size([614, 4, 1024]) labels torch.Size([614, 4]) 0 1023
Curr loss timestep torch.Size([614, 4]) tensor([109, 537, 394, 135], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.0428679920732975
bi 1 loss 0.24636822938919067
bi 2 loss 0.25051265954971313
bi 3 loss 0.041153643280267715
Epoch 0: :   3%|▎         | 15601/600000 [04:11<2:36:54, v_num=12, reduced_train_loss=0.863, global_step=15599.0, consumed_samples=62400.0, train_step_timing in s=0.356]Epoch 0: :   3%|▎         | 15601/600000 [04:11<2:36:54, v_num=12, reduced_train_loss=1.570, global_step=15600.0, consumed_samples=62404.0, train_step_timing in s=0.415]loss mask original None

First layer loss:  0.14505064487457275 torch.Size([683, 4]) 13.87534236907959 0.0
Max loss timestep torch.Size([683, 4]) tensor([625, 369, 322, 397], device='cuda:0') tensor(625, device='cuda:0')
bi 0 loss 0.21482740342617035
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 1 loss 0.14241239428520203
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
bi 2 loss 0.035011377185583115
speech mask sum tensor(218, device='cuda:0') loss mask sum tensor(218, device='cuda:0')
bi 3 loss 0.13722984492778778
speech mask sum tensor(505, device='cuda:0') loss mask sum tensor(505, device='cuda:0')
logits torch.Size([683, 4, 257024]) labels torch.Size([683, 4]) 0 257022
Layer  0  loss:  0.17038513720035553 0.0 10.857322692871094
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([625, 311, 180, 330], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.260960191488266
bi 1 loss 0.1156579777598381
bi 2 loss 0.059529855847358704
bi 3 loss 0.17761439085006714
Layer  1  loss:  0.17226900160312653 0.0 13.69777774810791
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([556, 369, 274, 331], device='cuda:0') tensor(556, device='cuda:0')
bi 0 loss 0.25552013516426086
bi 1 loss 0.11150401085615158
bi 2 loss 0.04800322279334068
bi 3 loss 0.19493305683135986
Layer  2  loss:  0.17594382166862488 0.0 13.976609230041504
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([568, 300, 263, 330], device='cuda:0') tensor(568, device='cuda:0')
bi 0 loss 0.2632625997066498
bi 1 loss 0.09763254225254059
bi 2 loss 0.06768254190683365
bi 3 loss 0.19904722273349762
Layer  3  loss:  0.18397466838359833 0.0 15.403156280517578
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([556, 300, 308, 569], device='cuda:0') tensor(556, device='cuda:0')
bi 0 loss 0.34843185544013977
bi 1 loss 0.12166707217693329
bi 2 loss 0.05028418451547623
bi 3 loss 0.14539366960525513
Layer  4  loss:  0.17048001289367676 0.0 9.778571128845215
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([556, 359, 302, 330], device='cuda:0') tensor(556, device='cuda:0')
bi 0 loss 0.2749308943748474
bi 1 loss 0.10360141098499298
bi 2 loss 0.04167810454964638
bi 3 loss 0.18152311444282532
Layer  5  loss:  0.2036866545677185 0.0 15.778634071350098
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([625, 358, 308, 396], device='cuda:0') tensor(625, device='cuda:0')
bi 0 loss 0.28415191173553467
bi 1 loss 0.10737202316522598
bi 2 loss 0.096896231174469
bi 3 loss 0.2426910400390625
Layer  6  loss:  0.17720216512680054 0.0 17.757871627807617
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([556, 358, 288, 330], device='cuda:0') tensor(556, device='cuda:0')
bi 0 loss 0.2770908772945404
bi 1 loss 0.11345408856868744
bi 2 loss 0.06123823672533035
bi 3 loss 0.18452230095863342
Epoch 0: :   3%|▎         | 15602/600000 [04:11<2:37:12, v_num=12, reduced_train_loss=1.570, global_step=15600.0, consumed_samples=62404.0, train_step_timing in s=0.415]Epoch 0: :   3%|▎         | 15602/600000 [04:11<2:37:12, v_num=12, reduced_train_loss=1.400, global_step=15601.0, consumed_samples=62408.0, train_step_timing in s=0.463]loss mask original None

First layer loss:  0.026208432391285896 torch.Size([385, 4]) 0.8387496471405029 0.0
Max loss timestep torch.Size([385, 4]) tensor([182,  81, 230, 215], device='cuda:0') tensor(81, device='cuda:0')
bi 0 loss 0.028294149786233902
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 1 loss 0.024594668298959732
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
bi 2 loss 0.0060681309551000595
speech mask sum tensor(72, device='cuda:0') loss mask sum tensor(72, device='cuda:0')
bi 3 loss 0.03755011409521103
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
logits torch.Size([385, 4, 257024]) labels torch.Size([385, 4]) 0 257022
Layer  0  loss:  0.023220540955662727 0.0 1.2121953964233398
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1023
Curr loss timestep torch.Size([385, 4]) tensor([ 80, 355, 229, 322], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.023640476167201996
bi 1 loss 0.022837992757558823
bi 2 loss 0.007672369480133057
bi 3 loss 0.031462661921978
Layer  1  loss:  0.02463766559958458 0.0 1.7106261253356934
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1023
Curr loss timestep torch.Size([385, 4]) tensor([142, 355, 236, 251], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.016602177172899246
bi 1 loss 0.030796857550740242
bi 2 loss 0.016216391697525978
bi 3 loss 0.02468733675777912
Layer  2  loss:  0.021861251443624496 0.0 0.39030924439430237
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1022
Curr loss timestep torch.Size([385, 4]) tensor([109, 330, 235, 229], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.02094101719558239
bi 1 loss 0.02304035797715187
bi 2 loss 0.010766252875328064
bi 3 loss 0.025925958529114723
Layer  3  loss:  0.023217445239424706 0.0 0.34413468837738037
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1021
Curr loss timestep torch.Size([385, 4]) tensor([ 82, 286, 240, 228], device='cuda:0') tensor(82, device='cuda:0')
bi 0 loss 0.0216972678899765
bi 1 loss 0.023475127294659615
bi 2 loss 0.015213562175631523
bi 3 loss 0.02854166179895401
Layer  4  loss:  0.02156696282327175 0.0 0.6523110866546631
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1023
Curr loss timestep torch.Size([385, 4]) tensor([ 88, 357, 233, 323], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.02194795198738575
bi 1 loss 0.02050083503127098
bi 2 loss 0.011232846416532993
bi 3 loss 0.028767695650458336
Layer  5  loss:  0.0208249781280756 0.0 0.4143225848674774
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1022
Curr loss timestep torch.Size([385, 4]) tensor([144, 355, 219, 222], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.02067393995821476
bi 1 loss 0.02185363881289959
bi 2 loss 0.011463327333331108
bi 3 loss 0.023415900766849518
Layer  6  loss:  0.02420615963637829 0.0 1.8091355562210083
logits torch.Size([385, 4, 1024]) labels torch.Size([385, 4]) 0 1020
Curr loss timestep torch.Size([385, 4]) tensor([196, 355, 235, 322], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.021840117871761322
bi 1 loss 0.02333412878215313
bi 2 loss 0.01522754319012165
bi 3 loss 0.03362483158707619
Epoch 0: :   3%|▎         | 15603/600000 [04:12<2:37:24, v_num=12, reduced_train_loss=1.400, global_step=15601.0, consumed_samples=62408.0, train_step_timing in s=0.463]Epoch 0: :   3%|▎         | 15603/600000 [04:12<2:37:24, v_num=12, reduced_train_loss=0.186, global_step=15602.0, consumed_samples=62412.0, train_step_timing in s=0.292]loss mask original None

First layer loss:  0.05447208508849144 torch.Size([441, 4]) 3.5364279747009277 0.0
Max loss timestep torch.Size([441, 4]) tensor([255, 302, 280, 287], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.04096078500151634
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 1 loss 0.05680033937096596
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 2 loss 0.06380174309015274
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 3 loss 0.052743542939424515
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
logits torch.Size([441, 4, 257024]) labels torch.Size([441, 4]) 0 257022
Layer  0  loss:  0.05656372755765915 0.0 3.8469369411468506
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([147, 368, 280, 167], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.03237523138523102
bi 1 loss 0.05067948251962662
bi 2 loss 0.0749564841389656
bi 3 loss 0.06469137221574783
Layer  1  loss:  0.05725269764661789 0.0 3.763820171356201
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([ 71, 392, 280, 272], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.026874247938394547
bi 1 loss 0.06819874793291092
bi 2 loss 0.06646072119474411
bi 3 loss 0.0608367919921875
Layer  2  loss:  0.05407002195715904 0.0 2.611417055130005
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([123, 169, 280, 270], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.03601237013936043
bi 1 loss 0.0486382432281971
bi 2 loss 0.06119745969772339
bi 3 loss 0.06998106092214584
Layer  3  loss:  0.05410425737500191 0.0 5.389297008514404
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([ 71, 313, 280, 265], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.027531802654266357
bi 1 loss 0.05639065057039261
bi 2 loss 0.0746617317199707
bi 3 loss 0.050928037613630295
Layer  4  loss:  0.05673252418637276 0.0 4.6643171310424805
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([217, 302, 280, 287], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.03550831973552704
bi 1 loss 0.050104789435863495
bi 2 loss 0.08486180007457733
bi 3 loss 0.05045352876186371
Layer  5  loss:  0.051472682505846024 0.0 5.583761215209961
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1018
Curr loss timestep torch.Size([441, 4]) tensor([ 96, 411, 280, 228], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.028314227238297462
bi 1 loss 0.04952065274119377
bi 2 loss 0.08260765671730042
bi 3 loss 0.03702346235513687
Layer  6  loss:  0.06226009503006935 0.0 2.8811230659484863
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([242, 302, 280, 261], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.05378594622015953
bi 1 loss 0.06806577742099762
bi 2 loss 0.052059106528759
bi 3 loss 0.0759536474943161
Epoch 0: :   3%|▎         | 15604/600000 [04:12<2:37:37, v_num=12, reduced_train_loss=0.186, global_step=15602.0, consumed_samples=62412.0, train_step_timing in s=0.292]Epoch 0: :   3%|▎         | 15604/600000 [04:12<2:37:37, v_num=12, reduced_train_loss=0.447, global_step=15603.0, consumed_samples=62416.0, train_step_timing in s=0.334]loss mask original None

First layer loss:  3.7329447269439697 torch.Size([568, 4]) 12.44321060180664 0.0
Max loss timestep torch.Size([568, 4]) tensor([358, 150, 381, 140], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 3.6765332221984863
speech mask sum tensor(360, device='cuda:0') loss mask sum tensor(360, device='cuda:0')
bi 1 loss 3.8649048805236816
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 3.857856035232544
speech mask sum tensor(461, device='cuda:0') loss mask sum tensor(461, device='cuda:0')
bi 3 loss 3.3522043228149414
speech mask sum tensor(144, device='cuda:0') loss mask sum tensor(144, device='cuda:0')
logits torch.Size([568, 4, 257024]) labels torch.Size([568, 4]) 0 257023
Layer  0  loss:  4.485043048858643 0.0 11.346294403076172
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([370,  83, 371, 128], device='cuda:0') tensor(120, device='cuda:0')
bi 0 loss 4.353302001953125
bi 1 loss 4.563387393951416
bi 2 loss 4.578540325164795
bi 3 loss 4.442713737487793
Layer  1  loss:  4.729934215545654 0.0 11.570297241210938
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([128, 152, 406, 149], device='cuda:0') tensor(150, device='cuda:0')
bi 0 loss 4.480971813201904
bi 1 loss 5.0539631843566895
bi 2 loss 4.819193363189697
bi 3 loss 4.76731014251709
Layer  2  loss:  4.930072784423828 0.0 12.240562438964844
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([313, 151, 207,  63], device='cuda:0') tensor(135, device='cuda:0')
bi 0 loss 4.768347263336182
bi 1 loss 4.977696418762207
bi 2 loss 4.990565776824951
bi 3 loss 5.096738815307617
Layer  3  loss:  4.966100692749023 0.0 12.431889533996582
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([330, 158, 160, 130], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 4.818187236785889
bi 1 loss 4.85529899597168
bi 2 loss 5.053669452667236
bi 3 loss 5.1578803062438965
Layer  4  loss:  5.11547327041626 0.0 11.32589340209961
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([ 90, 126, 254, 110], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 4.884437084197998
bi 1 loss 5.317599296569824
bi 2 loss 5.188955307006836
bi 3 loss 5.271132469177246
Layer  5  loss:  5.201107978820801 0.0 10.63706111907959
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1021
Curr loss timestep torch.Size([568, 4]) tensor([340, 132, 407,  67], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 4.9541425704956055
bi 1 loss 5.534653186798096
bi 2 loss 5.264111518859863
bi 3 loss 5.3087592124938965
Layer  6  loss:  5.197004318237305 0.0 11.257115364074707
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([341, 187, 499,  92], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 5.040112495422363
bi 1 loss 5.477547645568848
bi 2 loss 5.245263576507568
bi 3 loss 5.175623416900635
Epoch 0: :   3%|▎         | 15605/600000 [04:12<2:37:52, v_num=12, reduced_train_loss=0.447, global_step=15603.0, consumed_samples=62416.0, train_step_timing in s=0.334]Epoch 0: :   3%|▎         | 15605/600000 [04:12<2:37:52, v_num=12, reduced_train_loss=38.40, global_step=15604.0, consumed_samples=62420.0, train_step_timing in s=0.367]loss mask original None

First layer loss:  0.1368798166513443 torch.Size([415, 4]) 12.700830459594727 0.0
Max loss timestep torch.Size([415, 4]) tensor([199, 392, 283, 226], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.03805108740925789
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 1 loss 0.38707008957862854
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 2 loss 0.04822983220219612
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 3 loss 0.035434309393167496
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
logits torch.Size([415, 4, 257024]) labels torch.Size([415, 4]) 0 257023
Layer  0  loss:  0.14807499945163727 0.0 14.926828384399414
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1014
Curr loss timestep torch.Size([415, 4]) tensor([146, 333, 279, 218], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.033539917320013046
bi 1 loss 0.43571415543556213
bi 2 loss 0.04064929112792015
bi 3 loss 0.043908074498176575
Layer  1  loss:  0.14828762412071228 0.0 18.13091468811035
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([160, 331, 303, 191], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.035578854382038116
bi 1 loss 0.4221583306789398
bi 2 loss 0.05225806683301926
bi 3 loss 0.041586145758628845
Layer  2  loss:  0.15309059619903564 0.0 14.328062057495117
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([173, 333, 327, 243], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.05227571353316307
bi 1 loss 0.44326525926589966
bi 2 loss 0.03535725921392441
bi 3 loss 0.04617676883935928
Layer  3  loss:  0.16159890592098236 0.0 17.9791202545166
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1017
Curr loss timestep torch.Size([415, 4]) tensor([142, 391, 324, 181], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.028430068865418434
bi 1 loss 0.46816176176071167
bi 2 loss 0.05310956761240959
bi 3 loss 0.05408515781164169
Layer  4  loss:  0.17524483799934387 0.0 16.929868698120117
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1021
Curr loss timestep torch.Size([415, 4]) tensor([110, 331, 277, 216], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.03291856497526169
bi 1 loss 0.5039153099060059
bi 2 loss 0.053783614188432693
bi 3 loss 0.06979238986968994
Layer  5  loss:  0.17184841632843018 0.0 17.477073669433594
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1023
Curr loss timestep torch.Size([415, 4]) tensor([216, 331, 205, 229], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.04039016738533974
bi 1 loss 0.49499937891960144
bi 2 loss 0.06424926966428757
bi 3 loss 0.032198045402765274
Layer  6  loss:  0.16195252537727356 0.0 15.294710159301758
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([108, 330, 254, 225], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.03403077647089958
bi 1 loss 0.4856075048446655
bi 2 loss 0.04163874313235283
bi 3 loss 0.04225139319896698
Epoch 0: :   3%|▎         | 15606/600000 [04:13<2:38:04, v_num=12, reduced_train_loss=38.40, global_step=15604.0, consumed_samples=62420.0, train_step_timing in s=0.367]Epoch 0: :   3%|▎         | 15606/600000 [04:13<2:38:04, v_num=12, reduced_train_loss=1.260, global_step=15605.0, consumed_samples=62424.0, train_step_timing in s=0.313]loss mask original None

First layer loss:  0.14605765044689178 torch.Size([591, 4]) 9.081465721130371 0.0
Max loss timestep torch.Size([591, 4]) tensor([186,  72, 286, 433], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.055492620915174484
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 1 loss 0.05269026383757591
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 2 loss 0.1025780439376831
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 3 loss 0.23569630086421967
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
logits torch.Size([591, 4, 257024]) labels torch.Size([591, 4]) 0 257022
Layer  0  loss:  0.14495104551315308 0.0 12.942156791687012
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([181,  46, 407, 484], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 0.04632646590471268
bi 1 loss 0.0614604577422142
bi 2 loss 0.0758242979645729
bi 3 loss 0.25570055842399597
Layer  1  loss:  0.17864318192005157 0.0 9.657601356506348
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([180,  69, 329, 536], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.054721757769584656
bi 1 loss 0.056167297065258026
bi 2 loss 0.11557082831859589
bi 3 loss 0.30260056257247925
Layer  2  loss:  0.20074987411499023 0.0 11.837610244750977
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([177,  71, 306, 542], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.04762045666575432
bi 1 loss 0.06498239934444427
bi 2 loss 0.10835953801870346
bi 3 loss 0.3613314628601074
Layer  3  loss:  0.15065695345401764 0.0 14.782376289367676
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([167,  47, 410, 542], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.04975157976150513
bi 1 loss 0.026882432401180267
bi 2 loss 0.08769481629133224
bi 3 loss 0.2711709439754486
Layer  4  loss:  0.17173629999160767 0.0 22.98278045654297
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([165,  73, 416, 484], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 0.06844469159841537
bi 1 loss 0.06584013253450394
bi 2 loss 0.09293506294488907
bi 3 loss 0.30046454071998596
Layer  5  loss:  0.19525380432605743 0.0 14.856880187988281
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([161, 159, 286, 484], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 0.05529840290546417
bi 1 loss 0.051474250853061676
bi 2 loss 0.0653623417019844
bi 3 loss 0.39092719554901123
Layer  6  loss:  0.17621898651123047 0.0 15.262452125549316
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([199,  82, 300, 484], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 0.04223811626434326
bi 1 loss 0.03477245196700096
bi 2 loss 0.08374115824699402
bi 3 loss 0.33581453561782837
Epoch 0: :   3%|▎         | 15607/600000 [04:13<2:38:20, v_num=12, reduced_train_loss=1.260, global_step=15605.0, consumed_samples=62424.0, train_step_timing in s=0.313]Epoch 0: :   3%|▎         | 15607/600000 [04:13<2:38:20, v_num=12, reduced_train_loss=1.360, global_step=15606.0, consumed_samples=62428.0, train_step_timing in s=0.406]loss mask original None

First layer loss:  0.11609790474176407 torch.Size([582, 4]) 7.466796398162842 0.0
Max loss timestep torch.Size([582, 4]) tensor([256, 310, 536, 472], device='cuda:0') tensor(423, device='cuda:0')
bi 0 loss 0.0375007763504982
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 1 loss 0.08584475517272949
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
bi 2 loss 0.15029765665531158
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
bi 3 loss 0.1068275198340416
speech mask sum tensor(410, device='cuda:0') loss mask sum tensor(410, device='cuda:0')
logits torch.Size([582, 4, 257024]) labels torch.Size([582, 4]) 0 257023
Layer  0  loss:  0.14553654193878174 0.0 7.860599994659424
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([201, 365, 557, 472], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.12527011334896088
bi 1 loss 0.09063959866762161
bi 2 loss 0.2115742266178131
bi 3 loss 0.09556952118873596
Layer  1  loss:  0.15228664875030518 0.0 11.099345207214355
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([205, 365, 546, 473], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.06384699046611786
bi 1 loss 0.10630796104669571
bi 2 loss 0.19076722860336304
bi 3 loss 0.1472730189561844
Layer  2  loss:  0.13915801048278809 0.0 8.861051559448242
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([208, 365, 557, 423], device='cuda:0') tensor(557, device='cuda:0')
bi 0 loss 0.11565931141376495
bi 1 loss 0.09998210519552231
bi 2 loss 0.19042499363422394
bi 3 loss 0.10060486197471619
Layer  3  loss:  0.1722949892282486 0.0 15.893628120422363
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([247, 365, 534, 473], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.04112345725297928
bi 1 loss 0.08224640786647797
bi 2 loss 0.2571147382259369
bi 3 loss 0.14134229719638824
Layer  4  loss:  0.17030349373817444 0.0 10.019441604614258
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([230, 362, 554, 473], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.07777810841798782
bi 1 loss 0.07622900605201721
bi 2 loss 0.2415349930524826
bi 3 loss 0.1485947221517563
Layer  5  loss:  0.16889749467372894 0.0 12.422806739807129
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([257, 365, 554, 473], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.0510895773768425
bi 1 loss 0.1208508163690567
bi 2 loss 0.23657751083374023
bi 3 loss 0.1364450454711914
Layer  6  loss:  0.20250269770622253 0.0 11.03416633605957
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1019
Curr loss timestep torch.Size([582, 4]) tensor([204, 365, 427, 473], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.04200296103954315
bi 1 loss 0.09108461439609528
bi 2 loss 0.3246872127056122
bi 3 loss 0.14302001893520355
Epoch 0: :   3%|▎         | 15608/600000 [04:14<2:38:36, v_num=12, reduced_train_loss=1.360, global_step=15606.0, consumed_samples=62428.0, train_step_timing in s=0.406]Epoch 0: :   3%|▎         | 15608/600000 [04:14<2:38:36, v_num=12, reduced_train_loss=1.270, global_step=15607.0, consumed_samples=62432.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  0.11151549965143204 torch.Size([714, 4]) 8.151859283447266 0.0
Max loss timestep torch.Size([714, 4]) tensor([259, 416, 327,  97], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.06400299072265625
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 1 loss 0.18478727340698242
speech mask sum tensor(501, device='cuda:0') loss mask sum tensor(501, device='cuda:0')
bi 2 loss 0.04961429163813591
speech mask sum tensor(269, device='cuda:0') loss mask sum tensor(269, device='cuda:0')
bi 3 loss 0.05962762236595154
speech mask sum tensor(56, device='cuda:0') loss mask sum tensor(56, device='cuda:0')
logits torch.Size([714, 4, 257024]) labels torch.Size([714, 4]) 0 257022
Layer  0  loss:  0.12089665979146957 0.0 10.523868560791016
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([259, 295, 291,  91], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.07788397371768951
bi 1 loss 0.18452444672584534
bi 2 loss 0.07974622398614883
bi 3 loss 0.026602596044540405
Layer  1  loss:  0.14016549289226532 0.0 9.900293350219727
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1022
Curr loss timestep torch.Size([714, 4]) tensor([259, 416, 291,  91], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.06455107778310776
bi 1 loss 0.23229655623435974
bi 2 loss 0.08793105185031891
bi 3 loss 0.05427619442343712
Layer  2  loss:  0.1397361010313034 0.0 12.148104667663574
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1022
Curr loss timestep torch.Size([714, 4]) tensor([261, 416, 291,  90], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.08005942404270172
bi 1 loss 0.22930434346199036
bi 2 loss 0.07887962460517883
bi 3 loss 0.015449822880327702
Layer  3  loss:  0.14992663264274597 0.0 15.471842765808105
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([261, 416, 291, 111], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.05324535816907883
bi 1 loss 0.2632644772529602
bi 2 loss 0.09055816382169724
bi 3 loss 0.04438715800642967
Layer  4  loss:  0.14995117485523224 0.0 10.227889060974121
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1022
Curr loss timestep torch.Size([714, 4]) tensor([261, 295, 290,  95], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.09920065104961395
bi 1 loss 0.22260768711566925
bi 2 loss 0.10675305128097534
bi 3 loss 0.034599918872117996
Layer  5  loss:  0.15943041443824768 0.0 16.8601016998291
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([259, 295, 291, 120], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.09059792011976242
bi 1 loss 0.25078055262565613
bi 2 loss 0.10761331021785736
bi 3 loss 0.0348040871322155
Layer  6  loss:  0.15380768477916718 0.0 11.37239933013916
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([259, 416, 291, 118], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.09899391233921051
bi 1 loss 0.23643755912780762
bi 2 loss 0.08252937346696854
bi 3 loss 0.11030877381563187
Epoch 0: :   3%|▎         | 15609/600000 [04:14<2:38:55, v_num=12, reduced_train_loss=1.270, global_step=15607.0, consumed_samples=62432.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15609/600000 [04:14<2:38:55, v_num=12, reduced_train_loss=1.130, global_step=15608.0, consumed_samples=62436.0, train_step_timing in s=0.486]loss mask original None

First layer loss:  0.21023842692375183 torch.Size([774, 4]) 10.464317321777344 0.0
Max loss timestep torch.Size([774, 4]) tensor([634, 380, 436, 174], device='cuda:0') tensor(634, device='cuda:0')
bi 0 loss 0.3428410291671753
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
bi 1 loss 0.15879549086093903
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 2 loss 0.10892239958047867
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
bi 3 loss 0.06528372317552567
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
logits torch.Size([774, 4, 257024]) labels torch.Size([774, 4]) 0 257023
Layer  0  loss:  0.25980234146118164 0.0 12.286483764648438
logits torch.Size([774, 4, 1024]) labels torch.Size([774, 4]) 0 1023
Curr loss timestep torch.Size([774, 4]) tensor([613, 307, 436,  88], device='cuda:0') tensor(613, device='cuda:0')
bi 0 loss 0.435058057308197
bi 1 loss 0.14586785435676575
bi 2 loss 0.14992764592170715
bi 3 loss 0.06508602201938629
Layer  1  loss:  0.27914297580718994 0.0 14.470504760742188
logits torch.Size([774, 4, 1024]) labels torch.Size([774, 4]) 0 1023
Curr loss timestep torch.Size([774, 4]) tensor([394, 337, 436, 134], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.46590670943260193
bi 1 loss 0.16899584233760834
bi 2 loss 0.15448695421218872
bi 3 loss 0.07549656182527542
Layer  2  loss:  0.29738274216651917 0.0 14.239760398864746
logits torch.Size([774, 4, 1024]) labels torch.Size([774, 4]) 0 1022
Curr loss timestep torch.Size([774, 4]) tensor([395, 340, 319,  58], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.4978640079498291
bi 1 loss 0.15451748669147491
bi 2 loss 0.18949630856513977
bi 3 loss 0.053022854030132294
Layer  3  loss:  0.2559818625450134 0.0 13.362823486328125
logits torch.Size([774, 4, 1024]) labels torch.Size([774, 4]) 0 1023
Curr loss timestep torch.Size([774, 4]) tensor([395, 337, 436,  54], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.41466766595840454
bi 1 loss 0.16591842472553253
bi 2 loss 0.16204717755317688
bi 3 loss 0.057677049189805984
Layer  4  loss:  0.26338663697242737 0.0 13.350703239440918
logits torch.Size([774, 4, 1024]) labels torch.Size([774, 4]) 0 1023
Curr loss timestep torch.Size([774, 4]) tensor([395, 331, 436,  78], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.4399016797542572
bi 1 loss 0.12860816717147827
bi 2 loss 0.15711194276809692
bi 3 loss 0.07713483273983002
Layer  5  loss:  0.2725323438644409 0.0 13.094552993774414
logits torch.Size([774, 4, 1024]) labels torch.Size([774, 4]) 0 1020
Curr loss timestep torch.Size([774, 4]) tensor([634, 337, 436,  91], device='cuda:0') tensor(634, device='cuda:0')
bi 0 loss 0.4595532715320587
bi 1 loss 0.14396652579307556
bi 2 loss 0.1602781116962433
bi 3 loss 0.06178675591945648
Layer  6  loss:  0.25903549790382385 0.0 10.8505859375
logits torch.Size([774, 4, 1024]) labels torch.Size([774, 4]) 0 1021
Curr loss timestep torch.Size([774, 4]) tensor([396, 337, 319,  82], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.4237137734889984
bi 1 loss 0.1914287656545639
bi 2 loss 0.15394946932792664
bi 3 loss 0.044078901410102844
Epoch 0: :   3%|▎         | 15610/600000 [04:15<2:39:15, v_num=12, reduced_train_loss=1.130, global_step=15608.0, consumed_samples=62436.0, train_step_timing in s=0.486]Epoch 0: :   3%|▎         | 15610/600000 [04:15<2:39:15, v_num=12, reduced_train_loss=2.100, global_step=15609.0, consumed_samples=62440.0, train_step_timing in s=0.529]loss mask original None

First layer loss:  3.6828715801239014 torch.Size([584, 4]) 11.041045188903809 0.0
Max loss timestep torch.Size([584, 4]) tensor([541,  91, 258, 110], device='cuda:0') tensor(92, device='cuda:0')
bi 0 loss 3.878131866455078
speech mask sum tensor(357, device='cuda:0') loss mask sum tensor(357, device='cuda:0')
bi 1 loss 2.9213435649871826
speech mask sum tensor(68, device='cuda:0') loss mask sum tensor(68, device='cuda:0')
bi 2 loss 3.7159688472747803
speech mask sum tensor(324, device='cuda:0') loss mask sum tensor(324, device='cuda:0')
bi 3 loss 3.357333183288574
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
logits torch.Size([584, 4, 257024]) labels torch.Size([584, 4]) 0 257023
Layer  0  loss:  4.225131034851074 0.0 10.712928771972656
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([288,  73, 331,  89], device='cuda:0') tensor(95, device='cuda:0')
bi 0 loss 4.443129062652588
bi 1 loss 3.3889596462249756
bi 2 loss 4.123391628265381
bi 3 loss 4.361467361450195
Layer  1  loss:  4.556520938873291 0.0 10.253793716430664
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1019
Curr loss timestep torch.Size([584, 4]) tensor([259,  76, 186,  76], device='cuda:0') tensor(89, device='cuda:0')
bi 0 loss 4.682250022888184
bi 1 loss 3.857386350631714
bi 2 loss 4.567178249359131
bi 3 loss 4.547463893890381
Layer  2  loss:  4.770931243896484 0.0 11.742380142211914
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([330,  74, 367,  69], device='cuda:0') tensor(93, device='cuda:0')
bi 0 loss 5.0289130210876465
bi 1 loss 3.9318008422851562
bi 2 loss 4.722484111785889
bi 3 loss 4.5511393547058105
Layer  3  loss:  5.097562789916992 0.0 10.52452278137207
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([539,  81, 323,  42], device='cuda:0') tensor(81, device='cuda:0')
bi 0 loss 5.288671016693115
bi 1 loss 4.340488433837891
bi 2 loss 5.153997898101807
bi 3 loss 4.699498176574707
Layer  4  loss:  5.1457600593566895 0.0 10.534505844116211
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([536,  78, 202,  94], device='cuda:0') tensor(100, device='cuda:0')
bi 0 loss 5.405682563781738
bi 1 loss 4.062647342681885
bi 2 loss 5.183473587036133
bi 3 loss 4.789393901824951
Layer  5  loss:  5.246710777282715 0.0 9.786958694458008
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([309,  87,  83,  49], device='cuda:0') tensor(83, device='cuda:0')
bi 0 loss 5.49233865737915
bi 1 loss 4.323275566101074
bi 2 loss 5.164030075073242
bi 3 loss 5.268224716186523
Layer  6  loss:  5.2785964012146 0.0 10.166010856628418
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([548,  67, 218,  91], device='cuda:0') tensor(101, device='cuda:0')
bi 0 loss 5.500063896179199
bi 1 loss 4.19865083694458
bi 2 loss 5.360921859741211
bi 3 loss 4.911535263061523
Epoch 0: :   3%|▎         | 15611/600000 [04:15<2:39:30, v_num=12, reduced_train_loss=2.100, global_step=15609.0, consumed_samples=62440.0, train_step_timing in s=0.529]Epoch 0: :   3%|▎         | 15611/600000 [04:15<2:39:30, v_num=12, reduced_train_loss=38.00, global_step=15610.0, consumed_samples=62444.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  0.09106522053480148 torch.Size([441, 4]) 7.442975044250488 0.0
Max loss timestep torch.Size([441, 4]) tensor([ 69, 163, 109, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.07274670898914337
speech mask sum tensor(198, device='cuda:0') loss mask sum tensor(198, device='cuda:0')
bi 1 loss 0.05554313585162163
speech mask sum tensor(261, device='cuda:0') loss mask sum tensor(261, device='cuda:0')
bi 2 loss 0.05103592202067375
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
bi 3 loss 0.17143595218658447
speech mask sum tensor(285, device='cuda:0') loss mask sum tensor(285, device='cuda:0')
logits torch.Size([441, 4, 257024]) labels torch.Size([441, 4]) 0 257023
Layer  0  loss:  0.08605783432722092 0.0 9.950179100036621
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([145, 259, 265, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.05808672308921814
bi 1 loss 0.06586594879627228
bi 2 loss 0.05140108987689018
bi 3 loss 0.15438255667686462
Layer  1  loss:  0.09745956212282181 0.0 14.363200187683105
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([139, 230, 102, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.03615226596593857
bi 1 loss 0.08263907581567764
bi 2 loss 0.04132503643631935
bi 3 loss 0.20286525785923004
Layer  2  loss:  0.0995059683918953 0.0 11.924042701721191
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1022
Curr loss timestep torch.Size([441, 4]) tensor([ 79, 372,  94, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.0759398564696312
bi 1 loss 0.0682186707854271
bi 2 loss 0.040890488773584366
bi 3 loss 0.19594790041446686
Layer  3  loss:  0.08691998571157455 0.0 8.870210647583008
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1021
Curr loss timestep torch.Size([441, 4]) tensor([ 98, 315, 206, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.0482102632522583
bi 1 loss 0.05122317001223564
bi 2 loss 0.06009890139102936
bi 3 loss 0.1700311154127121
Layer  4  loss:  0.10003611445426941 0.0 18.441465377807617
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([180, 305,  92, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.05176873505115509
bi 1 loss 0.08669984340667725
bi 2 loss 0.046858660876750946
bi 3 loss 0.192429319024086
Layer  5  loss:  0.08797350525856018 0.0 12.563676834106445
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([ 84, 316, 167, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.050314150750637054
bi 1 loss 0.0766371637582779
bi 2 loss 0.04592893272638321
bi 3 loss 0.16139976680278778
Layer  6  loss:  0.10059228539466858 0.0 15.718822479248047
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([ 70, 319, 226, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.04862738028168678
bi 1 loss 0.07523074001073837
bi 2 loss 0.045670751482248306
bi 3 loss 0.20809686183929443
Epoch 0: :   3%|▎         | 15612/600000 [04:16<2:39:43, v_num=12, reduced_train_loss=38.00, global_step=15610.0, consumed_samples=62444.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15612/600000 [04:16<2:39:43, v_num=12, reduced_train_loss=0.750, global_step=15611.0, consumed_samples=62448.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  0.19409388303756714 torch.Size([717, 4]) 15.154925346374512 0.0
Max loss timestep torch.Size([717, 4]) tensor([140, 274, 313, 559], device='cuda:0') tensor(559, device='cuda:0')
bi 0 loss 0.03534381836652756
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 1 loss 0.14385567605495453
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
bi 2 loss 0.031874921172857285
speech mask sum tensor(338, device='cuda:0') loss mask sum tensor(338, device='cuda:0')
bi 3 loss 0.40223830938339233
speech mask sum tensor(461, device='cuda:0') loss mask sum tensor(461, device='cuda:0')
logits torch.Size([717, 4, 257024]) labels torch.Size([717, 4]) 0 257022
Layer  0  loss:  0.1829824596643448 0.0 11.884479522705078
logits torch.Size([717, 4, 1024]) labels torch.Size([717, 4]) 0 1023
Curr loss timestep torch.Size([717, 4]) tensor([187, 300, 259, 661], device='cuda:0') tensor(661, device='cuda:0')
bi 0 loss 0.0373544879257679
bi 1 loss 0.16287557780742645
bi 2 loss 0.06157277897000313
bi 3 loss 0.3361937403678894
Layer  1  loss:  0.20953316986560822 0.0 10.762717247009277
logits torch.Size([717, 4, 1024]) labels torch.Size([717, 4]) 0 1022
Curr loss timestep torch.Size([717, 4]) tensor([ 62, 300, 259, 558], device='cuda:0') tensor(558, device='cuda:0')
bi 0 loss 0.0318295918405056
bi 1 loss 0.1314491480588913
bi 2 loss 0.07851973921060562
bi 3 loss 0.42028242349624634
Layer  2  loss:  0.21900279819965363 0.0 13.973281860351562
logits torch.Size([717, 4, 1024]) labels torch.Size([717, 4]) 0 1022
Curr loss timestep torch.Size([717, 4]) tensor([146, 300, 258, 660], device='cuda:0') tensor(660, device='cuda:0')
bi 0 loss 0.014272689819335938
bi 1 loss 0.1390378177165985
bi 2 loss 0.10356820374727249
bi 3 loss 0.428987056016922
Layer  3  loss:  0.23983319103717804 0.0 15.664992332458496
logits torch.Size([717, 4, 1024]) labels torch.Size([717, 4]) 0 1021
Curr loss timestep torch.Size([717, 4]) tensor([137, 300, 259, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.027512729167938232
bi 1 loss 0.13627889752388
bi 2 loss 0.09058864414691925
bi 3 loss 0.4932570457458496
Layer  4  loss:  0.2432069629430771 0.0 13.307130813598633
logits torch.Size([717, 4, 1024]) labels torch.Size([717, 4]) 0 1023
Curr loss timestep torch.Size([717, 4]) tensor([ 56, 300, 263, 660], device='cuda:0') tensor(660, device='cuda:0')
bi 0 loss 0.03385986015200615
bi 1 loss 0.18782299757003784
bi 2 loss 0.130267933011055
bi 3 loss 0.4362744092941284
Layer  5  loss:  0.25093984603881836 0.0 15.367647171020508
logits torch.Size([717, 4, 1024]) labels torch.Size([717, 4]) 0 1022
Curr loss timestep torch.Size([717, 4]) tensor([160, 332, 268, 660], device='cuda:0') tensor(660, device='cuda:0')
bi 0 loss 0.045859988778829575
bi 1 loss 0.15269914269447327
bi 2 loss 0.13547317683696747
bi 3 loss 0.4734775424003601
Layer  6  loss:  0.22438347339630127 0.0 15.020589828491211
logits torch.Size([717, 4, 1024]) labels torch.Size([717, 4]) 0 1020
Curr loss timestep torch.Size([717, 4]) tensor([ 57, 300, 383, 559], device='cuda:0') tensor(559, device='cuda:0')
bi 0 loss 0.020375728607177734
bi 1 loss 0.1698695719242096
bi 2 loss 0.09882242232561111
bi 3 loss 0.4242613911628723
Epoch 0: :   3%|▎         | 15613/600000 [04:16<2:40:01, v_num=12, reduced_train_loss=0.750, global_step=15611.0, consumed_samples=62448.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15613/600000 [04:16<2:40:02, v_num=12, reduced_train_loss=1.760, global_step=15612.0, consumed_samples=62452.0, train_step_timing in s=0.484]loss mask original None

First layer loss:  3.688971996307373 torch.Size([488, 4]) 14.640091896057129 0.0
Max loss timestep torch.Size([488, 4]) tensor([115, 178, 265, 135], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 3.225114345550537
speech mask sum tensor(69, device='cuda:0') loss mask sum tensor(69, device='cuda:0')
bi 1 loss 3.817131996154785
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 2 loss 3.910067558288574
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 3 loss 3.56563138961792
speech mask sum tensor(345, device='cuda:0') loss mask sum tensor(345, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257023
Layer  0  loss:  4.219089031219482 0.0 10.297883987426758
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([125, 290, 297, 339], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 3.487959623336792
bi 1 loss 4.338090419769287
bi 2 loss 4.697972774505615
bi 3 loss 3.97353196144104
Layer  1  loss:  4.471155643463135 0.0 13.38623046875
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([152, 191, 321, 324], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 4.016714572906494
bi 1 loss 4.471003532409668
bi 2 loss 5.109271049499512
bi 3 loss 4.116361141204834
Layer  2  loss:  4.856616497039795 0.0 10.56002426147461
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([125, 195, 309, 242], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 4.409305572509766
bi 1 loss 4.905210971832275
bi 2 loss 5.4095139503479
bi 3 loss 4.536470413208008
Layer  3  loss:  4.935032844543457 0.0 10.144678115844727
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([104, 191, 463, 115], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 4.4981770515441895
bi 1 loss 5.160307884216309
bi 2 loss 5.491330623626709
bi 3 loss 4.525408744812012
Layer  4  loss:  5.0556559562683105 0.0 9.938543319702148
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1020
Curr loss timestep torch.Size([488, 4]) tensor([141, 291, 406, 233], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 4.620413303375244
bi 1 loss 4.954928874969482
bi 2 loss 5.733625411987305
bi 3 loss 4.717573642730713
Layer  5  loss:  5.176886081695557 0.0 9.643714904785156
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([133, 301, 406, 247], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 4.794186592102051
bi 1 loss 5.257050037384033
bi 2 loss 5.613181114196777
bi 3 loss 4.9100799560546875
Layer  6  loss:  5.211083889007568 0.0 9.47768783569336
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1021
Curr loss timestep torch.Size([488, 4]) tensor([126, 239, 366, 108], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 4.652256965637207
bi 1 loss 5.087706089019775
bi 2 loss 5.800302982330322
bi 3 loss 4.970613479614258
Epoch 0: :   3%|▎         | 15614/600000 [04:16<2:40:15, v_num=12, reduced_train_loss=1.760, global_step=15612.0, consumed_samples=62452.0, train_step_timing in s=0.484]Epoch 0: :   3%|▎         | 15614/600000 [04:16<2:40:15, v_num=12, reduced_train_loss=37.60, global_step=15613.0, consumed_samples=62456.0, train_step_timing in s=0.330]loss mask original None

First layer loss:  3.668508291244507 torch.Size([528, 4]) 12.084243774414062 0.0
Max loss timestep torch.Size([528, 4]) tensor([336, 305, 302, 219], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 3.6691017150878906
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
bi 1 loss 3.274278402328491
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 2 loss 3.3893425464630127
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
bi 3 loss 4.068465709686279
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
logits torch.Size([528, 4, 257024]) labels torch.Size([528, 4]) 0 257023
Layer  0  loss:  4.1068501472473145 0.0 10.027591705322266
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([341, 128, 305, 414], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 4.298027515411377
bi 1 loss 4.005092620849609
bi 2 loss 3.588362455368042
bi 3 loss 4.311293125152588
Layer  1  loss:  4.5507731437683105 0.0 10.429734230041504
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([277, 241, 301, 357], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.797515869140625
bi 1 loss 4.548844337463379
bi 2 loss 3.7674152851104736
bi 3 loss 4.814136028289795
Layer  2  loss:  4.748812198638916 0.0 10.276372909545898
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([382, 292, 402, 466], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 5.050549507141113
bi 1 loss 4.764434814453125
bi 2 loss 3.8644022941589355
bi 3 loss 5.013908386230469
Layer  3  loss:  4.860476493835449 0.0 10.692375183105469
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([219, 256, 353, 215], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 5.117913246154785
bi 1 loss 4.782685279846191
bi 2 loss 3.9756016731262207
bi 3 loss 5.221090793609619
Layer  4  loss:  5.012433052062988 0.0 10.376401901245117
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([216, 129, 362, 513], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 5.257533550262451
bi 1 loss 5.032014846801758
bi 2 loss 4.188086032867432
bi 3 loss 5.291290760040283
Layer  5  loss:  5.0585479736328125 0.0 10.16335391998291
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([183, 235, 343, 388], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 5.2954607009887695
bi 1 loss 5.088788032531738
bi 2 loss 4.142001628875732
bi 3 loss 5.397892475128174
Layer  6  loss:  5.1162109375 0.0 9.673421859741211
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([179, 281, 329, 183], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 5.432331562042236
bi 1 loss 5.10624361038208
bi 2 loss 4.131100654602051
bi 3 loss 5.446084499359131
Epoch 0: :   3%|▎         | 15615/600000 [04:17<2:40:28, v_num=12, reduced_train_loss=37.60, global_step=15613.0, consumed_samples=62456.0, train_step_timing in s=0.330]Epoch 0: :   3%|▎         | 15615/600000 [04:17<2:40:28, v_num=12, reduced_train_loss=37.10, global_step=15614.0, consumed_samples=62460.0, train_step_timing in s=0.344]loss mask original None

First layer loss:  3.1323964595794678 torch.Size([468, 4]) 10.398494720458984 0.0
Max loss timestep torch.Size([468, 4]) tensor([203, 100, 240, 380], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 2.7200067043304443
speech mask sum tensor(379, device='cuda:0') loss mask sum tensor(379, device='cuda:0')
bi 1 loss 3.6038269996643066
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 2 loss 3.3592472076416016
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
bi 3 loss 3.276827096939087
speech mask sum tensor(295, device='cuda:0') loss mask sum tensor(295, device='cuda:0')
logits torch.Size([468, 4, 257024]) labels torch.Size([468, 4]) 0 257022
Layer  0  loss:  3.8884501457214355 0.0 10.612052917480469
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([111,  48, 322, 224], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 3.7253546714782715
bi 1 loss 4.269416332244873
bi 2 loss 4.072459697723389
bi 3 loss 3.7860145568847656
Layer  1  loss:  4.240962505340576 0.0 10.417555809020996
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([388,  57, 273, 306], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 4.139014720916748
bi 1 loss 4.280150413513184
bi 2 loss 4.364211559295654
bi 3 loss 4.2581586837768555
Layer  2  loss:  4.643215179443359 0.0 10.152562141418457
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([ 77,  78, 330, 346], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.54471492767334
bi 1 loss 4.633015155792236
bi 2 loss 4.6418986320495605
bi 3 loss 4.77528715133667
Layer  3  loss:  4.744716167449951 0.0 9.563591003417969
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1021
Curr loss timestep torch.Size([468, 4]) tensor([388, 134, 194, 310], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 4.6504435539245605
bi 1 loss 4.749753475189209
bi 2 loss 4.810799598693848
bi 3 loss 4.811864376068115
Layer  4  loss:  5.006513595581055 0.0 11.475752830505371
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([ 81,  75, 326, 420], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 4.932960033416748
bi 1 loss 4.978329658508301
bi 2 loss 5.020823001861572
bi 3 loss 5.102227210998535
Layer  5  loss:  4.980905532836914 0.0 10.270350456237793
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([317,  64, 211, 182], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 4.846167087554932
bi 1 loss 5.052987098693848
bi 2 loss 5.1132588386535645
bi 3 loss 5.018606662750244
Layer  6  loss:  5.023568153381348 0.0 9.404165267944336
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([118, 106, 343, 394], device='cuda:0') tensor(370, device='cuda:0')
bi 0 loss 4.80902099609375
bi 1 loss 5.106918811798096
bi 2 loss 5.193390846252441
bi 3 loss 5.129497051239014
Epoch 0: :   3%|▎         | 15616/600000 [04:17<2:40:41, v_num=12, reduced_train_loss=37.10, global_step=15614.0, consumed_samples=62460.0, train_step_timing in s=0.344]Epoch 0: :   3%|▎         | 15616/600000 [04:17<2:40:41, v_num=12, reduced_train_loss=35.70, global_step=15615.0, consumed_samples=62464.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  0.10155168175697327 torch.Size([450, 4]) 8.041027069091797 0.0
Max loss timestep torch.Size([450, 4]) tensor([364, 314, 356, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.10098247230052948
speech mask sum tensor(198, device='cuda:0') loss mask sum tensor(198, device='cuda:0')
bi 1 loss 0.14799922704696655
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 2 loss 0.10467864573001862
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 3 loss 0.078391894698143
speech mask sum tensor(336, device='cuda:0') loss mask sum tensor(336, device='cuda:0')
logits torch.Size([450, 4, 257024]) labels torch.Size([450, 4]) 0 257023
Layer  0  loss:  0.11589077115058899 0.0 10.52054214477539
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([363, 315, 377, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.09930284321308136
bi 1 loss 0.16954250633716583
bi 2 loss 0.09952868521213531
bi 3 loss 0.10732446610927582
Layer  1  loss:  0.13180188834667206 0.0 21.289108276367188
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([363, 314, 336, 313], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.09531313180923462
bi 1 loss 0.12491154670715332
bi 2 loss 0.06412556022405624
bi 3 loss 0.18639510869979858
Layer  2  loss:  0.12345841526985168 0.0 12.801042556762695
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1022
Curr loss timestep torch.Size([450, 4]) tensor([364, 314, 432, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.1241416335105896
bi 1 loss 0.14652259647846222
bi 2 loss 0.0952460840344429
bi 3 loss 0.12449971586465836
Layer  3  loss:  0.13470971584320068 0.0 12.94043254852295
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1021
Curr loss timestep torch.Size([450, 4]) tensor([284, 316, 363, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.07796083390712738
bi 1 loss 0.2127208709716797
bi 2 loss 0.07440296560525894
bi 3 loss 0.15756651759147644
Layer  4  loss:  0.16992925107479095 0.0 20.281295776367188
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1022
Curr loss timestep torch.Size([450, 4]) tensor([363, 314, 326, 313], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.11997891217470169
bi 1 loss 0.23582085967063904
bi 2 loss 0.11120028048753738
bi 3 loss 0.19385601580142975
Layer  5  loss:  0.12992006540298462 0.0 14.561206817626953
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([363, 314, 395, 283], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.09247779846191406
bi 1 loss 0.19474878907203674
bi 2 loss 0.07093454152345657
bi 3 loss 0.1470952183008194
Layer  6  loss:  0.13239356875419617 0.0 16.1174259185791
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1022
Curr loss timestep torch.Size([450, 4]) tensor([364, 314, 338, 313], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.09295102953910828
bi 1 loss 0.19726285338401794
bi 2 loss 0.056329239159822464
bi 3 loss 0.15825088322162628
Epoch 0: :   3%|▎         | 15617/600000 [04:18<2:40:54, v_num=12, reduced_train_loss=35.70, global_step=15615.0, consumed_samples=62464.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15617/600000 [04:18<2:40:54, v_num=12, reduced_train_loss=1.040, global_step=15616.0, consumed_samples=62468.0, train_step_timing in s=0.324]loss mask original None

First layer loss:  0.09318127483129501 torch.Size([565, 4]) 7.708677291870117 0.0
Max loss timestep torch.Size([565, 4]) tensor([526, 298, 261, 136], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.14393654465675354
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
bi 1 loss 0.03598112240433693
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
bi 2 loss 0.09227372705936432
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 3 loss 0.013528133742511272
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
logits torch.Size([565, 4, 257024]) labels torch.Size([565, 4]) 0 257023
Layer  0  loss:  0.0984523668885231 0.0 14.828812599182129
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([525, 197, 256, 154], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.17107516527175903
bi 1 loss 0.043560612946748734
bi 2 loss 0.048376843333244324
bi 3 loss 0.02054317481815815
Layer  1  loss:  0.09551884233951569 0.0 15.299835205078125
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([525, 196, 316, 139], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.15285202860832214
bi 1 loss 0.03298572078347206
bi 2 loss 0.08389727771282196
bi 3 loss 0.021196480840444565
Layer  2  loss:  0.10272420197725296 0.0 17.39482307434082
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([525, 279, 378, 144], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.16314029693603516
bi 1 loss 0.022398509085178375
bi 2 loss 0.09969385713338852
bi 3 loss 0.03693368658423424
Layer  3  loss:  0.09885392338037491 0.0 11.728426933288574
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1021
Curr loss timestep torch.Size([565, 4]) tensor([525, 258, 379, 143], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.1469554454088211
bi 1 loss 0.06239429488778114
bi 2 loss 0.06999032199382782
bi 3 loss 0.039354659616947174
Layer  4  loss:  0.11362466216087341 0.0 13.831488609313965
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1021
Curr loss timestep torch.Size([565, 4]) tensor([412, 115, 261,  74], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.17315369844436646
bi 1 loss 0.03736123442649841
bi 2 loss 0.12305065244436264
bi 3 loss 0.0194455087184906
Layer  5  loss:  0.11978145688772202 0.0 16.636075973510742
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([525, 277, 374, 142], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.18300434947013855
bi 1 loss 0.043073005974292755
bi 2 loss 0.11530770361423492
bi 3 loss 0.038165654987096786
Layer  6  loss:  0.11465194821357727 0.0 11.271809577941895
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([413, 288, 378, 152], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.18073046207427979
bi 1 loss 0.05249438062310219
bi 2 loss 0.09581192582845688
bi 3 loss 0.018716072663664818
Epoch 0: :   3%|▎         | 15618/600000 [04:18<2:41:10, v_num=12, reduced_train_loss=1.040, global_step=15616.0, consumed_samples=62468.0, train_step_timing in s=0.324]Epoch 0: :   3%|▎         | 15618/600000 [04:18<2:41:10, v_num=12, reduced_train_loss=0.837, global_step=15617.0, consumed_samples=62472.0, train_step_timing in s=0.403]loss mask original None

First layer loss:  0.03734777867794037 torch.Size([369, 4]) 2.0507824420928955 0.0
Max loss timestep torch.Size([369, 4]) tensor([258, 266, 116, 143], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.043436307460069656
speech mask sum tensor(237, device='cuda:0') loss mask sum tensor(237, device='cuda:0')
bi 1 loss 0.04369938746094704
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
bi 2 loss 0.03087827004492283
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 3 loss 0.021943267434835434
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
logits torch.Size([369, 4, 257024]) labels torch.Size([369, 4]) 0 257022
Layer  0  loss:  0.04070769250392914 0.0 2.363011360168457
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([267, 304,  89, 112], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.04060553014278412
bi 1 loss 0.054693736135959625
bi 2 loss 0.02697906270623207
bi 3 loss 0.03591332212090492
Layer  1  loss:  0.03660967946052551 0.0 0.9802362322807312
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([270, 308,  57, 139], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.03825460001826286
bi 1 loss 0.05161404237151146
bi 2 loss 0.024281689897179604
bi 3 loss 0.02253914251923561
Layer  2  loss:  0.04075106605887413 0.0 2.845236301422119
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1022
Curr loss timestep torch.Size([369, 4]) tensor([271, 269,  81, 110], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.036901772022247314
bi 1 loss 0.05873912572860718
bi 2 loss 0.02872706949710846
bi 3 loss 0.031153256073594093
Layer  3  loss:  0.04186452925205231 0.0 3.2457756996154785
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1022
Curr loss timestep torch.Size([369, 4]) tensor([265, 266, 203, 148], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.04756387323141098
bi 1 loss 0.053292516618967056
bi 2 loss 0.033792898058891296
bi 3 loss 0.01845836266875267
Layer  4  loss:  0.037218958139419556 0.0 1.157119631767273
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([220, 268,  84, 127], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.04224476218223572
bi 1 loss 0.04920775070786476
bi 2 loss 0.02377726510167122
bi 3 loss 0.025165701285004616
Layer  5  loss:  0.034723229706287384 0.0 1.0889525413513184
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1022
Curr loss timestep torch.Size([369, 4]) tensor([174, 360, 206, 137], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.03329978883266449
bi 1 loss 0.04935759678483009
bi 2 loss 0.031044183298945427
bi 3 loss 0.010370971634984016
Layer  6  loss:  0.036432407796382904 0.0 1.7178597450256348
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1019
Curr loss timestep torch.Size([369, 4]) tensor([ 87, 320,  67,  94], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.036564089357852936
bi 1 loss 0.05661953240633011
bi 2 loss 0.02225550450384617
bi 3 loss 0.017132101580500603
Epoch 0: :   3%|▎         | 15619/600000 [04:18<2:41:21, v_num=12, reduced_train_loss=0.837, global_step=15617.0, consumed_samples=62472.0, train_step_timing in s=0.403]Epoch 0: :   3%|▎         | 15619/600000 [04:18<2:41:21, v_num=12, reduced_train_loss=0.306, global_step=15618.0, consumed_samples=62476.0, train_step_timing in s=0.285]loss mask original None

First layer loss:  0.053276706486940384 torch.Size([442, 4]) 9.572092056274414 0.0
Max loss timestep torch.Size([442, 4]) tensor([416, 220,  80,  49], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.11171417683362961
speech mask sum tensor(269, device='cuda:0') loss mask sum tensor(269, device='cuda:0')
bi 1 loss 0.021044157445430756
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 2 loss 0.0227979589253664
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 3 loss 0.02563679777085781
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
logits torch.Size([442, 4, 257024]) labels torch.Size([442, 4]) 0 257023
Layer  0  loss:  0.06977708637714386 0.0 12.969001770019531
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1023
Curr loss timestep torch.Size([442, 4]) tensor([417, 136, 264, 119], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.15935561060905457
bi 1 loss 0.01800004206597805
bi 2 loss 0.029462657868862152
bi 3 loss 0.02058238908648491
Layer  1  loss:  0.06374363601207733 0.0 12.817695617675781
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1023
Curr loss timestep torch.Size([442, 4]) tensor([415, 153, 232, 139], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.13715220987796783
bi 1 loss 0.02344624511897564
bi 2 loss 0.029652412980794907
bi 3 loss 0.022616025060415268
Layer  2  loss:  0.07956082373857498 0.0 16.457866668701172
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1022
Curr loss timestep torch.Size([442, 4]) tensor([416, 154, 232, 119], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.18826162815093994
bi 1 loss 0.02424972876906395
bi 2 loss 0.025809023529291153
bi 3 loss 0.01864670403301716
Layer  3  loss:  0.07767750322818756 0.0 16.46314239501953
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1019
Curr loss timestep torch.Size([442, 4]) tensor([416, 209, 117, 122], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.18320441246032715
bi 1 loss 0.020267058163881302
bi 2 loss 0.024165218695998192
bi 3 loss 0.02462903968989849
Layer  4  loss:  0.08269257098436356 0.0 19.035083770751953
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1022
Curr loss timestep torch.Size([442, 4]) tensor([415, 139, 264,  92], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.19590790569782257
bi 1 loss 0.022168220952153206
bi 2 loss 0.025782277807593346
bi 3 loss 0.02385326847434044
Layer  5  loss:  0.08561789989471436 0.0 16.144214630126953
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1022
Curr loss timestep torch.Size([442, 4]) tensor([417, 196, 264, 106], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.20512333512306213
bi 1 loss 0.02404114417731762
bi 2 loss 0.024188732728362083
bi 3 loss 0.02294710837304592
Layer  6  loss:  0.08961823582649231 0.0 20.220632553100586
logits torch.Size([442, 4, 1024]) labels torch.Size([442, 4]) 0 1023
Curr loss timestep torch.Size([442, 4]) tensor([416, 194, 242, 122], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.219375342130661
bi 1 loss 0.024858927354216576
bi 2 loss 0.023498225957155228
bi 3 loss 0.018385667353868484
Epoch 0: :   3%|▎         | 15620/600000 [04:19<2:41:34, v_num=12, reduced_train_loss=0.306, global_step=15618.0, consumed_samples=62476.0, train_step_timing in s=0.285]Epoch 0: :   3%|▎         | 15620/600000 [04:19<2:41:34, v_num=12, reduced_train_loss=0.602, global_step=15619.0, consumed_samples=62480.0, train_step_timing in s=0.324]loss mask original None

First layer loss:  0.12702572345733643 torch.Size([517, 4]) 11.628241539001465 0.0
Max loss timestep torch.Size([517, 4]) tensor([328, 297, 118, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.08683513104915619
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 1 loss 0.043948885053396225
speech mask sum tensor(93, device='cuda:0') loss mask sum tensor(93, device='cuda:0')
bi 2 loss 0.05337579548358917
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
bi 3 loss 0.20679332315921783
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
logits torch.Size([517, 4, 257024]) labels torch.Size([517, 4]) 0 257023
Layer  0  loss:  0.15782542526721954 0.0 18.157997131347656
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([328, 347, 113, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.10286777466535568
bi 1 loss 0.1268494576215744
bi 2 loss 0.02729993872344494
bi 3 loss 0.2551504969596863
Layer  1  loss:  0.16814982891082764 0.0 21.064029693603516
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([328, 348, 141, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.06480769068002701
bi 1 loss 0.08343055844306946
bi 2 loss 0.06585945934057236
bi 3 loss 0.299642950296402
Layer  2  loss:  0.1709584891796112 0.0 19.92424774169922
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([328, 352, 193, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.11977630853652954
bi 1 loss 0.06216226518154144
bi 2 loss 0.052449073642492294
bi 3 loss 0.28364357352256775
Layer  3  loss:  0.1632353663444519 0.0 10.158356666564941
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([257, 321, 102, 418], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.09684886783361435
bi 1 loss 0.06735352426767349
bi 2 loss 0.07647176831960678
bi 3 loss 0.2685040533542633
Layer  4  loss:  0.19010475277900696 0.0 13.044170379638672
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([296, 300, 105, 421], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.14615648984909058
bi 1 loss 0.03466559946537018
bi 2 loss 0.054663319140672684
bi 3 loss 0.318881630897522
Layer  5  loss:  0.14082923531532288 0.0 9.575897216796875
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1023
Curr loss timestep torch.Size([517, 4]) tensor([400, 323, 142, 409], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.08649729937314987
bi 1 loss 0.051891133189201355
bi 2 loss 0.03893952816724777
bi 3 loss 0.24281275272369385
Layer  6  loss:  0.21040910482406616 0.0 15.827982902526855
logits torch.Size([517, 4, 1024]) labels torch.Size([517, 4]) 0 1020
Curr loss timestep torch.Size([517, 4]) tensor([328, 301, 115, 420], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.12066207826137543
bi 1 loss 0.05059162154793739
bi 2 loss 0.03506094217300415
bi 3 loss 0.385545939207077
Epoch 0: :   3%|▎         | 15621/600000 [04:19<2:41:48, v_num=12, reduced_train_loss=0.602, global_step=15619.0, consumed_samples=62480.0, train_step_timing in s=0.324]Epoch 0: :   3%|▎         | 15621/600000 [04:19<2:41:48, v_num=12, reduced_train_loss=1.330, global_step=15620.0, consumed_samples=62484.0, train_step_timing in s=0.358]loss mask original None

First layer loss:  4.073216438293457 torch.Size([632, 4]) 12.75520133972168 0.0
Max loss timestep torch.Size([632, 4]) tensor([180,  81, 127, 537], device='cuda:0') tensor(127, device='cuda:0')
bi 0 loss 3.989072561264038
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
bi 1 loss 3.7340993881225586
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
bi 2 loss 4.383509159088135
speech mask sum tensor(503, device='cuda:0') loss mask sum tensor(503, device='cuda:0')
bi 3 loss 3.8875558376312256
speech mask sum tensor(473, device='cuda:0') loss mask sum tensor(473, device='cuda:0')
logits torch.Size([632, 4, 257024]) labels torch.Size([632, 4]) 0 257022
Layer  0  loss:  4.653836250305176 0.0 10.360671997070312
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1023
Curr loss timestep torch.Size([632, 4]) tensor([166, 136, 408, 217], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 4.436229705810547
bi 1 loss 4.1663384437561035
bi 2 loss 4.8283610343933105
bi 3 loss 4.72616720199585
Layer  1  loss:  4.905524730682373 0.0 10.490982055664062
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1022
Curr loss timestep torch.Size([632, 4]) tensor([302,  87, 177, 450], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 4.860015392303467
bi 1 loss 4.4448747634887695
bi 2 loss 5.1175618171691895
bi 3 loss 4.840149879455566
Layer  2  loss:  5.157321929931641 0.0 10.529480934143066
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1022
Curr loss timestep torch.Size([632, 4]) tensor([200, 102, 224, 242], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 5.0467753410339355
bi 1 loss 4.703028202056885
bi 2 loss 5.25726318359375
bi 3 loss 5.243232250213623
Layer  3  loss:  5.287363052368164 0.0 10.790160179138184
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1021
Curr loss timestep torch.Size([632, 4]) tensor([277, 127, 266, 347], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 5.247693061828613
bi 1 loss 4.845494747161865
bi 2 loss 5.32470703125
bi 3 loss 5.399152755737305
Layer  4  loss:  5.397016525268555 0.0 11.80035400390625
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1022
Curr loss timestep torch.Size([632, 4]) tensor([284, 160, 434, 528], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 5.341268062591553
bi 1 loss 5.075280666351318
bi 2 loss 5.4887309074401855
bi 3 loss 5.423826694488525
Layer  5  loss:  5.472061634063721 0.0 10.391366958618164
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1023
Curr loss timestep torch.Size([632, 4]) tensor([146,  91, 179, 548], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 5.463036060333252
bi 1 loss 5.036985397338867
bi 2 loss 5.591885566711426
bi 3 loss 5.478126525878906
Layer  6  loss:  5.446692943572998 0.0 10.438401222229004
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1021
Curr loss timestep torch.Size([632, 4]) tensor([231,  70, 437, 412], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 5.393721580505371
bi 1 loss 5.261074542999268
bi 2 loss 5.490314960479736
bi 3 loss 5.482905864715576
High loss detected
Logging training audio
Epoch 0: :   3%|▎         | 15622/600000 [04:20<2:42:15, v_num=12, reduced_train_loss=1.330, global_step=15620.0, consumed_samples=62484.0, train_step_timing in s=0.358]Epoch 0: :   3%|▎         | 15622/600000 [04:20<2:42:15, v_num=12, reduced_train_loss=40.40, global_step=15621.0, consumed_samples=62488.0, train_step_timing in s=0.689]loss mask original None

First layer loss:  0.12463977187871933 torch.Size([603, 4]) 11.68847942352295 0.0
Max loss timestep torch.Size([603, 4]) tensor([121, 395, 514, 343], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.049990665167570114
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 1 loss 0.10870944708585739
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 2 loss 0.19804944097995758
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
bi 3 loss 0.09863041341304779
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
logits torch.Size([603, 4, 257024]) labels torch.Size([603, 4]) 0 257022
Layer  0  loss:  0.16357626020908356 0.0 12.210798263549805
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([ 87, 395, 395, 343], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.03166775777935982
bi 1 loss 0.15820634365081787
bi 2 loss 0.22472676634788513
bi 3 loss 0.16952289640903473
Layer  1  loss:  0.15309612452983856 0.0 14.464057922363281
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([128, 316, 514, 343], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.033625345677137375
bi 1 loss 0.15821024775505066
bi 2 loss 0.21153104305267334
bi 3 loss 0.1390254646539688
Layer  2  loss:  0.16888777911663055 0.0 15.006841659545898
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([142, 395, 395, 308], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.03824317827820778
bi 1 loss 0.1617899239063263
bi 2 loss 0.20541222393512726
bi 3 loss 0.20821231603622437
Layer  3  loss:  0.13544176518917084 0.0 12.95449447631836
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([ 88, 530, 395, 344], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.03210711479187012
bi 1 loss 0.1316482573747635
bi 2 loss 0.20741291344165802
bi 3 loss 0.1087627187371254
Layer  4  loss:  0.15606530010700226 0.0 11.865668296813965
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([159, 395, 514, 343], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.02389390952885151
bi 1 loss 0.17371530830860138
bi 2 loss 0.22733138501644135
bi 3 loss 0.11334805190563202
Layer  5  loss:  0.1596626192331314 0.0 10.595353126525879
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([205, 396, 395, 343], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.03597574681043625
bi 1 loss 0.1729152798652649
bi 2 loss 0.1954948604106903
bi 3 loss 0.16413529217243195
Layer  6  loss:  0.14928793907165527 0.0 9.06384563446045
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([ 85, 395, 394, 343], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.04556446149945259
bi 1 loss 0.13921122252941132
bi 2 loss 0.16861999034881592
bi 3 loss 0.1997656673192978
Epoch 0: :   3%|▎         | 15623/600000 [04:20<2:42:31, v_num=12, reduced_train_loss=40.40, global_step=15621.0, consumed_samples=62488.0, train_step_timing in s=0.689]Epoch 0: :   3%|▎         | 15623/600000 [04:20<2:42:31, v_num=12, reduced_train_loss=1.210, global_step=15622.0, consumed_samples=62492.0, train_step_timing in s=0.419]loss mask original None

First layer loss:  3.4304556846618652 torch.Size([372, 4]) 9.77582836151123 0.0
Max loss timestep torch.Size([372, 4]) tensor([206, 116, 105, 294], device='cuda:0') tensor(105, device='cuda:0')
bi 0 loss 3.689934253692627
speech mask sum tensor(123, device='cuda:0') loss mask sum tensor(123, device='cuda:0')
bi 1 loss 3.813321113586426
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
bi 2 loss 3.145249843597412
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 3 loss 3.343430757522583
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
logits torch.Size([372, 4, 257024]) labels torch.Size([372, 4]) 0 257022
Layer  0  loss:  4.0577392578125 0.0 9.029088020324707
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1023
Curr loss timestep torch.Size([372, 4]) tensor([242,  85, 116, 132], device='cuda:0') tensor(116, device='cuda:0')
bi 0 loss 4.561307907104492
bi 1 loss 4.332685470581055
bi 2 loss 3.6556570529937744
bi 3 loss 3.955653429031372
Layer  1  loss:  4.364808559417725 0.0 10.826943397521973
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1023
Curr loss timestep torch.Size([372, 4]) tensor([285,  99,  85,  96], device='cuda:0') tensor(122, device='cuda:0')
bi 0 loss 4.734725475311279
bi 1 loss 4.582956790924072
bi 2 loss 3.851550817489624
bi 3 loss 4.39346170425415
Layer  2  loss:  4.597263813018799 0.0 10.537096977233887
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1023
Curr loss timestep torch.Size([372, 4]) tensor([238, 112,  59, 356], device='cuda:0') tensor(116, device='cuda:0')
bi 0 loss 4.8534979820251465
bi 1 loss 4.919447898864746
bi 2 loss 4.215165615081787
bi 3 loss 4.578363418579102
Layer  3  loss:  4.662381649017334 0.0 9.918354988098145
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1021
Curr loss timestep torch.Size([372, 4]) tensor([204,  59, 169, 209], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 4.7859392166137695
bi 1 loss 4.946406364440918
bi 2 loss 4.428685188293457
bi 3 loss 4.638803482055664
Layer  4  loss:  4.794057369232178 0.0 10.616582870483398
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1022
Curr loss timestep torch.Size([372, 4]) tensor([203,  64, 117, 289], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 5.012571334838867
bi 1 loss 4.9929518699646
bi 2 loss 4.441341400146484
bi 3 loss 4.81437873840332
Layer  5  loss:  4.80964994430542 0.0 10.28875732421875
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1022
Curr loss timestep torch.Size([372, 4]) tensor([206,  97, 162, 218], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 5.0768537521362305
bi 1 loss 5.330389022827148
bi 2 loss 4.310204029083252
bi 3 loss 4.784109592437744
Layer  6  loss:  4.805434226989746 0.0 9.6284761428833
logits torch.Size([372, 4, 1024]) labels torch.Size([372, 4]) 0 1022
Curr loss timestep torch.Size([372, 4]) tensor([217,  79,  88, 295], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 5.105253219604492
bi 1 loss 5.253489017486572
bi 2 loss 4.404121398925781
bi 3 loss 4.738913536071777
Epoch 0: :   3%|▎         | 15624/600000 [04:21<2:42:42, v_num=12, reduced_train_loss=1.210, global_step=15622.0, consumed_samples=62492.0, train_step_timing in s=0.419]Epoch 0: :   3%|▎         | 15624/600000 [04:21<2:42:42, v_num=12, reduced_train_loss=35.50, global_step=15623.0, consumed_samples=62496.0, train_step_timing in s=0.279]loss mask original None

First layer loss:  0.08417657762765884 torch.Size([478, 4]) 12.220646858215332 0.0
Max loss timestep torch.Size([478, 4]) tensor([364, 376, 353, 387], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.15436291694641113
speech mask sum tensor(311, device='cuda:0') loss mask sum tensor(311, device='cuda:0')
bi 1 loss 0.049313776195049286
speech mask sum tensor(266, device='cuda:0') loss mask sum tensor(266, device='cuda:0')
bi 2 loss 0.060502663254737854
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 3 loss 0.06545213609933853
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
logits torch.Size([478, 4, 257024]) labels torch.Size([478, 4]) 0 257022
Layer  0  loss:  0.09265483170747757 0.0 15.955436706542969
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1023
Curr loss timestep torch.Size([478, 4]) tensor([363, 370, 353, 387], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.16709376871585846
bi 1 loss 0.06342297047376633
bi 2 loss 0.05554934963583946
bi 3 loss 0.07679431885480881
Layer  1  loss:  0.09162889420986176 0.0 11.691835403442383
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1023
Curr loss timestep torch.Size([478, 4]) tensor([363, 380, 391, 387], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.18389126658439636
bi 1 loss 0.0434572696685791
bi 2 loss 0.04012609273195267
bi 3 loss 0.08673182129859924
Layer  2  loss:  0.1033666580915451 0.0 12.486886978149414
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([363, 349, 153, 387], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.21083000302314758
bi 1 loss 0.03466467931866646
bi 2 loss 0.06802684813737869
bi 3 loss 0.08668355643749237
Layer  3  loss:  0.08170372247695923 0.0 8.315154075622559
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1020
Curr loss timestep torch.Size([478, 4]) tensor([388, 286, 281, 272], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.12150977551937103
bi 1 loss 0.047979436814785004
bi 2 loss 0.07382500916719437
bi 3 loss 0.07788325101137161
Layer  4  loss:  0.08264196664094925 0.0 9.402522087097168
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([389, 232, 278, 387], device='cuda:0') tensor(389, device='cuda:0')
bi 0 loss 0.14807943999767303
bi 1 loss 0.05117841809988022
bi 2 loss 0.06008008122444153
bi 3 loss 0.06474371254444122
Layer  5  loss:  0.11055424064397812 0.0 14.075851440429688
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([364, 298, 264, 387], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.23385776579380035
bi 1 loss 0.0649171844124794
bi 2 loss 0.04946339130401611
bi 3 loss 0.0816367119550705
Layer  6  loss:  0.09975568950176239 0.0 15.240874290466309
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1023
Curr loss timestep torch.Size([478, 4]) tensor([364, 411, 353, 387], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.16489866375923157
bi 1 loss 0.07729931175708771
bi 2 loss 0.06848151236772537
bi 3 loss 0.08222639560699463
Epoch 0: :   3%|▎         | 15625/600000 [04:21<2:42:56, v_num=12, reduced_train_loss=35.50, global_step=15623.0, consumed_samples=62496.0, train_step_timing in s=0.279]Epoch 0: :   3%|▎         | 15625/600000 [04:21<2:42:56, v_num=12, reduced_train_loss=0.746, global_step=15624.0, consumed_samples=62500.0, train_step_timing in s=0.359]loss mask original None

First layer loss:  0.05751819163560867 torch.Size([533, 4]) 5.120268821716309 0.0
Max loss timestep torch.Size([533, 4]) tensor([321, 355, 261, 152], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.07858026772737503
speech mask sum tensor(252, device='cuda:0') loss mask sum tensor(252, device='cuda:0')
bi 1 loss 0.08155284821987152
speech mask sum tensor(168, device='cuda:0') loss mask sum tensor(168, device='cuda:0')
bi 2 loss 0.025658225640654564
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
bi 3 loss 0.04019465669989586
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
logits torch.Size([533, 4, 257024]) labels torch.Size([533, 4]) 0 257022
Layer  0  loss:  0.06131758913397789 0.0 3.6645045280456543
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([427, 306, 296, 196], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.08421265333890915
bi 1 loss 0.10993808507919312
bi 2 loss 0.028166556730866432
bi 3 loss 0.019752247259020805
Layer  1  loss:  0.06245831772685051 0.0 5.392359733581543
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([321, 319, 238, 145], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.0910608246922493
bi 1 loss 0.08477979898452759
bi 2 loss 0.034340210258960724
bi 3 loss 0.032029855996370316
Layer  2  loss:  0.0679633840918541 0.0 4.371737480163574
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([321, 431, 302,  66], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.09738893061876297
bi 1 loss 0.11222662031650543
bi 2 loss 0.030763832852244377
bi 3 loss 0.02572677843272686
Layer  3  loss:  0.05642033368349075 0.0 5.803969383239746
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1021
Curr loss timestep torch.Size([533, 4]) tensor([321, 428, 160, 191], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.06009393930435181
bi 1 loss 0.1114872545003891
bi 2 loss 0.03842438384890556
bi 3 loss 0.019270699471235275
Layer  4  loss:  0.07084323465824127 0.0 4.313708305358887
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([427, 355, 222, 107], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.10579029470682144
bi 1 loss 0.08511284738779068
bi 2 loss 0.03660409152507782
bi 3 loss 0.045742217451334
Layer  5  loss:  0.0717429518699646 0.0 2.6777055263519287
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([483, 400, 286, 148], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.11445921659469604
bi 1 loss 0.08189152181148529
bi 2 loss 0.037078551948070526
bi 3 loss 0.04003768786787987
Layer  6  loss:  0.08198244124650955 0.0 5.502877235412598
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([321, 295, 288,  95], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.14499495923519135
bi 1 loss 0.05718037486076355
bi 2 loss 0.04451252147555351
bi 3 loss 0.057578518986701965
Epoch 0: :   3%|▎         | 15626/600000 [04:21<2:43:11, v_num=12, reduced_train_loss=0.746, global_step=15624.0, consumed_samples=62500.0, train_step_timing in s=0.359]Epoch 0: :   3%|▎         | 15626/600000 [04:21<2:43:11, v_num=12, reduced_train_loss=0.530, global_step=15625.0, consumed_samples=62504.0, train_step_timing in s=0.371]loss mask original None

First layer loss:  0.028605474159121513 torch.Size([399, 4]) 0.7663517594337463 0.0
Max loss timestep torch.Size([399, 4]) tensor([171, 379, 115, 263], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.021642126142978668
speech mask sum tensor(144, device='cuda:0') loss mask sum tensor(144, device='cuda:0')
bi 1 loss 0.03255733475089073
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 2 loss 0.02302095852792263
speech mask sum tensor(108, device='cuda:0') loss mask sum tensor(108, device='cuda:0')
bi 3 loss 0.03496912866830826
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
logits torch.Size([399, 4, 257024]) labels torch.Size([399, 4]) 0 257022
Layer  0  loss:  0.023682041093707085 0.0 0.5206484794616699
logits torch.Size([399, 4, 1024]) labels torch.Size([399, 4]) 0 1023
Curr loss timestep torch.Size([399, 4]) tensor([249, 292, 148, 220], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.022596942260861397
bi 1 loss 0.02671312727034092
bi 2 loss 0.01755390875041485
bi 3 loss 0.024870147928595543
Layer  1  loss:  0.022642524912953377 0.0 0.6568273901939392
logits torch.Size([399, 4, 1024]) labels torch.Size([399, 4]) 0 1023
Curr loss timestep torch.Size([399, 4]) tensor([178, 352,  99, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.01828976534307003
bi 1 loss 0.0261369738727808
bi 2 loss 0.017681943252682686
bi 3 loss 0.02597104385495186
Layer  2  loss:  0.021265508607029915 0.0 0.7787898778915405
logits torch.Size([399, 4, 1024]) labels torch.Size([399, 4]) 0 1022
Curr loss timestep torch.Size([399, 4]) tensor([146, 379, 128, 235], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.021264102309942245
bi 1 loss 0.024245355278253555
bi 2 loss 0.01691511832177639
bi 3 loss 0.01944943331182003
Layer  3  loss:  0.03177213668823242 0.0 5.183055400848389
logits torch.Size([399, 4, 1024]) labels torch.Size([399, 4]) 0 1021
Curr loss timestep torch.Size([399, 4]) tensor([169, 379, 160, 245], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.020281638950109482
bi 1 loss 0.05238775163888931
bi 2 loss 0.0174638032913208
bi 3 loss 0.018743570894002914
Layer  4  loss:  0.028918147087097168 0.0 2.0939831733703613
logits torch.Size([399, 4, 1024]) labels torch.Size([399, 4]) 0 1023
Curr loss timestep torch.Size([399, 4]) tensor([218, 388, 122, 263], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.024502882733941078
bi 1 loss 0.038813114166259766
bi 2 loss 0.01555286068469286
bi 3 loss 0.027516232803463936
Layer  5  loss:  0.030192002654075623 0.0 3.0737271308898926
logits torch.Size([399, 4, 1024]) labels torch.Size([399, 4]) 0 1023
Curr loss timestep torch.Size([399, 4]) tensor([178, 379,  87, 262], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.022907141596078873
bi 1 loss 0.04398029297590256
bi 2 loss 0.016766605898737907
bi 3 loss 0.02468137815594673
Layer  6  loss:  0.029157955199480057 0.0 2.037250518798828
logits torch.Size([399, 4, 1024]) labels torch.Size([399, 4]) 0 1023
Curr loss timestep torch.Size([399, 4]) tensor([177, 379,  94, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.023032475262880325
bi 1 loss 0.033143721520900726
bi 2 loss 0.01575402356684208
bi 3 loss 0.04191608354449272
Epoch 0: :   3%|▎         | 15627/600000 [04:22<2:43:23, v_num=12, reduced_train_loss=0.530, global_step=15625.0, consumed_samples=62504.0, train_step_timing in s=0.371]Epoch 0: :   3%|▎         | 15627/600000 [04:22<2:43:23, v_num=12, reduced_train_loss=0.216, global_step=15626.0, consumed_samples=62508.0, train_step_timing in s=0.309]loss mask original None

First layer loss:  3.5080180168151855 torch.Size([572, 4]) 12.5659818649292 0.0
Max loss timestep torch.Size([572, 4]) tensor([266,  87, 237, 233], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 3.542052745819092
speech mask sum tensor(433, device='cuda:0') loss mask sum tensor(433, device='cuda:0')
bi 1 loss 3.9659693241119385
speech mask sum tensor(245, device='cuda:0') loss mask sum tensor(245, device='cuda:0')
bi 2 loss 3.25382661819458
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 3 loss 3.1268625259399414
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
logits torch.Size([572, 4, 257024]) labels torch.Size([572, 4]) 0 257022
Layer  0  loss:  4.06431245803833 0.0 10.02227783203125
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([277, 190, 197, 355], device='cuda:0') tensor(238, device='cuda:0')
bi 0 loss 3.951441764831543
bi 1 loss 4.1582489013671875
bi 2 loss 3.862656593322754
bi 3 loss 4.258244514465332
Layer  1  loss:  4.439153671264648 0.0 10.309873580932617
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([298,  91, 252, 271], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 4.321396827697754
bi 1 loss 4.472644329071045
bi 2 loss 4.242851734161377
bi 3 loss 4.697000026702881
Layer  2  loss:  4.564015865325928 0.0 11.267830848693848
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([316, 171, 255, 165], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 4.352116584777832
bi 1 loss 4.674203872680664
bi 2 loss 4.167818546295166
bi 3 loss 4.999746322631836
Layer  3  loss:  4.814349174499512 0.0 10.14814567565918
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1021
Curr loss timestep torch.Size([572, 4]) tensor([460, 117, 199, 341], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.697232723236084
bi 1 loss 4.753100395202637
bi 2 loss 4.478276252746582
bi 3 loss 5.226261138916016
Layer  4  loss:  4.997071266174316 0.0 9.87636947631836
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([306, 132, 242, 226], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 4.766085147857666
bi 1 loss 5.029606342315674
bi 2 loss 4.927731037139893
bi 3 loss 5.38985013961792
Layer  5  loss:  5.1022748947143555 0.0 9.728641510009766
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([541, 122, 254, 174], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.913534641265869
bi 1 loss 5.167731761932373
bi 2 loss 4.965227127075195
bi 3 loss 5.422756195068359
Layer  6  loss:  5.151130199432373 0.0 10.149212837219238
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([399, 285, 215, 157], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.9535675048828125
bi 1 loss 5.216845512390137
bi 2 loss 4.890717029571533
bi 3 loss 5.542944431304932
Epoch 0: :   3%|▎         | 15628/600000 [04:22<2:43:38, v_num=12, reduced_train_loss=0.216, global_step=15626.0, consumed_samples=62508.0, train_step_timing in s=0.309]Epoch 0: :   3%|▎         | 15628/600000 [04:22<2:43:38, v_num=12, reduced_train_loss=36.60, global_step=15627.0, consumed_samples=62512.0, train_step_timing in s=0.386]loss mask original None

First layer loss:  0.07778029143810272 torch.Size([445, 4]) 9.636234283447266 0.0
Max loss timestep torch.Size([445, 4]) tensor([298, 212, 138, 297], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.17478206753730774
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 1 loss 0.05190260708332062
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
bi 2 loss 0.041010044515132904
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 3 loss 0.06733740866184235
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
logits torch.Size([445, 4, 257024]) labels torch.Size([445, 4]) 0 257022
Layer  0  loss:  0.07363513112068176 0.0 6.830595016479492
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([342, 283, 137, 296], device='cuda:0') tensor(137, device='cuda:0')
bi 0 loss 0.05562891066074371
bi 1 loss 0.07512123137712479
bi 2 loss 0.08732318878173828
bi 3 loss 0.07333216816186905
Layer  1  loss:  0.060084547847509384 0.0 5.315155029296875
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([293, 292, 367, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.04572686180472374
bi 1 loss 0.06491068005561829
bi 2 loss 0.04226189851760864
bi 3 loss 0.07817767560482025
Layer  2  loss:  0.06288178265094757 0.0 4.763594627380371
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([248, 313, 373, 406], device='cuda:0') tensor(406, device='cuda:0')
bi 0 loss 0.0588633269071579
bi 1 loss 0.059523798525333405
bi 2 loss 0.053170666098594666
bi 3 loss 0.07559174299240112
Layer  3  loss:  0.07349713146686554 0.0 3.0582218170166016
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([327, 263, 355, 297], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.054541993886232376
bi 1 loss 0.06445183604955673
bi 2 loss 0.08163201063871384
bi 3 loss 0.08713697642087936
Layer  4  loss:  0.06145991012454033 0.0 1.7729966640472412
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([314, 382, 343, 296], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.06360218673944473
bi 1 loss 0.05130695551633835
bi 2 loss 0.0661209225654602
bi 3 loss 0.06549593806266785
Layer  5  loss:  0.06560506671667099 0.0 5.933808326721191
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1022
Curr loss timestep torch.Size([445, 4]) tensor([241, 357, 393, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.048363275825977325
bi 1 loss 0.06268178671598434
bi 2 loss 0.05290504917502403
bi 3 loss 0.0884285420179367
Layer  6  loss:  0.06912461668252945 0.0 4.243741512298584
logits torch.Size([445, 4, 1024]) labels torch.Size([445, 4]) 0 1023
Curr loss timestep torch.Size([445, 4]) tensor([282, 423, 393, 406], device='cuda:0') tensor(406, device='cuda:0')
bi 0 loss 0.05651802569627762
bi 1 loss 0.06742461770772934
bi 2 loss 0.07046613097190857
bi 3 loss 0.07747474312782288
Epoch 0: :   3%|▎         | 15629/600000 [04:22<2:43:51, v_num=12, reduced_train_loss=36.60, global_step=15627.0, consumed_samples=62512.0, train_step_timing in s=0.386]Epoch 0: :   3%|▎         | 15629/600000 [04:22<2:43:51, v_num=12, reduced_train_loss=0.544, global_step=15628.0, consumed_samples=62516.0, train_step_timing in s=0.323]loss mask original None

First layer loss:  3.4907708168029785 torch.Size([592, 4]) 12.071111679077148 0.0
Max loss timestep torch.Size([592, 4]) tensor([456, 107, 258, 155], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 3.5870437622070312
speech mask sum tensor(435, device='cuda:0') loss mask sum tensor(435, device='cuda:0')
bi 1 loss 3.3747713565826416
speech mask sum tensor(110, device='cuda:0') loss mask sum tensor(110, device='cuda:0')
bi 2 loss 3.508692979812622
speech mask sum tensor(377, device='cuda:0') loss mask sum tensor(377, device='cuda:0')
bi 3 loss 3.096536874771118
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
logits torch.Size([592, 4, 257024]) labels torch.Size([592, 4]) 0 257022
Layer  0  loss:  4.123289585113525 0.0 9.89592170715332
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([399, 109, 130, 208], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 4.248212814331055
bi 1 loss 4.063441276550293
bi 2 loss 4.093998908996582
bi 3 loss 3.7198212146759033
Layer  1  loss:  4.334042072296143 0.0 10.918149948120117
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([162, 129, 395, 216], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 4.289456367492676
bi 1 loss 4.491340160369873
bi 2 loss 4.322395324707031
bi 3 loss 4.405280590057373
Layer  2  loss:  4.587895393371582 0.0 10.192543983459473
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1022
Curr loss timestep torch.Size([592, 4]) tensor([385, 181, 318, 159], device='cuda:0') tensor(172, device='cuda:0')
bi 0 loss 4.5895094871521
bi 1 loss 4.667391777038574
bi 2 loss 4.594424724578857
bi 3 loss 4.457031726837158
Layer  3  loss:  4.762755393981934 0.0 9.983158111572266
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([180, 169, 456, 163], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 4.695619583129883
bi 1 loss 4.813039302825928
bi 2 loss 4.845553874969482
bi 3 loss 4.679879188537598
Layer  4  loss:  4.928857326507568 0.0 10.736421585083008
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([494, 168, 196, 172], device='cuda:0') tensor(172, device='cuda:0')
bi 0 loss 4.853730201721191
bi 1 loss 4.815642356872559
bi 2 loss 5.141905307769775
bi 3 loss 4.542211055755615
Layer  5  loss:  4.931947231292725 0.0 9.947062492370605
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1018
Curr loss timestep torch.Size([592, 4]) tensor([340, 149, 464, 181], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 4.7331061363220215
bi 1 loss 5.027794361114502
bi 2 loss 5.156398296356201
bi 3 loss 4.836716651916504
Layer  6  loss:  5.014526844024658 0.0 9.498708724975586
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([428, 114, 126, 174], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.871150970458984
bi 1 loss 5.046017169952393
bi 2 loss 5.178012371063232
bi 3 loss 4.984532833099365
Epoch 0: :   3%|▎         | 15630/600000 [04:23<2:44:06, v_num=12, reduced_train_loss=0.544, global_step=15628.0, consumed_samples=62516.0, train_step_timing in s=0.323]Epoch 0: :   3%|▎         | 15630/600000 [04:23<2:44:06, v_num=12, reduced_train_loss=36.20, global_step=15629.0, consumed_samples=62520.0, train_step_timing in s=0.386]loss mask original None

First layer loss:  0.08944422006607056 torch.Size([569, 4]) 12.229501724243164 0.0
Max loss timestep torch.Size([569, 4]) tensor([496, 304, 337, 261], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.10994569212198257
speech mask sum tensor(312, device='cuda:0') loss mask sum tensor(312, device='cuda:0')
bi 1 loss 0.0631832629442215
speech mask sum tensor(317, device='cuda:0') loss mask sum tensor(317, device='cuda:0')
bi 2 loss 0.11969351023435593
speech mask sum tensor(372, device='cuda:0') loss mask sum tensor(372, device='cuda:0')
bi 3 loss 0.04235093295574188
speech mask sum tensor(198, device='cuda:0') loss mask sum tensor(198, device='cuda:0')
logits torch.Size([569, 4, 257024]) labels torch.Size([569, 4]) 0 257023
Layer  0  loss:  0.11666737496852875 0.0 10.05526065826416
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([315, 355, 336, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.15972256660461426
bi 1 loss 0.08187416195869446
bi 2 loss 0.10537592321634293
bi 3 loss 0.1257414072751999
Layer  1  loss:  0.14074574410915375 0.0 20.157238006591797
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([392, 339, 336, 262], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.13204918801784515
bi 1 loss 0.10187017917633057
bi 2 loss 0.22006216645240784
bi 3 loss 0.06767075508832932
Layer  2  loss:  0.11665312200784683 0.0 9.063850402832031
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([456, 260, 336, 262], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.10239872336387634
bi 1 loss 0.10138656944036484
bi 2 loss 0.15978670120239258
bi 3 loss 0.08251768350601196
Layer  3  loss:  0.1257070153951645 0.0 12.956010818481445
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1019
Curr loss timestep torch.Size([569, 4]) tensor([392, 355, 460, 262], device='cuda:0') tensor(460, device='cuda:0')
bi 0 loss 0.12571708858013153
bi 1 loss 0.10950744152069092
bi 2 loss 0.16406816244125366
bi 3 loss 0.07955441623926163
Layer  4  loss:  0.125098317861557 0.0 13.262286186218262
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([530, 355, 337, 262], device='cuda:0') tensor(337, device='cuda:0')
bi 0 loss 0.13099651038646698
bi 1 loss 0.07076715677976608
bi 2 loss 0.1744244545698166
bi 3 loss 0.11011561006307602
Layer  5  loss:  0.10762288421392441 0.0 11.224361419677734
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([550, 273, 336, 313], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.10164506733417511
bi 1 loss 0.07066863775253296
bi 2 loss 0.16104921698570251
bi 3 loss 0.07582985609769821
Layer  6  loss:  0.1447446644306183 0.0 11.403698921203613
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1019
Curr loss timestep torch.Size([569, 4]) tensor([392, 355, 460, 262], device='cuda:0') tensor(460, device='cuda:0')
bi 0 loss 0.19270160794258118
bi 1 loss 0.1344064474105835
bi 2 loss 0.1579635739326477
bi 3 loss 0.06089230626821518
Epoch 0: :   3%|▎         | 15631/600000 [04:23<2:44:22, v_num=12, reduced_train_loss=36.20, global_step=15629.0, consumed_samples=62520.0, train_step_timing in s=0.386]Epoch 0: :   3%|▎         | 15631/600000 [04:23<2:44:22, v_num=12, reduced_train_loss=0.967, global_step=15630.0, consumed_samples=62524.0, train_step_timing in s=0.396]loss mask original None

First layer loss:  0.06156865507364273 torch.Size([538, 4]) 4.6976213455200195 0.0
Max loss timestep torch.Size([538, 4]) tensor([280, 210, 280,  87], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.047139398753643036
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 1 loss 0.031085260212421417
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 2 loss 0.083940289914608
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 3 loss 0.04724147915840149
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
logits torch.Size([538, 4, 257024]) labels torch.Size([538, 4]) 0 257022
Layer  0  loss:  0.06413603574037552 0.0 2.5374011993408203
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([275, 222, 281, 101], device='cuda:0') tensor(101, device='cuda:0')
bi 0 loss 0.062142033129930496
bi 1 loss 0.027905425056815147
bi 2 loss 0.07512617111206055
bi 3 loss 0.06172880530357361
Layer  1  loss:  0.07257635146379471 0.0 8.376445770263672
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1022
Curr loss timestep torch.Size([538, 4]) tensor([275, 191, 280, 134], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.07822111994028091
bi 1 loss 0.04677619785070419
bi 2 loss 0.08856167644262314
bi 3 loss 0.04150578752160072
Layer  2  loss:  0.059064991772174835 0.0 1.9560282230377197
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([331, 190, 280,  78], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.05205376446247101
bi 1 loss 0.03065958246588707
bi 2 loss 0.07812662422657013
bi 3 loss 0.04058137536048889
Layer  3  loss:  0.06079705432057381 0.0 4.748132705688477
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([329, 234, 280,  95], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.05700947716832161
bi 1 loss 0.03760938718914986
bi 2 loss 0.07508695125579834
bi 3 loss 0.045883432030677795
Layer  4  loss:  0.05243818834424019 0.0 3.771587610244751
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1021
Curr loss timestep torch.Size([538, 4]) tensor([264, 239, 280, 156], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.03403696417808533
bi 1 loss 0.06041494011878967
bi 2 loss 0.06406370550394058
bi 3 loss 0.04732571542263031
Layer  5  loss:  0.07103174179792404 0.0 6.656971454620361
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([358, 214, 280, 145], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.04688188061118126
bi 1 loss 0.02781101129949093
bi 2 loss 0.10875573009252548
bi 3 loss 0.04198798909783363
Layer  6  loss:  0.06372195482254028 0.0 3.357003927230835
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1022
Curr loss timestep torch.Size([538, 4]) tensor([319, 227, 280, 173], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.04045024886727333
bi 1 loss 0.027481485158205032
bi 2 loss 0.09223847091197968
bi 3 loss 0.05104689672589302
Epoch 0: :   3%|▎         | 15632/600000 [04:24<2:44:36, v_num=12, reduced_train_loss=0.967, global_step=15630.0, consumed_samples=62524.0, train_step_timing in s=0.396]Epoch 0: :   3%|▎         | 15632/600000 [04:24<2:44:37, v_num=12, reduced_train_loss=0.505, global_step=15631.0, consumed_samples=62528.0, train_step_timing in s=0.374]loss mask original None

First layer loss:  0.029531247913837433 torch.Size([381, 4]) 2.3087940216064453 0.0
Max loss timestep torch.Size([381, 4]) tensor([145, 353, 266, 258], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.027969637885689735
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 1 loss 0.02525576762855053
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 2 loss 0.022191302850842476
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 3 loss 0.042821161448955536
speech mask sum tensor(215, device='cuda:0') loss mask sum tensor(215, device='cuda:0')
logits torch.Size([381, 4, 257024]) labels torch.Size([381, 4]) 0 257023
Layer  0  loss:  0.028566457331180573 0.0 0.7973098158836365
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1023
Curr loss timestep torch.Size([381, 4]) tensor([145, 191, 192, 208], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 0.027625497430562973
bi 1 loss 0.032579366117715836
bi 2 loss 0.01992047391831875
bi 3 loss 0.034835536032915115
Layer  1  loss:  0.03294900059700012 0.0 1.2525068521499634
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1022
Curr loss timestep torch.Size([381, 4]) tensor([ 54, 283, 134, 258], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.02989782951772213
bi 1 loss 0.04725133627653122
bi 2 loss 0.01995158940553665
bi 3 loss 0.03552216291427612
Layer  2  loss:  0.03566671162843704 0.0 0.9636726379394531
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1022
Curr loss timestep torch.Size([381, 4]) tensor([177, 314, 177,  93], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 0.02978014387190342
bi 1 loss 0.04218083247542381
bi 2 loss 0.032893262803554535
bi 3 loss 0.036543313413858414
Layer  3  loss:  0.0365467295050621 0.0 3.117431163787842
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1022
Curr loss timestep torch.Size([381, 4]) tensor([139, 202, 135, 258], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.032702889293432236
bi 1 loss 0.029508370906114578
bi 2 loss 0.024900130927562714
bi 3 loss 0.058839742094278336
Layer  4  loss:  0.0350969098508358 0.0 1.3584978580474854
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1022
Curr loss timestep torch.Size([381, 4]) tensor([175, 283, 258, 277], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.025331048294901848
bi 1 loss 0.04872149974107742
bi 2 loss 0.032992444932460785
bi 3 loss 0.031084749847650528
Layer  5  loss:  0.04925252124667168 0.0 4.575064659118652
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1022
Curr loss timestep torch.Size([381, 4]) tensor([ 76, 286, 216, 258], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.03825017437338829
bi 1 loss 0.034962888807058334
bi 2 loss 0.042910635471343994
bi 3 loss 0.07776545733213425
Layer  6  loss:  0.047430429607629776 0.0 2.329878330230713
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1023
Curr loss timestep torch.Size([381, 4]) tensor([106, 280, 279, 258], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.04338286817073822
bi 1 loss 0.04679233208298683
bi 2 loss 0.05392034351825714
bi 3 loss 0.04376664385199547
Epoch 0: :   3%|▎         | 15633/600000 [04:24<2:44:48, v_num=12, reduced_train_loss=0.505, global_step=15631.0, consumed_samples=62528.0, train_step_timing in s=0.374]Epoch 0: :   3%|▎         | 15633/600000 [04:24<2:44:48, v_num=12, reduced_train_loss=0.295, global_step=15632.0, consumed_samples=62532.0, train_step_timing in s=0.291]loss mask original None

First layer loss:  0.03070634976029396 torch.Size([394, 4]) 1.5260953903198242 0.0
Max loss timestep torch.Size([394, 4]) tensor([354, 217, 191, 276], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 0.02570604346692562
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 1 loss 0.0350080244243145
speech mask sum tensor(215, device='cuda:0') loss mask sum tensor(215, device='cuda:0')
bi 2 loss 0.0224735289812088
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 3 loss 0.034447651356458664
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
logits torch.Size([394, 4, 257024]) labels torch.Size([394, 4]) 0 257022
Layer  0  loss:  0.03399980813264847 0.0 1.168959617614746
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1023
Curr loss timestep torch.Size([394, 4]) tensor([343,  72, 156, 274], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.0466378852725029
bi 1 loss 0.02884557470679283
bi 2 loss 0.036225974559783936
bi 3 loss 0.027577826753258705
Layer  1  loss:  0.034911952912807465 0.0 1.6726465225219727
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1023
Curr loss timestep torch.Size([394, 4]) tensor([304, 217, 185, 276], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.04326270520687103
bi 1 loss 0.03688008338212967
bi 2 loss 0.02187918685376644
bi 3 loss 0.03223421052098274
Layer  2  loss:  0.03579077869653702 0.0 1.0984824895858765
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1022
Curr loss timestep torch.Size([394, 4]) tensor([304, 205, 131, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.03178444132208824
bi 1 loss 0.03706688433885574
bi 2 loss 0.02741146832704544
bi 3 loss 0.04147547855973244
Layer  3  loss:  0.03318535163998604 0.0 1.0035040378570557
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1021
Curr loss timestep torch.Size([394, 4]) tensor([361, 185, 183, 277], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 0.042796939611434937
bi 1 loss 0.03829619660973549
bi 2 loss 0.02003953605890274
bi 3 loss 0.026790214702486992
Layer  4  loss:  0.03468739613890648 0.0 1.0980597734451294
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1022
Curr loss timestep torch.Size([394, 4]) tensor([368, 137, 134, 186], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 0.03879394754767418
bi 1 loss 0.027029316872358322
bi 2 loss 0.021004240959882736
bi 3 loss 0.044131405651569366
Layer  5  loss:  0.034640174359083176 0.0 1.9769456386566162
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1017
Curr loss timestep torch.Size([394, 4]) tensor([269,  80, 157, 275], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.04484153911471367
bi 1 loss 0.03307616710662842
bi 2 loss 0.024308249354362488
bi 3 loss 0.032437652349472046
Layer  6  loss:  0.03517706319689751 0.0 0.73035728931427
logits torch.Size([394, 4, 1024]) labels torch.Size([394, 4]) 0 1023
Curr loss timestep torch.Size([394, 4]) tensor([345,  54, 136, 232], device='cuda:0') tensor(54, device='cuda:0')
bi 0 loss 0.03172712400555611
bi 1 loss 0.03982817009091377
bi 2 loss 0.020235367119312286
bi 3 loss 0.04029867425560951
Epoch 0: :   3%|▎         | 15634/600000 [04:24<2:45:00, v_num=12, reduced_train_loss=0.295, global_step=15632.0, consumed_samples=62532.0, train_step_timing in s=0.291]Epoch 0: :   3%|▎         | 15634/600000 [04:24<2:45:00, v_num=12, reduced_train_loss=0.273, global_step=15633.0, consumed_samples=62536.0, train_step_timing in s=0.297]loss mask original None

First layer loss:  0.04365270957350731 torch.Size([409, 4]) 2.729121685028076 0.0
Max loss timestep torch.Size([409, 4]) tensor([214, 206, 264, 312], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.028103085234761238
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 1 loss 0.023287538439035416
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
bi 2 loss 0.08423589915037155
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 3 loss 0.043388526886701584
speech mask sum tensor(360, device='cuda:0') loss mask sum tensor(360, device='cuda:0')
logits torch.Size([409, 4, 257024]) labels torch.Size([409, 4]) 0 257023
Layer  0  loss:  0.03697961941361427 0.0 1.6241025924682617
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([215, 259, 279, 312], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.03326668217778206
bi 1 loss 0.02311583422124386
bi 2 loss 0.050894346088171005
bi 3 loss 0.04060197249054909
Layer  1  loss:  0.035297978669404984 0.0 1.6104018688201904
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([206, 275, 315, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.04282141104340553
bi 1 loss 0.02619202807545662
bi 2 loss 0.027053147554397583
bi 3 loss 0.041969917714595795
Layer  2  loss:  0.03600030392408371 0.0 0.9670631885528564
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([180, 176, 180, 283], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 0.02639014832675457
bi 1 loss 0.028071533888578415
bi 2 loss 0.0335538387298584
bi 3 loss 0.04631958156824112
Layer  3  loss:  0.03926678001880646 0.0 1.481665849685669
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1022
Curr loss timestep torch.Size([409, 4]) tensor([130, 202, 288, 147], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 0.03132236376404762
bi 1 loss 0.037778206169605255
bi 2 loss 0.049296822398900986
bi 3 loss 0.03866855427622795
Layer  4  loss:  0.040268175303936005 0.0 1.9537065029144287
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([185, 263, 178, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.02974412404000759
bi 1 loss 0.027885181829333305
bi 2 loss 0.05525850132107735
bi 3 loss 0.045294418931007385
Layer  5  loss:  0.038821011781692505 0.0 1.817848801612854
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([154, 187, 308, 308], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.052265871316194534
bi 1 loss 0.029012497514486313
bi 2 loss 0.04224013909697533
bi 3 loss 0.03773926943540573
Layer  6  loss:  0.03282073512673378 0.0 1.2828073501586914
logits torch.Size([409, 4, 1024]) labels torch.Size([409, 4]) 0 1023
Curr loss timestep torch.Size([409, 4]) tensor([141, 257, 293, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.03245628997683525
bi 1 loss 0.02437727339565754
bi 2 loss 0.035420726984739304
bi 3 loss 0.03709793835878372
Epoch 0: :   3%|▎         | 15635/600000 [04:25<2:45:13, v_num=12, reduced_train_loss=0.273, global_step=15633.0, consumed_samples=62536.0, train_step_timing in s=0.297]Epoch 0: :   3%|▎         | 15635/600000 [04:25<2:45:13, v_num=12, reduced_train_loss=0.303, global_step=15634.0, consumed_samples=62540.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.1458490639925003 torch.Size([577, 4]) 9.253454208374023 0.0
Max loss timestep torch.Size([577, 4]) tensor([383, 403, 302, 532], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.12244156748056412
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 1 loss 0.2026340365409851
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
bi 2 loss 0.10192672908306122
speech mask sum tensor(116, device='cuda:0') loss mask sum tensor(116, device='cuda:0')
bi 3 loss 0.12103882431983948
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
logits torch.Size([577, 4, 257024]) labels torch.Size([577, 4]) 0 257023
Layer  0  loss:  0.1653047800064087 0.0 11.607869148254395
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([288, 319, 303, 529], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.14278222620487213
bi 1 loss 0.20686239004135132
bi 2 loss 0.1760079711675644
bi 3 loss 0.1399954855442047
Layer  1  loss:  0.19220520555973053 0.0 15.06789779663086
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([288, 319, 303, 331], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.1696738749742508
bi 1 loss 0.2036001831293106
bi 2 loss 0.14124399423599243
bi 3 loss 0.2148413509130478
Layer  2  loss:  0.1748727709054947 0.0 11.61552619934082
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([383, 298, 298, 275], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.13814258575439453
bi 1 loss 0.21873225271701813
bi 2 loss 0.1179618239402771
bi 3 loss 0.17870789766311646
Layer  3  loss:  0.1644199937582016 0.0 12.095343589782715
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([383, 319, 303, 529], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.14242109656333923
bi 1 loss 0.19044269621372223
bi 2 loss 0.18526899814605713
bi 3 loss 0.15164946019649506
Layer  4  loss:  0.19399859011173248 0.0 13.65643310546875
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([288, 402, 270, 331], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.17958465218544006
bi 1 loss 0.2204648107290268
bi 2 loss 0.15717926621437073
bi 3 loss 0.19011038541793823
Layer  5  loss:  0.19023296236991882 0.0 12.287424087524414
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1023
Curr loss timestep torch.Size([577, 4]) tensor([288, 402, 259, 331], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.13914260268211365
bi 1 loss 0.24343253672122955
bi 2 loss 0.15163569152355194
bi 3 loss 0.19221390783786774
Layer  6  loss:  0.19602654874324799 0.0 14.442739486694336
logits torch.Size([577, 4, 1024]) labels torch.Size([577, 4]) 0 1022
Curr loss timestep torch.Size([577, 4]) tensor([288, 319, 270, 532], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.15265624225139618
bi 1 loss 0.20665867626667023
bi 2 loss 0.20755186676979065
bi 3 loss 0.2205507606267929
Epoch 0: :   3%|▎         | 15636/600000 [04:25<2:45:28, v_num=12, reduced_train_loss=0.303, global_step=15634.0, consumed_samples=62540.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15636/600000 [04:25<2:45:28, v_num=12, reduced_train_loss=1.420, global_step=15635.0, consumed_samples=62544.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.10137948393821716 torch.Size([571, 4]) 10.007102966308594 0.0
Max loss timestep torch.Size([571, 4]) tensor([523, 346, 270, 287], device='cuda:0') tensor(523, device='cuda:0')
bi 0 loss 0.14535284042358398
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
bi 1 loss 0.0819566622376442
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
bi 2 loss 0.09291709214448929
speech mask sum tensor(222, device='cuda:0') loss mask sum tensor(222, device='cuda:0')
bi 3 loss 0.03885066136717796
speech mask sum tensor(222, device='cuda:0') loss mask sum tensor(222, device='cuda:0')
logits torch.Size([571, 4, 257024]) labels torch.Size([571, 4]) 0 257023
Layer  0  loss:  0.11090213060379028 0.0 9.425171852111816
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1023
Curr loss timestep torch.Size([571, 4]) tensor([536, 314, 271, 288], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.1543082892894745
bi 1 loss 0.08397170156240463
bi 2 loss 0.12351346760988235
bi 3 loss 0.03894391283392906
Layer  1  loss:  0.15064404904842377 0.0 13.75728988647461
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1023
Curr loss timestep torch.Size([571, 4]) tensor([523, 369, 271, 285], device='cuda:0') tensor(523, device='cuda:0')
bi 0 loss 0.21756473183631897
bi 1 loss 0.07849650084972382
bi 2 loss 0.18291696906089783
bi 3 loss 0.0692291185259819
Layer  2  loss:  0.12497369945049286 0.0 10.660521507263184
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1022
Curr loss timestep torch.Size([571, 4]) tensor([536, 346, 271, 183], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.15549609065055847
bi 1 loss 0.11415176838636398
bi 2 loss 0.15774409472942352
bi 3 loss 0.03924953192472458
Layer  3  loss:  0.13775044679641724 0.0 13.006396293640137
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1022
Curr loss timestep torch.Size([571, 4]) tensor([537, 405, 270,  93], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.2118988186120987
bi 1 loss 0.08403012156486511
bi 2 loss 0.141205295920372
bi 3 loss 0.04358765855431557
Layer  4  loss:  0.11758928000926971 0.0 12.241722106933594
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1023
Curr loss timestep torch.Size([571, 4]) tensor([536, 369, 270, 287], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.15990056097507477
bi 1 loss 0.08171911537647247
bi 2 loss 0.12675905227661133
bi 3 loss 0.0638716071844101
Layer  5  loss:  0.14681217074394226 0.0 17.994728088378906
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1023
Curr loss timestep torch.Size([571, 4]) tensor([537, 369, 271, 284], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.22783394157886505
bi 1 loss 0.11388526111841202
bi 2 loss 0.11088231205940247
bi 3 loss 0.04798443987965584
Layer  6  loss:  0.14272083342075348 0.0 8.368212699890137
logits torch.Size([571, 4, 1024]) labels torch.Size([571, 4]) 0 1021
Curr loss timestep torch.Size([571, 4]) tensor([537, 367, 271, 287], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.17880523204803467
bi 1 loss 0.12181065231561661
bi 2 loss 0.18037720024585724
bi 3 loss 0.053684886544942856
Epoch 0: :   3%|▎         | 15637/600000 [04:26<2:45:44, v_num=12, reduced_train_loss=1.420, global_step=15635.0, consumed_samples=62544.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15637/600000 [04:26<2:45:44, v_num=12, reduced_train_loss=1.030, global_step=15636.0, consumed_samples=62548.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  0.09652747213840485 torch.Size([590, 4]) 10.75933837890625 0.0
Max loss timestep torch.Size([590, 4]) tensor([375, 517, 149, 128], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.1364888995885849
speech mask sum tensor(192, device='cuda:0') loss mask sum tensor(192, device='cuda:0')
bi 1 loss 0.12970507144927979
speech mask sum tensor(444, device='cuda:0') loss mask sum tensor(444, device='cuda:0')
bi 2 loss 0.037312593311071396
speech mask sum tensor(284, device='cuda:0') loss mask sum tensor(284, device='cuda:0')
bi 3 loss 0.07255140691995621
speech mask sum tensor(233, device='cuda:0') loss mask sum tensor(233, device='cuda:0')
logits torch.Size([590, 4, 257024]) labels torch.Size([590, 4]) 0 257023
Layer  0  loss:  0.11723547428846359 0.0 14.23475170135498
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([375, 369, 259, 279], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.1552218347787857
bi 1 loss 0.17061595618724823
bi 2 loss 0.05380374938249588
bi 3 loss 0.06152857467532158
Layer  1  loss:  0.10724640637636185 0.0 10.971471786499023
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([318, 369, 143, 297], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.05402815714478493
bi 1 loss 0.18202964961528778
bi 2 loss 0.06436891853809357
bi 3 loss 0.06085731461644173
Layer  2  loss:  0.11795594543218613 0.0 10.502836227416992
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([375, 369, 259, 312], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.15979710221290588
bi 1 loss 0.16072867810726166
bi 2 loss 0.06297032535076141
bi 3 loss 0.06899169832468033
Layer  3  loss:  0.11101587861776352 0.0 14.4174222946167
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([375, 369, 144, 244], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.12458354234695435
bi 1 loss 0.18585741519927979
bi 2 loss 0.02954697236418724
bi 3 loss 0.05652029067277908
Layer  4  loss:  0.1314714401960373 0.0 18.57250213623047
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([376, 369, 259, 130], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.12300118058919907
bi 1 loss 0.22655710577964783
bi 2 loss 0.06295858323574066
bi 3 loss 0.040767181664705276
Layer  5  loss:  0.13662102818489075 0.0 11.221635818481445
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([375, 369, 259, 302], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.16807226836681366
bi 1 loss 0.19926545023918152
bi 2 loss 0.0770132839679718
bi 3 loss 0.0639851987361908
Layer  6  loss:  0.1202990785241127 0.0 12.754905700683594
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([376, 369, 259, 302], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.18494383990764618
bi 1 loss 0.17595073580741882
bi 2 loss 0.05195188522338867
bi 3 loss 0.044288258999586105
Epoch 0: :   3%|▎         | 15638/600000 [04:26<2:46:00, v_num=12, reduced_train_loss=1.030, global_step=15636.0, consumed_samples=62548.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15638/600000 [04:26<2:46:00, v_num=12, reduced_train_loss=0.938, global_step=15637.0, consumed_samples=62552.0, train_step_timing in s=0.406]loss mask original None

First layer loss:  0.055173538625240326 torch.Size([455, 4]) 4.2644362449646 0.0
Max loss timestep torch.Size([455, 4]) tensor([289, 317, 123, 261], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.04209945350885391
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 1 loss 0.10007859766483307
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 2 loss 0.016608620062470436
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 3 loss 0.04582836478948593
speech mask sum tensor(159, device='cuda:0') loss mask sum tensor(159, device='cuda:0')
logits torch.Size([455, 4, 257024]) labels torch.Size([455, 4]) 0 257023
Layer  0  loss:  0.0801163986325264 0.0 6.823163032531738
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1023
Curr loss timestep torch.Size([455, 4]) tensor([270, 294,  46, 260], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 0.04098909720778465
bi 1 loss 0.18081514537334442
bi 2 loss 0.029010673984885216
bi 3 loss 0.05525593087077141
Layer  1  loss:  0.06450604647397995 0.0 5.288248062133789
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([384, 309,  68, 186], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.0327843576669693
bi 1 loss 0.1496991664171219
bi 2 loss 0.03170308843255043
bi 3 loss 0.03374772518873215
Layer  2  loss:  0.07496274262666702 0.0 5.908999443054199
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1023
Curr loss timestep torch.Size([455, 4]) tensor([407, 309,  65, 260], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.07901620119810104
bi 1 loss 0.11552850157022476
bi 2 loss 0.025985978543758392
bi 3 loss 0.04411817342042923
Layer  3  loss:  0.07359429448843002 0.0 6.621904373168945
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([290, 309,  55, 261], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.05751698836684227
bi 1 loss 0.129365935921669
bi 2 loss 0.03151145204901695
bi 3 loss 0.05778924375772476
Layer  4  loss:  0.1047365590929985 0.0 10.757542610168457
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1021
Curr loss timestep torch.Size([455, 4]) tensor([226, 317,  81, 228], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.06792127341032028
bi 1 loss 0.2356416881084442
bi 2 loss 0.02882939949631691
bi 3 loss 0.0505467914044857
Layer  5  loss:  0.08503233641386032 0.0 9.222794532775879
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1023
Curr loss timestep torch.Size([455, 4]) tensor([343, 309,  79, 186], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.06622324883937836
bi 1 loss 0.17074406147003174
bi 2 loss 0.041683346033096313
bi 3 loss 0.0346904918551445
Layer  6  loss:  0.10064154118299484 0.0 13.516128540039062
logits torch.Size([455, 4, 1024]) labels torch.Size([455, 4]) 0 1022
Curr loss timestep torch.Size([455, 4]) tensor([395, 309,  43, 258], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.05516928806900978
bi 1 loss 0.23412038385868073
bi 2 loss 0.017874762415885925
bi 3 loss 0.06488066166639328
Epoch 0: :   3%|▎         | 15639/600000 [04:26<2:46:12, v_num=12, reduced_train_loss=0.938, global_step=15637.0, consumed_samples=62552.0, train_step_timing in s=0.406]Epoch 0: :   3%|▎         | 15639/600000 [04:26<2:46:12, v_num=12, reduced_train_loss=0.639, global_step=15638.0, consumed_samples=62556.0, train_step_timing in s=0.326]loss mask original None

First layer loss:  0.0487113855779171 torch.Size([435, 4]) 3.555915117263794 0.0
Max loss timestep torch.Size([435, 4]) tensor([338, 222,  89, 105], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.08877864480018616
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
bi 1 loss 0.04499393701553345
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 2 loss 0.021686077117919922
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 3 loss 0.009596049785614014
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
logits torch.Size([435, 4, 257024]) labels torch.Size([435, 4]) 0 257022
Layer  0  loss:  0.037715792655944824 0.0 1.0986939668655396
logits torch.Size([435, 4, 1024]) labels torch.Size([435, 4]) 0 1023
Curr loss timestep torch.Size([435, 4]) tensor([305, 184, 190, 106], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 0.05136023461818695
bi 1 loss 0.042489439249038696
bi 2 loss 0.03199347108602524
bi 3 loss 0.012923839502036572
Layer  1  loss:  0.04887891560792923 0.0 3.6257359981536865
logits torch.Size([435, 4, 1024]) labels torch.Size([435, 4]) 0 1022
Curr loss timestep torch.Size([435, 4]) tensor([329, 221, 192,  87], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.08873289823532104
bi 1 loss 0.033609021455049515
bi 2 loss 0.03031623549759388
bi 3 loss 0.014587783254683018
Layer  2  loss:  0.05537543073296547 0.0 5.529328346252441
logits torch.Size([435, 4, 1024]) labels torch.Size([435, 4]) 0 1022
Curr loss timestep torch.Size([435, 4]) tensor([329,  84, 172, 101], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.10829945653676987
bi 1 loss 0.034527212381362915
bi 2 loss 0.024493549019098282
bi 3 loss 0.01776093989610672
Layer  3  loss:  0.05116989091038704 0.0 2.8311171531677246
logits torch.Size([435, 4, 1024]) labels torch.Size([435, 4]) 0 1022
Curr loss timestep torch.Size([435, 4]) tensor([278,  52, 195,  94], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.08273709565401077
bi 1 loss 0.05590935796499252
bi 2 loss 0.03049609810113907
bi 3 loss 0.010191306471824646
Layer  4  loss:  0.046319931745529175 0.0 2.7619895935058594
logits torch.Size([435, 4, 1024]) labels torch.Size([435, 4]) 0 1022
Curr loss timestep torch.Size([435, 4]) tensor([329,  89, 144, 110], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.079875648021698
bi 1 loss 0.03337310254573822
bi 2 loss 0.032435521483421326
bi 3 loss 0.015537568368017673
Layer  5  loss:  0.052990496158599854 0.0 5.260908126831055
logits torch.Size([435, 4, 1024]) labels torch.Size([435, 4]) 0 1022
Curr loss timestep torch.Size([435, 4]) tensor([329,  86,  92, 191], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.09381738305091858
bi 1 loss 0.03307655453681946
bi 2 loss 0.038641706109046936
bi 3 loss 0.01771630346775055
Layer  6  loss:  0.04425152391195297 0.0 2.00307035446167
logits torch.Size([435, 4, 1024]) labels torch.Size([435, 4]) 0 1023
Curr loss timestep torch.Size([435, 4]) tensor([280, 115,  90,  95], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.07473854720592499
bi 1 loss 0.04030340537428856
bi 2 loss 0.024802975356578827
bi 3 loss 0.014576095156371593
Epoch 0: :   3%|▎         | 15640/600000 [04:27<2:46:25, v_num=12, reduced_train_loss=0.639, global_step=15638.0, consumed_samples=62556.0, train_step_timing in s=0.326]Epoch 0: :   3%|▎         | 15640/600000 [04:27<2:46:25, v_num=12, reduced_train_loss=0.385, global_step=15639.0, consumed_samples=62560.0, train_step_timing in s=0.324]loss mask original None

First layer loss:  3.7515790462493896 torch.Size([564, 4]) 11.84644889831543 0.0
Max loss timestep torch.Size([564, 4]) tensor([136, 347, 182, 406], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 3.360670804977417
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
bi 1 loss 4.025577068328857
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 2 loss 3.749371290206909
speech mask sum tensor(497, device='cuda:0') loss mask sum tensor(497, device='cuda:0')
bi 3 loss 3.9648659229278564
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
logits torch.Size([564, 4, 257024]) labels torch.Size([564, 4]) 0 257023
Layer  0  loss:  4.262760639190674 0.0 10.462956428527832
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([411, 308, 169, 305], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 3.9155068397521973
bi 1 loss 4.425510406494141
bi 2 loss 4.279608249664307
bi 3 loss 4.492448806762695
Layer  1  loss:  4.508545875549316 0.0 10.486478805541992
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([291, 211, 494, 367], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.052558422088623
bi 1 loss 4.955208778381348
bi 2 loss 4.407575607299805
bi 3 loss 4.801114082336426
Layer  2  loss:  4.787337303161621 0.0 11.634819984436035
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([141, 211, 395, 298], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 4.508768081665039
bi 1 loss 5.149191379547119
bi 2 loss 4.7377705574035645
bi 3 loss 4.870485782623291
Layer  3  loss:  4.830090045928955 0.0 10.443605422973633
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1021
Curr loss timestep torch.Size([564, 4]) tensor([332, 235, 257, 465], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 4.513457775115967
bi 1 loss 5.021974563598633
bi 2 loss 4.809597015380859
bi 3 loss 5.057900428771973
Layer  4  loss:  5.0611653327941895 0.0 10.794599533081055
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([192, 403, 409, 192], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 4.728578567504883
bi 1 loss 5.213292598724365
bi 2 loss 5.015819072723389
bi 3 loss 5.380173683166504
Layer  5  loss:  5.199434757232666 0.0 10.469361305236816
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([431, 353, 408, 222], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 4.996314525604248
bi 1 loss 5.168454170227051
bi 2 loss 5.190316677093506
bi 3 loss 5.472122669219971
Layer  6  loss:  5.202554702758789 0.0 9.975414276123047
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([158, 286, 527, 468], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 4.941140174865723
bi 1 loss 5.153470993041992
bi 2 loss 5.258328914642334
bi 3 loss 5.456264019012451
Epoch 0: :   3%|▎         | 15641/600000 [04:27<2:46:40, v_num=12, reduced_train_loss=0.385, global_step=15639.0, consumed_samples=62560.0, train_step_timing in s=0.324]Epoch 0: :   3%|▎         | 15641/600000 [04:27<2:46:40, v_num=12, reduced_train_loss=37.60, global_step=15640.0, consumed_samples=62564.0, train_step_timing in s=0.370]loss mask original None

First layer loss:  0.14743201434612274 torch.Size([578, 4]) 12.783371925354004 0.0
Max loss timestep torch.Size([578, 4]) tensor([180, 507, 259, 270], device='cuda:0') tensor(507, device='cuda:0')
bi 0 loss 0.08169225603342056
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 1 loss 0.21539632976055145
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
bi 2 loss 0.11089382320642471
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 3 loss 0.11006561666727066
speech mask sum tensor(405, device='cuda:0') loss mask sum tensor(405, device='cuda:0')
logits torch.Size([578, 4, 257024]) labels torch.Size([578, 4]) 0 257023
Layer  0  loss:  0.135535329580307 0.0 13.579874992370605
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1023
Curr loss timestep torch.Size([578, 4]) tensor([220, 507, 276, 288], device='cuda:0') tensor(507, device='cuda:0')
bi 0 loss 0.07013702392578125
bi 1 loss 0.19425396621227264
bi 2 loss 0.05566561967134476
bi 3 loss 0.12407604604959488
Layer  1  loss:  0.1604735106229782 0.0 13.297530174255371
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1022
Curr loss timestep torch.Size([578, 4]) tensor([201, 507, 259, 270], device='cuda:0') tensor(507, device='cuda:0')
bi 0 loss 0.04118425026535988
bi 1 loss 0.2514365613460541
bi 2 loss 0.06551678478717804
bi 3 loss 0.13499481976032257
Layer  2  loss:  0.17786964774131775 0.0 10.982579231262207
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1022
Curr loss timestep torch.Size([578, 4]) tensor([218, 356, 276, 307], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.09068773686885834
bi 1 loss 0.26033279299736023
bi 2 loss 0.06486862152814865
bi 3 loss 0.16116192936897278
Layer  3  loss:  0.17494164407253265 0.0 11.815853118896484
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1020
Curr loss timestep torch.Size([578, 4]) tensor([218, 506, 276, 288], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.04718071222305298
bi 1 loss 0.2512929439544678
bi 2 loss 0.0651307925581932
bi 3 loss 0.17104488611221313
Layer  4  loss:  0.17268399894237518 0.0 18.70389747619629
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1022
Curr loss timestep torch.Size([578, 4]) tensor([203, 506, 259, 318], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.04504208639264107
bi 1 loss 0.27775120735168457
bi 2 loss 0.05501692369580269
bi 3 loss 0.14435628056526184
Layer  5  loss:  0.1951349675655365 0.0 13.024686813354492
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1022
Curr loss timestep torch.Size([578, 4]) tensor([183, 506, 161, 512], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.05850956588983536
bi 1 loss 0.3219835162162781
bi 2 loss 0.06414932012557983
bi 3 loss 0.15302075445652008
Layer  6  loss:  0.18207326531410217 0.0 13.29606819152832
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1021
Curr loss timestep torch.Size([578, 4]) tensor([222, 507, 144, 320], device='cuda:0') tensor(507, device='cuda:0')
bi 0 loss 0.0672888532280922
bi 1 loss 0.29685214161872864
bi 2 loss 0.07205704599618912
bi 3 loss 0.1388157606124878
Epoch 0: :   3%|▎         | 15642/600000 [04:28<2:46:55, v_num=12, reduced_train_loss=37.60, global_step=15640.0, consumed_samples=62564.0, train_step_timing in s=0.370]Epoch 0: :   3%|▎         | 15642/600000 [04:28<2:46:55, v_num=12, reduced_train_loss=1.350, global_step=15641.0, consumed_samples=62568.0, train_step_timing in s=0.396]loss mask original None

First layer loss:  0.05669976398348808 torch.Size([466, 4]) 3.0660526752471924 0.0
Max loss timestep torch.Size([466, 4]) tensor([171, 116, 426, 414], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 0.04792167991399765
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
bi 1 loss 0.04789312556385994
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 2 loss 0.07683481276035309
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
bi 3 loss 0.05122685804963112
speech mask sum tensor(389, device='cuda:0') loss mask sum tensor(389, device='cuda:0')
logits torch.Size([466, 4, 257024]) labels torch.Size([466, 4]) 0 257023
Layer  0  loss:  0.06057972088456154 0.0 3.2300896644592285
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([160,  50, 354, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.059088435024023056
bi 1 loss 0.023588361218571663
bi 2 loss 0.04772534221410751
bi 3 loss 0.08108588308095932
Layer  1  loss:  0.05740465596318245 0.0 4.45782470703125
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([163,  55, 404, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.03744155913591385
bi 1 loss 0.029505999758839607
bi 2 loss 0.06036655977368355
bi 3 loss 0.07542133331298828
Layer  2  loss:  0.04893209785223007 0.0 3.6262264251708984
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([272, 120, 428, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.03195396438241005
bi 1 loss 0.058241188526153564
bi 2 loss 0.045413900166749954
bi 3 loss 0.05819114297628403
Layer  3  loss:  0.053704578429460526 0.0 1.7355210781097412
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1022
Curr loss timestep torch.Size([466, 4]) tensor([218,  92, 275, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.05250464007258415
bi 1 loss 0.030260082334280014
bi 2 loss 0.07551020383834839
bi 3 loss 0.04721306636929512
Layer  4  loss:  0.061441387981176376 0.0 6.138142108917236
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([236,  75, 263, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.042416658252477646
bi 1 loss 0.0431501679122448
bi 2 loss 0.06151280552148819
bi 3 loss 0.07789818197488785
Layer  5  loss:  0.05970840901136398 0.0 6.730486869812012
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1022
Curr loss timestep torch.Size([466, 4]) tensor([177,  63, 426, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.0409279391169548
bi 1 loss 0.03521054610610008
bi 2 loss 0.07061421126127243
bi 3 loss 0.07080505043268204
Layer  6  loss:  0.05783512070775032 0.0 5.5261549949646
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1022
Curr loss timestep torch.Size([466, 4]) tensor([316,  98, 382, 278], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.05755329504609108
bi 1 loss 0.02243254892528057
bi 2 loss 0.05684381723403931
bi 3 loss 0.069386325776577
Epoch 0: :   3%|▎         | 15643/600000 [04:28<2:47:08, v_num=12, reduced_train_loss=1.350, global_step=15641.0, consumed_samples=62568.0, train_step_timing in s=0.396]Epoch 0: :   3%|▎         | 15643/600000 [04:28<2:47:08, v_num=12, reduced_train_loss=0.456, global_step=15642.0, consumed_samples=62572.0, train_step_timing in s=0.334]loss mask original None

First layer loss:  0.05590170621871948 torch.Size([494, 4]) 5.441247463226318 0.0
Max loss timestep torch.Size([494, 4]) tensor([291, 269,  99, 106], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.05104093998670578
speech mask sum tensor(210, device='cuda:0') loss mask sum tensor(210, device='cuda:0')
bi 1 loss 0.07533983141183853
speech mask sum tensor(270, device='cuda:0') loss mask sum tensor(270, device='cuda:0')
bi 2 loss 0.02509484440088272
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 3 loss 0.04207538813352585
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
logits torch.Size([494, 4, 257024]) labels torch.Size([494, 4]) 0 257022
Layer  0  loss:  0.04097144305706024 0.0 2.9064815044403076
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1023
Curr loss timestep torch.Size([494, 4]) tensor([291, 389, 146, 110], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.055396705865859985
bi 1 loss 0.03575591370463371
bi 2 loss 0.02041970007121563
bi 3 loss 0.04338987171649933
Layer  1  loss:  0.056069664657115936 0.0 10.926728248596191
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1022
Curr loss timestep torch.Size([494, 4]) tensor([288, 359, 155, 142], device='cuda:0') tensor(142, device='cuda:0')
bi 0 loss 0.05514846369624138
bi 1 loss 0.03920314833521843
bi 2 loss 0.02499210648238659
bi 3 loss 0.1296178698539734
Layer  2  loss:  0.041534096002578735 0.0 1.9107000827789307
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1022
Curr loss timestep torch.Size([494, 4]) tensor([291, 331, 131, 156], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.046043604612350464
bi 1 loss 0.04395470395684242
bi 2 loss 0.02413921244442463
bi 3 loss 0.041362959891557693
Layer  3  loss:  0.04920017719268799 0.0 2.1650657653808594
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1023
Curr loss timestep torch.Size([494, 4]) tensor([264, 388, 163, 145], device='cuda:0') tensor(388, device='cuda:0')
bi 0 loss 0.047506459057331085
bi 1 loss 0.06665275245904922
bi 2 loss 0.0201258547604084
bi 3 loss 0.03259092941880226
Layer  4  loss:  0.06379858404397964 0.0 3.3429346084594727
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1023
Curr loss timestep torch.Size([494, 4]) tensor([212, 299, 156, 153], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.07059939950704575
bi 1 loss 0.07382892817258835
bi 2 loss 0.03372981771826744
bi 3 loss 0.050205256789922714
Layer  5  loss:  0.04394516721367836 0.0 1.3091684579849243
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1022
Curr loss timestep torch.Size([494, 4]) tensor([246, 385, 143,  93], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 0.04960348829627037
bi 1 loss 0.05189115181565285
bi 2 loss 0.03209022060036659
bi 3 loss 0.022053314372897148
Layer  6  loss:  0.052705317735672 0.0 3.1171600818634033
logits torch.Size([494, 4, 1024]) labels torch.Size([494, 4]) 0 1019
Curr loss timestep torch.Size([494, 4]) tensor([287, 330, 133, 148], device='cuda:0') tensor(330, device='cuda:0')
bi 0 loss 0.04165260121226311
bi 1 loss 0.07407809793949127
bi 2 loss 0.041184261441230774
bi 3 loss 0.029393063858151436
Epoch 0: :   3%|▎         | 15644/600000 [04:28<2:47:22, v_num=12, reduced_train_loss=0.456, global_step=15642.0, consumed_samples=62572.0, train_step_timing in s=0.334]Epoch 0: :   3%|▎         | 15644/600000 [04:28<2:47:22, v_num=12, reduced_train_loss=0.404, global_step=15643.0, consumed_samples=62576.0, train_step_timing in s=0.347]loss mask original None

First layer loss:  3.6475136280059814 torch.Size([744, 4]) 12.337759017944336 0.0
Max loss timestep torch.Size([744, 4]) tensor([194, 481, 145, 647], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 3.4622719287872314
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 1 loss 3.9459614753723145
speech mask sum tensor(465, device='cuda:0') loss mask sum tensor(465, device='cuda:0')
bi 2 loss 3.6067306995391846
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 3 loss 3.4887869358062744
speech mask sum tensor(505, device='cuda:0') loss mask sum tensor(505, device='cuda:0')
logits torch.Size([744, 4, 257024]) labels torch.Size([744, 4]) 0 257022
Layer  0  loss:  4.33806037902832 0.0 10.429930686950684
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([160, 419, 303, 699], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 4.28495979309082
bi 1 loss 4.661677360534668
bi 2 loss 4.251235485076904
bi 3 loss 4.128401756286621
Layer  1  loss:  4.656749725341797 0.0 10.449487686157227
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([169, 560, 309, 678], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 4.516082286834717
bi 1 loss 5.06204891204834
bi 2 loss 4.474850177764893
bi 3 loss 4.482285022735596
Layer  2  loss:  4.871647357940674 0.0 10.676170349121094
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([209, 532, 332, 551], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 4.802677154541016
bi 1 loss 5.250242710113525
bi 2 loss 4.620445728302002
bi 3 loss 4.739182472229004
Layer  3  loss:  5.033629894256592 0.0 11.330172538757324
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([311, 588, 231, 586], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 5.118237018585205
bi 1 loss 5.453740119934082
bi 2 loss 4.661617279052734
bi 3 loss 4.8799872398376465
Layer  4  loss:  5.213285446166992 0.0 10.216618537902832
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([135, 332, 366, 684], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 5.349946022033691
bi 1 loss 5.602404594421387
bi 2 loss 4.880213260650635
bi 3 loss 5.035427570343018
Layer  5  loss:  5.291563510894775 0.0 10.727019309997559
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([325, 561, 299, 287], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 5.447464942932129
bi 1 loss 5.683521747589111
bi 2 loss 5.053042411804199
bi 3 loss 5.032862663269043
Layer  6  loss:  5.326207637786865 0.0 10.056343078613281
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1020
Curr loss timestep torch.Size([744, 4]) tensor([138, 640, 341, 344], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 5.389996528625488
bi 1 loss 5.742516040802002
bi 2 loss 4.97014045715332
bi 3 loss 5.174071788787842
Epoch 0: :   3%|▎         | 15645/600000 [04:29<2:47:39, v_num=12, reduced_train_loss=0.404, global_step=15643.0, consumed_samples=62576.0, train_step_timing in s=0.347]Epoch 0: :   3%|▎         | 15645/600000 [04:29<2:47:39, v_num=12, reduced_train_loss=38.40, global_step=15644.0, consumed_samples=62580.0, train_step_timing in s=0.441]loss mask original None

First layer loss:  0.10339479893445969 torch.Size([533, 4]) 13.359565734863281 0.0
Max loss timestep torch.Size([533, 4]) tensor([265, 391, 258, 339], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.13062968850135803
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
bi 1 loss 0.1346001923084259
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 2 loss 0.08264618366956711
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
bi 3 loss 0.05246998369693756
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
logits torch.Size([533, 4, 257024]) labels torch.Size([533, 4]) 0 257023
Layer  0  loss:  0.1455543488264084 0.0 13.443929672241211
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([273, 521, 396, 205], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.22684147953987122
bi 1 loss 0.15464068949222565
bi 2 loss 0.12896977365016937
bi 3 loss 0.05579623207449913
Layer  1  loss:  0.1563752442598343 0.0 12.549851417541504
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([262, 521, 396, 236], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.25133436918258667
bi 1 loss 0.16439774632453918
bi 2 loss 0.13417427241802216
bi 3 loss 0.06309095025062561
Layer  2  loss:  0.15897199511528015 0.0 12.832040786743164
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([262, 392, 396, 240], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.21134531497955322
bi 1 loss 0.19505427777767181
bi 2 loss 0.13886696100234985
bi 3 loss 0.06302664428949356
Layer  3  loss:  0.15121351182460785 0.0 21.003835678100586
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([265, 392, 396, 209], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.2905782163143158
bi 1 loss 0.12339550256729126
bi 2 loss 0.12468395382165909
bi 3 loss 0.07858284562826157
Layer  4  loss:  0.1770348995923996 0.0 12.500178337097168
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([262, 521, 258, 339], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.22166197001934052
bi 1 loss 0.20392701029777527
bi 2 loss 0.18115678429603577
bi 3 loss 0.05433589220046997
Layer  5  loss:  0.18687179684638977 0.0 16.51447296142578
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([265, 472, 396, 289], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.297675222158432
bi 1 loss 0.2198328822851181
bi 2 loss 0.1557220220565796
bi 3 loss 0.04344670847058296
Layer  6  loss:  0.18082529306411743 0.0 14.079108238220215
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([265, 392, 177, 259], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.2567388713359833
bi 1 loss 0.23988983035087585
bi 2 loss 0.13332124054431915
bi 3 loss 0.0703539252281189
Epoch 0: :   3%|▎         | 15646/600000 [04:29<2:47:54, v_num=12, reduced_train_loss=38.40, global_step=15644.0, consumed_samples=62580.0, train_step_timing in s=0.441]Epoch 0: :   3%|▎         | 15646/600000 [04:29<2:47:54, v_num=12, reduced_train_loss=1.260, global_step=15645.0, consumed_samples=62584.0, train_step_timing in s=0.372]loss mask original None

First layer loss:  3.253045082092285 torch.Size([744, 4]) 18.153522491455078 0.0
Max loss timestep torch.Size([744, 4]) tensor([137, 222, 410, 419], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.369329929351807
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 1 loss 3.1485402584075928
speech mask sum tensor(267, device='cuda:0') loss mask sum tensor(267, device='cuda:0')
bi 2 loss 2.8110556602478027
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
bi 3 loss 3.5928122997283936
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
logits torch.Size([744, 4, 257024]) labels torch.Size([744, 4]) 0 257021
Layer  0  loss:  3.9550838470458984 0.0 9.67072582244873
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([117, 270, 522, 366], device='cuda:0') tensor(429, device='cuda:0')
bi 0 loss 4.670551300048828
bi 1 loss 4.025782108306885
bi 2 loss 3.728196144104004
bi 3 loss 3.966155767440796
Layer  1  loss:  4.426715850830078 0.0 9.769343376159668
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([ 96, 385, 697, 154], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 4.832568645477295
bi 1 loss 4.577507972717285
bi 2 loss 4.168426513671875
bi 3 loss 4.544807434082031
Layer  2  loss:  4.676826000213623 0.0 9.412988662719727
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([123, 335, 321, 210], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 5.0991950035095215
bi 1 loss 4.765960693359375
bi 2 loss 4.353599548339844
bi 3 loss 4.943863391876221
Layer  3  loss:  4.853843688964844 0.0 10.781764030456543
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([149, 228, 465, 416], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 5.089838027954102
bi 1 loss 5.032009124755859
bi 2 loss 4.616467475891113
bi 3 loss 4.984127044677734
Layer  4  loss:  4.969581127166748 0.0 10.885810852050781
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1021
Curr loss timestep torch.Size([744, 4]) tensor([ 48, 407, 485, 381], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 5.405376434326172
bi 1 loss 5.159335136413574
bi 2 loss 4.712197780609131
bi 3 loss 5.040994644165039
Layer  5  loss:  5.124655246734619 0.0 11.266500473022461
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([ 74, 394, 674, 157], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 5.529500484466553
bi 1 loss 5.347371578216553
bi 2 loss 4.88539981842041
bi 3 loss 5.151751518249512
Layer  6  loss:  5.157938480377197 0.0 10.08919906616211
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([146, 321, 340, 272], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 5.559391498565674
bi 1 loss 5.230602264404297
bi 2 loss 5.006843090057373
bi 3 loss 5.173896789550781
Epoch 0: :   3%|▎         | 15647/600000 [04:30<2:48:11, v_num=12, reduced_train_loss=1.260, global_step=15645.0, consumed_samples=62584.0, train_step_timing in s=0.372]Epoch 0: :   3%|▎         | 15647/600000 [04:30<2:48:11, v_num=12, reduced_train_loss=36.40, global_step=15646.0, consumed_samples=62588.0, train_step_timing in s=0.438]loss mask original None

First layer loss:  0.182237908244133 torch.Size([539, 4]) 12.43988037109375 0.0
Max loss timestep torch.Size([539, 4]) tensor([237, 386, 262, 323], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.22877852618694305
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 1 loss 0.19690637290477753
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 2 loss 0.21741528809070587
speech mask sum tensor(400, device='cuda:0') loss mask sum tensor(400, device='cuda:0')
bi 3 loss 0.08864999562501907
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
logits torch.Size([539, 4, 257024]) labels torch.Size([539, 4]) 0 257022
Layer  0  loss:  0.187527135014534 0.0 13.337126731872559
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([367, 386, 496, 323], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.10966908931732178
bi 1 loss 0.24874922633171082
bi 2 loss 0.23741263151168823
bi 3 loss 0.10482321679592133
Layer  1  loss:  0.21550488471984863 0.0 13.733244895935059
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([258, 297, 264, 322], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.13942281901836395
bi 1 loss 0.278038889169693
bi 2 loss 0.2453506886959076
bi 3 loss 0.15479151904582977
Layer  2  loss:  0.18924525380134583 0.0 20.61773109436035
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([284, 296, 264, 323], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.12245729565620422
bi 1 loss 0.2134779691696167
bi 2 loss 0.230122908949852
bi 3 loss 0.15517400205135345
Layer  3  loss:  0.20149695873260498 0.0 14.836039543151855
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([253, 297, 264, 323], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.1123541072010994
bi 1 loss 0.2594295144081116
bi 2 loss 0.2569994330406189
bi 3 loss 0.12364064157009125
Layer  4  loss:  0.21930715441703796 0.0 15.406885147094727
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1021
Curr loss timestep torch.Size([539, 4]) tensor([326, 297, 264, 322], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.09825605899095535
bi 1 loss 0.2832290828227997
bi 2 loss 0.25588852167129517
bi 3 loss 0.17960622906684875
Layer  5  loss:  0.22419977188110352 0.0 18.131887435913086
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([337, 386, 264, 323], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.10246942192316055
bi 1 loss 0.276162326335907
bi 2 loss 0.2566705346107483
bi 3 loss 0.20464663207530975
Layer  6  loss:  0.22287197411060333 0.0 15.634562492370605
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([367, 386, 264, 323], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.07853758335113525
bi 1 loss 0.3223552107810974
bi 2 loss 0.23058433830738068
bi 3 loss 0.191618874669075
Epoch 0: :   3%|▎         | 15648/600000 [04:30<2:48:26, v_num=12, reduced_train_loss=36.40, global_step=15646.0, consumed_samples=62588.0, train_step_timing in s=0.438]Epoch 0: :   3%|▎         | 15648/600000 [04:30<2:48:26, v_num=12, reduced_train_loss=1.640, global_step=15647.0, consumed_samples=62592.0, train_step_timing in s=0.371]loss mask original None

First layer loss:  3.469409227371216 torch.Size([444, 4]) 13.27200698852539 0.0
Max loss timestep torch.Size([444, 4]) tensor([ 91,  47, 394, 174], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 3.9460294246673584
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 1 loss 2.715688467025757
speech mask sum tensor(40, device='cuda:0') loss mask sum tensor(40, device='cuda:0')
bi 2 loss 3.4506795406341553
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 3 loss 3.376106023788452
speech mask sum tensor(282, device='cuda:0') loss mask sum tensor(282, device='cuda:0')
logits torch.Size([444, 4, 257024]) labels torch.Size([444, 4]) 0 257022
Layer  0  loss:  3.859405279159546 0.0 10.476421356201172
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1023
Curr loss timestep torch.Size([444, 4]) tensor([ 99,  41, 108, 334], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 4.578071594238281
bi 1 loss 3.3186848163604736
bi 2 loss 3.987492322921753
bi 3 loss 3.4290990829467773
Layer  1  loss:  4.176321983337402 0.0 9.04898738861084
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([108,  49, 355, 251], device='cuda:0') tensor(157, device='cuda:0')
bi 0 loss 4.624138355255127
bi 1 loss 3.539956569671631
bi 2 loss 4.321413040161133
bi 3 loss 3.8650152683258057
Layer  2  loss:  4.440863609313965 0.0 10.14004135131836
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([ 97,  53, 131, 381], device='cuda:0') tensor(151, device='cuda:0')
bi 0 loss 4.8443145751953125
bi 1 loss 3.646660566329956
bi 2 loss 4.707765102386475
bi 3 loss 4.013046741485596
Layer  3  loss:  4.561870098114014 0.0 10.751777648925781
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1019
Curr loss timestep torch.Size([444, 4]) tensor([ 80,  50, 398, 214], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 4.810642719268799
bi 1 loss 4.048120975494385
bi 2 loss 4.771462440490723
bi 3 loss 4.242416858673096
Layer  4  loss:  4.629387378692627 0.0 10.044495582580566
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1022
Curr loss timestep torch.Size([444, 4]) tensor([115,  52, 102, 399], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 4.966630458831787
bi 1 loss 3.895956516265869
bi 2 loss 4.822509765625
bi 3 loss 4.320979118347168
Layer  5  loss:  4.723110198974609 0.0 9.73002815246582
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1023
Curr loss timestep torch.Size([444, 4]) tensor([157,  55, 192, 362], device='cuda:0') tensor(157, device='cuda:0')
bi 0 loss 4.9407758712768555
bi 1 loss 4.244603633880615
bi 2 loss 5.040399551391602
bi 3 loss 4.272023677825928
Layer  6  loss:  4.763950824737549 0.0 11.4993896484375
logits torch.Size([444, 4, 1024]) labels torch.Size([444, 4]) 0 1019
Curr loss timestep torch.Size([444, 4]) tensor([155,  55, 432, 351], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 5.175273895263672
bi 1 loss 4.335875511169434
bi 2 loss 4.9760823249816895
bi 3 loss 4.352348804473877
Epoch 0: :   3%|▎         | 15649/600000 [04:30<2:48:38, v_num=12, reduced_train_loss=1.640, global_step=15647.0, consumed_samples=62592.0, train_step_timing in s=0.371]Epoch 0: :   3%|▎         | 15649/600000 [04:30<2:48:38, v_num=12, reduced_train_loss=34.60, global_step=15648.0, consumed_samples=62596.0, train_step_timing in s=0.311]loss mask original None

First layer loss:  0.019520137459039688 torch.Size([318, 4]) 3.628197193145752 0.0
Max loss timestep torch.Size([318, 4]) tensor([ 57, 148, 292, 114], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.015331728383898735
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 1 loss 0.011048120446503162
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 2 loss 0.04008348286151886
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 3 loss 0.011124853044748306
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
logits torch.Size([318, 4, 257024]) labels torch.Size([318, 4]) 0 257022
Layer  0  loss:  0.021620463579893112 0.0 5.879282474517822
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1023
Curr loss timestep torch.Size([318, 4]) tensor([ 74, 187, 292, 182], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.013251912780106068
bi 1 loss 0.009451374411582947
bi 2 loss 0.0513523705303669
bi 3 loss 0.010522156953811646
Layer  1  loss:  0.02633909322321415 0.0 9.264579772949219
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1019
Curr loss timestep torch.Size([318, 4]) tensor([ 81, 157, 292,  94], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.011827317997813225
bi 1 loss 0.00806308351457119
bi 2 loss 0.071120984852314
bi 3 loss 0.010491542518138885
Layer  2  loss:  0.017931973561644554 0.0 3.9283270835876465
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1022
Curr loss timestep torch.Size([318, 4]) tensor([ 95, 166, 292, 133], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.012738227844238281
bi 1 loss 0.011234818026423454
bi 2 loss 0.037483908236026764
bi 3 loss 0.009424218907952309
Layer  3  loss:  0.01518531609326601 0.0 2.048884391784668
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1021
Curr loss timestep torch.Size([318, 4]) tensor([ 57, 178, 292, 203], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.013361858204007149
bi 1 loss 0.012097582221031189
bi 2 loss 0.025374894961714745
bi 3 loss 0.01000190805643797
Layer  4  loss:  0.025336110964417458 0.0 7.62697696685791
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1023
Curr loss timestep torch.Size([318, 4]) tensor([ 45, 227, 292, 107], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.01015680655837059
bi 1 loss 0.014018012210726738
bi 2 loss 0.06357160210609436
bi 3 loss 0.009652865119278431
Layer  5  loss:  0.02231409400701523 0.0 6.372063159942627
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1022
Curr loss timestep torch.Size([318, 4]) tensor([ 33, 246, 292, 175], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.012966235168278217
bi 1 loss 0.01207653246819973
bi 2 loss 0.05234894901514053
bi 3 loss 0.009858538396656513
Layer  6  loss:  0.029874667525291443 0.0 10.780900001525879
logits torch.Size([318, 4, 1024]) labels torch.Size([318, 4]) 0 1019
Curr loss timestep torch.Size([318, 4]) tensor([ 59, 179, 292, 163], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.01092340424656868
bi 1 loss 0.009651045314967632
bi 2 loss 0.08282968401908875
bi 3 loss 0.01086224801838398
Epoch 0: :   3%|▎         | 15650/600000 [04:31<2:48:49, v_num=12, reduced_train_loss=34.60, global_step=15648.0, consumed_samples=62596.0, train_step_timing in s=0.311]Epoch 0: :   3%|▎         | 15650/600000 [04:31<2:48:49, v_num=12, reduced_train_loss=0.178, global_step=15649.0, consumed_samples=62600.0, train_step_timing in s=0.264]loss mask original None

First layer loss:  3.715620279312134 torch.Size([528, 4]) 11.155577659606934 0.0
Max loss timestep torch.Size([528, 4]) tensor([393, 313,  83, 359], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 3.892953634262085
speech mask sum tensor(300, device='cuda:0') loss mask sum tensor(300, device='cuda:0')
bi 1 loss 3.662590265274048
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
bi 2 loss 3.4293220043182373
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 3 loss 3.7759594917297363
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
logits torch.Size([528, 4, 257024]) labels torch.Size([528, 4]) 0 257022
Layer  0  loss:  4.32313346862793 0.0 10.273941993713379
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([340, 405, 155, 364], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 4.746486186981201
bi 1 loss 4.130900859832764
bi 2 loss 4.12120246887207
bi 3 loss 4.148802280426025
Layer  1  loss:  4.664681911468506 0.0 10.32046890258789
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([440, 370,  64, 379], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 4.956279277801514
bi 1 loss 4.620625972747803
bi 2 loss 4.628035068511963
bi 3 loss 4.286127090454102
Layer  2  loss:  4.896407604217529 0.0 10.123828887939453
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([307, 211, 133, 386], device='cuda:0') tensor(430, device='cuda:0')
bi 0 loss 5.329339504241943
bi 1 loss 4.637781143188477
bi 2 loss 4.842883586883545
bi 3 loss 4.693798542022705
Layer  3  loss:  5.080214977264404 0.0 10.288604736328125
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([296, 145, 181, 378], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 5.450428485870361
bi 1 loss 4.833405017852783
bi 2 loss 4.942460536956787
bi 3 loss 5.038968563079834
Layer  4  loss:  5.285138130187988 0.0 10.438470840454102
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([419, 200, 159, 400], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 5.625793933868408
bi 1 loss 5.089574337005615
bi 2 loss 5.1346893310546875
bi 3 loss 5.2100629806518555
Layer  5  loss:  5.256690979003906 0.0 10.906218528747559
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([377, 132, 119, 416], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 5.614731311798096
bi 1 loss 4.960245132446289
bi 2 loss 5.270807266235352
bi 3 loss 5.189618110656738
Layer  6  loss:  5.358251094818115 0.0 10.302279472351074
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([504, 311, 185, 314], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 5.818790912628174
bi 1 loss 5.044804573059082
bi 2 loss 5.218046188354492
bi 3 loss 5.29039192199707
Epoch 0: :   3%|▎         | 15651/600000 [04:31<2:49:02, v_num=12, reduced_train_loss=0.178, global_step=15649.0, consumed_samples=62600.0, train_step_timing in s=0.264]Epoch 0: :   3%|▎         | 15651/600000 [04:31<2:49:02, v_num=12, reduced_train_loss=38.60, global_step=15650.0, consumed_samples=62604.0, train_step_timing in s=0.343]loss mask original None

First layer loss:  0.23418831825256348 torch.Size([558, 4]) 15.41201400756836 0.0
Max loss timestep torch.Size([558, 4]) tensor([395, 481, 531, 294], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.16008155047893524
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 1 loss 0.3370523452758789
speech mask sum tensor(405, device='cuda:0') loss mask sum tensor(405, device='cuda:0')
bi 2 loss 0.20896053314208984
speech mask sum tensor(384, device='cuda:0') loss mask sum tensor(384, device='cuda:0')
bi 3 loss 0.1906900703907013
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
logits torch.Size([558, 4, 257024]) labels torch.Size([558, 4]) 0 257023
Layer  0  loss:  0.29185378551483154 0.0 11.341772079467773
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([395, 480, 322, 404], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.1857164055109024
bi 1 loss 0.40463945269584656
bi 2 loss 0.32466796040534973
bi 3 loss 0.18847858905792236
Layer  1  loss:  0.30233874917030334 0.0 12.650496482849121
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([395, 323, 527, 403], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.21303057670593262
bi 1 loss 0.4093274474143982
bi 2 loss 0.3108782470226288
bi 3 loss 0.22334319353103638
Layer  2  loss:  0.3274935185909271 0.0 15.435413360595703
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([395, 386, 530, 404], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.16718247532844543
bi 1 loss 0.518330454826355
bi 2 loss 0.3005216419696808
bi 3 loss 0.24073997139930725
Layer  3  loss:  0.3247804045677185 0.0 15.445820808410645
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1020
Curr loss timestep torch.Size([558, 4]) tensor([395, 464, 532, 404], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.16115441918373108
bi 1 loss 0.45669788122177124
bi 2 loss 0.35422053933143616
bi 3 loss 0.24802307784557343
Layer  4  loss:  0.38146787881851196 0.0 16.512868881225586
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([395, 480, 530, 378], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.19867072999477386
bi 1 loss 0.5339832305908203
bi 2 loss 0.41451025009155273
bi 3 loss 0.2886740565299988
Layer  5  loss:  0.3358079493045807 0.0 11.688076972961426
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([549, 386, 531, 403], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.16390149295330048
bi 1 loss 0.4368453323841095
bi 2 loss 0.3892728388309479
bi 3 loss 0.27673444151878357
Layer  6  loss:  0.33616408705711365 0.0 16.124711990356445
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([395, 258, 527, 503], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 0.18639054894447327
bi 1 loss 0.42543455958366394
bi 2 loss 0.4212965965270996
bi 3 loss 0.23434588313102722
Epoch 0: :   3%|▎         | 15652/600000 [04:32<2:49:17, v_num=12, reduced_train_loss=38.60, global_step=15650.0, consumed_samples=62604.0, train_step_timing in s=0.343]Epoch 0: :   3%|▎         | 15652/600000 [04:32<2:49:17, v_num=12, reduced_train_loss=2.530, global_step=15651.0, consumed_samples=62608.0, train_step_timing in s=0.376]loss mask original None

First layer loss:  0.0744270607829094 torch.Size([562, 4]) 3.730182647705078 0.0
Max loss timestep torch.Size([562, 4]) tensor([195, 367, 294, 115], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.03905654698610306
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 0.09705417603254318
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 2 loss 0.06552517414093018
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 3 loss 0.038457710295915604
speech mask sum tensor(38, device='cuda:0') loss mask sum tensor(38, device='cuda:0')
logits torch.Size([562, 4, 257024]) labels torch.Size([562, 4]) 0 257023
Layer  0  loss:  0.1092209666967392 0.0 5.297201156616211
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([193, 498, 259, 118], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.05598457530140877
bi 1 loss 0.14933767914772034
bi 2 loss 0.08415400981903076
bi 3 loss 0.11231014877557755
Layer  1  loss:  0.08990691602230072 0.0 4.7033514976501465
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([160, 445, 238, 122], device='cuda:0') tensor(445, device='cuda:0')
bi 0 loss 0.029967987909913063
bi 1 loss 0.13673198223114014
bi 2 loss 0.06547263264656067
bi 3 loss 0.037215132266283035
Layer  2  loss:  0.07824468612670898 0.0 3.094428062438965
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1022
Curr loss timestep torch.Size([562, 4]) tensor([117, 350, 145, 126], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.03479078412055969
bi 1 loss 0.0939498171210289
bi 2 loss 0.08010146021842957
bi 3 loss 0.0278074461966753
Layer  3  loss:  0.09204786270856857 0.0 6.133389472961426
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1021
Curr loss timestep torch.Size([562, 4]) tensor([116, 553, 259, 121], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.03429114818572998
bi 1 loss 0.12221776694059372
bi 2 loss 0.08501135557889938
bi 3 loss 0.026425477117300034
Layer  4  loss:  0.08309544622898102 0.0 7.513980388641357
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1022
Curr loss timestep torch.Size([562, 4]) tensor([147, 367, 413, 108], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.028858399018645287
bi 1 loss 0.10630279034376144
bi 2 loss 0.08174525201320648
bi 3 loss 0.02050304226577282
Layer  5  loss:  0.09737541526556015 0.0 9.153207778930664
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([139, 352, 452, 124], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.02885994128882885
bi 1 loss 0.14357492327690125
bi 2 loss 0.07555902749300003
bi 3 loss 0.050188176333904266
Layer  6  loss:  0.0827312245965004 0.0 3.4945526123046875
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([147, 552, 452, 113], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.04010052978992462
bi 1 loss 0.09943034499883652
bi 2 loss 0.08247978240251541
bi 3 loss 0.04118874669075012
Epoch 0: :   3%|▎         | 15653/600000 [04:32<2:49:32, v_num=12, reduced_train_loss=2.530, global_step=15651.0, consumed_samples=62608.0, train_step_timing in s=0.376]Epoch 0: :   3%|▎         | 15653/600000 [04:32<2:49:32, v_num=12, reduced_train_loss=0.707, global_step=15652.0, consumed_samples=62612.0, train_step_timing in s=0.391]loss mask original None

First layer loss:  0.14603786170482635 torch.Size([611, 4]) 11.078783988952637 0.0
Max loss timestep torch.Size([611, 4]) tensor([338, 107, 355, 513], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.15161581337451935
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 1 loss 0.06256505846977234
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 2 loss 0.2299899458885193
speech mask sum tensor(447, device='cuda:0') loss mask sum tensor(447, device='cuda:0')
bi 3 loss 0.11805658042430878
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
logits torch.Size([611, 4, 257024]) labels torch.Size([611, 4]) 0 257023
Layer  0  loss:  0.1782355159521103 0.0 12.235673904418945
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([328, 238, 332, 312], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.34438246488571167
bi 1 loss 0.0788242369890213
bi 2 loss 0.23862004280090332
bi 3 loss 0.12419523298740387
Layer  1  loss:  0.17153239250183105 0.0 11.073580741882324
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([328, 300, 402, 513], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.30656078457832336
bi 1 loss 0.06555631011724472
bi 2 loss 0.24010084569454193
bi 3 loss 0.12505944073200226
Layer  2  loss:  0.19946716725826263 0.0 19.142702102661133
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([368,  47, 356, 513], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.33225515484809875
bi 1 loss 0.06417272984981537
bi 2 loss 0.28918108344078064
bi 3 loss 0.1522199958562851
Layer  3  loss:  0.2055744081735611 0.0 13.691935539245605
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([328, 289, 356, 594], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.38750025629997253
bi 1 loss 0.0850667804479599
bi 2 loss 0.3150269389152527
bi 3 loss 0.1141098216176033
Layer  4  loss:  0.18312318623065948 0.0 15.444191932678223
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([328,  81, 403, 513], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.3758551776409149
bi 1 loss 0.08206489682197571
bi 2 loss 0.23173266649246216
bi 3 loss 0.13131120800971985
Layer  5  loss:  0.21667490899562836 0.0 17.468839645385742
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([368, 198, 332, 513], device='cuda:0') tensor(332, device='cuda:0')
bi 0 loss 0.33208397030830383
bi 1 loss 0.08587359637022018
bi 2 loss 0.3141588866710663
bi 3 loss 0.16585393249988556
Layer  6  loss:  0.20447860658168793 0.0 14.775911331176758
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1021
Curr loss timestep torch.Size([611, 4]) tensor([368, 316, 402, 402], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.3378836214542389
bi 1 loss 0.07134490460157394
bi 2 loss 0.3160342276096344
bi 3 loss 0.13591130077838898
Epoch 0: :   3%|▎         | 15654/600000 [04:32<2:49:48, v_num=12, reduced_train_loss=0.707, global_step=15652.0, consumed_samples=62612.0, train_step_timing in s=0.391]Epoch 0: :   3%|▎         | 15654/600000 [04:32<2:49:48, v_num=12, reduced_train_loss=1.510, global_step=15653.0, consumed_samples=62616.0, train_step_timing in s=0.415]loss mask original None

First layer loss:  0.17918835580348969 torch.Size([651, 4]) 11.91351318359375 0.0
Max loss timestep torch.Size([651, 4]) tensor([270, 623, 492, 235], device='cuda:0') tensor(492, device='cuda:0')
bi 0 loss 0.06522991508245468
speech mask sum tensor(150, device='cuda:0') loss mask sum tensor(150, device='cuda:0')
bi 1 loss 0.2343115359544754
speech mask sum tensor(476, device='cuda:0') loss mask sum tensor(476, device='cuda:0')
bi 2 loss 0.24658522009849548
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
bi 3 loss 0.05388830974698067
speech mask sum tensor(201, device='cuda:0') loss mask sum tensor(201, device='cuda:0')
logits torch.Size([651, 4, 257024]) labels torch.Size([651, 4]) 0 257022
Layer  0  loss:  0.20143142342567444 0.0 14.172221183776855
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([328, 553, 464, 292], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.08398351073265076
bi 1 loss 0.21748988330364227
bi 2 loss 0.390133261680603
bi 3 loss 0.027612103149294853
Layer  1  loss:  0.2027065008878708 0.0 13.82972526550293
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([292, 553, 465, 274], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.06626446545124054
bi 1 loss 0.2269158512353897
bi 2 loss 0.3532825708389282
bi 3 loss 0.06890323013067245
Layer  2  loss:  0.23234990239143372 0.0 12.001049041748047
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([326, 553, 463, 270], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.06530109792947769
bi 1 loss 0.28867673873901367
bi 2 loss 0.3471928834915161
bi 3 loss 0.08763908594846725
Layer  3  loss:  0.2526955008506775 0.0 19.724740982055664
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([262, 554, 463, 290], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.07686693966388702
bi 1 loss 0.29632100462913513
bi 2 loss 0.44814443588256836
bi 3 loss 0.04917161539196968
Layer  4  loss:  0.2368004471063614 0.0 20.627182006835938
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([329, 554, 463, 290], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.12816081941127777
bi 1 loss 0.29822468757629395
bi 2 loss 0.3350655138492584
bi 3 loss 0.05605882778763771
Layer  5  loss:  0.24023260176181793 0.0 17.472991943359375
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([326, 553, 464, 290], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.08610756695270538
bi 1 loss 0.2898547053337097
bi 2 loss 0.3899233639240265
bi 3 loss 0.060492463409900665
Layer  6  loss:  0.25830894708633423 0.0 20.126550674438477
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([290, 553, 464, 287], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.1129738837480545
bi 1 loss 0.3164030909538269
bi 2 loss 0.39250117540359497
bi 3 loss 0.0702974796295166
Epoch 0: :   3%|▎         | 15655/600000 [04:33<2:50:06, v_num=12, reduced_train_loss=1.510, global_step=15653.0, consumed_samples=62616.0, train_step_timing in s=0.415]Epoch 0: :   3%|▎         | 15655/600000 [04:33<2:50:06, v_num=12, reduced_train_loss=1.800, global_step=15654.0, consumed_samples=62620.0, train_step_timing in s=0.446]loss mask original None

First layer loss:  0.07405222207307816 torch.Size([466, 4]) 8.503756523132324 0.0
Max loss timestep torch.Size([466, 4]) tensor([259, 100, 133, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.033434659242630005
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
bi 1 loss 0.01584945246577263
speech mask sum tensor(47, device='cuda:0') loss mask sum tensor(47, device='cuda:0')
bi 2 loss 0.03073030896484852
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
bi 3 loss 0.13793087005615234
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
logits torch.Size([466, 4, 257024]) labels torch.Size([466, 4]) 0 257023
Layer  0  loss:  0.07693572342395782 0.0 9.587787628173828
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([373, 102, 165, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.03511349484324455
bi 1 loss 0.03305846452713013
bi 2 loss 0.02652319148182869
bi 3 loss 0.1425476372241974
Layer  1  loss:  0.08380526304244995 0.0 10.217961311340332
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([115, 110, 190, 350], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.03459044545888901
bi 1 loss 0.019426308572292328
bi 2 loss 0.02652432769536972
bi 3 loss 0.16210776567459106
Layer  2  loss:  0.07739558815956116 0.0 8.964282989501953
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([268, 105, 142, 350], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.042624786496162415
bi 1 loss 0.01642276532948017
bi 2 loss 0.029920119792222977
bi 3 loss 0.137610524892807
Layer  3  loss:  0.06735377013683319 0.0 7.6745805740356445
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1022
Curr loss timestep torch.Size([466, 4]) tensor([330,  98, 185, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.03620212897658348
bi 1 loss 0.014061268419027328
bi 2 loss 0.03382165729999542
bi 3 loss 0.11772378534078598
Layer  4  loss:  0.07572004199028015 0.0 6.695528984069824
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1021
Curr loss timestep torch.Size([466, 4]) tensor([369, 104, 126, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.03808332234621048
bi 1 loss 0.017081070691347122
bi 2 loss 0.021093878895044327
bi 3 loss 0.14104047417640686
Layer  5  loss:  0.09661732614040375 0.0 14.219274520874023
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1023
Curr loss timestep torch.Size([466, 4]) tensor([358, 114, 130, 352], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.04410615190863609
bi 1 loss 0.014239445328712463
bi 2 loss 0.05348484218120575
bi 3 loss 0.17540383338928223
Layer  6  loss:  0.08873137831687927 0.0 10.719476699829102
logits torch.Size([466, 4, 1024]) labels torch.Size([466, 4]) 0 1019
Curr loss timestep torch.Size([466, 4]) tensor([302, 106, 218, 351], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.03779781237244606
bi 1 loss 0.01103226002305746
bi 2 loss 0.03265560418367386
bi 3 loss 0.17017990350723267
Epoch 0: :   3%|▎         | 15656/600000 [04:33<2:50:19, v_num=12, reduced_train_loss=1.800, global_step=15654.0, consumed_samples=62620.0, train_step_timing in s=0.446]Epoch 0: :   3%|▎         | 15656/600000 [04:33<2:50:19, v_num=12, reduced_train_loss=0.641, global_step=15655.0, consumed_samples=62624.0, train_step_timing in s=0.334]loss mask original None

First layer loss:  3.9115636348724365 torch.Size([604, 4]) 12.102412223815918 0.0
Max loss timestep torch.Size([604, 4]) tensor([259, 253, 235, 161], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 3.527092218399048
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 1 loss 4.015748977661133
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 2 loss 4.063033580780029
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 3 loss 4.063004493713379
speech mask sum tensor(218, device='cuda:0') loss mask sum tensor(218, device='cuda:0')
logits torch.Size([604, 4, 257024]) labels torch.Size([604, 4]) 0 257023
Layer  0  loss:  4.269231796264648 0.0 10.273618698120117
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([130, 436, 169, 275], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 3.802305221557617
bi 1 loss 4.426202774047852
bi 2 loss 4.177239894866943
bi 3 loss 4.548309803009033
Layer  1  loss:  4.807248115539551 0.0 11.434223175048828
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([221, 400, 189, 291], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 4.394127368927002
bi 1 loss 5.061708927154541
bi 2 loss 4.773018836975098
bi 3 loss 4.837896347045898
Layer  2  loss:  4.951509952545166 0.0 10.073022842407227
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([283, 264, 226, 247], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 4.797157287597656
bi 1 loss 4.978798866271973
bi 2 loss 4.818309307098389
bi 3 loss 5.138728618621826
Layer  3  loss:  5.048010349273682 0.0 9.621894836425781
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([291, 431, 238, 253], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 4.734430313110352
bi 1 loss 5.226691246032715
bi 2 loss 4.852675914764404
bi 3 loss 5.184566020965576
Layer  4  loss:  5.2548956871032715 0.0 11.095733642578125
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([164, 371, 224, 203], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 4.976349353790283
bi 1 loss 5.3941731452941895
bi 2 loss 5.071519374847412
bi 3 loss 5.413593769073486
Layer  5  loss:  5.232111930847168 0.0 9.546785354614258
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([313, 429, 201, 270], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 4.97921085357666
bi 1 loss 5.3916707038879395
bi 2 loss 4.997840881347656
bi 3 loss 5.357131481170654
Layer  6  loss:  5.259849548339844 0.0 9.118988037109375
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([196, 257, 201, 201], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 4.970332622528076
bi 1 loss 5.4006829261779785
bi 2 loss 5.076179504394531
bi 3 loss 5.427652835845947
Epoch 0: :   3%|▎         | 15657/600000 [04:34<2:50:34, v_num=12, reduced_train_loss=0.641, global_step=15655.0, consumed_samples=62624.0, train_step_timing in s=0.334]Epoch 0: :   3%|▎         | 15657/600000 [04:34<2:50:34, v_num=12, reduced_train_loss=38.70, global_step=15656.0, consumed_samples=62628.0, train_step_timing in s=0.381]loss mask original None

First layer loss:  3.5819485187530518 torch.Size([740, 4]) 10.547039031982422 0.0
Max loss timestep torch.Size([740, 4]) tensor([356, 236, 142, 422], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 3.968923330307007
speech mask sum tensor(491, device='cuda:0') loss mask sum tensor(491, device='cuda:0')
bi 1 loss 3.4323315620422363
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 2 loss 3.398447275161743
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 3 loss 3.248779773712158
speech mask sum tensor(442, device='cuda:0') loss mask sum tensor(442, device='cuda:0')
logits torch.Size([740, 4, 257024]) labels torch.Size([740, 4]) 0 257023
Layer  0  loss:  4.100067138671875 0.0 11.999567031860352
logits torch.Size([740, 4, 1024]) labels torch.Size([740, 4]) 0 1023
Curr loss timestep torch.Size([740, 4]) tensor([412, 255, 173, 340], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 4.540385723114014
bi 1 loss 4.322859287261963
bi 2 loss 3.5886614322662354
bi 3 loss 3.7545199394226074
Layer  1  loss:  4.430449962615967 0.0 11.739591598510742
logits torch.Size([740, 4, 1024]) labels torch.Size([740, 4]) 0 1023
Curr loss timestep torch.Size([740, 4]) tensor([673, 217,  81, 430], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 4.822572708129883
bi 1 loss 4.5497002601623535
bi 2 loss 3.8757338523864746
bi 3 loss 4.174696445465088
Layer  2  loss:  4.670477867126465 0.0 10.239627838134766
logits torch.Size([740, 4, 1024]) labels torch.Size([740, 4]) 0 1022
Curr loss timestep torch.Size([740, 4]) tensor([697, 250, 143, 149], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 5.043420791625977
bi 1 loss 4.914294719696045
bi 2 loss 4.269162178039551
bi 3 loss 4.355287551879883
Layer  3  loss:  4.726299285888672 0.0 10.53948974609375
logits torch.Size([740, 4, 1024]) labels torch.Size([740, 4]) 0 1022
Curr loss timestep torch.Size([740, 4]) tensor([366, 266, 194, 369], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 5.214935302734375
bi 1 loss 4.878211498260498
bi 2 loss 4.087385177612305
bi 3 loss 4.387764930725098
Layer  4  loss:  4.924742698669434 0.0 12.062037467956543
logits torch.Size([740, 4, 1024]) labels torch.Size([740, 4]) 0 1023
Curr loss timestep torch.Size([740, 4]) tensor([314, 228, 145, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 5.3192362785339355
bi 1 loss 4.977275848388672
bi 2 loss 4.375192165374756
bi 3 loss 4.67759370803833
Layer  5  loss:  4.895701885223389 0.0 11.304494857788086
logits torch.Size([740, 4, 1024]) labels torch.Size([740, 4]) 0 1020
Curr loss timestep torch.Size([740, 4]) tensor([653, 255, 170,  85], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 5.266363620758057
bi 1 loss 5.112197399139404
bi 2 loss 4.422977924346924
bi 3 loss 4.614597320556641
Layer  6  loss:  5.0111775398254395 0.0 10.77593994140625
logits torch.Size([740, 4, 1024]) labels torch.Size([740, 4]) 0 1021
Curr loss timestep torch.Size([740, 4]) tensor([314, 280, 146, 464], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 5.3256378173828125
bi 1 loss 5.35245418548584
bi 2 loss 4.527341365814209
bi 3 loss 4.772015571594238
Epoch 0: :   3%|▎         | 15658/600000 [04:34<2:50:51, v_num=12, reduced_train_loss=38.70, global_step=15656.0, consumed_samples=62628.0, train_step_timing in s=0.381]Epoch 0: :   3%|▎         | 15658/600000 [04:34<2:50:51, v_num=12, reduced_train_loss=36.30, global_step=15657.0, consumed_samples=62632.0, train_step_timing in s=0.440]loss mask original None

First layer loss:  0.046771273016929626 torch.Size([451, 4]) 6.999734878540039 0.0
Max loss timestep torch.Size([451, 4]) tensor([ 54, 292, 359, 307], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.02476908266544342
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
bi 1 loss 0.11788304895162582
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 2 loss 0.040458790957927704
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
bi 3 loss 0.03289765864610672
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
logits torch.Size([451, 4, 257024]) labels torch.Size([451, 4]) 0 257022
Layer  0  loss:  0.048632510006427765 0.0 8.063443183898926
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([231, 292, 262, 186], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.02295711077749729
bi 1 loss 0.11715942621231079
bi 2 loss 0.055349089205265045
bi 3 loss 0.025278640910983086
Layer  1  loss:  0.04553725942969322 0.0 4.387740135192871
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1022
Curr loss timestep torch.Size([451, 4]) tensor([197, 292, 269, 309], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.027548840269446373
bi 1 loss 0.10207737237215042
bi 2 loss 0.041120193898677826
bi 3 loss 0.03433971479535103
Layer  2  loss:  0.049853019416332245 0.0 7.342850208282471
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1022
Curr loss timestep torch.Size([451, 4]) tensor([ 42, 291, 262, 271], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.026124075055122375
bi 1 loss 0.13533267378807068
bi 2 loss 0.041523851454257965
bi 3 loss 0.031136196106672287
Layer  3  loss:  0.044910088181495667 0.0 5.29062032699585
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1021
Curr loss timestep torch.Size([451, 4]) tensor([ 44, 291, 338, 149], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.02494366094470024
bi 1 loss 0.11525064706802368
bi 2 loss 0.04083496704697609
bi 3 loss 0.026775112375617027
Layer  4  loss:  0.0502130351960659 0.0 7.818948268890381
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([129, 290, 404, 144], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.022671876475214958
bi 1 loss 0.1566588580608368
bi 2 loss 0.042303238064050674
bi 3 loss 0.021931122988462448
Layer  5  loss:  0.049894820898771286 0.0 7.6575798988342285
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1022
Curr loss timestep torch.Size([451, 4]) tensor([ 62, 290, 262, 287], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.02340524271130562
bi 1 loss 0.13994675874710083
bi 2 loss 0.03700801357626915
bi 3 loss 0.036501891911029816
Layer  6  loss:  0.05840538442134857 0.0 10.866190910339355
logits torch.Size([451, 4, 1024]) labels torch.Size([451, 4]) 0 1023
Curr loss timestep torch.Size([451, 4]) tensor([247, 292, 391, 254], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.024872280657291412
bi 1 loss 0.18734057247638702
bi 2 loss 0.03628323972225189
bi 3 loss 0.03878096118569374
Epoch 0: :   3%|▎         | 15659/600000 [04:35<2:51:04, v_num=12, reduced_train_loss=36.30, global_step=15657.0, consumed_samples=62632.0, train_step_timing in s=0.440]Epoch 0: :   3%|▎         | 15659/600000 [04:35<2:51:04, v_num=12, reduced_train_loss=0.394, global_step=15658.0, consumed_samples=62636.0, train_step_timing in s=0.326]loss mask original None

First layer loss:  0.1142241582274437 torch.Size([718, 4]) 10.43970012664795 0.0
Max loss timestep torch.Size([718, 4]) tensor([658, 217, 462, 227], device='cuda:0') tensor(462, device='cuda:0')
bi 0 loss 0.14788995683193207
speech mask sum tensor(438, device='cuda:0') loss mask sum tensor(438, device='cuda:0')
bi 1 loss 0.057964060455560684
speech mask sum tensor(125, device='cuda:0') loss mask sum tensor(125, device='cuda:0')
bi 2 loss 0.19176456332206726
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
bi 3 loss 0.03465196117758751
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
logits torch.Size([718, 4, 257024]) labels torch.Size([718, 4]) 0 257022
Layer  0  loss:  0.18109440803527832 0.0 11.765440940856934
logits torch.Size([718, 4, 1024]) labels torch.Size([718, 4]) 0 1023
Curr loss timestep torch.Size([718, 4]) tensor([658, 245, 464,  91], device='cuda:0') tensor(658, device='cuda:0')
bi 0 loss 0.2469719797372818
bi 1 loss 0.1464584618806839
bi 2 loss 0.23120318353176117
bi 3 loss 0.050561487674713135
Layer  1  loss:  0.18043728172779083 0.0 9.72955322265625
logits torch.Size([718, 4, 1024]) labels torch.Size([718, 4]) 0 1022
Curr loss timestep torch.Size([718, 4]) tensor([473, 263, 464, 173], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.25314459204673767
bi 1 loss 0.07145433127880096
bi 2 loss 0.24100123345851898
bi 3 loss 0.06889966130256653
Layer  2  loss:  0.21427837014198303 0.0 13.57969856262207
logits torch.Size([718, 4, 1024]) labels torch.Size([718, 4]) 0 1022
Curr loss timestep torch.Size([718, 4]) tensor([640, 214, 462, 275], device='cuda:0') tensor(640, device='cuda:0')
bi 0 loss 0.35158127546310425
bi 1 loss 0.08013664186000824
bi 2 loss 0.2051077038049698
bi 3 loss 0.044405270367860794
Layer  3  loss:  0.22983495891094208 0.0 16.1125545501709
logits torch.Size([718, 4, 1024]) labels torch.Size([718, 4]) 0 1023
Curr loss timestep torch.Size([718, 4]) tensor([658, 291, 463, 159], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.35256722569465637
bi 1 loss 0.09034234285354614
bi 2 loss 0.24816101789474487
bi 3 loss 0.07136387377977371
Layer  4  loss:  0.203861266374588 0.0 9.848618507385254
logits torch.Size([718, 4, 1024]) labels torch.Size([718, 4]) 0 1023
Curr loss timestep torch.Size([718, 4]) tensor([636, 265, 464, 135], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.2929379642009735
bi 1 loss 0.10811317712068558
bi 2 loss 0.27492743730545044
bi 3 loss 0.05005049705505371
Layer  5  loss:  0.19321982562541962 0.0 9.908638000488281
logits torch.Size([718, 4, 1024]) labels torch.Size([718, 4]) 0 1022
Curr loss timestep torch.Size([718, 4]) tensor([640, 265, 462, 269], device='cuda:0') tensor(462, device='cuda:0')
bi 0 loss 0.27957800030708313
bi 1 loss 0.10681993514299393
bi 2 loss 0.2435416728258133
bi 3 loss 0.05243254080414772
Layer  6  loss:  0.19990214705467224 0.0 11.024567604064941
logits torch.Size([718, 4, 1024]) labels torch.Size([718, 4]) 0 1019
Curr loss timestep torch.Size([718, 4]) tensor([658, 265, 462, 138], device='cuda:0') tensor(658, device='cuda:0')
bi 0 loss 0.2824537456035614
bi 1 loss 0.0900602638721466
bi 2 loss 0.31464335322380066
bi 3 loss 0.03756404295563698
Epoch 0: :   3%|▎         | 15660/600000 [04:35<2:51:23, v_num=12, reduced_train_loss=0.394, global_step=15658.0, consumed_samples=62636.0, train_step_timing in s=0.326]Epoch 0: :   3%|▎         | 15660/600000 [04:35<2:51:23, v_num=12, reduced_train_loss=1.520, global_step=15659.0, consumed_samples=62640.0, train_step_timing in s=0.489]loss mask original None

First layer loss:  0.026799891144037247 torch.Size([430, 4]) 0.8469443321228027 0.0
Max loss timestep torch.Size([430, 4]) tensor([134, 347, 265, 114], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.027697326615452766
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
bi 1 loss 0.036491334438323975
speech mask sum tensor(348, device='cuda:0') loss mask sum tensor(348, device='cuda:0')
bi 2 loss 0.018298732116818428
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
bi 3 loss 0.012028434313833714
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
logits torch.Size([430, 4, 257024]) labels torch.Size([430, 4]) 0 257023
Layer  0  loss:  0.02555236592888832 0.0 0.4824707508087158
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1023
Curr loss timestep torch.Size([430, 4]) tensor([300, 303, 260, 105], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.0238704401999712
bi 1 loss 0.03222839906811714
bi 2 loss 0.022137349471449852
bi 3 loss 0.016224252060055733
Layer  1  loss:  0.023813949897885323 0.0 1.770519733428955
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1022
Curr loss timestep torch.Size([430, 4]) tensor([139, 260, 155, 146], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.019505739212036133
bi 1 loss 0.03606819733977318
bi 2 loss 0.01795489527285099
bi 3 loss 0.009181668050587177
Layer  2  loss:  0.02319910377264023 0.0 0.6739044189453125
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1023
Curr loss timestep torch.Size([430, 4]) tensor([223, 286,  62, 155], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.029647666960954666
bi 1 loss 0.024755630642175674
bi 2 loss 0.018150195479393005
bi 3 loss 0.011582053266465664
Layer  3  loss:  0.02362450212240219 0.0 1.7828267812728882
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1021
Curr loss timestep torch.Size([430, 4]) tensor([ 89, 261,  82, 161], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.023408953100442886
bi 1 loss 0.03211010619997978
bi 2 loss 0.01683616265654564
bi 3 loss 0.011998078785836697
Layer  4  loss:  0.02446800470352173 0.0 0.4954347610473633
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1022
Curr loss timestep torch.Size([430, 4]) tensor([143, 362, 246, 123], device='cuda:0') tensor(143, device='cuda:0')
bi 0 loss 0.024082746356725693
bi 1 loss 0.0310018602758646
bi 2 loss 0.01945292390882969
bi 3 loss 0.01564444974064827
Layer  5  loss:  0.025171853601932526 0.0 1.4552297592163086
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1019
Curr loss timestep torch.Size([430, 4]) tensor([306, 260, 241, 121], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.025589141994714737
bi 1 loss 0.02890944667160511
bi 2 loss 0.022389568388462067
bi 3 loss 0.018132641911506653
Layer  6  loss:  0.02789025567471981 0.0 1.808877944946289
logits torch.Size([430, 4, 1024]) labels torch.Size([430, 4]) 0 1022
Curr loss timestep torch.Size([430, 4]) tensor([ 62, 260, 264, 153], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.026726849377155304
bi 1 loss 0.03789745271205902
bi 2 loss 0.023025495931506157
bi 3 loss 0.009505277499556541
Epoch 0: :   3%|▎         | 15661/600000 [04:35<2:51:35, v_num=12, reduced_train_loss=1.520, global_step=15659.0, consumed_samples=62640.0, train_step_timing in s=0.489]Epoch 0: :   3%|▎         | 15661/600000 [04:35<2:51:35, v_num=12, reduced_train_loss=0.201, global_step=15660.0, consumed_samples=62644.0, train_step_timing in s=0.315]loss mask original None

First layer loss:  0.14050130546092987 torch.Size([575, 4]) 12.546289443969727 0.0
Max loss timestep torch.Size([575, 4]) tensor([519, 275, 413, 198], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.2621486783027649
speech mask sum tensor(434, device='cuda:0') loss mask sum tensor(434, device='cuda:0')
bi 1 loss 0.051257163286209106
speech mask sum tensor(204, device='cuda:0') loss mask sum tensor(204, device='cuda:0')
bi 2 loss 0.07811392843723297
speech mask sum tensor(398, device='cuda:0') loss mask sum tensor(398, device='cuda:0')
bi 3 loss 0.04755862057209015
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
logits torch.Size([575, 4, 257024]) labels torch.Size([575, 4]) 0 257022
Layer  0  loss:  0.1342822164297104 0.0 11.250042915344238
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([517, 108, 410, 175], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.24500955641269684
bi 1 loss 0.06079435348510742
bi 2 loss 0.07663052529096603
bi 3 loss 0.037912990897893906
Layer  1  loss:  0.17937983572483063 0.0 13.847928047180176
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([541, 180, 273, 177], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.32528844475746155
bi 1 loss 0.036741986870765686
bi 2 loss 0.13144466280937195
bi 3 loss 0.035113003104925156
Layer  2  loss:  0.15245957672595978 0.0 10.604456901550293
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([516, 104, 273, 159], device='cuda:0') tensor(516, device='cuda:0')
bi 0 loss 0.2925887107849121
bi 1 loss 0.04190034419298172
bi 2 loss 0.08967211842536926
bi 3 loss 0.026054322719573975
Layer  3  loss:  0.15773391723632812 0.0 11.266561508178711
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([541,  96, 410, 159], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.28084099292755127
bi 1 loss 0.0770651325583458
bi 2 loss 0.09232853353023529
bi 3 loss 0.05353669822216034
Layer  4  loss:  0.1802293211221695 0.0 13.854702949523926
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([517, 281, 465, 166], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.3739388585090637
bi 1 loss 0.04135052487254143
bi 2 loss 0.07968804985284805
bi 3 loss 0.030484085902571678
Layer  5  loss:  0.1735679656267166 0.0 9.438560485839844
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([520, 281, 273, 174], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.2933315932750702
bi 1 loss 0.06788324564695358
bi 2 loss 0.12436944991350174
bi 3 loss 0.07036106288433075
Layer  6  loss:  0.15817411243915558 0.0 10.948785781860352
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([520, 280, 432, 202], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.2841193974018097
bi 1 loss 0.05706954374909401
bi 2 loss 0.10812047868967056
bi 3 loss 0.023759083822369576
Epoch 0: :   3%|▎         | 15662/600000 [04:36<2:51:51, v_num=12, reduced_train_loss=0.201, global_step=15660.0, consumed_samples=62644.0, train_step_timing in s=0.315]Epoch 0: :   3%|▎         | 15662/600000 [04:36<2:51:51, v_num=12, reduced_train_loss=1.280, global_step=15661.0, consumed_samples=62648.0, train_step_timing in s=0.399]loss mask original None

First layer loss:  0.03552907705307007 torch.Size([369, 4]) 2.775632858276367 0.0
Max loss timestep torch.Size([369, 4]) tensor([147, 289, 311, 294], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 0.022429602220654488
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 1 loss 0.04207275062799454
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 2 loss 0.019418561831116676
speech mask sum tensor(245, device='cuda:0') loss mask sum tensor(245, device='cuda:0')
bi 3 loss 0.05917126312851906
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
logits torch.Size([369, 4, 257024]) labels torch.Size([369, 4]) 0 257022
Layer  0  loss:  0.04662880674004555 0.0 5.343386650085449
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([189, 257, 324, 297], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.02875487320125103
bi 1 loss 0.06314242631196976
bi 2 loss 0.04528013616800308
bi 3 loss 0.04890371114015579
Layer  1  loss:  0.0372520387172699 0.0 3.654308319091797
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([221, 338, 311, 294], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 0.0156273003667593
bi 1 loss 0.04900013655424118
bi 2 loss 0.022622473537921906
bi 3 loss 0.06120568886399269
Layer  2  loss:  0.055725619196891785 0.0 5.387058258056641
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1022
Curr loss timestep torch.Size([369, 4]) tensor([185, 257, 311, 295], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.0326567143201828
bi 1 loss 0.07754573225975037
bi 2 loss 0.04916100949048996
bi 3 loss 0.06414413452148438
Layer  3  loss:  0.03933538496494293 0.0 2.9000682830810547
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1022
Curr loss timestep torch.Size([369, 4]) tensor([131, 257, 311, 297], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.01946728304028511
bi 1 loss 0.05298043414950371
bi 2 loss 0.04198480769991875
bi 3 loss 0.04001334309577942
Layer  4  loss:  0.04766560345888138 0.0 6.496472358703613
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1022
Curr loss timestep torch.Size([369, 4]) tensor([127, 265, 311, 297], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.02701224386692047
bi 1 loss 0.03200777247548103
bi 2 loss 0.053020089864730835
bi 3 loss 0.06522476673126221
Layer  5  loss:  0.04204452037811279 0.0 2.4155194759368896
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([215, 263, 311, 297], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.028206147253513336
bi 1 loss 0.04008244723081589
bi 2 loss 0.030584020540118217
bi 3 loss 0.06625716388225555
Layer  6  loss:  0.058766353875398636 0.0 4.698260307312012
logits torch.Size([369, 4, 1024]) labels torch.Size([369, 4]) 0 1023
Curr loss timestep torch.Size([369, 4]) tensor([218, 257, 311, 295], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.03499563783407211
bi 1 loss 0.04815516620874405
bi 2 loss 0.046315934509038925
bi 3 loss 0.09647560864686966
Epoch 0: :   3%|▎         | 15663/600000 [04:36<2:52:02, v_num=12, reduced_train_loss=1.280, global_step=15661.0, consumed_samples=62648.0, train_step_timing in s=0.399]Epoch 0: :   3%|▎         | 15663/600000 [04:36<2:52:02, v_num=12, reduced_train_loss=0.363, global_step=15662.0, consumed_samples=62652.0, train_step_timing in s=0.285]loss mask original None

First layer loss:  0.09776055812835693 torch.Size([606, 4]) 12.259281158447266 0.0
Max loss timestep torch.Size([606, 4]) tensor([249, 594, 411, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.07108385860919952
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 1 loss 0.10764896124601364
speech mask sum tensor(401, device='cuda:0') loss mask sum tensor(401, device='cuda:0')
bi 2 loss 0.08925153315067291
speech mask sum tensor(425, device='cuda:0') loss mask sum tensor(425, device='cuda:0')
bi 3 loss 0.1062556728720665
speech mask sum tensor(386, device='cuda:0') loss mask sum tensor(386, device='cuda:0')
logits torch.Size([606, 4, 257024]) labels torch.Size([606, 4]) 0 257022
Layer  0  loss:  0.12901534140110016 0.0 8.743620872497559
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([264, 589, 411, 260], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.05713776871562004
bi 1 loss 0.17621298134326935
bi 2 loss 0.12584325671195984
bi 3 loss 0.1088009774684906
Layer  1  loss:  0.12728162109851837 0.0 12.1254243850708
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1022
Curr loss timestep torch.Size([606, 4]) tensor([253, 594, 410, 261], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.06072676181793213
bi 1 loss 0.15816248953342438
bi 2 loss 0.15777026116847992
bi 3 loss 0.08508101105690002
Layer  2  loss:  0.14326688647270203 0.0 18.612550735473633
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1022
Curr loss timestep torch.Size([606, 4]) tensor([256, 594, 411, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.07480325549840927
bi 1 loss 0.1654796451330185
bi 2 loss 0.17019638419151306
bi 3 loss 0.11466249823570251
Layer  3  loss:  0.14357928931713104 0.0 14.67715835571289
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([263, 594, 411, 260], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.05896206572651863
bi 1 loss 0.17756769061088562
bi 2 loss 0.15339122712612152
bi 3 loss 0.1272801160812378
Layer  4  loss:  0.1420518308877945 0.0 15.980721473693848
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1022
Curr loss timestep torch.Size([606, 4]) tensor([238, 594, 411, 260], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.06561532616615295
bi 1 loss 0.15917423367500305
bi 2 loss 0.1534452736377716
bi 3 loss 0.13865044713020325
Layer  5  loss:  0.15315157175064087 0.0 13.336750030517578
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([216, 594, 411, 260], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.049916014075279236
bi 1 loss 0.1926773488521576
bi 2 loss 0.17033453285694122
bi 3 loss 0.12954387068748474
Layer  6  loss:  0.14743761718273163 0.0 10.42235279083252
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1021
Curr loss timestep torch.Size([606, 4]) tensor([223, 594, 411, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.09344428777694702
bi 1 loss 0.17233765125274658
bi 2 loss 0.13457249104976654
bi 3 loss 0.1547584980726242
Epoch 0: :   3%|▎         | 15664/600000 [04:37<2:52:18, v_num=12, reduced_train_loss=0.363, global_step=15662.0, consumed_samples=62652.0, train_step_timing in s=0.285]Epoch 0: :   3%|▎         | 15664/600000 [04:37<2:52:18, v_num=12, reduced_train_loss=1.080, global_step=15663.0, consumed_samples=62656.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.07428363710641861 torch.Size([465, 4]) 8.36433219909668 0.0
Max loss timestep torch.Size([465, 4]) tensor([381, 292, 220,  56], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 0.08943291753530502
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 1 loss 0.051531512290239334
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
bi 2 loss 0.08015816658735275
speech mask sum tensor(340, device='cuda:0') loss mask sum tensor(340, device='cuda:0')
bi 3 loss 0.03043309412896633
speech mask sum tensor(53, device='cuda:0') loss mask sum tensor(53, device='cuda:0')
logits torch.Size([465, 4, 257024]) labels torch.Size([465, 4]) 0 257022
Layer  0  loss:  0.06960205733776093 0.0 7.357683181762695
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([381, 292, 340,  60], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.06751494854688644
bi 1 loss 0.0559362955391407
bi 2 loss 0.08676032721996307
bi 3 loss 0.03392035886645317
Layer  1  loss:  0.0670652911067009 0.0 5.824850082397461
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([381, 292, 340,  42], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.06741965562105179
bi 1 loss 0.06563860177993774
bi 2 loss 0.07428750395774841
bi 3 loss 0.02450537495315075
Layer  2  loss:  0.07095100730657578 0.0 11.003982543945312
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([381, 292, 200,  53], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.0811135545372963
bi 1 loss 0.07311433553695679
bi 2 loss 0.06768161803483963
bi 3 loss 0.011508647352457047
Layer  3  loss:  0.07712289690971375 0.0 7.065778732299805
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([381, 128, 340,  64], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.0848456621170044
bi 1 loss 0.04846193641424179
bi 2 loss 0.09692706167697906
bi 3 loss 0.021623067557811737
Layer  4  loss:  0.07121310383081436 0.0 8.194348335266113
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1021
Curr loss timestep torch.Size([465, 4]) tensor([381, 292, 371,  67], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.06833282858133316
bi 1 loss 0.08063711225986481
bi 2 loss 0.07657250016927719
bi 3 loss 0.015687555074691772
Layer  5  loss:  0.0755510926246643 0.0 10.06960678100586
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1021
Curr loss timestep torch.Size([465, 4]) tensor([381, 296, 340,  67], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.07308503985404968
bi 1 loss 0.04526713863015175
bi 2 loss 0.1066732257604599
bi 3 loss 0.02567909099161625
Layer  6  loss:  0.050141241401433945 0.0 2.0938100814819336
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([381, 292, 350,  42], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 0.035194650292396545
bi 1 loss 0.0457335002720356
bi 2 loss 0.07336588203907013
bi 3 loss 0.024791304022073746
Epoch 0: :   3%|▎         | 15665/600000 [04:37<2:52:32, v_num=12, reduced_train_loss=1.080, global_step=15663.0, consumed_samples=62656.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15665/600000 [04:37<2:52:32, v_num=12, reduced_train_loss=0.556, global_step=15664.0, consumed_samples=62660.0, train_step_timing in s=0.335]loss mask original None

First layer loss:  0.04606031998991966 torch.Size([511, 4]) 2.170027256011963 0.0
Max loss timestep torch.Size([511, 4]) tensor([411, 212, 173, 228], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.04710618406534195
speech mask sum tensor(444, device='cuda:0') loss mask sum tensor(444, device='cuda:0')
bi 1 loss 0.053013939410448074
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
bi 2 loss 0.04888326674699783
speech mask sum tensor(83, device='cuda:0') loss mask sum tensor(83, device='cuda:0')
bi 3 loss 0.029013153165578842
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
logits torch.Size([511, 4, 257024]) labels torch.Size([511, 4]) 0 257022
Layer  0  loss:  0.04469652473926544 0.0 1.305140495300293
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1023
Curr loss timestep torch.Size([511, 4]) tensor([479, 329, 168, 171], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.04878900572657585
bi 1 loss 0.05348406359553337
bi 2 loss 0.027712954208254814
bi 3 loss 0.026432741433382034
Layer  1  loss:  0.05127708613872528 0.0 4.1285719871521
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1021
Curr loss timestep torch.Size([511, 4]) tensor([458, 281, 185, 175], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.04947726055979729
bi 1 loss 0.0717419907450676
bi 2 loss 0.02474858984351158
bi 3 loss 0.035983551293611526
Layer  2  loss:  0.04867570102214813 0.0 2.796022891998291
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1023
Curr loss timestep torch.Size([511, 4]) tensor([295, 281, 155, 201], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.05166616663336754
bi 1 loss 0.0646500363945961
bi 2 loss 0.02402532286942005
bi 3 loss 0.025536108762025833
Layer  3  loss:  0.05940735340118408 0.0 4.765305995941162
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1022
Curr loss timestep torch.Size([511, 4]) tensor([476, 278, 178, 163], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.05681541934609413
bi 1 loss 0.08582121878862381
bi 2 loss 0.02544846385717392
bi 3 loss 0.04033059999346733
Layer  4  loss:  0.05976434797048569 0.0 5.119391918182373
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1022
Curr loss timestep torch.Size([511, 4]) tensor([258, 281, 189, 165], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.06197163462638855
bi 1 loss 0.08374045044183731
bi 2 loss 0.03482254594564438
bi 3 loss 0.025117628276348114
Layer  5  loss:  0.0681489109992981 0.0 6.38582181930542
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1022
Curr loss timestep torch.Size([511, 4]) tensor([260, 278, 163, 166], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.07053980231285095
bi 1 loss 0.08695072680711746
bi 2 loss 0.03196823224425316
bi 3 loss 0.04847284033894539
Layer  6  loss:  0.05424787104129791 0.0 1.8781449794769287
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1023
Curr loss timestep torch.Size([511, 4]) tensor([416, 323, 175, 161], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.0678703561425209
bi 1 loss 0.04826206713914871
bi 2 loss 0.03251608833670616
bi 3 loss 0.03550119698047638
Epoch 0: :   3%|▎         | 15666/600000 [04:37<2:52:46, v_num=12, reduced_train_loss=0.556, global_step=15664.0, consumed_samples=62660.0, train_step_timing in s=0.335]Epoch 0: :   3%|▎         | 15666/600000 [04:37<2:52:46, v_num=12, reduced_train_loss=0.432, global_step=15665.0, consumed_samples=62664.0, train_step_timing in s=0.359]loss mask original None

First layer loss:  0.05481993779540062 torch.Size([541, 4]) 12.04855728149414 0.0
Max loss timestep torch.Size([541, 4]) tensor([361, 167, 143, 128], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.08597481995820999
speech mask sum tensor(363, device='cuda:0') loss mask sum tensor(363, device='cuda:0')
bi 1 loss 0.01136778760701418
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 2 loss 0.03172256052494049
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 3 loss 0.02309112623333931
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
logits torch.Size([541, 4, 257024]) labels torch.Size([541, 4]) 0 257022
Layer  0  loss:  0.04302046820521355 0.0 4.07876443862915
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([361, 178, 175, 245], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.0645156130194664
bi 1 loss 0.014087202958762646
bi 2 loss 0.03158453851938248
bi 3 loss 0.018117696046829224
Layer  1  loss:  0.05065610259771347 0.0 6.522676944732666
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([360, 222, 151, 178], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.07954924553632736
bi 1 loss 0.008847829885780811
bi 2 loss 0.04224447160959244
bi 3 loss 0.015167677775025368
Layer  2  loss:  0.041576236486434937 0.0 5.331387042999268
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([361, 220, 138, 180], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.06127879396080971
bi 1 loss 0.00810436811298132
bi 2 loss 0.036435745656490326
bi 3 loss 0.01995062083005905
Layer  3  loss:  0.05360054969787598 0.0 5.907440185546875
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1021
Curr loss timestep torch.Size([541, 4]) tensor([361, 228, 154, 264], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.08290503174066544
bi 1 loss 0.009240199811756611
bi 2 loss 0.040296122431755066
bi 3 loss 0.02129497192800045
Layer  4  loss:  0.052287258207798004 0.0 5.139376163482666
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([361, 193, 175, 264], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.08384930342435837
bi 1 loss 0.009396993555128574
bi 2 loss 0.018934620544314384
bi 3 loss 0.024797871708869934
Layer  5  loss:  0.031581632792949677 0.0 4.161750316619873
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1021
Curr loss timestep torch.Size([541, 4]) tensor([361, 223, 153, 133], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.041949328035116196
bi 1 loss 0.015507903881371021
bi 2 loss 0.03287441283464432
bi 3 loss 0.01717095449566841
Layer  6  loss:  0.04675377160310745 0.0 5.236837387084961
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([361, 189, 174, 158], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.07079017907381058
bi 1 loss 0.016602948307991028
bi 2 loss 0.024258684366941452
bi 3 loss 0.02280399762094021
Epoch 0: :   3%|▎         | 15667/600000 [04:38<2:53:00, v_num=12, reduced_train_loss=0.432, global_step=15665.0, consumed_samples=62664.0, train_step_timing in s=0.359]Epoch 0: :   3%|▎         | 15667/600000 [04:38<2:53:00, v_num=12, reduced_train_loss=0.374, global_step=15666.0, consumed_samples=62668.0, train_step_timing in s=0.374]loss mask original None

First layer loss:  0.09948179125785828 torch.Size([593, 4]) 8.526289939880371 0.0
Max loss timestep torch.Size([593, 4]) tensor([528, 267, 194, 297], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 0.15323969721794128
speech mask sum tensor(452, device='cuda:0') loss mask sum tensor(452, device='cuda:0')
bi 1 loss 0.03499125316739082
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 2 loss 0.03252837434411049
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 3 loss 0.08404770493507385
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
logits torch.Size([593, 4, 257024]) labels torch.Size([593, 4]) 0 257023
Layer  0  loss:  0.1197487860918045 0.0 11.528074264526367
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([528, 271, 195, 260], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 0.1913686841726303
bi 1 loss 0.03685295954346657
bi 2 loss 0.018757382407784462
bi 3 loss 0.09859134256839752
Layer  1  loss:  0.14862175285816193 0.0 15.256477355957031
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1022
Curr loss timestep torch.Size([593, 4]) tensor([528, 149, 178, 327], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 0.24564404785633087
bi 1 loss 0.03861827775835991
bi 2 loss 0.015104612335562706
bi 3 loss 0.11671412736177444
Layer  2  loss:  0.13347142934799194 0.0 10.220574378967285
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([260, 248, 178, 297], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.21951590478420258
bi 1 loss 0.04580561816692352
bi 2 loss 0.015945743769407272
bi 3 loss 0.09421930462121964
Layer  3  loss:  0.14921723306179047 0.0 15.497498512268066
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1022
Curr loss timestep torch.Size([593, 4]) tensor([260, 267, 173, 327], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.21507276594638824
bi 1 loss 0.06275449693202972
bi 2 loss 0.027654148638248444
bi 3 loss 0.14744339883327484
Layer  4  loss:  0.1335005760192871 0.0 12.079907417297363
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([260,  79, 174, 327], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.19474896788597107
bi 1 loss 0.044017963111400604
bi 2 loss 0.01722799986600876
bi 3 loss 0.14244318008422852
Layer  5  loss:  0.14557723701000214 0.0 9.650385856628418
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1023
Curr loss timestep torch.Size([593, 4]) tensor([528, 130, 192, 297], device='cuda:0') tensor(528, device='cuda:0')
bi 0 loss 0.2232016623020172
bi 1 loss 0.0464523620903492
bi 2 loss 0.02887437865138054
bi 3 loss 0.13438692688941956
Layer  6  loss:  0.13972388207912445 0.0 9.550979614257812
logits torch.Size([593, 4, 1024]) labels torch.Size([593, 4]) 0 1022
Curr loss timestep torch.Size([593, 4]) tensor([260, 250, 184, 297], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.20892593264579773
bi 1 loss 0.03324437513947487
bi 2 loss 0.018299847841262817
bi 3 loss 0.15340280532836914
Epoch 0: :   3%|▎         | 15668/600000 [04:38<2:53:16, v_num=12, reduced_train_loss=0.374, global_step=15666.0, consumed_samples=62668.0, train_step_timing in s=0.374]Epoch 0: :   3%|▎         | 15668/600000 [04:38<2:53:16, v_num=12, reduced_train_loss=1.070, global_step=15667.0, consumed_samples=62672.0, train_step_timing in s=0.411]loss mask original None

First layer loss:  0.06591294705867767 torch.Size([587, 4]) 10.131534576416016 0.0
Max loss timestep torch.Size([587, 4]) tensor([164,  73, 188, 546], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.03114192932844162
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 1 loss 0.026090355589985847
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 2 loss 0.037872057408094406
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 3 loss 0.10596900433301926
speech mask sum tensor(440, device='cuda:0') loss mask sum tensor(440, device='cuda:0')
logits torch.Size([587, 4, 257024]) labels torch.Size([587, 4]) 0 257023
Layer  0  loss:  0.08282198756933212 0.0 9.990616798400879
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([233, 208, 208, 546], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.031872231513261795
bi 1 loss 0.030610058456659317
bi 2 loss 0.033546656370162964
bi 3 loss 0.14153006672859192
Layer  1  loss:  0.08796977251768112 0.0 9.714751243591309
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([242,  63, 149, 547], device='cuda:0') tensor(547, device='cuda:0')
bi 0 loss 0.0511837899684906
bi 1 loss 0.03141454979777336
bi 2 loss 0.04164208471775055
bi 3 loss 0.14279597997665405
Layer  2  loss:  0.09900925308465958 0.0 9.569499015808105
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1022
Curr loss timestep torch.Size([587, 4]) tensor([188,  90, 184, 547], device='cuda:0') tensor(547, device='cuda:0')
bi 0 loss 0.028148075565695763
bi 1 loss 0.039650287479162216
bi 2 loss 0.03331785276532173
bi 3 loss 0.17355628311634064
Layer  3  loss:  0.0823427364230156 0.0 7.4510884284973145
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1021
Curr loss timestep torch.Size([587, 4]) tensor([232,  69, 198, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.03536467254161835
bi 1 loss 0.050702814012765884
bi 2 loss 0.03221476450562477
bi 3 loss 0.1304931342601776
Layer  4  loss:  0.10297774523496628 0.0 17.82100486755371
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([242, 100, 114, 546], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.04461667314171791
bi 1 loss 0.031034089624881744
bi 2 loss 0.04809834063053131
bi 3 loss 0.17528149485588074
Layer  5  loss:  0.12851323187351227 0.0 12.275861740112305
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1022
Curr loss timestep torch.Size([587, 4]) tensor([169, 152, 150, 549], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.04868809133768082
bi 1 loss 0.04073416441679001
bi 2 loss 0.03862852230668068
bi 3 loss 0.22766117751598358
Layer  6  loss:  0.08193384855985641 0.0 11.141006469726562
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1022
Curr loss timestep torch.Size([587, 4]) tensor([164, 129, 139, 546], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.02805906906723976
bi 1 loss 0.03913428634405136
bi 2 loss 0.03498369827866554
bi 3 loss 0.1364947110414505
Epoch 0: :   3%|▎         | 15669/600000 [04:39<2:53:32, v_num=12, reduced_train_loss=1.070, global_step=15667.0, consumed_samples=62672.0, train_step_timing in s=0.411]Epoch 0: :   3%|▎         | 15669/600000 [04:39<2:53:32, v_num=12, reduced_train_loss=0.731, global_step=15668.0, consumed_samples=62676.0, train_step_timing in s=0.404]loss mask original None

First layer loss:  0.1136561706662178 torch.Size([526, 4]) 11.571928977966309 0.0
Max loss timestep torch.Size([526, 4]) tensor([304, 329, 164, 199], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.10101761668920517
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
bi 1 loss 0.16908058524131775
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
bi 2 loss 0.039217930287122726
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 3 loss 0.016309859231114388
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
logits torch.Size([526, 4, 257024]) labels torch.Size([526, 4]) 0 257022
Layer  0  loss:  0.09828107059001923 0.0 9.47301959991455
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1023
Curr loss timestep torch.Size([526, 4]) tensor([339, 329, 259, 215], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.09005042910575867
bi 1 loss 0.1411328762769699
bi 2 loss 0.03241405636072159
bi 3 loss 0.03520740941166878
Layer  1  loss:  0.1477135866880417 0.0 15.820990562438965
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([304, 329, 263, 224], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.17607340216636658
bi 1 loss 0.179703027009964
bi 2 loss 0.06540601700544357
bi 3 loss 0.03187599033117294
Layer  2  loss:  0.1371067613363266 0.0 10.909595489501953
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1023
Curr loss timestep torch.Size([526, 4]) tensor([291, 328, 173, 193], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.13509351015090942
bi 1 loss 0.18663541972637177
bi 2 loss 0.06630872935056686
bi 3 loss 0.021273380145430565
Layer  3  loss:  0.13461817800998688 0.0 14.598525047302246
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([304, 329, 160, 193], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.15518707036972046
bi 1 loss 0.17891868948936462
bi 2 loss 0.03374041989445686
bi 3 loss 0.022320201620459557
Layer  4  loss:  0.12608160078525543 0.0 13.445637702941895
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([388, 328, 237, 229], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.14272285997867584
bi 1 loss 0.1560964286327362
bi 2 loss 0.06304866075515747
bi 3 loss 0.026938362047076225
Layer  5  loss:  0.1470908224582672 0.0 18.094867706298828
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([304, 328, 238, 193], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.1750110387802124
bi 1 loss 0.18266655504703522
bi 2 loss 0.038677915930747986
bi 3 loss 0.07092474400997162
Layer  6  loss:  0.13614557683467865 0.0 11.58120346069336
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1021
Curr loss timestep torch.Size([526, 4]) tensor([388, 328, 265, 191], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.18230125308036804
bi 1 loss 0.14318472146987915
bi 2 loss 0.07112164795398712
bi 3 loss 0.050277139991521835
Epoch 0: :   3%|▎         | 15670/600000 [04:39<2:53:46, v_num=12, reduced_train_loss=0.731, global_step=15668.0, consumed_samples=62676.0, train_step_timing in s=0.404]Epoch 0: :   3%|▎         | 15670/600000 [04:39<2:53:46, v_num=12, reduced_train_loss=1.040, global_step=15669.0, consumed_samples=62680.0, train_step_timing in s=0.364]loss mask original None

First layer loss:  0.055982742458581924 torch.Size([482, 4]) 3.244466543197632 0.0
Max loss timestep torch.Size([482, 4]) tensor([ 85, 383, 326, 189], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.04014453664422035
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 1 loss 0.06412555277347565
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
bi 2 loss 0.06059105321764946
speech mask sum tensor(315, device='cuda:0') loss mask sum tensor(315, device='cuda:0')
bi 3 loss 0.04548672214150429
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
logits torch.Size([482, 4, 257024]) labels torch.Size([482, 4]) 0 257023
Layer  0  loss:  0.0634644404053688 0.0 1.9596903324127197
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([105, 272, 356,  94], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.025287803262472153
bi 1 loss 0.0832609012722969
bi 2 loss 0.07402776926755905
bi 3 loss 0.0388522669672966
Layer  1  loss:  0.0462389774620533 0.0 2.4616827964782715
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([ 45, 264, 348, 150], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.02426266483962536
bi 1 loss 0.06134803220629692
bi 2 loss 0.0511440709233284
bi 3 loss 0.02956472337245941
Layer  2  loss:  0.06125393509864807 0.0 2.7461917400360107
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([ 63, 383, 380, 213], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.04854513332247734
bi 1 loss 0.08582957834005356
bi 2 loss 0.06463579833507538
bi 3 loss 0.03184688091278076
Layer  3  loss:  0.05764048919081688 0.0 2.6790952682495117
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([ 58, 383, 466, 221], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.03133801370859146
bi 1 loss 0.08106277883052826
bi 2 loss 0.05234651267528534
bi 3 loss 0.04954349994659424
Layer  4  loss:  0.0651988610625267 0.0 5.198399543762207
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1022
Curr loss timestep torch.Size([482, 4]) tensor([ 52, 390, 310, 140], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.0259182658046484
bi 1 loss 0.1299392431974411
bi 2 loss 0.051953088492155075
bi 3 loss 0.02635502628982067
Layer  5  loss:  0.06012909114360809 0.0 4.209671497344971
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1023
Curr loss timestep torch.Size([482, 4]) tensor([105, 347, 408,  86], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.02983659878373146
bi 1 loss 0.08546478301286697
bi 2 loss 0.06266787648200989
bi 3 loss 0.03866306692361832
Layer  6  loss:  0.05994737520813942 0.0 4.069876194000244
logits torch.Size([482, 4, 1024]) labels torch.Size([482, 4]) 0 1020
Curr loss timestep torch.Size([482, 4]) tensor([ 99, 347, 411, 180], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.013595223426818848
bi 1 loss 0.0861060619354248
bi 2 loss 0.06836331635713577
bi 3 loss 0.03473162278532982
Epoch 0: :   3%|▎         | 15671/600000 [04:40<2:54:00, v_num=12, reduced_train_loss=1.040, global_step=15669.0, consumed_samples=62680.0, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15671/600000 [04:40<2:54:00, v_num=12, reduced_train_loss=0.470, global_step=15670.0, consumed_samples=62684.0, train_step_timing in s=0.353]loss mask original None

First layer loss:  3.8791816234588623 torch.Size([628, 4]) 11.381913185119629 0.0
Max loss timestep torch.Size([628, 4]) tensor([530, 367, 243, 186], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 3.656369686126709
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
bi 1 loss 4.114344596862793
speech mask sum tensor(434, device='cuda:0') loss mask sum tensor(434, device='cuda:0')
bi 2 loss 3.62446665763855
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 3 loss 4.019299507141113
speech mask sum tensor(413, device='cuda:0') loss mask sum tensor(413, device='cuda:0')
logits torch.Size([628, 4, 257024]) labels torch.Size([628, 4]) 0 257022
Layer  0  loss:  4.354506969451904 0.0 11.497446060180664
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([224, 123, 243, 454], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 4.0539631843566895
bi 1 loss 4.740387439727783
bi 2 loss 4.199775218963623
bi 3 loss 4.382632255554199
Layer  1  loss:  4.657527923583984 0.0 11.428201675415039
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([144, 515, 198, 478], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 4.211071491241455
bi 1 loss 5.085777282714844
bi 2 loss 4.081585884094238
bi 3 loss 5.014222621917725
Layer  2  loss:  4.9056396484375 0.0 10.326834678649902
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1022
Curr loss timestep torch.Size([628, 4]) tensor([472, 140, 125, 555], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.36525821685791
bi 1 loss 5.316532135009766
bi 2 loss 4.602290630340576
bi 3 loss 5.265328407287598
Layer  3  loss:  4.949058532714844 0.0 12.203441619873047
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1021
Curr loss timestep torch.Size([628, 4]) tensor([473, 488, 190, 440], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 4.456803798675537
bi 1 loss 5.3368330001831055
bi 2 loss 4.4601263999938965
bi 3 loss 5.362415790557861
Layer  4  loss:  5.1112236976623535 0.0 10.86098575592041
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1022
Curr loss timestep torch.Size([628, 4]) tensor([554, 231, 253, 176], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 4.581289291381836
bi 1 loss 5.5215325355529785
bi 2 loss 4.655246257781982
bi 3 loss 5.530675888061523
Layer  5  loss:  5.172837734222412 0.0 11.644766807556152
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1022
Curr loss timestep torch.Size([628, 4]) tensor([466, 300, 248, 478], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 4.669466018676758
bi 1 loss 5.64128303527832
bi 2 loss 4.615894317626953
bi 3 loss 5.546721458435059
Layer  6  loss:  5.179191589355469 0.0 9.776260375976562
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1021
Curr loss timestep torch.Size([628, 4]) tensor([583, 539, 147, 332], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 4.601785182952881
bi 1 loss 5.6548919677734375
bi 2 loss 4.678048610687256
bi 3 loss 5.608153820037842
Epoch 0: :   3%|▎         | 15672/600000 [04:40<2:54:15, v_num=12, reduced_train_loss=0.470, global_step=15670.0, consumed_samples=62684.0, train_step_timing in s=0.353]Epoch 0: :   3%|▎         | 15672/600000 [04:40<2:54:15, v_num=12, reduced_train_loss=38.20, global_step=15671.0, consumed_samples=62688.0, train_step_timing in s=0.394]loss mask original None

First layer loss:  0.17291554808616638 torch.Size([695, 4]) 8.165948867797852 0.0
Max loss timestep torch.Size([695, 4]) tensor([316, 470, 403, 332], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.10495947301387787
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 1 loss 0.1219545304775238
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
bi 2 loss 0.23696103692054749
speech mask sum tensor(468, device='cuda:0') loss mask sum tensor(468, device='cuda:0')
bi 3 loss 0.23011833429336548
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
logits torch.Size([695, 4, 257024]) labels torch.Size([695, 4]) 0 257022
Layer  0  loss:  0.19006673991680145 0.0 13.104084968566895
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1023
Curr loss timestep torch.Size([695, 4]) tensor([289, 349, 289, 332], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.05330503359436989
bi 1 loss 0.1807601898908615
bi 2 loss 0.2645799219608307
bi 3 loss 0.1994476318359375
Layer  1  loss:  0.23152172565460205 0.0 12.933753967285156
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1023
Curr loss timestep torch.Size([695, 4]) tensor([316, 336, 614, 291], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.09179950505495071
bi 1 loss 0.1841045320034027
bi 2 loss 0.3387695848941803
bi 3 loss 0.25851935148239136
Layer  2  loss:  0.24215663969516754 0.0 13.832375526428223
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1022
Curr loss timestep torch.Size([695, 4]) tensor([315, 336, 289, 331], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.08044013381004333
bi 1 loss 0.22118832170963287
bi 2 loss 0.35971009731292725
bi 3 loss 0.19751277565956116
Layer  3  loss:  0.25409090518951416 0.0 13.293961524963379
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1023
Curr loss timestep torch.Size([695, 4]) tensor([316, 349, 326, 311], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.09598369151353836
bi 1 loss 0.18808019161224365
bi 2 loss 0.3766321539878845
bi 3 loss 0.31573250889778137
Layer  4  loss:  0.25693777203559875 0.0 13.74206256866455
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1022
Curr loss timestep torch.Size([695, 4]) tensor([315, 499, 614, 291], device='cuda:0') tensor(614, device='cuda:0')
bi 0 loss 0.15273147821426392
bi 1 loss 0.22315043210983276
bi 2 loss 0.350241482257843
bi 3 loss 0.2349047064781189
Layer  5  loss:  0.2572181522846222 0.0 13.184021949768066
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1022
Curr loss timestep torch.Size([695, 4]) tensor([312, 442, 464, 311], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.13166755437850952
bi 1 loss 0.19063317775726318
bi 2 loss 0.37524354457855225
bi 3 loss 0.2869004011154175
Layer  6  loss:  0.2756723463535309 0.0 16.662187576293945
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1022
Curr loss timestep torch.Size([695, 4]) tensor([315, 336, 289, 331], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.12549728155136108
bi 1 loss 0.2387389838695526
bi 2 loss 0.39309900999069214
bi 3 loss 0.25945886969566345
Epoch 0: :   3%|▎         | 15673/600000 [04:40<2:54:34, v_num=12, reduced_train_loss=38.20, global_step=15671.0, consumed_samples=62688.0, train_step_timing in s=0.394]Epoch 0: :   3%|▎         | 15673/600000 [04:40<2:54:34, v_num=12, reduced_train_loss=1.880, global_step=15672.0, consumed_samples=62692.0, train_step_timing in s=0.479]loss mask original None

First layer loss:  0.07720009982585907 torch.Size([565, 4]) 6.884261131286621 0.0
Max loss timestep torch.Size([565, 4]) tensor([220, 127, 425, 339], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.024423792958259583
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 1 loss 0.046945635229349136
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 2 loss 0.08676695823669434
speech mask sum tensor(469, device='cuda:0') loss mask sum tensor(469, device='cuda:0')
bi 3 loss 0.111995168030262
speech mask sum tensor(239, device='cuda:0') loss mask sum tensor(239, device='cuda:0')
logits torch.Size([565, 4, 257024]) labels torch.Size([565, 4]) 0 257023
Layer  0  loss:  0.08886878937482834 0.0 11.691733360290527
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([164,  66, 451, 339], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.021323006600141525
bi 1 loss 0.05116289481520653
bi 2 loss 0.11236637830734253
bi 3 loss 0.11061722785234451
Layer  1  loss:  0.09619368612766266 0.0 8.757488250732422
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1021
Curr loss timestep torch.Size([565, 4]) tensor([174, 192, 544, 483], device='cuda:0') tensor(483, device='cuda:0')
bi 0 loss 0.0273448396474123
bi 1 loss 0.032353512942790985
bi 2 loss 0.12830093502998352
bi 3 loss 0.11989644914865494
Layer  2  loss:  0.08924879133701324 0.0 7.485739707946777
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([147,  86, 544, 483], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.041871629655361176
bi 1 loss 0.03963713347911835
bi 2 loss 0.10570815950632095
bi 3 loss 0.12053875625133514
Layer  3  loss:  0.11930477619171143 0.0 9.76590633392334
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1021
Curr loss timestep torch.Size([565, 4]) tensor([117,  68, 542, 483], device='cuda:0') tensor(483, device='cuda:0')
bi 0 loss 0.034099627286195755
bi 1 loss 0.04146215692162514
bi 2 loss 0.1443450152873993
bi 3 loss 0.17667093873023987
Layer  4  loss:  0.10009918361902237 0.0 8.66423511505127
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([170, 182, 448, 339], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.034194886684417725
bi 1 loss 0.03325251489877701
bi 2 loss 0.12462954223155975
bi 3 loss 0.13892260193824768
Layer  5  loss:  0.11888016760349274 0.0 6.292884826660156
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([171, 199, 546, 339], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.03804134204983711
bi 1 loss 0.04590693861246109
bi 2 loss 0.16266103088855743
bi 3 loss 0.13340526819229126
Layer  6  loss:  0.13177579641342163 0.0 6.698891639709473
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([185, 186, 542, 339], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.034021150320768356
bi 1 loss 0.04088426008820534
bi 2 loss 0.19572874903678894
bi 3 loss 0.1295618861913681
Epoch 0: :   3%|▎         | 15674/600000 [04:41<2:54:49, v_num=12, reduced_train_loss=1.880, global_step=15672.0, consumed_samples=62692.0, train_step_timing in s=0.479]Epoch 0: :   3%|▎         | 15674/600000 [04:41<2:54:49, v_num=12, reduced_train_loss=0.822, global_step=15673.0, consumed_samples=62696.0, train_step_timing in s=0.394]loss mask original None

First layer loss:  0.12473279237747192 torch.Size([751, 4]) 6.621775150299072 0.0
Max loss timestep torch.Size([751, 4]) tensor([193,  84, 736, 208], device='cuda:0') tensor(736, device='cuda:0')
bi 0 loss 0.04802047088742256
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 1 loss 0.017556708306074142
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 2 loss 0.1798708289861679
speech mask sum tensor(487, device='cuda:0') loss mask sum tensor(487, device='cuda:0')
bi 3 loss 0.03013760782778263
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([751, 4, 257024]) labels torch.Size([751, 4]) 0 257022
Layer  0  loss:  0.16979748010635376 0.0 8.633801460266113
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1023
Curr loss timestep torch.Size([751, 4]) tensor([268,  79, 736, 214], device='cuda:0') tensor(736, device='cuda:0')
bi 0 loss 0.08902749419212341
bi 1 loss 0.013907399959862232
bi 2 loss 0.24376758933067322
bi 3 loss 0.033582426607608795
Layer  1  loss:  0.18243002891540527 0.0 8.570073127746582
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1022
Curr loss timestep torch.Size([751, 4]) tensor([269,  56, 735, 214], device='cuda:0') tensor(735, device='cuda:0')
bi 0 loss 0.06177373602986336
bi 1 loss 0.03261903300881386
bi 2 loss 0.2667958736419678
bi 3 loss 0.027305686846375465
Layer  2  loss:  0.16604240238666534 0.0 9.973262786865234
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1022
Curr loss timestep torch.Size([751, 4]) tensor([258,  97, 645, 212], device='cuda:0') tensor(645, device='cuda:0')
bi 0 loss 0.044986359775066376
bi 1 loss 0.02026684582233429
bi 2 loss 0.24835138022899628
bi 3 loss 0.0174772460013628
Layer  3  loss:  0.19581639766693115 0.0 10.565861701965332
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1022
Curr loss timestep torch.Size([751, 4]) tensor([259,  96, 645, 218], device='cuda:0') tensor(645, device='cuda:0')
bi 0 loss 0.13430412113666534
bi 1 loss 0.038769327104091644
bi 2 loss 0.2734825611114502
bi 3 loss 0.024598484858870506
Layer  4  loss:  0.2204824984073639 0.0 14.094480514526367
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1023
Curr loss timestep torch.Size([751, 4]) tensor([268, 116, 613, 181], device='cuda:0') tensor(613, device='cuda:0')
bi 0 loss 0.14393217861652374
bi 1 loss 0.03957919403910637
bi 2 loss 0.30682000517845154
bi 3 loss 0.043834466487169266
Layer  5  loss:  0.18235749006271362 0.0 6.6543869972229
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1019
Curr loss timestep torch.Size([751, 4]) tensor([268, 119, 613, 254], device='cuda:0') tensor(613, device='cuda:0')
bi 0 loss 0.14682894945144653
bi 1 loss 0.026506438851356506
bi 2 loss 0.25042465329170227
bi 3 loss 0.03232573717832565
Layer  6  loss:  0.19134439527988434 0.0 9.201523780822754
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1021
Curr loss timestep torch.Size([751, 4]) tensor([268, 115, 533, 218], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.10560502111911774
bi 1 loss 0.032817378640174866
bi 2 loss 0.2725606858730316
bi 3 loss 0.027016570791602135
Epoch 0: :   3%|▎         | 15675/600000 [04:41<2:55:09, v_num=12, reduced_train_loss=0.822, global_step=15673.0, consumed_samples=62696.0, train_step_timing in s=0.394]Epoch 0: :   3%|▎         | 15675/600000 [04:41<2:55:09, v_num=12, reduced_train_loss=1.430, global_step=15674.0, consumed_samples=62700.0, train_step_timing in s=0.513]loss mask original None

First layer loss:  0.030769547447562218 torch.Size([355, 4]) 1.9586725234985352 0.0
Max loss timestep torch.Size([355, 4]) tensor([303, 134, 258, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.036958470940589905
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 1 loss 0.02575661800801754
speech mask sum tensor(144, device='cuda:0') loss mask sum tensor(144, device='cuda:0')
bi 2 loss 0.0232070405036211
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 3 loss 0.0422670841217041
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
logits torch.Size([355, 4, 257024]) labels torch.Size([355, 4]) 0 257023
Layer  0  loss:  0.0308951698243618 0.0 1.3515167236328125
logits torch.Size([355, 4, 1024]) labels torch.Size([355, 4]) 0 1023
Curr loss timestep torch.Size([355, 4]) tensor([299, 172, 271, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.037900932133197784
bi 1 loss 0.016841735690832138
bi 2 loss 0.026966873556375504
bi 3 loss 0.0427577868103981
Layer  1  loss:  0.026437493041157722 0.0 0.7844268083572388
logits torch.Size([355, 4, 1024]) labels torch.Size([355, 4]) 0 1022
Curr loss timestep torch.Size([355, 4]) tensor([303, 132, 302, 314], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.034545112401247025
bi 1 loss 0.03008183464407921
bi 2 loss 0.021212954074144363
bi 3 loss 0.02496281825006008
Layer  2  loss:  0.028075948357582092 0.0 0.9609619379043579
logits torch.Size([355, 4, 1024]) labels torch.Size([355, 4]) 0 1022
Curr loss timestep torch.Size([355, 4]) tensor([308, 138,  63, 264], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.027595380321145058
bi 1 loss 0.021703315898776054
bi 2 loss 0.028294920921325684
bi 3 loss 0.033386945724487305
Layer  3  loss:  0.02820245549082756 0.0 0.5124507546424866
logits torch.Size([355, 4, 1024]) labels torch.Size([355, 4]) 0 1023
Curr loss timestep torch.Size([355, 4]) tensor([294, 113, 154, 263], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.03973972424864769
bi 1 loss 0.02211236208677292
bi 2 loss 0.02417627163231373
bi 3 loss 0.02946164272725582
Layer  4  loss:  0.02708783745765686 0.0 0.9382039904594421
logits torch.Size([355, 4, 1024]) labels torch.Size([355, 4]) 0 1020
Curr loss timestep torch.Size([355, 4]) tensor([271, 111, 211, 317], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 0.027860840782523155
bi 1 loss 0.02895207516849041
bi 2 loss 0.023781387135386467
bi 3 loss 0.03057761676609516
Layer  5  loss:  0.031130950897932053 0.0 0.8049219846725464
logits torch.Size([355, 4, 1024]) labels torch.Size([355, 4]) 0 1023
Curr loss timestep torch.Size([355, 4]) tensor([307, 133, 293, 317], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.02764679677784443
bi 1 loss 0.030681990087032318
bi 2 loss 0.030206473544239998
bi 3 loss 0.03635157272219658
Layer  6  loss:  0.03400715813040733 0.0 1.6051613092422485
logits torch.Size([355, 4, 1024]) labels torch.Size([355, 4]) 0 1019
Curr loss timestep torch.Size([355, 4]) tensor([303, 184, 271, 264], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.043296754360198975
bi 1 loss 0.017507590353488922
bi 2 loss 0.02515741065144539
bi 3 loss 0.05430462583899498
Epoch 0: :   3%|▎         | 15676/600000 [04:42<2:55:20, v_num=12, reduced_train_loss=1.430, global_step=15674.0, consumed_samples=62700.0, train_step_timing in s=0.513]Epoch 0: :   3%|▎         | 15676/600000 [04:42<2:55:20, v_num=12, reduced_train_loss=0.237, global_step=15675.0, consumed_samples=62704.0, train_step_timing in s=0.277]loss mask original None

First layer loss:  0.02047700062394142 torch.Size([495, 4]) 0.4299497604370117 0.0
Max loss timestep torch.Size([495, 4]) tensor([ 59, 155, 288,  87], device='cuda:0') tensor(87, device='cuda:0')
bi 0 loss 0.018154596909880638
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
bi 1 loss 0.012484977021813393
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 2 loss 0.024689769372344017
speech mask sum tensor(393, device='cuda:0') loss mask sum tensor(393, device='cuda:0')
bi 3 loss 0.021940207108855247
speech mask sum tensor(86, device='cuda:0') loss mask sum tensor(86, device='cuda:0')
logits torch.Size([495, 4, 257024]) labels torch.Size([495, 4]) 0 257022
Layer  0  loss:  0.02165939286351204 0.0 0.8299030065536499
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([ 70, 172, 389, 113], device='cuda:0') tensor(389, device='cuda:0')
bi 0 loss 0.024082602933049202
bi 1 loss 0.011215602979063988
bi 2 loss 0.024335511028766632
bi 3 loss 0.021013781428337097
Layer  1  loss:  0.02079492248594761 0.0 0.5238826274871826
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([ 67, 119, 422,  76], device='cuda:0') tensor(422, device='cuda:0')
bi 0 loss 0.023352447897195816
bi 1 loss 0.01240917295217514
bi 2 loss 0.02344345673918724
bi 3 loss 0.01625683158636093
Layer  2  loss:  0.02066757157444954 0.0 0.5156497359275818
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1022
Curr loss timestep torch.Size([495, 4]) tensor([159,  93, 391,  97], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.023762159049510956
bi 1 loss 0.015848837792873383
bi 2 loss 0.022049957886338234
bi 3 loss 0.014087219722568989
Layer  3  loss:  0.02270372584462166 0.0 0.7294564247131348
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1018
Curr loss timestep torch.Size([495, 4]) tensor([ 67, 133, 380, 115], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.020871667191386223
bi 1 loss 0.01601463183760643
bi 2 loss 0.028667695820331573
bi 3 loss 0.012470296584069729
Layer  4  loss:  0.021947810426354408 0.0 1.2556571960449219
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1022
Curr loss timestep torch.Size([495, 4]) tensor([194, 153, 367,  78], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 0.022277288138866425
bi 1 loss 0.021215496584773064
bi 2 loss 0.021797126159071922
bi 3 loss 0.022995909675955772
Layer  5  loss:  0.02229395881295204 0.0 0.9986090660095215
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([284, 169, 288,  82], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.017484184354543686
bi 1 loss 0.018222764134407043
bi 2 loss 0.026192687451839447
bi 3 loss 0.02531958743929863
Layer  6  loss:  0.020818211138248444 0.0 0.4256168603897095
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1019
Curr loss timestep torch.Size([495, 4]) tensor([ 97, 151, 318, 128], device='cuda:0') tensor(151, device='cuda:0')
bi 0 loss 0.021215802058577538
bi 1 loss 0.012613517232239246
bi 2 loss 0.02177003026008606
bi 3 loss 0.029841886833310127
Epoch 0: :   3%|▎         | 15677/600000 [04:42<2:55:34, v_num=12, reduced_train_loss=0.237, global_step=15675.0, consumed_samples=62704.0, train_step_timing in s=0.277]Epoch 0: :   3%|▎         | 15677/600000 [04:42<2:55:34, v_num=12, reduced_train_loss=0.171, global_step=15676.0, consumed_samples=62708.0, train_step_timing in s=0.348]loss mask original None

First layer loss:  0.1798267811536789 torch.Size([707, 4]) 11.895565032958984 0.0
Max loss timestep torch.Size([707, 4]) tensor([384, 306,  83, 361], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.17165274918079376
speech mask sum tensor(495, device='cuda:0') loss mask sum tensor(495, device='cuda:0')
bi 1 loss 0.08725570887327194
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
bi 2 loss 0.09775876998901367
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 3 loss 0.28682705760002136
speech mask sum tensor(442, device='cuda:0') loss mask sum tensor(442, device='cuda:0')
logits torch.Size([707, 4, 257024]) labels torch.Size([707, 4]) 0 257023
Layer  0  loss:  0.22105471789836884 0.0 14.422013282775879
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([383, 323,  65, 487], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.2555752098560333
bi 1 loss 0.17945174872875214
bi 2 loss 0.03460574150085449
bi 3 loss 0.2794950306415558
Layer  1  loss:  0.24483419954776764 0.0 14.042119026184082
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([383, 267, 162, 488], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.2540262043476105
bi 1 loss 0.15325289964675903
bi 2 loss 0.057032760232686996
bi 3 loss 0.3692084848880768
Layer  2  loss:  0.24037595093250275 0.0 20.658370971679688
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1022
Curr loss timestep torch.Size([707, 4]) tensor([385, 262, 152, 665], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.25017786026000977
bi 1 loss 0.14621788263320923
bi 2 loss 0.03581145405769348
bi 3 loss 0.3719336688518524
Layer  3  loss:  0.2684929370880127 0.0 11.980613708496094
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([383, 307,  83, 361], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.26111289858818054
bi 1 loss 0.20863932371139526
bi 2 loss 0.05988167226314545
bi 3 loss 0.3952735662460327
Layer  4  loss:  0.27071529626846313 0.0 14.488977432250977
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1021
Curr loss timestep torch.Size([707, 4]) tensor([385, 279,  72, 488], device='cuda:0') tensor(488, device='cuda:0')
bi 0 loss 0.28601786494255066
bi 1 loss 0.1844591349363327
bi 2 loss 0.043364208191633224
bi 3 loss 0.3983428478240967
Layer  5  loss:  0.28480708599090576 0.0 16.324626922607422
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1019
Curr loss timestep torch.Size([707, 4]) tensor([385, 307, 175, 361], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.24653790891170502
bi 1 loss 0.2214270532131195
bi 2 loss 0.02722441963851452
bi 3 loss 0.4661926329135895
Layer  6  loss:  0.2886684536933899 0.0 19.156394958496094
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1022
Curr loss timestep torch.Size([707, 4]) tensor([384, 308, 103, 361], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.28568005561828613
bi 1 loss 0.1999155879020691
bi 2 loss 0.0465293824672699
bi 3 loss 0.44388577342033386
Epoch 0: :   3%|▎         | 15678/600000 [04:43<2:55:53, v_num=12, reduced_train_loss=0.171, global_step=15676.0, consumed_samples=62708.0, train_step_timing in s=0.348]Epoch 0: :   3%|▎         | 15678/600000 [04:43<2:55:53, v_num=12, reduced_train_loss=2.000, global_step=15677.0, consumed_samples=62712.0, train_step_timing in s=0.481]loss mask original None

First layer loss:  3.389934539794922 torch.Size([592, 4]) 12.481327056884766 0.0
Max loss timestep torch.Size([592, 4]) tensor([261, 512, 416, 264], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 3.128438711166382
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 1 loss 3.535764455795288
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
bi 2 loss 3.60738468170166
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
bi 3 loss 3.1378684043884277
speech mask sum tensor(458, device='cuda:0') loss mask sum tensor(458, device='cuda:0')
logits torch.Size([592, 4, 257024]) labels torch.Size([592, 4]) 0 257023
Layer  0  loss:  3.9923272132873535 0.0 9.977945327758789
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([220, 477, 461, 387], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 4.094475746154785
bi 1 loss 4.16082239151001
bi 2 loss 4.243603706359863
bi 3 loss 3.586303234100342
Layer  1  loss:  4.403948783874512 0.0 10.473260879516602
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1022
Curr loss timestep torch.Size([592, 4]) tensor([296, 308, 298, 173], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 4.559817314147949
bi 1 loss 4.352038860321045
bi 2 loss 4.8029069900512695
bi 3 loss 4.037975311279297
Layer  2  loss:  4.65380859375 0.0 10.048179626464844
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([286, 204, 140, 157], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 4.7458930015563965
bi 1 loss 4.69833517074585
bi 2 loss 5.012205123901367
bi 3 loss 4.2596330642700195
Layer  3  loss:  4.886303901672363 0.0 10.878666877746582
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([245, 343, 206, 154], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 5.026612281799316
bi 1 loss 4.849343299865723
bi 2 loss 5.362080097198486
bi 3 loss 4.44117546081543
Layer  4  loss:  5.061570167541504 0.0 10.9996337890625
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([253, 334, 287, 405], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 5.279409408569336
bi 1 loss 5.041951656341553
bi 2 loss 5.431182384490967
bi 3 loss 4.6769914627075195
Layer  5  loss:  5.096643447875977 0.0 10.465386390686035
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([273, 401, 493, 198], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 5.236308574676514
bi 1 loss 5.0852131843566895
bi 2 loss 5.480620861053467
bi 3 loss 4.713951587677002
Layer  6  loss:  5.087029457092285 0.0 9.938028335571289
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1022
Curr loss timestep torch.Size([592, 4]) tensor([279, 369, 128, 247], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 5.105002403259277
bi 1 loss 5.080196857452393
bi 2 loss 5.595242500305176
bi 3 loss 4.620694160461426
Epoch 0: :   3%|▎         | 15679/600000 [04:43<2:56:07, v_num=12, reduced_train_loss=2.000, global_step=15677.0, consumed_samples=62712.0, train_step_timing in s=0.481]Epoch 0: :   3%|▎         | 15679/600000 [04:43<2:56:07, v_num=12, reduced_train_loss=36.60, global_step=15678.0, consumed_samples=62716.0, train_step_timing in s=0.371]loss mask original None

First layer loss:  3.7659332752227783 torch.Size([412, 4]) 13.164548873901367 0.0
Max loss timestep torch.Size([412, 4]) tensor([103, 273, 140, 185], device='cuda:0') tensor(140, device='cuda:0')
bi 0 loss 4.202005386352539
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
bi 1 loss 3.5421416759490967
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
bi 2 loss 3.8879048824310303
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 3 loss 3.600492238998413
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
logits torch.Size([412, 4, 257024]) labels torch.Size([412, 4]) 0 257023
Layer  0  loss:  4.385511875152588 0.0 11.551763534545898
logits torch.Size([412, 4, 1024]) labels torch.Size([412, 4]) 0 1023
Curr loss timestep torch.Size([412, 4]) tensor([103, 256, 297, 205], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.637729167938232
bi 1 loss 4.169410705566406
bi 2 loss 4.856113910675049
bi 3 loss 4.02809476852417
Layer  1  loss:  4.573387145996094 0.0 9.859036445617676
logits torch.Size([412, 4, 1024]) labels torch.Size([412, 4]) 0 1022
Curr loss timestep torch.Size([412, 4]) tensor([ 74, 326, 199, 184], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.952206134796143
bi 1 loss 4.3714399337768555
bi 2 loss 4.75649881362915
bi 3 loss 4.3700127601623535
Layer  2  loss:  4.808840274810791 0.0 10.417644500732422
logits torch.Size([412, 4, 1024]) labels torch.Size([412, 4]) 0 1022
Curr loss timestep torch.Size([412, 4]) tensor([218, 240, 101, 366], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 5.084893226623535
bi 1 loss 4.736396789550781
bi 2 loss 4.9641289710998535
bi 3 loss 4.566888809204102
Layer  3  loss:  4.959170341491699 0.0 10.960186004638672
logits torch.Size([412, 4, 1024]) labels torch.Size([412, 4]) 0 1020
Curr loss timestep torch.Size([412, 4]) tensor([150, 272, 201, 196], device='cuda:0') tensor(118, device='cuda:0')
bi 0 loss 5.184674263000488
bi 1 loss 4.966850757598877
bi 2 loss 5.245387554168701
bi 3 loss 4.555881977081299
Layer  4  loss:  5.085318088531494 0.0 10.244512557983398
logits torch.Size([412, 4, 1024]) labels torch.Size([412, 4]) 0 1023
Curr loss timestep torch.Size([412, 4]) tensor([217, 268, 309, 268], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 5.0896687507629395
bi 1 loss 5.023521900177002
bi 2 loss 5.3653244972229
bi 3 loss 4.900444984436035
Layer  5  loss:  5.088510513305664 0.0 10.09649658203125
logits torch.Size([412, 4, 1024]) labels torch.Size([412, 4]) 0 1019
Curr loss timestep torch.Size([412, 4]) tensor([ 96, 123, 106, 342], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 5.23055362701416
bi 1 loss 5.0411224365234375
bi 2 loss 5.3831892013549805
bi 3 loss 4.787088394165039
Layer  6  loss:  5.260797500610352 0.0 11.3106050491333
logits torch.Size([412, 4, 1024]) labels torch.Size([412, 4]) 0 1023
Curr loss timestep torch.Size([412, 4]) tensor([219, 220, 239, 211], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 5.410585880279541
bi 1 loss 5.184906959533691
bi 2 loss 5.44285249710083
bi 3 loss 5.080929279327393
Epoch 0: :   3%|▎         | 15680/600000 [04:43<2:56:19, v_num=12, reduced_train_loss=36.60, global_step=15678.0, consumed_samples=62716.0, train_step_timing in s=0.371]Epoch 0: :   3%|▎         | 15680/600000 [04:43<2:56:19, v_num=12, reduced_train_loss=37.90, global_step=15679.0, consumed_samples=62720.0, train_step_timing in s=0.295]loss mask original None

First layer loss:  0.11163271218538284 torch.Size([530, 4]) 9.31332778930664 0.0
Max loss timestep torch.Size([530, 4]) tensor([284, 313, 223, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.06287911534309387
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
bi 1 loss 0.05815362557768822
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 2 loss 0.04192034900188446
speech mask sum tensor(110, device='cuda:0') loss mask sum tensor(110, device='cuda:0')
bi 3 loss 0.1959119439125061
speech mask sum tensor(481, device='cuda:0') loss mask sum tensor(481, device='cuda:0')
logits torch.Size([530, 4, 257024]) labels torch.Size([530, 4]) 0 257022
Layer  0  loss:  0.14868874847888947 0.0 12.028833389282227
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([318, 468, 236, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.06577979028224945
bi 1 loss 0.12626464664936066
bi 2 loss 0.04057959467172623
bi 3 loss 0.2481691986322403
Layer  1  loss:  0.16494660079479218 0.0 10.567085266113281
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([284, 415, 264, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.10549638420343399
bi 1 loss 0.13389810919761658
bi 2 loss 0.03903587535023689
bi 3 loss 0.2564021348953247
Layer  2  loss:  0.18123239278793335 0.0 13.752313613891602
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([392, 263, 229, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.09274612367153168
bi 1 loss 0.12615783512592316
bi 2 loss 0.09566745907068253
bi 3 loss 0.29942673444747925
Layer  3  loss:  0.16326642036437988 0.0 11.130847930908203
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([284, 415, 275, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.07423272728919983
bi 1 loss 0.155411958694458
bi 2 loss 0.048732999712228775
bi 3 loss 0.2599219083786011
Layer  4  loss:  0.1615843027830124 0.0 14.078639030456543
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([284, 263, 212, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.10630976408720016
bi 1 loss 0.14948026835918427
bi 2 loss 0.06354130059480667
bi 3 loss 0.23212376236915588
Layer  5  loss:  0.16101613640785217 0.0 9.694942474365234
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([392, 415, 239, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.1118902713060379
bi 1 loss 0.11851540952920914
bi 2 loss 0.05550852417945862
bi 3 loss 0.24711433053016663
Layer  6  loss:  0.19180075824260712 0.0 10.029128074645996
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([284, 415, 249, 507], device='cuda:0') tensor(507, device='cuda:0')
bi 0 loss 0.08592421561479568
bi 1 loss 0.16454114019870758
bi 2 loss 0.06070595234632492
bi 3 loss 0.31641435623168945
Epoch 0: :   3%|▎         | 15681/600000 [04:44<2:56:33, v_num=12, reduced_train_loss=37.90, global_step=15679.0, consumed_samples=62720.0, train_step_timing in s=0.295]Epoch 0: :   3%|▎         | 15681/600000 [04:44<2:56:33, v_num=12, reduced_train_loss=1.280, global_step=15680.0, consumed_samples=62724.0, train_step_timing in s=0.371]loss mask original None

First layer loss:  0.014835041016340256 torch.Size([395, 4]) 0.2566574811935425 0.0
Max loss timestep torch.Size([395, 4]) tensor([ 89,  59, 295,  88], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.013858054764568806
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 1 loss 0.012202988378703594
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 2 loss 0.018099389970302582
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 3 loss 0.011655201204121113
speech mask sum tensor(167, device='cuda:0') loss mask sum tensor(167, device='cuda:0')
logits torch.Size([395, 4, 257024]) labels torch.Size([395, 4]) 0 257022
Layer  0  loss:  0.015446605160832405 0.0 0.28062304854393005
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1023
Curr loss timestep torch.Size([395, 4]) tensor([ 97, 115, 272,  86], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.013295397162437439
bi 1 loss 0.012167959474027157
bi 2 loss 0.0203393567353487
bi 3 loss 0.01073740515857935
Layer  1  loss:  0.01470101810991764 0.0 0.23744246363639832
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1023
Curr loss timestep torch.Size([395, 4]) tensor([103,  81, 343, 150], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.013522712513804436
bi 1 loss 0.01147453673183918
bi 2 loss 0.017548704519867897
bi 3 loss 0.012663254514336586
Layer  2  loss:  0.016270337626338005 0.0 0.8704254031181335
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1022
Curr loss timestep torch.Size([395, 4]) tensor([124,  76, 385, 105], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.012458987534046173
bi 1 loss 0.015766872093081474
bi 2 loss 0.021738026291131973
bi 3 loss 0.010103206150233746
Layer  3  loss:  0.01631411910057068 0.0 0.288512259721756
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1022
Curr loss timestep torch.Size([395, 4]) tensor([143, 111, 343, 191], device='cuda:0') tensor(191, device='cuda:0')
bi 0 loss 0.014211361296474934
bi 1 loss 0.018996629863977432
bi 2 loss 0.01752803847193718
bi 3 loss 0.01415293663740158
Layer  4  loss:  0.022494928911328316 0.0 2.9221317768096924
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1020
Curr loss timestep torch.Size([395, 4]) tensor([ 78, 120, 344, 197], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.015526331961154938
bi 1 loss 0.013066461309790611
bi 2 loss 0.034804895520210266
bi 3 loss 0.012305552139878273
Layer  5  loss:  0.01852273941040039 0.0 1.1446658372879028
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1022
Curr loss timestep torch.Size([395, 4]) tensor([ 91, 114, 344, 126], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.013425879180431366
bi 1 loss 0.012411476112902164
bi 2 loss 0.025463050231337547
bi 3 loss 0.013971925713121891
Layer  6  loss:  0.020707599818706512 0.0 3.2795088291168213
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1020
Curr loss timestep torch.Size([395, 4]) tensor([124,  57, 344, 114], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.015168027020990849
bi 1 loss 0.012112905271351337
bi 2 loss 0.02921118214726448
bi 3 loss 0.015313715673983097
Epoch 0: :   3%|▎         | 15682/600000 [04:44<2:56:45, v_num=12, reduced_train_loss=1.280, global_step=15680.0, consumed_samples=62724.0, train_step_timing in s=0.371]Epoch 0: :   3%|▎         | 15682/600000 [04:44<2:56:45, v_num=12, reduced_train_loss=0.139, global_step=15681.0, consumed_samples=62728.0, train_step_timing in s=0.298]loss mask original None

First layer loss:  3.6255786418914795 torch.Size([476, 4]) 12.352502822875977 0.0
Max loss timestep torch.Size([476, 4]) tensor([173, 101, 207, 236], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 3.3755948543548584
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 1 loss 2.9487900733947754
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 2 loss 3.740593910217285
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 3 loss 3.887971878051758
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
logits torch.Size([476, 4, 257024]) labels torch.Size([476, 4]) 0 257022
Layer  0  loss:  4.079932689666748 0.0 9.217700958251953
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1023
Curr loss timestep torch.Size([476, 4]) tensor([179, 128, 410, 142], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 3.438952684402466
bi 1 loss 3.3798727989196777
bi 2 loss 4.36442232131958
bi 3 loss 4.261666297912598
Layer  1  loss:  4.435232162475586 0.0 10.719613075256348
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1021
Curr loss timestep torch.Size([476, 4]) tensor([234, 100, 226, 219], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 3.8697049617767334
bi 1 loss 3.9256534576416016
bi 2 loss 4.65476131439209
bi 3 loss 4.605407238006592
Layer  2  loss:  4.615686893463135 0.0 10.508225440979004
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1022
Curr loss timestep torch.Size([476, 4]) tensor([245, 146, 381, 119], device='cuda:0') tensor(154, device='cuda:0')
bi 0 loss 4.010076522827148
bi 1 loss 3.8595991134643555
bi 2 loss 5.0249714851379395
bi 3 loss 4.551692008972168
Layer  3  loss:  4.738309383392334 0.0 10.942215919494629
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1022
Curr loss timestep torch.Size([476, 4]) tensor([185, 102, 127, 226], device='cuda:0') tensor(142, device='cuda:0')
bi 0 loss 4.070772647857666
bi 1 loss 4.093003273010254
bi 2 loss 5.032478332519531
bi 3 loss 4.890385627746582
Layer  4  loss:  4.9433794021606445 0.0 9.670402526855469
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1021
Curr loss timestep torch.Size([476, 4]) tensor([192, 133, 114, 241], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 4.167196750640869
bi 1 loss 4.601478099822998
bi 2 loss 5.25966739654541
bi 3 loss 4.970008850097656
Layer  5  loss:  4.9866766929626465 0.0 9.964946746826172
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1022
Curr loss timestep torch.Size([476, 4]) tensor([260, 152, 255, 131], device='cuda:0') tensor(241, device='cuda:0')
bi 0 loss 4.381438255310059
bi 1 loss 4.541198253631592
bi 2 loss 5.335568428039551
bi 3 loss 4.890271186828613
Layer  6  loss:  5.054625988006592 0.0 9.644429206848145
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1020
Curr loss timestep torch.Size([476, 4]) tensor([183, 143, 281, 208], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.293420314788818
bi 1 loss 4.442105293273926
bi 2 loss 5.468363285064697
bi 3 loss 5.009612560272217
Epoch 0: :   3%|▎         | 15683/600000 [04:44<2:56:58, v_num=12, reduced_train_loss=0.139, global_step=15681.0, consumed_samples=62728.0, train_step_timing in s=0.298]Epoch 0: :   3%|▎         | 15683/600000 [04:44<2:56:58, v_num=12, reduced_train_loss=36.50, global_step=15682.0, consumed_samples=62732.0, train_step_timing in s=0.327]loss mask original None

First layer loss:  0.07574336975812912 torch.Size([374, 4]) 9.722037315368652 0.0
Max loss timestep torch.Size([374, 4]) tensor([284,  68, 347, 274], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.061987340450286865
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 1 loss 0.04386885091662407
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 2 loss 0.12461099028587341
speech mask sum tensor(258, device='cuda:0') loss mask sum tensor(258, device='cuda:0')
bi 3 loss 0.06914110481739044
speech mask sum tensor(158, device='cuda:0') loss mask sum tensor(158, device='cuda:0')
logits torch.Size([374, 4, 257024]) labels torch.Size([374, 4]) 0 257023
Layer  0  loss:  0.07533290237188339 0.0 6.453738212585449
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1023
Curr loss timestep torch.Size([374, 4]) tensor([307, 267, 347, 269], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.057748254388570786
bi 1 loss 0.05111207813024521
bi 2 loss 0.13015329837799072
bi 3 loss 0.049469366669654846
Layer  1  loss:  0.0788760632276535 0.0 16.93984031677246
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1022
Curr loss timestep torch.Size([374, 4]) tensor([307, 273, 347, 253], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.06820068508386612
bi 1 loss 0.04197624698281288
bi 2 loss 0.13174690306186676
bi 3 loss 0.07136276364326477
Layer  2  loss:  0.07644478231668472 0.0 13.505990982055664
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1022
Curr loss timestep torch.Size([374, 4]) tensor([284, 102, 347, 172], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.06594516336917877
bi 1 loss 0.05724737420678139
bi 2 loss 0.12302879244089127
bi 3 loss 0.04695563018321991
Layer  3  loss:  0.08470679074525833 0.0 15.666813850402832
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1021
Curr loss timestep torch.Size([374, 4]) tensor([284,  49, 347, 281], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.07018855214118958
bi 1 loss 0.061541177332401276
bi 2 loss 0.12746471166610718
bi 3 loss 0.0731755867600441
Layer  4  loss:  0.08664344251155853 0.0 15.043715476989746
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1022
Curr loss timestep torch.Size([374, 4]) tensor([212, 298, 347, 228], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.07935825735330582
bi 1 loss 0.04426183924078941
bi 2 loss 0.15872274339199066
bi 3 loss 0.053867749869823456
Layer  5  loss:  0.08787185698747635 0.0 14.233909606933594
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1023
Curr loss timestep torch.Size([374, 4]) tensor([254, 258, 347, 162], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.07551515847444534
bi 1 loss 0.06606092303991318
bi 2 loss 0.14556153118610382
bi 3 loss 0.04707111418247223
Layer  6  loss:  0.08383432775735855 0.0 13.644691467285156
logits torch.Size([374, 4, 1024]) labels torch.Size([374, 4]) 0 1022
Curr loss timestep torch.Size([374, 4]) tensor([205, 258, 347, 280], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.09280288219451904
bi 1 loss 0.0647508054971695
bi 2 loss 0.11834739148616791
bi 3 loss 0.051917340606451035
Epoch 0: :   3%|▎         | 15684/600000 [04:45<2:57:09, v_num=12, reduced_train_loss=36.50, global_step=15682.0, consumed_samples=62732.0, train_step_timing in s=0.327]Epoch 0: :   3%|▎         | 15684/600000 [04:45<2:57:09, v_num=12, reduced_train_loss=0.649, global_step=15683.0, consumed_samples=62736.0, train_step_timing in s=0.291]loss mask original None

First layer loss:  0.07807797938585281 torch.Size([419, 4]) 7.753111839294434 0.0
Max loss timestep torch.Size([419, 4]) tensor([267, 400, 256, 321], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.14289437234401703
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
bi 1 loss 0.07030000537633896
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 2 loss 0.04075091332197189
speech mask sum tensor(225, device='cuda:0') loss mask sum tensor(225, device='cuda:0')
bi 3 loss 0.05114847421646118
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
logits torch.Size([419, 4, 257024]) labels torch.Size([419, 4]) 0 257022
Layer  0  loss:  0.12498687952756882 0.0 10.589977264404297
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1023
Curr loss timestep torch.Size([419, 4]) tensor([268, 400, 197, 315], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.207203209400177
bi 1 loss 0.09274258464574814
bi 2 loss 0.03794769570231438
bi 3 loss 0.17271322011947632
Layer  1  loss:  0.1457032710313797 0.0 12.45199966430664
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1023
Curr loss timestep torch.Size([419, 4]) tensor([314, 400, 265, 316], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.23435892164707184
bi 1 loss 0.10417730361223221
bi 2 loss 0.04379848390817642
bi 3 loss 0.21769367158412933
Layer  2  loss:  0.1470857709646225 0.0 14.142200469970703
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1022
Curr loss timestep torch.Size([419, 4]) tensor([268, 400, 195, 314], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.2622721195220947
bi 1 loss 0.09396837651729584
bi 2 loss 0.039564941078424454
bi 3 loss 0.21261252462863922
Layer  3  loss:  0.1519952118396759 0.0 19.936077117919922
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1021
Curr loss timestep torch.Size([419, 4]) tensor([267, 400, 316, 316], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.260661244392395
bi 1 loss 0.09848275780677795
bi 2 loss 0.03477101773023605
bi 3 loss 0.23666390776634216
Layer  4  loss:  0.14485400915145874 0.0 15.038596153259277
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1023
Curr loss timestep torch.Size([419, 4]) tensor([268, 399, 264, 316], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.2535768449306488
bi 1 loss 0.10641097277402878
bi 2 loss 0.04647497087717056
bi 3 loss 0.18271727859973907
Layer  5  loss:  0.16769447922706604 0.0 15.356317520141602
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1023
Curr loss timestep torch.Size([419, 4]) tensor([314, 400, 255, 316], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.26806971430778503
bi 1 loss 0.11817166209220886
bi 2 loss 0.037059348076581955
bi 3 loss 0.26990583539009094
Layer  6  loss:  0.16444584727287292 0.0 12.378385543823242
logits torch.Size([419, 4, 1024]) labels torch.Size([419, 4]) 0 1022
Curr loss timestep torch.Size([419, 4]) tensor([268, 400, 172, 316], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.2895871102809906
bi 1 loss 0.11136555671691895
bi 2 loss 0.036329057067632675
bi 3 loss 0.2395084798336029
Epoch 0: :   3%|▎         | 15685/600000 [04:45<2:57:22, v_num=12, reduced_train_loss=0.649, global_step=15683.0, consumed_samples=62736.0, train_step_timing in s=0.291]Epoch 0: :   3%|▎         | 15685/600000 [04:45<2:57:22, v_num=12, reduced_train_loss=1.120, global_step=15684.0, consumed_samples=62740.0, train_step_timing in s=0.310]loss mask original None

First layer loss:  0.06384260952472687 torch.Size([477, 4]) 2.240760087966919 0.0
Max loss timestep torch.Size([477, 4]) tensor([397, 170, 116, 250], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.08670143783092499
speech mask sum tensor(404, device='cuda:0') loss mask sum tensor(404, device='cuda:0')
bi 1 loss 0.04596216604113579
speech mask sum tensor(182, device='cuda:0') loss mask sum tensor(182, device='cuda:0')
bi 2 loss 0.040948547422885895
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 3 loss 0.049203213304281235
speech mask sum tensor(224, device='cuda:0') loss mask sum tensor(224, device='cuda:0')
logits torch.Size([477, 4, 257024]) labels torch.Size([477, 4]) 0 257019
Layer  0  loss:  0.0707838386297226 0.0 4.6462907791137695
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([397, 298, 142, 257], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.08521097153425217
bi 1 loss 0.07240293174982071
bi 2 loss 0.044560715556144714
bi 3 loss 0.057261936366558075
Layer  1  loss:  0.06641994416713715 0.0 3.4828691482543945
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1022
Curr loss timestep torch.Size([477, 4]) tensor([391, 298, 145, 121], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.09636066854000092
bi 1 loss 0.0709787905216217
bi 2 loss 0.029171405360102654
bi 3 loss 0.028337646275758743
Layer  2  loss:  0.07556765526533127 0.0 5.4494781494140625
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1022
Curr loss timestep torch.Size([477, 4]) tensor([391, 302, 142, 268], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.10271479189395905
bi 1 loss 0.07745016366243362
bi 2 loss 0.032645028084516525
bi 3 loss 0.04768732935190201
Layer  3  loss:  0.09330615401268005 0.0 9.123714447021484
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([397, 159, 120, 268], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.1149861067533493
bi 1 loss 0.09636849910020828
bi 2 loss 0.027318788692355156
bi 3 loss 0.0864778608083725
Layer  4  loss:  0.06967481970787048 0.0 4.273625373840332
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([264, 303, 103, 268], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.0901552215218544
bi 1 loss 0.08718555420637131
bi 2 loss 0.02943030372262001
bi 3 loss 0.039709724485874176
Layer  5  loss:  0.07160384207963943 0.0 5.200822830200195
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1021
Curr loss timestep torch.Size([477, 4]) tensor([298, 303, 174, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.09241916239261627
bi 1 loss 0.06684320420026779
bi 2 loss 0.04523177072405815
bi 3 loss 0.05182238295674324
Layer  6  loss:  0.0722196102142334 0.0 8.47800350189209
logits torch.Size([477, 4, 1024]) labels torch.Size([477, 4]) 0 1023
Curr loss timestep torch.Size([477, 4]) tensor([397, 302, 171, 168], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.0937599167227745
bi 1 loss 0.06613148003816605
bi 2 loss 0.084515281021595
bi 3 loss 0.03183954954147339
Epoch 0: :   3%|▎         | 15686/600000 [04:46<2:57:35, v_num=12, reduced_train_loss=1.120, global_step=15684.0, consumed_samples=62740.0, train_step_timing in s=0.310]Epoch 0: :   3%|▎         | 15686/600000 [04:46<2:57:35, v_num=12, reduced_train_loss=0.583, global_step=15685.0, consumed_samples=62744.0, train_step_timing in s=0.341]loss mask original None

First layer loss:  0.23085513710975647 torch.Size([870, 4]) 12.89061164855957 0.0
Max loss timestep torch.Size([870, 4]) tensor([272, 286, 621, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.05097406357526779
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 1 loss 0.16729986667633057
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 2 loss 0.36203429102897644
speech mask sum tensor(501, device='cuda:0') loss mask sum tensor(501, device='cuda:0')
bi 3 loss 0.17140117287635803
speech mask sum tensor(320, device='cuda:0') loss mask sum tensor(320, device='cuda:0')
logits torch.Size([870, 4, 257024]) labels torch.Size([870, 4]) 0 257023
Layer  0  loss:  0.34790730476379395 0.0 17.508472442626953
logits torch.Size([870, 4, 1024]) labels torch.Size([870, 4]) 0 1023
Curr loss timestep torch.Size([870, 4]) tensor([258, 288, 541, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.05611588805913925
bi 1 loss 0.18308068811893463
bi 2 loss 0.6230196356773376
bi 3 loss 0.18533648550510406
Layer  1  loss:  0.34528210759162903 0.0 12.530904769897461
logits torch.Size([870, 4, 1024]) labels torch.Size([870, 4]) 0 1022
Curr loss timestep torch.Size([870, 4]) tensor([279, 287, 621, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.08228111267089844
bi 1 loss 0.25794777274131775
bi 2 loss 0.5997755527496338
bi 3 loss 0.15734601020812988
Layer  2  loss:  0.4206445515155792 0.0 18.299739837646484
logits torch.Size([870, 4, 1024]) labels torch.Size([870, 4]) 0 1023
Curr loss timestep torch.Size([870, 4]) tensor([271, 287, 541, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.07792700082063675
bi 1 loss 0.17634597420692444
bi 2 loss 0.7735662460327148
bi 3 loss 0.20888154208660126
Layer  3  loss:  0.3957291543483734 0.0 13.314282417297363
logits torch.Size([870, 4, 1024]) labels torch.Size([870, 4]) 0 1023
Curr loss timestep torch.Size([870, 4]) tensor([155, 287, 689, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.06037912890315056
bi 1 loss 0.1757500022649765
bi 2 loss 0.7265413999557495
bi 3 loss 0.20154280960559845
Layer  4  loss:  0.398599773645401 0.0 18.253488540649414
logits torch.Size([870, 4, 1024]) labels torch.Size([870, 4]) 0 1023
Curr loss timestep torch.Size([870, 4]) tensor([264, 286, 541, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.04246135428547859
bi 1 loss 0.2403004914522171
bi 2 loss 0.7294025421142578
bi 3 loss 0.18613283336162567
Layer  5  loss:  0.40028810501098633 0.0 20.01614761352539
logits torch.Size([870, 4, 1024]) labels torch.Size([870, 4]) 0 1022
Curr loss timestep torch.Size([870, 4]) tensor([122, 287, 621, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.06471756845712662
bi 1 loss 0.25609850883483887
bi 2 loss 0.7001814246177673
bi 3 loss 0.2160431146621704
Layer  6  loss:  0.428720623254776 0.0 18.515655517578125
logits torch.Size([870, 4, 1024]) labels torch.Size([870, 4]) 0 1023
Curr loss timestep torch.Size([870, 4]) tensor([279, 286, 516, 274], device='cuda:0') tensor(516, device='cuda:0')
bi 0 loss 0.05043743550777435
bi 1 loss 0.24102671444416046
bi 2 loss 0.7760472297668457
bi 3 loss 0.21933531761169434
Epoch 0: :   3%|▎         | 15687/600000 [04:46<2:57:58, v_num=12, reduced_train_loss=0.583, global_step=15685.0, consumed_samples=62744.0, train_step_timing in s=0.341]Epoch 0: :   3%|▎         | 15687/600000 [04:46<2:57:58, v_num=12, reduced_train_loss=2.970, global_step=15686.0, consumed_samples=62748.0, train_step_timing in s=0.602]loss mask original None

First layer loss:  0.12796278297901154 torch.Size([579, 4]) 9.7046480178833 0.0
Max loss timestep torch.Size([579, 4]) tensor([502, 293, 268, 380], device='cuda:0') tensor(502, device='cuda:0')
bi 0 loss 0.184202179312706
speech mask sum tensor(358, device='cuda:0') loss mask sum tensor(358, device='cuda:0')
bi 1 loss 0.09607358276844025
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 2 loss 0.10362353175878525
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 3 loss 0.09212695062160492
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
logits torch.Size([579, 4, 257024]) labels torch.Size([579, 4]) 0 257023
Layer  0  loss:  0.1296091377735138 0.0 7.753734111785889
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([280, 365, 267, 386], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.18719585239887238
bi 1 loss 0.09265999495983124
bi 2 loss 0.09884880483150482
bi 3 loss 0.10459164530038834
Layer  1  loss:  0.15326891839504242 0.0 12.582233428955078
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1022
Curr loss timestep torch.Size([579, 4]) tensor([502, 293, 267, 371], device='cuda:0') tensor(502, device='cuda:0')
bi 0 loss 0.24379701912403107
bi 1 loss 0.09128939360380173
bi 2 loss 0.10641461610794067
bi 3 loss 0.12071340531110764
Layer  2  loss:  0.17527523636817932 0.0 14.858783721923828
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1022
Curr loss timestep torch.Size([579, 4]) tensor([280, 293, 265, 389], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.2803754210472107
bi 1 loss 0.13289232552051544
bi 2 loss 0.05096551775932312
bi 3 loss 0.11887632310390472
Layer  3  loss:  0.17874589562416077 0.0 17.031267166137695
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([281, 281, 268, 389], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.25656858086586
bi 1 loss 0.1029990166425705
bi 2 loss 0.18868108093738556
bi 3 loss 0.16651780903339386
Layer  4  loss:  0.15582044422626495 0.0 8.538065910339355
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([502, 293, 268, 295], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.24984776973724365
bi 1 loss 0.12414681911468506
bi 2 loss 0.05963016301393509
bi 3 loss 0.08472349494695663
Layer  5  loss:  0.146882101893425 0.0 13.681299209594727
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1022
Curr loss timestep torch.Size([579, 4]) tensor([280, 292, 264, 319], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.24183902144432068
bi 1 loss 0.10524313896894455
bi 2 loss 0.04579256847500801
bi 3 loss 0.09617315977811813
Layer  6  loss:  0.15783467888832092 0.0 17.31447410583496
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([280, 281, 267, 255], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.2670177221298218
bi 1 loss 0.09524877369403839
bi 2 loss 0.10180968046188354
bi 3 loss 0.09450817853212357
Epoch 0: :   3%|▎         | 15688/600000 [04:47<2:58:15, v_num=12, reduced_train_loss=2.970, global_step=15686.0, consumed_samples=62748.0, train_step_timing in s=0.602]Epoch 0: :   3%|▎         | 15688/600000 [04:47<2:58:15, v_num=12, reduced_train_loss=1.230, global_step=15687.0, consumed_samples=62752.0, train_step_timing in s=0.426]loss mask original None

First layer loss:  3.374099016189575 torch.Size([660, 4]) 10.78042984008789 0.0
Max loss timestep torch.Size([660, 4]) tensor([245, 421,  95, 177], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 3.3644678592681885
speech mask sum tensor(449, device='cuda:0') loss mask sum tensor(449, device='cuda:0')
bi 1 loss 3.5282199382781982
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 2 loss 3.291898727416992
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 3 loss 3.0452239513397217
speech mask sum tensor(138, device='cuda:0') loss mask sum tensor(138, device='cuda:0')
logits torch.Size([660, 4, 257024]) labels torch.Size([660, 4]) 0 257023
Layer  0  loss:  4.1907501220703125 0.0 12.258030891418457
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1023
Curr loss timestep torch.Size([660, 4]) tensor([562, 281,  84, 246], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 4.036787033081055
bi 1 loss 4.517117500305176
bi 2 loss 4.078163146972656
bi 3 loss 3.8692052364349365
Layer  1  loss:  4.443716526031494 0.0 11.213424682617188
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1023
Curr loss timestep torch.Size([660, 4]) tensor([564, 376, 137, 179], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 4.365808486938477
bi 1 loss 4.601705074310303
bi 2 loss 4.4308929443359375
bi 3 loss 4.258584022521973
Layer  2  loss:  4.750244617462158 0.0 10.123796463012695
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1022
Curr loss timestep torch.Size([660, 4]) tensor([405, 279,  92, 183], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 4.570542812347412
bi 1 loss 5.113533020019531
bi 2 loss 4.454996109008789
bi 3 loss 4.584402561187744
Layer  3  loss:  4.83198356628418 0.0 9.623809814453125
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1021
Curr loss timestep torch.Size([660, 4]) tensor([472, 231,  72, 177], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 4.774583339691162
bi 1 loss 5.121750831604004
bi 2 loss 4.515639781951904
bi 3 loss 4.49860954284668
Layer  4  loss:  4.990816116333008 0.0 10.100971221923828
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1020
Curr loss timestep torch.Size([660, 4]) tensor([633, 230,  81, 172], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 4.84130859375
bi 1 loss 5.285627365112305
bi 2 loss 4.924070835113525
bi 3 loss 4.700357437133789
Layer  5  loss:  5.012568473815918 0.0 9.751940727233887
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1019
Curr loss timestep torch.Size([660, 4]) tensor([412, 482, 144, 257], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 4.819373607635498
bi 1 loss 5.322423458099365
bi 2 loss 4.8580241203308105
bi 3 loss 4.906557083129883
Layer  6  loss:  5.0373334884643555 0.0 10.882682800292969
logits torch.Size([660, 4, 1024]) labels torch.Size([660, 4]) 0 1023
Curr loss timestep torch.Size([660, 4]) tensor([265, 462,  68, 198], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 4.832945823669434
bi 1 loss 5.406454563140869
bi 2 loss 4.88095760345459
bi 3 loss 4.800311088562012
Epoch 0: :   3%|▎         | 15689/600000 [04:47<2:58:31, v_num=12, reduced_train_loss=1.230, global_step=15687.0, consumed_samples=62752.0, train_step_timing in s=0.426]Epoch 0: :   3%|▎         | 15689/600000 [04:47<2:58:31, v_num=12, reduced_train_loss=36.60, global_step=15688.0, consumed_samples=62756.0, train_step_timing in s=0.413]loss mask original None

First layer loss:  3.6388051509857178 torch.Size([392, 4]) 11.667814254760742 0.0
Max loss timestep torch.Size([392, 4]) tensor([324, 131, 100, 100], device='cuda:0') tensor(100, device='cuda:0')
bi 0 loss 3.425429105758667
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 1 loss 3.7842166423797607
speech mask sum tensor(219, device='cuda:0') loss mask sum tensor(219, device='cuda:0')
bi 2 loss 3.9043586254119873
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 3 loss 2.879948616027832
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
logits torch.Size([392, 4, 257024]) labels torch.Size([392, 4]) 0 257023
Layer  0  loss:  4.010086536407471 0.0 10.315818786621094
logits torch.Size([392, 4, 1024]) labels torch.Size([392, 4]) 0 1023
Curr loss timestep torch.Size([392, 4]) tensor([266,  57, 316, 122], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 3.833251714706421
bi 1 loss 4.334150314331055
bi 2 loss 3.8808469772338867
bi 3 loss 4.0984978675842285
Layer  1  loss:  4.391799449920654 0.0 10.30000114440918
logits torch.Size([392, 4, 1024]) labels torch.Size([392, 4]) 0 1022
Curr loss timestep torch.Size([392, 4]) tensor([232,  64, 267, 109], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 3.972073554992676
bi 1 loss 4.8087663650512695
bi 2 loss 4.587860107421875
bi 3 loss 3.727266550064087
Layer  2  loss:  4.824507236480713 0.0 10.199767112731934
logits torch.Size([392, 4, 1024]) labels torch.Size([392, 4]) 0 1023
Curr loss timestep torch.Size([392, 4]) tensor([250,  86, 117,  86], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.606204032897949
bi 1 loss 4.998126029968262
bi 2 loss 4.976251125335693
bi 3 loss 4.414724826812744
Layer  3  loss:  4.832081317901611 0.0 10.125284194946289
logits torch.Size([392, 4, 1024]) labels torch.Size([392, 4]) 0 1022
Curr loss timestep torch.Size([392, 4]) tensor([271, 224, 333,  90], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.342487812042236
bi 1 loss 4.870659351348877
bi 2 loss 5.179514408111572
bi 3 loss 4.8242669105529785
Layer  4  loss:  4.949059009552002 0.0 10.355443000793457
logits torch.Size([392, 4, 1024]) labels torch.Size([392, 4]) 0 1021
Curr loss timestep torch.Size([392, 4]) tensor([180, 132, 257,  98], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.615593910217285
bi 1 loss 5.098469257354736
bi 2 loss 5.139764785766602
bi 3 loss 4.780681133270264
Layer  5  loss:  5.032861232757568 0.0 9.577909469604492
logits torch.Size([392, 4, 1024]) labels torch.Size([392, 4]) 0 1021
Curr loss timestep torch.Size([392, 4]) tensor([188, 175, 237, 137], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 4.798851490020752
bi 1 loss 5.013219356536865
bi 2 loss 5.285428524017334
bi 3 loss 4.818572044372559
Layer  6  loss:  5.154236316680908 0.0 10.135196685791016
logits torch.Size([392, 4, 1024]) labels torch.Size([392, 4]) 0 1022
Curr loss timestep torch.Size([392, 4]) tensor([261, 201, 320, 102], device='cuda:0') tensor(102, device='cuda:0')
bi 0 loss 5.022607326507568
bi 1 loss 5.034939765930176
bi 2 loss 5.395827770233154
bi 3 loss 4.963545322418213
Epoch 0: :   3%|▎         | 15690/600000 [04:47<2:58:43, v_num=12, reduced_train_loss=36.60, global_step=15688.0, consumed_samples=62756.0, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15690/600000 [04:47<2:58:43, v_num=12, reduced_train_loss=36.80, global_step=15689.0, consumed_samples=62760.0, train_step_timing in s=0.304]loss mask original None

First layer loss:  3.968278408050537 torch.Size([436, 4]) 13.433406829833984 0.0
Max loss timestep torch.Size([436, 4]) tensor([398,  86, 122, 253], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 4.286001682281494
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
bi 1 loss 2.914827346801758
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 2 loss 3.411510944366455
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 3 loss 4.130885124206543
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
logits torch.Size([436, 4, 257024]) labels torch.Size([436, 4]) 0 257022
Layer  0  loss:  4.057464122772217 0.0 10.083045959472656
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([383,  52, 161, 235], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.208954334259033
bi 1 loss 3.124497890472412
bi 2 loss 3.8974103927612305
bi 3 loss 4.362362861633301
Layer  1  loss:  4.167895317077637 0.0 10.401082992553711
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([239,  68, 134, 235], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 4.411640167236328
bi 1 loss 3.4237453937530518
bi 2 loss 3.8411448001861572
bi 3 loss 4.149463176727295
Layer  2  loss:  4.420905113220215 0.0 9.360735893249512
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([144,  70, 115, 257], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 4.693593502044678
bi 1 loss 3.404486894607544
bi 2 loss 4.0420355796813965
bi 3 loss 4.55234956741333
Layer  3  loss:  4.611741542816162 0.0 9.822668075561523
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1021
Curr loss timestep torch.Size([436, 4]) tensor([176,  79, 149, 249], device='cuda:0') tensor(149, device='cuda:0')
bi 0 loss 4.912848472595215
bi 1 loss 3.446399211883545
bi 2 loss 4.2417426109313965
bi 3 loss 4.743926525115967
Layer  4  loss:  4.688625812530518 0.0 10.641011238098145
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1023
Curr loss timestep torch.Size([436, 4]) tensor([397,  91, 117, 253], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 4.989322185516357
bi 1 loss 3.57334303855896
bi 2 loss 4.307253360748291
bi 3 loss 4.795059680938721
Layer  5  loss:  4.841325283050537 0.0 9.67474365234375
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1017
Curr loss timestep torch.Size([436, 4]) tensor([398,  80, 163, 277], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 5.1210479736328125
bi 1 loss 4.0481767654418945
bi 2 loss 4.5312676429748535
bi 3 loss 4.712826728820801
Layer  6  loss:  4.8797783851623535 0.0 9.701589584350586
logits torch.Size([436, 4, 1024]) labels torch.Size([436, 4]) 0 1022
Curr loss timestep torch.Size([436, 4]) tensor([359,  76, 164, 251], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 5.200440406799316
bi 1 loss 3.659512519836426
bi 2 loss 4.528029441833496
bi 3 loss 4.9649553298950195
Epoch 0: :   3%|▎         | 15691/600000 [04:48<2:58:55, v_num=12, reduced_train_loss=36.80, global_step=15689.0, consumed_samples=62760.0, train_step_timing in s=0.304]Epoch 0: :   3%|▎         | 15691/600000 [04:48<2:58:55, v_num=12, reduced_train_loss=35.60, global_step=15690.0, consumed_samples=62764.0, train_step_timing in s=0.306]loss mask original None

First layer loss:  2.996731758117676 torch.Size([716, 4]) 10.476394653320312 0.0
Max loss timestep torch.Size([716, 4]) tensor([194, 620, 346, 346], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 3.263749122619629
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 1 loss 2.0679917335510254
speech mask sum tensor(447, device='cuda:0') loss mask sum tensor(447, device='cuda:0')
bi 2 loss 3.501316547393799
speech mask sum tensor(406, device='cuda:0') loss mask sum tensor(406, device='cuda:0')
bi 3 loss 3.799527645111084
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
logits torch.Size([716, 4, 257024]) labels torch.Size([716, 4]) 0 257023
Layer  0  loss:  3.5210628509521484 0.0 10.544979095458984
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([194, 605, 316, 165], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.131222724914551
bi 1 loss 2.521383285522461
bi 2 loss 4.162056922912598
bi 3 loss 4.104851245880127
Layer  1  loss:  3.848886013031006 0.0 9.518501281738281
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([187, 664, 309, 249], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.231216907501221
bi 1 loss 2.8872032165527344
bi 2 loss 4.459344387054443
bi 3 loss 4.491682052612305
Layer  2  loss:  4.024655818939209 0.0 9.74278736114502
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([179, 467, 355, 300], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 4.381430625915527
bi 1 loss 2.9074079990386963
bi 2 loss 4.724967002868652
bi 3 loss 4.81693172454834
Layer  3  loss:  4.03608512878418 0.0 9.607901573181152
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([184, 357, 594, 182], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 4.426403045654297
bi 1 loss 2.906344413757324
bi 2 loss 4.696718215942383
bi 3 loss 4.909111022949219
Layer  4  loss:  4.166821479797363 0.0 9.707130432128906
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([193, 302, 377, 319], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 4.343120574951172
bi 1 loss 2.9942660331726074
bi 2 loss 4.9471588134765625
bi 3 loss 4.988246917724609
Layer  5  loss:  4.324527740478516 0.0 11.668386459350586
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([162, 447, 581, 193], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 4.525722980499268
bi 1 loss 3.122934341430664
bi 2 loss 5.07680082321167
bi 3 loss 5.241090774536133
Layer  6  loss:  4.298542499542236 0.0 10.161178588867188
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([189, 448, 375, 342], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 4.558111667633057
bi 1 loss 3.040461301803589
bi 2 loss 5.0998687744140625
bi 3 loss 5.217686176300049
Epoch 0: :   3%|▎         | 15692/600000 [04:48<2:59:12, v_num=12, reduced_train_loss=35.60, global_step=15690.0, consumed_samples=62764.0, train_step_timing in s=0.306]Epoch 0: :   3%|▎         | 15692/600000 [04:48<2:59:12, v_num=12, reduced_train_loss=31.20, global_step=15691.0, consumed_samples=62768.0, train_step_timing in s=0.440]loss mask original None

First layer loss:  0.09210378676652908 torch.Size([465, 4]) 8.833815574645996 0.0
Max loss timestep torch.Size([465, 4]) tensor([376, 389, 268, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.1118970438838005
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 1 loss 0.053733568638563156
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
bi 2 loss 0.1194211095571518
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 3 loss 0.08460413664579391
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
logits torch.Size([465, 4, 257024]) labels torch.Size([465, 4]) 0 257022
Layer  0  loss:  0.09887593984603882 0.0 13.517106056213379
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([304, 153, 442, 262], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.10679977387189865
bi 1 loss 0.062461793422698975
bi 2 loss 0.14594104886054993
bi 3 loss 0.07405839115381241
Layer  1  loss:  0.10308006405830383 0.0 8.33965015411377
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([305, 287, 442, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.1554516702890396
bi 1 loss 0.052812933921813965
bi 2 loss 0.13976708054542542
bi 3 loss 0.07392747700214386
Layer  2  loss:  0.12460246682167053 0.0 10.838712692260742
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([305, 262, 442, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.12959425151348114
bi 1 loss 0.08929527550935745
bi 2 loss 0.13369567692279816
bi 3 loss 0.14595258235931396
Layer  3  loss:  0.10059235990047455 0.0 8.102941513061523
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1017
Curr loss timestep torch.Size([465, 4]) tensor([305, 369, 442, 383], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.08598004281520844
bi 1 loss 0.06599415838718414
bi 2 loss 0.1371687799692154
bi 3 loss 0.10200300067663193
Layer  4  loss:  0.1315847635269165 0.0 13.34859848022461
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([376, 125, 442, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.161325141787529
bi 1 loss 0.06444257497787476
bi 2 loss 0.17445874214172363
bi 3 loss 0.12771399319171906
Layer  5  loss:  0.1176348477602005 0.0 9.220778465270996
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([305, 268, 442, 262], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.10701687633991241
bi 1 loss 0.07797221839427948
bi 2 loss 0.14904385805130005
bi 3 loss 0.12755854427814484
Layer  6  loss:  0.10304613411426544 0.0 8.524123191833496
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1019
Curr loss timestep torch.Size([465, 4]) tensor([305, 376, 442, 262], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.09981197863817215
bi 1 loss 0.06879140436649323
bi 2 loss 0.14451321959495544
bi 3 loss 0.09042516350746155
Epoch 0: :   3%|▎         | 15693/600000 [04:49<2:59:25, v_num=12, reduced_train_loss=31.20, global_step=15691.0, consumed_samples=62768.0, train_step_timing in s=0.440]Epoch 0: :   3%|▎         | 15693/600000 [04:49<2:59:25, v_num=12, reduced_train_loss=0.872, global_step=15692.0, consumed_samples=62772.0, train_step_timing in s=0.333]loss mask original None

First layer loss:  3.565507650375366 torch.Size([560, 4]) 12.184760093688965 0.0
Max loss timestep torch.Size([560, 4]) tensor([162, 152, 277, 445], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 3.642563819885254
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
bi 1 loss 3.382875680923462
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 2 loss 3.8117055892944336
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 3 loss 3.603020668029785
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
logits torch.Size([560, 4, 257024]) labels torch.Size([560, 4]) 0 257023
Layer  0  loss:  4.129488468170166 0.0 10.080461502075195
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([268, 193, 276, 277], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.253870487213135
bi 1 loss 4.199755668640137
bi 2 loss 3.3448586463928223
bi 3 loss 4.173354148864746
Layer  1  loss:  4.526670455932617 0.0 10.809549331665039
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([168, 138, 280, 418], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 4.944378852844238
bi 1 loss 4.1949028968811035
bi 2 loss 4.303377151489258
bi 3 loss 4.584988117218018
Layer  2  loss:  4.883180141448975 0.0 10.857623100280762
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([136, 263, 295, 214], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 5.294878005981445
bi 1 loss 4.821448802947998
bi 2 loss 4.463076591491699
bi 3 loss 4.796460151672363
Layer  3  loss:  4.972805500030518 0.0 10.404993057250977
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1020
Curr loss timestep torch.Size([560, 4]) tensor([182, 370, 278, 528], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 5.360125541687012
bi 1 loss 4.811520576477051
bi 2 loss 4.640147686004639
bi 3 loss 4.950384616851807
Layer  4  loss:  4.985979080200195 0.0 11.008249282836914
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1023
Curr loss timestep torch.Size([560, 4]) tensor([223, 363, 293, 416], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 5.3973588943481445
bi 1 loss 4.811721324920654
bi 2 loss 4.554499626159668
bi 3 loss 4.979884624481201
Layer  5  loss:  5.188491344451904 0.0 10.559906005859375
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([313, 151, 289, 532], device='cuda:0') tensor(151, device='cuda:0')
bi 0 loss 5.549193382263184
bi 1 loss 5.0326738357543945
bi 2 loss 4.819827556610107
bi 3 loss 5.183313369750977
Layer  6  loss:  5.216798782348633 0.0 11.087837219238281
logits torch.Size([560, 4, 1024]) labels torch.Size([560, 4]) 0 1022
Curr loss timestep torch.Size([560, 4]) tensor([195, 173, 280, 183], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 5.609601020812988
bi 1 loss 5.085993766784668
bi 2 loss 4.725347995758057
bi 3 loss 5.202184200286865
Epoch 0: :   3%|▎         | 15694/600000 [04:49<2:59:39, v_num=12, reduced_train_loss=0.872, global_step=15692.0, consumed_samples=62772.0, train_step_timing in s=0.333]Epoch 0: :   3%|▎         | 15694/600000 [04:49<2:59:39, v_num=12, reduced_train_loss=37.50, global_step=15693.0, consumed_samples=62776.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  0.154495969414711 torch.Size([501, 4]) 9.737459182739258 0.0
Max loss timestep torch.Size([501, 4]) tensor([364, 302, 314, 281], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.08381370455026627
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
bi 1 loss 0.1619889885187149
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 2 loss 0.2156926542520523
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 3 loss 0.18562635779380798
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
logits torch.Size([501, 4, 257024]) labels torch.Size([501, 4]) 0 257022
Layer  0  loss:  0.1816512495279312 0.0 10.449657440185547
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1023
Curr loss timestep torch.Size([501, 4]) tensor([364, 302, 305, 226], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.11463561654090881
bi 1 loss 0.22235266864299774
bi 2 loss 0.27517396211624146
bi 3 loss 0.10703247040510178
Layer  1  loss:  0.17918820679187775 0.0 12.188307762145996
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1023
Curr loss timestep torch.Size([501, 4]) tensor([364, 302, 455, 218], device='cuda:0') tensor(455, device='cuda:0')
bi 0 loss 0.13180768489837646
bi 1 loss 0.1569863110780716
bi 2 loss 0.3110547363758087
bi 3 loss 0.10719054192304611
Layer  2  loss:  0.16353319585323334 0.0 11.214476585388184
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1022
Curr loss timestep torch.Size([501, 4]) tensor([365, 416, 359, 273], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.11695338040590286
bi 1 loss 0.18418152630329132
bi 2 loss 0.22389201819896698
bi 3 loss 0.13027174770832062
Layer  3  loss:  0.18977008759975433 0.0 10.929220199584961
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1020
Curr loss timestep torch.Size([501, 4]) tensor([364, 304, 305, 381], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.11674650758504868
bi 1 loss 0.2319507896900177
bi 2 loss 0.2876373827457428
bi 3 loss 0.11777565628290176
Layer  4  loss:  0.20381838083267212 0.0 14.497352600097656
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1022
Curr loss timestep torch.Size([501, 4]) tensor([405, 302, 455, 315], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.15523523092269897
bi 1 loss 0.18025076389312744
bi 2 loss 0.3345927596092224
bi 3 loss 0.13780194520950317
Layer  5  loss:  0.1838340014219284 0.0 10.998597145080566
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1023
Curr loss timestep torch.Size([501, 4]) tensor([364, 304, 314, 259], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.11173930764198303
bi 1 loss 0.21632607281208038
bi 2 loss 0.2778099775314331
bi 3 loss 0.13071325421333313
Layer  6  loss:  0.18676821887493134 0.0 9.645476341247559
logits torch.Size([501, 4, 1024]) labels torch.Size([501, 4]) 0 1019
Curr loss timestep torch.Size([501, 4]) tensor([364, 302, 314, 316], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.16216632723808289
bi 1 loss 0.17509810626506805
bi 2 loss 0.28271740674972534
bi 3 loss 0.10888209193944931
Epoch 0: :   3%|▎         | 15695/600000 [04:49<2:59:52, v_num=12, reduced_train_loss=37.50, global_step=15693.0, consumed_samples=62776.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15695/600000 [04:49<2:59:52, v_num=12, reduced_train_loss=1.440, global_step=15694.0, consumed_samples=62780.0, train_step_timing in s=0.351]loss mask original None

First layer loss:  0.0805952176451683 torch.Size([633, 4]) 8.506551742553711 0.0
Max loss timestep torch.Size([633, 4]) tensor([ 93,  55, 505, 167], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.015519922599196434
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 1 loss 0.030445754528045654
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 2 loss 0.12072653323411942
speech mask sum tensor(449, device='cuda:0') loss mask sum tensor(449, device='cuda:0')
bi 3 loss 0.036421045660972595
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
logits torch.Size([633, 4, 257024]) labels torch.Size([633, 4]) 0 257022
Layer  0  loss:  0.10499289631843567 0.0 12.033377647399902
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([105, 111, 505, 219], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.018885478377342224
bi 1 loss 0.018740037456154823
bi 2 loss 0.16266395151615143
bi 3 loss 0.045568134635686874
Layer  1  loss:  0.09643667191267014 0.0 10.941064834594727
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([ 64,  76, 505, 259], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.009721077047288418
bi 1 loss 0.04516526311635971
bi 2 loss 0.13545529544353485
bi 3 loss 0.06777724623680115
Layer  2  loss:  0.11166878044605255 0.0 9.10744857788086
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([ 93,  76, 307, 185], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.013197744265198708
bi 1 loss 0.057867296040058136
bi 2 loss 0.17060939967632294
bi 3 loss 0.03701615706086159
Layer  3  loss:  0.11092939972877502 0.0 8.892708778381348
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([ 85,  77, 307, 285], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.016511345282197
bi 1 loss 0.030770335346460342
bi 2 loss 0.1682540774345398
bi 3 loss 0.053509946912527084
Layer  4  loss:  0.09054017812013626 0.0 9.751333236694336
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([117, 116, 505, 171], device='cuda:0') tensor(505, device='cuda:0')
bi 0 loss 0.01655993051826954
bi 1 loss 0.03669685870409012
bi 2 loss 0.13603460788726807
bi 3 loss 0.038855358958244324
Layer  5  loss:  0.10160668939352036 0.0 9.597916603088379
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1021
Curr loss timestep torch.Size([633, 4]) tensor([106, 117, 306, 292], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.018749365583062172
bi 1 loss 0.05490204691886902
bi 2 loss 0.1545184999704361
bi 3 loss 0.030640125274658203
Layer  6  loss:  0.12480797618627548 0.0 13.297225952148438
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1020
Curr loss timestep torch.Size([633, 4]) tensor([ 95,  77, 306, 172], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.03881062567234039
bi 1 loss 0.03239625319838524
bi 2 loss 0.1921725571155548
bi 3 loss 0.04262835159897804
Epoch 0: :   3%|▎         | 15696/600000 [04:50<3:00:09, v_num=12, reduced_train_loss=1.440, global_step=15694.0, consumed_samples=62780.0, train_step_timing in s=0.351]Epoch 0: :   3%|▎         | 15696/600000 [04:50<3:00:09, v_num=12, reduced_train_loss=0.822, global_step=15695.0, consumed_samples=62784.0, train_step_timing in s=0.435]loss mask original None

First layer loss:  0.020103201270103455 torch.Size([447, 4]) 0.4556969404220581 0.0
Max loss timestep torch.Size([447, 4]) tensor([ 76, 221, 241, 327], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 0.016938425600528717
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
bi 1 loss 0.021784275770187378
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 2 loss 0.018509551882743835
speech mask sum tensor(158, device='cuda:0') loss mask sum tensor(158, device='cuda:0')
bi 3 loss 0.021634038537740707
speech mask sum tensor(262, device='cuda:0') loss mask sum tensor(262, device='cuda:0')
logits torch.Size([447, 4, 257024]) labels torch.Size([447, 4]) 0 257022
Layer  0  loss:  0.02064087986946106 0.0 0.5496809482574463
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([135, 108, 225, 333], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.019881930202245712
bi 1 loss 0.021794870495796204
bi 2 loss 0.0142435971647501
bi 3 loss 0.02405366860330105
Layer  1  loss:  0.02049924246966839 0.0 0.8992293477058411
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([120, 100, 179, 322], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.019029157236218452
bi 1 loss 0.017550963908433914
bi 2 loss 0.018760934472084045
bi 3 loss 0.024701593443751335
Layer  2  loss:  0.02360004372894764 0.0 0.5249338150024414
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([118, 179, 169, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.02438204549252987
bi 1 loss 0.020597541704773903
bi 2 loss 0.027658257633447647
bi 3 loss 0.02301645278930664
Layer  3  loss:  0.019494010135531425 0.0 0.4915176033973694
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1023
Curr loss timestep torch.Size([447, 4]) tensor([130, 220, 234, 400], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 0.023070717230439186
bi 1 loss 0.01982075907289982
bi 2 loss 0.017651528120040894
bi 3 loss 0.01823597028851509
Layer  4  loss:  0.02111315354704857 0.0 0.26552048325538635
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([155, 127, 246, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.019653907045722008
bi 1 loss 0.022117098793387413
bi 2 loss 0.02009926736354828
bi 3 loss 0.021810011938214302
Layer  5  loss:  0.01898731105029583 0.0 0.4558223485946655
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([130,  99, 121, 322], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 0.019925525411963463
bi 1 loss 0.017726166173815727
bi 2 loss 0.016928868368268013
bi 3 loss 0.020650755614042282
Layer  6  loss:  0.019895561039447784 0.0 0.40867921710014343
logits torch.Size([447, 4, 1024]) labels torch.Size([447, 4]) 0 1022
Curr loss timestep torch.Size([447, 4]) tensor([102, 191, 174, 328], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.01622786931693554
bi 1 loss 0.01804628036916256
bi 2 loss 0.019589951261878014
bi 3 loss 0.02368251420557499
Epoch 0: :   3%|▎         | 15697/600000 [04:50<3:00:22, v_num=12, reduced_train_loss=0.822, global_step=15695.0, consumed_samples=62784.0, train_step_timing in s=0.435]Epoch 0: :   3%|▎         | 15697/600000 [04:50<3:00:22, v_num=12, reduced_train_loss=0.164, global_step=15696.0, consumed_samples=62788.0, train_step_timing in s=0.324]loss mask original None

First layer loss:  0.028744403272867203 torch.Size([437, 4]) 0.8804283142089844 0.0
Max loss timestep torch.Size([437, 4]) tensor([140,  90, 268,  77], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.012670463882386684
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
bi 1 loss 0.008657819591462612
speech mask sum tensor(37, device='cuda:0') loss mask sum tensor(37, device='cuda:0')
bi 2 loss 0.04430777579545975
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 3 loss 0.024068668484687805
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
logits torch.Size([437, 4, 257024]) labels torch.Size([437, 4]) 0 257022
Layer  0  loss:  0.04101508855819702 0.0 2.226602554321289
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([ 81,  96, 393,  93], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.0180591382086277
bi 1 loss 0.01933547668159008
bi 2 loss 0.06629253178834915
bi 3 loss 0.020041026175022125
Layer  1  loss:  0.032024942338466644 0.0 0.7757829427719116
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([101,  93, 295,  80], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.016924334689974785
bi 1 loss 0.013154101558029652
bi 2 loss 0.04455976560711861
bi 3 loss 0.034762874245643616
Layer  2  loss:  0.032882917672395706 0.0 0.9375603199005127
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([159,  91, 369,  70], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.019282054156064987
bi 1 loss 0.016836930066347122
bi 2 loss 0.0413874126970768
bi 3 loss 0.0443442277610302
Layer  3  loss:  0.04050974175333977 0.0 2.4352965354919434
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1021
Curr loss timestep torch.Size([437, 4]) tensor([173,  91, 296,  89], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.019156549125909805
bi 1 loss 0.027088358998298645
bi 2 loss 0.061002206057310104
bi 3 loss 0.027598023414611816
Layer  4  loss:  0.036440134048461914 0.0 0.6783944964408875
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1020
Curr loss timestep torch.Size([437, 4]) tensor([157, 102, 302,  70], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.017696233466267586
bi 1 loss 0.014843315817415714
bi 2 loss 0.0560256689786911
bi 3 loss 0.025067631155252457
Layer  5  loss:  0.02565048448741436 0.0 0.5006815791130066
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([ 83, 106, 327,  99], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.017274750396609306
bi 1 loss 0.004983589518815279
bi 2 loss 0.0353800430893898
bi 3 loss 0.023310501128435135
Layer  6  loss:  0.03314400091767311 0.0 0.9600378274917603
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1020
Curr loss timestep torch.Size([437, 4]) tensor([135,  96, 325,  98], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.01320104394108057
bi 1 loss 0.006983834318816662
bi 2 loss 0.05727125331759453
bi 3 loss 0.011560220271348953
Epoch 0: :   3%|▎         | 15698/600000 [04:51<3:00:35, v_num=12, reduced_train_loss=0.164, global_step=15696.0, consumed_samples=62788.0, train_step_timing in s=0.324]Epoch 0: :   3%|▎         | 15698/600000 [04:51<3:00:35, v_num=12, reduced_train_loss=0.270, global_step=15697.0, consumed_samples=62792.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.12054605036973953 torch.Size([750, 4]) 7.0778584480285645 0.0
Max loss timestep torch.Size([750, 4]) tensor([694, 182, 150, 280], device='cuda:0') tensor(694, device='cuda:0')
bi 0 loss 0.20543219149112701
speech mask sum tensor(490, device='cuda:0') loss mask sum tensor(490, device='cuda:0')
bi 1 loss 0.01772180013358593
speech mask sum tensor(108, device='cuda:0') loss mask sum tensor(108, device='cuda:0')
bi 2 loss 0.027407027781009674
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
bi 3 loss 0.06671512871980667
speech mask sum tensor(338, device='cuda:0') loss mask sum tensor(338, device='cuda:0')
logits torch.Size([750, 4, 257024]) labels torch.Size([750, 4]) 0 257023
Layer  0  loss:  0.14808467030525208 0.0 8.417576789855957
logits torch.Size([750, 4, 1024]) labels torch.Size([750, 4]) 0 1023
Curr loss timestep torch.Size([750, 4]) tensor([694, 163, 104, 266], device='cuda:0') tensor(694, device='cuda:0')
bi 0 loss 0.2503996193408966
bi 1 loss 0.025171121582388878
bi 2 loss 0.03531584516167641
bi 3 loss 0.08307231217622757
Layer  1  loss:  0.14126430451869965 0.0 8.954744338989258
logits torch.Size([750, 4, 1024]) labels torch.Size([750, 4]) 0 1022
Curr loss timestep torch.Size([750, 4]) tensor([546, 176, 108, 276], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.23257966339588165
bi 1 loss 0.01840311661362648
bi 2 loss 0.033004067838191986
bi 3 loss 0.09042055159807205
Layer  2  loss:  0.15913431346416473 0.0 8.303007125854492
logits torch.Size([750, 4, 1024]) labels torch.Size([750, 4]) 0 1023
Curr loss timestep torch.Size([750, 4]) tensor([549, 186, 139, 275], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.2646336555480957
bi 1 loss 0.02916768379509449
bi 2 loss 0.07028251141309738
bi 3 loss 0.08241885155439377
Layer  3  loss:  0.16956086456775665 0.0 15.20108413696289
logits torch.Size([750, 4, 1024]) labels torch.Size([750, 4]) 0 1022
Curr loss timestep torch.Size([750, 4]) tensor([694, 191,  89, 276], device='cuda:0') tensor(694, device='cuda:0')
bi 0 loss 0.289650559425354
bi 1 loss 0.03674079477787018
bi 2 loss 0.039058931171894073
bi 3 loss 0.08887113630771637
Layer  4  loss:  0.14848297834396362 0.0 11.732781410217285
logits torch.Size([750, 4, 1024]) labels torch.Size([750, 4]) 0 1022
Curr loss timestep torch.Size([750, 4]) tensor([694, 223, 157, 266], device='cuda:0') tensor(694, device='cuda:0')
bi 0 loss 0.24159055948257446
bi 1 loss 0.02664625458419323
bi 2 loss 0.03447248786687851
bi 3 loss 0.09695941209793091
Layer  5  loss:  0.17700457572937012 0.0 13.232963562011719
logits torch.Size([750, 4, 1024]) labels torch.Size([750, 4]) 0 1023
Curr loss timestep torch.Size([750, 4]) tensor([694, 184, 101, 367], device='cuda:0') tensor(694, device='cuda:0')
bi 0 loss 0.30880600214004517
bi 1 loss 0.027959467843174934
bi 2 loss 0.031357474625110626
bi 3 loss 0.09043533354997635
Layer  6  loss:  0.20045383274555206 0.0 16.127368927001953
logits torch.Size([750, 4, 1024]) labels torch.Size([750, 4]) 0 1020
Curr loss timestep torch.Size([750, 4]) tensor([694, 188, 100, 402], device='cuda:0') tensor(694, device='cuda:0')
bi 0 loss 0.3600226044654846
bi 1 loss 0.030748864635825157
bi 2 loss 0.06622108072042465
bi 3 loss 0.07577381283044815
Epoch 0: :   3%|▎         | 15699/600000 [04:51<3:00:54, v_num=12, reduced_train_loss=0.270, global_step=15697.0, consumed_samples=62792.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15699/600000 [04:51<3:00:54, v_num=12, reduced_train_loss=1.260, global_step=15698.0, consumed_samples=62796.0, train_step_timing in s=0.512]loss mask original None

First layer loss:  3.876859188079834 torch.Size([556, 4]) 12.990948677062988 0.0
Max loss timestep torch.Size([556, 4]) tensor([529, 209, 176, 257], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 3.5619876384735107
speech mask sum tensor(344, device='cuda:0') loss mask sum tensor(344, device='cuda:0')
bi 1 loss 4.178689479827881
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
bi 2 loss 4.219598770141602
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 3 loss 3.6127476692199707
speech mask sum tensor(159, device='cuda:0') loss mask sum tensor(159, device='cuda:0')
logits torch.Size([556, 4, 257024]) labels torch.Size([556, 4]) 0 257022
Layer  0  loss:  4.371699333190918 0.0 12.009974479675293
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([236, 235, 161, 176], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 4.075057029724121
bi 1 loss 4.662805557250977
bi 2 loss 4.5553154945373535
bi 3 loss 4.210790634155273
Layer  1  loss:  4.8475823402404785 0.0 11.837442398071289
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([516, 301, 232, 249], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.531485080718994
bi 1 loss 5.149502754211426
bi 2 loss 5.26434326171875
bi 3 loss 4.530984401702881
Layer  2  loss:  5.006398677825928 0.0 11.006502151489258
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([444, 227, 194, 229], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 4.564579963684082
bi 1 loss 5.480680465698242
bi 2 loss 5.359405040740967
bi 3 loss 4.614522457122803
Layer  3  loss:  5.2057390213012695 0.0 11.330133438110352
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1021
Curr loss timestep torch.Size([556, 4]) tensor([280, 115, 177, 200], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 4.99484395980835
bi 1 loss 5.432619094848633
bi 2 loss 5.525064945220947
bi 3 loss 4.905632972717285
Layer  4  loss:  5.2616353034973145 0.0 9.773799896240234
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([399, 407, 212, 219], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 5.0784993171691895
bi 1 loss 5.568976402282715
bi 2 loss 5.3966145515441895
bi 3 loss 4.854081630706787
Layer  5  loss:  5.368834495544434 0.0 10.356050491333008
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1023
Curr loss timestep torch.Size([556, 4]) tensor([268, 136, 250, 230], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 5.268410682678223
bi 1 loss 5.612817764282227
bi 2 loss 5.544323921203613
bi 3 loss 4.897310256958008
Layer  6  loss:  5.427418231964111 0.0 10.630194664001465
logits torch.Size([556, 4, 1024]) labels torch.Size([556, 4]) 0 1022
Curr loss timestep torch.Size([556, 4]) tensor([468, 253, 177, 161], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 5.231660842895508
bi 1 loss 5.776151180267334
bi 2 loss 5.722334384918213
bi 3 loss 4.833717346191406
Epoch 0: :   3%|▎         | 15700/600000 [04:52<3:01:08, v_num=12, reduced_train_loss=1.260, global_step=15698.0, consumed_samples=62796.0, train_step_timing in s=0.512]Epoch 0: :   3%|▎         | 15700/600000 [04:52<3:01:08, v_num=12, reduced_train_loss=39.40, global_step=15699.0, consumed_samples=62800.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  3.6313111782073975 torch.Size([264, 4]) 10.029561996459961 0.0
Max loss timestep torch.Size([264, 4]) tensor([139, 134, 132, 226], device='cuda:0') tensor(132, device='cuda:0')
bi 0 loss 4.015616416931152
speech mask sum tensor(189, device='cuda:0') loss mask sum tensor(189, device='cuda:0')
bi 1 loss 2.9528212547302246
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 2 loss 3.464232921600342
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 3 loss 3.5198450088500977
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
logits torch.Size([264, 4, 257024]) labels torch.Size([264, 4]) 0 257022
Layer  0  loss:  4.182760238647461 0.0 9.254905700683594
logits torch.Size([264, 4, 1024]) labels torch.Size([264, 4]) 0 1023
Curr loss timestep torch.Size([264, 4]) tensor([ 88, 130,  89, 175], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 4.619253635406494
bi 1 loss 2.836385726928711
bi 2 loss 4.084871768951416
bi 3 loss 4.246345520019531
Layer  1  loss:  4.386858940124512 0.0 9.057233810424805
logits torch.Size([264, 4, 1024]) labels torch.Size([264, 4]) 0 1023
Curr loss timestep torch.Size([264, 4]) tensor([ 89, 147, 118, 187], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 4.790395259857178
bi 1 loss 3.0860884189605713
bi 2 loss 4.555245399475098
bi 3 loss 4.074786186218262
Layer  2  loss:  4.698098659515381 0.0 9.062437057495117
logits torch.Size([264, 4, 1024]) labels torch.Size([264, 4]) 0 1022
Curr loss timestep torch.Size([264, 4]) tensor([103, 142, 144, 226], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.932648181915283
bi 1 loss 3.4100613594055176
bi 2 loss 4.848127365112305
bi 3 loss 4.743448257446289
Layer  3  loss:  4.6292009353637695 0.0 9.242706298828125
logits torch.Size([264, 4, 1024]) labels torch.Size([264, 4]) 0 1023
Curr loss timestep torch.Size([264, 4]) tensor([189, 157,  87, 219], device='cuda:0') tensor(157, device='cuda:0')
bi 0 loss 4.885917663574219
bi 1 loss 3.08563232421875
bi 2 loss 4.957832336425781
bi 3 loss 4.50014066696167
Layer  4  loss:  4.828209400177002 0.0 9.256633758544922
logits torch.Size([264, 4, 1024]) labels torch.Size([264, 4]) 0 1023
Curr loss timestep torch.Size([264, 4]) tensor([128, 140, 174, 179], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 5.221149921417236
bi 1 loss 3.2614471912384033
bi 2 loss 4.992933750152588
bi 3 loss 4.696913719177246
Layer  5  loss:  4.966726779937744 0.0 9.629180908203125
logits torch.Size([264, 4, 1024]) labels torch.Size([264, 4]) 0 1015
Curr loss timestep torch.Size([264, 4]) tensor([205, 143, 115, 236], device='cuda:0') tensor(191, device='cuda:0')
bi 0 loss 5.217351913452148
bi 1 loss 3.6195228099823
bi 2 loss 5.148200035095215
bi 3 loss 4.965359210968018
Layer  6  loss:  4.959227085113525 0.0 11.348797798156738
logits torch.Size([264, 4, 1024]) labels torch.Size([264, 4]) 0 1023
Curr loss timestep torch.Size([264, 4]) tensor([ 92, 162, 210, 222], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 5.315451622009277
bi 1 loss 3.2639331817626953
bi 2 loss 5.160181522369385
bi 3 loss 4.918949127197266
Epoch 0: :   3%|▎         | 15701/600000 [04:52<3:01:18, v_num=12, reduced_train_loss=39.40, global_step=15699.0, consumed_samples=62800.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15701/600000 [04:52<3:01:18, v_num=12, reduced_train_loss=36.30, global_step=15700.0, consumed_samples=62804.0, train_step_timing in s=0.238]loss mask original None

First layer loss:  0.006628198549151421 torch.Size([325, 4]) 0.058020059019327164 0.0
Max loss timestep torch.Size([325, 4]) tensor([162, 288, 202,  85], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.005209252703934908
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 1 loss 0.007046298123896122
speech mask sum tensor(144, device='cuda:0') loss mask sum tensor(144, device='cuda:0')
bi 2 loss 0.006327900104224682
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 3 loss 0.00864832941442728
speech mask sum tensor(99, device='cuda:0') loss mask sum tensor(99, device='cuda:0')
logits torch.Size([325, 4, 257024]) labels torch.Size([325, 4]) 0 257022
Layer  0  loss:  0.006801226641982794 0.0 0.08499105274677277
logits torch.Size([325, 4, 1024]) labels torch.Size([325, 4]) 0 1023
Curr loss timestep torch.Size([325, 4]) tensor([199, 262, 170,  83], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.005256200674921274
bi 1 loss 0.007855165749788284
bi 2 loss 0.007621120661497116
bi 3 loss 0.006959991995245218
Layer  1  loss:  0.006433174014091492 0.0 0.15402087569236755
logits torch.Size([325, 4, 1024]) labels torch.Size([325, 4]) 0 1020
Curr loss timestep torch.Size([325, 4]) tensor([146, 300, 170, 103], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.004975415300577879
bi 1 loss 0.008008616045117378
bi 2 loss 0.005510492715984583
bi 3 loss 0.007468367926776409
Layer  2  loss:  0.005757517646998167 0.0 0.08470303565263748
logits torch.Size([325, 4, 1024]) labels torch.Size([325, 4]) 0 1022
Curr loss timestep torch.Size([325, 4]) tensor([124, 262, 169,  93], device='cuda:0') tensor(93, device='cuda:0')
bi 0 loss 0.0039164056070148945
bi 1 loss 0.006584796588867903
bi 2 loss 0.005298872943967581
bi 3 loss 0.00803484208881855
Layer  3  loss:  0.005783689208328724 0.0 0.060997720807790756
logits torch.Size([325, 4, 1024]) labels torch.Size([325, 4]) 0 1022
Curr loss timestep torch.Size([325, 4]) tensor([112, 262, 190,  75], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 0.004274079576134682
bi 1 loss 0.0067374310456216335
bi 2 loss 0.006648663897067308
bi 3 loss 0.005984250921756029
Layer  4  loss:  0.0061447955667972565 0.0 0.17277148365974426
logits torch.Size([325, 4, 1024]) labels torch.Size([325, 4]) 0 1022
Curr loss timestep torch.Size([325, 4]) tensor([124, 267, 221,  41], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.003733965801075101
bi 1 loss 0.008272310718894005
bi 2 loss 0.006818791385740042
bi 3 loss 0.006307609379291534
Layer  5  loss:  0.005928106606006622 0.0 0.0794127881526947
logits torch.Size([325, 4, 1024]) labels torch.Size([325, 4]) 0 1018
Curr loss timestep torch.Size([325, 4]) tensor([122, 268, 229,  77], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 0.004185524303466082
bi 1 loss 0.006424659863114357
bi 2 loss 0.006746299099177122
bi 3 loss 0.007222624029964209
Layer  6  loss:  0.005799936130642891 0.0 0.07456763088703156
logits torch.Size([325, 4, 1024]) labels torch.Size([325, 4]) 0 1019
Curr loss timestep torch.Size([325, 4]) tensor([139, 309, 170,  85], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 0.003975832834839821
bi 1 loss 0.007176558021456003
bi 2 loss 0.005699559580534697
bi 3 loss 0.0068848757073283195
Epoch 0: :   3%|▎         | 15702/600000 [04:52<3:01:28, v_num=12, reduced_train_loss=36.30, global_step=15700.0, consumed_samples=62804.0, train_step_timing in s=0.238]Epoch 0: :   3%|▎         | 15702/600000 [04:52<3:01:28, v_num=12, reduced_train_loss=0.0493, global_step=15701.0, consumed_samples=62808.0, train_step_timing in s=0.272]loss mask original None

First layer loss:  0.09085582941770554 torch.Size([534, 4]) 8.28830623626709 0.0
Max loss timestep torch.Size([534, 4]) tensor([134, 124, 364,  93], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.03469597548246384
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 1 loss 0.02586909756064415
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 2 loss 0.16482292115688324
speech mask sum tensor(281, device='cuda:0') loss mask sum tensor(281, device='cuda:0')
bi 3 loss 0.012807769700884819
speech mask sum tensor(49, device='cuda:0') loss mask sum tensor(49, device='cuda:0')
logits torch.Size([534, 4, 257024]) labels torch.Size([534, 4]) 0 257023
Layer  0  loss:  0.10579259693622589 0.0 9.691454887390137
logits torch.Size([534, 4, 1024]) labels torch.Size([534, 4]) 0 1023
Curr loss timestep torch.Size([534, 4]) tensor([121, 109, 362,  92], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.037395067512989044
bi 1 loss 0.020451625809073448
bi 2 loss 0.19681361317634583
bi 3 loss 0.014217381365597248
Layer  1  loss:  0.1028108224272728 0.0 12.298174858093262
logits torch.Size([534, 4, 1024]) labels torch.Size([534, 4]) 0 1023
Curr loss timestep torch.Size([534, 4]) tensor([221, 102, 363,  89], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.04161854460835457
bi 1 loss 0.020639309659600258
bi 2 loss 0.18620915710926056
bi 3 loss 0.017924319952726364
Layer  2  loss:  0.09114640951156616 0.0 9.294669151306152
logits torch.Size([534, 4, 1024]) labels torch.Size([534, 4]) 0 1022
Curr loss timestep torch.Size([534, 4]) tensor([ 68, 115, 380,  95], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.027325011789798737
bi 1 loss 0.028741708025336266
bi 2 loss 0.17174869775772095
bi 3 loss 0.005914227105677128
Layer  3  loss:  0.08240474760532379 0.0 8.47130298614502
logits torch.Size([534, 4, 1024]) labels torch.Size([534, 4]) 0 1023
Curr loss timestep torch.Size([534, 4]) tensor([148, 112, 363,  90], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.030819008126854897
bi 1 loss 0.033693257719278336
bi 2 loss 0.14699728786945343
bi 3 loss 0.01423629093915224
Layer  4  loss:  0.09997637569904327 0.0 13.268674850463867
logits torch.Size([534, 4, 1024]) labels torch.Size([534, 4]) 0 1022
Curr loss timestep torch.Size([534, 4]) tensor([233, 146, 363,  96], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.03554530441761017
bi 1 loss 0.04653092846274376
bi 2 loss 0.1770414561033249
bi 3 loss 0.0249796062707901
Layer  5  loss:  0.1192752793431282 0.0 15.961823463439941
logits torch.Size([534, 4, 1024]) labels torch.Size([534, 4]) 0 1023
Curr loss timestep torch.Size([534, 4]) tensor([233, 134, 363,  95], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.032917752861976624
bi 1 loss 0.06470032781362534
bi 2 loss 0.2187209278345108
bi 3 loss 0.016439126804471016
Layer  6  loss:  0.13985712826251984 0.0 13.844615936279297
logits torch.Size([534, 4, 1024]) labels torch.Size([534, 4]) 0 1022
Curr loss timestep torch.Size([534, 4]) tensor([223, 138, 380,  94], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.05756530538201332
bi 1 loss 0.025046976283192635
bi 2 loss 0.25365152955055237
bi 3 loss 0.022448552772402763
Epoch 0: :   3%|▎         | 15703/600000 [04:53<3:01:43, v_num=12, reduced_train_loss=0.0493, global_step=15701.0, consumed_samples=62808.0, train_step_timing in s=0.272]Epoch 0: :   3%|▎         | 15703/600000 [04:53<3:01:43, v_num=12, reduced_train_loss=0.832, global_step=15702.0, consumed_samples=62812.0, train_step_timing in s=0.373] loss mask original None

First layer loss:  0.16046258807182312 torch.Size([691, 4]) 10.91076374053955 0.0
Max loss timestep torch.Size([691, 4]) tensor([293, 390, 506, 313], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.07940958440303802
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 1 loss 0.1313159018754959
speech mask sum tensor(285, device='cuda:0') loss mask sum tensor(285, device='cuda:0')
bi 2 loss 0.2928103506565094
speech mask sum tensor(491, device='cuda:0') loss mask sum tensor(491, device='cuda:0')
bi 3 loss 0.06285274773836136
speech mask sum tensor(432, device='cuda:0') loss mask sum tensor(432, device='cuda:0')
logits torch.Size([691, 4, 257024]) labels torch.Size([691, 4]) 0 257023
Layer  0  loss:  0.16946479678153992 0.0 15.439754486083984
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([293, 314, 643, 413], device='cuda:0') tensor(643, device='cuda:0')
bi 0 loss 0.10657404363155365
bi 1 loss 0.1495552510023117
bi 2 loss 0.2862178087234497
bi 3 loss 0.07596000283956528
Layer  1  loss:  0.19951112568378448 0.0 8.636184692382812
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([293, 262, 640, 413], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.14822229743003845
bi 1 loss 0.2077653706073761
bi 2 loss 0.325967013835907
bi 3 loss 0.07159077376127243
Layer  2  loss:  0.22110603749752045 0.0 13.75948715209961
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([293, 314, 506, 314], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.18288210034370422
bi 1 loss 0.1713366061449051
bi 2 loss 0.3970164656639099
bi 3 loss 0.06984297931194305
Layer  3  loss:  0.22530315816402435 0.0 15.78342056274414
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([293, 390, 507, 413], device='cuda:0') tensor(507, device='cuda:0')
bi 0 loss 0.13418319821357727
bi 1 loss 0.14257130026817322
bi 2 loss 0.44736647605895996
bi 3 loss 0.06524750590324402
Layer  4  loss:  0.22354088723659515 0.0 10.853931427001953
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([293, 314, 558, 413], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.14091856777668
bi 1 loss 0.1652609407901764
bi 2 loss 0.424861341714859
bi 3 loss 0.06740854680538177
Layer  5  loss:  0.2501942813396454 0.0 12.602726936340332
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([293, 326, 643, 413], device='cuda:0') tensor(643, device='cuda:0')
bi 0 loss 0.16504546999931335
bi 1 loss 0.19197238981723785
bi 2 loss 0.4364510178565979
bi 3 loss 0.11219153553247452
Layer  6  loss:  0.23160532116889954 0.0 14.741684913635254
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1019
Curr loss timestep torch.Size([691, 4]) tensor([291, 314, 506, 327], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.1654309332370758
bi 1 loss 0.14271099865436554
bi 2 loss 0.4209316074848175
bi 3 loss 0.10248702019453049
Epoch 0: :   3%|▎         | 15704/600000 [04:53<3:02:02, v_num=12, reduced_train_loss=0.832, global_step=15702.0, consumed_samples=62812.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15704/600000 [04:53<3:02:02, v_num=12, reduced_train_loss=1.680, global_step=15703.0, consumed_samples=62816.0, train_step_timing in s=0.505]loss mask original None

First layer loss:  3.8471031188964844 torch.Size([604, 4]) 9.997035026550293 0.0
Max loss timestep torch.Size([604, 4]) tensor([296, 196, 307, 103], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 3.4540657997131348
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
bi 1 loss 3.56704044342041
speech mask sum tensor(68, device='cuda:0') loss mask sum tensor(68, device='cuda:0')
bi 2 loss 4.248082637786865
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
bi 3 loss 3.6475393772125244
speech mask sum tensor(308, device='cuda:0') loss mask sum tensor(308, device='cuda:0')
logits torch.Size([604, 4, 257024]) labels torch.Size([604, 4]) 0 257023
Layer  0  loss:  4.43473482131958 0.0 11.861394882202148
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([274, 191, 424, 122], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 4.120595455169678
bi 1 loss 4.047863006591797
bi 2 loss 4.814774036407471
bi 3 loss 4.2362060546875
Layer  1  loss:  4.6614813804626465 0.0 10.361966133117676
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([249, 209, 270, 381], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 4.203607559204102
bi 1 loss 4.223669528961182
bi 2 loss 5.004174709320068
bi 3 loss 4.610377788543701
Layer  2  loss:  4.7689433097839355 0.0 9.585588455200195
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([362, 175, 281, 163], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 4.4760870933532715
bi 1 loss 4.134663105010986
bi 2 loss 5.08528995513916
bi 3 loss 4.692073345184326
Layer  3  loss:  4.952280521392822 0.0 10.376757621765137
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([236, 192, 469, 109], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 4.669361591339111
bi 1 loss 4.188541412353516
bi 2 loss 5.270076274871826
bi 3 loss 4.8960041999816895
Layer  4  loss:  5.175259113311768 0.0 10.996289253234863
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1021
Curr loss timestep torch.Size([604, 4]) tensor([338, 178, 239, 291], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 4.849503993988037
bi 1 loss 4.574725151062012
bi 2 loss 5.511559963226318
bi 3 loss 5.0862040519714355
Layer  5  loss:  5.277632236480713 0.0 10.32550048828125
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([316, 215, 471, 215], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 5.004941463470459
bi 1 loss 4.42210578918457
bi 2 loss 5.613559246063232
bi 3 loss 5.212436199188232
Layer  6  loss:  5.293280601501465 0.0 11.300537109375
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([239, 172, 593, 167], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 4.975317001342773
bi 1 loss 4.888591766357422
bi 2 loss 5.5753607749938965
bi 3 loss 5.224457263946533
Epoch 0: :   3%|▎         | 15705/600000 [04:53<3:02:17, v_num=12, reduced_train_loss=1.680, global_step=15703.0, consumed_samples=62816.0, train_step_timing in s=0.505]Epoch 0: :   3%|▎         | 15705/600000 [04:53<3:02:17, v_num=12, reduced_train_loss=38.40, global_step=15704.0, consumed_samples=62820.0, train_step_timing in s=0.383]loss mask original None

First layer loss:  0.04204086586833 torch.Size([367, 4]) 0.810775637626648 0.0
Max loss timestep torch.Size([367, 4]) tensor([222, 158, 257, 344], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 0.03283548355102539
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 1 loss 0.0265826266258955
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 2 loss 0.04912275820970535
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 3 loss 0.0579395554959774
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
logits torch.Size([367, 4, 257024]) labels torch.Size([367, 4]) 0 257022
Layer  0  loss:  0.04267227649688721 0.0 4.6110520362854
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1023
Curr loss timestep torch.Size([367, 4]) tensor([107, 290, 222, 128], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.035846807062625885
bi 1 loss 0.05463842302560806
bi 2 loss 0.04377763345837593
bi 3 loss 0.04050543159246445
Layer  1  loss:  0.04490786790847778 0.0 1.4983631372451782
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1023
Curr loss timestep torch.Size([367, 4]) tensor([262, 290, 222, 332], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.036120545119047165
bi 1 loss 0.04727886989712715
bi 2 loss 0.05430740490555763
bi 3 loss 0.048235662281513214
Layer  2  loss:  0.0330669991672039 0.0 1.2063133716583252
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1023
Curr loss timestep torch.Size([367, 4]) tensor([265, 290, 249, 334], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.02873695082962513
bi 1 loss 0.025579135864973068
bi 2 loss 0.02914031594991684
bi 3 loss 0.04279358312487602
Layer  3  loss:  0.044111937284469604 0.0 2.657470703125
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1022
Curr loss timestep torch.Size([367, 4]) tensor([277, 290, 242, 332], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.035799335688352585
bi 1 loss 0.04723741114139557
bi 2 loss 0.024145156145095825
bi 3 loss 0.05507059395313263
Layer  4  loss:  0.04256700351834297 0.0 1.0293079614639282
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1020
Curr loss timestep torch.Size([367, 4]) tensor([140, 290, 223, 330], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 0.035495832562446594
bi 1 loss 0.036258451640605927
bi 2 loss 0.03377991542220116
bi 3 loss 0.055310431867837906
Layer  5  loss:  0.04097990691661835 0.0 2.650843858718872
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1023
Curr loss timestep torch.Size([367, 4]) tensor([276, 293, 257, 313], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.04087815806269646
bi 1 loss 0.03138412907719612
bi 2 loss 0.025810491293668747
bi 3 loss 0.05168267339468002
Layer  6  loss:  0.03355108201503754 0.0 1.4120278358459473
logits torch.Size([367, 4, 1024]) labels torch.Size([367, 4]) 0 1023
Curr loss timestep torch.Size([367, 4]) tensor([150, 290, 244, 345], device='cuda:0') tensor(290, device='cuda:0')
bi 0 loss 0.03042379952967167
bi 1 loss 0.03332725912332535
bi 2 loss 0.031243758276104927
bi 3 loss 0.03706793114542961
Epoch 0: :   3%|▎         | 15706/600000 [04:54<3:02:28, v_num=12, reduced_train_loss=38.40, global_step=15704.0, consumed_samples=62820.0, train_step_timing in s=0.383]Epoch 0: :   3%|▎         | 15706/600000 [04:54<3:02:28, v_num=12, reduced_train_loss=0.324, global_step=15705.0, consumed_samples=62824.0, train_step_timing in s=0.283]loss mask original None

First layer loss:  0.04772951081395149 torch.Size([497, 4]) 2.4666969776153564 0.0
Max loss timestep torch.Size([497, 4]) tensor([418, 245, 202, 105], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.06075477972626686
speech mask sum tensor(419, device='cuda:0') loss mask sum tensor(419, device='cuda:0')
bi 1 loss 0.041883062571287155
speech mask sum tensor(126, device='cuda:0') loss mask sum tensor(126, device='cuda:0')
bi 2 loss 0.03482571244239807
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
bi 3 loss 0.03423532843589783
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
logits torch.Size([497, 4, 257024]) labels torch.Size([497, 4]) 0 257022
Layer  0  loss:  0.04880042374134064 0.0 2.6561994552612305
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([280, 262, 352,  75], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.06413182616233826
bi 1 loss 0.03569401800632477
bi 2 loss 0.032859526574611664
bi 3 loss 0.04040852561593056
Layer  1  loss:  0.050574835389852524 0.0 4.857903003692627
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([320, 254, 351, 116], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.06688452512025833
bi 1 loss 0.04593643918633461
bi 2 loss 0.03635884448885918
bi 3 loss 0.027518458664417267
Layer  2  loss:  0.04888342693448067 0.0 4.912090301513672
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([320, 283, 184, 126], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.0681968703866005
bi 1 loss 0.028444340452551842
bi 2 loss 0.029708879068493843
bi 3 loss 0.04053565859794617
Layer  3  loss:  0.048073336482048035 0.0 2.9419898986816406
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([320, 278, 353,  77], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.05538468435406685
bi 1 loss 0.047002073377370834
bi 2 loss 0.0534733422100544
bi 3 loss 0.015407157130539417
Layer  4  loss:  0.05323221534490585 0.0 2.9389867782592773
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([320, 182, 336, 125], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.06893675774335861
bi 1 loss 0.05681837722659111
bi 2 loss 0.03530510142445564
bi 3 loss 0.0307871513068676
Layer  5  loss:  0.05997070297598839 0.0 6.7174296379089355
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([320, 235, 268,  89], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.07983085513114929
bi 1 loss 0.050997234880924225
bi 2 loss 0.04917403683066368
bi 3 loss 0.023361969739198685
Layer  6  loss:  0.04948717728257179 0.0 1.86733078956604
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([320, 270, 277,  99], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.0534886009991169
bi 1 loss 0.05230565741658211
bi 2 loss 0.04316502436995506
bi 3 loss 0.045073240995407104
Epoch 0: :   3%|▎         | 15707/600000 [04:54<3:02:42, v_num=12, reduced_train_loss=0.324, global_step=15705.0, consumed_samples=62824.0, train_step_timing in s=0.283]Epoch 0: :   3%|▎         | 15707/600000 [04:54<3:02:42, v_num=12, reduced_train_loss=0.407, global_step=15706.0, consumed_samples=62828.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  0.18409933149814606 torch.Size([742, 4]) 12.72890853881836 0.0
Max loss timestep torch.Size([742, 4]) tensor([599, 449, 274, 255], device='cuda:0') tensor(599, device='cuda:0')
bi 0 loss 0.29779526591300964
speech mask sum tensor(411, device='cuda:0') loss mask sum tensor(411, device='cuda:0')
bi 1 loss 0.17733748257160187
speech mask sum tensor(387, device='cuda:0') loss mask sum tensor(387, device='cuda:0')
bi 2 loss 0.11678528785705566
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 3 loss 0.12576313316822052
speech mask sum tensor(350, device='cuda:0') loss mask sum tensor(350, device='cuda:0')
logits torch.Size([742, 4, 257024]) labels torch.Size([742, 4]) 0 257023
Layer  0  loss:  0.2060905396938324 0.0 14.976461410522461
logits torch.Size([742, 4, 1024]) labels torch.Size([742, 4]) 0 1023
Curr loss timestep torch.Size([742, 4]) tensor([594, 312, 274, 484], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.4047486484050751
bi 1 loss 0.2030201256275177
bi 2 loss 0.10901089012622833
bi 3 loss 0.0738385021686554
Layer  1  loss:  0.23527978360652924 0.0 13.037466049194336
logits torch.Size([742, 4, 1024]) labels torch.Size([742, 4]) 0 1022
Curr loss timestep torch.Size([742, 4]) tensor([395, 449, 274, 284], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.3863601088523865
bi 1 loss 0.2255728542804718
bi 2 loss 0.2172073870897293
bi 3 loss 0.08677711337804794
Layer  2  loss:  0.2382383793592453 0.0 13.828811645507812
logits torch.Size([742, 4, 1024]) labels torch.Size([742, 4]) 0 1022
Curr loss timestep torch.Size([742, 4]) tensor([396, 449, 274, 424], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.38537389039993286
bi 1 loss 0.22235369682312012
bi 2 loss 0.2228565216064453
bi 3 loss 0.09849298000335693
Layer  3  loss:  0.24779903888702393 0.0 10.828847885131836
logits torch.Size([742, 4, 1024]) labels torch.Size([742, 4]) 0 1023
Curr loss timestep torch.Size([742, 4]) tensor([394, 449, 274, 179], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.4652879238128662
bi 1 loss 0.19167351722717285
bi 2 loss 0.1896243691444397
bi 3 loss 0.11297077685594559
Layer  4  loss:  0.23723195493221283 0.0 13.045892715454102
logits torch.Size([742, 4, 1024]) labels torch.Size([742, 4]) 0 1023
Curr loss timestep torch.Size([742, 4]) tensor([688, 327, 362, 334], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.40515539050102234
bi 1 loss 0.21598504483699799
bi 2 loss 0.20973096787929535
bi 3 loss 0.09119299799203873
Layer  5  loss:  0.22584696114063263 0.0 14.189764976501465
logits torch.Size([742, 4, 1024]) labels torch.Size([742, 4]) 0 1023
Curr loss timestep torch.Size([742, 4]) tensor([396, 447, 274, 279], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.374504953622818
bi 1 loss 0.2271856814622879
bi 2 loss 0.19903670251369476
bi 3 loss 0.07676330208778381
Layer  6  loss:  0.23110052943229675 0.0 15.40418815612793
logits torch.Size([742, 4, 1024]) labels torch.Size([742, 4]) 0 1023
Curr loss timestep torch.Size([742, 4]) tensor([594, 448, 274, 331], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.3929574489593506
bi 1 loss 0.19924436509609222
bi 2 loss 0.19644004106521606
bi 3 loss 0.11111666262149811
Epoch 0: :   3%|▎         | 15708/600000 [04:55<3:03:01, v_num=12, reduced_train_loss=0.407, global_step=15706.0, consumed_samples=62828.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15708/600000 [04:55<3:03:01, v_num=12, reduced_train_loss=1.810, global_step=15707.0, consumed_samples=62832.0, train_step_timing in s=0.502]loss mask original None

First layer loss:  0.11757027357816696 torch.Size([595, 4]) 9.378705978393555 0.0
Max loss timestep torch.Size([595, 4]) tensor([301, 550,  80, 317], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.10042575746774673
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
bi 1 loss 0.16678689420223236
speech mask sum tensor(502, device='cuda:0') loss mask sum tensor(502, device='cuda:0')
bi 2 loss 0.034432392567396164
speech mask sum tensor(168, device='cuda:0') loss mask sum tensor(168, device='cuda:0')
bi 3 loss 0.09558755159378052
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
logits torch.Size([595, 4, 257024]) labels torch.Size([595, 4]) 0 257023
Layer  0  loss:  0.12621943652629852 0.0 14.783254623413086
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([283, 554, 104, 317], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.056651521474123
bi 1 loss 0.20376500487327576
bi 2 loss 0.05645838752388954
bi 3 loss 0.08126351982355118
Layer  1  loss:  0.13357959687709808 0.0 13.615873336791992
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([323, 553, 147, 316], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.07803937047719955
bi 1 loss 0.1932568997144699
bi 2 loss 0.06786197423934937
bi 3 loss 0.10526791214942932
Layer  2  loss:  0.16645599901676178 0.0 16.427387237548828
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1022
Curr loss timestep torch.Size([595, 4]) tensor([320, 553, 103, 349], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.055421482771635056
bi 1 loss 0.27104902267456055
bi 2 loss 0.07748428732156754
bi 3 loss 0.11056092381477356
Layer  3  loss:  0.15432941913604736 0.0 16.27429962158203
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([271, 550, 168, 349], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.042924050241708755
bi 1 loss 0.26675283908843994
bi 2 loss 0.0865911990404129
bi 3 loss 0.07832146435976028
Layer  4  loss:  0.1825471967458725 0.0 15.534671783447266
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1022
Curr loss timestep torch.Size([595, 4]) tensor([239, 550, 139, 316], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.08100588619709015
bi 1 loss 0.3215291202068329
bi 2 loss 0.04586021229624748
bi 3 loss 0.09776000678539276
Layer  5  loss:  0.16432078182697296 0.0 11.385361671447754
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([301, 553, 183, 316], device='cuda:0') tensor(553, device='cuda:0')
bi 0 loss 0.19820542633533478
bi 1 loss 0.24250128865242004
bi 2 loss 0.03893974423408508
bi 3 loss 0.10125842690467834
Layer  6  loss:  0.17499856650829315 0.0 16.844497680664062
logits torch.Size([595, 4, 1024]) labels torch.Size([595, 4]) 0 1023
Curr loss timestep torch.Size([595, 4]) tensor([297, 554, 158, 316], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.1077210009098053
bi 1 loss 0.2726009786128998
bi 2 loss 0.06374075263738632
bi 3 loss 0.12073126435279846
Epoch 0: :   3%|▎         | 15709/600000 [04:55<3:03:17, v_num=12, reduced_train_loss=1.810, global_step=15707.0, consumed_samples=62832.0, train_step_timing in s=0.502]Epoch 0: :   3%|▎         | 15709/600000 [04:55<3:03:17, v_num=12, reduced_train_loss=1.220, global_step=15708.0, consumed_samples=62836.0, train_step_timing in s=0.410]loss mask original None

First layer loss:  3.734955310821533 torch.Size([408, 4]) 11.510286331176758 0.0
Max loss timestep torch.Size([408, 4]) tensor([204, 272, 251, 101], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 3.222111940383911
speech mask sum tensor(75, device='cuda:0') loss mask sum tensor(75, device='cuda:0')
bi 1 loss 3.742055654525757
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 2 loss 3.2447643280029297
speech mask sum tensor(76, device='cuda:0') loss mask sum tensor(76, device='cuda:0')
bi 3 loss 3.9745798110961914
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
logits torch.Size([408, 4, 257024]) labels torch.Size([408, 4]) 0 257022
Layer  0  loss:  4.02656888961792 0.0 10.310257911682129
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1023
Curr loss timestep torch.Size([408, 4]) tensor([174, 301, 229, 185], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 3.3701260089874268
bi 1 loss 3.7782719135284424
bi 2 loss 3.8009843826293945
bi 3 loss 4.402483940124512
Layer  1  loss:  4.4653143882751465 0.0 11.338736534118652
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1022
Curr loss timestep torch.Size([408, 4]) tensor([216, 214, 210, 225], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 3.651287317276001
bi 1 loss 4.324069976806641
bi 2 loss 4.678109645843506
bi 3 loss 4.702124118804932
Layer  2  loss:  4.625794887542725 0.0 9.988739013671875
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1022
Curr loss timestep torch.Size([408, 4]) tensor([211, 312, 221, 341], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 3.938345432281494
bi 1 loss 4.47412109375
bi 2 loss 4.686112880706787
bi 3 loss 4.876159191131592
Layer  3  loss:  4.739095211029053 0.0 9.633764266967773
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1022
Curr loss timestep torch.Size([408, 4]) tensor([212, 223, 247, 247], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 4.066467761993408
bi 1 loss 4.5419602394104
bi 2 loss 4.698276042938232
bi 3 loss 5.040289878845215
Layer  4  loss:  5.058969974517822 0.0 10.86154556274414
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1022
Curr loss timestep torch.Size([408, 4]) tensor([196, 235, 195, 331], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 4.0825886726379395
bi 1 loss 4.839557647705078
bi 2 loss 5.259130954742432
bi 3 loss 5.3890910148620605
Layer  5  loss:  4.987804412841797 0.0 9.438312530517578
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1023
Curr loss timestep torch.Size([408, 4]) tensor([185, 300, 212, 256], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 3.9930028915405273
bi 1 loss 4.794097900390625
bi 2 loss 5.182399749755859
bi 3 loss 5.3069963455200195
Layer  6  loss:  5.005871295928955 0.0 9.365945816040039
logits torch.Size([408, 4, 1024]) labels torch.Size([408, 4]) 0 1022
Curr loss timestep torch.Size([408, 4]) tensor([220, 301, 227, 271], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.041748046875
bi 1 loss 4.808950424194336
bi 2 loss 5.194880485534668
bi 3 loss 5.321105480194092
Epoch 0: :   3%|▎         | 15710/600000 [04:56<3:03:29, v_num=12, reduced_train_loss=1.220, global_step=15708.0, consumed_samples=62836.0, train_step_timing in s=0.410]Epoch 0: :   3%|▎         | 15710/600000 [04:56<3:03:29, v_num=12, reduced_train_loss=36.60, global_step=15709.0, consumed_samples=62840.0, train_step_timing in s=0.294]loss mask original None

First layer loss:  3.5049595832824707 torch.Size([632, 4]) 13.140820503234863 0.0
Max loss timestep torch.Size([632, 4]) tensor([547, 217, 146, 389], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 3.336991786956787
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 1 loss 3.5378832817077637
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 2 loss 3.37404203414917
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
bi 3 loss 3.7761597633361816
speech mask sum tensor(303, device='cuda:0') loss mask sum tensor(303, device='cuda:0')
logits torch.Size([632, 4, 257024]) labels torch.Size([632, 4]) 0 257023
Layer  0  loss:  4.0875420570373535 0.0 10.245841026306152
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1023
Curr loss timestep torch.Size([632, 4]) tensor([433, 322, 115, 425], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 3.992110252380371
bi 1 loss 4.149049758911133
bi 2 loss 4.174010276794434
bi 3 loss 4.152108192443848
Layer  1  loss:  4.461130619049072 0.0 10.608864784240723
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1022
Curr loss timestep torch.Size([632, 4]) tensor([554, 219, 139, 441], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 4.390072822570801
bi 1 loss 4.2519145011901855
bi 2 loss 4.806449890136719
bi 3 loss 4.54766845703125
Layer  2  loss:  4.71030330657959 0.0 10.439936637878418
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1022
Curr loss timestep torch.Size([632, 4]) tensor([351, 320,  83, 403], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 4.446147918701172
bi 1 loss 4.784846782684326
bi 2 loss 5.058525562286377
bi 3 loss 4.902080059051514
Layer  3  loss:  4.908631324768066 0.0 10.053091049194336
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1022
Curr loss timestep torch.Size([632, 4]) tensor([450, 303,  98, 432], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 4.715824604034424
bi 1 loss 4.960771560668945
bi 2 loss 4.947933673858643
bi 3 loss 5.13575553894043
Layer  4  loss:  4.980013847351074 0.0 11.11175537109375
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1022
Curr loss timestep torch.Size([632, 4]) tensor([356, 367,  78, 465], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 4.794803142547607
bi 1 loss 5.081486225128174
bi 2 loss 5.279899597167969
bi 3 loss 5.063150882720947
Layer  5  loss:  5.093713283538818 0.0 10.345293045043945
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1023
Curr loss timestep torch.Size([632, 4]) tensor([454, 256,  72, 280], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 4.965453624725342
bi 1 loss 5.176705837249756
bi 2 loss 5.20207405090332
bi 3 loss 5.183429718017578
Layer  6  loss:  5.1969075202941895 0.0 11.591147422790527
logits torch.Size([632, 4, 1024]) labels torch.Size([632, 4]) 0 1023
Curr loss timestep torch.Size([632, 4]) tensor([393, 354, 150, 436], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 4.9935503005981445
bi 1 loss 5.388314723968506
bi 2 loss 5.265151023864746
bi 3 loss 5.3451738357543945
Epoch 0: :   3%|▎         | 15711/600000 [04:56<3:03:44, v_num=12, reduced_train_loss=36.60, global_step=15709.0, consumed_samples=62840.0, train_step_timing in s=0.294]Epoch 0: :   3%|▎         | 15711/600000 [04:56<3:03:44, v_num=12, reduced_train_loss=36.90, global_step=15710.0, consumed_samples=62844.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.16049492359161377 torch.Size([581, 4]) 18.25210952758789 0.0
Max loss timestep torch.Size([581, 4]) tensor([120, 324, 286, 342], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.04246245697140694
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 1 loss 0.2199714332818985
speech mask sum tensor(417, device='cuda:0') loss mask sum tensor(417, device='cuda:0')
bi 2 loss 0.06157354265451431
speech mask sum tensor(338, device='cuda:0') loss mask sum tensor(338, device='cuda:0')
bi 3 loss 0.27597248554229736
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
logits torch.Size([581, 4, 257024]) labels torch.Size([581, 4]) 0 257022
Layer  0  loss:  0.15459783375263214 0.0 12.907848358154297
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([105, 503, 106, 344], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.04240866005420685
bi 1 loss 0.23107409477233887
bi 2 loss 0.048254650086164474
bi 3 loss 0.24102765321731567
Layer  1  loss:  0.14585623145103455 0.0 14.896241188049316
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([122, 325, 155, 342], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.05380019173026085
bi 1 loss 0.2214307188987732
bi 2 loss 0.0658753514289856
bi 3 loss 0.17291593551635742
Layer  2  loss:  0.17429885268211365 0.0 13.948962211608887
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([136, 324, 172, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.046893514692783356
bi 1 loss 0.25861048698425293
bi 2 loss 0.06477805972099304
bi 3 loss 0.25704053044319153
Layer  3  loss:  0.20211204886436462 0.0 19.16033172607422
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1021
Curr loss timestep torch.Size([581, 4]) tensor([101, 325, 206, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.04017217084765434
bi 1 loss 0.2955760657787323
bi 2 loss 0.09425041079521179
bi 3 loss 0.2798573672771454
Layer  4  loss:  0.19484956562519073 0.0 20.609699249267578
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([143, 325, 384, 342], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.05034458637237549
bi 1 loss 0.27468982338905334
bi 2 loss 0.09165425598621368
bi 3 loss 0.28575757145881653
Layer  5  loss:  0.15382128953933716 0.0 14.312904357910156
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([104, 325, 166, 342], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.06253520399332047
bi 1 loss 0.21986454725265503
bi 2 loss 0.05191376432776451
bi 3 loss 0.24440886080265045
Layer  6  loss:  0.17812487483024597 0.0 16.34117317199707
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1020
Curr loss timestep torch.Size([581, 4]) tensor([144, 324, 284, 342], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.04597233608365059
bi 1 loss 0.26311951875686646
bi 2 loss 0.08627666532993317
bi 3 loss 0.2284020185470581
Epoch 0: :   3%|▎         | 15712/600000 [04:56<3:04:00, v_num=12, reduced_train_loss=36.90, global_step=15710.0, consumed_samples=62844.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15712/600000 [04:56<3:04:00, v_num=12, reduced_train_loss=1.360, global_step=15711.0, consumed_samples=62848.0, train_step_timing in s=0.400]loss mask original None

First layer loss:  0.18658684194087982 torch.Size([633, 4]) 16.64278221130371 0.0
Max loss timestep torch.Size([633, 4]) tensor([425, 568, 106, 333], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.22917820513248444
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
bi 1 loss 0.2179020494222641
speech mask sum tensor(474, device='cuda:0') loss mask sum tensor(474, device='cuda:0')
bi 2 loss 0.055965736508369446
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.1272197961807251
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
logits torch.Size([633, 4, 257024]) labels torch.Size([633, 4]) 0 257023
Layer  0  loss:  0.152215376496315 0.0 10.105216979980469
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([425, 339, 162, 333], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.1545570194721222
bi 1 loss 0.19060558080673218
bi 2 loss 0.07692427188158035
bi 3 loss 0.10371328890323639
Layer  1  loss:  0.1986268162727356 0.0 10.11933422088623
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([425, 339, 151, 333], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.262911856174469
bi 1 loss 0.19375787675380707
bi 2 loss 0.10129322856664658
bi 3 loss 0.17137758433818817
Layer  2  loss:  0.21174296736717224 0.0 17.406557083129883
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([425, 529, 129, 333], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.26509779691696167
bi 1 loss 0.24009913206100464
bi 2 loss 0.06697895377874374
bi 3 loss 0.1516612023115158
Layer  3  loss:  0.19078390300273895 0.0 11.250299453735352
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1021
Curr loss timestep torch.Size([633, 4]) tensor([425, 529, 146, 330], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.22011487185955048
bi 1 loss 0.2467784583568573
bi 2 loss 0.07391669601202011
bi 3 loss 0.08305396139621735
Layer  4  loss:  0.19591861963272095 0.0 10.727700233459473
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([425, 339, 110, 333], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.2844927906990051
bi 1 loss 0.21674910187721252
bi 2 loss 0.04548473283648491
bi 3 loss 0.10148070007562637
Layer  5  loss:  0.20710505545139313 0.0 12.801326751708984
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([339, 529, 103, 333], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.28894543647766113
bi 1 loss 0.20992347598075867
bi 2 loss 0.04418855905532837
bi 3 loss 0.17593371868133545
Layer  6  loss:  0.18134799599647522 0.0 13.838739395141602
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1021
Curr loss timestep torch.Size([633, 4]) tensor([424, 339,  98, 333], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.20532670617103577
bi 1 loss 0.21311120688915253
bi 2 loss 0.03460356593132019
bi 3 loss 0.16138632595539093
Epoch 0: :   3%|▎         | 15713/600000 [04:57<3:04:16, v_num=12, reduced_train_loss=1.360, global_step=15711.0, consumed_samples=62848.0, train_step_timing in s=0.400]Epoch 0: :   3%|▎         | 15713/600000 [04:57<3:04:16, v_num=12, reduced_train_loss=1.520, global_step=15712.0, consumed_samples=62852.0, train_step_timing in s=0.434]loss mask original None

First layer loss:  3.801203966140747 torch.Size([572, 4]) 17.053630828857422 0.0
Max loss timestep torch.Size([572, 4]) tensor([110,  82, 520, 184], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 3.907517671585083
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
bi 1 loss 3.4284956455230713
speech mask sum tensor(61, device='cuda:0') loss mask sum tensor(61, device='cuda:0')
bi 2 loss 3.730116844177246
speech mask sum tensor(360, device='cuda:0') loss mask sum tensor(360, device='cuda:0')
bi 3 loss 3.810295343399048
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
logits torch.Size([572, 4, 257024]) labels torch.Size([572, 4]) 0 257022
Layer  0  loss:  4.225155830383301 0.0 10.227415084838867
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([470,  75, 269,  93], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 4.320816993713379
bi 1 loss 3.703946590423584
bi 2 loss 4.18586540222168
bi 3 loss 4.238776683807373
Layer  1  loss:  4.589278221130371 0.0 11.294551849365234
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([237,  58, 557, 471], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 4.6296892166137695
bi 1 loss 4.152741432189941
bi 2 loss 4.639317512512207
bi 3 loss 4.571105003356934
Layer  2  loss:  4.753330230712891 0.0 11.325745582580566
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([136,  51, 256, 463], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 4.858723163604736
bi 1 loss 4.470755100250244
bi 2 loss 4.807788848876953
bi 3 loss 4.650866508483887
Layer  3  loss:  4.843650817871094 0.0 9.865557670593262
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1019
Curr loss timestep torch.Size([572, 4]) tensor([184,  77, 529, 436], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 4.8037590980529785
bi 1 loss 4.656454086303711
bi 2 loss 4.980457782745361
bi 3 loss 4.796563148498535
Layer  4  loss:  5.039398193359375 0.0 10.062017440795898
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1023
Curr loss timestep torch.Size([572, 4]) tensor([372,  89, 475, 425], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 5.101186275482178
bi 1 loss 4.3997883796691895
bi 2 loss 5.151095390319824
bi 3 loss 4.979757308959961
Layer  5  loss:  5.127835273742676 0.0 10.654149055480957
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1020
Curr loss timestep torch.Size([572, 4]) tensor([184,  85, 294, 479], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 5.103728294372559
bi 1 loss 4.601093292236328
bi 2 loss 5.314662456512451
bi 3 loss 5.072185516357422
Layer  6  loss:  5.203235626220703 0.0 11.376924514770508
logits torch.Size([572, 4, 1024]) labels torch.Size([572, 4]) 0 1022
Curr loss timestep torch.Size([572, 4]) tensor([251,  59, 452, 215], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 5.186957836151123
bi 1 loss 4.771541595458984
bi 2 loss 5.348196506500244
bi 3 loss 5.1609272956848145
Epoch 0: :   3%|▎         | 15714/600000 [04:57<3:04:31, v_num=12, reduced_train_loss=1.520, global_step=15712.0, consumed_samples=62852.0, train_step_timing in s=0.434]Epoch 0: :   3%|▎         | 15714/600000 [04:57<3:04:31, v_num=12, reduced_train_loss=37.60, global_step=15713.0, consumed_samples=62856.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  0.2932022511959076 torch.Size([691, 4]) 15.64270305633545 0.0
Max loss timestep torch.Size([691, 4]) tensor([468, 656, 519, 286], device='cuda:0') tensor(656, device='cuda:0')
bi 0 loss 0.26086485385894775
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
bi 1 loss 0.46419233083724976
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
bi 2 loss 0.25852590799331665
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
bi 3 loss 0.14412714540958405
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
logits torch.Size([691, 4, 257024]) labels torch.Size([691, 4]) 0 257022
Layer  0  loss:  0.3216742277145386 0.0 12.124762535095215
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([377, 653, 573, 296], device='cuda:0') tensor(406, device='cuda:0')
bi 0 loss 0.27085617184638977
bi 1 loss 0.5178075432777405
bi 2 loss 0.31915268301963806
bi 3 loss 0.10555696487426758
Layer  1  loss:  0.3678257465362549 0.0 15.459250450134277
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([398, 653, 570, 295], device='cuda:0') tensor(653, device='cuda:0')
bi 0 loss 0.3285357654094696
bi 1 loss 0.5750162601470947
bi 2 loss 0.32247987389564514
bi 3 loss 0.19366666674613953
Layer  2  loss:  0.3418918550014496 0.0 12.316211700439453
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([467, 653, 407, 295], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 0.35507732629776
bi 1 loss 0.5349922776222229
bi 2 loss 0.26693424582481384
bi 3 loss 0.14987324178218842
Layer  3  loss:  0.3659283220767975 0.0 18.314144134521484
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1022
Curr loss timestep torch.Size([691, 4]) tensor([468, 656, 551, 286], device='cuda:0') tensor(656, device='cuda:0')
bi 0 loss 0.35506755113601685
bi 1 loss 0.5788840055465698
bi 2 loss 0.3055705428123474
bi 3 loss 0.15868738293647766
Layer  4  loss:  0.3997636139392853 0.0 14.50451946258545
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([468, 653, 571, 286], device='cuda:0') tensor(468, device='cuda:0')
bi 0 loss 0.382440984249115
bi 1 loss 0.6532159447669983
bi 2 loss 0.312701940536499
bi 3 loss 0.18992069363594055
Layer  5  loss:  0.4167739450931549 0.0 15.521485328674316
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([302, 656, 551, 295], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.34734877943992615
bi 1 loss 0.6971380114555359
bi 2 loss 0.35591989755630493
bi 3 loss 0.20999448001384735
Layer  6  loss:  0.39469781517982483 0.0 19.418907165527344
logits torch.Size([691, 4, 1024]) labels torch.Size([691, 4]) 0 1023
Curr loss timestep torch.Size([691, 4]) tensor([377, 653, 407, 296], device='cuda:0') tensor(653, device='cuda:0')
bi 0 loss 0.34021326899528503
bi 1 loss 0.7013581395149231
bi 2 loss 0.296042263507843
bi 3 loss 0.18972352147102356
Epoch 0: :   3%|▎         | 15715/600000 [04:58<3:04:49, v_num=12, reduced_train_loss=37.60, global_step=15713.0, consumed_samples=62856.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15715/600000 [04:58<3:04:49, v_num=12, reduced_train_loss=2.900, global_step=15714.0, consumed_samples=62860.0, train_step_timing in s=0.473]loss mask original None

First layer loss:  3.8726630210876465 torch.Size([596, 4]) 13.690519332885742 0.0
Max loss timestep torch.Size([596, 4]) tensor([518, 167, 154, 419], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 3.7234299182891846
speech mask sum tensor(426, device='cuda:0') loss mask sum tensor(426, device='cuda:0')
bi 1 loss 3.6851017475128174
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 2 loss 4.520724296569824
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 3 loss 3.8627004623413086
speech mask sum tensor(424, device='cuda:0') loss mask sum tensor(424, device='cuda:0')
logits torch.Size([596, 4, 257024]) labels torch.Size([596, 4]) 0 257022
Layer  0  loss:  4.352309226989746 0.0 11.180683135986328
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([416, 112, 180, 193], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.4110798835754395
bi 1 loss 3.970508575439453
bi 2 loss 4.240134239196777
bi 3 loss 4.497783184051514
Layer  1  loss:  4.65967321395874 0.0 9.35352897644043
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([544, 189, 160, 149], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 4.685916423797607
bi 1 loss 4.4234724044799805
bi 2 loss 4.6167378425598145
bi 3 loss 4.750035285949707
Layer  2  loss:  4.998566627502441 0.0 10.330278396606445
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([483,  54, 218, 413], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.994595527648926
bi 1 loss 4.746042251586914
bi 2 loss 4.743298530578613
bi 3 loss 5.20487642288208
Layer  3  loss:  5.05201530456543 0.0 10.420286178588867
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([362, 158, 218, 462], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 5.174575328826904
bi 1 loss 4.508461952209473
bi 2 loss 4.9309492111206055
bi 3 loss 5.205740928649902
Layer  4  loss:  5.198312759399414 0.0 11.016336441040039
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1021
Curr loss timestep torch.Size([596, 4]) tensor([504, 162, 160, 425], device='cuda:0') tensor(191, device='cuda:0')
bi 0 loss 5.351947784423828
bi 1 loss 4.853281497955322
bi 2 loss 4.875820636749268
bi 3 loss 5.310657024383545
Layer  5  loss:  5.215456008911133 0.0 10.23135757446289
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([476,  96, 159, 491], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 5.343429088592529
bi 1 loss 4.9329609870910645
bi 2 loss 4.92642879486084
bi 3 loss 5.31449556350708
Layer  6  loss:  5.2491254806518555 0.0 10.930747985839844
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([244,  94, 182, 556], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 5.391471862792969
bi 1 loss 4.8144612312316895
bi 2 loss 5.1074604988098145
bi 3 loss 5.344117164611816
Epoch 0: :   3%|▎         | 15716/600000 [04:58<3:05:04, v_num=12, reduced_train_loss=2.900, global_step=15714.0, consumed_samples=62860.0, train_step_timing in s=0.473]Epoch 0: :   3%|▎         | 15716/600000 [04:58<3:05:04, v_num=12, reduced_train_loss=38.60, global_step=15715.0, consumed_samples=62864.0, train_step_timing in s=0.378]loss mask original None

First layer loss:  3.3304169178009033 torch.Size([552, 4]) 10.281546592712402 0.0
Max loss timestep torch.Size([552, 4]) tensor([424, 296, 180, 357], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 3.638315200805664
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
bi 1 loss 4.061916828155518
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 2 loss 2.267983913421631
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 3 loss 3.132275342941284
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
logits torch.Size([552, 4, 257024]) labels torch.Size([552, 4]) 0 257022
Layer  0  loss:  3.9034037590026855 0.0 10.438630104064941
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([429, 325, 264, 347], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 4.065342426300049
bi 1 loss 4.631644248962402
bi 2 loss 3.102599620819092
bi 3 loss 3.7102513313293457
Layer  1  loss:  4.30197811126709 0.0 11.437932968139648
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([486, 322, 295, 358], device='cuda:0') tensor(292, device='cuda:0')
bi 0 loss 4.635201930999756
bi 1 loss 4.813758850097656
bi 2 loss 3.5511505603790283
bi 3 loss 3.9831595420837402
Layer  2  loss:  4.636106491088867 0.0 10.910775184631348
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([133, 316, 310, 124], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 5.052253723144531
bi 1 loss 4.93062162399292
bi 2 loss 3.811351776123047
bi 3 loss 4.441006660461426
Layer  3  loss:  4.7603983879089355 0.0 9.529043197631836
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([514, 210, 232, 147], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 5.229971408843994
bi 1 loss 4.947379112243652
bi 2 loss 3.9254722595214844
bi 3 loss 4.583745002746582
Layer  4  loss:  4.876454830169678 0.0 10.352920532226562
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([398, 162, 264, 141], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 5.188625335693359
bi 1 loss 5.181329727172852
bi 2 loss 4.177608966827393
bi 3 loss 4.7267842292785645
Layer  5  loss:  4.970364093780518 0.0 10.086292266845703
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([293, 160, 271, 357], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 5.389434337615967
bi 1 loss 5.24264669418335
bi 2 loss 4.087441444396973
bi 3 loss 4.841090679168701
Layer  6  loss:  5.009395122528076 0.0 11.289916038513184
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([379, 152, 187, 297], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 5.405404567718506
bi 1 loss 5.353297710418701
bi 2 loss 4.240076541900635
bi 3 loss 4.754359722137451
Epoch 0: :   3%|▎         | 15717/600000 [04:59<3:05:18, v_num=12, reduced_train_loss=38.60, global_step=15715.0, consumed_samples=62864.0, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15717/600000 [04:59<3:05:18, v_num=12, reduced_train_loss=35.80, global_step=15716.0, consumed_samples=62868.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  0.06230275705456734 torch.Size([563, 4]) 10.155069351196289 0.0
Max loss timestep torch.Size([563, 4]) tensor([144, 535, 330, 376], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.029774682596325874
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 1 loss 0.09659793227910995
speech mask sum tensor(407, device='cuda:0') loss mask sum tensor(407, device='cuda:0')
bi 2 loss 0.039542075246572495
speech mask sum tensor(257, device='cuda:0') loss mask sum tensor(257, device='cuda:0')
bi 3 loss 0.05074182525277138
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
logits torch.Size([563, 4, 257024]) labels torch.Size([563, 4]) 0 257022
Layer  0  loss:  0.07758663594722748 0.0 10.20167350769043
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([ 64, 535, 332, 312], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.05097253993153572
bi 1 loss 0.11576584726572037
bi 2 loss 0.05798359587788582
bi 3 loss 0.049627311527729034
Layer  1  loss:  0.08654629439115524 0.0 10.300973892211914
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([ 46, 349, 331, 292], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.03506937250494957
bi 1 loss 0.09926529973745346
bi 2 loss 0.13139693439006805
bi 3 loss 0.04972909763455391
Layer  2  loss:  0.07157678157091141 0.0 10.312620162963867
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([128, 349, 332, 260], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.032570067793130875
bi 1 loss 0.1074753850698471
bi 2 loss 0.06047758460044861
bi 3 loss 0.04797839745879173
Layer  3  loss:  0.07031568884849548 0.0 8.101432800292969
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([ 97, 534, 331, 323], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.029473114758729935
bi 1 loss 0.10115575045347214
bi 2 loss 0.079497791826725
bi 3 loss 0.03316611796617508
Layer  4  loss:  0.08854223042726517 0.0 11.105602264404297
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([114, 534, 331, 374], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.037395503371953964
bi 1 loss 0.12066642194986343
bi 2 loss 0.10657516866922379
bi 3 loss 0.04663637652993202
Layer  5  loss:  0.08935775607824326 0.0 11.07461166381836
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([ 92, 349, 331, 304], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.030619410797953606
bi 1 loss 0.12763682007789612
bi 2 loss 0.10542923957109451
bi 3 loss 0.04423459246754646
Layer  6  loss:  0.08653409779071808 0.0 10.157052040100098
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([ 85, 349, 331, 303], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.03235846012830734
bi 1 loss 0.1286012977361679
bi 2 loss 0.0762854665517807
bi 3 loss 0.06257850676774979
Epoch 0: :   3%|▎         | 15718/600000 [04:59<3:05:33, v_num=12, reduced_train_loss=35.80, global_step=15716.0, consumed_samples=62868.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15718/600000 [04:59<3:05:33, v_num=12, reduced_train_loss=0.633, global_step=15717.0, consumed_samples=62872.0, train_step_timing in s=0.392]loss mask original None

First layer loss:  0.006339086685329676 torch.Size([334, 4]) 0.05418751388788223 0.0
Max loss timestep torch.Size([334, 4]) tensor([209, 131, 288, 171], device='cuda:0') tensor(131, device='cuda:0')
bi 0 loss 0.007008110638707876
speech mask sum tensor(68, device='cuda:0') loss mask sum tensor(68, device='cuda:0')
bi 1 loss 0.005474180914461613
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
bi 2 loss 0.0037824588362127542
speech mask sum tensor(51, device='cuda:0') loss mask sum tensor(51, device='cuda:0')
bi 3 loss 0.0076461792923510075
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
logits torch.Size([334, 4, 257024]) labels torch.Size([334, 4]) 0 257022
Layer  0  loss:  0.005369978491216898 0.0 0.06282048672437668
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1023
Curr loss timestep torch.Size([334, 4]) tensor([172, 124, 314, 106], device='cuda:0') tensor(106, device='cuda:0')
bi 0 loss 0.0045570312067866325
bi 1 loss 0.005465000867843628
bi 2 loss 0.0030134893022477627
bi 3 loss 0.006483439356088638
Layer  1  loss:  0.005727128591388464 0.0 0.06740308552980423
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1023
Curr loss timestep torch.Size([334, 4]) tensor([207, 126, 322,  72], device='cuda:0') tensor(72, device='cuda:0')
bi 0 loss 0.005502792075276375
bi 1 loss 0.004621370695531368
bi 2 loss 0.00313117285259068
bi 3 loss 0.007664287928491831
Layer  2  loss:  0.0071886335499584675 0.0 0.3938716650009155
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1022
Curr loss timestep torch.Size([334, 4]) tensor([180,  92, 325, 151], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.003172600409016013
bi 1 loss 0.0060526663437485695
bi 2 loss 0.01559186540544033
bi 3 loss 0.00708921579644084
Layer  3  loss:  0.00539386086165905 0.0 0.0488213412463665
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1019
Curr loss timestep torch.Size([334, 4]) tensor([176,  90, 291, 142], device='cuda:0') tensor(142, device='cuda:0')
bi 0 loss 0.005983981303870678
bi 1 loss 0.004757783375680447
bi 2 loss 0.00332988821901381
bi 3 loss 0.006373507436364889
Layer  4  loss:  0.005476067773997784 0.0 0.07287424057722092
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1022
Curr loss timestep torch.Size([334, 4]) tensor([215, 124, 292, 118], device='cuda:0') tensor(124, device='cuda:0')
bi 0 loss 0.004660544916987419
bi 1 loss 0.005618023220449686
bi 2 loss 0.0036080842837691307
bi 3 loss 0.006381647195667028
Layer  5  loss:  0.005668858531862497 0.0 0.04128933697938919
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1017
Curr loss timestep torch.Size([334, 4]) tensor([217, 145, 291, 138], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 0.005150130018591881
bi 1 loss 0.006189283914864063
bi 2 loss 0.004254303872585297
bi 3 loss 0.0059605794958770275
Layer  6  loss:  0.0062105669640004635 0.0 0.05996266379952431
logits torch.Size([334, 4, 1024]) labels torch.Size([334, 4]) 0 1021
Curr loss timestep torch.Size([334, 4]) tensor([174,  92, 322, 115], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 0.005005151033401489
bi 1 loss 0.006829699035733938
bi 2 loss 0.005321544129401445
bi 3 loss 0.006554347928613424
Epoch 0: :   3%|▎         | 15719/600000 [04:59<3:05:44, v_num=12, reduced_train_loss=0.633, global_step=15717.0, consumed_samples=62872.0, train_step_timing in s=0.392]Epoch 0: :   3%|▎         | 15719/600000 [04:59<3:05:44, v_num=12, reduced_train_loss=0.0474, global_step=15718.0, consumed_samples=62876.0, train_step_timing in s=0.268]loss mask original None

First layer loss:  3.589195728302002 torch.Size([552, 4]) 10.528901100158691 0.0
Max loss timestep torch.Size([552, 4]) tensor([179,  65, 514, 301], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 3.3730900287628174
speech mask sum tensor(90, device='cuda:0') loss mask sum tensor(90, device='cuda:0')
bi 1 loss 2.8768954277038574
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 2 loss 3.829169988632202
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
bi 3 loss 3.4741830825805664
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
logits torch.Size([552, 4, 257024]) labels torch.Size([552, 4]) 0 257022
Layer  0  loss:  4.134134292602539 0.0 10.970455169677734
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([209,  71, 494, 211], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 4.087839126586914
bi 1 loss 3.250868320465088
bi 2 loss 4.272834300994873
bi 3 loss 4.15910005569458
Layer  1  loss:  4.439136028289795 0.0 9.335049629211426
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([177,  79, 192, 107], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 4.398937702178955
bi 1 loss 4.094602584838867
bi 2 loss 4.628196716308594
bi 3 loss 4.249650478363037
Layer  2  loss:  4.743992328643799 0.0 10.022077560424805
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([216,  66, 230, 127], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.773134231567383
bi 1 loss 4.24741792678833
bi 2 loss 4.775787353515625
bi 3 loss 4.809914588928223
Layer  3  loss:  4.85478401184082 0.0 10.435129165649414
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([200, 103, 232, 200], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.97333288192749
bi 1 loss 4.3479461669921875
bi 2 loss 4.828032493591309
bi 3 loss 4.982398986816406
Layer  4  loss:  4.940060138702393 0.0 9.52508544921875
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1022
Curr loss timestep torch.Size([552, 4]) tensor([235,  85, 314, 256], device='cuda:0') tensor(204, device='cuda:0')
bi 0 loss 5.203674793243408
bi 1 loss 4.39969539642334
bi 2 loss 4.950583457946777
bi 3 loss 4.969329357147217
Layer  5  loss:  5.063174724578857 0.0 10.615400314331055
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1023
Curr loss timestep torch.Size([552, 4]) tensor([188,  71, 168, 313], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 5.260680198669434
bi 1 loss 4.48286247253418
bi 2 loss 4.997958660125732
bi 3 loss 5.241147994995117
Layer  6  loss:  5.188431262969971 0.0 10.726179122924805
logits torch.Size([552, 4, 1024]) labels torch.Size([552, 4]) 0 1019
Curr loss timestep torch.Size([552, 4]) tensor([216,  72, 398, 174], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 5.512292385101318
bi 1 loss 4.497197151184082
bi 2 loss 5.146795272827148
bi 3 loss 5.314868927001953
Epoch 0: :   3%|▎         | 15720/600000 [05:00<3:05:57, v_num=12, reduced_train_loss=0.0474, global_step=15718.0, consumed_samples=62876.0, train_step_timing in s=0.268]Epoch 0: :   3%|▎         | 15720/600000 [05:00<3:05:57, v_num=12, reduced_train_loss=37.00, global_step=15719.0, consumed_samples=62880.0, train_step_timing in s=0.353] loss mask original None

First layer loss:  3.8197128772735596 torch.Size([564, 4]) 12.395081520080566 0.0
Max loss timestep torch.Size([564, 4]) tensor([263, 223, 147, 348], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 3.7658166885375977
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 1 loss 3.7996461391448975
speech mask sum tensor(404, device='cuda:0') loss mask sum tensor(404, device='cuda:0')
bi 2 loss 3.2073028087615967
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 3 loss 4.312169075012207
speech mask sum tensor(246, device='cuda:0') loss mask sum tensor(246, device='cuda:0')
logits torch.Size([564, 4, 257024]) labels torch.Size([564, 4]) 0 257023
Layer  0  loss:  4.207202434539795 0.0 10.139511108398438
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([190, 261, 225, 302], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 4.389420986175537
bi 1 loss 4.028024196624756
bi 2 loss 3.8603761196136475
bi 3 loss 4.608620643615723
Layer  1  loss:  4.491238594055176 0.0 10.04921817779541
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([160, 177, 212, 187], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 4.820403575897217
bi 1 loss 4.386953353881836
bi 2 loss 4.124086856842041
bi 3 loss 4.677894592285156
Layer  2  loss:  4.8611063957214355 0.0 9.720081329345703
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([229, 354, 167, 269], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.913586616516113
bi 1 loss 4.801638126373291
bi 2 loss 4.554488658905029
bi 3 loss 5.13165283203125
Layer  3  loss:  4.968585968017578 0.0 10.265532493591309
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1019
Curr loss timestep torch.Size([564, 4]) tensor([197, 426, 177, 364], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 5.143352031707764
bi 1 loss 4.92363977432251
bi 2 loss 4.63785982131958
bi 3 loss 5.143857479095459
Layer  4  loss:  5.1185994148254395 0.0 10.680801391601562
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([247, 482, 182, 267], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 5.351191520690918
bi 1 loss 5.065019607543945
bi 2 loss 4.734185695648193
bi 3 loss 5.303329944610596
Layer  5  loss:  5.16318416595459 0.0 8.824636459350586
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([161, 504, 266, 262], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 5.305878639221191
bi 1 loss 5.096689224243164
bi 2 loss 4.838511943817139
bi 3 loss 5.392764091491699
Layer  6  loss:  5.277218341827393 0.0 10.315829277038574
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1021
Curr loss timestep torch.Size([564, 4]) tensor([280, 264, 266, 392], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 5.530524253845215
bi 1 loss 5.163524150848389
bi 2 loss 5.056807518005371
bi 3 loss 5.433099746704102
Epoch 0: :   3%|▎         | 15721/600000 [05:00<3:06:11, v_num=12, reduced_train_loss=37.00, global_step=15719.0, consumed_samples=62880.0, train_step_timing in s=0.353]Epoch 0: :   3%|▎         | 15721/600000 [05:00<3:06:11, v_num=12, reduced_train_loss=37.90, global_step=15720.0, consumed_samples=62884.0, train_step_timing in s=0.365]loss mask original None

First layer loss:  3.8076188564300537 torch.Size([508, 4]) 11.520133018493652 0.0
Max loss timestep torch.Size([508, 4]) tensor([247, 390, 237, 184], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 4.020079135894775
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 1 loss 3.5172832012176514
speech mask sum tensor(454, device='cuda:0') loss mask sum tensor(454, device='cuda:0')
bi 2 loss 4.139118671417236
speech mask sum tensor(321, device='cuda:0') loss mask sum tensor(321, device='cuda:0')
bi 3 loss 3.3206493854522705
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
logits torch.Size([508, 4, 257024]) labels torch.Size([508, 4]) 0 257023
Layer  0  loss:  4.241970539093018 0.0 10.184246063232422
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([174, 150, 148, 207], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 4.383296489715576
bi 1 loss 4.15842866897583
bi 2 loss 4.402360916137695
bi 3 loss 3.4829928874969482
Layer  1  loss:  4.661749839782715 0.0 10.266231536865234
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([320, 154, 195, 195], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 4.689785480499268
bi 1 loss 4.6700520515441895
bi 2 loss 4.811830043792725
bi 3 loss 3.8075456619262695
Layer  2  loss:  5.04235315322876 0.0 10.357831954956055
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([189, 177, 271, 227], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 5.117267608642578
bi 1 loss 5.075779914855957
bi 2 loss 5.219803333282471
bi 3 loss 3.7121598720550537
Layer  3  loss:  5.147407054901123 0.0 10.748664855957031
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([247, 435, 172, 193], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 5.285748481750488
bi 1 loss 5.0806708335876465
bi 2 loss 5.384041786193848
bi 3 loss 3.9417366981506348
Layer  4  loss:  5.337738037109375 0.0 9.57122802734375
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([399, 377, 321, 198], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 5.415185451507568
bi 1 loss 5.3586015701293945
bi 2 loss 5.514180660247803
bi 3 loss 4.0835089683532715
Layer  5  loss:  5.46183443069458 0.0 9.941816329956055
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([224, 356, 316, 221], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 5.592192649841309
bi 1 loss 5.437602519989014
bi 2 loss 5.628063678741455
bi 3 loss 4.3352789878845215
Layer  6  loss:  5.488476753234863 0.0 10.493474006652832
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([229, 423, 147, 211], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 5.619702339172363
bi 1 loss 5.4039788246154785
bi 2 loss 5.766488552093506
bi 3 loss 4.236715316772461
Epoch 0: :   3%|▎         | 15722/600000 [05:00<3:06:25, v_num=12, reduced_train_loss=37.90, global_step=15720.0, consumed_samples=62884.0, train_step_timing in s=0.365]Epoch 0: :   3%|▎         | 15722/600000 [05:00<3:06:25, v_num=12, reduced_train_loss=39.20, global_step=15721.0, consumed_samples=62888.0, train_step_timing in s=0.336]loss mask original None

First layer loss:  0.0279409047216177 torch.Size([350, 4]) 4.2940874099731445 0.0
Max loss timestep torch.Size([350, 4]) tensor([275, 236, 277,  87], device='cuda:0') tensor(87, device='cuda:0')
bi 0 loss 0.02700013667345047
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
bi 1 loss 0.015920160338282585
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 2 loss 0.023766137659549713
speech mask sum tensor(233, device='cuda:0') loss mask sum tensor(233, device='cuda:0')
bi 3 loss 0.05093136429786682
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
logits torch.Size([350, 4, 257024]) labels torch.Size([350, 4]) 0 257023
Layer  0  loss:  0.022413019090890884 0.0 1.1853406429290771
logits torch.Size([350, 4, 1024]) labels torch.Size([350, 4]) 0 1023
Curr loss timestep torch.Size([350, 4]) tensor([308, 193, 269,  88], device='cuda:0') tensor(88, device='cuda:0')
bi 0 loss 0.0227527879178524
bi 1 loss 0.01373653020709753
bi 2 loss 0.02234632521867752
bi 3 loss 0.030403096228837967
Layer  1  loss:  0.021899977698922157 0.0 1.6725224256515503
logits torch.Size([350, 4, 1024]) labels torch.Size([350, 4]) 0 1023
Curr loss timestep torch.Size([350, 4]) tensor([233, 177, 283, 120], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.020175402984023094
bi 1 loss 0.015720294788479805
bi 2 loss 0.029253624379634857
bi 3 loss 0.016969705000519753
Layer  2  loss:  0.024227596819400787 0.0 1.1430706977844238
logits torch.Size([350, 4, 1024]) labels torch.Size([350, 4]) 0 1022
Curr loss timestep torch.Size([350, 4]) tensor([235, 175, 124,  98], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 0.0331566259264946
bi 1 loss 0.014664371497929096
bi 2 loss 0.02131667546927929
bi 3 loss 0.018161790445446968
Layer  3  loss:  0.022507663816213608 0.0 0.8087156414985657
logits torch.Size([350, 4, 1024]) labels torch.Size([350, 4]) 0 1023
Curr loss timestep torch.Size([350, 4]) tensor([165, 170, 276, 154], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.02569037303328514
bi 1 loss 0.017741795629262924
bi 2 loss 0.025966407731175423
bi 3 loss 0.012348666787147522
Layer  4  loss:  0.02159820683300495 0.0 0.4197317957878113
logits torch.Size([350, 4, 1024]) labels torch.Size([350, 4]) 0 1022
Curr loss timestep torch.Size([350, 4]) tensor([155, 224, 116, 102], device='cuda:0') tensor(137, device='cuda:0')
bi 0 loss 0.02666020579636097
bi 1 loss 0.020088519901037216
bi 2 loss 0.02072862721979618
bi 3 loss 0.012623506598174572
Layer  5  loss:  0.01857699826359749 0.0 0.2670206129550934
logits torch.Size([350, 4, 1024]) labels torch.Size([350, 4]) 0 1023
Curr loss timestep torch.Size([350, 4]) tensor([254, 183, 240, 157], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 0.017756953835487366
bi 1 loss 0.01290773507207632
bi 2 loss 0.023947013542056084
bi 3 loss 0.015066244639456272
Layer  6  loss:  0.022667013108730316 0.0 0.548027515411377
logits torch.Size([350, 4, 1024]) labels torch.Size([350, 4]) 0 1021
Curr loss timestep torch.Size([350, 4]) tensor([235, 196, 268, 123], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 0.026554446667432785
bi 1 loss 0.015888089314103127
bi 2 loss 0.02557860128581524
bi 3 loss 0.013947887346148491
Epoch 0: :   3%|▎         | 15723/600000 [05:01<3:06:35, v_num=12, reduced_train_loss=39.20, global_step=15721.0, consumed_samples=62888.0, train_step_timing in s=0.336]Epoch 0: :   3%|▎         | 15723/600000 [05:01<3:06:35, v_num=12, reduced_train_loss=0.182, global_step=15722.0, consumed_samples=62892.0, train_step_timing in s=0.275]loss mask original None

First layer loss:  0.16812056303024292 torch.Size([667, 4]) 19.479473114013672 0.0
Max loss timestep torch.Size([667, 4]) tensor([574, 367, 324, 141], device='cuda:0') tensor(574, device='cuda:0')
bi 0 loss 0.2785094082355499
speech mask sum tensor(434, device='cuda:0') loss mask sum tensor(434, device='cuda:0')
bi 1 loss 0.07479444891214371
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 2 loss 0.13100941479206085
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 3 loss 0.057353533804416656
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
logits torch.Size([667, 4, 257024]) labels torch.Size([667, 4]) 0 257022
Layer  0  loss:  0.15770265460014343 0.0 20.293212890625
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([575, 367, 274, 159], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.2799658477306366
bi 1 loss 0.04121050983667374
bi 2 loss 0.13295325636863708
bi 3 loss 0.038178443908691406
Layer  1  loss:  0.1798134595155716 0.0 11.942420959472656
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([574, 270, 324, 139], device='cuda:0') tensor(574, device='cuda:0')
bi 0 loss 0.26750078797340393
bi 1 loss 0.06487176567316055
bi 2 loss 0.21740619838237762
bi 3 loss 0.07313264161348343
Layer  2  loss:  0.17898795008659363 0.0 15.095192909240723
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([574, 206, 324, 134], device='cuda:0') tensor(574, device='cuda:0')
bi 0 loss 0.2905867397785187
bi 1 loss 0.07463144510984421
bi 2 loss 0.16270646452903748
bi 3 loss 0.054012980312108994
Layer  3  loss:  0.1550387293100357 0.0 11.846535682678223
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1022
Curr loss timestep torch.Size([667, 4]) tensor([575, 355, 324, 121], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.2627830505371094
bi 1 loss 0.06895846128463745
bi 2 loss 0.10798909515142441
bi 3 loss 0.05377430468797684
Layer  4  loss:  0.17663151025772095 0.0 11.416851043701172
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([575, 367, 335, 129], device='cuda:0') tensor(575, device='cuda:0')
bi 0 loss 0.28505900502204895
bi 1 loss 0.038697026669979095
bi 2 loss 0.20316648483276367
bi 3 loss 0.0695703998208046
Layer  5  loss:  0.16470766067504883 0.0 12.531556129455566
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1023
Curr loss timestep torch.Size([667, 4]) tensor([573, 367, 324,  80], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.24993126094341278
bi 1 loss 0.07081128656864166
bi 2 loss 0.1997670829296112
bi 3 loss 0.020351285114884377
Layer  6  loss:  0.2036968618631363 0.0 14.795389175415039
logits torch.Size([667, 4, 1024]) labels torch.Size([667, 4]) 0 1020
Curr loss timestep torch.Size([667, 4]) tensor([573, 263, 324, 145], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.31288817524909973
bi 1 loss 0.06748849153518677
bi 2 loss 0.263357013463974
bi 3 loss 0.031480345875024796
Epoch 0: :   3%|▎         | 15724/600000 [05:01<3:06:53, v_num=12, reduced_train_loss=0.182, global_step=15722.0, consumed_samples=62892.0, train_step_timing in s=0.275]Epoch 0: :   3%|▎         | 15724/600000 [05:01<3:06:53, v_num=12, reduced_train_loss=1.380, global_step=15723.0, consumed_samples=62896.0, train_step_timing in s=0.462]loss mask original None

First layer loss:  0.04368199408054352 torch.Size([490, 4]) 10.964776992797852 0.0
Max loss timestep torch.Size([490, 4]) tensor([112, 364, 381,  75], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.017772264778614044
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 1 loss 0.05552750825881958
speech mask sum tensor(434, device='cuda:0') loss mask sum tensor(434, device='cuda:0')
bi 2 loss 0.051545675843954086
speech mask sum tensor(341, device='cuda:0') loss mask sum tensor(341, device='cuda:0')
bi 3 loss 0.018920838832855225
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
logits torch.Size([490, 4, 257024]) labels torch.Size([490, 4]) 0 257022
Layer  0  loss:  0.032362934201955795 0.0 2.661882162094116
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([ 97, 287, 381, 184], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.023883776739239693
bi 1 loss 0.03198400139808655
bi 2 loss 0.04315044730901718
bi 3 loss 0.019605396315455437
Layer  1  loss:  0.039604026824235916 0.0 7.73419189453125
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1022
Curr loss timestep torch.Size([490, 4]) tensor([ 62, 283, 381, 185], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.035285595804452896
bi 1 loss 0.03307422623038292
bi 2 loss 0.060559604316949844
bi 3 loss 0.02080320566892624
Layer  2  loss:  0.05618395656347275 0.0 12.78138542175293
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1022
Curr loss timestep torch.Size([490, 4]) tensor([121, 282, 381, 140], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.02382437326014042
bi 1 loss 0.06424982845783234
bi 2 loss 0.07715760916471481
bi 3 loss 0.020952317863702774
Layer  3  loss:  0.04557550698518753 0.0 14.094635963439941
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1017
Curr loss timestep torch.Size([490, 4]) tensor([105, 287, 381, 144], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.02185944840312004
bi 1 loss 0.036642685532569885
bi 2 loss 0.08170899003744125
bi 3 loss 0.016644898802042007
Layer  4  loss:  0.03962703421711922 0.0 8.387567520141602
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([ 62, 316, 381, 186], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.02254370227456093
bi 1 loss 0.030835675075650215
bi 2 loss 0.06379697471857071
bi 3 loss 0.026867669075727463
Layer  5  loss:  0.03977131098508835 0.0 9.146007537841797
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([123, 169, 381, 211], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.01971827819943428
bi 1 loss 0.03484036400914192
bi 2 loss 0.059933871030807495
bi 3 loss 0.02704068459570408
Layer  6  loss:  0.03915901854634285 0.0 6.127267360687256
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1021
Curr loss timestep torch.Size([490, 4]) tensor([ 70, 269, 381, 181], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.024132028222084045
bi 1 loss 0.0317765474319458
bi 2 loss 0.06865280866622925
bi 3 loss 0.01349788997322321
Epoch 0: :   3%|▎         | 15725/600000 [05:02<3:07:07, v_num=12, reduced_train_loss=1.380, global_step=15723.0, consumed_samples=62896.0, train_step_timing in s=0.462]Epoch 0: :   3%|▎         | 15725/600000 [05:02<3:07:07, v_num=12, reduced_train_loss=0.336, global_step=15724.0, consumed_samples=62900.0, train_step_timing in s=0.342]loss mask original None

First layer loss:  0.1301480233669281 torch.Size([590, 4]) 12.797333717346191 0.0
Max loss timestep torch.Size([590, 4]) tensor([564, 185, 287, 122], device='cuda:0') tensor(564, device='cuda:0')
bi 0 loss 0.21501968801021576
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
bi 1 loss 0.025425609201192856
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 2 loss 0.11882484704256058
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 3 loss 0.03380332514643669
speech mask sum tensor(62, device='cuda:0') loss mask sum tensor(62, device='cuda:0')
logits torch.Size([590, 4, 257024]) labels torch.Size([590, 4]) 0 257022
Layer  0  loss:  0.1515653282403946 0.0 9.847112655639648
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([562, 269, 287, 119], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.24838535487651825
bi 1 loss 0.046527113765478134
bi 2 loss 0.12270115315914154
bi 3 loss 0.023851661011576653
Layer  1  loss:  0.1700143963098526 0.0 9.302209854125977
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([562, 279, 300, 127], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.23671042919158936
bi 1 loss 0.06297134608030319
bi 2 loss 0.25167009234428406
bi 3 loss 0.013735483400523663
Layer  2  loss:  0.16565477848052979 0.0 9.76441478729248
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([562, 279, 300, 129], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.23174360394477844
bi 1 loss 0.041756290942430496
bi 2 loss 0.28014054894447327
bi 3 loss 0.008427837863564491
Layer  3  loss:  0.17320787906646729 0.0 14.051407814025879
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([563, 253, 300, 122], device='cuda:0') tensor(563, device='cuda:0')
bi 0 loss 0.2826261818408966
bi 1 loss 0.041777484118938446
bi 2 loss 0.17075584828853607
bi 3 loss 0.016270173713564873
Layer  4  loss:  0.18633660674095154 0.0 16.870988845825195
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1022
Curr loss timestep torch.Size([590, 4]) tensor([563, 280, 288, 117], device='cuda:0') tensor(563, device='cuda:0')
bi 0 loss 0.3179454505443573
bi 1 loss 0.030439164489507675
bi 2 loss 0.17102757096290588
bi 3 loss 0.012349053286015987
Layer  5  loss:  0.17441248893737793 0.0 17.727275848388672
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1023
Curr loss timestep torch.Size([590, 4]) tensor([563, 334, 287, 119], device='cuda:0') tensor(563, device='cuda:0')
bi 0 loss 0.28627878427505493
bi 1 loss 0.05381520092487335
bi 2 loss 0.13721251487731934
bi 3 loss 0.031191788613796234
Layer  6  loss:  0.19340188801288605 0.0 22.226665496826172
logits torch.Size([590, 4, 1024]) labels torch.Size([590, 4]) 0 1021
Curr loss timestep torch.Size([590, 4]) tensor([563, 295, 287, 117], device='cuda:0') tensor(563, device='cuda:0')
bi 0 loss 0.332567036151886
bi 1 loss 0.03742917627096176
bi 2 loss 0.1582765281200409
bi 3 loss 0.014516718685626984
Epoch 0: :   3%|▎         | 15726/600000 [05:02<3:07:22, v_num=12, reduced_train_loss=0.336, global_step=15724.0, consumed_samples=62900.0, train_step_timing in s=0.342]Epoch 0: :   3%|▎         | 15726/600000 [05:02<3:07:22, v_num=12, reduced_train_loss=1.340, global_step=15725.0, consumed_samples=62904.0, train_step_timing in s=0.404]loss mask original None

First layer loss:  0.057408470660448074 torch.Size([513, 4]) 4.005546569824219 0.0
Max loss timestep torch.Size([513, 4]) tensor([272, 324,  63, 275], device='cuda:0') tensor(63, device='cuda:0')
bi 0 loss 0.05772396922111511
speech mask sum tensor(258, device='cuda:0') loss mask sum tensor(258, device='cuda:0')
bi 1 loss 0.06053069978952408
speech mask sum tensor(392, device='cuda:0') loss mask sum tensor(392, device='cuda:0')
bi 2 loss 0.12072038650512695
speech mask sum tensor(53, device='cuda:0') loss mask sum tensor(53, device='cuda:0')
bi 3 loss 0.040335763245821
speech mask sum tensor(273, device='cuda:0') loss mask sum tensor(273, device='cuda:0')
logits torch.Size([513, 4, 257024]) labels torch.Size([513, 4]) 0 257020
Layer  0  loss:  0.06466094404459 0.0 2.807971954345703
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([357, 375,  84, 242], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.08460459858179092
bi 1 loss 0.06549127399921417
bi 2 loss 0.04513861984014511
bi 3 loss 0.048410870134830475
Layer  1  loss:  0.05609564855694771 0.0 5.037581443786621
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([364, 494,  68, 266], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.07697517424821854
bi 1 loss 0.06084233894944191
bi 2 loss 0.029862305149435997
bi 3 loss 0.03464050963521004
Layer  2  loss:  0.06327030807733536 0.0 10.256330490112305
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([364, 332,  85, 271], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.09057129174470901
bi 1 loss 0.06367797404527664
bi 2 loss 0.04333645477890968
bi 3 loss 0.04075394570827484
Layer  3  loss:  0.05738276243209839 0.0 10.239225387573242
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([364, 260,  70, 261], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.10778400301933289
bi 1 loss 0.04099961742758751
bi 2 loss 0.03895081207156181
bi 3 loss 0.036853693425655365
Layer  4  loss:  0.060686565935611725 0.0 10.864283561706543
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([364, 295,  80,  92], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.08442354947328568
bi 1 loss 0.06327217817306519
bi 2 loss 0.013826827518641949
bi 3 loss 0.043638452887535095
Layer  5  loss:  0.061441633850336075 0.0 10.625337600708008
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([364, 378,  76, 111], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.09453951567411423
bi 1 loss 0.05239373445510864
bi 2 loss 0.06354289501905441
bi 3 loss 0.04274621605873108
Layer  6  loss:  0.06182560324668884 0.0 11.496785163879395
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([364, 375,  76, 251], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 0.09314543008804321
bi 1 loss 0.05661384388804436
bi 2 loss 0.038008976727724075
bi 3 loss 0.04433393105864525
Epoch 0: :   3%|▎         | 15727/600000 [05:02<3:07:36, v_num=12, reduced_train_loss=1.340, global_step=15725.0, consumed_samples=62904.0, train_step_timing in s=0.404]Epoch 0: :   3%|▎         | 15727/600000 [05:02<3:07:36, v_num=12, reduced_train_loss=0.483, global_step=15726.0, consumed_samples=62908.0, train_step_timing in s=0.356]loss mask original None

First layer loss:  3.8655660152435303 torch.Size([500, 4]) 11.014732360839844 0.0
Max loss timestep torch.Size([500, 4]) tensor([179, 213, 319, 248], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 3.289573907852173
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
bi 1 loss 3.809668779373169
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 2 loss 4.086358547210693
speech mask sum tensor(270, device='cuda:0') loss mask sum tensor(270, device='cuda:0')
bi 3 loss 4.167359352111816
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
logits torch.Size([500, 4, 257024]) labels torch.Size([500, 4]) 0 257023
Layer  0  loss:  4.368138790130615 0.0 9.475522994995117
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1023
Curr loss timestep torch.Size([500, 4]) tensor([195, 271, 146, 259], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 3.9370646476745605
bi 1 loss 4.171037673950195
bi 2 loss 4.62606954574585
bi 3 loss 4.711434841156006
Layer  1  loss:  4.696371078491211 0.0 10.829878807067871
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([ 98, 377, 108, 222], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 4.31920862197876
bi 1 loss 4.589547634124756
bi 2 loss 4.779228210449219
bi 3 loss 5.112672805786133
Layer  2  loss:  4.994688510894775 0.0 10.553041458129883
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([124, 467, 238, 181], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 4.703926086425781
bi 1 loss 4.97001838684082
bi 2 loss 4.996728897094727
bi 3 loss 5.315776348114014
Layer  3  loss:  5.134799480438232 0.0 9.903223037719727
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1021
Curr loss timestep torch.Size([500, 4]) tensor([ 98, 346, 290, 295], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 4.742702484130859
bi 1 loss 5.153884410858154
bi 2 loss 5.267870903015137
bi 3 loss 5.270061492919922
Layer  4  loss:  5.284530162811279 0.0 10.051933288574219
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([134, 325, 199, 208], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.960550308227539
bi 1 loss 5.222918510437012
bi 2 loss 5.575417518615723
bi 3 loss 5.239551067352295
Layer  5  loss:  5.318231105804443 0.0 10.110777854919434
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([ 97, 479, 130, 190], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 5.017016410827637
bi 1 loss 5.248081684112549
bi 2 loss 5.5838398933410645
bi 3 loss 5.306151390075684
Layer  6  loss:  5.349048614501953 0.0 9.81071662902832
logits torch.Size([500, 4, 1024]) labels torch.Size([500, 4]) 0 1022
Curr loss timestep torch.Size([500, 4]) tensor([110, 480, 359, 257], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.8955230712890625
bi 1 loss 5.288039684295654
bi 2 loss 5.685396194458008
bi 3 loss 5.356125354766846
Epoch 0: :   3%|▎         | 15728/600000 [05:03<3:07:49, v_num=12, reduced_train_loss=0.483, global_step=15726.0, consumed_samples=62908.0, train_step_timing in s=0.356]Epoch 0: :   3%|▎         | 15728/600000 [05:03<3:07:49, v_num=12, reduced_train_loss=39.00, global_step=15727.0, consumed_samples=62912.0, train_step_timing in s=0.333]loss mask original None

First layer loss:  0.05399736762046814 torch.Size([559, 4]) 2.364025354385376 0.0
Max loss timestep torch.Size([559, 4]) tensor([ 86, 537, 103, 523], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.021133948117494583
speech mask sum tensor(242, device='cuda:0') loss mask sum tensor(242, device='cuda:0')
bi 1 loss 0.08404681086540222
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 2 loss 0.024797815829515457
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 3 loss 0.052191052585840225
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
logits torch.Size([559, 4, 257024]) labels torch.Size([559, 4]) 0 257022
Layer  0  loss:  0.06690827757120132 0.0 4.14624547958374
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([201, 534,  92, 523], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.031827375292778015
bi 1 loss 0.09106364101171494
bi 2 loss 0.04114167392253876
bi 3 loss 0.07078654319047928
Layer  1  loss:  0.07169260084629059 0.0 5.080887794494629
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([ 51, 534,  81, 471], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.035461608320474625
bi 1 loss 0.09735961258411407
bi 2 loss 0.031082315370440483
bi 3 loss 0.07899975031614304
Layer  2  loss:  0.06958789378404617 0.0 4.666854381561279
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([225, 536, 112, 397], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.025435103103518486
bi 1 loss 0.11901482194662094
bi 2 loss 0.02762593887746334
bi 3 loss 0.05954763665795326
Layer  3  loss:  0.07474872469902039 0.0 5.891418933868408
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([236, 536,  74, 311], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.03191542252898216
bi 1 loss 0.11958642303943634
bi 2 loss 0.05104035511612892
bi 3 loss 0.06307234615087509
Layer  4  loss:  0.06928076595067978 0.0 9.63354206085205
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1022
Curr loss timestep torch.Size([559, 4]) tensor([ 95, 536, 133, 279], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.030967755243182182
bi 1 loss 0.11054108291864395
bi 2 loss 0.03417832776904106
bi 3 loss 0.06170649081468582
Layer  5  loss:  0.07144660502672195 0.0 8.020960807800293
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([251, 536,  72, 522], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.025308240205049515
bi 1 loss 0.11693819612264633
bi 2 loss 0.029993796721100807
bi 3 loss 0.06598006188869476
Layer  6  loss:  0.06980407983064651 0.0 6.900792121887207
logits torch.Size([559, 4, 1024]) labels torch.Size([559, 4]) 0 1023
Curr loss timestep torch.Size([559, 4]) tensor([200, 536,  79, 361], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.0346837043762207
bi 1 loss 0.11635342985391617
bi 2 loss 0.031806718558073044
bi 3 loss 0.056426435708999634
Epoch 0: :   3%|▎         | 15729/600000 [05:03<3:08:04, v_num=12, reduced_train_loss=39.00, global_step=15727.0, consumed_samples=62912.0, train_step_timing in s=0.333]Epoch 0: :   3%|▎         | 15729/600000 [05:03<3:08:04, v_num=12, reduced_train_loss=0.547, global_step=15728.0, consumed_samples=62916.0, train_step_timing in s=0.382]loss mask original None

First layer loss:  0.20181716978549957 torch.Size([566, 4]) 19.27370262145996 0.0
Max loss timestep torch.Size([566, 4]) tensor([269, 119, 325, 426], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.12003663182258606
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
bi 1 loss 0.039129916578531265
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 0.2702426612377167
speech mask sum tensor(303, device='cuda:0') loss mask sum tensor(303, device='cuda:0')
bi 3 loss 0.25509825348854065
speech mask sum tensor(370, device='cuda:0') loss mask sum tensor(370, device='cuda:0')
logits torch.Size([566, 4, 257024]) labels torch.Size([566, 4]) 0 257022
Layer  0  loss:  0.19347815215587616 0.0 11.493809700012207
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([367, 161, 325, 323], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.1319301873445511
bi 1 loss 0.05577811598777771
bi 2 loss 0.20017895102500916
bi 3 loss 0.2757478356361389
Layer  1  loss:  0.20957548916339874 0.0 15.343796730041504
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([267,  92, 272, 539], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.1967279464006424
bi 1 loss 0.036666613072156906
bi 2 loss 0.25089123845100403
bi 3 loss 0.2458813190460205
Layer  2  loss:  0.23198702931404114 0.0 12.848837852478027
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([269, 156, 324, 534], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.21074549853801727
bi 1 loss 0.0335824228823185
bi 2 loss 0.22816123068332672
bi 3 loss 0.31964269280433655
Layer  3  loss:  0.2239806056022644 0.0 15.185389518737793
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([269, 165, 325, 414], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.1595340222120285
bi 1 loss 0.025002125650644302
bi 2 loss 0.2512560486793518
bi 3 loss 0.31323036551475525
Layer  4  loss:  0.2808828055858612 0.0 15.077942848205566
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([269, 161, 324, 427], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.21898053586483002
bi 1 loss 0.051003407686948776
bi 2 loss 0.2674744427204132
bi 3 loss 0.41297534108161926
Layer  5  loss:  0.2500820755958557 0.0 12.428173065185547
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1020
Curr loss timestep torch.Size([566, 4]) tensor([269,  93, 324, 427], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.20468081533908844
bi 1 loss 0.0748487338423729
bi 2 loss 0.2097301185131073
bi 3 loss 0.3743387460708618
Layer  6  loss:  0.2475610375404358 0.0 13.01668930053711
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([269, 173, 325, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.1850079447031021
bi 1 loss 0.047395721077919006
bi 2 loss 0.2538340985774994
bi 3 loss 0.3532595932483673
Epoch 0: :   3%|▎         | 15730/600000 [05:04<3:08:19, v_num=12, reduced_train_loss=0.547, global_step=15728.0, consumed_samples=62916.0, train_step_timing in s=0.382]Epoch 0: :   3%|▎         | 15730/600000 [05:04<3:08:19, v_num=12, reduced_train_loss=1.840, global_step=15729.0, consumed_samples=62920.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  0.034973397850990295 torch.Size([461, 4]) 1.5497790575027466 0.0
Max loss timestep torch.Size([461, 4]) tensor([154, 421, 234,  92], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.03207921236753464
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 1 loss 0.06310740113258362
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
bi 2 loss 0.028317758813500404
speech mask sum tensor(311, device='cuda:0') loss mask sum tensor(311, device='cuda:0')
bi 3 loss 0.011305202730000019
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
logits torch.Size([461, 4, 257024]) labels torch.Size([461, 4]) 0 257023
Layer  0  loss:  0.042386677116155624 0.0 3.7146949768066406
logits torch.Size([461, 4, 1024]) labels torch.Size([461, 4]) 0 1023
Curr loss timestep torch.Size([461, 4]) tensor([245, 418, 238,  71], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.03205856308341026
bi 1 loss 0.08855798840522766
bi 2 loss 0.029978159815073013
bi 3 loss 0.026227334514260292
Layer  1  loss:  0.03852826729416847 0.0 3.095303773880005
logits torch.Size([461, 4, 1024]) labels torch.Size([461, 4]) 0 1023
Curr loss timestep torch.Size([461, 4]) tensor([190, 421, 296,  98], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.026249488815665245
bi 1 loss 0.07488489151000977
bi 2 loss 0.03517652302980423
bi 3 loss 0.010611297562718391
Layer  2  loss:  0.028803259134292603 0.0 0.8377853631973267
logits torch.Size([461, 4, 1024]) labels torch.Size([461, 4]) 0 1023
Curr loss timestep torch.Size([461, 4]) tensor([169, 417, 376, 103], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.028891803696751595
bi 1 loss 0.03967000171542168
bi 2 loss 0.025140812620520592
bi 3 loss 0.02077575959265232
Layer  3  loss:  0.045485444366931915 0.0 5.102035999298096
logits torch.Size([461, 4, 1024]) labels torch.Size([461, 4]) 0 1020
Curr loss timestep torch.Size([461, 4]) tensor([ 69, 420, 352,  68], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.03508767485618591
bi 1 loss 0.10663236677646637
bi 2 loss 0.027832884341478348
bi 3 loss 0.01966352015733719
Layer  4  loss:  0.04878654703497887 0.0 6.632505416870117
logits torch.Size([461, 4, 1024]) labels torch.Size([461, 4]) 0 1023
Curr loss timestep torch.Size([461, 4]) tensor([153, 420, 392,  69], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.03156949207186699
bi 1 loss 0.11573798954486847
bi 2 loss 0.03069557435810566
bi 3 loss 0.03233950585126877
Layer  5  loss:  0.04136364534497261 0.0 2.0438485145568848
logits torch.Size([461, 4, 1024]) labels torch.Size([461, 4]) 0 1023
Curr loss timestep torch.Size([461, 4]) tensor([120, 420, 254,  81], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.04024900123476982
bi 1 loss 0.060223110020160675
bi 2 loss 0.03454555943608284
bi 3 loss 0.0331173837184906
Layer  6  loss:  0.04834164306521416 0.0 4.634593963623047
logits torch.Size([461, 4, 1024]) labels torch.Size([461, 4]) 0 1023
Curr loss timestep torch.Size([461, 4]) tensor([195, 421, 371,  96], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 0.03684895113110542
bi 1 loss 0.10499734431505203
bi 2 loss 0.03395918756723404
bi 3 loss 0.021457230672240257
Epoch 0: :   3%|▎         | 15731/600000 [05:04<3:08:33, v_num=12, reduced_train_loss=1.840, global_step=15729.0, consumed_samples=62920.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15731/600000 [05:04<3:08:33, v_num=12, reduced_train_loss=0.329, global_step=15730.0, consumed_samples=62924.0, train_step_timing in s=0.340]loss mask original None

First layer loss:  0.029300792142748833 torch.Size([371, 4]) 0.8886364102363586 0.0
Max loss timestep torch.Size([371, 4]) tensor([167, 304, 164,  81], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.012865572236478329
speech mask sum tensor(126, device='cuda:0') loss mask sum tensor(126, device='cuda:0')
bi 1 loss 0.03629487380385399
speech mask sum tensor(218, device='cuda:0') loss mask sum tensor(218, device='cuda:0')
bi 2 loss 0.026229754090309143
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 3 loss 0.041362568736076355
speech mask sum tensor(99, device='cuda:0') loss mask sum tensor(99, device='cuda:0')
logits torch.Size([371, 4, 257024]) labels torch.Size([371, 4]) 0 257022
Layer  0  loss:  0.02792297676205635 0.0 1.8537105321884155
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([ 88, 304,  74, 142], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.015865352004766464
bi 1 loss 0.04608280211687088
bi 2 loss 0.022471493110060692
bi 3 loss 0.014899540692567825
Layer  1  loss:  0.02750770002603531 0.0 0.9820080995559692
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([ 83, 333, 174, 130], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.01709989830851555
bi 1 loss 0.033434491604566574
bi 2 loss 0.030391128733754158
bi 3 loss 0.021557576954364777
Layer  2  loss:  0.026691561564803123 0.0 1.3932660818099976
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([169, 333, 155,  90], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.008440189994871616
bi 1 loss 0.038061995059251785
bi 2 loss 0.03084196336567402
bi 3 loss 0.0160368625074625
Layer  3  loss:  0.0266618300229311 0.0 0.721674919128418
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1020
Curr loss timestep torch.Size([371, 4]) tensor([152, 227, 210,  96], device='cuda:0') tensor(96, device='cuda:0')
bi 0 loss 0.013536768965423107
bi 1 loss 0.031681522727012634
bi 2 loss 0.027196289971470833
bi 3 loss 0.031173869967460632
Layer  4  loss:  0.0280296728014946 0.0 1.519386649131775
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([ 87, 333,  62, 101], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.014125197194516659
bi 1 loss 0.03537838160991669
bi 2 loss 0.033243242651224136
bi 3 loss 0.018432529643177986
Layer  5  loss:  0.026141321286559105 0.0 0.8585691452026367
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([172, 345, 194, 126], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.007579481694847345
bi 1 loss 0.0432378388941288
bi 2 loss 0.02124117501080036
bi 3 loss 0.022562358528375626
Layer  6  loss:  0.028880005702376366 0.0 1.637845516204834
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([ 87, 333,  53, 147], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.00986496638506651
bi 1 loss 0.035579830408096313
bi 2 loss 0.02769462577998638
bi 3 loss 0.040854234248399734
Epoch 0: :   3%|▎         | 15732/600000 [05:04<3:08:44, v_num=12, reduced_train_loss=0.329, global_step=15730.0, consumed_samples=62924.0, train_step_timing in s=0.340]Epoch 0: :   3%|▎         | 15732/600000 [05:04<3:08:44, v_num=12, reduced_train_loss=0.221, global_step=15731.0, consumed_samples=62928.0, train_step_timing in s=0.288]loss mask original None

First layer loss:  0.05474201589822769 torch.Size([518, 4]) 5.508937835693359 0.0
Max loss timestep torch.Size([518, 4]) tensor([289, 176, 318, 409], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.08063304424285889
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
bi 1 loss 0.0447201132774353
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 2 loss 0.037875719368457794
speech mask sum tensor(270, device='cuda:0') loss mask sum tensor(270, device='cuda:0')
bi 3 loss 0.03559670224785805
speech mask sum tensor(279, device='cuda:0') loss mask sum tensor(279, device='cuda:0')
logits torch.Size([518, 4, 257024]) labels torch.Size([518, 4]) 0 257023
Layer  0  loss:  0.0569329559803009 0.0 6.2239155769348145
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([289, 205, 319, 404], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.09308955818414688
bi 1 loss 0.03256365656852722
bi 2 loss 0.036478545516729355
bi 3 loss 0.032365716993808746
Layer  1  loss:  0.06572683155536652 0.0 7.928858280181885
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([288,  87, 316, 421], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.08846006542444229
bi 1 loss 0.07343461364507675
bi 2 loss 0.052053339779376984
bi 3 loss 0.03959338739514351
Layer  2  loss:  0.1083996519446373 0.0 8.376890182495117
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1022
Curr loss timestep torch.Size([518, 4]) tensor([288, 198, 320, 332], device='cuda:0') tensor(332, device='cuda:0')
bi 0 loss 0.0698477104306221
bi 1 loss 0.03654785826802254
bi 2 loss 0.062077898532152176
bi 3 loss 0.24927036464214325
Layer  3  loss:  0.06740324199199677 0.0 5.534632682800293
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1022
Curr loss timestep torch.Size([518, 4]) tensor([288, 188, 319, 298], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 0.0873722955584526
bi 1 loss 0.10396604984998703
bi 2 loss 0.0462692528963089
bi 3 loss 0.03843348100781441
Layer  4  loss:  0.0647425651550293 0.0 10.286995887756348
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1022
Curr loss timestep torch.Size([518, 4]) tensor([289, 166, 320, 325], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.09039205312728882
bi 1 loss 0.043381333351135254
bi 2 loss 0.036486171185970306
bi 3 loss 0.06264672428369522
Layer  5  loss:  0.10201054066419601 0.0 5.26321268081665
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1023
Curr loss timestep torch.Size([518, 4]) tensor([328, 142, 314, 331], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.09366200864315033
bi 1 loss 0.042222823947668076
bi 2 loss 0.0910964235663414
bi 3 loss 0.15540577471256256
Layer  6  loss:  0.0835665911436081 0.0 8.758628845214844
logits torch.Size([518, 4, 1024]) labels torch.Size([518, 4]) 0 1019
Curr loss timestep torch.Size([518, 4]) tensor([289, 183, 318, 323], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.10587487369775772
bi 1 loss 0.050146788358688354
bi 2 loss 0.051935113966464996
bi 3 loss 0.09596601128578186
Epoch 0: :   3%|▎         | 15733/600000 [05:05<3:08:58, v_num=12, reduced_train_loss=0.221, global_step=15731.0, consumed_samples=62928.0, train_step_timing in s=0.288]Epoch 0: :   3%|▎         | 15733/600000 [05:05<3:08:58, v_num=12, reduced_train_loss=0.604, global_step=15732.0, consumed_samples=62932.0, train_step_timing in s=0.360]loss mask original None

First layer loss:  0.04394516348838806 torch.Size([485, 4]) 4.294497489929199 0.0
Max loss timestep torch.Size([485, 4]) tensor([192, 229, 300, 239], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 0.04337439313530922
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 1 loss 0.04876546934247017
speech mask sum tensor(252, device='cuda:0') loss mask sum tensor(252, device='cuda:0')
bi 2 loss 0.04203562065958977
speech mask sum tensor(340, device='cuda:0') loss mask sum tensor(340, device='cuda:0')
bi 3 loss 0.03969039022922516
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
logits torch.Size([485, 4, 257024]) labels torch.Size([485, 4]) 0 257023
Layer  0  loss:  0.05012704059481621 0.0 3.351647138595581
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1023
Curr loss timestep torch.Size([485, 4]) tensor([319, 269, 450, 276], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.05428116023540497
bi 1 loss 0.048326388001441956
bi 2 loss 0.04809064418077469
bi 3 loss 0.05281352624297142
Layer  1  loss:  0.03917711228132248 0.0 0.9489615559577942
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([263, 270, 450, 294], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 0.02618032693862915
bi 1 loss 0.04616928473114967
bi 2 loss 0.04061971604824066
bi 3 loss 0.04347063601016998
Layer  2  loss:  0.12124446779489517 0.0 9.812722206115723
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([188, 181, 255, 271], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 0.03438137471675873
bi 1 loss 0.047776829451322556
bi 2 loss 0.24987106025218964
bi 3 loss 0.05313315615057945
Layer  3  loss:  0.042971160262823105 0.0 1.3146525621414185
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([252, 263, 283, 286], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.037481386214494705
bi 1 loss 0.04245438799262047
bi 2 loss 0.05017995089292526
bi 3 loss 0.03174366429448128
Layer  4  loss:  0.04357659071683884 0.0 1.7489805221557617
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1023
Curr loss timestep torch.Size([485, 4]) tensor([168,  72, 205, 228], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 0.04459845647215843
bi 1 loss 0.04419638216495514
bi 2 loss 0.04420647770166397
bi 3 loss 0.038025159388780594
Layer  5  loss:  0.09348048269748688 0.0 7.188997745513916
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1022
Curr loss timestep torch.Size([485, 4]) tensor([223, 238, 255, 277], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 0.03043730929493904
bi 1 loss 0.05113187059760094
bi 2 loss 0.18472671508789062
bi 3 loss 0.024538686498999596
Layer  6  loss:  0.05472394451498985 0.0 2.4140591621398926
logits torch.Size([485, 4, 1024]) labels torch.Size([485, 4]) 0 1019
Curr loss timestep torch.Size([485, 4]) tensor([319,  78, 472, 236], device='cuda:0') tensor(472, device='cuda:0')
bi 0 loss 0.042204756289720535
bi 1 loss 0.04519420117139816
bi 2 loss 0.07927308231592178
bi 3 loss 0.02290276065468788
Epoch 0: :   3%|▎         | 15734/600000 [05:05<3:09:11, v_num=12, reduced_train_loss=0.604, global_step=15732.0, consumed_samples=62932.0, train_step_timing in s=0.360]Epoch 0: :   3%|▎         | 15734/600000 [05:05<3:09:11, v_num=12, reduced_train_loss=0.489, global_step=15733.0, consumed_samples=62936.0, train_step_timing in s=0.343]loss mask original None

First layer loss:  3.278390645980835 torch.Size([788, 4]) 11.624893188476562 0.0
Max loss timestep torch.Size([788, 4]) tensor([691, 203, 320, 146], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 3.4215869903564453
speech mask sum tensor(478, device='cuda:0') loss mask sum tensor(478, device='cuda:0')
bi 1 loss 3.7261219024658203
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 2 loss 2.9000368118286133
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
bi 3 loss 2.9542253017425537
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
logits torch.Size([788, 4, 257024]) labels torch.Size([788, 4]) 0 257023
Layer  0  loss:  4.007209300994873 0.0 12.193035125732422
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1023
Curr loss timestep torch.Size([788, 4]) tensor([568, 208, 279, 231], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.096354007720947
bi 1 loss 4.423314094543457
bi 2 loss 4.1630353927612305
bi 3 loss 3.5261998176574707
Layer  1  loss:  4.451080799102783 0.0 10.407028198242188
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1022
Curr loss timestep torch.Size([788, 4]) tensor([317, 225, 228, 342], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 4.5862202644348145
bi 1 loss 4.918062210083008
bi 2 loss 4.1253485679626465
bi 3 loss 4.10416316986084
Layer  2  loss:  4.712889194488525 0.0 11.689777374267578
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1022
Curr loss timestep torch.Size([788, 4]) tensor([328, 259, 305, 129], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 4.637771129608154
bi 1 loss 5.297514915466309
bi 2 loss 4.636486530303955
bi 3 loss 4.568554401397705
Layer  3  loss:  4.764461040496826 0.0 11.189071655273438
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1023
Curr loss timestep torch.Size([788, 4]) tensor([711, 271, 300, 340], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 4.907256126403809
bi 1 loss 5.071591854095459
bi 2 loss 4.50832986831665
bi 3 loss 4.456127166748047
Layer  4  loss:  4.950552463531494 0.0 10.2404203414917
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1022
Curr loss timestep torch.Size([788, 4]) tensor([676, 236, 283, 132], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 5.043521404266357
bi 1 loss 5.220641613006592
bi 2 loss 4.707450866699219
bi 3 loss 4.750255107879639
Layer  5  loss:  5.036569118499756 0.0 10.71737003326416
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1023
Curr loss timestep torch.Size([788, 4]) tensor([513, 230, 274, 207], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 5.101095676422119
bi 1 loss 5.290128231048584
bi 2 loss 4.750681400299072
bi 3 loss 4.9213738441467285
Layer  6  loss:  5.036185264587402 0.0 10.293230056762695
logits torch.Size([788, 4, 1024]) labels torch.Size([788, 4]) 0 1022
Curr loss timestep torch.Size([788, 4]) tensor([390, 285, 291, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 5.1429572105407715
bi 1 loss 5.201690673828125
bi 2 loss 4.849032402038574
bi 3 loss 4.83912467956543
Epoch 0: :   3%|▎         | 15735/600000 [05:06<3:09:30, v_num=12, reduced_train_loss=0.489, global_step=15733.0, consumed_samples=62936.0, train_step_timing in s=0.343]Epoch 0: :   3%|▎         | 15735/600000 [05:06<3:09:30, v_num=12, reduced_train_loss=36.20, global_step=15734.0, consumed_samples=62940.0, train_step_timing in s=0.483]loss mask original None

First layer loss:  3.4619433879852295 torch.Size([240, 4]) 12.335594177246094 0.0
Max loss timestep torch.Size([240, 4]) tensor([113, 179, 153, 112], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 3.1914403438568115
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 1 loss 3.5534632205963135
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 2 loss 3.4550681114196777
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 3 loss 3.6467783451080322
speech mask sum tensor(198, device='cuda:0') loss mask sum tensor(198, device='cuda:0')
logits torch.Size([240, 4, 257024]) labels torch.Size([240, 4]) 0 257022
Layer  0  loss:  3.9508891105651855 0.0 11.131769180297852
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1023
Curr loss timestep torch.Size([240, 4]) tensor([175, 190, 107,  85], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 4.142556190490723
bi 1 loss 3.8366081714630127
bi 2 loss 3.9469780921936035
bi 3 loss 3.8489909172058105
Layer  1  loss:  4.45009708404541 0.0 10.42254638671875
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1023
Curr loss timestep torch.Size([240, 4]) tensor([155, 192, 179, 202], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.664593696594238
bi 1 loss 4.220417499542236
bi 2 loss 4.335198879241943
bi 3 loss 4.47061014175415
Layer  2  loss:  4.701784610748291 0.0 10.286853790283203
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([168, 187, 174, 176], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 4.878137588500977
bi 1 loss 4.420664310455322
bi 2 loss 4.6340813636779785
bi 3 loss 4.738039493560791
Layer  3  loss:  4.697155952453613 0.0 10.440755844116211
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([198, 199, 226, 146], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 4.879074573516846
bi 1 loss 4.490992546081543
bi 2 loss 4.631237983703613
bi 3 loss 4.694126129150391
Layer  4  loss:  4.9853410720825195 0.0 9.341028213500977
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1023
Curr loss timestep torch.Size([240, 4]) tensor([ 99, 220, 108, 188], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 5.304511070251465
bi 1 loss 4.61817741394043
bi 2 loss 4.835488796234131
bi 3 loss 5.0100908279418945
Layer  5  loss:  5.091799259185791 0.0 9.203144073486328
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([146, 219, 127, 174], device='cuda:0') tensor(165, device='cuda:0')
bi 0 loss 5.211391448974609
bi 1 loss 4.744894027709961
bi 2 loss 5.097358703613281
bi 3 loss 5.144242286682129
Layer  6  loss:  5.080028057098389 0.0 9.2652587890625
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([123, 212, 189,  94], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 5.281763076782227
bi 1 loss 4.6557440757751465
bi 2 loss 5.062280178070068
bi 3 loss 5.118904113769531
Epoch 0: :   3%|▎         | 15736/600000 [05:06<3:09:39, v_num=12, reduced_train_loss=36.20, global_step=15734.0, consumed_samples=62940.0, train_step_timing in s=0.483]Epoch 0: :   3%|▎         | 15736/600000 [05:06<3:09:39, v_num=12, reduced_train_loss=36.40, global_step=15735.0, consumed_samples=62944.0, train_step_timing in s=0.240]loss mask original None

First layer loss:  0.042132116854190826 torch.Size([581, 4]) 2.1312310695648193 0.0
Max loss timestep torch.Size([581, 4]) tensor([ 66, 261, 416, 118], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.024737702682614326
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 1 loss 0.042750757187604904
speech mask sum tensor(129, device='cuda:0') loss mask sum tensor(129, device='cuda:0')
bi 2 loss 0.06024078652262688
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
bi 3 loss 0.02558162994682789
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
logits torch.Size([581, 4, 257024]) labels torch.Size([581, 4]) 0 257022
Layer  0  loss:  0.05055733025074005 0.0 3.4211008548736572
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([272, 259, 323,  99], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.033540401607751846
bi 1 loss 0.0493348129093647
bi 2 loss 0.07183859497308731
bi 3 loss 0.026985779404640198
Layer  1  loss:  0.05561278760433197 0.0 3.5389177799224854
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([272, 259, 371, 189], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.05162612348794937
bi 1 loss 0.08708968758583069
bi 2 loss 0.06083591654896736
bi 3 loss 0.02540399320423603
Layer  2  loss:  0.07230788469314575 0.0 5.985321521759033
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([270, 259, 371, 152], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.05480581149458885
bi 1 loss 0.05287913605570793
bi 2 loss 0.11030776798725128
bi 3 loss 0.02223687618970871
Layer  3  loss:  0.047309309244155884 0.0 5.764411926269531
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([158, 259, 371, 104], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.017128003761172295
bi 1 loss 0.05857768654823303
bi 2 loss 0.07628681510686874
bi 3 loss 0.016863351687788963
Layer  4  loss:  0.060610201209783554 0.0 3.4770376682281494
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([272, 259, 372, 212], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.04231741651892662
bi 1 loss 0.049629874527454376
bi 2 loss 0.08884751051664352
bi 3 loss 0.029425805434584618
Layer  5  loss:  0.05871567502617836 0.0 6.047607421875
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1018
Curr loss timestep torch.Size([581, 4]) tensor([305, 259, 372, 232], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.02792370319366455
bi 1 loss 0.060400452464818954
bi 2 loss 0.09045130759477615
bi 3 loss 0.029758842661976814
Layer  6  loss:  0.05437694117426872 0.0 3.921820640563965
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1020
Curr loss timestep torch.Size([581, 4]) tensor([270, 226, 295, 221], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.033059120178222656
bi 1 loss 0.030455762520432472
bi 2 loss 0.0914672389626503
bi 3 loss 0.01619129069149494
Epoch 0: :   3%|▎         | 15737/600000 [05:06<3:09:55, v_num=12, reduced_train_loss=36.40, global_step=15735.0, consumed_samples=62944.0, train_step_timing in s=0.240]Epoch 0: :   3%|▎         | 15737/600000 [05:06<3:09:55, v_num=12, reduced_train_loss=0.442, global_step=15736.0, consumed_samples=62948.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  0.006164588965475559 torch.Size([283, 4]) 0.047214407473802567 0.0
Max loss timestep torch.Size([283, 4]) tensor([167, 181,  83, 129], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 0.005289500579237938
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
bi 1 loss 0.007216637954115868
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 2 loss 0.007772430777549744
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 3 loss 0.004915623925626278
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
logits torch.Size([283, 4, 257024]) labels torch.Size([283, 4]) 0 257023
Layer  0  loss:  0.005822502076625824 0.0 0.24052660167217255
logits torch.Size([283, 4, 1024]) labels torch.Size([283, 4]) 0 1023
Curr loss timestep torch.Size([283, 4]) tensor([260, 181, 127, 113], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.007034149952232838
bi 1 loss 0.006114503834396601
bi 2 loss 0.00552084855735302
bi 3 loss 0.0043912651017308235
Layer  1  loss:  0.006129383575171232 0.0 0.07420963793992996
logits torch.Size([283, 4, 1024]) labels torch.Size([283, 4]) 0 1023
Curr loss timestep torch.Size([283, 4]) tensor([238, 186,  95, 165], device='cuda:0') tensor(238, device='cuda:0')
bi 0 loss 0.004997888579964638
bi 1 loss 0.006671753246337175
bi 2 loss 0.007008564658463001
bi 3 loss 0.0062220352701842785
Layer  2  loss:  0.005608000326901674 0.0 0.06415248662233353
logits torch.Size([283, 4, 1024]) labels torch.Size([283, 4]) 0 1023
Curr loss timestep torch.Size([283, 4]) tensor([173, 146,  83, 166], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 0.005181154236197472
bi 1 loss 0.00704185338690877
bi 2 loss 0.006100528407841921
bi 3 loss 0.004333364311605692
Layer  3  loss:  0.005657771602272987 0.0 0.07435107976198196
logits torch.Size([283, 4, 1024]) labels torch.Size([283, 4]) 0 1021
Curr loss timestep torch.Size([283, 4]) tensor([177, 140, 104, 118], device='cuda:0') tensor(104, device='cuda:0')
bi 0 loss 0.005485984031111002
bi 1 loss 0.0072983643040061
bi 2 loss 0.00569518655538559
bi 3 loss 0.004241298884153366
Layer  4  loss:  0.00616035982966423 0.0 0.10713525116443634
logits torch.Size([283, 4, 1024]) labels torch.Size([283, 4]) 0 1022
Curr loss timestep torch.Size([283, 4]) tensor([164, 125,  90, 179], device='cuda:0') tensor(90, device='cuda:0')
bi 0 loss 0.005459269043058157
bi 1 loss 0.00680921645835042
bi 2 loss 0.007515303324908018
bi 3 loss 0.005295879207551479
Layer  5  loss:  0.006282535847276449 0.0 0.0566442646086216
logits torch.Size([283, 4, 1024]) labels torch.Size([283, 4]) 0 1022
Curr loss timestep torch.Size([283, 4]) tensor([267, 170, 117, 114], device='cuda:0') tensor(114, device='cuda:0')
bi 0 loss 0.0055168550461530685
bi 1 loss 0.007501009851694107
bi 2 loss 0.007614044938236475
bi 3 loss 0.004959758371114731
Layer  6  loss:  0.005457185674458742 0.0 0.040524937212467194
logits torch.Size([283, 4, 1024]) labels torch.Size([283, 4]) 0 1020
Curr loss timestep torch.Size([283, 4]) tensor([237, 147,  86, 161], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 0.004202916286885738
bi 1 loss 0.006134849041700363
bi 2 loss 0.007579793222248554
bi 3 loss 0.004607612732797861
Epoch 0: :   3%|▎         | 15738/600000 [05:07<3:10:05, v_num=12, reduced_train_loss=0.442, global_step=15736.0, consumed_samples=62948.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15738/600000 [05:07<3:10:05, v_num=12, reduced_train_loss=0.0473, global_step=15737.0, consumed_samples=6.3e+4, train_step_timing in s=0.248]loss mask original None

First layer loss:  0.051208581775426865 torch.Size([471, 4]) 6.815364837646484 0.0
Max loss timestep torch.Size([471, 4]) tensor([258, 146, 100, 412], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.04844959080219269
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 1 loss 0.0607118159532547
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
bi 2 loss 0.03515039384365082
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 3 loss 0.05369136855006218
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
logits torch.Size([471, 4, 257024]) labels torch.Size([471, 4]) 0 257022
Layer  0  loss:  0.04712309315800667 0.0 6.88263463973999
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([211, 150, 128, 410], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.033379632979631424
bi 1 loss 0.04641767218708992
bi 2 loss 0.013157687149941921
bi 3 loss 0.06628920882940292
Layer  1  loss:  0.059019785374403 0.0 8.46792221069336
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([260,  77, 135, 410], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.043758563697338104
bi 1 loss 0.038609281182289124
bi 2 loss 0.021760249510407448
bi 3 loss 0.08797209709882736
Layer  2  loss:  0.04999855160713196 0.0 3.474064350128174
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([260,  93, 146, 410], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.05750982090830803
bi 1 loss 0.028325023129582405
bi 2 loss 0.026049934327602386
bi 3 loss 0.05961688235402107
Layer  3  loss:  0.051688194274902344 0.0 6.164051532745361
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1021
Curr loss timestep torch.Size([471, 4]) tensor([ 76,  80, 103, 412], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.04870632290840149
bi 1 loss 0.02691161446273327
bi 2 loss 0.023534981533885002
bi 3 loss 0.07116375863552094
Layer  4  loss:  0.05035566911101341 0.0 5.228717803955078
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([260, 120, 133, 410], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.04682224243879318
bi 1 loss 0.03215648606419563
bi 2 loss 0.021439380943775177
bi 3 loss 0.06781814247369766
Layer  5  loss:  0.04846939444541931 0.0 9.157544136047363
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1021
Curr loss timestep torch.Size([471, 4]) tensor([105, 163, 148, 410], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.03531556949019432
bi 1 loss 0.03176708146929741
bi 2 loss 0.014228466898202896
bi 3 loss 0.07363758981227875
Layer  6  loss:  0.05167414993047714 0.0 6.256994724273682
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([117, 167, 151, 412], device='cuda:0') tensor(412, device='cuda:0')
bi 0 loss 0.03722771629691124
bi 1 loss 0.03554222732782364
bi 2 loss 0.01680009253323078
bi 3 loss 0.07770918309688568
Epoch 0: :   3%|▎         | 15739/600000 [05:07<3:10:18, v_num=12, reduced_train_loss=0.0473, global_step=15737.0, consumed_samples=6.3e+4, train_step_timing in s=0.248]Epoch 0: :   3%|▎         | 15739/600000 [05:07<3:10:18, v_num=12, reduced_train_loss=0.410, global_step=15738.0, consumed_samples=6.3e+4, train_step_timing in s=0.350] loss mask original None

First layer loss:  0.2120596319437027 torch.Size([666, 4]) 9.503839492797852 0.0
Max loss timestep torch.Size([666, 4]) tensor([284, 439, 284, 221], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.2634337842464447
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
bi 1 loss 0.2221706211566925
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
bi 2 loss 0.1741996705532074
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 3 loss 0.05875629931688309
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
logits torch.Size([666, 4, 257024]) labels torch.Size([666, 4]) 0 257023
Layer  0  loss:  0.2449806034564972 0.0 16.437440872192383
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([584, 488, 257, 269], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.29210546612739563
bi 1 loss 0.2264166623353958
bi 2 loss 0.27778974175453186
bi 3 loss 0.06493543088436127
Layer  1  loss:  0.2255106419324875 0.0 17.615230560302734
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([568, 487, 257, 257], device='cuda:0') tensor(568, device='cuda:0')
bi 0 loss 0.25402072072029114
bi 1 loss 0.2159663438796997
bi 2 loss 0.2901570796966553
bi 3 loss 0.041475169360637665
Layer  2  loss:  0.23738299310207367 0.0 13.031377792358398
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1022
Curr loss timestep torch.Size([666, 4]) tensor([568, 488, 257, 211], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.22772373259067535
bi 1 loss 0.2571293115615845
bi 2 loss 0.33010125160217285
bi 3 loss 0.07791995257139206
Layer  3  loss:  0.2531642019748688 0.0 16.64666175842285
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([584, 487, 257, 293], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.32033324241638184
bi 1 loss 0.21327392756938934
bi 2 loss 0.28639906644821167
bi 3 loss 0.05061541870236397
Layer  4  loss:  0.26148056983947754 0.0 10.907894134521484
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([325, 488, 257, 235], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.26428431272506714
bi 1 loss 0.2842036783695221
bi 2 loss 0.3471628427505493
bi 3 loss 0.06014832481741905
Layer  5  loss:  0.28178510069847107 0.0 19.890573501586914
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([584, 488, 257, 192], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.3055208921432495
bi 1 loss 0.2631004750728607
bi 2 loss 0.37332630157470703
bi 3 loss 0.09486520290374756
Layer  6  loss:  0.27289924025535583 0.0 13.409565925598145
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1022
Curr loss timestep torch.Size([666, 4]) tensor([584, 487, 257, 238], device='cuda:0') tensor(584, device='cuda:0')
bi 0 loss 0.33661800622940063
bi 1 loss 0.2680702209472656
bi 2 loss 0.24909238517284393
bi 3 loss 0.08826277405023575
Epoch 0: :   3%|▎         | 15740/600000 [05:08<3:10:36, v_num=12, reduced_train_loss=0.410, global_step=15738.0, consumed_samples=6.3e+4, train_step_timing in s=0.350]Epoch 0: :   3%|▎         | 15740/600000 [05:08<3:10:36, v_num=12, reduced_train_loss=1.990, global_step=15739.0, consumed_samples=6.3e+4, train_step_timing in s=0.465]loss mask original None

First layer loss:  3.8457539081573486 torch.Size([596, 4]) 11.474994659423828 0.0
Max loss timestep torch.Size([596, 4]) tensor([212, 174, 418, 168], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 3.999438762664795
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 1 loss 3.874418020248413
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 2 loss 3.885282278060913
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 3 loss 3.081514358520508
speech mask sum tensor(63, device='cuda:0') loss mask sum tensor(63, device='cuda:0')
logits torch.Size([596, 4, 257024]) labels torch.Size([596, 4]) 0 257022
Layer  0  loss:  4.441655158996582 0.0 10.41261100769043
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([194, 176, 403, 159], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 4.556234836578369
bi 1 loss 4.043491840362549
bi 2 loss 4.606083869934082
bi 3 loss 3.7964608669281006
Layer  1  loss:  4.797703266143799 0.0 10.115406036376953
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1023
Curr loss timestep torch.Size([596, 4]) tensor([195, 115, 358, 155], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.857705116271973
bi 1 loss 4.525234699249268
bi 2 loss 4.999500274658203
bi 3 loss 3.799138069152832
Layer  2  loss:  4.99964714050293 0.0 9.838504791259766
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([154,  93, 313, 179], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 5.119694709777832
bi 1 loss 4.702421188354492
bi 2 loss 5.157438278198242
bi 3 loss 4.18073844909668
Layer  3  loss:  5.0991950035095215 0.0 10.162673950195312
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([111, 117, 503, 167], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 5.145188331604004
bi 1 loss 4.806070804595947
bi 2 loss 5.274076461791992
bi 3 loss 4.365786552429199
Layer  4  loss:  5.242278099060059 0.0 10.653568267822266
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([162,  94, 466, 184], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 5.397575378417969
bi 1 loss 4.957834243774414
bi 2 loss 5.393595218658447
bi 3 loss 4.341639995574951
Layer  5  loss:  5.332149982452393 0.0 9.901308059692383
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1022
Curr loss timestep torch.Size([596, 4]) tensor([163, 184, 435, 187], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 5.310579776763916
bi 1 loss 5.031598091125488
bi 2 loss 5.5145583152771
bi 3 loss 4.754296779632568
Layer  6  loss:  5.302669048309326 0.0 11.104028701782227
logits torch.Size([596, 4, 1024]) labels torch.Size([596, 4]) 0 1021
Curr loss timestep torch.Size([596, 4]) tensor([110, 159, 567, 185], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 5.346797943115234
bi 1 loss 4.983187198638916
bi 2 loss 5.517937660217285
bi 3 loss 4.35203218460083
Epoch 0: :   3%|▎         | 15741/600000 [05:08<3:10:51, v_num=12, reduced_train_loss=1.990, global_step=15739.0, consumed_samples=6.3e+4, train_step_timing in s=0.465]Epoch 0: :   3%|▎         | 15741/600000 [05:08<3:10:51, v_num=12, reduced_train_loss=39.10, global_step=15740.0, consumed_samples=6.3e+4, train_step_timing in s=0.378]loss mask original None

First layer loss:  3.694024085998535 torch.Size([548, 4]) 11.830909729003906 0.0
Max loss timestep torch.Size([548, 4]) tensor([105, 324, 240, 127], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 3.5426714420318604
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
bi 1 loss 3.5692036151885986
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 2 loss 3.5993993282318115
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 3 loss 3.869262218475342
speech mask sum tensor(426, device='cuda:0') loss mask sum tensor(426, device='cuda:0')
logits torch.Size([548, 4, 257024]) labels torch.Size([548, 4]) 0 257022
Layer  0  loss:  4.32452917098999 0.0 10.36337947845459
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([ 91, 103, 194, 335], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 3.748584508895874
bi 1 loss 4.2480010986328125
bi 2 loss 4.258237361907959
bi 3 loss 4.544274806976318
Layer  1  loss:  4.5608906745910645 0.0 10.124589920043945
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 79, 308, 193, 452], device='cuda:0') tensor(152, device='cuda:0')
bi 0 loss 4.414029121398926
bi 1 loss 4.4313273429870605
bi 2 loss 4.1929850578308105
bi 3 loss 4.815157890319824
Layer  2  loss:  4.752889156341553 0.0 9.672536849975586
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([124, 255, 186, 398], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 4.198026657104492
bi 1 loss 4.741450309753418
bi 2 loss 4.508504390716553
bi 3 loss 4.957423686981201
Layer  3  loss:  4.873361587524414 0.0 10.208795547485352
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 76, 260, 180, 410], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 4.552762031555176
bi 1 loss 4.772885322570801
bi 2 loss 4.807286262512207
bi 3 loss 5.056885719299316
Layer  4  loss:  4.982168197631836 0.0 10.267793655395508
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 73, 136, 191, 234], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.862114906311035
bi 1 loss 4.785118103027344
bi 2 loss 4.84830379486084
bi 3 loss 5.227445125579834
Layer  5  loss:  5.079559326171875 0.0 10.15932559967041
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 74, 380, 179, 339], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.826192855834961
bi 1 loss 4.9060750007629395
bi 2 loss 4.948450088500977
bi 3 loss 5.332797050476074
Layer  6  loss:  5.104788303375244 0.0 9.937240600585938
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 83, 163, 165, 169], device='cuda:0') tensor(158, device='cuda:0')
bi 0 loss 4.968234062194824
bi 1 loss 5.0018439292907715
bi 2 loss 4.965062141418457
bi 3 loss 5.269071102142334
Epoch 0: :   3%|▎         | 15742/600000 [05:08<3:11:04, v_num=12, reduced_train_loss=39.10, global_step=15740.0, consumed_samples=6.3e+4, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15742/600000 [05:08<3:11:04, v_num=12, reduced_train_loss=37.40, global_step=15741.0, consumed_samples=6.3e+4, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.18770864605903625 torch.Size([662, 4]) 12.869543075561523 0.0
Max loss timestep torch.Size([662, 4]) tensor([545, 309, 561, 322], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.2695957124233246
speech mask sum tensor(410, device='cuda:0') loss mask sum tensor(410, device='cuda:0')
bi 1 loss 0.20757390558719635
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 2 loss 0.16555163264274597
speech mask sum tensor(484, device='cuda:0') loss mask sum tensor(484, device='cuda:0')
bi 3 loss 0.054407112300395966
speech mask sum tensor(227, device='cuda:0') loss mask sum tensor(227, device='cuda:0')
logits torch.Size([662, 4, 257024]) labels torch.Size([662, 4]) 0 257022
Layer  0  loss:  0.2776651978492737 0.0 11.664115905761719
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1023
Curr loss timestep torch.Size([662, 4]) tensor([549, 365, 562, 341], device='cuda:0') tensor(559, device='cuda:0')
bi 0 loss 0.3769319951534271
bi 1 loss 0.15774640440940857
bi 2 loss 0.39086848497390747
bi 3 loss 0.05405264347791672
Layer  1  loss:  0.29163041710853577 0.0 15.274271965026855
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1023
Curr loss timestep torch.Size([662, 4]) tensor([557, 364, 311, 341], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.38329175114631653
bi 1 loss 0.18607690930366516
bi 2 loss 0.36037367582321167
bi 3 loss 0.15294575691223145
Layer  2  loss:  0.301544725894928 0.0 11.895622253417969
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1023
Curr loss timestep torch.Size([662, 4]) tensor([545, 363, 561, 364], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.29520732164382935
bi 1 loss 0.19349999725818634
bi 2 loss 0.47907784581184387
bi 3 loss 0.11199841648340225
Layer  3  loss:  0.31703490018844604 0.0 14.241470336914062
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1022
Curr loss timestep torch.Size([662, 4]) tensor([545, 364, 562, 304], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.4207235872745514
bi 1 loss 0.1922435611486435
bi 2 loss 0.41074466705322266
bi 3 loss 0.13500532507896423
Layer  4  loss:  0.32883164286613464 0.0 17.75421714782715
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1022
Curr loss timestep torch.Size([662, 4]) tensor([544, 364, 562, 341], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.4439782202243805
bi 1 loss 0.18841180205345154
bi 2 loss 0.4460088610649109
bi 3 loss 0.10175107419490814
Layer  5  loss:  0.28936639428138733 0.0 16.977262496948242
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1022
Curr loss timestep torch.Size([662, 4]) tensor([544, 364, 560, 341], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.3629723787307739
bi 1 loss 0.16836853325366974
bi 2 loss 0.41189828515052795
bi 3 loss 0.09398451447486877
Layer  6  loss:  0.3083834648132324 0.0 16.36665153503418
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1021
Curr loss timestep torch.Size([662, 4]) tensor([549, 365, 560, 364], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.37084493041038513
bi 1 loss 0.13825714588165283
bi 2 loss 0.48359236121177673
bi 3 loss 0.1015411987900734
Epoch 0: :   3%|▎         | 15743/600000 [05:09<3:11:22, v_num=12, reduced_train_loss=37.40, global_step=15741.0, consumed_samples=6.3e+4, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15743/600000 [05:09<3:11:22, v_num=12, reduced_train_loss=2.300, global_step=15742.0, consumed_samples=6.3e+4, train_step_timing in s=0.456]loss mask original None

First layer loss:  0.049894001334905624 torch.Size([423, 4]) 4.304058074951172 0.0
Max loss timestep torch.Size([423, 4]) tensor([208, 100,  72, 362], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.036997415125370026
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 1 loss 0.039675354957580566
speech mask sum tensor(76, device='cuda:0') loss mask sum tensor(76, device='cuda:0')
bi 2 loss 0.030736109241843224
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 3 loss 0.08288447558879852
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
logits torch.Size([423, 4, 257024]) labels torch.Size([423, 4]) 0 257022
Layer  0  loss:  0.05196738615632057 0.0 4.486822605133057
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([155, 129, 165, 363], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.04091523960232735
bi 1 loss 0.02164877951145172
bi 2 loss 0.026211507618427277
bi 3 loss 0.09706999361515045
Layer  1  loss:  0.04706855118274689 0.0 2.029921770095825
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([114, 125, 190, 267], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.03313671797513962
bi 1 loss 0.0380341075360775
bi 2 loss 0.037296317517757416
bi 3 loss 0.07162676751613617
Layer  2  loss:  0.06558069586753845 0.0 9.64588737487793
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([159, 152, 112, 362], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.04268600791692734
bi 1 loss 0.027533376589417458
bi 2 loss 0.029856789857149124
bi 3 loss 0.1331489533185959
Layer  3  loss:  0.047191593796014786 0.0 6.963954925537109
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1018
Curr loss timestep torch.Size([423, 4]) tensor([142,  97,  71, 362], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.03602282702922821
bi 1 loss 0.033247850835323334
bi 2 loss 0.023497959598898888
bi 3 loss 0.08437204360961914
Layer  4  loss:  0.05803430825471878 0.0 7.355668544769287
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1021
Curr loss timestep torch.Size([423, 4]) tensor([ 88, 109, 165, 362], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.04069601744413376
bi 1 loss 0.028084538877010345
bi 2 loss 0.04505624622106552
bi 3 loss 0.09630487859249115
Layer  5  loss:  0.059987086802721024 0.0 6.935329914093018
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([136, 134, 149, 362], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.04368346557021141
bi 1 loss 0.046614449471235275
bi 2 loss 0.022922659292817116
bi 3 loss 0.11401760578155518
Layer  6  loss:  0.05516330152750015 0.0 9.05261516571045
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([206, 107,  83, 362], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.04440955072641373
bi 1 loss 0.029313821345567703
bi 2 loss 0.0319807194173336
bi 3 loss 0.09591767191886902
Epoch 0: :   3%|▎         | 15744/600000 [05:09<3:11:34, v_num=12, reduced_train_loss=2.300, global_step=15742.0, consumed_samples=6.3e+4, train_step_timing in s=0.456]Epoch 0: :   3%|▎         | 15744/600000 [05:09<3:11:34, v_num=12, reduced_train_loss=0.435, global_step=15743.0, consumed_samples=6.3e+4, train_step_timing in s=0.311]loss mask original None

First layer loss:  0.07236336916685104 torch.Size([563, 4]) 4.522732734680176 0.0
Max loss timestep torch.Size([563, 4]) tensor([189, 533,  47, 324], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.06431107223033905
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 1 loss 0.08561894297599792
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 2 loss 0.047505032271146774
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 3 loss 0.051160577684640884
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
logits torch.Size([563, 4, 257024]) labels torch.Size([563, 4]) 0 257023
Layer  0  loss:  0.09252389520406723 0.0 8.136034965515137
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([177, 533,  40, 333], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.03219826519489288
bi 1 loss 0.12719306349754333
bi 2 loss 0.03227262571454048
bi 3 loss 0.06942782551050186
Layer  1  loss:  0.10426139831542969 0.0 9.319177627563477
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([227, 534,  81, 324], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.0463981069624424
bi 1 loss 0.1304313689470291
bi 2 loss 0.0178134236484766
bi 3 loss 0.11807282269001007
Layer  2  loss:  0.1118389144539833 0.0 10.520679473876953
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([152, 536,  59, 324], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.03931514173746109
bi 1 loss 0.14342710375785828
bi 2 loss 0.036901578307151794
bi 3 loss 0.11627592891454697
Layer  3  loss:  0.1183500811457634 0.0 10.021886825561523
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1021
Curr loss timestep torch.Size([563, 4]) tensor([175, 533,  50, 328], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.023447666317224503
bi 1 loss 0.14110980927944183
bi 2 loss 0.08469335734844208
bi 3 loss 0.1491638422012329
Layer  4  loss:  0.10318013280630112 0.0 6.787027359008789
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([151, 533,  42, 324], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.019543711096048355
bi 1 loss 0.13677936792373657
bi 2 loss 0.04078657925128937
bi 3 loss 0.10504552721977234
Layer  5  loss:  0.1084325909614563 0.0 7.312201976776123
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([195, 533,  79, 328], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.031137334182858467
bi 1 loss 0.13114728033542633
bi 2 loss 0.05099767446517944
bi 3 loss 0.1356218010187149
Layer  6  loss:  0.11109280586242676 0.0 7.15008020401001
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([187, 533,  72, 328], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.0505390465259552
bi 1 loss 0.1386210024356842
bi 2 loss 0.039492640644311905
bi 3 loss 0.11574306339025497
Epoch 0: :   3%|▎         | 15745/600000 [05:10<3:11:49, v_num=12, reduced_train_loss=0.435, global_step=15743.0, consumed_samples=6.3e+4, train_step_timing in s=0.311]Epoch 0: :   3%|▎         | 15745/600000 [05:10<3:11:49, v_num=12, reduced_train_loss=0.822, global_step=15744.0, consumed_samples=6.3e+4, train_step_timing in s=0.393]loss mask original None

First layer loss:  3.565669059753418 torch.Size([664, 4]) 13.123296737670898 0.0
Max loss timestep torch.Size([664, 4]) tensor([369, 530, 108, 202], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 3.64308500289917
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 1 loss 3.606875419616699
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
bi 2 loss 3.5997703075408936
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 3 loss 2.9143929481506348
speech mask sum tensor(60, device='cuda:0') loss mask sum tensor(60, device='cuda:0')
logits torch.Size([664, 4, 257024]) labels torch.Size([664, 4]) 0 257022
Layer  0  loss:  4.045589923858643 0.0 10.344894409179688
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([217, 500,  89, 209], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 4.215337753295898
bi 1 loss 4.051784515380859
bi 2 loss 3.6335763931274414
bi 3 loss 4.089083671569824
Layer  1  loss:  4.541468620300293 0.0 9.510843276977539
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([186, 590,  92, 219], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 4.478739261627197
bi 1 loss 4.725065231323242
bi 2 loss 4.154913425445557
bi 3 loss 4.126531600952148
Layer  2  loss:  4.841213226318359 0.0 10.937554359436035
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([277, 510, 111, 216], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 4.926482200622559
bi 1 loss 4.92963981628418
bi 2 loss 4.372298717498779
bi 3 loss 4.705881118774414
Layer  3  loss:  4.898697376251221 0.0 10.190221786499023
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1020
Curr loss timestep torch.Size([664, 4]) tensor([224, 503, 111, 211], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 4.853538513183594
bi 1 loss 5.111187934875488
bi 2 loss 4.471868991851807
bi 3 loss 4.27876091003418
Layer  4  loss:  5.072047233581543 0.0 9.639812469482422
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([222, 361,  91, 220], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 5.070443153381348
bi 1 loss 5.247744560241699
bi 2 loss 4.641434669494629
bi 3 loss 4.562108039855957
Layer  5  loss:  5.144925117492676 0.0 9.810052871704102
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1023
Curr loss timestep torch.Size([664, 4]) tensor([308, 344, 112, 245], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 5.130825042724609
bi 1 loss 5.29660701751709
bi 2 loss 4.858921051025391
bi 3 loss 4.601099014282227
Layer  6  loss:  5.172961711883545 0.0 9.104220390319824
logits torch.Size([664, 4, 1024]) labels torch.Size([664, 4]) 0 1022
Curr loss timestep torch.Size([664, 4]) tensor([312, 246,  99, 206], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 5.008406639099121
bi 1 loss 5.336297035217285
bi 2 loss 5.006864547729492
bi 3 loss 4.899321556091309
Epoch 0: :   3%|▎         | 15746/600000 [05:10<3:12:05, v_num=12, reduced_train_loss=0.822, global_step=15744.0, consumed_samples=6.3e+4, train_step_timing in s=0.393]Epoch 0: :   3%|▎         | 15746/600000 [05:10<3:12:05, v_num=12, reduced_train_loss=37.30, global_step=15745.0, consumed_samples=6.3e+4, train_step_timing in s=0.410]loss mask original None

First layer loss:  0.045581333339214325 torch.Size([495, 4]) 8.644962310791016 0.0
Max loss timestep torch.Size([495, 4]) tensor([ 86, 264, 458, 301], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.07199851423501968
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 1 loss 0.027166342362761497
speech mask sum tensor(91, device='cuda:0') loss mask sum tensor(91, device='cuda:0')
bi 2 loss 0.039025843143463135
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
bi 3 loss 0.047871123999357224
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
logits torch.Size([495, 4, 257024]) labels torch.Size([495, 4]) 0 257022
Layer  0  loss:  0.05421333387494087 0.0 7.313449382781982
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([126, 285, 344, 301], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.03784804046154022
bi 1 loss 0.03055400587618351
bi 2 loss 0.07467631250619888
bi 3 loss 0.04610600695014
Layer  1  loss:  0.05863340571522713 0.0 7.87556791305542
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([ 74, 286, 345, 301], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 0.04422431439161301
bi 1 loss 0.033286258578300476
bi 2 loss 0.07051946967840195
bi 3 loss 0.05840134993195534
Layer  2  loss:  0.06002483144402504 0.0 3.5398736000061035
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1022
Curr loss timestep torch.Size([495, 4]) tensor([ 88, 264, 430,  89], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.03903914615511894
bi 1 loss 0.0664212554693222
bi 2 loss 0.06665564328432083
bi 3 loss 0.058922868221998215
Layer  3  loss:  0.04884872958064079 0.0 6.505592346191406
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([116, 234, 344, 337], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.023694638162851334
bi 1 loss 0.04018393158912659
bi 2 loss 0.06566008180379868
bi 3 loss 0.043258704245090485
Layer  4  loss:  0.05429855361580849 0.0 3.2391412258148193
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1022
Curr loss timestep torch.Size([495, 4]) tensor([ 74, 264, 344, 299], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.03722181171178818
bi 1 loss 0.06246573477983475
bi 2 loss 0.06160988658666611
bi 3 loss 0.05085619166493416
Layer  5  loss:  0.042314376682043076 0.0 3.687894582748413
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([122, 243, 345, 297], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.03403991460800171
bi 1 loss 0.029126198962330818
bi 2 loss 0.05103342980146408
bi 3 loss 0.040055036544799805
Layer  6  loss:  0.06886430084705353 0.0 8.55130672454834
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1022
Curr loss timestep torch.Size([495, 4]) tensor([113, 264, 344, 301], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.038452066481113434
bi 1 loss 0.05426575988531113
bi 2 loss 0.08295996487140656
bi 3 loss 0.06900684535503387
Epoch 0: :   3%|▎         | 15747/600000 [05:11<3:12:19, v_num=12, reduced_train_loss=37.30, global_step=15745.0, consumed_samples=6.3e+4, train_step_timing in s=0.410]Epoch 0: :   3%|▎         | 15747/600000 [05:11<3:12:19, v_num=12, reduced_train_loss=0.433, global_step=15746.0, consumed_samples=6.3e+4, train_step_timing in s=0.360]loss mask original None

First layer loss:  0.1902921497821808 torch.Size([629, 4]) 13.49431324005127 0.0
Max loss timestep torch.Size([629, 4]) tensor([308,  88, 116, 517], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.16751855611801147
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 1 loss 0.03428284078836441
speech mask sum tensor(63, device='cuda:0') loss mask sum tensor(63, device='cuda:0')
bi 2 loss 0.07513430714607239
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
bi 3 loss 0.27833321690559387
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
logits torch.Size([629, 4, 257024]) labels torch.Size([629, 4]) 0 257023
Layer  0  loss:  0.18932421505451202 0.0 9.578774452209473
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([308, 104, 259, 610], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.2084794044494629
bi 1 loss 0.031069321557879448
bi 2 loss 0.055738434195518494
bi 3 loss 0.2656933069229126
Layer  1  loss:  0.18985827267169952 0.0 8.410568237304688
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1022
Curr loss timestep torch.Size([629, 4]) tensor([306,  94, 231, 462], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.16897103190422058
bi 1 loss 0.06577065587043762
bi 2 loss 0.06053635850548744
bi 3 loss 0.27833864092826843
Layer  2  loss:  0.19204553961753845 0.0 14.142967224121094
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1022
Curr loss timestep torch.Size([629, 4]) tensor([308,  97,  99, 517], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.19584472477436066
bi 1 loss 0.03165256604552269
bi 2 loss 0.047907616943120956
bi 3 loss 0.28100359439849854
Layer  3  loss:  0.18773509562015533 0.0 11.88213062286377
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1021
Curr loss timestep torch.Size([629, 4]) tensor([307, 109, 136, 517], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.23646442592144012
bi 1 loss 0.0532701350748539
bi 2 loss 0.03647635877132416
bi 3 loss 0.2539645731449127
Layer  4  loss:  0.21638135612010956 0.0 10.700322151184082
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([308,  87, 120, 518], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.20211955904960632
bi 1 loss 0.023491885513067245
bi 2 loss 0.06532663851976395
bi 3 loss 0.3224126100540161
Layer  5  loss:  0.18817466497421265 0.0 8.30357837677002
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1022
Curr loss timestep torch.Size([629, 4]) tensor([307, 109, 169, 517], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.18269877135753632
bi 1 loss 0.1274511218070984
bi 2 loss 0.03363944590091705
bi 3 loss 0.2705393433570862
Layer  6  loss:  0.1717016100883484 0.0 12.908177375793457
logits torch.Size([629, 4, 1024]) labels torch.Size([629, 4]) 0 1023
Curr loss timestep torch.Size([629, 4]) tensor([307,  87, 231, 517], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.2111029326915741
bi 1 loss 0.04086952656507492
bi 2 loss 0.0677812397480011
bi 3 loss 0.22042608261108398
Epoch 0: :   3%|▎         | 15748/600000 [05:11<3:12:36, v_num=12, reduced_train_loss=0.433, global_step=15746.0, consumed_samples=6.3e+4, train_step_timing in s=0.360]Epoch 0: :   3%|▎         | 15748/600000 [05:11<3:12:36, v_num=12, reduced_train_loss=1.530, global_step=15747.0, consumed_samples=6.3e+4, train_step_timing in s=0.438]loss mask original None

First layer loss:  0.13007421791553497 torch.Size([685, 4]) 11.988249778747559 0.0
Max loss timestep torch.Size([685, 4]) tensor([280, 184, 287, 317], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.18172141909599304
speech mask sum tensor(419, device='cuda:0') loss mask sum tensor(419, device='cuda:0')
bi 1 loss 0.0790262445807457
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 2 loss 0.07533694803714752
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
bi 3 loss 0.11486054211854935
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
logits torch.Size([685, 4, 257024]) labels torch.Size([685, 4]) 0 257023
Layer  0  loss:  0.15706683695316315 0.0 12.697027206420898
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([280, 167, 183, 332], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.2615431845188141
bi 1 loss 0.050367530435323715
bi 2 loss 0.06509896367788315
bi 3 loss 0.0982430949807167
Layer  1  loss:  0.17763034999370575 0.0 12.2918062210083
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([281, 167, 263, 332], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.30265820026397705
bi 1 loss 0.02282387763261795
bi 2 loss 0.07924184948205948
bi 3 loss 0.10155078768730164
Layer  2  loss:  0.15910179913043976 0.0 14.3704195022583
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([280, 168, 263, 340], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.2401334047317505
bi 1 loss 0.05496494099497795
bi 2 loss 0.11243560910224915
bi 3 loss 0.08454388380050659
Layer  3  loss:  0.1590932458639145 0.0 11.567634582519531
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1018
Curr loss timestep torch.Size([685, 4]) tensor([280, 159, 287, 332], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.24274766445159912
bi 1 loss 0.040442973375320435
bi 2 loss 0.1154874637722969
bi 3 loss 0.08014113456010818
Layer  4  loss:  0.16679848730564117 0.0 11.270112037658691
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([281, 185, 263, 340], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.2512989640235901
bi 1 loss 0.03978549689054489
bi 2 loss 0.09679774940013885
bi 3 loss 0.13146451115608215
Layer  5  loss:  0.16092555224895477 0.0 9.292840957641602
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([281, 185, 287, 308], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.25183531641960144
bi 1 loss 0.05341758951544762
bi 2 loss 0.08928316086530685
bi 3 loss 0.10338880866765976
Layer  6  loss:  0.18832281231880188 0.0 13.850789070129395
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1021
Curr loss timestep torch.Size([685, 4]) tensor([280, 154, 263, 275], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.31619542837142944
bi 1 loss 0.10607665032148361
bi 2 loss 0.08795773237943649
bi 3 loss 0.0742681622505188
Epoch 0: :   3%|▎         | 15749/600000 [05:11<3:12:54, v_num=12, reduced_train_loss=1.530, global_step=15747.0, consumed_samples=6.3e+4, train_step_timing in s=0.438]Epoch 0: :   3%|▎         | 15749/600000 [05:11<3:12:54, v_num=12, reduced_train_loss=1.300, global_step=15748.0, consumed_samples=6.3e+4, train_step_timing in s=0.464]loss mask original None

First layer loss:  0.2064848691225052 torch.Size([695, 4]) 13.79213809967041 0.0
Max loss timestep torch.Size([695, 4]) tensor([386, 342, 375, 338], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.32459452748298645
speech mask sum tensor(497, device='cuda:0') loss mask sum tensor(497, device='cuda:0')
bi 1 loss 0.10908053070306778
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 2 loss 0.20862294733524323
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 3 loss 0.107515849173069
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
logits torch.Size([695, 4, 257024]) labels torch.Size([695, 4]) 0 257022
Layer  0  loss:  0.2357635498046875 0.0 14.125825881958008
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1023
Curr loss timestep torch.Size([695, 4]) tensor([386, 342, 283, 338], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.3886938691139221
bi 1 loss 0.17408287525177002
bi 2 loss 0.2041705697774887
bi 3 loss 0.08490125834941864
Layer  1  loss:  0.22025743126869202 0.0 12.274352073669434
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1022
Curr loss timestep torch.Size([695, 4]) tensor([386, 342, 348, 258], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.3439401090145111
bi 1 loss 0.11281915754079819
bi 2 loss 0.21125885844230652
bi 3 loss 0.13605426251888275
Layer  2  loss:  0.23302434384822845 0.0 13.564214706420898
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1023
Curr loss timestep torch.Size([695, 4]) tensor([386, 345, 283, 338], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.3175183832645416
bi 1 loss 0.1925545185804367
bi 2 loss 0.24407684803009033
bi 3 loss 0.12082234770059586
Layer  3  loss:  0.26822516322135925 0.0 11.599807739257812
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1023
Curr loss timestep torch.Size([695, 4]) tensor([386, 345, 284, 259], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.3744507431983948
bi 1 loss 0.21419017016887665
bi 2 loss 0.2947353720664978
bi 3 loss 0.11473096162080765
Layer  4  loss:  0.23605944216251373 0.0 12.970048904418945
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1022
Curr loss timestep torch.Size([695, 4]) tensor([618, 365, 376, 340], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.3412383794784546
bi 1 loss 0.1369701623916626
bi 2 loss 0.28276586532592773
bi 3 loss 0.10491921752691269
Layer  5  loss:  0.25462374091148376 0.0 13.353775024414062
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1022
Curr loss timestep torch.Size([695, 4]) tensor([541, 345, 283, 338], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.34312859177589417
bi 1 loss 0.15241888165473938
bi 2 loss 0.3243911862373352
bi 3 loss 0.12559491395950317
Layer  6  loss:  0.2716718316078186 0.0 14.291260719299316
logits torch.Size([695, 4, 1024]) labels torch.Size([695, 4]) 0 1023
Curr loss timestep torch.Size([695, 4]) tensor([386, 365, 336, 338], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.3839249908924103
bi 1 loss 0.1664043366909027
bi 2 loss 0.32846856117248535
bi 3 loss 0.12260737270116806
Epoch 0: :   3%|▎         | 15750/600000 [05:12<3:13:12, v_num=12, reduced_train_loss=1.300, global_step=15748.0, consumed_samples=6.3e+4, train_step_timing in s=0.464]Epoch 0: :   3%|▎         | 15750/600000 [05:12<3:13:12, v_num=12, reduced_train_loss=1.930, global_step=15749.0, consumed_samples=6.3e+4, train_step_timing in s=0.478]loss mask original None

First layer loss:  0.1591651737689972 torch.Size([519, 4]) 14.980878829956055 0.0
Max loss timestep torch.Size([519, 4]) tensor([257, 404, 152, 377], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.13542316854000092
speech mask sum tensor(249, device='cuda:0') loss mask sum tensor(249, device='cuda:0')
bi 1 loss 0.19100309908390045
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
bi 2 loss 0.06486479938030243
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 3 loss 0.20789341628551483
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
logits torch.Size([519, 4, 257024]) labels torch.Size([519, 4]) 0 257022
Layer  0  loss:  0.1751130372285843 0.0 13.60519027709961
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([257, 368, 204, 377], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.15032973885536194
bi 1 loss 0.20050294697284698
bi 2 loss 0.08092834055423737
bi 3 loss 0.23468109965324402
Layer  1  loss:  0.14817015826702118 0.0 13.255107879638672
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([352, 440, 296, 376], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.113185353577137
bi 1 loss 0.19768911600112915
bi 2 loss 0.06737902015447617
bi 3 loss 0.16889728605747223
Layer  2  loss:  0.1979568600654602 0.0 17.177106857299805
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([257, 403, 212, 376], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.14027656614780426
bi 1 loss 0.24906432628631592
bi 2 loss 0.09273173660039902
bi 3 loss 0.2567645311355591
Layer  3  loss:  0.1720057725906372 0.0 9.292146682739258
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([257, 369, 161, 377], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.1531677544116974
bi 1 loss 0.2560522258281708
bi 2 loss 0.09123505651950836
bi 3 loss 0.12449353188276291
Layer  4  loss:  0.19462355971336365 0.0 19.26586151123047
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([257, 368, 255, 376], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.14497092366218567
bi 1 loss 0.2331700325012207
bi 2 loss 0.10733114928007126
bi 3 loss 0.2510197162628174
Layer  5  loss:  0.18467605113983154 0.0 21.188579559326172
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([257, 369, 173, 376], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.1341315507888794
bi 1 loss 0.2608632445335388
bi 2 loss 0.0634676143527031
bi 3 loss 0.21106074750423431
Layer  6  loss:  0.17845934629440308 0.0 15.939720153808594
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1021
Curr loss timestep torch.Size([519, 4]) tensor([257, 368, 275, 375], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.1330203264951706
bi 1 loss 0.2117222547531128
bi 2 loss 0.1126168891787529
bi 3 loss 0.2218269407749176
Epoch 0: :   3%|▎         | 15751/600000 [05:12<3:13:26, v_num=12, reduced_train_loss=1.930, global_step=15749.0, consumed_samples=6.3e+4, train_step_timing in s=0.478]Epoch 0: :   3%|▎         | 15751/600000 [05:12<3:13:26, v_num=12, reduced_train_loss=1.410, global_step=15750.0, consumed_samples=6.3e+4, train_step_timing in s=0.362]loss mask original None

First layer loss:  0.14607436954975128 torch.Size([607, 4]) 16.968923568725586 0.0
Max loss timestep torch.Size([607, 4]) tensor([319, 419, 352, 340], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.07576704025268555
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 1 loss 0.09398335218429565
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
bi 2 loss 0.3162394165992737
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 3 loss 0.15106019377708435
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
logits torch.Size([607, 4, 257024]) labels torch.Size([607, 4]) 0 257022
Layer  0  loss:  0.14036625623703003 0.0 6.628192901611328
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([319, 425, 352, 403], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.12706786394119263
bi 1 loss 0.1359356790781021
bi 2 loss 0.18374307453632355
bi 3 loss 0.13268591463565826
Layer  1  loss:  0.16057942807674408 0.0 11.878026962280273
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([322, 365, 352, 271], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.075045146048069
bi 1 loss 0.10264147073030472
bi 2 loss 0.27966928482055664
bi 3 loss 0.19752448797225952
Layer  2  loss:  0.17608273029327393 0.0 12.785163879394531
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([372, 420, 352, 599], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.12271738052368164
bi 1 loss 0.098592109978199
bi 2 loss 0.34515103697776794
bi 3 loss 0.1930924952030182
Layer  3  loss:  0.17598560452461243 0.0 12.21581745147705
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([319, 365, 443, 271], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.10164713859558105
bi 1 loss 0.10128003358840942
bi 2 loss 0.38359716534614563
bi 3 loss 0.18528662621974945
Layer  4  loss:  0.17786148190498352 0.0 12.125535011291504
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([372, 211, 352, 261], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.12953433394432068
bi 1 loss 0.1284996122121811
bi 2 loss 0.2932892143726349
bi 3 loss 0.19230836629867554
Layer  5  loss:  0.19375909864902496 0.0 17.839950561523438
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([268, 425, 352, 273], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.09766873717308044
bi 1 loss 0.12503397464752197
bi 2 loss 0.3969528079032898
bi 3 loss 0.21038776636123657
Layer  6  loss:  0.1702137589454651 0.0 11.126900672912598
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([319, 425, 352, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.09421437233686447
bi 1 loss 0.11693677306175232
bi 2 loss 0.24411515891551971
bi 3 loss 0.21714195609092712
Epoch 0: :   3%|▎         | 15752/600000 [05:13<3:13:42, v_num=12, reduced_train_loss=1.410, global_step=15750.0, consumed_samples=6.3e+4, train_step_timing in s=0.362]Epoch 0: :   3%|▎         | 15752/600000 [05:13<3:13:42, v_num=12, reduced_train_loss=1.340, global_step=15751.0, consumed_samples=6.3e+4, train_step_timing in s=0.418]loss mask original None

First layer loss:  0.11138042062520981 torch.Size([591, 4]) 18.017452239990234 0.0
Max loss timestep torch.Size([591, 4]) tensor([107, 307, 349, 413], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.030774369835853577
speech mask sum tensor(47, device='cuda:0') loss mask sum tensor(47, device='cuda:0')
bi 1 loss 0.027777908369898796
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 2 loss 0.19382673501968384
speech mask sum tensor(430, device='cuda:0') loss mask sum tensor(430, device='cuda:0')
bi 3 loss 0.06665864586830139
speech mask sum tensor(336, device='cuda:0') loss mask sum tensor(336, device='cuda:0')
logits torch.Size([591, 4, 257024]) labels torch.Size([591, 4]) 0 257023
Layer  0  loss:  0.10762155055999756 0.0 8.365886688232422
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([105, 306, 349, 413], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.013440261594951153
bi 1 loss 0.028299834579229355
bi 2 loss 0.20241747796535492
bi 3 loss 0.04645875468850136
Layer  1  loss:  0.11849882453680038 0.0 12.136436462402344
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([106, 288, 552, 366], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.05137157440185547
bi 1 loss 0.03515283018350601
bi 2 loss 0.2152157425880432
bi 3 loss 0.05347665771842003
Layer  2  loss:  0.13688373565673828 0.0 10.09502124786377
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([115, 260, 346, 366], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 0.029017196968197823
bi 1 loss 0.048477642238140106
bi 2 loss 0.2330770045518875
bi 3 loss 0.08122728765010834
Layer  3  loss:  0.12106603384017944 0.0 9.97160530090332
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([115, 279, 349, 366], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.016317082569003105
bi 1 loss 0.034462857991456985
bi 2 loss 0.22357851266860962
bi 3 loss 0.055818602442741394
Layer  4  loss:  0.11789260804653168 0.0 8.523157119750977
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([109, 172, 549, 149], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.015757735818624496
bi 1 loss 0.031376149505376816
bi 2 loss 0.21280580759048462
bi 3 loss 0.06195344403386116
Layer  5  loss:  0.13937827944755554 0.0 11.475360870361328
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([106, 282, 346, 366], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 0.017503155395388603
bi 1 loss 0.04584093764424324
bi 2 loss 0.2536954879760742
bi 3 loss 0.06552600860595703
Layer  6  loss:  0.10862113535404205 0.0 13.33568000793457
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([109, 306, 349, 366], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.004259579349309206
bi 1 loss 0.02798493579030037
bi 2 loss 0.20234225690364838
bi 3 loss 0.051036324352025986
Epoch 0: :   3%|▎         | 15753/600000 [05:13<3:13:58, v_num=12, reduced_train_loss=1.340, global_step=15751.0, consumed_samples=6.3e+4, train_step_timing in s=0.418]Epoch 0: :   3%|▎         | 15753/600000 [05:13<3:13:58, v_num=12, reduced_train_loss=0.961, global_step=15752.0, consumed_samples=6.3e+4, train_step_timing in s=0.407]loss mask original None

First layer loss:  0.14240935444831848 torch.Size([562, 4]) 17.513202667236328 0.0
Max loss timestep torch.Size([562, 4]) tensor([307, 282, 365, 287], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.08198674023151398
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
bi 1 loss 0.13540072739124298
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
bi 2 loss 0.24013830721378326
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 3 loss 0.025078769773244858
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
logits torch.Size([562, 4, 257024]) labels torch.Size([562, 4]) 0 257023
Layer  0  loss:  0.14330503344535828 0.0 7.822261333465576
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([390, 284, 533, 143], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.06282443553209305
bi 1 loss 0.1281505823135376
bi 2 loss 0.25720682740211487
bi 3 loss 0.025486180558800697
Layer  1  loss:  0.18741339445114136 0.0 10.380292892456055
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1022
Curr loss timestep torch.Size([562, 4]) tensor([375, 283, 487, 153], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.12812328338623047
bi 1 loss 0.19532716274261475
bi 2 loss 0.2918893098831177
bi 3 loss 0.0350751094520092
Layer  2  loss:  0.19316211342811584 0.0 12.532238960266113
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([245, 283, 486, 263], device='cuda:0') tensor(486, device='cuda:0')
bi 0 loss 0.10805527120828629
bi 1 loss 0.16571539640426636
bi 2 loss 0.34431710839271545
bi 3 loss 0.028332145884633064
Layer  3  loss:  0.18284405767917633 0.0 11.876618385314941
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1021
Curr loss timestep torch.Size([562, 4]) tensor([376, 283, 487, 292], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.09897249937057495
bi 1 loss 0.16439956426620483
bi 2 loss 0.320831298828125
bi 3 loss 0.028257476165890694
Layer  4  loss:  0.18943123519420624 0.0 15.325810432434082
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([380, 283, 488, 125], device='cuda:0') tensor(488, device='cuda:0')
bi 0 loss 0.12476421147584915
bi 1 loss 0.17896053194999695
bi 2 loss 0.32180649042129517
bi 3 loss 0.01682005263864994
Layer  5  loss:  0.16072367131710052 0.0 8.86088752746582
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([379, 345, 487, 233], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.1486484855413437
bi 1 loss 0.12447095662355423
bi 2 loss 0.26490339636802673
bi 3 loss 0.031208287924528122
Layer  6  loss:  0.16451780498027802 0.0 17.058624267578125
logits torch.Size([562, 4, 1024]) labels torch.Size([562, 4]) 0 1023
Curr loss timestep torch.Size([562, 4]) tensor([366, 283, 486, 127], device='cuda:0') tensor(486, device='cuda:0')
bi 0 loss 0.07752025872468948
bi 1 loss 0.14606773853302002
bi 2 loss 0.2949313819408417
bi 3 loss 0.026679325848817825
Epoch 0: :   3%|▎         | 15754/600000 [05:14<3:14:13, v_num=12, reduced_train_loss=0.961, global_step=15752.0, consumed_samples=6.3e+4, train_step_timing in s=0.407]Epoch 0: :   3%|▎         | 15754/600000 [05:14<3:14:13, v_num=12, reduced_train_loss=1.360, global_step=15753.0, consumed_samples=6.3e+4, train_step_timing in s=0.392]loss mask original None

First layer loss:  0.23075050115585327 torch.Size([573, 4]) 13.78413200378418 0.0
Max loss timestep torch.Size([573, 4]) tensor([289, 371, 445, 312], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.09877380728721619
speech mask sum tensor(279, device='cuda:0') loss mask sum tensor(279, device='cuda:0')
bi 1 loss 0.5274876356124878
speech mask sum tensor(409, device='cuda:0') loss mask sum tensor(409, device='cuda:0')
bi 2 loss 0.10484467446804047
speech mask sum tensor(294, device='cuda:0') loss mask sum tensor(294, device='cuda:0')
bi 3 loss 0.07492200285196304
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
logits torch.Size([573, 4, 257024]) labels torch.Size([573, 4]) 0 257022
Layer  0  loss:  0.25489065051078796 0.0 12.172101020812988
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([324, 530, 337, 309], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.17923156917095184
bi 1 loss 0.5186479687690735
bi 2 loss 0.12199103087186813
bi 3 loss 0.09851234406232834
Layer  1  loss:  0.24013744294643402 0.0 12.583298683166504
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1022
Curr loss timestep torch.Size([573, 4]) tensor([324, 372, 442, 310], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.15136471390724182
bi 1 loss 0.43512824177742004
bi 2 loss 0.16083240509033203
bi 3 loss 0.1363079696893692
Layer  2  loss:  0.260031521320343 0.0 14.046584129333496
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([324, 372, 445, 309], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.14842678606510162
bi 1 loss 0.5071777701377869
bi 2 loss 0.1387593299150467
bi 3 loss 0.14760181307792664
Layer  3  loss:  0.24501028656959534 0.0 13.89581298828125
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1022
Curr loss timestep torch.Size([573, 4]) tensor([324, 533, 427, 308], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.2179964929819107
bi 1 loss 0.432600736618042
bi 2 loss 0.1429949551820755
bi 3 loss 0.11650162935256958
Layer  4  loss:  0.27165788412094116 0.0 20.657695770263672
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1022
Curr loss timestep torch.Size([573, 4]) tensor([323, 372, 351, 309], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.17758840322494507
bi 1 loss 0.49701783061027527
bi 2 loss 0.10262300819158554
bi 3 loss 0.21844279766082764
Layer  5  loss:  0.25780466198921204 0.0 13.25031566619873
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1021
Curr loss timestep torch.Size([573, 4]) tensor([345, 397, 442, 308], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.138780415058136
bi 1 loss 0.5145307183265686
bi 2 loss 0.12235280871391296
bi 3 loss 0.15298393368721008
Layer  6  loss:  0.280058890581131 0.0 16.12544822692871
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1022
Curr loss timestep torch.Size([573, 4]) tensor([324, 371, 301, 261], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.13781800866127014
bi 1 loss 0.542926013469696
bi 2 loss 0.1850857436656952
bi 3 loss 0.14922165870666504
Epoch 0: :   3%|▎         | 15755/600000 [05:14<3:14:28, v_num=12, reduced_train_loss=1.360, global_step=15753.0, consumed_samples=6.3e+4, train_step_timing in s=0.392]Epoch 0: :   3%|▎         | 15755/600000 [05:14<3:14:28, v_num=12, reduced_train_loss=2.040, global_step=15754.0, consumed_samples=6.3e+4, train_step_timing in s=0.396]loss mask original None

First layer loss:  3.412525177001953 torch.Size([756, 4]) 14.83956241607666 0.0
Max loss timestep torch.Size([756, 4]) tensor([298, 384, 447, 321], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 4.0131096839904785
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
bi 1 loss 3.142535448074341
speech mask sum tensor(335, device='cuda:0') loss mask sum tensor(335, device='cuda:0')
bi 2 loss 3.0437097549438477
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
bi 3 loss 3.6289377212524414
speech mask sum tensor(387, device='cuda:0') loss mask sum tensor(387, device='cuda:0')
logits torch.Size([756, 4, 257024]) labels torch.Size([756, 4]) 0 257023
Layer  0  loss:  3.9652650356292725 0.0 10.667086601257324
logits torch.Size([756, 4, 1024]) labels torch.Size([756, 4]) 0 1023
Curr loss timestep torch.Size([756, 4]) tensor([172, 217, 421, 552], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 4.254135608673096
bi 1 loss 3.415970802307129
bi 2 loss 4.127537250518799
bi 3 loss 4.018161773681641
Layer  1  loss:  4.350273609161377 0.0 11.120635032653809
logits torch.Size([756, 4, 1024]) labels torch.Size([756, 4]) 0 1023
Curr loss timestep torch.Size([756, 4]) tensor([129, 320, 603, 363], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 4.533617973327637
bi 1 loss 3.8971023559570312
bi 2 loss 4.387627124786377
bi 3 loss 4.5543951988220215
Layer  2  loss:  4.563999652862549 0.0 11.388195991516113
logits torch.Size([756, 4, 1024]) labels torch.Size([756, 4]) 0 1023
Curr loss timestep torch.Size([756, 4]) tensor([220, 174, 307, 316], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 4.849834442138672
bi 1 loss 4.2967329025268555
bi 2 loss 4.541111946105957
bi 3 loss 4.600952625274658
Layer  3  loss:  4.645452976226807 0.0 11.063969612121582
logits torch.Size([756, 4, 1024]) labels torch.Size([756, 4]) 0 1022
Curr loss timestep torch.Size([756, 4]) tensor([215, 199, 294, 373], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 5.030101776123047
bi 1 loss 4.23741340637207
bi 2 loss 4.63311767578125
bi 3 loss 4.714538097381592
Layer  4  loss:  4.8746724128723145 0.0 12.273910522460938
logits torch.Size([756, 4, 1024]) labels torch.Size([756, 4]) 0 1022
Curr loss timestep torch.Size([756, 4]) tensor([161, 105, 733, 524], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 5.307903289794922
bi 1 loss 4.237308502197266
bi 2 loss 4.97755241394043
bi 3 loss 4.963961601257324
Layer  5  loss:  4.896526336669922 0.0 12.22331428527832
logits torch.Size([756, 4, 1024]) labels torch.Size([756, 4]) 0 1023
Curr loss timestep torch.Size([756, 4]) tensor([163, 260, 595, 449], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 5.243432521820068
bi 1 loss 4.509109020233154
bi 2 loss 4.8167829513549805
bi 3 loss 5.059329509735107
Layer  6  loss:  4.880262851715088 0.0 10.745779037475586
logits torch.Size([756, 4, 1024]) labels torch.Size([756, 4]) 0 1021
Curr loss timestep torch.Size([756, 4]) tensor([321,  85, 425, 280], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 5.120214462280273
bi 1 loss 4.495349407196045
bi 2 loss 4.919188499450684
bi 3 loss 4.979353427886963
Epoch 0: :   3%|▎         | 15756/600000 [05:15<3:14:46, v_num=12, reduced_train_loss=2.040, global_step=15754.0, consumed_samples=6.3e+4, train_step_timing in s=0.396]Epoch 0: :   3%|▎         | 15756/600000 [05:15<3:14:46, v_num=12, reduced_train_loss=35.60, global_step=15755.0, consumed_samples=6.3e+4, train_step_timing in s=0.455]loss mask original None

First layer loss:  0.17932307720184326 torch.Size([611, 4]) 9.547989845275879 0.0
Max loss timestep torch.Size([611, 4]) tensor([561, 122,  63, 185], device='cuda:0') tensor(561, device='cuda:0')
bi 0 loss 0.31128180027008057
speech mask sum tensor(358, device='cuda:0') loss mask sum tensor(358, device='cuda:0')
bi 1 loss 0.10276950895786285
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 2 loss 0.027318477630615234
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
bi 3 loss 0.03604802116751671
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
logits torch.Size([611, 4, 257024]) labels torch.Size([611, 4]) 0 257023
Layer  0  loss:  0.18420283496379852 0.0 12.88742733001709
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([426, 146,  44, 277], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 0.34657829999923706
bi 1 loss 0.039482466876506805
bi 2 loss 0.02305779978632927
bi 3 loss 0.052737973630428314
Layer  1  loss:  0.2020890861749649 0.0 11.286860466003418
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([428, 141,  44, 226], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.3787969648838043
bi 1 loss 0.04039291664958
bi 2 loss 0.01632709614932537
bi 3 loss 0.06790663301944733
Layer  2  loss:  0.2070988118648529 0.0 13.816864967346191
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([549, 115,  54, 276], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.39579305052757263
bi 1 loss 0.053720623254776
bi 2 loss 0.01727735809981823
bi 3 loss 0.03912459313869476
Layer  3  loss:  0.1906503289937973 0.0 14.145113945007324
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1018
Curr loss timestep torch.Size([611, 4]) tensor([427, 170,  63, 276], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.3546539843082428
bi 1 loss 0.04793216288089752
bi 2 loss 0.03195473179221153
bi 3 loss 0.052404094487428665
Layer  4  loss:  0.20167836546897888 0.0 14.869494438171387
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1023
Curr loss timestep torch.Size([611, 4]) tensor([549, 113,  63, 276], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.371639221906662
bi 1 loss 0.05189373344182968
bi 2 loss 0.031350940465927124
bi 3 loss 0.06288932263851166
Layer  5  loss:  0.1987294703722 0.0 13.32440185546875
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([426, 138,  60, 276], device='cuda:0') tensor(426, device='cuda:0')
bi 0 loss 0.3666798174381256
bi 1 loss 0.04294790327548981
bi 2 loss 0.036777596920728683
bi 3 loss 0.06749915331602097
Layer  6  loss:  0.2269854098558426 0.0 20.79141616821289
logits torch.Size([611, 4, 1024]) labels torch.Size([611, 4]) 0 1022
Curr loss timestep torch.Size([611, 4]) tensor([428, 183,  55, 277], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.4260357618331909
bi 1 loss 0.05188078433275223
bi 2 loss 0.017335671931505203
bi 3 loss 0.06827519088983536
Epoch 0: :   3%|▎         | 15757/600000 [05:15<3:15:02, v_num=12, reduced_train_loss=35.60, global_step=15755.0, consumed_samples=6.3e+4, train_step_timing in s=0.455]Epoch 0: :   3%|▎         | 15757/600000 [05:15<3:15:02, v_num=12, reduced_train_loss=1.590, global_step=15756.0, consumed_samples=6.3e+4, train_step_timing in s=0.415]loss mask original None

First layer loss:  0.051530107855796814 torch.Size([515, 4]) 6.819509983062744 0.0
Max loss timestep torch.Size([515, 4]) tensor([271, 448,  90, 304], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.06042934209108353
speech mask sum tensor(237, device='cuda:0') loss mask sum tensor(237, device='cuda:0')
bi 1 loss 0.05017329379916191
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
bi 2 loss 0.021131606772542
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
bi 3 loss 0.07032499462366104
speech mask sum tensor(84, device='cuda:0') loss mask sum tensor(84, device='cuda:0')
logits torch.Size([515, 4, 257024]) labels torch.Size([515, 4]) 0 257022
Layer  0  loss:  0.05584480240941048 0.0 5.799380779266357
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([272, 448, 120, 291], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.08149158954620361
bi 1 loss 0.05603276193141937
bi 2 loss 0.019964613020420074
bi 3 loss 0.02703910693526268
Layer  1  loss:  0.05495915189385414 0.0 5.934049129486084
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([271, 275,  90, 253], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.08954895287752151
bi 1 loss 0.04490777477622032
bi 2 loss 0.017751844599843025
bi 3 loss 0.049860477447509766
Layer  2  loss:  0.06247842684388161 0.0 5.178574085235596
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1022
Curr loss timestep torch.Size([515, 4]) tensor([271, 493, 106, 304], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.0785534456372261
bi 1 loss 0.06295934319496155
bi 2 loss 0.020443519577383995
bi 3 loss 0.06694568693637848
Layer  3  loss:  0.05105852335691452 0.0 5.2280449867248535
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1022
Curr loss timestep torch.Size([515, 4]) tensor([272, 446,  46, 286], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.06340401619672775
bi 1 loss 0.045519355684518814
bi 2 loss 0.05093560740351677
bi 3 loss 0.041964441537857056
Layer  4  loss:  0.04951153323054314 0.0 3.8180623054504395
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1022
Curr loss timestep torch.Size([515, 4]) tensor([271, 439, 104, 281], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.05645323544740677
bi 1 loss 0.05196916311979294
bi 2 loss 0.02263549156486988
bi 3 loss 0.05184920132160187
Layer  5  loss:  0.04780495911836624 0.0 2.104219436645508
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1021
Curr loss timestep torch.Size([515, 4]) tensor([271, 238,  49, 272], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.06243470311164856
bi 1 loss 0.04500463977456093
bi 2 loss 0.02159133367240429
bi 3 loss 0.051917996257543564
Layer  6  loss:  0.04733069986104965 0.0 3.891099452972412
logits torch.Size([515, 4, 1024]) labels torch.Size([515, 4]) 0 1023
Curr loss timestep torch.Size([515, 4]) tensor([271, 448,  51, 288], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.06277958303689957
bi 1 loss 0.04674374684691429
bi 2 loss 0.01642468385398388
bi 3 loss 0.044718462973833084
Epoch 0: :   3%|▎         | 15758/600000 [05:16<3:15:16, v_num=12, reduced_train_loss=1.590, global_step=15756.0, consumed_samples=6.3e+4, train_step_timing in s=0.415]Epoch 0: :   3%|▎         | 15758/600000 [05:16<3:15:16, v_num=12, reduced_train_loss=0.421, global_step=15757.0, consumed_samples=6.3e+4, train_step_timing in s=0.359]loss mask original None

First layer loss:  3.8219943046569824 torch.Size([636, 4]) 13.847468376159668 0.0
Max loss timestep torch.Size([636, 4]) tensor([ 59, 287, 191, 178], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 3.908930540084839
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 1 loss 4.036338806152344
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 2 loss 4.026373386383057
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 3 loss 2.9746148586273193
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
logits torch.Size([636, 4, 257024]) labels torch.Size([636, 4]) 0 257022
Layer  0  loss:  4.368929862976074 0.0 10.566487312316895
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([145, 277, 209, 234], device='cuda:0') tensor(152, device='cuda:0')
bi 0 loss 4.519291877746582
bi 1 loss 4.530397891998291
bi 2 loss 4.581633567810059
bi 3 loss 3.5699007511138916
Layer  1  loss:  4.681935787200928 0.0 10.845121383666992
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([149, 578, 361, 127], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 4.421311378479004
bi 1 loss 4.837532997131348
bi 2 loss 5.083347797393799
bi 3 loss 3.9375569820404053
Layer  2  loss:  4.910315036773682 0.0 11.864356994628906
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([148, 308, 294, 193], device='cuda:0') tensor(156, device='cuda:0')
bi 0 loss 4.8942670822143555
bi 1 loss 5.153286457061768
bi 2 loss 5.126982688903809
bi 3 loss 4.066695213317871
Layer  3  loss:  5.043929576873779 0.0 10.657015800476074
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([160, 600, 417, 217], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 5.257705211639404
bi 1 loss 5.196231365203857
bi 2 loss 5.235694885253906
bi 3 loss 4.245290279388428
Layer  4  loss:  5.122884273529053 0.0 10.723028182983398
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([105, 326, 355, 194], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 5.055271148681641
bi 1 loss 5.350216865539551
bi 2 loss 5.415442943572998
bi 3 loss 4.236771106719971
Layer  5  loss:  5.172148704528809 0.0 9.790725708007812
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1019
Curr loss timestep torch.Size([636, 4]) tensor([151, 349, 350, 178], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 5.3142547607421875
bi 1 loss 5.375946044921875
bi 2 loss 5.377514839172363
bi 3 loss 4.300739288330078
Layer  6  loss:  5.219449043273926 0.0 10.058635711669922
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1021
Curr loss timestep torch.Size([636, 4]) tensor([164, 319, 412, 239], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 5.2093024253845215
bi 1 loss 5.3644328117370605
bi 2 loss 5.519850730895996
bi 3 loss 4.450340747833252
Epoch 0: :   3%|▎         | 15759/600000 [05:16<3:15:31, v_num=12, reduced_train_loss=0.421, global_step=15757.0, consumed_samples=6.3e+4, train_step_timing in s=0.359]Epoch 0: :   3%|▎         | 15759/600000 [05:16<3:15:31, v_num=12, reduced_train_loss=38.30, global_step=15758.0, consumed_samples=6.3e+4, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.1304963082075119 torch.Size([670, 4]) 8.6461181640625 0.0
Max loss timestep torch.Size([670, 4]) tensor([266, 165, 583, 106], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.038836099207401276
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 1 loss 0.03587945178151131
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 2 loss 0.220452219247818
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
bi 3 loss 0.04334936663508415
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
logits torch.Size([670, 4, 257024]) labels torch.Size([670, 4]) 0 257023
Layer  0  loss:  0.21460238099098206 0.0 13.251304626464844
logits torch.Size([670, 4, 1024]) labels torch.Size([670, 4]) 0 1023
Curr loss timestep torch.Size([670, 4]) tensor([160, 154, 589, 168], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.05291900783777237
bi 1 loss 0.0560307502746582
bi 2 loss 0.37273678183555603
bi 3 loss 0.055989913642406464
Layer  1  loss:  0.22270053625106812 0.0 10.699953079223633
logits torch.Size([670, 4, 1024]) labels torch.Size([670, 4]) 0 1022
Curr loss timestep torch.Size([670, 4]) tensor([247, 110, 307, 106], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.04983030632138252
bi 1 loss 0.04492444545030594
bi 2 loss 0.39749404788017273
bi 3 loss 0.041486091911792755
Layer  2  loss:  0.20543059706687927 0.0 7.264873504638672
logits torch.Size([670, 4, 1024]) labels torch.Size([670, 4]) 0 1023
Curr loss timestep torch.Size([670, 4]) tensor([234, 152, 583, 111], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.04278183355927467
bi 1 loss 0.03627545386552811
bi 2 loss 0.3693002760410309
bi 3 loss 0.03830315172672272
Layer  3  loss:  0.22760576009750366 0.0 18.924169540405273
logits torch.Size([670, 4, 1024]) labels torch.Size([670, 4]) 0 1022
Curr loss timestep torch.Size([670, 4]) tensor([300, 110, 307,  97], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.054027147591114044
bi 1 loss 0.03370910882949829
bi 2 loss 0.41116318106651306
bi 3 loss 0.032305389642715454
Layer  4  loss:  0.23757344484329224 0.0 13.438594818115234
logits torch.Size([670, 4, 1024]) labels torch.Size([670, 4]) 0 1023
Curr loss timestep torch.Size([670, 4]) tensor([176, 148, 639, 184], device='cuda:0') tensor(639, device='cuda:0')
bi 0 loss 0.04951192066073418
bi 1 loss 0.029701601713895798
bi 2 loss 0.43268659710884094
bi 3 loss 0.036173705011606216
Layer  5  loss:  0.21164166927337646 0.0 14.282671928405762
logits torch.Size([670, 4, 1024]) labels torch.Size([670, 4]) 0 1023
Curr loss timestep torch.Size([670, 4]) tensor([308, 195, 307, 166], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.04709397256374359
bi 1 loss 0.07285372912883759
bi 2 loss 0.35287579894065857
bi 3 loss 0.09487155079841614
Layer  6  loss:  0.22373375296592712 0.0 15.019075393676758
logits torch.Size([670, 4, 1024]) labels torch.Size([670, 4]) 0 1021
Curr loss timestep torch.Size([670, 4]) tensor([179, 114, 307, 181], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.04306193068623543
bi 1 loss 0.058603499084711075
bi 2 loss 0.39774784445762634
bi 3 loss 0.045463621616363525
Epoch 0: :   3%|▎         | 15760/600000 [05:16<3:15:49, v_num=12, reduced_train_loss=38.30, global_step=15758.0, consumed_samples=6.3e+4, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15760/600000 [05:16<3:15:49, v_num=12, reduced_train_loss=1.670, global_step=15759.0, consumed_samples=6.3e+4, train_step_timing in s=0.463]loss mask original None

First layer loss:  3.654376268386841 torch.Size([616, 4]) 15.704499244689941 0.0
Max loss timestep torch.Size([616, 4]) tensor([469, 288, 130, 217], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 4.050137996673584
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
bi 1 loss 3.0900158882141113
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
bi 2 loss 3.703035593032837
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 3 loss 3.8146049976348877
speech mask sum tensor(150, device='cuda:0') loss mask sum tensor(150, device='cuda:0')
logits torch.Size([616, 4, 257024]) labels torch.Size([616, 4]) 0 257020
Layer  0  loss:  4.081512928009033 0.0 10.382681846618652
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([481, 276, 249, 271], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.5838236808776855
bi 1 loss 3.601112127304077
bi 2 loss 4.090023517608643
bi 3 loss 3.717172861099243
Layer  1  loss:  4.485030651092529 0.0 11.212095260620117
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([393, 462, 213, 207], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 4.8429131507873535
bi 1 loss 4.061097621917725
bi 2 loss 4.213914394378662
bi 3 loss 4.8673577308654785
Layer  2  loss:  4.724122047424316 0.0 9.909601211547852
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([390, 102, 215, 258], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 5.038699626922607
bi 1 loss 4.292015075683594
bi 2 loss 4.67505407333374
bi 3 loss 4.9384074211120605
Layer  3  loss:  4.76222038269043 0.0 9.715190887451172
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([465, 253, 253, 284], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 5.057770729064941
bi 1 loss 4.4080071449279785
bi 2 loss 4.69946813583374
bi 3 loss 4.846473217010498
Layer  4  loss:  4.930306911468506 0.0 10.4969482421875
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([265, 302, 150, 211], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 5.223686695098877
bi 1 loss 4.547013282775879
bi 2 loss 4.748080730438232
bi 3 loss 5.281662940979004
Layer  5  loss:  5.0086774826049805 0.0 10.855072021484375
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1023
Curr loss timestep torch.Size([616, 4]) tensor([570, 146, 247, 265], device='cuda:0') tensor(255, device='cuda:0')
bi 0 loss 5.281679153442383
bi 1 loss 4.597842693328857
bi 2 loss 4.9349164962768555
bi 3 loss 5.340051651000977
Layer  6  loss:  5.045461177825928 0.0 10.776243209838867
logits torch.Size([616, 4, 1024]) labels torch.Size([616, 4]) 0 1022
Curr loss timestep torch.Size([616, 4]) tensor([395, 202, 226, 252], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 5.30563497543335
bi 1 loss 4.693997383117676
bi 2 loss 4.907470703125
bi 3 loss 5.353206157684326
Epoch 0: :   3%|▎         | 15761/600000 [05:17<3:16:04, v_num=12, reduced_train_loss=1.670, global_step=15759.0, consumed_samples=6.3e+4, train_step_timing in s=0.463]Epoch 0: :   3%|▎         | 15761/600000 [05:17<3:16:04, v_num=12, reduced_train_loss=36.70, global_step=15760.0, consumed_samples=6.3e+4, train_step_timing in s=0.390]loss mask original None

First layer loss:  0.029844915494322777 torch.Size([443, 4]) 1.181527853012085 0.0
Max loss timestep torch.Size([443, 4]) tensor([111, 192, 336, 206], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.018116667866706848
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 1 loss 0.02948782965540886
speech mask sum tensor(158, device='cuda:0') loss mask sum tensor(158, device='cuda:0')
bi 2 loss 0.037681203335523605
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 3 loss 0.028029384091496468
speech mask sum tensor(90, device='cuda:0') loss mask sum tensor(90, device='cuda:0')
logits torch.Size([443, 4, 257024]) labels torch.Size([443, 4]) 0 257022
Layer  0  loss:  0.02585594914853573 0.0 0.6894254684448242
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1023
Curr loss timestep torch.Size([443, 4]) tensor([217, 154, 324, 168], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.021123729646205902
bi 1 loss 0.020827336236834526
bi 2 loss 0.03213658928871155
bi 3 loss 0.02416885644197464
Layer  1  loss:  0.02811674401164055 0.0 0.8291014432907104
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([115, 231, 387, 165], device='cuda:0') tensor(387, device='cuda:0')
bi 0 loss 0.024257874116301537
bi 1 loss 0.02577676624059677
bi 2 loss 0.032741572707891464
bi 3 loss 0.02516787312924862
Layer  2  loss:  0.027579262852668762 0.0 1.0739959478378296
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([100, 230, 185, 169], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 0.030971867963671684
bi 1 loss 0.032741766422986984
bi 2 loss 0.020373577252030373
bi 3 loss 0.03431381657719612
Layer  3  loss:  0.026253269985318184 0.0 0.621834397315979
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([227, 263, 329, 156], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.023081526160240173
bi 1 loss 0.022293485701084137
bi 2 loss 0.032335393130779266
bi 3 loss 0.020435497164726257
Layer  4  loss:  0.028928380459547043 0.0 1.2825632095336914
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([115, 212, 431, 167], device='cuda:0') tensor(431, device='cuda:0')
bi 0 loss 0.028824597597122192
bi 1 loss 0.02989877387881279
bi 2 loss 0.031995512545108795
bi 3 loss 0.018043259158730507
Layer  5  loss:  0.02981453202664852 0.0 2.4543490409851074
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1021
Curr loss timestep torch.Size([443, 4]) tensor([113, 271, 335, 152], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.034184958785772324
bi 1 loss 0.01566602848470211
bi 2 loss 0.03875204175710678
bi 3 loss 0.01933150924742222
Layer  6  loss:  0.029731201007962227 0.0 0.8773455619812012
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1019
Curr loss timestep torch.Size([443, 4]) tensor([223, 172, 335, 150], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.028534606099128723
bi 1 loss 0.019362298771739006
bi 2 loss 0.0382266566157341
bi 3 loss 0.024169813841581345
Epoch 0: :   3%|▎         | 15762/600000 [05:17<3:16:16, v_num=12, reduced_train_loss=36.70, global_step=15760.0, consumed_samples=6.3e+4, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15762/600000 [05:17<3:16:16, v_num=12, reduced_train_loss=0.226, global_step=15761.0, consumed_samples=6.3e+4, train_step_timing in s=0.323]loss mask original None

First layer loss:  0.07587172091007233 torch.Size([463, 4]) 5.322424411773682 0.0
Max loss timestep torch.Size([463, 4]) tensor([399, 149, 393, 227], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.09815650433301926
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 1 loss 0.025630787014961243
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 2 loss 0.11282294243574142
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 3 loss 0.03458057716488838
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
logits torch.Size([463, 4, 257024]) labels torch.Size([463, 4]) 0 257023
Layer  0  loss:  0.08652200549840927 0.0 7.193475723266602
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([399, 111, 332, 136], device='cuda:0') tensor(332, device='cuda:0')
bi 0 loss 0.08515119552612305
bi 1 loss 0.018749389797449112
bi 2 loss 0.12727373838424683
bi 3 loss 0.0721583366394043
Layer  1  loss:  0.08837323635816574 0.0 9.361520767211914
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([385, 114, 403, 277], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.12286615371704102
bi 1 loss 0.053645361214876175
bi 2 loss 0.10792796313762665
bi 3 loss 0.05014334246516228
Layer  2  loss:  0.10296909511089325 0.0 11.315373420715332
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1022
Curr loss timestep torch.Size([463, 4]) tensor([385, 173, 404, 274], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.10882756114006042
bi 1 loss 0.029463697224855423
bi 2 loss 0.15487325191497803
bi 3 loss 0.07025669515132904
Layer  3  loss:  0.0850786417722702 0.0 8.088293075561523
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([385, 107, 402, 275], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.13079918920993805
bi 1 loss 0.03358747065067291
bi 2 loss 0.11104405671358109
bi 3 loss 0.03748094290494919
Layer  4  loss:  0.10121578723192215 0.0 10.955643653869629
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1021
Curr loss timestep torch.Size([463, 4]) tensor([385, 172, 404, 116], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.15627706050872803
bi 1 loss 0.04447353258728981
bi 2 loss 0.12193911522626877
bi 3 loss 0.05499224364757538
Layer  5  loss:  0.07558854669332504 0.0 5.7531304359436035
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1023
Curr loss timestep torch.Size([463, 4]) tensor([385, 106, 404, 200], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.13120754063129425
bi 1 loss 0.026209374889731407
bi 2 loss 0.08676587045192719
bi 3 loss 0.03740199655294418
Layer  6  loss:  0.07356765121221542 0.0 8.819708824157715
logits torch.Size([463, 4, 1024]) labels torch.Size([463, 4]) 0 1019
Curr loss timestep torch.Size([463, 4]) tensor([399, 165, 404, 277], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.08499877154827118
bi 1 loss 0.038513220846652985
bi 2 loss 0.09999939799308777
bi 3 loss 0.04770675674080849
Epoch 0: :   3%|▎         | 15763/600000 [05:18<3:16:29, v_num=12, reduced_train_loss=0.226, global_step=15761.0, consumed_samples=6.3e+4, train_step_timing in s=0.323]Epoch 0: :   3%|▎         | 15763/600000 [05:18<3:16:29, v_num=12, reduced_train_loss=0.689, global_step=15762.0, consumed_samples=63052.0, train_step_timing in s=0.329]loss mask original None

First layer loss:  0.06968917697668076 torch.Size([535, 4]) 15.312829971313477 0.0
Max loss timestep torch.Size([535, 4]) tensor([139, 201, 259, 127], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.0580054335296154
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
bi 1 loss 0.018249476328492165
speech mask sum tensor(80, device='cuda:0') loss mask sum tensor(80, device='cuda:0')
bi 2 loss 0.10061879456043243
speech mask sum tensor(408, device='cuda:0') loss mask sum tensor(408, device='cuda:0')
bi 3 loss 0.03750470653176308
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
logits torch.Size([535, 4, 257024]) labels torch.Size([535, 4]) 0 257023
Layer  0  loss:  0.08352849632501602 0.0 7.696475505828857
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([422, 243, 259, 100], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.07379378378391266
bi 1 loss 0.02518637105822563
bi 2 loss 0.12118687480688095
bi 3 loss 0.029142260551452637
Layer  1  loss:  0.0711836889386177 0.0 4.753533840179443
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([488, 222, 259,  80], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.06079516187310219
bi 1 loss 0.021582167595624924
bi 2 loss 0.0999850258231163
bi 3 loss 0.0408766008913517
Layer  2  loss:  0.06109805777668953 0.0 4.2637739181518555
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1022
Curr loss timestep torch.Size([535, 4]) tensor([175, 200, 259, 148], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.05686962977051735
bi 1 loss 0.03592569753527641
bi 2 loss 0.08123140037059784
bi 3 loss 0.02561117708683014
Layer  3  loss:  0.07029280066490173 0.0 7.105151176452637
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([142, 204, 259,  97], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.06853208690881729
bi 1 loss 0.019928308203816414
bi 2 loss 0.09389348328113556
bi 3 loss 0.03247801214456558
Layer  4  loss:  0.06394702941179276 0.0 9.248937606811523
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([276, 225, 259, 112], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.061544209718704224
bi 1 loss 0.016223708167672157
bi 2 loss 0.08725200593471527
bi 3 loss 0.02723916433751583
Layer  5  loss:  0.0641215592622757 0.0 6.5380940437316895
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([308, 197, 259,  86], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.048937804996967316
bi 1 loss 0.024881962686777115
bi 2 loss 0.09515590220689774
bi 3 loss 0.03396575525403023
Layer  6  loss:  0.07120482623577118 0.0 7.051361560821533
logits torch.Size([535, 4, 1024]) labels torch.Size([535, 4]) 0 1023
Curr loss timestep torch.Size([535, 4]) tensor([487, 197, 318,  69], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.050238460302352905
bi 1 loss 0.045140594244003296
bi 2 loss 0.10497397929430008
bi 3 loss 0.04068562388420105
Epoch 0: :   3%|▎         | 15764/600000 [05:18<3:16:44, v_num=12, reduced_train_loss=0.689, global_step=15762.0, consumed_samples=63052.0, train_step_timing in s=0.329]Epoch 0: :   3%|▎         | 15764/600000 [05:18<3:16:44, v_num=12, reduced_train_loss=0.555, global_step=15763.0, consumed_samples=63056.0, train_step_timing in s=0.376]loss mask original None

First layer loss:  0.09236304461956024 torch.Size([725, 4]) 7.307224750518799 0.0
Max loss timestep torch.Size([725, 4]) tensor([139, 211, 200, 674], device='cuda:0') tensor(674, device='cuda:0')
bi 0 loss 0.05023578554391861
speech mask sum tensor(120, device='cuda:0') loss mask sum tensor(120, device='cuda:0')
bi 1 loss 0.030699485912919044
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 2 loss 0.023732902482151985
speech mask sum tensor(150, device='cuda:0') loss mask sum tensor(150, device='cuda:0')
bi 3 loss 0.14796032011508942
speech mask sum tensor(387, device='cuda:0') loss mask sum tensor(387, device='cuda:0')
logits torch.Size([725, 4, 257024]) labels torch.Size([725, 4]) 0 257023
Layer  0  loss:  0.12099552899599075 0.0 12.009031295776367
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1023
Curr loss timestep torch.Size([725, 4]) tensor([164, 171, 161, 685], device='cuda:0') tensor(685, device='cuda:0')
bi 0 loss 0.027700381353497505
bi 1 loss 0.025649433955550194
bi 2 loss 0.03263923525810242
bi 3 loss 0.20880810916423798
Layer  1  loss:  0.11845604330301285 0.0 9.966378211975098
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1022
Curr loss timestep torch.Size([725, 4]) tensor([212, 209, 109, 688], device='cuda:0') tensor(688, device='cuda:0')
bi 0 loss 0.026777230203151703
bi 1 loss 0.03812591731548309
bi 2 loss 0.02845001593232155
bi 3 loss 0.20252679288387299
Layer  2  loss:  0.11564938724040985 0.0 9.246999740600586
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1023
Curr loss timestep torch.Size([725, 4]) tensor([216, 152, 146, 685], device='cuda:0') tensor(685, device='cuda:0')
bi 0 loss 0.042025867849588394
bi 1 loss 0.03805691748857498
bi 2 loss 0.029113851487636566
bi 3 loss 0.19206900894641876
Layer  3  loss:  0.15025007724761963 0.0 12.16530990600586
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1023
Curr loss timestep torch.Size([725, 4]) tensor([154, 154, 147, 685], device='cuda:0') tensor(685, device='cuda:0')
bi 0 loss 0.031692177057266235
bi 1 loss 0.030605684965848923
bi 2 loss 0.023989642038941383
bi 3 loss 0.2668662369251251
Layer  4  loss:  0.14351432025432587 0.0 16.316957473754883
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1022
Curr loss timestep torch.Size([725, 4]) tensor([146, 164, 100, 685], device='cuda:0') tensor(685, device='cuda:0')
bi 0 loss 0.03223254159092903
bi 1 loss 0.025597060099244118
bi 2 loss 0.02580130659043789
bi 3 loss 0.2541150748729706
Layer  5  loss:  0.15749375522136688 0.0 15.046335220336914
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1023
Curr loss timestep torch.Size([725, 4]) tensor([223, 154, 110, 690], device='cuda:0') tensor(690, device='cuda:0')
bi 0 loss 0.028261326253414154
bi 1 loss 0.017442071810364723
bi 2 loss 0.025056155398488045
bi 3 loss 0.28508731722831726
Layer  6  loss:  0.13771384954452515 0.0 10.418539047241211
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1021
Curr loss timestep torch.Size([725, 4]) tensor([156, 186, 114, 690], device='cuda:0') tensor(690, device='cuda:0')
bi 0 loss 0.033996812999248505
bi 1 loss 0.02576950378715992
bi 2 loss 0.026382040232419968
bi 3 loss 0.24195222556591034
Epoch 0: :   3%|▎         | 15765/600000 [05:19<3:17:03, v_num=12, reduced_train_loss=0.555, global_step=15763.0, consumed_samples=63056.0, train_step_timing in s=0.376]Epoch 0: :   3%|▎         | 15765/600000 [05:19<3:17:03, v_num=12, reduced_train_loss=1.040, global_step=15764.0, consumed_samples=63060.0, train_step_timing in s=0.497]loss mask original None

First layer loss:  0.08106197416782379 torch.Size([607, 4]) 11.18915843963623 0.0
Max loss timestep torch.Size([607, 4]) tensor([570, 278, 194,  94], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.11762028187513351
speech mask sum tensor(448, device='cuda:0') loss mask sum tensor(448, device='cuda:0')
bi 1 loss 0.05218426510691643
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
bi 2 loss 0.04423193633556366
speech mask sum tensor(159, device='cuda:0') loss mask sum tensor(159, device='cuda:0')
bi 3 loss 0.008135540410876274
speech mask sum tensor(54, device='cuda:0') loss mask sum tensor(54, device='cuda:0')
logits torch.Size([607, 4, 257024]) labels torch.Size([607, 4]) 0 257022
Layer  0  loss:  0.07623419910669327 0.0 5.721658706665039
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([570, 379, 138, 113], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.09994716942310333
bi 1 loss 0.07323776185512543
bi 2 loss 0.032915569841861725
bi 3 loss 0.019705232232809067
Layer  1  loss:  0.06717249006032944 0.0 3.6969733238220215
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([542, 338, 150, 113], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.0968141183257103
bi 1 loss 0.04544518142938614
bi 2 loss 0.032783254981040955
bi 3 loss 0.014251453801989555
Layer  2  loss:  0.0650198757648468 0.0 3.4245223999023438
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([479, 379, 171, 116], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.08008986711502075
bi 1 loss 0.06110645830631256
bi 2 loss 0.040504660457372665
bi 3 loss 0.02870171144604683
Layer  3  loss:  0.08677621930837631 0.0 7.051833629608154
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([559, 278, 166,  91], device='cuda:0') tensor(559, device='cuda:0')
bi 0 loss 0.11389635503292084
bi 1 loss 0.06582187861204147
bi 2 loss 0.055583689361810684
bi 3 loss 0.04209809750318527
Layer  4  loss:  0.08715004473924637 0.0 6.670709133148193
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([543, 278, 184, 100], device='cuda:0') tensor(543, device='cuda:0')
bi 0 loss 0.11111960560083389
bi 1 loss 0.10001081973314285
bi 2 loss 0.024472186341881752
bi 3 loss 0.018541719764471054
Layer  5  loss:  0.10378936678171158 0.0 6.504934310913086
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([570, 278, 140,  98], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.12104586511850357
bi 1 loss 0.12665501236915588
bi 2 loss 0.05089511349797249
bi 3 loss 0.019824765622615814
Layer  6  loss:  0.10125557333230972 0.0 5.35003137588501
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([581, 278,  87, 109], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.1397780478000641
bi 1 loss 0.09452030062675476
bi 2 loss 0.0327896773815155
bi 3 loss 0.01169347669929266
Epoch 0: :   3%|▎         | 15766/600000 [05:19<3:17:19, v_num=12, reduced_train_loss=1.040, global_step=15764.0, consumed_samples=63060.0, train_step_timing in s=0.497]Epoch 0: :   3%|▎         | 15766/600000 [05:19<3:17:19, v_num=12, reduced_train_loss=0.668, global_step=15765.0, consumed_samples=63064.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.03285808488726616 torch.Size([441, 4]) 5.504939079284668 0.0
Max loss timestep torch.Size([441, 4]) tensor([126,  60, 130, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.011058761738240719
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 1 loss 0.010648289695382118
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
bi 2 loss 0.026265989989042282
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 3 loss 0.05392323061823845
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
logits torch.Size([441, 4, 257024]) labels torch.Size([441, 4]) 0 257023
Layer  0  loss:  0.038871586322784424 0.0 6.235508441925049
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([109,  91, 114, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.010115429759025574
bi 1 loss 0.008889589458703995
bi 2 loss 0.028448013588786125
bi 3 loss 0.06784691661596298
Layer  1  loss:  0.03476220741868019 0.0 7.693772315979004
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([161,  80,  93, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.01726522296667099
bi 1 loss 0.012433059513568878
bi 2 loss 0.01815902628004551
bi 3 loss 0.0594521090388298
Layer  2  loss:  0.023237891495227814 0.0 2.2514331340789795
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1022
Curr loss timestep torch.Size([441, 4]) tensor([108,  83,  67, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.010050581768155098
bi 1 loss 0.011224654503166676
bi 2 loss 0.02355140447616577
bi 3 loss 0.0331045463681221
Layer  3  loss:  0.05153356492519379 0.0 12.266885757446289
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1021
Curr loss timestep torch.Size([441, 4]) tensor([112,  86,  90, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.009030905552208424
bi 1 loss 0.01213880442082882
bi 2 loss 0.027233023196458817
bi 3 loss 0.09806690365076065
Layer  4  loss:  0.03433690220117569 0.0 7.607117176055908
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([180,  75,  57, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.008626887574791908
bi 1 loss 0.0110227195546031
bi 2 loss 0.02374139055609703
bi 3 loss 0.05998041853308678
Layer  5  loss:  0.031093250960111618 0.0 7.3712544441223145
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1023
Curr loss timestep torch.Size([441, 4]) tensor([123,  72, 106, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.014946234412491322
bi 1 loss 0.011199482716619968
bi 2 loss 0.020695721730589867
bi 3 loss 0.050846002995967865
Layer  6  loss:  0.03350202366709709 0.0 6.456172943115234
logits torch.Size([441, 4, 1024]) labels torch.Size([441, 4]) 0 1021
Curr loss timestep torch.Size([441, 4]) tensor([182,  76,  76, 414], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.008897705003619194
bi 1 loss 0.007886124774813652
bi 2 loss 0.02058449760079384
bi 3 loss 0.06058048829436302
Epoch 0: :   3%|▎         | 15767/600000 [05:19<3:17:31, v_num=12, reduced_train_loss=0.668, global_step=15765.0, consumed_samples=63064.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15767/600000 [05:19<3:17:31, v_num=12, reduced_train_loss=0.280, global_step=15766.0, consumed_samples=63068.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  0.05478522181510925 torch.Size([569, 4]) 5.456141471862793 0.0
Max loss timestep torch.Size([569, 4]) tensor([199, 459, 234, 222], device='cuda:0') tensor(459, device='cuda:0')
bi 0 loss 0.06252207607030869
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 1 loss 0.06715349107980728
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 2 loss 0.04472232609987259
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 3 loss 0.027267592027783394
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
logits torch.Size([569, 4, 257024]) labels torch.Size([569, 4]) 0 257022
Layer  0  loss:  0.06397306174039841 0.0 3.3800253868103027
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([170, 354, 224, 191], device='cuda:0') tensor(354, device='cuda:0')
bi 0 loss 0.0626513883471489
bi 1 loss 0.08790673315525055
bi 2 loss 0.03425130248069763
bi 3 loss 0.032030027359724045
Layer  1  loss:  0.06002340465784073 0.0 2.9105122089385986
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([309, 545, 234,  69], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.06630834192037582
bi 1 loss 0.06627558916807175
bi 2 loss 0.04464630037546158
bi 3 loss 0.04937328025698662
Layer  2  loss:  0.06331562995910645 0.0 2.5488195419311523
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([267, 355, 225, 184], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.062302205711603165
bi 1 loss 0.08342358469963074
bi 2 loss 0.028734510764479637
bi 3 loss 0.04157531261444092
Layer  3  loss:  0.0575023852288723 0.0 2.9544544219970703
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([268, 541, 192,  82], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.050261255353689194
bi 1 loss 0.07936462014913559
bi 2 loss 0.03478076308965683
bi 3 loss 0.03177280351519585
Layer  4  loss:  0.061729807406663895 0.0 3.0330729484558105
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1020
Curr loss timestep torch.Size([569, 4]) tensor([307, 355, 197, 178], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.07235094159841537
bi 1 loss 0.06877898424863815
bi 2 loss 0.028269078582525253
bi 3 loss 0.05500881001353264
Layer  5  loss:  0.06712327152490616 0.0 3.1524343490600586
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([315, 344, 244,  79], device='cuda:0') tensor(79, device='cuda:0')
bi 0 loss 0.058006033301353455
bi 1 loss 0.06405296176671982
bi 2 loss 0.07867874205112457
bi 3 loss 0.07602798938751221
Layer  6  loss:  0.05654770880937576 0.0 3.429468870162964
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([277, 542, 200, 212], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.07028375566005707
bi 1 loss 0.0636577233672142
bi 2 loss 0.024769023060798645
bi 3 loss 0.04577801376581192
Epoch 0: :   3%|▎         | 15768/600000 [05:20<3:17:47, v_num=12, reduced_train_loss=0.280, global_step=15766.0, consumed_samples=63068.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15768/600000 [05:20<3:17:47, v_num=12, reduced_train_loss=0.485, global_step=15767.0, consumed_samples=63072.0, train_step_timing in s=0.408]loss mask original None

First layer loss:  0.043724752962589264 torch.Size([578, 4]) 2.206498384475708 0.0
Max loss timestep torch.Size([578, 4]) tensor([ 72, 113, 139, 321], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.039399366825819016
speech mask sum tensor(200, device='cuda:0') loss mask sum tensor(200, device='cuda:0')
bi 1 loss 0.031180594116449356
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 2 loss 0.04336308687925339
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
bi 3 loss 0.04860776662826538
speech mask sum tensor(407, device='cuda:0') loss mask sum tensor(407, device='cuda:0')
logits torch.Size([578, 4, 257024]) labels torch.Size([578, 4]) 0 257023
Layer  0  loss:  0.04750412330031395 0.0 2.7236642837524414
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1023
Curr loss timestep torch.Size([578, 4]) tensor([174, 102,  97, 454], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.037841860204935074
bi 1 loss 0.04469629377126694
bi 2 loss 0.04303640127182007
bi 3 loss 0.05454001948237419
Layer  1  loss:  0.04731094837188721 0.0 3.497546434402466
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1022
Curr loss timestep torch.Size([578, 4]) tensor([226, 118, 107, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.034178271889686584
bi 1 loss 0.028698090463876724
bi 2 loss 0.053396906703710556
bi 3 loss 0.05533379688858986
Layer  2  loss:  0.05901092290878296 0.0 3.5954484939575195
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1022
Curr loss timestep torch.Size([578, 4]) tensor([179,  90,  99, 454], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.045438140630722046
bi 1 loss 0.0474814809858799
bi 2 loss 0.0356287881731987
bi 3 loss 0.0769931972026825
Layer  3  loss:  0.06454329937696457 0.0 4.825762748718262
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1022
Curr loss timestep torch.Size([578, 4]) tensor([176,  94, 148, 518], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.03617547079920769
bi 1 loss 0.04392513260245323
bi 2 loss 0.05654746666550636
bi 3 loss 0.08583436161279678
Layer  4  loss:  0.046213433146476746 0.0 1.6003166437149048
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1022
Curr loss timestep torch.Size([578, 4]) tensor([188,  73,  99, 404], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.03235648572444916
bi 1 loss 0.019324060529470444
bi 2 loss 0.047231584787368774
bi 3 loss 0.058250706642866135
Layer  5  loss:  0.06073024123907089 0.0 3.317631721496582
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1023
Curr loss timestep torch.Size([578, 4]) tensor([200,  76,  98, 548], device='cuda:0') tensor(548, device='cuda:0')
bi 0 loss 0.03334289416670799
bi 1 loss 0.025559019297361374
bi 2 loss 0.0580657459795475
bi 3 loss 0.08254847675561905
Layer  6  loss:  0.051066331565380096 0.0 4.262607574462891
logits torch.Size([578, 4, 1024]) labels torch.Size([578, 4]) 0 1023
Curr loss timestep torch.Size([578, 4]) tensor([ 65, 114, 110, 454], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 0.032750118523836136
bi 1 loss 0.04211093857884407
bi 2 loss 0.03917314484715462
bi 3 loss 0.0664665549993515
Epoch 0: :   3%|▎         | 15769/600000 [05:20<3:18:02, v_num=12, reduced_train_loss=0.485, global_step=15767.0, consumed_samples=63072.0, train_step_timing in s=0.408]Epoch 0: :   3%|▎         | 15769/600000 [05:20<3:18:02, v_num=12, reduced_train_loss=0.420, global_step=15768.0, consumed_samples=63076.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.07473084330558777 torch.Size([509, 4]) 7.627965927124023 0.0
Max loss timestep torch.Size([509, 4]) tensor([288,  83, 315,  75], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.08558744192123413
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 1 loss 0.023756474256515503
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 2 loss 0.10578641295433044
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 3 loss 0.052135635167360306
speech mask sum tensor(80, device='cuda:0') loss mask sum tensor(80, device='cuda:0')
logits torch.Size([509, 4, 257024]) labels torch.Size([509, 4]) 0 257022
Layer  0  loss:  0.10022405534982681 0.0 11.343853950500488
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1023
Curr loss timestep torch.Size([509, 4]) tensor([287, 130, 315,  72], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.14501813054084778
bi 1 loss 0.028826948255300522
bi 2 loss 0.12371770292520523
bi 3 loss 0.019890710711479187
Layer  1  loss:  0.11749836057424545 0.0 9.498071670532227
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([288, 104, 315,  89], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.18770720064640045
bi 1 loss 0.029105547815561295
bi 2 loss 0.11687133461236954
bi 3 loss 0.06433790922164917
Layer  2  loss:  0.09411180019378662 0.0 8.959067344665527
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([287, 142, 315,  67], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.14598961174488068
bi 1 loss 0.04079066962003708
bi 2 loss 0.09235623478889465
bi 3 loss 0.028269190341234207
Layer  3  loss:  0.10660125315189362 0.0 7.158101558685303
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1019
Curr loss timestep torch.Size([509, 4]) tensor([286, 166, 315,  67], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.1496029496192932
bi 1 loss 0.024678023532032967
bi 2 loss 0.13223622739315033
bi 3 loss 0.05326226353645325
Layer  4  loss:  0.12398186326026917 0.0 12.582276344299316
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([287, 104, 316, 116], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.16329233348369598
bi 1 loss 0.031641434878110886
bi 2 loss 0.16893504559993744
bi 3 loss 0.04366058111190796
Layer  5  loss:  0.11535856872797012 0.0 12.241827964782715
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([286, 207, 315,  64], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.17049729824066162
bi 1 loss 0.04721919074654579
bi 2 loss 0.12669755518436432
bi 3 loss 0.02798299491405487
Layer  6  loss:  0.12261931598186493 0.0 13.461665153503418
logits torch.Size([509, 4, 1024]) labels torch.Size([509, 4]) 0 1022
Curr loss timestep torch.Size([509, 4]) tensor([287, 151, 315,  93], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.1554161012172699
bi 1 loss 0.040950238704681396
bi 2 loss 0.17045947909355164
bi 3 loss 0.030693452805280685
Epoch 0: :   3%|▎         | 15770/600000 [05:21<3:18:16, v_num=12, reduced_train_loss=0.420, global_step=15768.0, consumed_samples=63076.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15770/600000 [05:21<3:18:16, v_num=12, reduced_train_loss=0.855, global_step=15769.0, consumed_samples=63080.0, train_step_timing in s=0.357]loss mask original None

First layer loss:  0.1685209572315216 torch.Size([651, 4]) 9.642352104187012 0.0
Max loss timestep torch.Size([651, 4]) tensor([317, 142, 172, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.13067972660064697
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 1 loss 0.04888732358813286
speech mask sum tensor(122, device='cuda:0') loss mask sum tensor(122, device='cuda:0')
bi 2 loss 0.038920413702726364
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
bi 3 loss 0.26865872740745544
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
logits torch.Size([651, 4, 257024]) labels torch.Size([651, 4]) 0 257022
Layer  0  loss:  0.14323492348194122 0.0 10.509956359863281
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([279, 235, 187, 624], device='cuda:0') tensor(624, device='cuda:0')
bi 0 loss 0.08751887083053589
bi 1 loss 0.056596286594867706
bi 2 loss 0.019028646871447563
bi 3 loss 0.24340657889842987
Layer  1  loss:  0.18324874341487885 0.0 9.077047348022461
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([379, 209, 230, 566], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.13872283697128296
bi 1 loss 0.06648843735456467
bi 2 loss 0.03674694523215294
bi 3 loss 0.29240989685058594
Layer  2  loss:  0.19506162405014038 0.0 13.500130653381348
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([317, 171, 171, 566], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.14800243079662323
bi 1 loss 0.06204590946435928
bi 2 loss 0.04233193397521973
bi 3 loss 0.3123806416988373
Layer  3  loss:  0.17992953956127167 0.0 12.966928482055664
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1022
Curr loss timestep torch.Size([651, 4]) tensor([379, 186, 244, 566], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.12653274834156036
bi 1 loss 0.05502106621861458
bi 2 loss 0.05212562903761864
bi 3 loss 0.2904786467552185
Layer  4  loss:  0.18873915076255798 0.0 17.140361785888672
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([379, 200, 283, 566], device='cuda:0') tensor(566, device='cuda:0')
bi 0 loss 0.14517882466316223
bi 1 loss 0.03965258598327637
bi 2 loss 0.03894101083278656
bi 3 loss 0.30736351013183594
Layer  5  loss:  0.17345654964447021 0.0 10.078995704650879
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([317, 149, 164, 626], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.1153051108121872
bi 1 loss 0.07174785435199738
bi 2 loss 0.04836813732981682
bi 3 loss 0.279591828584671
Layer  6  loss:  0.16587257385253906 0.0 13.298155784606934
logits torch.Size([651, 4, 1024]) labels torch.Size([651, 4]) 0 1023
Curr loss timestep torch.Size([651, 4]) tensor([379, 164, 188, 619], device='cuda:0') tensor(619, device='cuda:0')
bi 0 loss 0.09311400353908539
bi 1 loss 0.02561492845416069
bi 2 loss 0.05795475095510483
bi 3 loss 0.28584712743759155
Epoch 0: :   3%|▎         | 15771/600000 [05:21<3:18:33, v_num=12, reduced_train_loss=0.855, global_step=15769.0, consumed_samples=63080.0, train_step_timing in s=0.357]Epoch 0: :   3%|▎         | 15771/600000 [05:21<3:18:33, v_num=12, reduced_train_loss=1.400, global_step=15770.0, consumed_samples=63084.0, train_step_timing in s=0.442]loss mask original None

First layer loss:  3.709888458251953 torch.Size([588, 4]) 10.234657287597656 0.0
Max loss timestep torch.Size([588, 4]) tensor([ 88, 298, 182, 202], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 3.6625921726226807
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 1 loss 3.6607182025909424
speech mask sum tensor(422, device='cuda:0') loss mask sum tensor(422, device='cuda:0')
bi 2 loss 4.032325744628906
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
bi 3 loss 3.5108642578125
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
logits torch.Size([588, 4, 257024]) labels torch.Size([588, 4]) 0 257022
Layer  0  loss:  4.300446033477783 0.0 12.276880264282227
logits torch.Size([588, 4, 1024]) labels torch.Size([588, 4]) 0 1023
Curr loss timestep torch.Size([588, 4]) tensor([168, 190, 189, 244], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 4.004087448120117
bi 1 loss 4.38797664642334
bi 2 loss 4.28453254699707
bi 3 loss 4.288447856903076
Layer  1  loss:  4.521677017211914 0.0 10.005010604858398
logits torch.Size([588, 4, 1024]) labels torch.Size([588, 4]) 0 1022
Curr loss timestep torch.Size([588, 4]) tensor([151, 524, 307, 189], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 4.247961044311523
bi 1 loss 4.621379375457764
bi 2 loss 4.388859272003174
bi 3 loss 4.588470458984375
Layer  2  loss:  4.835556507110596 0.0 10.400200843811035
logits torch.Size([588, 4, 1024]) labels torch.Size([588, 4]) 0 1023
Curr loss timestep torch.Size([588, 4]) tensor([144, 256, 227, 209], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 4.337236404418945
bi 1 loss 4.870085716247559
bi 2 loss 5.006485462188721
bi 3 loss 4.808581352233887
Layer  3  loss:  4.928842067718506 0.0 10.230927467346191
logits torch.Size([588, 4, 1024]) labels torch.Size([588, 4]) 0 1022
Curr loss timestep torch.Size([588, 4]) tensor([133, 215, 303, 430], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 4.446409702301025
bi 1 loss 4.93931770324707
bi 2 loss 5.018887996673584
bi 3 loss 5.005776405334473
Layer  4  loss:  5.072989463806152 0.0 11.769691467285156
logits torch.Size([588, 4, 1024]) labels torch.Size([588, 4]) 0 1022
Curr loss timestep torch.Size([588, 4]) tensor([107, 247, 346, 322], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 4.780864238739014
bi 1 loss 5.044979095458984
bi 2 loss 5.1813554763793945
bi 3 loss 5.123319625854492
Layer  5  loss:  5.162723541259766 0.0 10.488143920898438
logits torch.Size([588, 4, 1024]) labels torch.Size([588, 4]) 0 1022
Curr loss timestep torch.Size([588, 4]) tensor([178, 252, 294, 244], device='cuda:0') tensor(244, device='cuda:0')
bi 0 loss 4.662894248962402
bi 1 loss 5.195605278015137
bi 2 loss 5.105792999267578
bi 3 loss 5.344454765319824
Layer  6  loss:  5.167196273803711 0.0 10.307971000671387
logits torch.Size([588, 4, 1024]) labels torch.Size([588, 4]) 0 1023
Curr loss timestep torch.Size([588, 4]) tensor([103, 482, 194, 367], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 4.826003551483154
bi 1 loss 5.21948766708374
bi 2 loss 5.105737209320068
bi 3 loss 5.266172885894775
Epoch 0: :   3%|▎         | 15772/600000 [05:22<3:18:47, v_num=12, reduced_train_loss=1.400, global_step=15770.0, consumed_samples=63084.0, train_step_timing in s=0.442]Epoch 0: :   3%|▎         | 15772/600000 [05:22<3:18:47, v_num=12, reduced_train_loss=37.70, global_step=15771.0, consumed_samples=63088.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  0.07656286656856537 torch.Size([497, 4]) 7.415832996368408 0.0
Max loss timestep torch.Size([497, 4]) tensor([462, 311, 167, 146], device='cuda:0') tensor(462, device='cuda:0')
bi 0 loss 0.09079597890377045
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 1 loss 0.07763567566871643
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 2 loss 0.05116149038076401
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 3 loss 0.0483560673892498
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
logits torch.Size([497, 4, 257024]) labels torch.Size([497, 4]) 0 257022
Layer  0  loss:  0.12712328135967255 0.0 8.563501358032227
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([462, 346, 135, 120], device='cuda:0') tensor(462, device='cuda:0')
bi 0 loss 0.15207567811012268
bi 1 loss 0.16088451445102692
bi 2 loss 0.04791155830025673
bi 3 loss 0.059024278074502945
Layer  1  loss:  0.11727861315011978 0.0 8.564994812011719
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([399, 362, 161,  74], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.12318658828735352
bi 1 loss 0.19011573493480682
bi 2 loss 0.06608004122972488
bi 3 loss 0.037110667675733566
Layer  2  loss:  0.1314406543970108 0.0 7.035565376281738
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1023
Curr loss timestep torch.Size([497, 4]) tensor([381, 280, 173, 114], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.16298870742321014
bi 1 loss 0.14144042134284973
bi 2 loss 0.06722994148731232
bi 3 loss 0.06419824808835983
Layer  3  loss:  0.11986680328845978 0.0 6.446878910064697
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1020
Curr loss timestep torch.Size([497, 4]) tensor([465, 280, 130, 149], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.14729543030261993
bi 1 loss 0.12236235290765762
bi 2 loss 0.06395742297172546
bi 3 loss 0.0697096511721611
Layer  4  loss:  0.13028046488761902 0.0 10.596715927124023
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1022
Curr loss timestep torch.Size([497, 4]) tensor([465, 280, 121,  98], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.16977882385253906
bi 1 loss 0.10532485693693161
bi 2 loss 0.03019600547850132
bi 3 loss 0.1094578430056572
Layer  5  loss:  0.13170269131660461 0.0 11.781478881835938
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1021
Curr loss timestep torch.Size([497, 4]) tensor([381, 332, 179, 115], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.18460333347320557
bi 1 loss 0.10536887496709824
bi 2 loss 0.08391374349594116
bi 3 loss 0.03525431826710701
Layer  6  loss:  0.1192091554403305 0.0 8.182903289794922
logits torch.Size([497, 4, 1024]) labels torch.Size([497, 4]) 0 1021
Curr loss timestep torch.Size([497, 4]) tensor([324, 362, 147, 113], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.14567239582538605
bi 1 loss 0.1392027586698532
bi 2 loss 0.03491413965821266
bi 3 loss 0.06822364032268524
Epoch 0: :   3%|▎         | 15773/600000 [05:22<3:19:02, v_num=12, reduced_train_loss=37.70, global_step=15771.0, consumed_samples=63088.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15773/600000 [05:22<3:19:02, v_num=12, reduced_train_loss=0.953, global_step=15772.0, consumed_samples=63092.0, train_step_timing in s=0.385]loss mask original None

First layer loss:  0.058464840054512024 torch.Size([469, 4]) 7.395337104797363 0.0
Max loss timestep torch.Size([469, 4]) tensor([317, 121, 120, 259], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.04830874502658844
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
bi 1 loss 0.023619452491402626
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 2 loss 0.03495747968554497
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.12097634375095367
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
logits torch.Size([469, 4, 257024]) labels torch.Size([469, 4]) 0 257022
Layer  0  loss:  0.07067326456308365 0.0 10.782974243164062
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1023
Curr loss timestep torch.Size([469, 4]) tensor([321, 203, 119, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.04358634352684021
bi 1 loss 0.027202432975172997
bi 2 loss 0.027208486571907997
bi 3 loss 0.17971570789813995
Layer  1  loss:  0.07026616483926773 0.0 10.09437370300293
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1023
Curr loss timestep torch.Size([469, 4]) tensor([314, 118, 197, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.049774639308452606
bi 1 loss 0.03552037477493286
bi 2 loss 0.02538475953042507
bi 3 loss 0.16263143718242645
Layer  2  loss:  0.09151705354452133 0.0 14.860112190246582
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1022
Curr loss timestep torch.Size([469, 4]) tensor([257, 202, 108, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.06966223567724228
bi 1 loss 0.035948581993579865
bi 2 loss 0.03241738677024841
bi 3 loss 0.2143702208995819
Layer  3  loss:  0.08583424985408783 0.0 12.117056846618652
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1023
Curr loss timestep torch.Size([469, 4]) tensor([321,  88, 170, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.0621151328086853
bi 1 loss 0.02236957661807537
bi 2 loss 0.028434567153453827
bi 3 loss 0.21740300953388214
Layer  4  loss:  0.07606876641511917 0.0 13.719597816467285
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1022
Curr loss timestep torch.Size([469, 4]) tensor([321, 135, 195, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.04882170632481575
bi 1 loss 0.02141493372619152
bi 2 loss 0.02490862086415291
bi 3 loss 0.2006765902042389
Layer  5  loss:  0.07263647019863129 0.0 9.202753067016602
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1021
Curr loss timestep torch.Size([469, 4]) tensor([321, 130, 108, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.051577575504779816
bi 1 loss 0.016670288518071175
bi 2 loss 0.05069371685385704
bi 3 loss 0.16927874088287354
Layer  6  loss:  0.08844445645809174 0.0 9.347410202026367
logits torch.Size([469, 4, 1024]) labels torch.Size([469, 4]) 0 1022
Curr loss timestep torch.Size([469, 4]) tensor([317, 106, 125, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.07043164223432541
bi 1 loss 0.02445397712290287
bi 2 loss 0.06554316729307175
bi 3 loss 0.1884462535381317
Epoch 0: :   3%|▎         | 15774/600000 [05:22<3:19:15, v_num=12, reduced_train_loss=0.953, global_step=15772.0, consumed_samples=63092.0, train_step_timing in s=0.385]Epoch 0: :   3%|▎         | 15774/600000 [05:22<3:19:15, v_num=12, reduced_train_loss=0.614, global_step=15773.0, consumed_samples=63096.0, train_step_timing in s=0.336]loss mask original None

First layer loss:  3.768428325653076 torch.Size([584, 4]) 10.386597633361816 0.0
Max loss timestep torch.Size([584, 4]) tensor([218, 365, 175, 173], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 3.6233878135681152
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 1 loss 4.094616889953613
speech mask sum tensor(366, device='cuda:0') loss mask sum tensor(366, device='cuda:0')
bi 2 loss 3.464190721511841
speech mask sum tensor(433, device='cuda:0') loss mask sum tensor(433, device='cuda:0')
bi 3 loss 3.9225943088531494
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
logits torch.Size([584, 4, 257024]) labels torch.Size([584, 4]) 0 257023
Layer  0  loss:  4.207353591918945 0.0 11.697683334350586
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([219, 371, 409, 362], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 4.173399925231934
bi 1 loss 4.405649185180664
bi 2 loss 4.398378849029541
bi 3 loss 3.7940638065338135
Layer  1  loss:  4.671763896942139 0.0 10.85276985168457
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([293, 222, 529, 357], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.453159809112549
bi 1 loss 4.598464488983154
bi 2 loss 4.795544147491455
bi 3 loss 4.775193691253662
Layer  2  loss:  4.941972732543945 0.0 10.794347763061523
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([235, 516, 169, 420], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 4.6987833976745605
bi 1 loss 4.914829254150391
bi 2 loss 5.132375717163086
bi 3 loss 4.935641765594482
Layer  3  loss:  5.064438343048096 0.0 10.500298500061035
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([336, 428, 304, 321], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 4.753802299499512
bi 1 loss 5.0605549812316895
bi 2 loss 5.279594421386719
bi 3 loss 5.058848857879639
Layer  4  loss:  5.155056953430176 0.0 11.249911308288574
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([225, 387, 318, 203], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 4.756223678588867
bi 1 loss 5.122366428375244
bi 2 loss 5.287032127380371
bi 3 loss 5.35415506362915
Layer  5  loss:  5.348126411437988 0.0 10.817142486572266
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([204, 214, 561, 156], device='cuda:0') tensor(244, device='cuda:0')
bi 0 loss 4.985591411590576
bi 1 loss 5.346658706665039
bi 2 loss 5.401913166046143
bi 3 loss 5.581139087677002
Layer  6  loss:  5.394359588623047 0.0 10.172989845275879
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([330, 369, 537, 144], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 5.029901504516602
bi 1 loss 5.441797256469727
bi 2 loss 5.426458835601807
bi 3 loss 5.604778289794922
Epoch 0: :   3%|▎         | 15775/600000 [05:23<3:19:30, v_num=12, reduced_train_loss=0.614, global_step=15773.0, consumed_samples=63096.0, train_step_timing in s=0.336]Epoch 0: :   3%|▎         | 15775/600000 [05:23<3:19:30, v_num=12, reduced_train_loss=38.60, global_step=15774.0, consumed_samples=63100.0, train_step_timing in s=0.370]loss mask original None

First layer loss:  0.09180683642625809 torch.Size([541, 4]) 7.509084701538086 0.0
Max loss timestep torch.Size([541, 4]) tensor([ 86, 287, 479, 316], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.035749200731515884
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
bi 1 loss 0.15419930219650269
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 2 loss 0.11098252236843109
speech mask sum tensor(388, device='cuda:0') loss mask sum tensor(388, device='cuda:0')
bi 3 loss 0.040764324367046356
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
logits torch.Size([541, 4, 257024]) labels torch.Size([541, 4]) 0 257023
Layer  0  loss:  0.12272000312805176 0.0 13.654157638549805
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([100, 377, 480, 256], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.035208385437726974
bi 1 loss 0.14793866872787476
bi 2 loss 0.18117105960845947
bi 3 loss 0.06402276456356049
Layer  1  loss:  0.10101523995399475 0.0 10.125690460205078
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([129, 375, 480, 272], device='cuda:0') tensor(375, device='cuda:0')
bi 0 loss 0.02936501055955887
bi 1 loss 0.12951171398162842
bi 2 loss 0.12248233705759048
bi 3 loss 0.07701953500509262
Layer  2  loss:  0.1211027130484581 0.0 9.674932479858398
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([113, 375, 479, 333], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 0.05852710083127022
bi 1 loss 0.1446518450975418
bi 2 loss 0.15908144414424896
bi 3 loss 0.07937978208065033
Layer  3  loss:  0.10748069733381271 0.0 10.963478088378906
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([145, 375, 479, 255], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 0.06207740679383278
bi 1 loss 0.07397234439849854
bi 2 loss 0.17235679924488068
bi 3 loss 0.07231111079454422
Layer  4  loss:  0.1111258864402771 0.0 7.179250717163086
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1023
Curr loss timestep torch.Size([541, 4]) tensor([ 96, 377, 479, 256], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.031623661518096924
bi 1 loss 0.14482882618904114
bi 2 loss 0.1344824880361557
bi 3 loss 0.08348746597766876
Layer  5  loss:  0.11192695796489716 0.0 12.10850715637207
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1022
Curr loss timestep torch.Size([541, 4]) tensor([114, 377, 479, 256], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 0.04784858971834183
bi 1 loss 0.14907769858837128
bi 2 loss 0.13137665390968323
bi 3 loss 0.08157818764448166
Layer  6  loss:  0.12210650742053986 0.0 9.814963340759277
logits torch.Size([541, 4, 1024]) labels torch.Size([541, 4]) 0 1019
Curr loss timestep torch.Size([541, 4]) tensor([131, 345, 479, 330], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 0.10219411551952362
bi 1 loss 0.13079766929149628
bi 2 loss 0.14976529777050018
bi 3 loss 0.09032975882291794
Epoch 0: :   3%|▎         | 15776/600000 [05:23<3:19:44, v_num=12, reduced_train_loss=38.60, global_step=15774.0, consumed_samples=63100.0, train_step_timing in s=0.370]Epoch 0: :   3%|▎         | 15776/600000 [05:23<3:19:44, v_num=12, reduced_train_loss=0.889, global_step=15775.0, consumed_samples=63104.0, train_step_timing in s=0.377]loss mask original None

First layer loss:  3.5745949745178223 torch.Size([592, 4]) 12.71374797821045 0.0
Max loss timestep torch.Size([592, 4]) tensor([299, 227,  64, 494], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 3.3800995349884033
speech mask sum tensor(465, device='cuda:0') loss mask sum tensor(465, device='cuda:0')
bi 1 loss 4.022523403167725
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 2 loss 3.2288599014282227
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 3 loss 3.752803325653076
speech mask sum tensor(365, device='cuda:0') loss mask sum tensor(365, device='cuda:0')
logits torch.Size([592, 4, 257024]) labels torch.Size([592, 4]) 0 257022
Layer  0  loss:  4.319342613220215 0.0 10.256174087524414
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([265, 158, 113, 174], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 4.2153801918029785
bi 1 loss 4.602856159210205
bi 2 loss 4.181209087371826
bi 3 loss 4.38188362121582
Layer  1  loss:  4.565217018127441 0.0 10.435234069824219
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1022
Curr loss timestep torch.Size([592, 4]) tensor([297, 156, 138, 251], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 4.396396636962891
bi 1 loss 4.680497169494629
bi 2 loss 4.450234413146973
bi 3 loss 4.7707200050354
Layer  2  loss:  4.842430114746094 0.0 10.887289047241211
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1022
Curr loss timestep torch.Size([592, 4]) tensor([151, 145,  75, 195], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.60675573348999
bi 1 loss 5.213720798492432
bi 2 loss 4.8913469314575195
bi 3 loss 4.97745943069458
Layer  3  loss:  4.944995880126953 0.0 9.902070045471191
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([379, 241,  91, 365], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.695413112640381
bi 1 loss 5.199997901916504
bi 2 loss 4.918694019317627
bi 3 loss 5.1686906814575195
Layer  4  loss:  5.096744060516357 0.0 11.164091110229492
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([519, 249, 108, 256], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 4.870724201202393
bi 1 loss 5.263487815856934
bi 2 loss 5.276151657104492
bi 3 loss 5.260023593902588
Layer  5  loss:  5.130779266357422 0.0 10.723821640014648
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1023
Curr loss timestep torch.Size([592, 4]) tensor([277, 165,  82, 517], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 4.911290168762207
bi 1 loss 5.498502731323242
bi 2 loss 5.106940746307373
bi 3 loss 5.26994514465332
Layer  6  loss:  5.233254909515381 0.0 11.627612113952637
logits torch.Size([592, 4, 1024]) labels torch.Size([592, 4]) 0 1020
Curr loss timestep torch.Size([592, 4]) tensor([521, 162, 136, 354], device='cuda:0') tensor(258, device='cuda:0')
bi 0 loss 5.042397499084473
bi 1 loss 5.825310230255127
bi 2 loss 4.868269920349121
bi 3 loss 5.354953765869141
Epoch 0: :   3%|▎         | 15777/600000 [05:24<3:19:59, v_num=12, reduced_train_loss=0.889, global_step=15775.0, consumed_samples=63104.0, train_step_timing in s=0.377]Epoch 0: :   3%|▎         | 15777/600000 [05:24<3:19:59, v_num=12, reduced_train_loss=37.70, global_step=15776.0, consumed_samples=63108.0, train_step_timing in s=0.373]loss mask original None

First layer loss:  0.23503223061561584 torch.Size([710, 4]) 11.378588676452637 0.0
Max loss timestep torch.Size([710, 4]) tensor([415, 587, 289, 661], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.1472208946943283
speech mask sum tensor(389, device='cuda:0') loss mask sum tensor(389, device='cuda:0')
bi 1 loss 0.242348313331604
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
bi 2 loss 0.13746318221092224
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
bi 3 loss 0.36973312497138977
speech mask sum tensor(490, device='cuda:0') loss mask sum tensor(490, device='cuda:0')
logits torch.Size([710, 4, 257024]) labels torch.Size([710, 4]) 0 257023
Layer  0  loss:  0.29293110966682434 0.0 16.0126895904541
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([415, 588, 288, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.21605879068374634
bi 1 loss 0.3415769636631012
bi 2 loss 0.1635359227657318
bi 3 loss 0.40239572525024414
Layer  1  loss:  0.37111353874206543 0.0 15.824155807495117
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([487, 589, 288, 259], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.27227598428726196
bi 1 loss 0.48028525710105896
bi 2 loss 0.14947816729545593
bi 3 loss 0.5074875354766846
Layer  2  loss:  0.34282270073890686 0.0 15.807673454284668
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([313, 570, 288, 551], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.2229611873626709
bi 1 loss 0.485835999250412
bi 2 loss 0.17839863896369934
bi 3 loss 0.42081522941589355
Layer  3  loss:  0.3912968933582306 0.0 15.054408073425293
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([487, 588, 289, 569], device='cuda:0') tensor(588, device='cuda:0')
bi 0 loss 0.24442023038864136
bi 1 loss 0.5195682048797607
bi 2 loss 0.19614365696907043
bi 3 loss 0.5277286171913147
Layer  4  loss:  0.3704812526702881 0.0 16.03299903869629
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([416, 589, 288, 662], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.23019611835479736
bi 1 loss 0.5019696950912476
bi 2 loss 0.16237516701221466
bi 3 loss 0.5081309080123901
Layer  5  loss:  0.38201579451560974 0.0 17.624250411987305
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1023
Curr loss timestep torch.Size([710, 4]) tensor([306, 589, 289, 504], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.25437483191490173
bi 1 loss 0.5016801357269287
bi 2 loss 0.22947773337364197
bi 3 loss 0.4800373315811157
Layer  6  loss:  0.4031517207622528 0.0 17.52009391784668
logits torch.Size([710, 4, 1024]) labels torch.Size([710, 4]) 0 1022
Curr loss timestep torch.Size([710, 4]) tensor([487, 589, 289, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.17615289986133575
bi 1 loss 0.5965370535850525
bi 2 loss 0.17318236827850342
bi 3 loss 0.5657913088798523
Epoch 0: :   3%|▎         | 15778/600000 [05:24<3:20:17, v_num=12, reduced_train_loss=37.70, global_step=15776.0, consumed_samples=63108.0, train_step_timing in s=0.373]Epoch 0: :   3%|▎         | 15778/600000 [05:24<3:20:17, v_num=12, reduced_train_loss=2.790, global_step=15777.0, consumed_samples=63112.0, train_step_timing in s=0.480]loss mask original None

First layer loss:  3.4351518154144287 torch.Size([468, 4]) 10.413575172424316 0.0
Max loss timestep torch.Size([468, 4]) tensor([309, 137,  88, 211], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 3.1639485359191895
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 1 loss 3.693739891052246
speech mask sum tensor(376, device='cuda:0') loss mask sum tensor(376, device='cuda:0')
bi 2 loss 3.2870161533355713
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
bi 3 loss 3.305220365524292
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
logits torch.Size([468, 4, 257024]) labels torch.Size([468, 4]) 0 257023
Layer  0  loss:  3.7960221767425537 0.0 9.697531700134277
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([144, 152, 106, 239], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 3.7340922355651855
bi 1 loss 3.7748217582702637
bi 2 loss 3.675321340560913
bi 3 loss 4.007399559020996
Layer  1  loss:  4.025074481964111 0.0 10.093086242675781
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([259, 389,  96, 273], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 3.9632389545440674
bi 1 loss 4.062119483947754
bi 2 loss 3.661663293838501
bi 3 loss 4.177310466766357
Layer  2  loss:  4.340136528015137 0.0 11.190162658691406
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([262, 360, 103, 279], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 4.168363571166992
bi 1 loss 4.372679233551025
bi 2 loss 4.013147354125977
bi 3 loss 4.686600685119629
Layer  3  loss:  4.455023288726807 0.0 10.113309860229492
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1021
Curr loss timestep torch.Size([468, 4]) tensor([336, 374,  97, 301], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 4.417688846588135
bi 1 loss 4.426707744598389
bi 2 loss 4.050503253936768
bi 3 loss 4.748571395874023
Layer  4  loss:  4.527344226837158 0.0 9.975625038146973
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([327, 360,  99, 188], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 4.397391319274902
bi 1 loss 4.571358680725098
bi 2 loss 4.2150750160217285
bi 3 loss 4.763782024383545
Layer  5  loss:  4.6755828857421875 0.0 10.27493953704834
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1023
Curr loss timestep torch.Size([468, 4]) tensor([291, 199, 116, 188], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 4.453925132751465
bi 1 loss 4.765475749969482
bi 2 loss 4.168692111968994
bi 3 loss 5.0306782722473145
Layer  6  loss:  4.735865592956543 0.0 10.046558380126953
logits torch.Size([468, 4, 1024]) labels torch.Size([468, 4]) 0 1022
Curr loss timestep torch.Size([468, 4]) tensor([368, 197,  86, 182], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 4.41680383682251
bi 1 loss 4.92244815826416
bi 2 loss 4.71902322769165
bi 3 loss 4.828334331512451
Epoch 0: :   3%|▎         | 15779/600000 [05:24<3:20:29, v_num=12, reduced_train_loss=2.790, global_step=15777.0, consumed_samples=63112.0, train_step_timing in s=0.480]Epoch 0: :   3%|▎         | 15779/600000 [05:24<3:20:29, v_num=12, reduced_train_loss=34.00, global_step=15778.0, consumed_samples=63116.0, train_step_timing in s=0.319]loss mask original None

First layer loss:  3.472691059112549 torch.Size([696, 4]) 10.465656280517578 0.0
Max loss timestep torch.Size([696, 4]) tensor([280, 427, 228, 231], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 3.8640871047973633
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 1 loss 3.6129705905914307
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 2 loss 3.321446657180786
speech mask sum tensor(471, device='cuda:0') loss mask sum tensor(471, device='cuda:0')
bi 3 loss 3.4260408878326416
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
logits torch.Size([696, 4, 257024]) labels torch.Size([696, 4]) 0 257022
Layer  0  loss:  4.282779693603516 0.0 9.667411804199219
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([319, 479, 668, 146], device='cuda:0') tensor(244, device='cuda:0')
bi 0 loss 4.548094749450684
bi 1 loss 4.48819637298584
bi 2 loss 4.181163311004639
bi 3 loss 4.154688835144043
Layer  1  loss:  4.508254051208496 0.0 11.617186546325684
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([241, 483, 632,  80], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 4.564076900482178
bi 1 loss 4.676957607269287
bi 2 loss 4.500836372375488
bi 3 loss 4.342298984527588
Layer  2  loss:  4.9741435050964355 0.0 10.614761352539062
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([309, 400, 247, 256], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 5.212766647338867
bi 1 loss 5.029796123504639
bi 2 loss 4.951045036315918
bi 3 loss 4.814767837524414
Layer  3  loss:  5.121180534362793 0.0 10.778672218322754
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1021
Curr loss timestep torch.Size([696, 4]) tensor([300, 434, 273, 110], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 5.089438438415527
bi 1 loss 5.276968479156494
bi 2 loss 5.187524795532227
bi 3 loss 4.8594560623168945
Layer  4  loss:  5.216646671295166 0.0 11.32850170135498
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([362, 489, 439, 103], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 5.31403112411499
bi 1 loss 5.386241912841797
bi 2 loss 5.273150444030762
bi 3 loss 4.87661075592041
Layer  5  loss:  5.359294891357422 0.0 10.346866607666016
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([328, 463, 602, 243], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 5.44193172454834
bi 1 loss 5.341444969177246
bi 2 loss 5.387845516204834
bi 3 loss 5.253105640411377
Layer  6  loss:  5.455215930938721 0.0 10.712957382202148
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([269, 365, 534, 232], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 5.460903167724609
bi 1 loss 5.644376754760742
bi 2 loss 5.414955139160156
bi 3 loss 5.38059663772583
Epoch 0: :   3%|▎         | 15780/600000 [05:25<3:20:45, v_num=12, reduced_train_loss=34.00, global_step=15778.0, consumed_samples=63116.0, train_step_timing in s=0.319]Epoch 0: :   3%|▎         | 15780/600000 [05:25<3:20:45, v_num=12, reduced_train_loss=38.40, global_step=15779.0, consumed_samples=63120.0, train_step_timing in s=0.421]loss mask original None

First layer loss:  3.37750506401062 torch.Size([628, 4]) 10.976617813110352 0.0
Max loss timestep torch.Size([628, 4]) tensor([101, 250, 399,  93], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 3.21354341506958
speech mask sum tensor(389, device='cuda:0') loss mask sum tensor(389, device='cuda:0')
bi 1 loss 3.7017838954925537
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
bi 2 loss 3.0421321392059326
speech mask sum tensor(476, device='cuda:0') loss mask sum tensor(476, device='cuda:0')
bi 3 loss 4.112491130828857
speech mask sum tensor(210, device='cuda:0') loss mask sum tensor(210, device='cuda:0')
logits torch.Size([628, 4, 257024]) labels torch.Size([628, 4]) 0 257023
Layer  0  loss:  3.876490592956543 0.0 10.760488510131836
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([140, 254, 171, 263], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 3.877234935760498
bi 1 loss 4.010006904602051
bi 2 loss 3.5444018840789795
bi 3 loss 4.492424488067627
Layer  1  loss:  4.182982444763184 0.0 11.22852611541748
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([186, 167, 160, 263], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.2014055252075195
bi 1 loss 4.353085041046143
bi 2 loss 3.852163553237915
bi 3 loss 4.726180076599121
Layer  2  loss:  4.441250801086426 0.0 10.657340049743652
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1022
Curr loss timestep torch.Size([628, 4]) tensor([302, 236, 229, 158], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 4.385542392730713
bi 1 loss 4.617198467254639
bi 2 loss 4.147841453552246
bi 3 loss 5.03104305267334
Layer  3  loss:  4.551998138427734 0.0 10.665281295776367
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([419, 265, 170, 249], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 4.497826099395752
bi 1 loss 4.633782386779785
bi 2 loss 4.332915306091309
bi 3 loss 5.065978527069092
Layer  4  loss:  4.698213577270508 0.0 11.086833953857422
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1022
Curr loss timestep torch.Size([628, 4]) tensor([452, 248, 417, 267], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.668435573577881
bi 1 loss 4.767425060272217
bi 2 loss 4.465226173400879
bi 3 loss 5.211277008056641
Layer  5  loss:  4.78495979309082 0.0 10.585236549377441
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([462, 130, 186, 129], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 4.709818363189697
bi 1 loss 4.966360092163086
bi 2 loss 4.577871799468994
bi 3 loss 5.209558486938477
Layer  6  loss:  4.831800937652588 0.0 10.322125434875488
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1021
Curr loss timestep torch.Size([628, 4]) tensor([306, 139, 233, 236], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.855426788330078
bi 1 loss 5.035919189453125
bi 2 loss 4.55167818069458
bi 3 loss 5.215945720672607
Epoch 0: :   3%|▎         | 15781/600000 [05:25<3:21:01, v_num=12, reduced_train_loss=38.40, global_step=15779.0, consumed_samples=63120.0, train_step_timing in s=0.421]Epoch 0: :   3%|▎         | 15781/600000 [05:25<3:21:01, v_num=12, reduced_train_loss=34.70, global_step=15780.0, consumed_samples=63124.0, train_step_timing in s=0.392]loss mask original None

First layer loss:  0.05062636360526085 torch.Size([486, 4]) 3.5954484939575195 0.0
Max loss timestep torch.Size([486, 4]) tensor([328, 140, 456, 157], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.05376511067152023
speech mask sum tensor(239, device='cuda:0') loss mask sum tensor(239, device='cuda:0')
bi 1 loss 0.03366490453481674
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 2 loss 0.06477361917495728
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 3 loss 0.028890762478113174
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
logits torch.Size([486, 4, 257024]) labels torch.Size([486, 4]) 0 257023
Layer  0  loss:  0.050198543816804886 0.0 1.633833408355713
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1023
Curr loss timestep torch.Size([486, 4]) tensor([263, 151, 362, 156], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 0.042735181748867035
bi 1 loss 0.033623069524765015
bi 2 loss 0.07744166254997253
bi 3 loss 0.02849251590669155
Layer  1  loss:  0.0563109889626503 0.0 1.6296336650848389
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1022
Curr loss timestep torch.Size([486, 4]) tensor([243, 132, 347, 156], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 0.04618976637721062
bi 1 loss 0.023844553157687187
bi 2 loss 0.08543488383293152
bi 3 loss 0.06422726809978485
Layer  2  loss:  0.061816245317459106 0.0 2.8127996921539307
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1022
Curr loss timestep torch.Size([486, 4]) tensor([322, 107, 477, 152], device='cuda:0') tensor(477, device='cuda:0')
bi 0 loss 0.05296232923865318
bi 1 loss 0.044778622686862946
bi 2 loss 0.09899800270795822
bi 3 loss 0.018627772107720375
Layer  3  loss:  0.059603143483400345 0.0 3.2395458221435547
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1022
Curr loss timestep torch.Size([486, 4]) tensor([328, 110, 311, 154], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.036167412996292114
bi 1 loss 0.04626967012882233
bi 2 loss 0.11016960442066193
bi 3 loss 0.02389162965118885
Layer  4  loss:  0.050408147275447845 0.0 1.5077366828918457
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1022
Curr loss timestep torch.Size([486, 4]) tensor([328, 111, 394, 135], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.035164229571819305
bi 1 loss 0.022582337260246277
bi 2 loss 0.09970318526029587
bi 3 loss 0.013573224656283855
Layer  5  loss:  0.06050790473818779 0.0 3.0042951107025146
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1021
Curr loss timestep torch.Size([486, 4]) tensor([343, 147, 351, 136], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.04783698171377182
bi 1 loss 0.022663019597530365
bi 2 loss 0.1074722409248352
bi 3 loss 0.03738786652684212
Layer  6  loss:  0.06809300184249878 0.0 6.071802616119385
logits torch.Size([486, 4, 1024]) labels torch.Size([486, 4]) 0 1019
Curr loss timestep torch.Size([486, 4]) tensor([328, 134, 474, 162], device='cuda:0') tensor(328, device='cuda:0')
bi 0 loss 0.0725819393992424
bi 1 loss 0.021271582692861557
bi 2 loss 0.10121683776378632
bi 3 loss 0.03844207525253296
Epoch 0: :   3%|▎         | 15782/600000 [05:26<3:21:14, v_num=12, reduced_train_loss=34.70, global_step=15780.0, consumed_samples=63124.0, train_step_timing in s=0.392]Epoch 0: :   3%|▎         | 15782/600000 [05:26<3:21:14, v_num=12, reduced_train_loss=0.458, global_step=15781.0, consumed_samples=63128.0, train_step_timing in s=0.341]loss mask original None

First layer loss:  0.0432639941573143 torch.Size([489, 4]) 1.7706856727600098 0.0
Max loss timestep torch.Size([489, 4]) tensor([181, 356, 203, 153], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.03254430741071701
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 1 loss 0.05667663738131523
speech mask sum tensor(311, device='cuda:0') loss mask sum tensor(311, device='cuda:0')
bi 2 loss 0.022246867418289185
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 3 loss 0.053146738559007645
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
logits torch.Size([489, 4, 257024]) labels torch.Size([489, 4]) 0 257022
Layer  0  loss:  0.059643685817718506 0.0 6.220836639404297
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1023
Curr loss timestep torch.Size([489, 4]) tensor([248, 433, 287, 119], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 0.032645970582962036
bi 1 loss 0.05439888313412666
bi 2 loss 0.08450981229543686
bi 3 loss 0.07214655727148056
Layer  1  loss:  0.05793653056025505 0.0 12.720277786254883
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([280, 198, 287, 166], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.03038857690989971
bi 1 loss 0.0546824112534523
bi 2 loss 0.10311098396778107
bi 3 loss 0.04371068999171257
Layer  2  loss:  0.06384944170713425 0.0 15.470051765441895
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1023
Curr loss timestep torch.Size([489, 4]) tensor([184, 280, 287, 117], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.028156336396932602
bi 1 loss 0.05724162980914116
bi 2 loss 0.13205586373806
bi 3 loss 0.03900061175227165
Layer  3  loss:  0.0595877468585968 0.0 6.903867244720459
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1021
Curr loss timestep torch.Size([489, 4]) tensor([184, 362, 287, 190], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.04839279130101204
bi 1 loss 0.05701052024960518
bi 2 loss 0.08592039346694946
bi 3 loss 0.047098591923713684
Layer  4  loss:  0.06494935601949692 0.0 13.943221092224121
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([259, 354, 287, 175], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.02853662334382534
bi 1 loss 0.06908349692821503
bi 2 loss 0.10439301282167435
bi 3 loss 0.052801962941884995
Layer  5  loss:  0.08396544307470322 0.0 13.553184509277344
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1021
Curr loss timestep torch.Size([489, 4]) tensor([193, 356, 287, 214], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.030291365459561348
bi 1 loss 0.10712402313947678
bi 2 loss 0.12429376691579819
bi 3 loss 0.05279293283820152
Layer  6  loss:  0.06553361564874649 0.0 11.65939998626709
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([187, 356, 287, 117], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.015125647187232971
bi 1 loss 0.07854218035936356
bi 2 loss 0.11360306292772293
bi 3 loss 0.041818924248218536
Epoch 0: :   3%|▎         | 15783/600000 [05:26<3:21:28, v_num=12, reduced_train_loss=0.458, global_step=15781.0, consumed_samples=63128.0, train_step_timing in s=0.341]Epoch 0: :   3%|▎         | 15783/600000 [05:26<3:21:28, v_num=12, reduced_train_loss=0.499, global_step=15782.0, consumed_samples=63132.0, train_step_timing in s=0.359]loss mask original None

First layer loss:  0.10816000401973724 torch.Size([561, 4]) 8.503989219665527 0.0
Max loss timestep torch.Size([561, 4]) tensor([304, 274, 264, 272], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.13773180544376373
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 1 loss 0.04735398665070534
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 2 loss 0.14343129098415375
speech mask sum tensor(470, device='cuda:0') loss mask sum tensor(470, device='cuda:0')
bi 3 loss 0.06881137937307358
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257023
Layer  0  loss:  0.13519297540187836 0.0 13.035492897033691
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([304, 269, 517, 273], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.17954236268997192
bi 1 loss 0.05098330229520798
bi 2 loss 0.19153741002082825
bi 3 loss 0.06165265291929245
Layer  1  loss:  0.14117492735385895 0.0 13.16793441772461
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([305, 274, 264, 255], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.17642569541931152
bi 1 loss 0.04294917732477188
bi 2 loss 0.2062968760728836
bi 3 loss 0.07656238228082657
Layer  2  loss:  0.17722778022289276 0.0 8.195924758911133
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([367, 274, 511, 268], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.31120428442955017
bi 1 loss 0.05321262404322624
bi 2 loss 0.17860649526119232
bi 3 loss 0.14822198450565338
Layer  3  loss:  0.1552436649799347 0.0 11.423943519592285
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1017
Curr loss timestep torch.Size([561, 4]) tensor([304, 275, 456, 324], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.22039978206157684
bi 1 loss 0.08356736600399017
bi 2 loss 0.20053909718990326
bi 3 loss 0.06473805755376816
Layer  4  loss:  0.16753694415092468 0.0 11.584047317504883
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([305, 274, 264, 281], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.23129326105117798
bi 1 loss 0.07986629009246826
bi 2 loss 0.2301209568977356
bi 3 loss 0.061850085854530334
Layer  5  loss:  0.17825497686862946 0.0 13.035086631774902
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([304, 274, 264, 307], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.27186232805252075
bi 1 loss 0.08809869736433029
bi 2 loss 0.21752935647964478
bi 3 loss 0.08554235845804214
Layer  6  loss:  0.15697883069515228 0.0 17.576629638671875
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([305, 275, 264, 260], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.24055582284927368
bi 1 loss 0.08015803247690201
bi 2 loss 0.1859397441148758
bi 3 loss 0.08232611417770386
Epoch 0: :   3%|▎         | 15784/600000 [05:26<3:21:43, v_num=12, reduced_train_loss=0.499, global_step=15782.0, consumed_samples=63132.0, train_step_timing in s=0.359]Epoch 0: :   3%|▎         | 15784/600000 [05:26<3:21:43, v_num=12, reduced_train_loss=1.220, global_step=15783.0, consumed_samples=63136.0, train_step_timing in s=0.391]loss mask original None

First layer loss:  0.10920590907335281 torch.Size([489, 4]) 13.598912239074707 0.0
Max loss timestep torch.Size([489, 4]) tensor([272, 349, 303, 289], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 0.09289651364088058
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 1 loss 0.13343045115470886
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 2 loss 0.057724155485630035
speech mask sum tensor(406, device='cuda:0') loss mask sum tensor(406, device='cuda:0')
bi 3 loss 0.37111398577690125
speech mask sum tensor(84, device='cuda:0') loss mask sum tensor(84, device='cuda:0')
logits torch.Size([489, 4, 257024]) labels torch.Size([489, 4]) 0 257021
Layer  0  loss:  0.1173001229763031 0.0 10.094158172607422
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1023
Curr loss timestep torch.Size([489, 4]) tensor([350, 349, 318, 289], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.15735554695129395
bi 1 loss 0.08141470700502396
bi 2 loss 0.06625304371118546
bi 3 loss 0.29620933532714844
Layer  1  loss:  0.14762848615646362 0.0 18.26204490661621
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([350, 349, 446, 287], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.15987616777420044
bi 1 loss 0.07993949949741364
bi 2 loss 0.06506010890007019
bi 3 loss 0.6117220520973206
Layer  2  loss:  0.14562834799289703 0.0 13.720086097717285
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1023
Curr loss timestep torch.Size([489, 4]) tensor([350, 349, 444, 287], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.14824320375919342
bi 1 loss 0.1338023841381073
bi 2 loss 0.07789783179759979
bi 3 loss 0.48290321230888367
Layer  3  loss:  0.11326339840888977 0.0 12.625284194946289
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1020
Curr loss timestep torch.Size([489, 4]) tensor([272, 349, 442, 287], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.11590436846017838
bi 1 loss 0.06816423684358597
bi 2 loss 0.06606125086545944
bi 3 loss 0.40154406428337097
Layer  4  loss:  0.16712990403175354 0.0 16.547121047973633
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1023
Curr loss timestep torch.Size([489, 4]) tensor([272, 349, 464, 287], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.19358083605766296
bi 1 loss 0.1636967658996582
bi 2 loss 0.0798596739768982
bi 3 loss 0.5135142803192139
Layer  5  loss:  0.1444552093744278 0.0 10.219015121459961
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([350, 349, 444, 287], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.15254370868206024
bi 1 loss 0.13801507651805878
bi 2 loss 0.09554851055145264
bi 3 loss 0.36592382192611694
Layer  6  loss:  0.15023426711559296 0.0 12.375493049621582
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([350, 349, 444, 289], device='cuda:0') tensor(350, device='cuda:0')
bi 0 loss 0.20770291984081268
bi 1 loss 0.07645988464355469
bi 2 loss 0.06704426556825638
bi 3 loss 0.4887164831161499
Epoch 0: :   3%|▎         | 15785/600000 [05:27<3:21:56, v_num=12, reduced_train_loss=1.220, global_step=15783.0, consumed_samples=63136.0, train_step_timing in s=0.391]Epoch 0: :   3%|▎         | 15785/600000 [05:27<3:21:56, v_num=12, reduced_train_loss=1.090, global_step=15784.0, consumed_samples=63140.0, train_step_timing in s=0.343]loss mask original None

First layer loss:  0.1458846628665924 torch.Size([638, 4]) 7.696667671203613 0.0
Max loss timestep torch.Size([638, 4]) tensor([ 45,  65, 364, 615], device='cuda:0') tensor(615, device='cuda:0')
bi 0 loss 0.05908406153321266
speech mask sum tensor(46, device='cuda:0') loss mask sum tensor(46, device='cuda:0')
bi 1 loss 0.03664135932922363
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
bi 2 loss 0.15637922286987305
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
bi 3 loss 0.20366685092449188
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
logits torch.Size([638, 4, 257024]) labels torch.Size([638, 4]) 0 257023
Layer  0  loss:  0.16349998116493225 0.0 9.788264274597168
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([ 38, 120, 364, 554], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.03414905071258545
bi 1 loss 0.039114855229854584
bi 2 loss 0.17276325821876526
bi 3 loss 0.23535816371440887
Layer  1  loss:  0.17062699794769287 0.0 8.337145805358887
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([ 58,  87, 364, 616], device='cuda:0') tensor(616, device='cuda:0')
bi 0 loss 0.028250228613615036
bi 1 loss 0.04083247482776642
bi 2 loss 0.1851758509874344
bi 3 loss 0.24409592151641846
Layer  2  loss:  0.22097209095954895 0.0 11.994807243347168
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([ 59, 117, 363, 554], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.055145036429166794
bi 1 loss 0.046696633100509644
bi 2 loss 0.13931410014629364
bi 3 loss 0.3703750967979431
Layer  3  loss:  0.20682327449321747 0.0 10.382341384887695
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1021
Curr loss timestep torch.Size([638, 4]) tensor([ 48, 118, 364, 622], device='cuda:0') tensor(622, device='cuda:0')
bi 0 loss 0.04847026243805885
bi 1 loss 0.03792828321456909
bi 2 loss 0.15970835089683533
bi 3 loss 0.3339823782444
Layer  4  loss:  0.18288575112819672 0.0 12.311635971069336
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1021
Curr loss timestep torch.Size([638, 4]) tensor([ 58,  53, 363, 622], device='cuda:0') tensor(622, device='cuda:0')
bi 0 loss 0.05052804946899414
bi 1 loss 0.03727101907134056
bi 2 loss 0.2513878345489502
bi 3 loss 0.2330179214477539
Layer  5  loss:  0.2019905000925064 0.0 10.92125415802002
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1021
Curr loss timestep torch.Size([638, 4]) tensor([ 58, 144, 364, 554], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.02277006208896637
bi 1 loss 0.03015849180519581
bi 2 loss 0.18099336326122284
bi 3 loss 0.31956997513771057
Layer  6  loss:  0.17188283801078796 0.0 11.282218933105469
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1021
Curr loss timestep torch.Size([638, 4]) tensor([ 48,  79, 364, 623], device='cuda:0') tensor(623, device='cuda:0')
bi 0 loss 0.03229387849569321
bi 1 loss 0.03148605674505234
bi 2 loss 0.17456692457199097
bi 3 loss 0.2562132775783539
Epoch 0: :   3%|▎         | 15786/600000 [05:27<3:22:13, v_num=12, reduced_train_loss=1.090, global_step=15784.0, consumed_samples=63140.0, train_step_timing in s=0.343]Epoch 0: :   3%|▎         | 15786/600000 [05:27<3:22:13, v_num=12, reduced_train_loss=1.460, global_step=15785.0, consumed_samples=63144.0, train_step_timing in s=0.436]loss mask original None

First layer loss:  3.4844586849212646 torch.Size([388, 4]) 10.533709526062012 0.0
Max loss timestep torch.Size([388, 4]) tensor([255, 132, 245, 285], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 3.680553674697876
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 1 loss 2.944859266281128
speech mask sum tensor(225, device='cuda:0') loss mask sum tensor(225, device='cuda:0')
bi 2 loss 3.627434730529785
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 3 loss 3.745804786682129
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
logits torch.Size([388, 4, 257024]) labels torch.Size([388, 4]) 0 257021
Layer  0  loss:  4.216332912445068 0.0 11.519331932067871
logits torch.Size([388, 4, 1024]) labels torch.Size([388, 4]) 0 1023
Curr loss timestep torch.Size([388, 4]) tensor([309, 197, 335, 186], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.61065673828125
bi 1 loss 3.0652904510498047
bi 2 loss 4.479526519775391
bi 3 loss 4.845913410186768
Layer  1  loss:  4.493015766143799 0.0 10.71349811553955
logits torch.Size([388, 4, 1024]) labels torch.Size([388, 4]) 0 1023
Curr loss timestep torch.Size([388, 4]) tensor([298,  98, 202, 269], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.538064002990723
bi 1 loss 3.729572057723999
bi 2 loss 4.8399858474731445
bi 3 loss 4.8382792472839355
Layer  2  loss:  4.774853229522705 0.0 10.794873237609863
logits torch.Size([388, 4, 1024]) labels torch.Size([388, 4]) 0 1022
Curr loss timestep torch.Size([388, 4]) tensor([194, 207, 327, 298], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.830496311187744
bi 1 loss 3.830974578857422
bi 2 loss 5.157426357269287
bi 3 loss 5.262795925140381
Layer  3  loss:  4.8266801834106445 0.0 11.506719589233398
logits torch.Size([388, 4, 1024]) labels torch.Size([388, 4]) 0 1022
Curr loss timestep torch.Size([388, 4]) tensor([282,  62, 247, 215], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 5.084062099456787
bi 1 loss 3.7559492588043213
bi 2 loss 5.157648086547852
bi 3 loss 5.377102375030518
Layer  4  loss:  4.934859752655029 0.0 11.419617652893066
logits torch.Size([388, 4, 1024]) labels torch.Size([388, 4]) 0 1022
Curr loss timestep torch.Size([388, 4]) tensor([277, 237, 140, 245], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 5.097835540771484
bi 1 loss 3.817509174346924
bi 2 loss 5.45379114151001
bi 3 loss 5.356295585632324
Layer  5  loss:  5.036780834197998 0.0 9.88828182220459
logits torch.Size([388, 4, 1024]) labels torch.Size([388, 4]) 0 1022
Curr loss timestep torch.Size([388, 4]) tensor([292, 162, 277, 232], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 5.2545342445373535
bi 1 loss 3.999479055404663
bi 2 loss 5.534801959991455
bi 3 loss 5.359205722808838
Layer  6  loss:  5.0089030265808105 0.0 9.809516906738281
logits torch.Size([388, 4, 1024]) labels torch.Size([388, 4]) 0 1021
Curr loss timestep torch.Size([388, 4]) tensor([286,  78, 349, 229], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 5.21095085144043
bi 1 loss 3.9156417846679688
bi 2 loss 5.493483066558838
bi 3 loss 5.421337127685547
Epoch 0: :   3%|▎         | 15787/600000 [05:28<3:22:24, v_num=12, reduced_train_loss=1.460, global_step=15785.0, consumed_samples=63144.0, train_step_timing in s=0.436]Epoch 0: :   3%|▎         | 15787/600000 [05:28<3:22:24, v_num=12, reduced_train_loss=36.80, global_step=15786.0, consumed_samples=63148.0, train_step_timing in s=0.295]loss mask original None

First layer loss:  0.0913337990641594 torch.Size([701, 4]) 8.118316650390625 0.0
Max loss timestep torch.Size([701, 4]) tensor([195,  66, 118, 618], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 0.13090212643146515
speech mask sum tensor(273, device='cuda:0') loss mask sum tensor(273, device='cuda:0')
bi 1 loss 0.035345014184713364
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
bi 2 loss 0.02964666299521923
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
bi 3 loss 0.10331592708826065
speech mask sum tensor(489, device='cuda:0') loss mask sum tensor(489, device='cuda:0')
logits torch.Size([701, 4, 257024]) labels torch.Size([701, 4]) 0 257022
Layer  0  loss:  0.10411980748176575 0.0 10.624882698059082
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1023
Curr loss timestep torch.Size([701, 4]) tensor([378,  60, 192, 618], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.07036371529102325
bi 1 loss 0.03972063958644867
bi 2 loss 0.030960172414779663
bi 3 loss 0.16262508928775787
Layer  1  loss:  0.10268466174602509 0.0 12.285079956054688
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1022
Curr loss timestep torch.Size([701, 4]) tensor([368, 201, 201, 618], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.07522065192461014
bi 1 loss 0.025043657049536705
bi 2 loss 0.04157726466655731
bi 3 loss 0.16006942093372345
Layer  2  loss:  0.10249710083007812 0.0 5.408791542053223
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1022
Curr loss timestep torch.Size([701, 4]) tensor([278,  68, 193, 618], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.07973070442676544
bi 1 loss 0.05069858208298683
bi 2 loss 0.03486812487244606
bi 3 loss 0.1489751785993576
Layer  3  loss:  0.08717603981494904 0.0 5.1446051597595215
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1018
Curr loss timestep torch.Size([701, 4]) tensor([302, 100, 161, 618], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.07197187095880508
bi 1 loss 0.03186540678143501
bi 2 loss 0.04876574128866196
bi 3 loss 0.12453235685825348
Layer  4  loss:  0.1002197265625 0.0 4.974954605102539
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1023
Curr loss timestep torch.Size([701, 4]) tensor([404,  90, 163, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.08195516467094421
bi 1 loss 0.018344860523939133
bi 2 loss 0.02961968071758747
bi 3 loss 0.15607191622257233
Layer  5  loss:  0.10563195496797562 0.0 7.682485580444336
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1022
Curr loss timestep torch.Size([701, 4]) tensor([278,  87, 151, 618], device='cuda:0') tensor(618, device='cuda:0')
bi 0 loss 0.09392447024583817
bi 1 loss 0.029840271919965744
bi 2 loss 0.058403484523296356
bi 3 loss 0.15057630836963654
Layer  6  loss:  0.10689323395490646 0.0 5.9272637367248535
logits torch.Size([701, 4, 1024]) labels torch.Size([701, 4]) 0 1023
Curr loss timestep torch.Size([701, 4]) tensor([368, 182, 202, 577], device='cuda:0') tensor(577, device='cuda:0')
bi 0 loss 0.0690532699227333
bi 1 loss 0.031273793429136276
bi 2 loss 0.04965750128030777
bi 3 loss 0.16849073767662048
Epoch 0: :   3%|▎         | 15788/600000 [05:28<3:22:43, v_num=12, reduced_train_loss=36.80, global_step=15786.0, consumed_samples=63148.0, train_step_timing in s=0.295]Epoch 0: :   3%|▎         | 15788/600000 [05:28<3:22:43, v_num=12, reduced_train_loss=0.801, global_step=15787.0, consumed_samples=63152.0, train_step_timing in s=0.483]loss mask original None

First layer loss:  0.0751422867178917 torch.Size([558, 4]) 8.970273971557617 0.0
Max loss timestep torch.Size([558, 4]) tensor([305, 320, 346, 308], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.046605855226516724
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 1 loss 0.11479313671588898
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 2 loss 0.04749515280127525
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 3 loss 0.0735323429107666
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
logits torch.Size([558, 4, 257024]) labels torch.Size([558, 4]) 0 257022
Layer  0  loss:  0.08311059325933456 0.0 7.819218158721924
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([308, 529, 313, 307], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.07118425518274307
bi 1 loss 0.08966681361198425
bi 2 loss 0.06314864754676819
bi 3 loss 0.11027615517377853
Layer  1  loss:  0.10676092654466629 0.0 9.625679016113281
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([308, 530, 326, 308], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.08726595342159271
bi 1 loss 0.13542374968528748
bi 2 loss 0.08062437921762466
bi 3 loss 0.11281277984380722
Layer  2  loss:  0.11017856746912003 0.0 8.32363224029541
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([304, 320, 313, 308], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.07716279476881027
bi 1 loss 0.14836160838603973
bi 2 loss 0.12335147708654404
bi 3 loss 0.06026479974389076
Layer  3  loss:  0.10091263800859451 0.0 10.855011940002441
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([134, 507, 326, 307], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.0784076526761055
bi 1 loss 0.11758065223693848
bi 2 loss 0.12369433045387268
bi 3 loss 0.06376995891332626
Layer  4  loss:  0.10615623742341995 0.0 8.351034164428711
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([261, 320, 313, 308], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.06642701476812363
bi 1 loss 0.11668969690799713
bi 2 loss 0.1377009153366089
bi 3 loss 0.08343194425106049
Layer  5  loss:  0.12541770935058594 0.0 9.138651847839355
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1021
Curr loss timestep torch.Size([558, 4]) tensor([308, 320, 326, 308], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.06646206229925156
bi 1 loss 0.16775298118591309
bi 2 loss 0.12962783873081207
bi 3 loss 0.10492528229951859
Layer  6  loss:  0.1211000382900238 0.0 12.75218677520752
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([300, 530, 326, 308], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.08828537166118622
bi 1 loss 0.1409260630607605
bi 2 loss 0.13232918083667755
bi 3 loss 0.10391032695770264
Epoch 0: :   3%|▎         | 15789/600000 [05:29<3:22:58, v_num=12, reduced_train_loss=0.801, global_step=15787.0, consumed_samples=63152.0, train_step_timing in s=0.483]Epoch 0: :   3%|▎         | 15789/600000 [05:29<3:22:58, v_num=12, reduced_train_loss=0.829, global_step=15788.0, consumed_samples=63156.0, train_step_timing in s=0.394]loss mask original None

First layer loss:  3.8523011207580566 torch.Size([512, 4]) 13.616155624389648 0.0
Max loss timestep torch.Size([512, 4]) tensor([170, 163,  80, 303], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 3.8739120960235596
speech mask sum tensor(419, device='cuda:0') loss mask sum tensor(419, device='cuda:0')
bi 1 loss 4.018402576446533
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
bi 2 loss 3.5847244262695312
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 3 loss 3.7576632499694824
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
logits torch.Size([512, 4, 257024]) labels torch.Size([512, 4]) 0 257022
Layer  0  loss:  4.2676286697387695 0.0 10.882706642150879
logits torch.Size([512, 4, 1024]) labels torch.Size([512, 4]) 0 1023
Curr loss timestep torch.Size([512, 4]) tensor([404, 339, 139, 163], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 4.206484317779541
bi 1 loss 4.292973518371582
bi 2 loss 4.146090507507324
bi 3 loss 4.424273490905762
Layer  1  loss:  4.613163948059082 0.0 10.306593894958496
logits torch.Size([512, 4, 1024]) labels torch.Size([512, 4]) 0 1022
Curr loss timestep torch.Size([512, 4]) tensor([176, 340, 141, 182], device='cuda:0') tensor(141, device='cuda:0')
bi 0 loss 4.5940117835998535
bi 1 loss 4.750871181488037
bi 2 loss 4.57680606842041
bi 3 loss 4.478852272033691
Layer  2  loss:  4.800502777099609 0.0 10.633452415466309
logits torch.Size([512, 4, 1024]) labels torch.Size([512, 4]) 0 1022
Curr loss timestep torch.Size([512, 4]) tensor([404, 227, 170, 160], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 4.690422058105469
bi 1 loss 4.920374393463135
bi 2 loss 4.926639080047607
bi 3 loss 4.7487897872924805
Layer  3  loss:  4.895627975463867 0.0 10.380376815795898
logits torch.Size([512, 4, 1024]) labels torch.Size([512, 4]) 0 1017
Curr loss timestep torch.Size([512, 4]) tensor([329, 133, 114, 336], device='cuda:0') tensor(189, device='cuda:0')
bi 0 loss 4.771178722381592
bi 1 loss 5.185801029205322
bi 2 loss 4.888012409210205
bi 3 loss 4.719905853271484
Layer  4  loss:  5.018657207489014 0.0 9.525165557861328
logits torch.Size([512, 4, 1024]) labels torch.Size([512, 4]) 0 1023
Curr loss timestep torch.Size([512, 4]) tensor([451, 117, 144, 260], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.92305326461792
bi 1 loss 5.236156463623047
bi 2 loss 4.988587856292725
bi 3 loss 4.9073805809021
Layer  5  loss:  5.081228256225586 0.0 10.003692626953125
logits torch.Size([512, 4, 1024]) labels torch.Size([512, 4]) 0 1022
Curr loss timestep torch.Size([512, 4]) tensor([345, 311, 207, 289], device='cuda:0') tensor(154, device='cuda:0')
bi 0 loss 4.911244869232178
bi 1 loss 5.2433977127075195
bi 2 loss 5.274117469787598
bi 3 loss 5.034838676452637
Layer  6  loss:  5.129831314086914 0.0 11.057703971862793
logits torch.Size([512, 4, 1024]) labels torch.Size([512, 4]) 0 1022
Curr loss timestep torch.Size([512, 4]) tensor([218, 254, 143, 156], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.99901008605957
bi 1 loss 5.323359489440918
bi 2 loss 5.148550987243652
bi 3 loss 5.08391809463501
Epoch 0: :   3%|▎         | 15790/600000 [05:29<3:23:11, v_num=12, reduced_train_loss=0.829, global_step=15788.0, consumed_samples=63156.0, train_step_timing in s=0.394]Epoch 0: :   3%|▎         | 15790/600000 [05:29<3:23:11, v_num=12, reduced_train_loss=37.70, global_step=15789.0, consumed_samples=63160.0, train_step_timing in s=0.338]loss mask original None

First layer loss:  0.021236782893538475 torch.Size([370, 4]) 0.3268493115901947 0.0
Max loss timestep torch.Size([370, 4]) tensor([ 64, 324,  73, 130], device='cuda:0') tensor(115, device='cuda:0')
bi 0 loss 0.01727035641670227
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
bi 1 loss 0.02054806426167488
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
bi 2 loss 0.02657291106879711
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 3 loss 0.024114146828651428
speech mask sum tensor(124, device='cuda:0') loss mask sum tensor(124, device='cuda:0')
logits torch.Size([370, 4, 257024]) labels torch.Size([370, 4]) 0 257022
Layer  0  loss:  0.016973482444882393 0.0 0.3876008987426758
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1023
Curr loss timestep torch.Size([370, 4]) tensor([154, 230, 101, 126], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 0.013420268893241882
bi 1 loss 0.017221808433532715
bi 2 loss 0.02149794064462185
bi 3 loss 0.018161093816161156
Layer  1  loss:  0.02059839479625225 0.0 0.5226462483406067
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1019
Curr loss timestep torch.Size([370, 4]) tensor([137, 334, 103, 124], device='cuda:0') tensor(124, device='cuda:0')
bi 0 loss 0.012690098024904728
bi 1 loss 0.025837911292910576
bi 2 loss 0.02252306416630745
bi 3 loss 0.021764086559414864
Layer  2  loss:  0.0170891135931015 0.0 0.30233749747276306
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1022
Curr loss timestep torch.Size([370, 4]) tensor([139, 210,  52, 121], device='cuda:0') tensor(139, device='cuda:0')
bi 0 loss 0.013002889230847359
bi 1 loss 0.020307473838329315
bi 2 loss 0.013453379273414612
bi 3 loss 0.020879963412880898
Layer  3  loss:  0.021150149405002594 0.0 0.43837255239486694
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1022
Curr loss timestep torch.Size([370, 4]) tensor([152, 278,  93, 153], device='cuda:0') tensor(152, device='cuda:0')
bi 0 loss 0.018280034884810448
bi 1 loss 0.018049756065011024
bi 2 loss 0.021730326116085052
bi 3 loss 0.031037604436278343
Layer  4  loss:  0.01758367009460926 0.0 0.3416666090488434
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1021
Curr loss timestep torch.Size([370, 4]) tensor([180, 262,  73,  95], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 0.012671787291765213
bi 1 loss 0.02103496342897415
bi 2 loss 0.015464434400200844
bi 3 loss 0.02090625651180744
Layer  5  loss:  0.01916329190135002 0.0 0.38791021704673767
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1015
Curr loss timestep torch.Size([370, 4]) tensor([142, 231,  88, 120], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 0.013401218689978123
bi 1 loss 0.023013871163129807
bi 2 loss 0.018657110631465912
bi 3 loss 0.02165929414331913
Layer  6  loss:  0.017986122518777847 0.0 0.5218127965927124
logits torch.Size([370, 4, 1024]) labels torch.Size([370, 4]) 0 1019
Curr loss timestep torch.Size([370, 4]) tensor([187, 261,  85, 171], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.012969249859452248
bi 1 loss 0.021118924021720886
bi 2 loss 0.018109114840626717
bi 3 loss 0.020065922290086746
Epoch 0: :   3%|▎         | 15791/600000 [05:29<3:23:22, v_num=12, reduced_train_loss=37.70, global_step=15789.0, consumed_samples=63160.0, train_step_timing in s=0.338]Epoch 0: :   3%|▎         | 15791/600000 [05:29<3:23:22, v_num=12, reduced_train_loss=0.152, global_step=15790.0, consumed_samples=63164.0, train_step_timing in s=0.295]loss mask original None

First layer loss:  0.11081377416849136 torch.Size([550, 4]) 6.379947662353516 0.0
Max loss timestep torch.Size([550, 4]) tensor([361, 314, 340, 483], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.1660652607679367
speech mask sum tensor(339, device='cuda:0') loss mask sum tensor(339, device='cuda:0')
bi 1 loss 0.0948563814163208
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
bi 2 loss 0.08861991763114929
speech mask sum tensor(295, device='cuda:0') loss mask sum tensor(295, device='cuda:0')
bi 3 loss 0.07220949977636337
speech mask sum tensor(285, device='cuda:0') loss mask sum tensor(285, device='cuda:0')
logits torch.Size([550, 4, 257024]) labels torch.Size([550, 4]) 0 257023
Layer  0  loss:  0.12334149330854416 0.0 8.721386909484863
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1023
Curr loss timestep torch.Size([550, 4]) tensor([537, 267, 340, 304], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.18390081822872162
bi 1 loss 0.0860883817076683
bi 2 loss 0.0975005105137825
bi 3 loss 0.08772822469472885
Layer  1  loss:  0.16755755245685577 0.0 8.253384590148926
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1022
Curr loss timestep torch.Size([550, 4]) tensor([410, 282, 341, 304], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.28902220726013184
bi 1 loss 0.07439570873975754
bi 2 loss 0.08970775455236435
bi 3 loss 0.1278492957353592
Layer  2  loss:  0.17210248112678528 0.0 12.781639099121094
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1022
Curr loss timestep torch.Size([550, 4]) tensor([410, 275, 341, 304], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.23752744495868683
bi 1 loss 0.11517360061407089
bi 2 loss 0.13117149472236633
bi 3 loss 0.15142987668514252
Layer  3  loss:  0.16318370401859283 0.0 12.551840782165527
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1021
Curr loss timestep torch.Size([550, 4]) tensor([457, 315, 341, 405], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 0.25721967220306396
bi 1 loss 0.064215287566185
bi 2 loss 0.13743749260902405
bi 3 loss 0.10367703437805176
Layer  4  loss:  0.17832422256469727 0.0 13.687819480895996
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1022
Curr loss timestep torch.Size([550, 4]) tensor([410, 284, 341, 405], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.3058954179286957
bi 1 loss 0.03984377160668373
bi 2 loss 0.1110282763838768
bi 3 loss 0.13219517469406128
Layer  5  loss:  0.1897730529308319 0.0 8.44697093963623
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1022
Curr loss timestep torch.Size([550, 4]) tensor([410, 262, 283, 405], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.2642483413219452
bi 1 loss 0.1029333844780922
bi 2 loss 0.1763482540845871
bi 3 loss 0.13763034343719482
Layer  6  loss:  0.1585179716348648 0.0 11.356993675231934
logits torch.Size([550, 4, 1024]) labels torch.Size([550, 4]) 0 1019
Curr loss timestep torch.Size([550, 4]) tensor([364, 292, 283, 304], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.22355179488658905
bi 1 loss 0.08243788778781891
bi 2 loss 0.13631382584571838
bi 3 loss 0.12389933317899704
Epoch 0: :   3%|▎         | 15792/600000 [05:30<3:23:37, v_num=12, reduced_train_loss=0.152, global_step=15790.0, consumed_samples=63164.0, train_step_timing in s=0.295]Epoch 0: :   3%|▎         | 15792/600000 [05:30<3:23:37, v_num=12, reduced_train_loss=1.260, global_step=15791.0, consumed_samples=63168.0, train_step_timing in s=0.380]loss mask original None

First layer loss:  0.22909310460090637 torch.Size([630, 4]) 13.05526351928711 0.0
Max loss timestep torch.Size([630, 4]) tensor([198, 465, 330, 522], device='cuda:0') tensor(465, device='cuda:0')
bi 0 loss 0.06925040483474731
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
bi 1 loss 0.39270058274269104
speech mask sum tensor(384, device='cuda:0') loss mask sum tensor(384, device='cuda:0')
bi 2 loss 0.08503929525613785
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
bi 3 loss 0.22122390568256378
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
logits torch.Size([630, 4, 257024]) labels torch.Size([630, 4]) 0 257023
Layer  0  loss:  0.22858956456184387 0.0 13.617528915405273
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([190, 530, 330, 526], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.08724378794431686
bi 1 loss 0.3236318826675415
bi 2 loss 0.09595324844121933
bi 3 loss 0.2712080776691437
Layer  1  loss:  0.24721172451972961 0.0 8.927626609802246
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1022
Curr loss timestep torch.Size([630, 4]) tensor([203, 530, 330, 522], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.05067465826869011
bi 1 loss 0.34426847100257874
bi 2 loss 0.12154265493154526
bi 3 loss 0.2967776954174042
Layer  2  loss:  0.2925466299057007 0.0 16.812589645385742
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1022
Curr loss timestep torch.Size([630, 4]) tensor([202, 463, 330, 538], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.08079253137111664
bi 1 loss 0.38093435764312744
bi 2 loss 0.126840278506279
bi 3 loss 0.3825996220111847
Layer  3  loss:  0.28417930006980896 0.0 10.92106819152832
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([135, 530, 330, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.04298451915383339
bi 1 loss 0.3970703184604645
bi 2 loss 0.09791658073663712
bi 3 loss 0.37369945645332336
Layer  4  loss:  0.30345889925956726 0.0 15.22263240814209
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1022
Curr loss timestep torch.Size([630, 4]) tensor([185, 365, 330, 538], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.05539442598819733
bi 1 loss 0.4118247330188751
bi 2 loss 0.10421275347471237
bi 3 loss 0.40817421674728394
Layer  5  loss:  0.28497835993766785 0.0 11.898114204406738
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([207, 490, 330, 526], device='cuda:0') tensor(490, device='cuda:0')
bi 0 loss 0.047243501991033554
bi 1 loss 0.4070242643356323
bi 2 loss 0.10235358029603958
bi 3 loss 0.362576961517334
Layer  6  loss:  0.31129807233810425 0.0 13.666014671325684
logits torch.Size([630, 4, 1024]) labels torch.Size([630, 4]) 0 1023
Curr loss timestep torch.Size([630, 4]) tensor([163, 490, 322, 522], device='cuda:0') tensor(490, device='cuda:0')
bi 0 loss 0.09572134912014008
bi 1 loss 0.42093729972839355
bi 2 loss 0.10953792184591293
bi 3 loss 0.40851694345474243
Epoch 0: :   3%|▎         | 15793/600000 [05:30<3:23:53, v_num=12, reduced_train_loss=1.260, global_step=15791.0, consumed_samples=63168.0, train_step_timing in s=0.380]Epoch 0: :   3%|▎         | 15793/600000 [05:30<3:23:53, v_num=12, reduced_train_loss=2.180, global_step=15792.0, consumed_samples=63172.0, train_step_timing in s=0.433]loss mask original None

First layer loss:  3.5504324436187744 torch.Size([652, 4]) 10.445295333862305 0.0
Max loss timestep torch.Size([652, 4]) tensor([ 83, 310, 394, 298], device='cuda:0') tensor(466, device='cuda:0')
bi 0 loss 3.7182745933532715
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 1 loss 3.7744340896606445
speech mask sum tensor(469, device='cuda:0') loss mask sum tensor(469, device='cuda:0')
bi 2 loss 3.2599809169769287
speech mask sum tensor(369, device='cuda:0') loss mask sum tensor(369, device='cuda:0')
bi 3 loss 3.5104527473449707
speech mask sum tensor(371, device='cuda:0') loss mask sum tensor(371, device='cuda:0')
logits torch.Size([652, 4, 257024]) labels torch.Size([652, 4]) 0 257022
Layer  0  loss:  4.2572760581970215 0.0 11.17794418334961
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1023
Curr loss timestep torch.Size([652, 4]) tensor([117, 548, 394, 225], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 4.600710868835449
bi 1 loss 4.3486151695251465
bi 2 loss 4.042888641357422
bi 3 loss 4.261545181274414
Layer  1  loss:  4.552591800689697 0.0 13.131248474121094
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1022
Curr loss timestep torch.Size([652, 4]) tensor([138, 520, 397, 386], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 4.8053297996521
bi 1 loss 4.597242832183838
bi 2 loss 4.184683799743652
bi 3 loss 4.793267726898193
Layer  2  loss:  4.786393165588379 0.0 10.933527946472168
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1023
Curr loss timestep torch.Size([652, 4]) tensor([143, 203, 249, 398], device='cuda:0') tensor(456, device='cuda:0')
bi 0 loss 4.658813953399658
bi 1 loss 4.888343811035156
bi 2 loss 4.262505531311035
bi 3 loss 5.213306903839111
Layer  3  loss:  4.937158107757568 0.0 12.154850006103516
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1021
Curr loss timestep torch.Size([652, 4]) tensor([ 93, 358, 454, 366], device='cuda:0') tensor(454, device='cuda:0')
bi 0 loss 4.970683574676514
bi 1 loss 4.983663082122803
bi 2 loss 4.470378875732422
bi 3 loss 5.333505153656006
Layer  4  loss:  5.037073612213135 0.0 11.15183162689209
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1022
Curr loss timestep torch.Size([652, 4]) tensor([125, 471, 228, 512], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 4.89162015914917
bi 1 loss 5.016976833343506
bi 2 loss 4.65165376663208
bi 3 loss 5.485416889190674
Layer  5  loss:  5.125901699066162 0.0 9.997231483459473
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1023
Curr loss timestep torch.Size([652, 4]) tensor([121, 436, 364, 509], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 4.97980260848999
bi 1 loss 5.246541500091553
bi 2 loss 4.582100868225098
bi 3 loss 5.554037570953369
Layer  6  loss:  5.121063709259033 0.0 10.916958808898926
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1020
Curr loss timestep torch.Size([652, 4]) tensor([110, 437, 409, 247], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 4.9870452880859375
bi 1 loss 5.1143317222595215
bi 2 loss 4.722456932067871
bi 3 loss 5.5625176429748535
Epoch 0: :   3%|▎         | 15794/600000 [05:31<3:24:09, v_num=12, reduced_train_loss=2.180, global_step=15792.0, consumed_samples=63172.0, train_step_timing in s=0.433]Epoch 0: :   3%|▎         | 15794/600000 [05:31<3:24:09, v_num=12, reduced_train_loss=37.40, global_step=15793.0, consumed_samples=63176.0, train_step_timing in s=0.402]loss mask original None

First layer loss:  0.06436766684055328 torch.Size([599, 4]) 4.773027420043945 0.0
Max loss timestep torch.Size([599, 4]) tensor([543,  68, 227, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.07851610332727432
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 1 loss 0.004490939434617758
speech mask sum tensor(37, device='cuda:0') loss mask sum tensor(37, device='cuda:0')
bi 2 loss 0.05433126166462898
speech mask sum tensor(188, device='cuda:0') loss mask sum tensor(188, device='cuda:0')
bi 3 loss 0.06332052499055862
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257023
Layer  0  loss:  0.08324820548295975 0.0 9.559319496154785
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([544,  72, 130, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.1196112409234047
bi 1 loss 0.04710869491100311
bi 2 loss 0.041772060096263885
bi 3 loss 0.07622262835502625
Layer  1  loss:  0.09271840751171112 0.0 9.881402969360352
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([544,  70, 107, 374], device='cuda:0') tensor(107, device='cuda:0')
bi 0 loss 0.13628867268562317
bi 1 loss 0.02018033154308796
bi 2 loss 0.09491664916276932
bi 3 loss 0.05760940536856651
Layer  2  loss:  0.05980198085308075 0.0 5.980247497558594
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([544,  68, 121, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.08564625680446625
bi 1 loss 0.011062636971473694
bi 2 loss 0.03612067922949791
bi 3 loss 0.054079942405223846
Layer  3  loss:  0.08070532232522964 0.0 4.269248962402344
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1021
Curr loss timestep torch.Size([599, 4]) tensor([543,  71, 151, 374], device='cuda:0') tensor(543, device='cuda:0')
bi 0 loss 0.13870076835155487
bi 1 loss 0.03816636651754379
bi 2 loss 0.03630702942609787
bi 3 loss 0.05519842356443405
Layer  4  loss:  0.07111892104148865 0.0 5.758838176727295
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([544,  67, 135, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.10148641467094421
bi 1 loss 0.010521023534238338
bi 2 loss 0.05638687312602997
bi 3 loss 0.05719999969005585
Layer  5  loss:  0.0781186893582344 0.0 12.177178382873535
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([544,  73, 189, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.1281331330537796
bi 1 loss 0.024024654179811478
bi 2 loss 0.022758232429623604
bi 3 loss 0.06797932833433151
Layer  6  loss:  0.09350308030843735 0.0 12.481048583984375
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1019
Curr loss timestep torch.Size([599, 4]) tensor([305,  68, 254, 374], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.12475576251745224
bi 1 loss 0.013715083710849285
bi 2 loss 0.049372971057891846
bi 3 loss 0.09791930019855499
Epoch 0: :   3%|▎         | 15795/600000 [05:31<3:24:25, v_num=12, reduced_train_loss=37.40, global_step=15793.0, consumed_samples=63176.0, train_step_timing in s=0.402]Epoch 0: :   3%|▎         | 15795/600000 [05:31<3:24:25, v_num=12, reduced_train_loss=0.624, global_step=15794.0, consumed_samples=63180.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.08579861372709274 torch.Size([607, 4]) 9.358208656311035 0.0
Max loss timestep torch.Size([607, 4]) tensor([193, 275, 570, 314], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.022155102342367172
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 1 loss 0.05156240984797478
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 2 loss 0.14244529604911804
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 3 loss 0.07853468507528305
speech mask sum tensor(351, device='cuda:0') loss mask sum tensor(351, device='cuda:0')
logits torch.Size([607, 4, 257024]) labels torch.Size([607, 4]) 0 257023
Layer  0  loss:  0.11705918610095978 0.0 10.595723152160645
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([200, 301, 578, 314], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.049286000430583954
bi 1 loss 0.10242388397455215
bi 2 loss 0.1956588476896286
bi 3 loss 0.07429113984107971
Layer  1  loss:  0.13000008463859558 0.0 13.157999038696289
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([218, 300, 456, 315], device='cuda:0') tensor(300, device='cuda:0')
bi 0 loss 0.03052476793527603
bi 1 loss 0.1238689050078392
bi 2 loss 0.21945194900035858
bi 3 loss 0.08577301353216171
Layer  2  loss:  0.1393972635269165 0.0 12.339963912963867
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([ 84, 300, 570, 314], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.04853883013129234
bi 1 loss 0.0951586589217186
bi 2 loss 0.22009991109371185
bi 3 loss 0.12609513103961945
Layer  3  loss:  0.1510465294122696 0.0 10.220102310180664
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([181, 301, 570, 314], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.04387925565242767
bi 1 loss 0.11893584579229355
bi 2 loss 0.251543253660202
bi 3 loss 0.11595018953084946
Layer  4  loss:  0.1394186019897461 0.0 12.061450958251953
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([166, 299, 570, 314], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.023070013150572777
bi 1 loss 0.12782064080238342
bi 2 loss 0.21572470664978027
bi 3 loss 0.12221211940050125
Layer  5  loss:  0.1619344800710678 0.0 12.443471908569336
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([221, 300, 570, 315], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.04451816529035568
bi 1 loss 0.10749475657939911
bi 2 loss 0.2730921804904938
bi 3 loss 0.13526062667369843
Layer  6  loss:  0.15608108043670654 0.0 13.766496658325195
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([ 90, 299, 570, 314], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.035228148102760315
bi 1 loss 0.0681423768401146
bi 2 loss 0.27525991201400757
bi 3 loss 0.14476770162582397
Epoch 0: :   3%|▎         | 15796/600000 [05:32<3:24:41, v_num=12, reduced_train_loss=0.624, global_step=15794.0, consumed_samples=63180.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15796/600000 [05:32<3:24:41, v_num=12, reduced_train_loss=1.080, global_step=15795.0, consumed_samples=63184.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.06373989582061768 torch.Size([454, 4]) 5.950539588928223 0.0
Max loss timestep torch.Size([454, 4]) tensor([340, 204, 270, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.08217267692089081
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 1 loss 0.029121069237589836
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
bi 2 loss 0.03654230013489723
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 3 loss 0.09772597253322601
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
logits torch.Size([454, 4, 257024]) labels torch.Size([454, 4]) 0 257021
Layer  0  loss:  0.0716477781534195 0.0 12.689047813415527
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1023
Curr loss timestep torch.Size([454, 4]) tensor([340, 174, 290, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.07585259526968002
bi 1 loss 0.027498647570610046
bi 2 loss 0.03440818190574646
bi 3 loss 0.1292971670627594
Layer  1  loss:  0.08597902953624725 0.0 9.947715759277344
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([305, 168, 178, 345], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.06575780361890793
bi 1 loss 0.03454868867993355
bi 2 loss 0.041599299758672714
bi 3 loss 0.16975679993629456
Layer  2  loss:  0.09612421691417694 0.0 9.341854095458984
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([339, 216, 236, 345], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.13885082304477692
bi 1 loss 0.03186915069818497
bi 2 loss 0.047727588564157486
bi 3 loss 0.1520717740058899
Layer  3  loss:  0.09334644675254822 0.0 10.815240859985352
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1022
Curr loss timestep torch.Size([454, 4]) tensor([339, 147, 287, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.09107905626296997
bi 1 loss 0.03868231177330017
bi 2 loss 0.04143846780061722
bi 3 loss 0.17439773678779602
Layer  4  loss:  0.08392071723937988 0.0 7.85562801361084
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1021
Curr loss timestep torch.Size([454, 4]) tensor([339,  59, 301, 345], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.16002953052520752
bi 1 loss 0.034139882773160934
bi 2 loss 0.04774405062198639
bi 3 loss 0.09914563596248627
Layer  5  loss:  0.08905914425849915 0.0 10.282649040222168
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1020
Curr loss timestep torch.Size([454, 4]) tensor([305, 217, 105, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.11247140914201736
bi 1 loss 0.031045084819197655
bi 2 loss 0.05259896069765091
bi 3 loss 0.14287254214286804
Layer  6  loss:  0.0946962833404541 0.0 9.888492584228516
logits torch.Size([454, 4, 1024]) labels torch.Size([454, 4]) 0 1019
Curr loss timestep torch.Size([454, 4]) tensor([280, 213,  99, 344], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.1535046249628067
bi 1 loss 0.024207763373851776
bi 2 loss 0.05440494045615196
bi 3 loss 0.1375846415758133
Epoch 0: :   3%|▎         | 15797/600000 [05:32<3:24:53, v_num=12, reduced_train_loss=1.080, global_step=15795.0, consumed_samples=63184.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15797/600000 [05:32<3:24:53, v_num=12, reduced_train_loss=0.679, global_step=15796.0, consumed_samples=63188.0, train_step_timing in s=0.326]loss mask original None

First layer loss:  0.08890670537948608 torch.Size([613, 4]) 9.267127990722656 0.0
Max loss timestep torch.Size([613, 4]) tensor([ 49, 501, 489,  92], device='cuda:0') tensor(489, device='cuda:0')
bi 0 loss 0.06618104875087738
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 1 loss 0.06800339370965958
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
bi 2 loss 0.1544877588748932
speech mask sum tensor(457, device='cuda:0') loss mask sum tensor(457, device='cuda:0')
bi 3 loss 0.022905947640538216
speech mask sum tensor(239, device='cuda:0') loss mask sum tensor(239, device='cuda:0')
logits torch.Size([613, 4, 257024]) labels torch.Size([613, 4]) 0 257023
Layer  0  loss:  0.1310412883758545 0.0 8.098343849182129
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([267, 501, 533, 260], device='cuda:0') tensor(501, device='cuda:0')
bi 0 loss 0.07113904505968094
bi 1 loss 0.12585462629795074
bi 2 loss 0.21894702315330505
bi 3 loss 0.03536124899983406
Layer  1  loss:  0.13091716170310974 0.0 12.6287202835083
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([ 70, 501, 489,  96], device='cuda:0') tensor(489, device='cuda:0')
bi 0 loss 0.06035781651735306
bi 1 loss 0.09744354337453842
bi 2 loss 0.23867280781269073
bi 3 loss 0.0563046857714653
Layer  2  loss:  0.14886300265789032 0.0 14.647797584533691
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([229, 283, 489, 147], device='cuda:0') tensor(489, device='cuda:0')
bi 0 loss 0.05824338272213936
bi 1 loss 0.10622550547122955
bi 2 loss 0.28877735137939453
bi 3 loss 0.04953010752797127
Layer  3  loss:  0.1435273289680481 0.0 14.27647876739502
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([ 75, 501, 535, 194], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.05421815067529678
bi 1 loss 0.1238582506775856
bi 2 loss 0.26365765929222107
bi 3 loss 0.041902266442775726
Layer  4  loss:  0.14958293735980988 0.0 11.688228607177734
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([ 57, 501, 535, 114], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.0671653002500534
bi 1 loss 0.1063341498374939
bi 2 loss 0.2760756015777588
bi 3 loss 0.0682281106710434
Layer  5  loss:  0.1547505259513855 0.0 12.365365028381348
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1020
Curr loss timestep torch.Size([613, 4]) tensor([270, 501, 489, 204], device='cuda:0') tensor(489, device='cuda:0')
bi 0 loss 0.05473658815026283
bi 1 loss 0.11044758558273315
bi 2 loss 0.303282767534256
bi 3 loss 0.05173126980662346
Layer  6  loss:  0.14354023337364197 0.0 13.975820541381836
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([120, 335, 489, 208], device='cuda:0') tensor(489, device='cuda:0')
bi 0 loss 0.07626529783010483
bi 1 loss 0.07968679070472717
bi 2 loss 0.28406956791877747
bi 3 loss 0.05399564653635025
Epoch 0: :   3%|▎         | 15798/600000 [05:33<3:25:20, v_num=12, reduced_train_loss=0.679, global_step=15796.0, consumed_samples=63188.0, train_step_timing in s=0.326]Epoch 0: :   3%|▎         | 15798/600000 [05:33<3:25:20, v_num=12, reduced_train_loss=1.090, global_step=15797.0, consumed_samples=63192.0, train_step_timing in s=0.696]loss mask original None

First layer loss:  3.796635627746582 torch.Size([516, 4]) 12.337915420532227 0.0
Max loss timestep torch.Size([516, 4]) tensor([355,  98, 237, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 3.162339687347412
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 3.8966000080108643
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 2 loss 4.14271354675293
speech mask sum tensor(329, device='cuda:0') loss mask sum tensor(329, device='cuda:0')
bi 3 loss 3.1934115886688232
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
logits torch.Size([516, 4, 257024]) labels torch.Size([516, 4]) 0 257023
Layer  0  loss:  4.256943225860596 0.0 9.64409065246582
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([289,  77, 270, 270], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 3.711198329925537
bi 1 loss 4.2508440017700195
bi 2 loss 4.710535526275635
bi 3 loss 3.367002487182617
Layer  1  loss:  4.395925998687744 0.0 9.827123641967773
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([309, 119, 432, 297], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 3.9319379329681396
bi 1 loss 4.40350866317749
bi 2 loss 4.780343532562256
bi 3 loss 3.6208884716033936
Layer  2  loss:  4.714244365692139 0.0 10.066487312316895
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([294,  93, 388, 284], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 3.8800058364868164
bi 1 loss 4.834196090698242
bi 2 loss 5.149979114532471
bi 3 loss 4.00787878036499
Layer  3  loss:  4.866884708404541 0.0 11.395045280456543
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([313, 153, 215, 261], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 4.034429550170898
bi 1 loss 4.907249450683594
bi 2 loss 5.38787841796875
bi 3 loss 4.007126331329346
Layer  4  loss:  5.080707550048828 0.0 8.963469505310059
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([302, 129, 356, 283], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 4.27528190612793
bi 1 loss 5.2480549812316895
bi 2 loss 5.567550182342529
bi 3 loss 4.080747127532959
Layer  5  loss:  5.059682369232178 0.0 10.007204055786133
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1022
Curr loss timestep torch.Size([516, 4]) tensor([355, 191, 218, 299], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 4.118803024291992
bi 1 loss 5.229694366455078
bi 2 loss 5.555699825286865
bi 3 loss 4.185821533203125
Layer  6  loss:  5.048112869262695 0.0 9.95286750793457
logits torch.Size([516, 4, 1024]) labels torch.Size([516, 4]) 0 1023
Curr loss timestep torch.Size([516, 4]) tensor([367, 100, 478, 268], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 4.261646270751953
bi 1 loss 5.234752655029297
bi 2 loss 5.555974960327148
bi 3 loss 3.919239044189453
Epoch 0: :   3%|▎         | 15799/600000 [05:33<3:25:33, v_num=12, reduced_train_loss=1.090, global_step=15797.0, consumed_samples=63192.0, train_step_timing in s=0.696]Epoch 0: :   3%|▎         | 15799/600000 [05:33<3:25:33, v_num=12, reduced_train_loss=37.20, global_step=15798.0, consumed_samples=63196.0, train_step_timing in s=0.339]loss mask original None

First layer loss:  0.01201492827385664 torch.Size([387, 4]) 0.1495818942785263 0.0
Max loss timestep torch.Size([387, 4]) tensor([289, 236, 144, 205], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 0.012088095769286156
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 1 loss 0.012108758091926575
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
bi 2 loss 0.008922970853745937
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 3 loss 0.014546571299433708
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
logits torch.Size([387, 4, 257024]) labels torch.Size([387, 4]) 0 257023
Layer  0  loss:  0.012737948447465897 0.0 0.13396933674812317
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1023
Curr loss timestep torch.Size([387, 4]) tensor([242, 233, 146, 146], device='cuda:0') tensor(146, device='cuda:0')
bi 0 loss 0.012885120697319508
bi 1 loss 0.013444623909890652
bi 2 loss 0.011596494354307652
bi 3 loss 0.012809215113520622
Layer  1  loss:  0.011949308216571808 0.0 0.16847196221351624
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1022
Curr loss timestep torch.Size([387, 4]) tensor([315,  88,  92,  97], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 0.011596065945923328
bi 1 loss 0.010326351970434189
bi 2 loss 0.011153820902109146
bi 3 loss 0.014795354567468166
Layer  2  loss:  0.010532582178711891 0.0 0.20738357305526733
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1022
Curr loss timestep torch.Size([387, 4]) tensor([318, 187, 103, 226], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.013850442133843899
bi 1 loss 0.009888734668493271
bi 2 loss 0.006515092682093382
bi 3 loss 0.011394119821488857
Layer  3  loss:  0.012514791451394558 0.0 0.21253758668899536
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1022
Curr loss timestep torch.Size([387, 4]) tensor([279,  65, 206, 231], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 0.016019320115447044
bi 1 loss 0.010267678648233414
bi 2 loss 0.011225633323192596
bi 3 loss 0.012564513832330704
Layer  4  loss:  0.011981886811554432 0.0 0.23985907435417175
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1021
Curr loss timestep torch.Size([387, 4]) tensor([355, 233, 160, 184], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 0.015436573885381222
bi 1 loss 0.011250062845647335
bi 2 loss 0.008354944176971912
bi 3 loss 0.012459294870495796
Layer  5  loss:  0.011511644348502159 0.0 0.1593838483095169
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1023
Curr loss timestep torch.Size([387, 4]) tensor([302, 182,  94, 201], device='cuda:0') tensor(182, device='cuda:0')
bi 0 loss 0.01259700395166874
bi 1 loss 0.010888233780860901
bi 2 loss 0.010960405692458153
bi 3 loss 0.011580218560993671
Layer  6  loss:  0.010517939925193787 0.0 0.18759006261825562
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1023
Curr loss timestep torch.Size([387, 4]) tensor([311, 198, 192,  77], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 0.011079845950007439
bi 1 loss 0.010043206624686718
bi 2 loss 0.010261857882142067
bi 3 loss 0.010695415548980236
Epoch 0: :   3%|▎         | 15800/600000 [05:33<3:25:44, v_num=12, reduced_train_loss=37.20, global_step=15798.0, consumed_samples=63196.0, train_step_timing in s=0.339]Epoch 0: :   3%|▎         | 15800/600000 [05:33<3:25:44, v_num=12, reduced_train_loss=0.0938, global_step=15799.0, consumed_samples=63200.0, train_step_timing in s=0.300]loss mask original None

First layer loss:  0.16013103723526 torch.Size([575, 4]) 15.248273849487305 0.0
Max loss timestep torch.Size([575, 4]) tensor([315, 265, 268, 530], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.0916021317243576
speech mask sum tensor(329, device='cuda:0') loss mask sum tensor(329, device='cuda:0')
bi 1 loss 0.08786047250032425
speech mask sum tensor(344, device='cuda:0') loss mask sum tensor(344, device='cuda:0')
bi 2 loss 0.12107709795236588
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
bi 3 loss 0.325396865606308
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
logits torch.Size([575, 4, 257024]) labels torch.Size([575, 4]) 0 257022
Layer  0  loss:  0.21931245923042297 0.0 13.231437683105469
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([278, 353, 293, 471], device='cuda:0') tensor(471, device='cuda:0')
bi 0 loss 0.0834072083234787
bi 1 loss 0.13773725926876068
bi 2 loss 0.21288074553012848
bi 3 loss 0.4259974956512451
Layer  1  loss:  0.21801789104938507 0.0 14.28188705444336
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([388, 392, 267, 471], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.12643785774707794
bi 1 loss 0.10425598919391632
bi 2 loss 0.1897168904542923
bi 3 loss 0.43421581387519836
Layer  2  loss:  0.23394058644771576 0.0 11.31718635559082
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([391, 353, 267, 325], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.11117745190858841
bi 1 loss 0.15706992149353027
bi 2 loss 0.2150401771068573
bi 3 loss 0.43516409397125244
Layer  3  loss:  0.23611822724342346 0.0 13.983983993530273
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1021
Curr loss timestep torch.Size([575, 4]) tensor([335, 265, 362, 471], device='cuda:0') tensor(471, device='cuda:0')
bi 0 loss 0.14201079308986664
bi 1 loss 0.15033234655857086
bi 2 loss 0.18485015630722046
bi 3 loss 0.44820356369018555
Layer  4  loss:  0.2279197722673416 0.0 13.3118257522583
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([334, 392, 362, 471], device='cuda:0') tensor(471, device='cuda:0')
bi 0 loss 0.11472658067941666
bi 1 loss 0.1324024647474289
bi 2 loss 0.1977461576461792
bi 3 loss 0.44806820154190063
Layer  5  loss:  0.23691312968730927 0.0 13.479817390441895
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([386, 392, 267, 325], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.13575609028339386
bi 1 loss 0.13247178494930267
bi 2 loss 0.23974888026714325
bi 3 loss 0.42560580372810364
Layer  6  loss:  0.24119582772254944 0.0 15.015682220458984
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([388, 353, 267, 471], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.1190844401717186
bi 1 loss 0.1482262909412384
bi 2 loss 0.27439695596694946
bi 3 loss 0.4113566279411316
Epoch 0: :   3%|▎         | 15801/600000 [05:34<3:26:00, v_num=12, reduced_train_loss=0.0938, global_step=15799.0, consumed_samples=63200.0, train_step_timing in s=0.300]Epoch 0: :   3%|▎         | 15801/600000 [05:34<3:26:00, v_num=12, reduced_train_loss=1.770, global_step=15800.0, consumed_samples=63204.0, train_step_timing in s=0.401] loss mask original None

First layer loss:  3.9545698165893555 torch.Size([524, 4]) 11.997150421142578 0.0
Max loss timestep torch.Size([524, 4]) tensor([256, 402, 378, 328], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 2.963244676589966
speech mask sum tensor(45, device='cuda:0') loss mask sum tensor(45, device='cuda:0')
bi 1 loss 4.472691059112549
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 2 loss 3.546950340270996
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 3 loss 3.798809289932251
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
logits torch.Size([524, 4, 257024]) labels torch.Size([524, 4]) 0 257023
Layer  0  loss:  4.2247090339660645 0.0 10.996251106262207
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([256, 400, 439, 387], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 3.5475471019744873
bi 1 loss 4.721981525421143
bi 2 loss 3.5184085369110107
bi 3 loss 4.360196113586426
Layer  1  loss:  4.499939441680908 0.0 10.027510643005371
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([258, 161, 444, 243], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 3.443516731262207
bi 1 loss 5.1017537117004395
bi 2 loss 3.941195249557495
bi 3 loss 4.392451763153076
Layer  2  loss:  4.832448482513428 0.0 12.274662017822266
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([266, 220, 267, 339], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 3.648409366607666
bi 1 loss 5.357479095458984
bi 2 loss 4.353113174438477
bi 3 loss 4.776744365692139
Layer  3  loss:  4.869308948516846 0.0 10.036884307861328
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1022
Curr loss timestep torch.Size([524, 4]) tensor([263,  75, 452, 276], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 3.444727659225464
bi 1 loss 5.491558074951172
bi 2 loss 4.354138374328613
bi 3 loss 4.751020908355713
Layer  4  loss:  4.974137306213379 0.0 10.314156532287598
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1022
Curr loss timestep torch.Size([524, 4]) tensor([268, 197, 358, 314], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 3.620241403579712
bi 1 loss 5.513301372528076
bi 2 loss 4.489867210388184
bi 3 loss 4.933035850524902
Layer  5  loss:  5.027287483215332 0.0 10.110689163208008
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([256, 174, 456, 318], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 3.3571088314056396
bi 1 loss 5.570033550262451
bi 2 loss 4.5353312492370605
bi 3 loss 5.04530143737793
Layer  6  loss:  5.143520832061768 0.0 10.934134483337402
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1020
Curr loss timestep torch.Size([524, 4]) tensor([257, 374, 283, 398], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 3.5415523052215576
bi 1 loss 5.703946590423584
bi 2 loss 4.687638282775879
bi 3 loss 5.0851263999938965
Epoch 0: :   3%|▎         | 15802/600000 [05:34<3:26:13, v_num=12, reduced_train_loss=1.770, global_step=15800.0, consumed_samples=63204.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15802/600000 [05:34<3:26:13, v_num=12, reduced_train_loss=37.50, global_step=15801.0, consumed_samples=63208.0, train_step_timing in s=0.340]loss mask original None

First layer loss:  0.1320096254348755 torch.Size([749, 4]) 6.475602149963379 0.0
Max loss timestep torch.Size([749, 4]) tensor([230, 581, 325, 357], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.015800269320607185
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 1 loss 0.21169526875019073
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
bi 2 loss 0.06402314454317093
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 3 loss 0.1533443033695221
speech mask sum tensor(337, device='cuda:0') loss mask sum tensor(337, device='cuda:0')
logits torch.Size([749, 4, 257024]) labels torch.Size([749, 4]) 0 257022
Layer  0  loss:  0.16273702681064606 0.0 11.557990074157715
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1023
Curr loss timestep torch.Size([749, 4]) tensor([171, 562, 315, 357], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.026787078008055687
bi 1 loss 0.3092065453529358
bi 2 loss 0.08683256804943085
bi 3 loss 0.12691760063171387
Layer  1  loss:  0.1781953126192093 0.0 8.815908432006836
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([188, 562, 315, 356], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.02585325390100479
bi 1 loss 0.3322076201438904
bi 2 loss 0.08361174166202545
bi 3 loss 0.15639722347259521
Layer  2  loss:  0.17777635157108307 0.0 8.302140235900879
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([147, 432, 315, 356], device='cuda:0') tensor(432, device='cuda:0')
bi 0 loss 0.017992794513702393
bi 1 loss 0.33027026057243347
bi 2 loss 0.10624494403600693
bi 3 loss 0.14349237084388733
Layer  3  loss:  0.19615457952022552 0.0 9.895783424377441
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([209, 530, 315, 356], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.0364542230963707
bi 1 loss 0.3894754648208618
bi 2 loss 0.09723188728094101
bi 3 loss 0.13842067122459412
Layer  4  loss:  0.19153931736946106 0.0 10.17996597290039
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1023
Curr loss timestep torch.Size([749, 4]) tensor([143, 530, 315, 357], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.029134726151823997
bi 1 loss 0.37013763189315796
bi 2 loss 0.10217677056789398
bi 3 loss 0.14379112422466278
Layer  5  loss:  0.21564805507659912 0.0 15.547233581542969
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([224, 530, 315, 356], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.024156959727406502
bi 1 loss 0.41135066747665405
bi 2 loss 0.08460170030593872
bi 3 loss 0.19529108703136444
Layer  6  loss:  0.17889252305030823 0.0 11.337907791137695
logits torch.Size([749, 4, 1024]) labels torch.Size([749, 4]) 0 1022
Curr loss timestep torch.Size([749, 4]) tensor([167, 530, 315, 356], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.015304004773497581
bi 1 loss 0.34335678815841675
bi 2 loss 0.09495009481906891
bi 3 loss 0.14294014871120453
Epoch 0: :   3%|▎         | 15803/600000 [05:35<3:26:32, v_num=12, reduced_train_loss=37.50, global_step=15801.0, consumed_samples=63208.0, train_step_timing in s=0.340]Epoch 0: :   3%|▎         | 15803/600000 [05:35<3:26:32, v_num=12, reduced_train_loss=1.430, global_step=15802.0, consumed_samples=63212.0, train_step_timing in s=0.510]loss mask original None

First layer loss:  3.6520140171051025 torch.Size([604, 4]) 12.982098579406738 0.0
Max loss timestep torch.Size([604, 4]) tensor([351, 130, 236, 377], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 3.1277410984039307
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 1 loss 3.373248815536499
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 2 loss 4.002848148345947
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 3 loss 3.8231239318847656
speech mask sum tensor(442, device='cuda:0') loss mask sum tensor(442, device='cuda:0')
logits torch.Size([604, 4, 257024]) labels torch.Size([604, 4]) 0 257022
Layer  0  loss:  4.238092422485352 0.0 10.808392524719238
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([314, 173, 276, 287], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 4.32079553604126
bi 1 loss 3.6538398265838623
bi 2 loss 4.237963676452637
bi 3 loss 4.332543849945068
Layer  1  loss:  4.454446315765381 0.0 10.25100040435791
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([255, 181, 283, 250], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 4.37087869644165
bi 1 loss 3.6874890327453613
bi 2 loss 4.666350841522217
bi 3 loss 4.584357738494873
Layer  2  loss:  4.811555862426758 0.0 9.446826934814453
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([328, 164, 222, 178], device='cuda:0') tensor(364, device='cuda:0')
bi 0 loss 4.919633388519287
bi 1 loss 3.94204044342041
bi 2 loss 4.944341659545898
bi 3 loss 4.905967712402344
Layer  3  loss:  4.898037910461426 0.0 10.895135879516602
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([425, 176, 289, 465], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 4.990776538848877
bi 1 loss 4.038119316101074
bi 2 loss 5.06609582901001
bi 3 loss 4.983384132385254
Layer  4  loss:  5.085930824279785 0.0 10.934162139892578
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([265, 158, 354, 474], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 5.118932247161865
bi 1 loss 4.423361301422119
bi 2 loss 5.310128211975098
bi 3 loss 5.1319475173950195
Layer  5  loss:  5.091296672821045 0.0 11.097917556762695
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([348, 159, 246, 212], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 5.185858726501465
bi 1 loss 4.115240573883057
bi 2 loss 5.30620002746582
bi 3 loss 5.183558940887451
Layer  6  loss:  5.1327104568481445 0.0 9.795578956604004
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([256, 160, 278, 220], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 5.244798183441162
bi 1 loss 4.374457836151123
bi 2 loss 5.315873622894287
bi 3 loss 5.179626941680908
Epoch 0: :   3%|▎         | 15804/600000 [05:35<3:26:48, v_num=12, reduced_train_loss=1.430, global_step=15802.0, consumed_samples=63212.0, train_step_timing in s=0.510]Epoch 0: :   3%|▎         | 15804/600000 [05:35<3:26:48, v_num=12, reduced_train_loss=37.40, global_step=15803.0, consumed_samples=63216.0, train_step_timing in s=0.396]loss mask original None

First layer loss:  0.12048138678073883 torch.Size([573, 4]) 11.125471115112305 0.0
Max loss timestep torch.Size([573, 4]) tensor([349, 214, 360, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.09593687206506729
speech mask sum tensor(216, device='cuda:0') loss mask sum tensor(216, device='cuda:0')
bi 1 loss 0.040020450949668884
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 2 loss 0.129778653383255
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 3 loss 0.14574003219604492
speech mask sum tensor(412, device='cuda:0') loss mask sum tensor(412, device='cuda:0')
logits torch.Size([573, 4, 257024]) labels torch.Size([573, 4]) 0 257022
Layer  0  loss:  0.1451365351676941 0.0 16.500221252441406
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([284, 202, 359, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.1411316990852356
bi 1 loss 0.032918307930231094
bi 2 loss 0.12939193844795227
bi 3 loss 0.18716585636138916
Layer  1  loss:  0.15298157930374146 0.0 11.507214546203613
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([284, 154, 359, 479], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 0.12016052007675171
bi 1 loss 0.04018891230225563
bi 2 loss 0.1354062557220459
bi 3 loss 0.21170341968536377
Layer  2  loss:  0.1702868640422821 0.0 13.548445701599121
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([348, 202, 358, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.12997440993785858
bi 1 loss 0.04869583994150162
bi 2 loss 0.1690143346786499
bi 3 loss 0.222232848405838
Layer  3  loss:  0.16758017241954803 0.0 12.894438743591309
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1022
Curr loss timestep torch.Size([573, 4]) tensor([284, 218, 359, 479], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 0.15254054963588715
bi 1 loss 0.047895852476358414
bi 2 loss 0.18042612075805664
bi 3 loss 0.19467176496982574
Layer  4  loss:  0.14956751465797424 0.0 9.895214080810547
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1022
Curr loss timestep torch.Size([573, 4]) tensor([347, 194, 359, 479], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.13937929272651672
bi 1 loss 0.04531652480363846
bi 2 loss 0.15857379138469696
bi 3 loss 0.17336112260818481
Layer  5  loss:  0.18076184391975403 0.0 13.062748908996582
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1021
Curr loss timestep torch.Size([573, 4]) tensor([347, 180, 359, 479], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 0.14909599721431732
bi 1 loss 0.07189749926328659
bi 2 loss 0.16232597827911377
bi 3 loss 0.23859383165836334
Layer  6  loss:  0.15978257358074188 0.0 15.245577812194824
logits torch.Size([573, 4, 1024]) labels torch.Size([573, 4]) 0 1023
Curr loss timestep torch.Size([573, 4]) tensor([349, 189, 359, 480], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.14256706833839417
bi 1 loss 0.04285373166203499
bi 2 loss 0.17303138971328735
bi 3 loss 0.18702161312103271
Epoch 0: :   3%|▎         | 15805/600000 [05:36<3:27:03, v_num=12, reduced_train_loss=37.40, global_step=15803.0, consumed_samples=63216.0, train_step_timing in s=0.396]Epoch 0: :   3%|▎         | 15805/600000 [05:36<3:27:03, v_num=12, reduced_train_loss=1.250, global_step=15804.0, consumed_samples=63220.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.1005418449640274 torch.Size([579, 4]) 7.85070276260376 0.0
Max loss timestep torch.Size([579, 4]) tensor([542, 394, 272, 424], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.16124866902828217
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 1 loss 0.08390916883945465
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 2 loss 0.07273434847593307
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 3 loss 0.06469894200563431
speech mask sum tensor(351, device='cuda:0') loss mask sum tensor(351, device='cuda:0')
logits torch.Size([579, 4, 257024]) labels torch.Size([579, 4]) 0 257022
Layer  0  loss:  0.12315937131643295 0.0 8.562833786010742
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([559, 452, 223, 449], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.20341657102108002
bi 1 loss 0.12638168036937714
bi 2 loss 0.031131669878959656
bi 3 loss 0.07801955938339233
Layer  1  loss:  0.1266651451587677 0.0 9.133023262023926
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1022
Curr loss timestep torch.Size([579, 4]) tensor([554, 452, 271, 323], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.21917620301246643
bi 1 loss 0.1175203025341034
bi 2 loss 0.05792932212352753
bi 3 loss 0.06978391110897064
Layer  2  loss:  0.14835013449192047 0.0 12.785014152526855
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1022
Curr loss timestep torch.Size([579, 4]) tensor([542, 453, 257, 343], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.23571060597896576
bi 1 loss 0.12862876057624817
bi 2 loss 0.11991530656814575
bi 3 loss 0.08872311562299728
Layer  3  loss:  0.14790558815002441 0.0 8.95126724243164
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([368, 452, 275, 215], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.2204844355583191
bi 1 loss 0.14144352078437805
bi 2 loss 0.1255628764629364
bi 3 loss 0.08993414044380188
Layer  4  loss:  0.15541794896125793 0.0 11.035889625549316
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([561, 452, 247, 379], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.2908492982387543
bi 1 loss 0.14062093198299408
bi 2 loss 0.06229947879910469
bi 3 loss 0.07023400813341141
Layer  5  loss:  0.15807169675827026 0.0 10.265746116638184
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([561, 453, 270, 343], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.23857846856117249
bi 1 loss 0.1276446133852005
bi 2 loss 0.06133056804537773
bi 3 loss 0.14143343269824982
Layer  6  loss:  0.14664632081985474 0.0 11.937960624694824
logits torch.Size([579, 4, 1024]) labels torch.Size([579, 4]) 0 1023
Curr loss timestep torch.Size([579, 4]) tensor([368, 368, 287, 343], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.24635809659957886
bi 1 loss 0.14002983272075653
bi 2 loss 0.06295812129974365
bi 3 loss 0.08663762360811234
Epoch 0: :   3%|▎         | 15806/600000 [05:36<3:27:18, v_num=12, reduced_train_loss=1.250, global_step=15804.0, consumed_samples=63220.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15806/600000 [05:36<3:27:18, v_num=12, reduced_train_loss=1.110, global_step=15805.0, consumed_samples=63224.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  3.881676197052002 torch.Size([692, 4]) 11.46664047241211 0.0
Max loss timestep torch.Size([692, 4]) tensor([332, 228, 289, 249], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 4.084587574005127
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
bi 1 loss 4.188213348388672
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 2 loss 4.208866596221924
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 3 loss 2.9939985275268555
speech mask sum tensor(332, device='cuda:0') loss mask sum tensor(332, device='cuda:0')
logits torch.Size([692, 4, 257024]) labels torch.Size([692, 4]) 0 257023
Layer  0  loss:  4.531440258026123 0.0 11.255160331726074
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1023
Curr loss timestep torch.Size([692, 4]) tensor([247,  76, 290, 304], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 4.623668193817139
bi 1 loss 5.031586647033691
bi 2 loss 4.621572494506836
bi 3 loss 3.799142837524414
Layer  1  loss:  4.778146266937256 0.0 11.539628982543945
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1023
Curr loss timestep torch.Size([692, 4]) tensor([409, 365, 311, 296], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 4.8834004402160645
bi 1 loss 5.194679260253906
bi 2 loss 4.801633358001709
bi 3 loss 4.17294979095459
Layer  2  loss:  5.010635852813721 0.0 10.93878173828125
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1022
Curr loss timestep torch.Size([692, 4]) tensor([638,  62, 327, 150], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 4.994058609008789
bi 1 loss 5.393607139587402
bi 2 loss 5.3274078369140625
bi 3 loss 4.358341217041016
Layer  3  loss:  5.117265224456787 0.0 11.273787498474121
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1023
Curr loss timestep torch.Size([692, 4]) tensor([573, 254, 205, 214], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 5.132416725158691
bi 1 loss 5.5646162033081055
bi 2 loss 5.325960159301758
bi 3 loss 4.446052074432373
Layer  4  loss:  5.260120391845703 0.0 11.330039024353027
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1022
Curr loss timestep torch.Size([692, 4]) tensor([637, 172, 194, 322], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 5.2628068923950195
bi 1 loss 5.618141174316406
bi 2 loss 5.505190372467041
bi 3 loss 4.668898105621338
Layer  5  loss:  5.405494213104248 0.0 10.416999816894531
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1022
Curr loss timestep torch.Size([692, 4]) tensor([530, 205, 333, 311], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 5.325951099395752
bi 1 loss 5.758256435394287
bi 2 loss 5.7128472328186035
bi 3 loss 4.881069660186768
Layer  6  loss:  5.29995584487915 0.0 10.101497650146484
logits torch.Size([692, 4, 1024]) labels torch.Size([692, 4]) 0 1023
Curr loss timestep torch.Size([692, 4]) tensor([614, 339, 289,  85], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 5.186690807342529
bi 1 loss 5.814309120178223
bi 2 loss 5.5613250732421875
bi 3 loss 4.692407131195068
Epoch 0: :   3%|▎         | 15807/600000 [05:37<3:27:34, v_num=12, reduced_train_loss=1.110, global_step=15805.0, consumed_samples=63224.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15807/600000 [05:37<3:27:34, v_num=12, reduced_train_loss=39.30, global_step=15806.0, consumed_samples=63228.0, train_step_timing in s=0.432]loss mask original None

First layer loss:  0.10347334295511246 torch.Size([613, 4]) 11.108611106872559 0.0
Max loss timestep torch.Size([613, 4]) tensor([275, 473, 188, 176], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.0859273299574852
speech mask sum tensor(230, device='cuda:0') loss mask sum tensor(230, device='cuda:0')
bi 1 loss 0.16449877619743347
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
bi 2 loss 0.03372633457183838
speech mask sum tensor(216, device='cuda:0') loss mask sum tensor(216, device='cuda:0')
bi 3 loss 0.027854610234498978
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
logits torch.Size([613, 4, 257024]) labels torch.Size([613, 4]) 0 257023
Layer  0  loss:  0.07865700870752335 0.0 12.679917335510254
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([192, 597, 186, 206], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.06018352508544922
bi 1 loss 0.12243997305631638
bi 2 loss 0.0412946417927742
bi 3 loss 0.009351000189781189
Layer  1  loss:  0.08616328239440918 0.0 6.554592132568359
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1022
Curr loss timestep torch.Size([613, 4]) tensor([350, 597,  68, 208], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.07037733495235443
bi 1 loss 0.1279723048210144
bi 2 loss 0.044587019830942154
bi 3 loss 0.029193580150604248
Layer  2  loss:  0.09721208363771439 0.0 11.28463363647461
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1022
Curr loss timestep torch.Size([613, 4]) tensor([309, 597, 219, 184], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.08806207031011581
bi 1 loss 0.1496153622865677
bi 2 loss 0.037936337292194366
bi 3 loss 0.01603669486939907
Layer  3  loss:  0.08880053460597992 0.0 12.39232349395752
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1023
Curr loss timestep torch.Size([613, 4]) tensor([309, 473, 155, 180], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.0729546770453453
bi 1 loss 0.1420629471540451
bi 2 loss 0.0282590351998806
bi 3 loss 0.023348959162831306
Layer  4  loss:  0.09500479698181152 0.0 11.4229736328125
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1022
Curr loss timestep torch.Size([613, 4]) tensor([309, 597, 167, 185], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.08539644628763199
bi 1 loss 0.14406311511993408
bi 2 loss 0.04326355457305908
bi 3 loss 0.012810604646801949
Layer  5  loss:  0.09379201382398605 0.0 12.41799545288086
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1022
Curr loss timestep torch.Size([613, 4]) tensor([309, 473, 162, 212], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.08472492545843124
bi 1 loss 0.1289338916540146
bi 2 loss 0.06585665792226791
bi 3 loss 0.01894286461174488
Layer  6  loss:  0.10737626254558563 0.0 9.577824592590332
logits torch.Size([613, 4, 1024]) labels torch.Size([613, 4]) 0 1022
Curr loss timestep torch.Size([613, 4]) tensor([349, 473, 126, 184], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 0.08060206472873688
bi 1 loss 0.16502679884433746
bi 2 loss 0.05801084265112877
bi 3 loss 0.022639445960521698
Epoch 0: :   3%|▎         | 15808/600000 [05:37<3:27:50, v_num=12, reduced_train_loss=39.30, global_step=15806.0, consumed_samples=63228.0, train_step_timing in s=0.432]Epoch 0: :   3%|▎         | 15808/600000 [05:37<3:27:50, v_num=12, reduced_train_loss=0.750, global_step=15807.0, consumed_samples=63232.0, train_step_timing in s=0.418]loss mask original None

First layer loss:  0.16599388420581818 torch.Size([847, 4]) 10.210474967956543 0.0
Max loss timestep torch.Size([847, 4]) tensor([130, 118, 114, 664], device='cuda:0') tensor(664, device='cuda:0')
bi 0 loss 0.026308109983801842
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 1 loss 0.030303016304969788
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 2 loss 0.045525260269641876
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 3 loss 0.29670101404190063
speech mask sum tensor(431, device='cuda:0') loss mask sum tensor(431, device='cuda:0')
logits torch.Size([847, 4, 257024]) labels torch.Size([847, 4]) 0 257023
Layer  0  loss:  0.17375600337982178 0.0 12.563422203063965
logits torch.Size([847, 4, 1024]) labels torch.Size([847, 4]) 0 1023
Curr loss timestep torch.Size([847, 4]) tensor([106, 108, 117, 663], device='cuda:0') tensor(663, device='cuda:0')
bi 0 loss 0.01992114633321762
bi 1 loss 0.034866515547037125
bi 2 loss 0.05109965056180954
bi 3 loss 0.3106750249862671
Layer  1  loss:  0.22191785275936127 0.0 14.137788772583008
logits torch.Size([847, 4, 1024]) labels torch.Size([847, 4]) 0 1023
Curr loss timestep torch.Size([847, 4]) tensor([106, 125, 111, 663], device='cuda:0') tensor(663, device='cuda:0')
bi 0 loss 0.02251412533223629
bi 1 loss 0.04579312354326248
bi 2 loss 0.04377329349517822
bi 3 loss 0.4018315374851227
Layer  2  loss:  0.18699753284454346 0.0 11.397594451904297
logits torch.Size([847, 4, 1024]) labels torch.Size([847, 4]) 0 1022
Curr loss timestep torch.Size([847, 4]) tensor([ 80, 119, 121, 664], device='cuda:0') tensor(664, device='cuda:0')
bi 0 loss 0.019982468336820602
bi 1 loss 0.04113157466053963
bi 2 loss 0.0522952526807785
bi 3 loss 0.33373597264289856
Layer  3  loss:  0.22500738501548767 0.0 11.619229316711426
logits torch.Size([847, 4, 1024]) labels torch.Size([847, 4]) 0 1023
Curr loss timestep torch.Size([847, 4]) tensor([176, 105, 143, 664], device='cuda:0') tensor(664, device='cuda:0')
bi 0 loss 0.02043193019926548
bi 1 loss 0.04863986745476723
bi 2 loss 0.05614188313484192
bi 3 loss 0.40454670786857605
Layer  4  loss:  0.24188275635242462 0.0 11.361841201782227
logits torch.Size([847, 4, 1024]) labels torch.Size([847, 4]) 0 1022
Curr loss timestep torch.Size([847, 4]) tensor([166,  83,  83, 663], device='cuda:0') tensor(663, device='cuda:0')
bi 0 loss 0.029703466221690178
bi 1 loss 0.03990868106484413
bi 2 loss 0.061970699578523636
bi 3 loss 0.4378545880317688
Layer  5  loss:  0.2449241578578949 0.0 12.276850700378418
logits torch.Size([847, 4, 1024]) labels torch.Size([847, 4]) 0 1023
Curr loss timestep torch.Size([847, 4]) tensor([166, 200,  97, 672], device='cuda:0') tensor(672, device='cuda:0')
bi 0 loss 0.037000611424446106
bi 1 loss 0.025771014392375946
bi 2 loss 0.0769876018166542
bi 3 loss 0.44482484459877014
Layer  6  loss:  0.2319977730512619 0.0 14.657099723815918
logits torch.Size([847, 4, 1024]) labels torch.Size([847, 4]) 0 1023
Curr loss timestep torch.Size([847, 4]) tensor([131, 169, 100, 663], device='cuda:0') tensor(663, device='cuda:0')
bi 0 loss 0.042198095470666885
bi 1 loss 0.05026107653975487
bi 2 loss 0.041668329387903214
bi 3 loss 0.414265513420105
Epoch 0: :   3%|▎         | 15809/600000 [05:38<3:28:13, v_num=12, reduced_train_loss=0.750, global_step=15807.0, consumed_samples=63232.0, train_step_timing in s=0.418]Epoch 0: :   3%|▎         | 15809/600000 [05:38<3:28:13, v_num=12, reduced_train_loss=1.690, global_step=15808.0, consumed_samples=63236.0, train_step_timing in s=0.583]loss mask original None

First layer loss:  3.66087007522583 torch.Size([376, 4]) 12.7749662399292 0.0
Max loss timestep torch.Size([376, 4]) tensor([251, 158, 127, 315], device='cuda:0') tensor(127, device='cuda:0')
bi 0 loss 3.99696683883667
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 1 loss 4.041109561920166
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 2 loss 2.851064920425415
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 3 loss 3.4787728786468506
speech mask sum tensor(270, device='cuda:0') loss mask sum tensor(270, device='cuda:0')
logits torch.Size([376, 4, 257024]) labels torch.Size([376, 4]) 0 257022
Layer  0  loss:  4.078350067138672 0.0 9.629749298095703
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1023
Curr loss timestep torch.Size([376, 4]) tensor([278, 250, 136, 341], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 4.192998886108398
bi 1 loss 4.489646911621094
bi 2 loss 3.3762025833129883
bi 3 loss 3.955993175506592
Layer  1  loss:  4.459812164306641 0.0 10.31558609008789
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([278, 195, 128, 311], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 4.224256992340088
bi 1 loss 4.929837703704834
bi 2 loss 4.139716625213623
bi 3 loss 4.31334924697876
Layer  2  loss:  4.798604488372803 0.0 10.817438125610352
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([168, 284, 130, 150], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 4.684315204620361
bi 1 loss 5.038053035736084
bi 2 loss 4.458454608917236
bi 3 loss 4.8113908767700195
Layer  3  loss:  4.927112579345703 0.0 10.65813159942627
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([194, 273, 146, 215], device='cuda:0') tensor(150, device='cuda:0')
bi 0 loss 4.942698001861572
bi 1 loss 5.155820369720459
bi 2 loss 4.663215160369873
bi 3 loss 4.825681209564209
Layer  4  loss:  4.993065357208252 0.0 10.70887565612793
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([143, 345, 209, 146], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 4.937353134155273
bi 1 loss 5.33212423324585
bi 2 loss 4.463818073272705
bi 3 loss 4.9657111167907715
Layer  5  loss:  5.123509407043457 0.0 9.47651481628418
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1020
Curr loss timestep torch.Size([376, 4]) tensor([154, 207, 123, 315], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 5.1502909660339355
bi 1 loss 5.474618434906006
bi 2 loss 4.535670757293701
bi 3 loss 5.059974670410156
Layer  6  loss:  5.132116794586182 0.0 9.505002975463867
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1023
Curr loss timestep torch.Size([376, 4]) tensor([294, 260, 227, 151], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 5.028080940246582
bi 1 loss 5.421537399291992
bi 2 loss 4.7562689781188965
bi 3 loss 5.1069183349609375
Epoch 0: :   3%|▎         | 15810/600000 [05:38<3:28:24, v_num=12, reduced_train_loss=1.690, global_step=15808.0, consumed_samples=63236.0, train_step_timing in s=0.583]Epoch 0: :   3%|▎         | 15810/600000 [05:38<3:28:24, v_num=12, reduced_train_loss=37.20, global_step=15809.0, consumed_samples=63240.0, train_step_timing in s=0.285]loss mask original None

First layer loss:  0.08928778022527695 torch.Size([530, 4]) 8.80151653289795 0.0
Max loss timestep torch.Size([530, 4]) tensor([309, 393, 111, 103], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.17932264506816864
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 1 loss 0.10903443396091461
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
bi 2 loss 0.03505624085664749
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 3 loss 0.027058839797973633
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
logits torch.Size([530, 4, 257024]) labels torch.Size([530, 4]) 0 257023
Layer  0  loss:  0.0828496515750885 0.0 8.388076782226562
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([309, 368, 113, 129], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.1940218061208725
bi 1 loss 0.0916483923792839
bi 2 loss 0.02593867853283882
bi 3 loss 0.03888159990310669
Layer  1  loss:  0.09590618312358856 0.0 8.116619110107422
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([309, 294,  87, 115], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.20619964599609375
bi 1 loss 0.1212196871638298
bi 2 loss 0.01936214230954647
bi 3 loss 0.02269517257809639
Layer  2  loss:  0.1040995866060257 0.0 13.672561645507812
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([309, 369,  86,  92], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.355475515127182
bi 1 loss 0.1027115061879158
bi 2 loss 0.027162866666913033
bi 3 loss 0.027738774195313454
Layer  3  loss:  0.12261985242366791 0.0 14.005378723144531
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1021
Curr loss timestep torch.Size([530, 4]) tensor([309, 369,  84, 130], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.36752617359161377
bi 1 loss 0.13775673508644104
bi 2 loss 0.029929332435131073
bi 3 loss 0.017520545050501823
Layer  4  loss:  0.11218895763158798 0.0 10.246296882629395
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1016
Curr loss timestep torch.Size([530, 4]) tensor([309, 368,  78, 190], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.19061428308486938
bi 1 loss 0.1398085653781891
bi 2 loss 0.04977783188223839
bi 3 loss 0.04086123779416084
Layer  5  loss:  0.10408992320299149 0.0 16.915281295776367
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([309, 294,  96, 185], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.33586087822914124
bi 1 loss 0.11452153325080872
bi 2 loss 0.02329171448945999
bi 3 loss 0.010307279415428638
Layer  6  loss:  0.09951762109994888 0.0 10.807513236999512
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([309, 368, 108,  92], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.2921333909034729
bi 1 loss 0.10794049501419067
bi 2 loss 0.018100379034876823
bi 3 loss 0.030384611338377
Epoch 0: :   3%|▎         | 15811/600000 [05:38<3:28:38, v_num=12, reduced_train_loss=37.20, global_step=15809.0, consumed_samples=63240.0, train_step_timing in s=0.285]Epoch 0: :   3%|▎         | 15811/600000 [05:38<3:28:38, v_num=12, reduced_train_loss=0.811, global_step=15810.0, consumed_samples=63244.0, train_step_timing in s=0.370]loss mask original None

First layer loss:  0.047312647104263306 torch.Size([423, 4]) 2.8521065711975098 0.0
Max loss timestep torch.Size([423, 4]) tensor([344,  82, 377,  46], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.05202654376626015
speech mask sum tensor(287, device='cuda:0') loss mask sum tensor(287, device='cuda:0')
bi 1 loss 0.025690503418445587
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 2 loss 0.06911313533782959
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
bi 3 loss 0.014013821259140968
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
logits torch.Size([423, 4, 257024]) labels torch.Size([423, 4]) 0 257023
Layer  0  loss:  0.049608390778303146 0.0 3.2380051612854004
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([303, 103, 377, 126], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.06566113233566284
bi 1 loss 0.029269088059663773
bi 2 loss 0.0551052950322628
bi 3 loss 0.01356672402471304
Layer  1  loss:  0.06573141366243362 0.0 4.157439708709717
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([318, 105, 377,  84], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.06604297459125519
bi 1 loss 0.09113017469644547
bi 2 loss 0.07664506882429123
bi 3 loss 0.03117951564490795
Layer  2  loss:  0.05075249820947647 0.0 1.9193053245544434
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([348, 102, 377,  60], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.05642009153962135
bi 1 loss 0.03405642509460449
bi 2 loss 0.06981686502695084
bi 3 loss 0.01637200079858303
Layer  3  loss:  0.05247373506426811 0.0 1.3975045680999756
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([181,  69, 346,  82], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 0.06472069025039673
bi 1 loss 0.022112062200903893
bi 2 loss 0.06297390908002853
bi 3 loss 0.024199767038226128
Layer  4  loss:  0.05764100328087807 0.0 4.030984878540039
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([285,  85, 377,  69], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.05597696080803871
bi 1 loss 0.03487541154026985
bi 2 loss 0.08766593039035797
bi 3 loss 0.02768303081393242
Layer  5  loss:  0.06646881252527237 0.0 7.876546382904053
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([288,  99, 377,  52], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.048974793404340744
bi 1 loss 0.02576468139886856
bi 2 loss 0.1377384215593338
bi 3 loss 0.020695196464657784
Layer  6  loss:  0.04082619026303291 0.0 2.328979253768921
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([226,  78, 377, 128], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.03658102825284004
bi 1 loss 0.0282132625579834
bi 2 loss 0.06745317578315735
bi 3 loss 0.01636086031794548
Epoch 0: :   3%|▎         | 15812/600000 [05:39<3:28:50, v_num=12, reduced_train_loss=0.811, global_step=15810.0, consumed_samples=63244.0, train_step_timing in s=0.370]Epoch 0: :   3%|▎         | 15812/600000 [05:39<3:28:50, v_num=12, reduced_train_loss=0.431, global_step=15811.0, consumed_samples=63248.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  3.7873785495758057 torch.Size([636, 4]) 12.230692863464355 0.0
Max loss timestep torch.Size([636, 4]) tensor([325, 119, 265, 499], device='cuda:0') tensor(230, device='cuda:0')
bi 0 loss 3.9300172328948975
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 1 loss 3.80289626121521
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 2 loss 3.964785099029541
speech mask sum tensor(264, device='cuda:0') loss mask sum tensor(264, device='cuda:0')
bi 3 loss 3.580576181411743
speech mask sum tensor(452, device='cuda:0') loss mask sum tensor(452, device='cuda:0')
logits torch.Size([636, 4, 257024]) labels torch.Size([636, 4]) 0 257022
Layer  0  loss:  4.18580961227417 0.0 10.78962516784668
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([308, 109, 231, 578], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 4.24005651473999
bi 1 loss 4.044015884399414
bi 2 loss 4.442221164703369
bi 3 loss 4.062810897827148
Layer  1  loss:  4.654216289520264 0.0 10.483668327331543
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([360, 243,  73, 464], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 5.0106520652771
bi 1 loss 4.657102108001709
bi 2 loss 4.6834797859191895
bi 3 loss 4.395319938659668
Layer  2  loss:  4.8551506996154785 0.0 9.869451522827148
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([327, 181, 190, 375], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 5.2200093269348145
bi 1 loss 4.848605632781982
bi 2 loss 4.960270881652832
bi 3 loss 4.550478935241699
Layer  3  loss:  4.910312652587891 0.0 10.406645774841309
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([447, 261,  52, 232], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 5.234812259674072
bi 1 loss 4.866587162017822
bi 2 loss 4.975603103637695
bi 3 loss 4.672754287719727
Layer  4  loss:  5.0561909675598145 0.0 9.591903686523438
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([406, 115, 191, 287], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 5.37603759765625
bi 1 loss 5.109711170196533
bi 2 loss 5.170415878295898
bi 3 loss 4.749731540679932
Layer  5  loss:  5.11330509185791 0.0 12.414384841918945
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([371, 226, 170, 436], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 5.444046974182129
bi 1 loss 5.17805814743042
bi 2 loss 5.0108819007873535
bi 3 loss 4.921010971069336
Layer  6  loss:  5.117244243621826 0.0 10.55622673034668
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([349, 182, 201, 239], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 5.401583194732666
bi 1 loss 5.25535249710083
bi 2 loss 5.112742900848389
bi 3 loss 4.866285800933838
Epoch 0: :   3%|▎         | 15813/600000 [05:39<3:29:06, v_num=12, reduced_train_loss=0.431, global_step=15811.0, consumed_samples=63248.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15813/600000 [05:39<3:29:06, v_num=12, reduced_train_loss=37.70, global_step=15812.0, consumed_samples=63252.0, train_step_timing in s=0.402]loss mask original None

First layer loss:  0.09031324833631516 torch.Size([603, 4]) 8.750287055969238 0.0
Max loss timestep torch.Size([603, 4]) tensor([359, 342, 476, 528], device='cuda:0') tensor(476, device='cuda:0')
bi 0 loss 0.057575445622205734
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
bi 1 loss 0.047779060900211334
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 2 loss 0.11523690074682236
speech mask sum tensor(355, device='cuda:0') loss mask sum tensor(355, device='cuda:0')
bi 3 loss 0.14634886384010315
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
logits torch.Size([603, 4, 257024]) labels torch.Size([603, 4]) 0 257023
Layer  0  loss:  0.14322644472122192 0.0 9.447443008422852
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([354, 374, 477, 565], device='cuda:0') tensor(565, device='cuda:0')
bi 0 loss 0.07614969462156296
bi 1 loss 0.08270576596260071
bi 2 loss 0.14728929102420807
bi 3 loss 0.3109850585460663
Layer  1  loss:  0.18518973886966705 0.0 12.28551959991455
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([370, 266, 475, 516], device='cuda:0') tensor(475, device='cuda:0')
bi 0 loss 0.08955834805965424
bi 1 loss 0.051900871098041534
bi 2 loss 0.19466891884803772
bi 3 loss 0.46955135464668274
Layer  2  loss:  0.205619677901268 0.0 11.84596061706543
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([357, 371, 476, 516], device='cuda:0') tensor(476, device='cuda:0')
bi 0 loss 0.09912008047103882
bi 1 loss 0.0999855101108551
bi 2 loss 0.18256767094135284
bi 3 loss 0.5340518951416016
Layer  3  loss:  0.17567302286624908 0.0 10.968927383422852
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([370, 348, 475, 541], device='cuda:0') tensor(475, device='cuda:0')
bi 0 loss 0.06957913935184479
bi 1 loss 0.07060664892196655
bi 2 loss 0.1720164269208908
bi 3 loss 0.46890789270401
Layer  4  loss:  0.1850862354040146 0.0 12.813834190368652
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([357, 243, 475, 565], device='cuda:0') tensor(475, device='cuda:0')
bi 0 loss 0.08600369095802307
bi 1 loss 0.03442193195223808
bi 2 loss 0.16901060938835144
bi 3 loss 0.5388007760047913
Layer  5  loss:  0.20449350774288177 0.0 12.813406944274902
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([370, 374, 475, 528], device='cuda:0') tensor(475, device='cuda:0')
bi 0 loss 0.1293371319770813
bi 1 loss 0.10094424337148666
bi 2 loss 0.1684853732585907
bi 3 loss 0.5026494860649109
Layer  6  loss:  0.2277449071407318 0.0 13.953417778015137
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1019
Curr loss timestep torch.Size([603, 4]) tensor([370, 288, 477, 565], device='cuda:0') tensor(477, device='cuda:0')
bi 0 loss 0.08420330286026001
bi 1 loss 0.10829591751098633
bi 2 loss 0.20618660748004913
bi 3 loss 0.6285921335220337
Epoch 0: :   3%|▎         | 15814/600000 [05:40<3:29:22, v_num=12, reduced_train_loss=37.70, global_step=15812.0, consumed_samples=63252.0, train_step_timing in s=0.402]Epoch 0: :   3%|▎         | 15814/600000 [05:40<3:29:22, v_num=12, reduced_train_loss=1.420, global_step=15813.0, consumed_samples=63256.0, train_step_timing in s=0.419]loss mask original None

First layer loss:  0.040762726217508316 torch.Size([375, 4]) 4.871336460113525 0.0
Max loss timestep torch.Size([375, 4]) tensor([160, 363, 213, 252], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.025635112076997757
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 1 loss 0.07371019572019577
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 2 loss 0.017674822360277176
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 3 loss 0.028410818427801132
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
logits torch.Size([375, 4, 257024]) labels torch.Size([375, 4]) 0 257022
Layer  0  loss:  0.0404900498688221 0.0 6.768884181976318
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([279, 363, 147, 254], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.026850998401641846
bi 1 loss 0.07006113231182098
bi 2 loss 0.02460426092147827
bi 3 loss 0.02459629811346531
Layer  1  loss:  0.042478643357753754 0.0 5.952761173248291
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([235, 363, 169, 221], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.018459388986229897
bi 1 loss 0.09474842995405197
bi 2 loss 0.00802791677415371
bi 3 loss 0.020695777609944344
Layer  2  loss:  0.04286321997642517 0.0 7.919867038726807
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([ 82, 363, 181, 267], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.023835107684135437
bi 1 loss 0.08321698009967804
bi 2 loss 0.020872049033641815
bi 3 loss 0.02269677072763443
Layer  3  loss:  0.04091550037264824 0.0 4.3174872398376465
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([145, 307, 213, 248], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.026682348921895027
bi 1 loss 0.07161445170640945
bi 2 loss 0.017440780997276306
bi 3 loss 0.031827885657548904
Layer  4  loss:  0.055916398763656616 0.0 8.98915958404541
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1022
Curr loss timestep torch.Size([375, 4]) tensor([165, 307, 152, 202], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.02387719415128231
bi 1 loss 0.12423387914896011
bi 2 loss 0.015809807926416397
bi 3 loss 0.02423633076250553
Layer  5  loss:  0.04020396247506142 0.0 7.126663684844971
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([227, 363, 148, 228], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.020498644560575485
bi 1 loss 0.08493617922067642
bi 2 loss 0.01113667618483305
bi 3 loss 0.018679678440093994
Layer  6  loss:  0.047880869358778 0.0 5.6633806228637695
logits torch.Size([375, 4, 1024]) labels torch.Size([375, 4]) 0 1023
Curr loss timestep torch.Size([375, 4]) tensor([327, 268, 152, 264], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.021302789449691772
bi 1 loss 0.10619815438985825
bi 2 loss 0.01347820833325386
bi 3 loss 0.018783628940582275
Epoch 0: :   3%|▎         | 15815/600000 [05:40<3:29:33, v_num=12, reduced_train_loss=1.420, global_step=15813.0, consumed_samples=63256.0, train_step_timing in s=0.419]Epoch 0: :   3%|▎         | 15815/600000 [05:40<3:29:33, v_num=12, reduced_train_loss=0.352, global_step=15814.0, consumed_samples=63260.0, train_step_timing in s=0.288]loss mask original None

First layer loss:  0.15267246961593628 torch.Size([495, 4]) 10.433055877685547 0.0
Max loss timestep torch.Size([495, 4]) tensor([303, 264, 189, 286], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.2586277723312378
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 1 loss 0.19237980246543884
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 2 loss 0.04929933324456215
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 3 loss 0.09751200675964355
speech mask sum tensor(407, device='cuda:0') loss mask sum tensor(407, device='cuda:0')
logits torch.Size([495, 4, 257024]) labels torch.Size([495, 4]) 0 257023
Layer  0  loss:  0.1768607199192047 0.0 14.766824722290039
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([305, 264, 166, 286], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.25174716114997864
bi 1 loss 0.3397376239299774
bi 2 loss 0.05133863165974617
bi 3 loss 0.10792406648397446
Layer  1  loss:  0.1933014988899231 0.0 13.527244567871094
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1022
Curr loss timestep torch.Size([495, 4]) tensor([383, 264, 195, 286], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.28115350008010864
bi 1 loss 0.34272894263267517
bi 2 loss 0.0294475257396698
bi 3 loss 0.12925943732261658
Layer  2  loss:  0.19403450191020966 0.0 13.187899589538574
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1023
Curr loss timestep torch.Size([495, 4]) tensor([303, 262, 155, 286], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.2822968363761902
bi 1 loss 0.32180172204971313
bi 2 loss 0.03923952206969261
bi 3 loss 0.13440093398094177
Layer  3  loss:  0.2181801199913025 0.0 16.107044219970703
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1021
Curr loss timestep torch.Size([495, 4]) tensor([304, 262, 197, 286], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.41845446825027466
bi 1 loss 0.23497171700000763
bi 2 loss 0.051557864993810654
bi 3 loss 0.12545214593410492
Layer  4  loss:  0.18515722453594208 0.0 13.30015754699707
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1022
Curr loss timestep torch.Size([495, 4]) tensor([305, 264, 149, 286], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 0.2928066551685333
bi 1 loss 0.2538681626319885
bi 2 loss 0.03514505922794342
bi 3 loss 0.130652517080307
Layer  5  loss:  0.2051001489162445 0.0 14.79015827178955
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1022
Curr loss timestep torch.Size([495, 4]) tensor([383, 264, 199, 286], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.35440197587013245
bi 1 loss 0.24581216275691986
bi 2 loss 0.028150564059615135
bi 3 loss 0.1393546462059021
Layer  6  loss:  0.2362169623374939 0.0 13.944804191589355
logits torch.Size([495, 4, 1024]) labels torch.Size([495, 4]) 0 1020
Curr loss timestep torch.Size([495, 4]) tensor([304, 264, 197, 286], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.3638988733291626
bi 1 loss 0.4300099313259125
bi 2 loss 0.04760192334651947
bi 3 loss 0.1389971524477005
Epoch 0: :   3%|▎         | 15816/600000 [05:40<3:29:46, v_num=12, reduced_train_loss=0.352, global_step=15814.0, consumed_samples=63260.0, train_step_timing in s=0.288]Epoch 0: :   3%|▎         | 15816/600000 [05:40<3:29:46, v_num=12, reduced_train_loss=1.560, global_step=15815.0, consumed_samples=63264.0, train_step_timing in s=0.346]loss mask original None

First layer loss:  0.3031257688999176 torch.Size([603, 4]) 15.597498893737793 0.0
Max loss timestep torch.Size([603, 4]) tensor([391, 409, 547, 328], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.3485722243785858
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 1 loss 0.42156386375427246
speech mask sum tensor(488, device='cuda:0') loss mask sum tensor(488, device='cuda:0')
bi 2 loss 0.2787717878818512
speech mask sum tensor(460, device='cuda:0') loss mask sum tensor(460, device='cuda:0')
bi 3 loss 0.07997635006904602
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
logits torch.Size([603, 4, 257024]) labels torch.Size([603, 4]) 0 257022
Layer  0  loss:  0.378780722618103 0.0 15.17597484588623
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([391, 345, 521, 328], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.5559519529342651
bi 1 loss 0.46371960639953613
bi 2 loss 0.3359244763851166
bi 3 loss 0.14090530574321747
Layer  1  loss:  0.4024481773376465 0.0 14.617643356323242
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([392, 425, 521, 327], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.7295927405357361
bi 1 loss 0.43852248787879944
bi 2 loss 0.36792615056037903
bi 3 loss 0.11503925174474716
Layer  2  loss:  0.40116626024246216 0.0 15.828600883483887
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([391, 464, 521, 328], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.5199162364006042
bi 1 loss 0.5235921740531921
bi 2 loss 0.354112833738327
bi 3 loss 0.1487233191728592
Layer  3  loss:  0.42845267057418823 0.0 16.182641983032227
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([391, 408, 370, 328], device='cuda:0') tensor(408, device='cuda:0')
bi 0 loss 0.5949058532714844
bi 1 loss 0.5633549690246582
bi 2 loss 0.3683180510997772
bi 3 loss 0.13481348752975464
Layer  4  loss:  0.4579932987689972 0.0 19.05476188659668
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([391, 344, 547, 270], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.5928876996040344
bi 1 loss 0.5573736429214478
bi 2 loss 0.43267199397087097
bi 3 loss 0.1966419517993927
Layer  5  loss:  0.47351402044296265 0.0 20.20322036743164
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([391, 344, 547, 328], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.6484116911888123
bi 1 loss 0.5714200139045715
bi 2 loss 0.4651387631893158
bi 3 loss 0.14988461136817932
Layer  6  loss:  0.47438421845436096 0.0 17.392292022705078
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([393, 408, 521, 328], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.7068705558776855
bi 1 loss 0.585480272769928
bi 2 loss 0.4383714199066162
bi 3 loss 0.12616866827011108
Epoch 0: :   3%|▎         | 15817/600000 [05:41<3:30:02, v_num=12, reduced_train_loss=1.560, global_step=15815.0, consumed_samples=63264.0, train_step_timing in s=0.346]Epoch 0: :   3%|▎         | 15817/600000 [05:41<3:30:02, v_num=12, reduced_train_loss=3.320, global_step=15816.0, consumed_samples=63268.0, train_step_timing in s=0.415]loss mask original None

First layer loss:  3.688413381576538 torch.Size([604, 4]) 12.108684539794922 0.0
Max loss timestep torch.Size([604, 4]) tensor([227, 442, 135, 168], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 3.153068780899048
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 1 loss 3.5509979724884033
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 2 loss 4.066697597503662
speech mask sum tensor(483, device='cuda:0') loss mask sum tensor(483, device='cuda:0')
bi 3 loss 3.2099602222442627
speech mask sum tensor(183, device='cuda:0') loss mask sum tensor(183, device='cuda:0')
logits torch.Size([604, 4, 257024]) labels torch.Size([604, 4]) 0 257022
Layer  0  loss:  4.141727924346924 0.0 10.762236595153809
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([254, 439, 223, 132], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 3.191300630569458
bi 1 loss 3.693814277648926
bi 2 loss 4.741008758544922
bi 3 loss 3.898854970932007
Layer  1  loss:  4.36083459854126 0.0 10.476338386535645
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([227, 397, 404, 142], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 3.9454398155212402
bi 1 loss 4.065494060516357
bi 2 loss 4.74463415145874
bi 3 loss 4.135969161987305
Layer  2  loss:  4.556947231292725 0.0 10.627199172973633
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([226, 229, 369, 133], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 4.076084136962891
bi 1 loss 4.260357856750488
bi 2 loss 4.937544345855713
bi 3 loss 4.372410297393799
Layer  3  loss:  4.622834205627441 0.0 10.784324645996094
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1021
Curr loss timestep torch.Size([604, 4]) tensor([228, 297, 315, 279], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 4.459070205688477
bi 1 loss 4.223114967346191
bi 2 loss 5.000730037689209
bi 3 loss 4.513546466827393
Layer  4  loss:  4.727802276611328 0.0 11.336952209472656
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1022
Curr loss timestep torch.Size([604, 4]) tensor([263, 197, 305, 237], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 4.50063943862915
bi 1 loss 4.320827484130859
bi 2 loss 5.198644161224365
bi 3 loss 4.416395664215088
Layer  5  loss:  4.8460893630981445 0.0 12.36550521850586
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1023
Curr loss timestep torch.Size([604, 4]) tensor([232, 400, 305, 280], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 4.538915157318115
bi 1 loss 4.630821228027344
bi 2 loss 5.193082332611084
bi 3 loss 4.5066680908203125
Layer  6  loss:  4.878530502319336 0.0 10.52078914642334
logits torch.Size([604, 4, 1024]) labels torch.Size([604, 4]) 0 1020
Curr loss timestep torch.Size([604, 4]) tensor([214, 494, 528, 171], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 4.733623504638672
bi 1 loss 4.583488941192627
bi 2 loss 5.239924430847168
bi 3 loss 4.590986251831055
Epoch 0: :   3%|▎         | 15818/600000 [05:41<3:30:16, v_num=12, reduced_train_loss=3.320, global_step=15816.0, consumed_samples=63268.0, train_step_timing in s=0.415]Epoch 0: :   3%|▎         | 15818/600000 [05:41<3:30:17, v_num=12, reduced_train_loss=35.80, global_step=15817.0, consumed_samples=63272.0, train_step_timing in s=0.379]loss mask original None

First layer loss:  0.08547394722700119 torch.Size([561, 4]) 8.65622615814209 0.0
Max loss timestep torch.Size([561, 4]) tensor([457, 133, 151, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.07851767539978027
speech mask sum tensor(433, device='cuda:0') loss mask sum tensor(433, device='cuda:0')
bi 1 loss 0.04892875626683235
speech mask sum tensor(233, device='cuda:0') loss mask sum tensor(233, device='cuda:0')
bi 2 loss 0.02270127460360527
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.1427103877067566
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257022
Layer  0  loss:  0.09388789534568787 0.0 16.687889099121094
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([535, 132, 220, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.06233524531126022
bi 1 loss 0.039340171962976456
bi 2 loss 0.021648110821843147
bi 3 loss 0.19546860456466675
Layer  1  loss:  0.10610668361186981 0.0 14.09738826751709
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([536, 120, 120, 436], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.06584088504314423
bi 1 loss 0.0369085930287838
bi 2 loss 0.033051371574401855
bi 3 loss 0.2276042103767395
Layer  2  loss:  0.09739387035369873 0.0 11.499279975891113
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([536, 264, 144, 436], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.08219470828771591
bi 1 loss 0.04224042221903801
bi 2 loss 0.026792213320732117
bi 3 loss 0.17939075827598572
Layer  3  loss:  0.10179316997528076 0.0 11.768486976623535
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1017
Curr loss timestep torch.Size([561, 4]) tensor([536, 101, 103, 436], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.06341709196567535
bi 1 loss 0.051091283559799194
bi 2 loss 0.02139180898666382
bi 3 loss 0.2123408317565918
Layer  4  loss:  0.12345249950885773 0.0 13.600763320922852
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([536,  96, 182, 436], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.07748410105705261
bi 1 loss 0.039304766803979874
bi 2 loss 0.027565959841012955
bi 3 loss 0.2705630958080292
Layer  5  loss:  0.11271987110376358 0.0 13.47584056854248
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([526, 231, 147, 435], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.08793088793754578
bi 1 loss 0.035058990120887756
bi 2 loss 0.02733607590198517
bi 3 loss 0.2264026403427124
Layer  6  loss:  0.09614730626344681 0.0 14.270025253295898
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([526, 188, 167, 436], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.06936321407556534
bi 1 loss 0.04245737940073013
bi 2 loss 0.03202923387289047
bi 3 loss 0.1882156878709793
Epoch 0: :   3%|▎         | 15819/600000 [05:42<3:30:31, v_num=12, reduced_train_loss=35.80, global_step=15817.0, consumed_samples=63272.0, train_step_timing in s=0.379]Epoch 0: :   3%|▎         | 15819/600000 [05:42<3:30:31, v_num=12, reduced_train_loss=0.817, global_step=15818.0, consumed_samples=63276.0, train_step_timing in s=0.391]loss mask original None

First layer loss:  0.04100261628627777 torch.Size([533, 4]) 0.7493412494659424 0.0
Max loss timestep torch.Size([533, 4]) tensor([314, 256, 184, 231], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.054496608674526215
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 1 loss 0.04595871642231941
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 2 loss 0.023983774706721306
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 3 loss 0.025946883484721184
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
logits torch.Size([533, 4, 257024]) labels torch.Size([533, 4]) 0 257023
Layer  0  loss:  0.07253411412239075 0.0 5.2275238037109375
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([346, 327, 187, 183], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 0.12861710786819458
bi 1 loss 0.04694056138396263
bi 2 loss 0.04289409518241882
bi 3 loss 0.03543272241950035
Layer  1  loss:  0.06090587005019188 0.0 5.693541526794434
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([349, 354, 205, 194], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.08208400756120682
bi 1 loss 0.07113199681043625
bi 2 loss 0.04027307406067848
bi 3 loss 0.03171996399760246
Layer  2  loss:  0.08184833824634552 0.0 5.649064540863037
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([349, 354, 217, 206], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.12865231931209564
bi 1 loss 0.08826027065515518
bi 2 loss 0.013302301056683064
bi 3 loss 0.04530716687440872
Layer  3  loss:  0.06030917912721634 0.0 4.9940996170043945
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1020
Curr loss timestep torch.Size([533, 4]) tensor([349, 356, 207,  79], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.06907489150762558
bi 1 loss 0.08108486980199814
bi 2 loss 0.04169492796063423
bi 3 loss 0.036740418523550034
Layer  4  loss:  0.0573962964117527 0.0 3.5530285835266113
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([346, 304, 187,  69], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 0.08081458508968353
bi 1 loss 0.06381396949291229
bi 2 loss 0.0477122962474823
bi 3 loss 0.02334497682750225
Layer  5  loss:  0.08186163753271103 0.0 5.0273756980896
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([349, 283, 185, 232], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.13975630700588226
bi 1 loss 0.056769438087940216
bi 2 loss 0.06057385727763176
bi 3 loss 0.037482861429452896
Layer  6  loss:  0.06344806402921677 0.0 3.502088785171509
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([444, 305, 186, 229], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 0.09785130620002747
bi 1 loss 0.05542641878128052
bi 2 loss 0.05630169436335564
bi 3 loss 0.02734953910112381
Epoch 0: :   3%|▎         | 15820/600000 [05:42<3:30:46, v_num=12, reduced_train_loss=0.817, global_step=15818.0, consumed_samples=63276.0, train_step_timing in s=0.391]Epoch 0: :   3%|▎         | 15820/600000 [05:42<3:30:46, v_num=12, reduced_train_loss=0.519, global_step=15819.0, consumed_samples=63280.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  0.11117225885391235 torch.Size([585, 4]) 11.828088760375977 0.0
Max loss timestep torch.Size([585, 4]) tensor([380, 325, 307, 431], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.10932106524705887
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
bi 1 loss 0.04477520287036896
speech mask sum tensor(284, device='cuda:0') loss mask sum tensor(284, device='cuda:0')
bi 2 loss 0.1543341428041458
speech mask sum tensor(488, device='cuda:0') loss mask sum tensor(488, device='cuda:0')
bi 3 loss 0.10263831168413162
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
logits torch.Size([585, 4, 257024]) labels torch.Size([585, 4]) 0 257023
Layer  0  loss:  0.14382636547088623 0.0 13.187536239624023
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([380, 320, 307, 430], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.1435784250497818
bi 1 loss 0.11775341629981995
bi 2 loss 0.1561979055404663
bi 3 loss 0.15192171931266785
Layer  1  loss:  0.12663015723228455 0.0 9.618060111999512
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([380, 278, 306, 436], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.11977144330739975
bi 1 loss 0.07735618203878403
bi 2 loss 0.1586797833442688
bi 3 loss 0.13127702474594116
Layer  2  loss:  0.12366679310798645 0.0 11.347234725952148
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([379, 351, 306, 288], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.12303625047206879
bi 1 loss 0.057373981922864914
bi 2 loss 0.16554787755012512
bi 3 loss 0.11598610132932663
Layer  3  loss:  0.15289655327796936 0.0 14.980165481567383
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([380, 351, 306, 435], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.12645216286182404
bi 1 loss 0.10089713335037231
bi 2 loss 0.21636396646499634
bi 3 loss 0.11605533957481384
Layer  4  loss:  0.14011169970035553 0.0 16.018686294555664
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([380, 350, 307, 329], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.1332942694425583
bi 1 loss 0.05673304945230484
bi 2 loss 0.19200044870376587
bi 3 loss 0.1446991115808487
Layer  5  loss:  0.15822535753250122 0.0 14.704231262207031
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([380, 261, 306, 436], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.16658054292201996
bi 1 loss 0.10644786059856415
bi 2 loss 0.19425635039806366
bi 3 loss 0.1254315972328186
Layer  6  loss:  0.14989207684993744 0.0 12.769999504089355
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([380, 323, 448, 431], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.157762348651886
bi 1 loss 0.060324106365442276
bi 2 loss 0.17463457584381104
bi 3 loss 0.20830276608467102
Epoch 0: :   3%|▎         | 15821/600000 [05:42<3:31:01, v_num=12, reduced_train_loss=0.519, global_step=15819.0, consumed_samples=63280.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15821/600000 [05:42<3:31:01, v_num=12, reduced_train_loss=1.110, global_step=15820.0, consumed_samples=63284.0, train_step_timing in s=0.400]loss mask original None

First layer loss:  3.9880189895629883 torch.Size([472, 4]) 11.656612396240234 0.0
Max loss timestep torch.Size([472, 4]) tensor([149, 211, 139, 198], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 3.8047702312469482
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
bi 1 loss 3.8400015830993652
speech mask sum tensor(342, device='cuda:0') loss mask sum tensor(342, device='cuda:0')
bi 2 loss 4.2310004234313965
speech mask sum tensor(390, device='cuda:0') loss mask sum tensor(390, device='cuda:0')
bi 3 loss 3.9321506023406982
speech mask sum tensor(180, device='cuda:0') loss mask sum tensor(180, device='cuda:0')
logits torch.Size([472, 4, 257024]) labels torch.Size([472, 4]) 0 257022
Layer  0  loss:  4.4229841232299805 0.0 11.034534454345703
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([101, 175, 203, 295], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 4.295211315155029
bi 1 loss 4.2144927978515625
bi 2 loss 4.6711320877075195
bi 3 loss 4.413496017456055
Layer  1  loss:  4.621562957763672 0.0 11.843254089355469
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([204, 396, 285, 179], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 4.42042875289917
bi 1 loss 4.3969340324401855
bi 2 loss 4.891518592834473
bi 3 loss 4.671292304992676
Layer  2  loss:  4.846523284912109 0.0 11.635558128356934
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([102, 263, 335, 341], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 4.588926792144775
bi 1 loss 4.579165458679199
bi 2 loss 5.17460298538208
bi 3 loss 4.909844398498535
Layer  3  loss:  5.096745491027832 0.0 10.27734661102295
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1021
Curr loss timestep torch.Size([472, 4]) tensor([184, 143, 180, 332], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 4.918216705322266
bi 1 loss 4.7265753746032715
bi 2 loss 5.413792133331299
bi 3 loss 5.297615051269531
Layer  4  loss:  5.143673419952393 0.0 12.085965156555176
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1019
Curr loss timestep torch.Size([472, 4]) tensor([221, 158, 163, 233], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.882997035980225
bi 1 loss 4.863336086273193
bi 2 loss 5.392548084259033
bi 3 loss 5.406449317932129
Layer  5  loss:  5.150272369384766 0.0 10.2536039352417
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1020
Curr loss timestep torch.Size([472, 4]) tensor([225, 138, 436, 238], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.966403007507324
bi 1 loss 4.858284950256348
bi 2 loss 5.442323207855225
bi 3 loss 5.262268543243408
Layer  6  loss:  5.219126224517822 0.0 10.58489990234375
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([ 93, 222, 112, 342], device='cuda:0') tensor(222, device='cuda:0')
bi 0 loss 4.94083309173584
bi 1 loss 4.743129730224609
bi 2 loss 5.569953918457031
bi 3 loss 5.650961875915527
Epoch 0: :   3%|▎         | 15822/600000 [05:43<3:31:13, v_num=12, reduced_train_loss=1.110, global_step=15820.0, consumed_samples=63284.0, train_step_timing in s=0.400]Epoch 0: :   3%|▎         | 15822/600000 [05:43<3:31:13, v_num=12, reduced_train_loss=38.50, global_step=15821.0, consumed_samples=63288.0, train_step_timing in s=0.321]loss mask original None

First layer loss:  0.07008326798677444 torch.Size([423, 4]) 6.617386817932129 0.0
Max loss timestep torch.Size([423, 4]) tensor([315, 243, 107, 313], device='cuda:0') tensor(243, device='cuda:0')
bi 0 loss 0.07070852071046829
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 1 loss 0.12499915063381195
speech mask sum tensor(132, device='cuda:0') loss mask sum tensor(132, device='cuda:0')
bi 2 loss 0.03388555347919464
speech mask sum tensor(108, device='cuda:0') loss mask sum tensor(108, device='cuda:0')
bi 3 loss 0.04785250127315521
speech mask sum tensor(157, device='cuda:0') loss mask sum tensor(157, device='cuda:0')
logits torch.Size([423, 4, 257024]) labels torch.Size([423, 4]) 0 257022
Layer  0  loss:  0.03488727658987045 0.0 1.219792127609253
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([315, 162, 134, 242], device='cuda:0') tensor(315, device='cuda:0')
bi 0 loss 0.04658247157931328
bi 1 loss 0.02527262642979622
bi 2 loss 0.02726164646446705
bi 3 loss 0.030264101922512054
Layer  1  loss:  0.05232010781764984 0.0 4.5142083168029785
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([359, 181, 154, 254], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.08861379325389862
bi 1 loss 0.03044966422021389
bi 2 loss 0.01693345047533512
bi 3 loss 0.03933844715356827
Layer  2  loss:  0.056803006678819656 0.0 3.0949697494506836
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([314, 255, 157, 342], device='cuda:0') tensor(157, device='cuda:0')
bi 0 loss 0.06375396251678467
bi 1 loss 0.027831828221678734
bi 2 loss 0.07362645119428635
bi 3 loss 0.058918192982673645
Layer  3  loss:  0.04071313887834549 0.0 3.2931723594665527
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1021
Curr loss timestep torch.Size([423, 4]) tensor([316, 165, 130, 251], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.06139238178730011
bi 1 loss 0.021104730665683746
bi 2 loss 0.024046357721090317
bi 3 loss 0.0369209349155426
Layer  4  loss:  0.05342815816402435 0.0 5.281410217285156
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([314, 159, 133, 225], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.08390365540981293
bi 1 loss 0.038932569324970245
bi 2 loss 0.033413298428058624
bi 3 loss 0.03260284289717674
Layer  5  loss:  0.056176356971263885 0.0 6.7026214599609375
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([314, 268, 136, 323], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.08256247639656067
bi 1 loss 0.028091946616768837
bi 2 loss 0.045280735939741135
bi 3 loss 0.046780265867710114
Layer  6  loss:  0.048753563314676285 0.0 5.236772060394287
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1019
Curr loss timestep torch.Size([423, 4]) tensor([316, 152, 169, 242], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.07036392390727997
bi 1 loss 0.029450902715325356
bi 2 loss 0.027711203321814537
bi 3 loss 0.04628494754433632
Epoch 0: :   3%|▎         | 15823/600000 [05:43<3:31:25, v_num=12, reduced_train_loss=38.50, global_step=15821.0, consumed_samples=63288.0, train_step_timing in s=0.321]Epoch 0: :   3%|▎         | 15823/600000 [05:43<3:31:25, v_num=12, reduced_train_loss=0.413, global_step=15822.0, consumed_samples=63292.0, train_step_timing in s=0.310]loss mask original None

First layer loss:  0.0929817333817482 torch.Size([450, 4]) 15.281501770019531 0.0
Max loss timestep torch.Size([450, 4]) tensor([197, 197, 116, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.01525136735290289
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 1 loss 0.04822133481502533
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 2 loss 0.04259977862238884
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 3 loss 0.17917360365390778
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
logits torch.Size([450, 4, 257024]) labels torch.Size([450, 4]) 0 257022
Layer  0  loss:  0.09222856163978577 0.0 9.812820434570312
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([164, 200, 374, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.013321062549948692
bi 1 loss 0.03086627833545208
bi 2 loss 0.041588954627513885
bi 3 loss 0.1835755854845047
Layer  1  loss:  0.09236802160739899 0.0 14.070575714111328
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([169, 217, 374, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.024702880531549454
bi 1 loss 0.032192662358284
bi 2 loss 0.051410771906375885
bi 3 loss 0.17026036977767944
Layer  2  loss:  0.09556838124990463 0.0 12.343905448913574
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1022
Curr loss timestep torch.Size([450, 4]) tensor([180, 190, 111, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.026603102684020996
bi 1 loss 0.0716233029961586
bi 2 loss 0.027678705751895905
bi 3 loss 0.19131433963775635
Layer  3  loss:  0.11724581569433212 0.0 19.026391983032227
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1023
Curr loss timestep torch.Size([450, 4]) tensor([179, 206, 374, 275], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.024478156119585037
bi 1 loss 0.024810602888464928
bi 2 loss 0.05852929502725601
bi 3 loss 0.22936749458312988
Layer  4  loss:  0.10516688227653503 0.0 12.554381370544434
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1022
Curr loss timestep torch.Size([450, 4]) tensor([169, 197, 375, 274], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 0.04860512912273407
bi 1 loss 0.03819507732987404
bi 2 loss 0.0374174565076828
bi 3 loss 0.20894549787044525
Layer  5  loss:  0.12380032241344452 0.0 16.601900100708008
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1022
Curr loss timestep torch.Size([450, 4]) tensor([179, 230, 370, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.02109367586672306
bi 1 loss 0.06786400079727173
bi 2 loss 0.04611048102378845
bi 3 loss 0.24812230467796326
Layer  6  loss:  0.12369559705257416 0.0 15.799724578857422
logits torch.Size([450, 4, 1024]) labels torch.Size([450, 4]) 0 1020
Curr loss timestep torch.Size([450, 4]) tensor([186, 210, 374, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.015624811872839928
bi 1 loss 0.028906207531690598
bi 2 loss 0.046983931213617325
bi 3 loss 0.2592339813709259
Epoch 0: :   3%|▎         | 15824/600000 [05:43<3:31:38, v_num=12, reduced_train_loss=0.413, global_step=15822.0, consumed_samples=63292.0, train_step_timing in s=0.310]Epoch 0: :   3%|▎         | 15824/600000 [05:43<3:31:38, v_num=12, reduced_train_loss=0.843, global_step=15823.0, consumed_samples=63296.0, train_step_timing in s=0.323]loss mask original None

First layer loss:  0.15786632895469666 torch.Size([662, 4]) 8.379899024963379 0.0
Max loss timestep torch.Size([662, 4]) tensor([309, 600, 276, 338], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.11645735055208206
speech mask sum tensor(269, device='cuda:0') loss mask sum tensor(269, device='cuda:0')
bi 1 loss 0.1736403852701187
speech mask sum tensor(487, device='cuda:0') loss mask sum tensor(487, device='cuda:0')
bi 2 loss 0.23513862490653992
speech mask sum tensor(95, device='cuda:0') loss mask sum tensor(95, device='cuda:0')
bi 3 loss 0.14105325937271118
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
logits torch.Size([662, 4, 257024]) labels torch.Size([662, 4]) 0 257023
Layer  0  loss:  0.1843538135290146 0.0 13.208675384521484
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1023
Curr loss timestep torch.Size([662, 4]) tensor([309, 525, 278, 339], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.14541897177696228
bi 1 loss 0.22579237818717957
bi 2 loss 0.15915443003177643
bi 3 loss 0.15269498527050018
Layer  1  loss:  0.2219005525112152 0.0 13.930366516113281
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1023
Curr loss timestep torch.Size([662, 4]) tensor([309, 600, 276, 340], device='cuda:0') tensor(600, device='cuda:0')
bi 0 loss 0.13048449158668518
bi 1 loss 0.3126903772354126
bi 2 loss 0.19091373682022095
bi 3 loss 0.14969287812709808
Layer  2  loss:  0.1934889256954193 0.0 20.31443977355957
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1023
Curr loss timestep torch.Size([662, 4]) tensor([309, 599, 282, 339], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.11281571537256241
bi 1 loss 0.22537513077259064
bi 2 loss 0.09662605077028275
bi 3 loss 0.2600451409816742
Layer  3  loss:  0.20053930580615997 0.0 13.12782096862793
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1022
Curr loss timestep torch.Size([662, 4]) tensor([309, 599, 283, 339], device='cuda:0') tensor(599, device='cuda:0')
bi 0 loss 0.14661473035812378
bi 1 loss 0.24106840789318085
bi 2 loss 0.2931685149669647
bi 3 loss 0.13979583978652954
Layer  4  loss:  0.23543918132781982 0.0 14.892760276794434
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1022
Curr loss timestep torch.Size([662, 4]) tensor([309, 599, 275, 338], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.14490237832069397
bi 1 loss 0.30376747250556946
bi 2 loss 0.2070143073797226
bi 3 loss 0.20850791037082672
Layer  5  loss:  0.2508443593978882 0.0 16.37739372253418
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1022
Curr loss timestep torch.Size([662, 4]) tensor([309, 599, 283, 338], device='cuda:0') tensor(599, device='cuda:0')
bi 0 loss 0.12780515849590302
bi 1 loss 0.3353957533836365
bi 2 loss 0.2721259295940399
bi 3 loss 0.20711833238601685
Layer  6  loss:  0.2540208399295807 0.0 16.86403465270996
logits torch.Size([662, 4, 1024]) labels torch.Size([662, 4]) 0 1023
Curr loss timestep torch.Size([662, 4]) tensor([307, 291, 283, 338], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 0.12095259130001068
bi 1 loss 0.3266311287879944
bi 2 loss 0.26137575507164
bi 3 loss 0.25287556648254395
Epoch 0: :   3%|▎         | 15825/600000 [05:44<3:31:55, v_num=12, reduced_train_loss=0.843, global_step=15823.0, consumed_samples=63296.0, train_step_timing in s=0.323]Epoch 0: :   3%|▎         | 15825/600000 [05:44<3:31:55, v_num=12, reduced_train_loss=1.700, global_step=15824.0, consumed_samples=63300.0, train_step_timing in s=0.452]loss mask original None

First layer loss:  0.035109784454107285 torch.Size([437, 4]) 4.637176036834717 0.0
Max loss timestep torch.Size([437, 4]) tensor([312, 172, 212, 324], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.059719525277614594
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
bi 1 loss 0.012570381164550781
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 2 loss 0.01991896703839302
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 3 loss 0.03115793503820896
speech mask sum tensor(272, device='cuda:0') loss mask sum tensor(272, device='cuda:0')
logits torch.Size([437, 4, 257024]) labels torch.Size([437, 4]) 0 257022
Layer  0  loss:  0.03665434196591377 0.0 3.7970216274261475
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([312, 214, 223, 410], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.051694221794605255
bi 1 loss 0.01702537015080452
bi 2 loss 0.02298208698630333
bi 3 loss 0.03789188712835312
Layer  1  loss:  0.029629405587911606 0.0 1.2337615489959717
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([312, 201, 272, 367], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.03872717544436455
bi 1 loss 0.02046358212828636
bi 2 loss 0.018789950758218765
bi 3 loss 0.030666673555970192
Layer  2  loss:  0.029330594465136528 0.0 0.8732818961143494
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([312, 190, 266, 304], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.037983354181051254
bi 1 loss 0.015828844159841537
bi 2 loss 0.025571824982762337
bi 3 loss 0.02894178219139576
Layer  3  loss:  0.03480719029903412 0.0 1.486281394958496
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([312, 178, 225, 366], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.05110636353492737
bi 1 loss 0.01349024660885334
bi 2 loss 0.022589601576328278
bi 3 loss 0.03504360467195511
Layer  4  loss:  0.03528447821736336 0.0 2.752077579498291
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1020
Curr loss timestep torch.Size([437, 4]) tensor([312, 188, 270, 264], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.049704115837812424
bi 1 loss 0.016841355711221695
bi 2 loss 0.022548208013176918
bi 3 loss 0.03619745373725891
Layer  5  loss:  0.035921234637498856 0.0 5.199880123138428
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([312, 185, 272, 191], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.06020813435316086
bi 1 loss 0.01206754706799984
bi 2 loss 0.022345062345266342
bi 3 loss 0.03189776837825775
Layer  6  loss:  0.033870089799165726 0.0 2.603858232498169
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1021
Curr loss timestep torch.Size([437, 4]) tensor([312, 191, 243, 309], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.04164339229464531
bi 1 loss 0.008542456664144993
bi 2 loss 0.029778264462947845
bi 3 loss 0.03780725225806236
Epoch 0: :   3%|▎         | 15826/600000 [05:44<3:32:07, v_num=12, reduced_train_loss=1.700, global_step=15824.0, consumed_samples=63300.0, train_step_timing in s=0.452]Epoch 0: :   3%|▎         | 15826/600000 [05:44<3:32:07, v_num=12, reduced_train_loss=0.271, global_step=15825.0, consumed_samples=63304.0, train_step_timing in s=0.317]loss mask original None

First layer loss:  3.684502363204956 torch.Size([508, 4]) 11.27690315246582 0.0
Max loss timestep torch.Size([508, 4]) tensor([ 95,  83, 170, 444], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 3.89331316947937
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 1 loss 4.075433254241943
speech mask sum tensor(107, device='cuda:0') loss mask sum tensor(107, device='cuda:0')
bi 2 loss 3.6593947410583496
speech mask sum tensor(99, device='cuda:0') loss mask sum tensor(99, device='cuda:0')
bi 3 loss 3.4818289279937744
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
logits torch.Size([508, 4, 257024]) labels torch.Size([508, 4]) 0 257022
Layer  0  loss:  4.116262435913086 0.0 10.59432601928711
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([145,  57, 164, 335], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 4.17461633682251
bi 1 loss 4.197392463684082
bi 2 loss 4.232222557067871
bi 3 loss 4.036359786987305
Layer  1  loss:  4.554203033447266 0.0 10.616717338562012
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([144,  69, 145, 317], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 4.60062313079834
bi 1 loss 4.38665246963501
bi 2 loss 4.45596981048584
bi 3 loss 4.601532936096191
Layer  2  loss:  4.726688861846924 0.0 10.449626922607422
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([ 80, 102, 163, 439], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 4.8004608154296875
bi 1 loss 4.512197971343994
bi 2 loss 4.884555816650391
bi 3 loss 4.708947658538818
Layer  3  loss:  4.801641464233398 0.0 9.575963020324707
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1021
Curr loss timestep torch.Size([508, 4]) tensor([191, 123, 155, 418], device='cuda:0') tensor(123, device='cuda:0')
bi 0 loss 4.905053615570068
bi 1 loss 4.465497016906738
bi 2 loss 4.7078142166137695
bi 3 loss 4.865585803985596
Layer  4  loss:  5.036081790924072 0.0 10.897369384765625
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([138,  84, 144, 425], device='cuda:0') tensor(138, device='cuda:0')
bi 0 loss 4.993969440460205
bi 1 loss 4.748073577880859
bi 2 loss 5.218045711517334
bi 3 loss 5.089310646057129
Layer  5  loss:  5.124363899230957 0.0 10.528054237365723
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([220, 102, 175, 281], device='cuda:0') tensor(129, device='cuda:0')
bi 0 loss 5.120876312255859
bi 1 loss 4.878349304199219
bi 2 loss 5.14361047744751
bi 3 loss 5.188055992126465
Layer  6  loss:  5.119900226593018 0.0 10.345514297485352
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([101,  61, 143, 160], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 5.128621578216553
bi 1 loss 4.855044364929199
bi 2 loss 5.357975006103516
bi 3 loss 5.127713203430176
Epoch 0: :   3%|▎         | 15827/600000 [05:45<3:32:20, v_num=12, reduced_train_loss=0.271, global_step=15825.0, consumed_samples=63304.0, train_step_timing in s=0.317]Epoch 0: :   3%|▎         | 15827/600000 [05:45<3:32:20, v_num=12, reduced_train_loss=37.20, global_step=15826.0, consumed_samples=63308.0, train_step_timing in s=0.334]loss mask original None

First layer loss:  0.016073722392320633 torch.Size([387, 4]) 0.18729810416698456 0.0
Max loss timestep torch.Size([387, 4]) tensor([332,  54, 344,  84], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.015231424011290073
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 1 loss 0.016490930691361427
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
bi 2 loss 0.02029712311923504
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 3 loss 0.012223624624311924
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
logits torch.Size([387, 4, 257024]) labels torch.Size([387, 4]) 0 257023
Layer  0  loss:  0.01709914393723011 0.0 0.3849600553512573
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1023
Curr loss timestep torch.Size([387, 4]) tensor([330, 111, 294, 155], device='cuda:0') tensor(111, device='cuda:0')
bi 0 loss 0.01427285186946392
bi 1 loss 0.01914754882454872
bi 2 loss 0.02011413499712944
bi 3 loss 0.015152795240283012
Layer  1  loss:  0.017311973497271538 0.0 0.5469799637794495
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1022
Curr loss timestep torch.Size([387, 4]) tensor([344,  55, 313, 143], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.023270606994628906
bi 1 loss 0.010553882457315922
bi 2 loss 0.01664048805832863
bi 3 loss 0.017102789133787155
Layer  2  loss:  0.01706928201019764 0.0 0.6085134744644165
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1022
Curr loss timestep torch.Size([387, 4]) tensor([344,  57, 364, 192], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.01893601566553116
bi 1 loss 0.017086073756217957
bi 2 loss 0.01880676858127117
bi 3 loss 0.013725645840168
Layer  3  loss:  0.01556503213942051 0.0 0.24083472788333893
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1021
Curr loss timestep torch.Size([387, 4]) tensor([273,  66, 283, 161], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 0.016979539766907692
bi 1 loss 0.01445150375366211
bi 2 loss 0.01756936125457287
bi 3 loss 0.013013551943004131
Layer  4  loss:  0.020469339564442635 0.0 1.2047501802444458
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1022
Curr loss timestep torch.Size([387, 4]) tensor([344,  82, 313,  90], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.024070322513580322
bi 1 loss 0.017043396830558777
bi 2 loss 0.024425465613603592
bi 3 loss 0.015500187873840332
Layer  5  loss:  0.016901256516575813 0.0 0.3275738060474396
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1022
Curr loss timestep torch.Size([387, 4]) tensor([343,  66, 280, 116], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.019635263830423355
bi 1 loss 0.01587693952023983
bi 2 loss 0.018048718571662903
bi 3 loss 0.014063539914786816
Layer  6  loss:  0.019151803106069565 0.0 0.2654998302459717
logits torch.Size([387, 4, 1024]) labels torch.Size([387, 4]) 0 1022
Curr loss timestep torch.Size([387, 4]) tensor([254,  66, 237, 191], device='cuda:0') tensor(237, device='cuda:0')
bi 0 loss 0.018532589077949524
bi 1 loss 0.0212490763515234
bi 2 loss 0.018113382160663605
bi 3 loss 0.019456814974546432
Epoch 0: :   3%|▎         | 15828/600000 [05:45<3:32:31, v_num=12, reduced_train_loss=37.20, global_step=15826.0, consumed_samples=63308.0, train_step_timing in s=0.334]Epoch 0: :   3%|▎         | 15828/600000 [05:45<3:32:31, v_num=12, reduced_train_loss=0.140, global_step=15827.0, consumed_samples=63312.0, train_step_timing in s=0.295]loss mask original None

First layer loss:  3.631842613220215 torch.Size([612, 4]) 10.852701187133789 0.0
Max loss timestep torch.Size([612, 4]) tensor([173, 197, 396, 164], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 3.693281888961792
speech mask sum tensor(457, device='cuda:0') loss mask sum tensor(457, device='cuda:0')
bi 1 loss 2.8688576221466064
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 2 loss 3.808462381362915
speech mask sum tensor(473, device='cuda:0') loss mask sum tensor(473, device='cuda:0')
bi 3 loss 3.4733362197875977
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
logits torch.Size([612, 4, 257024]) labels torch.Size([612, 4]) 0 257023
Layer  0  loss:  4.139969825744629 0.0 11.064088821411133
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1023
Curr loss timestep torch.Size([612, 4]) tensor([434, 190, 296, 254], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 4.330483436584473
bi 1 loss 3.9976279735565186
bi 2 loss 3.966158151626587
bi 3 loss 4.223671913146973
Layer  1  loss:  4.582921028137207 0.0 11.252927780151367
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1022
Curr loss timestep torch.Size([612, 4]) tensor([417, 227, 236, 163], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 4.7746148109436035
bi 1 loss 4.594925880432129
bi 2 loss 4.399076461791992
bi 3 loss 4.5683794021606445
Layer  2  loss:  4.690682411193848 0.0 10.281826972961426
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1022
Curr loss timestep torch.Size([612, 4]) tensor([554, 238, 558, 187], device='cuda:0') tensor(165, device='cuda:0')
bi 0 loss 4.8789896965026855
bi 1 loss 4.309147834777832
bi 2 loss 4.582156181335449
bi 3 loss 4.761011123657227
Layer  3  loss:  4.861936569213867 0.0 9.958905220031738
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1023
Curr loss timestep torch.Size([612, 4]) tensor([171, 194, 181, 191], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 5.065229415893555
bi 1 loss 4.545653343200684
bi 2 loss 4.655146598815918
bi 3 loss 5.159183979034424
Layer  4  loss:  5.040441989898682 0.0 10.629034042358398
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1022
Curr loss timestep torch.Size([612, 4]) tensor([451, 224, 212, 246], device='cuda:0') tensor(203, device='cuda:0')
bi 0 loss 5.135130405426025
bi 1 loss 4.894081115722656
bi 2 loss 5.014036178588867
bi 3 loss 4.943574905395508
Layer  5  loss:  5.063210487365723 0.0 10.0432710647583
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1021
Curr loss timestep torch.Size([612, 4]) tensor([576, 248, 269, 275], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 5.130947113037109
bi 1 loss 5.20094633102417
bi 2 loss 4.952229976654053
bi 3 loss 5.101673126220703
Layer  6  loss:  5.1586432456970215 0.0 10.006736755371094
logits torch.Size([612, 4, 1024]) labels torch.Size([612, 4]) 0 1022
Curr loss timestep torch.Size([612, 4]) tensor([553, 251, 202, 194], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 5.145147800445557
bi 1 loss 5.019228458404541
bi 2 loss 5.148148536682129
bi 3 loss 5.353275299072266
Epoch 0: :   3%|▎         | 15829/600000 [05:45<3:32:46, v_num=12, reduced_train_loss=0.140, global_step=15827.0, consumed_samples=63312.0, train_step_timing in s=0.295]Epoch 0: :   3%|▎         | 15829/600000 [05:45<3:32:46, v_num=12, reduced_train_loss=37.20, global_step=15828.0, consumed_samples=63316.0, train_step_timing in s=0.382]loss mask original None

First layer loss:  0.07253608852624893 torch.Size([681, 4]) 11.599932670593262 0.0
Max loss timestep torch.Size([681, 4]) tensor([583, 262, 210, 276], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.14944475889205933
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 1 loss 0.02777959033846855
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 2 loss 0.036398887634277344
speech mask sum tensor(149, device='cuda:0') loss mask sum tensor(149, device='cuda:0')
bi 3 loss 0.0407763235270977
speech mask sum tensor(227, device='cuda:0') loss mask sum tensor(227, device='cuda:0')
logits torch.Size([681, 4, 257024]) labels torch.Size([681, 4]) 0 257022
Layer  0  loss:  0.08859064429998398 0.0 10.91166877746582
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1023
Curr loss timestep torch.Size([681, 4]) tensor([630, 207, 136, 131], device='cuda:0') tensor(630, device='cuda:0')
bi 0 loss 0.2127918004989624
bi 1 loss 0.034591786563396454
bi 2 loss 0.03164368122816086
bi 3 loss 0.01696806773543358
Layer  1  loss:  0.1228395625948906 0.0 12.049653053283691
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1023
Curr loss timestep torch.Size([681, 4]) tensor([583, 262, 217, 233], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.2589065432548523
bi 1 loss 0.06434987485408783
bi 2 loss 0.0656147301197052
bi 3 loss 0.040276337414979935
Layer  2  loss:  0.11554858833551407 0.0 10.714481353759766
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1022
Curr loss timestep torch.Size([681, 4]) tensor([557, 278, 183, 125], device='cuda:0') tensor(557, device='cuda:0')
bi 0 loss 0.24661163985729218
bi 1 loss 0.07161985337734222
bi 2 loss 0.0410870723426342
bi 3 loss 0.03554163873195648
Layer  3  loss:  0.11386523395776749 0.0 13.28925895690918
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1021
Curr loss timestep torch.Size([681, 4]) tensor([583, 177, 159, 276], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.26255908608436584
bi 1 loss 0.053042057901620865
bi 2 loss 0.04373451694846153
bi 3 loss 0.025340715423226357
Layer  4  loss:  0.10559838265180588 0.0 15.654065132141113
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1023
Curr loss timestep torch.Size([681, 4]) tensor([557, 124, 127, 274], device='cuda:0') tensor(557, device='cuda:0')
bi 0 loss 0.23979264497756958
bi 1 loss 0.036893997341394424
bi 2 loss 0.02801789529621601
bi 3 loss 0.04974903166294098
Layer  5  loss:  0.11607826501131058 0.0 12.703594207763672
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1023
Curr loss timestep torch.Size([681, 4]) tensor([630, 113, 139, 274], device='cuda:0') tensor(630, device='cuda:0')
bi 0 loss 0.26162463426589966
bi 1 loss 0.04198940843343735
bi 2 loss 0.0345890074968338
bi 3 loss 0.05330832675099373
Layer  6  loss:  0.11709826439619064 0.0 12.057236671447754
logits torch.Size([681, 4, 1024]) labels torch.Size([681, 4]) 0 1020
Curr loss timestep torch.Size([681, 4]) tensor([583, 232, 214, 274], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.24895961582660675
bi 1 loss 0.049441274255514145
bi 2 loss 0.06406690925359726
bi 3 loss 0.047147441655397415
Epoch 0: :   3%|▎         | 15830/600000 [05:46<3:33:04, v_num=12, reduced_train_loss=37.20, global_step=15828.0, consumed_samples=63316.0, train_step_timing in s=0.382]Epoch 0: :   3%|▎         | 15830/600000 [05:46<3:33:04, v_num=12, reduced_train_loss=0.852, global_step=15829.0, consumed_samples=63320.0, train_step_timing in s=0.465]loss mask original None

First layer loss:  0.15529289841651917 torch.Size([683, 4]) 17.29741668701172 0.0
Max loss timestep torch.Size([683, 4]) tensor([399, 171, 276, 605], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.08358864486217499
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
bi 1 loss 0.13055293262004852
speech mask sum tensor(90, device='cuda:0') loss mask sum tensor(90, device='cuda:0')
bi 2 loss 0.0334198996424675
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 3 loss 0.26981911063194275
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
logits torch.Size([683, 4, 257024]) labels torch.Size([683, 4]) 0 257023
Layer  0  loss:  0.16161498427391052 0.0 10.649843215942383
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([358, 190, 255, 621], device='cuda:0') tensor(621, device='cuda:0')
bi 0 loss 0.10953346639871597
bi 1 loss 0.05038631334900856
bi 2 loss 0.05157987400889397
bi 3 loss 0.2733854353427887
Layer  1  loss:  0.1680031716823578 0.0 14.428587913513184
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([358, 195, 233, 604], device='cuda:0') tensor(604, device='cuda:0')
bi 0 loss 0.14338523149490356
bi 1 loss 0.032326698303222656
bi 2 loss 0.05017726868391037
bi 3 loss 0.2699725031852722
Layer  2  loss:  0.1755221039056778 0.0 12.529325485229492
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([406, 150, 276, 589], device='cuda:0') tensor(589, device='cuda:0')
bi 0 loss 0.0947757437825203
bi 1 loss 0.02133326604962349
bi 2 loss 0.06517703086137772
bi 3 loss 0.31478002667427063
Layer  3  loss:  0.19466237723827362 0.0 15.271438598632812
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([407, 167, 294, 604], device='cuda:0') tensor(604, device='cuda:0')
bi 0 loss 0.13656960427761078
bi 1 loss 0.04657094180583954
bi 2 loss 0.05228620022535324
bi 3 loss 0.33385053277015686
Layer  4  loss:  0.17878399789333344 0.0 16.146228790283203
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1023
Curr loss timestep torch.Size([683, 4]) tensor([407, 159, 261, 605], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.1190195381641388
bi 1 loss 0.028740668669342995
bi 2 loss 0.04352041706442833
bi 3 loss 0.31585246324539185
Layer  5  loss:  0.19028116762638092 0.0 12.656094551086426
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1021
Curr loss timestep torch.Size([683, 4]) tensor([358, 189, 130, 604], device='cuda:0') tensor(604, device='cuda:0')
bi 0 loss 0.11963869631290436
bi 1 loss 0.035857558250427246
bi 2 loss 0.03601384535431862
bi 3 loss 0.34510400891304016
Layer  6  loss:  0.19487974047660828 0.0 14.191044807434082
logits torch.Size([683, 4, 1024]) labels torch.Size([683, 4]) 0 1022
Curr loss timestep torch.Size([683, 4]) tensor([358, 148, 303, 487], device='cuda:0') tensor(487, device='cuda:0')
bi 0 loss 0.12822329998016357
bi 1 loss 0.022952888160943985
bi 2 loss 0.0449986606836319
bi 3 loss 0.34812501072883606
Epoch 0: :   3%|▎         | 15831/600000 [05:46<3:33:22, v_num=12, reduced_train_loss=0.852, global_step=15829.0, consumed_samples=63320.0, train_step_timing in s=0.465]Epoch 0: :   3%|▎         | 15831/600000 [05:46<3:33:22, v_num=12, reduced_train_loss=1.420, global_step=15830.0, consumed_samples=63324.0, train_step_timing in s=0.466]loss mask original None

First layer loss:  0.1544058471918106 torch.Size([685, 4]) 9.221841812133789 0.0
Max loss timestep torch.Size([685, 4]) tensor([ 98, 299, 350, 305], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.04026545211672783
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 1 loss 0.12068890035152435
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 2 loss 0.1931304782629013
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
bi 3 loss 0.18223151564598083
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
logits torch.Size([685, 4, 257024]) labels torch.Size([685, 4]) 0 257022
Layer  0  loss:  0.1604025959968567 0.0 12.907139778137207
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([ 99, 299, 283, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.05673692002892494
bi 1 loss 0.121405228972435
bi 2 loss 0.09484301507472992
bi 3 loss 0.2402247190475464
Layer  1  loss:  0.18956315517425537 0.0 12.740449905395508
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1022
Curr loss timestep torch.Size([685, 4]) tensor([ 64, 299, 359, 550], device='cuda:0') tensor(550, device='cuda:0')
bi 0 loss 0.02855340577661991
bi 1 loss 0.12392441928386688
bi 2 loss 0.09425000101327896
bi 3 loss 0.313532292842865
Layer  2  loss:  0.17109940946102142 0.0 12.750741004943848
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([ 85, 299, 360, 304], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.03859998658299446
bi 1 loss 0.10789358615875244
bi 2 loss 0.11645978689193726
bi 3 loss 0.2672341763973236
Layer  3  loss:  0.18093985319137573 0.0 16.328723907470703
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([113, 299, 296, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.08070948719978333
bi 1 loss 0.14299215376377106
bi 2 loss 0.09212657064199448
bi 3 loss 0.2707127332687378
Layer  4  loss:  0.2086879163980484 0.0 11.982003211975098
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([ 43, 300, 336, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.05448625236749649
bi 1 loss 0.16324320435523987
bi 2 loss 0.08569733798503876
bi 3 loss 0.33200961351394653
Layer  5  loss:  0.20387405157089233 0.0 11.86683177947998
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([ 69, 299, 350, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.037968870252370834
bi 1 loss 0.12572932243347168
bi 2 loss 0.1034838855266571
bi 3 loss 0.33927005529403687
Layer  6  loss:  0.21895276010036469 0.0 12.635238647460938
logits torch.Size([685, 4, 1024]) labels torch.Size([685, 4]) 0 1023
Curr loss timestep torch.Size([685, 4]) tensor([ 86, 299, 296, 304], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.1000693142414093
bi 1 loss 0.11528290808200836
bi 2 loss 0.11672799289226532
bi 3 loss 0.36069396138191223
Epoch 0: :   3%|▎         | 15832/600000 [05:47<3:33:39, v_num=12, reduced_train_loss=1.420, global_step=15830.0, consumed_samples=63324.0, train_step_timing in s=0.466]Epoch 0: :   3%|▎         | 15832/600000 [05:47<3:33:39, v_num=12, reduced_train_loss=1.490, global_step=15831.0, consumed_samples=63328.0, train_step_timing in s=0.464]loss mask original None

First layer loss:  0.07271073013544083 torch.Size([381, 4]) 8.293928146362305 0.0
Max loss timestep torch.Size([381, 4]) tensor([ 45, 267, 181, 266], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.05474334582686424
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 1 loss 0.09982160478830338
speech mask sum tensor(252, device='cuda:0') loss mask sum tensor(252, device='cuda:0')
bi 2 loss 0.10402272641658783
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
bi 3 loss 0.051971517503261566
speech mask sum tensor(188, device='cuda:0') loss mask sum tensor(188, device='cuda:0')
logits torch.Size([381, 4, 257024]) labels torch.Size([381, 4]) 0 257022
Layer  0  loss:  0.05879667028784752 0.0 5.553091049194336
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1023
Curr loss timestep torch.Size([381, 4]) tensor([ 51, 267, 189, 185], device='cuda:0') tensor(51, device='cuda:0')
bi 0 loss 0.0631067305803299
bi 1 loss 0.0625646710395813
bi 2 loss 0.02631164714694023
bi 3 loss 0.05890381708741188
Layer  1  loss:  0.06045020371675491 0.0 9.157732009887695
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1022
Curr loss timestep torch.Size([381, 4]) tensor([111, 267, 176, 266], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.050727952271699905
bi 1 loss 0.09013677388429642
bi 2 loss 0.03998043015599251
bi 3 loss 0.04243258386850357
Layer  2  loss:  0.05139430612325668 0.0 1.6165663003921509
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1023
Curr loss timestep torch.Size([381, 4]) tensor([306, 284, 192, 267], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.04223799332976341
bi 1 loss 0.05987017601728439
bi 2 loss 0.05636357516050339
bi 3 loss 0.051899123936891556
Layer  3  loss:  0.0655328705906868 0.0 11.429500579833984
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1023
Curr loss timestep torch.Size([381, 4]) tensor([239, 267, 195, 269], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.03944433107972145
bi 1 loss 0.10392128676176071
bi 2 loss 0.044178545475006104
bi 3 loss 0.06054162606596947
Layer  4  loss:  0.06769668310880661 0.0 8.725592613220215
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1023
Curr loss timestep torch.Size([381, 4]) tensor([244, 267, 180, 300], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.03791361302137375
bi 1 loss 0.10127576440572739
bi 2 loss 0.04214148595929146
bi 3 loss 0.07615163177251816
Layer  5  loss:  0.05715937539935112 0.0 6.078192234039307
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1019
Curr loss timestep torch.Size([381, 4]) tensor([ 56, 267, 189, 269], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.05047692731022835
bi 1 loss 0.06937681883573532
bi 2 loss 0.030240051448345184
bi 3 loss 0.060329001396894455
Layer  6  loss:  0.06424633413553238 0.0 7.766332149505615
logits torch.Size([381, 4, 1024]) labels torch.Size([381, 4]) 0 1023
Curr loss timestep torch.Size([381, 4]) tensor([308, 267, 197, 219], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.04797539860010147
bi 1 loss 0.10790359228849411
bi 2 loss 0.04668556898832321
bi 3 loss 0.03621869906783104
Epoch 0: :   3%|▎         | 15833/600000 [05:47<3:33:50, v_num=12, reduced_train_loss=1.490, global_step=15831.0, consumed_samples=63328.0, train_step_timing in s=0.464]Epoch 0: :   3%|▎         | 15833/600000 [05:47<3:33:50, v_num=12, reduced_train_loss=0.498, global_step=15832.0, consumed_samples=63332.0, train_step_timing in s=0.288]loss mask original None

First layer loss:  2.8792531490325928 torch.Size([540, 4]) 10.2645263671875 0.0
Max loss timestep torch.Size([540, 4]) tensor([ 64, 439, 132, 352], device='cuda:0') tensor(64, device='cuda:0')
bi 0 loss 3.450805902481079
speech mask sum tensor(60, device='cuda:0') loss mask sum tensor(60, device='cuda:0')
bi 1 loss 2.630293130874634
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 2 loss 3.1706321239471436
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 3 loss 2.7712631225585938
speech mask sum tensor(138, device='cuda:0') loss mask sum tensor(138, device='cuda:0')
logits torch.Size([540, 4, 257024]) labels torch.Size([540, 4]) 0 257022
Layer  0  loss:  3.394547700881958 0.0 9.931011199951172
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 67, 392, 113, 359], device='cuda:0') tensor(71, device='cuda:0')
bi 0 loss 3.8573882579803467
bi 1 loss 2.9594218730926514
bi 2 loss 3.940192937850952
bi 3 loss 3.395397186279297
Layer  1  loss:  3.670349359512329 0.0 10.17149829864502
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1021
Curr loss timestep torch.Size([540, 4]) tensor([ 62, 422, 152, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 3.57362961769104
bi 1 loss 3.2549259662628174
bi 2 loss 4.218810081481934
bi 3 loss 3.8724286556243896
Layer  2  loss:  4.092938423156738 0.0 9.364734649658203
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1022
Curr loss timestep torch.Size([540, 4]) tensor([ 53, 525, 164, 416], device='cuda:0') tensor(62, device='cuda:0')
bi 0 loss 3.950143337249756
bi 1 loss 3.8398568630218506
bi 2 loss 4.436892032623291
bi 3 loss 4.240767955780029
Layer  3  loss:  4.177151203155518 0.0 8.842700004577637
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 52, 524, 173, 320], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 4.03981876373291
bi 1 loss 3.6031954288482666
bi 2 loss 4.67650842666626
bi 3 loss 4.766918182373047
Layer  4  loss:  4.275259017944336 0.0 9.732661247253418
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 45, 343,  68, 427], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 4.174073696136475
bi 1 loss 3.827687978744507
bi 2 loss 4.611058235168457
bi 3 loss 4.796677589416504
Layer  5  loss:  4.33664083480835 0.0 9.214465141296387
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1023
Curr loss timestep torch.Size([540, 4]) tensor([ 80, 493, 177, 376], device='cuda:0') tensor(80, device='cuda:0')
bi 0 loss 4.242194652557373
bi 1 loss 3.732901096343994
bi 2 loss 4.768759727478027
bi 3 loss 5.0466437339782715
Layer  6  loss:  4.394768714904785 0.0 9.149909973144531
logits torch.Size([540, 4, 1024]) labels torch.Size([540, 4]) 0 1021
Curr loss timestep torch.Size([540, 4]) tensor([ 71, 291, 107, 309], device='cuda:0') tensor(81, device='cuda:0')
bi 0 loss 4.254635334014893
bi 1 loss 3.8785459995269775
bi 2 loss 4.903791427612305
bi 3 loss 4.8608245849609375
Epoch 0: :   3%|▎         | 15834/600000 [05:48<3:34:04, v_num=12, reduced_train_loss=0.498, global_step=15832.0, consumed_samples=63332.0, train_step_timing in s=0.288]Epoch 0: :   3%|▎         | 15834/600000 [05:48<3:34:04, v_num=12, reduced_train_loss=31.20, global_step=15833.0, consumed_samples=63336.0, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.19422192871570587 torch.Size([777, 4]) 11.003002166748047 0.0
Max loss timestep torch.Size([777, 4]) tensor([230, 669, 333,  81], device='cuda:0') tensor(669, device='cuda:0')
bi 0 loss 0.05900613218545914
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 1 loss 0.3710814416408539
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 2 loss 0.02778928354382515
speech mask sum tensor(247, device='cuda:0') loss mask sum tensor(247, device='cuda:0')
bi 3 loss 0.06805343180894852
speech mask sum tensor(55, device='cuda:0') loss mask sum tensor(55, device='cuda:0')
logits torch.Size([777, 4, 257024]) labels torch.Size([777, 4]) 0 257022
Layer  0  loss:  0.2094506025314331 0.0 11.909268379211426
logits torch.Size([777, 4, 1024]) labels torch.Size([777, 4]) 0 1023
Curr loss timestep torch.Size([777, 4]) tensor([197, 758, 332,  84], device='cuda:0') tensor(758, device='cuda:0')
bi 0 loss 0.10154527425765991
bi 1 loss 0.38777416944503784
bi 2 loss 0.03701907768845558
bi 3 loss 0.02028612233698368
Layer  1  loss:  0.24131977558135986 0.0 14.364943504333496
logits torch.Size([777, 4, 1024]) labels torch.Size([777, 4]) 0 1023
Curr loss timestep torch.Size([777, 4]) tensor([219, 732, 271,  98], device='cuda:0') tensor(732, device='cuda:0')
bi 0 loss 0.045327283442020416
bi 1 loss 0.46850714087486267
bi 2 loss 0.04578496143221855
bi 3 loss 0.06212160736322403
Layer  2  loss:  0.25364285707473755 0.0 17.73550796508789
logits torch.Size([777, 4, 1024]) labels torch.Size([777, 4]) 0 1022
Curr loss timestep torch.Size([777, 4]) tensor([266, 659, 278,  86], device='cuda:0') tensor(659, device='cuda:0')
bi 0 loss 0.046168699860572815
bi 1 loss 0.4951257109642029
bi 2 loss 0.05065783113241196
bi 3 loss 0.0388956181704998
Layer  3  loss:  0.23478099703788757 0.0 11.631420135498047
logits torch.Size([777, 4, 1024]) labels torch.Size([777, 4]) 0 1021
Curr loss timestep torch.Size([777, 4]) tensor([181, 662, 333,  79], device='cuda:0') tensor(662, device='cuda:0')
bi 0 loss 0.04099496454000473
bi 1 loss 0.448865681886673
bi 2 loss 0.05862659960985184
bi 3 loss 0.0559907928109169
Layer  4  loss:  0.240738183259964 0.0 12.705347061157227
logits torch.Size([777, 4, 1024]) labels torch.Size([777, 4]) 0 1020
Curr loss timestep torch.Size([777, 4]) tensor([204, 732, 293,  79], device='cuda:0') tensor(732, device='cuda:0')
bi 0 loss 0.057726144790649414
bi 1 loss 0.46906405687332153
bi 2 loss 0.0420631505548954
bi 3 loss 0.02972455695271492
Layer  5  loss:  0.2300785481929779 0.0 13.451620101928711
logits torch.Size([777, 4, 1024]) labels torch.Size([777, 4]) 0 1023
Curr loss timestep torch.Size([777, 4]) tensor([284, 759, 275,  84], device='cuda:0') tensor(759, device='cuda:0')
bi 0 loss 0.09266290068626404
bi 1 loss 0.42549896240234375
bi 2 loss 0.052009113132953644
bi 3 loss 0.02960602194070816
Layer  6  loss:  0.23526594042778015 0.0 11.682971000671387
logits torch.Size([777, 4, 1024]) labels torch.Size([777, 4]) 0 1022
Curr loss timestep torch.Size([777, 4]) tensor([264, 759, 332,  82], device='cuda:0') tensor(759, device='cuda:0')
bi 0 loss 0.058589182794094086
bi 1 loss 0.4572172462940216
bi 2 loss 0.03349621221423149
bi 3 loss 0.0653858557343483
Epoch 0: :   3%|▎         | 15835/600000 [05:48<3:34:25, v_num=12, reduced_train_loss=31.20, global_step=15833.0, consumed_samples=63336.0, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15835/600000 [05:48<3:34:25, v_num=12, reduced_train_loss=1.840, global_step=15834.0, consumed_samples=63340.0, train_step_timing in s=0.547]loss mask original None

First layer loss:  0.141348198056221 torch.Size([599, 4]) 9.219901084899902 0.0
Max loss timestep torch.Size([599, 4]) tensor([172, 402,  98, 302], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.07476387172937393
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 0.2184697538614273
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 2 loss 0.02332497201859951
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 3 loss 0.14562197029590607
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257023
Layer  0  loss:  0.20711776614189148 0.0 14.298312187194824
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([199, 403, 124, 305], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.043190326541662216
bi 1 loss 0.37452155351638794
bi 2 loss 0.039436861872673035
bi 3 loss 0.2024577558040619
Layer  1  loss:  0.20434913039207458 0.0 13.09593677520752
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([169, 402,  96, 522], device='cuda:0') tensor(402, device='cuda:0')
bi 0 loss 0.04166218638420105
bi 1 loss 0.40408623218536377
bi 2 loss 0.024078495800495148
bi 3 loss 0.18665540218353271
Layer  2  loss:  0.22190223634243011 0.0 11.832432746887207
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([215, 450, 113, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.051267970353364944
bi 1 loss 0.4001912772655487
bi 2 loss 0.04766382649540901
bi 3 loss 0.21506741642951965
Layer  3  loss:  0.21918687224388123 0.0 12.000160217285156
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([203, 402, 111, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.039388641715049744
bi 1 loss 0.35339054465293884
bi 2 loss 0.046901874244213104
bi 3 loss 0.23513482511043549
Layer  4  loss:  0.2499067336320877 0.0 14.730151176452637
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([180, 404, 143, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.033698271960020065
bi 1 loss 0.5431850552558899
bi 2 loss 0.041295308619737625
bi 3 loss 0.2066313624382019
Layer  5  loss:  0.2038193792104721 0.0 16.370344161987305
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([139, 404, 113, 305], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.05016133189201355
bi 1 loss 0.3159659802913666
bi 2 loss 0.032910529524087906
bi 3 loss 0.22364340722560883
Layer  6  loss:  0.19973981380462646 0.0 14.320305824279785
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([223, 580, 101, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.04158550873398781
bi 1 loss 0.3271273076534271
bi 2 loss 0.01942620240151882
bi 3 loss 0.21538089215755463
Epoch 0: :   3%|▎         | 15836/600000 [05:49<3:34:40, v_num=12, reduced_train_loss=1.840, global_step=15834.0, consumed_samples=63340.0, train_step_timing in s=0.547]Epoch 0: :   3%|▎         | 15836/600000 [05:49<3:34:40, v_num=12, reduced_train_loss=1.650, global_step=15835.0, consumed_samples=63344.0, train_step_timing in s=0.413]loss mask original None

First layer loss:  0.19493021070957184 torch.Size([643, 4]) 12.344502449035645 0.0
Max loss timestep torch.Size([643, 4]) tensor([260, 543, 283, 263], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.21850869059562683
speech mask sum tensor(140, device='cuda:0') loss mask sum tensor(140, device='cuda:0')
bi 1 loss 0.2741893231868744
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
bi 2 loss 0.051034148782491684
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 3 loss 0.1880815625190735
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
logits torch.Size([643, 4, 257024]) labels torch.Size([643, 4]) 0 257022
Layer  0  loss:  0.23455126583576202 0.0 15.805198669433594
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1023
Curr loss timestep torch.Size([643, 4]) tensor([259, 543, 241, 263], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.3014346957206726
bi 1 loss 0.33721768856048584
bi 2 loss 0.05100305378437042
bi 3 loss 0.1651649922132492
Layer  1  loss:  0.23707500100135803 0.0 15.204389572143555
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1022
Curr loss timestep torch.Size([643, 4]) tensor([259, 368, 283, 263], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.24088047444820404
bi 1 loss 0.3380228281021118
bi 2 loss 0.06543835252523422
bi 3 loss 0.23321543633937836
Layer  2  loss:  0.22036993503570557 0.0 19.673532485961914
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1022
Curr loss timestep torch.Size([643, 4]) tensor([260, 368, 283, 263], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.2588181793689728
bi 1 loss 0.31754472851753235
bi 2 loss 0.043205637484788895
bi 3 loss 0.20030765235424042
Layer  3  loss:  0.21771679818630219 0.0 12.907854080200195
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1023
Curr loss timestep torch.Size([643, 4]) tensor([259, 368, 278, 263], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.2524566948413849
bi 1 loss 0.3008244037628174
bi 2 loss 0.0654744952917099
bi 3 loss 0.19993241131305695
Layer  4  loss:  0.23216091096401215 0.0 17.85627555847168
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1023
Curr loss timestep torch.Size([643, 4]) tensor([259, 368, 164, 263], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.18988028168678284
bi 1 loss 0.35581567883491516
bi 2 loss 0.04525402933359146
bi 3 loss 0.2290223240852356
Layer  5  loss:  0.21337959170341492 0.0 16.494802474975586
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1022
Curr loss timestep torch.Size([643, 4]) tensor([260, 368, 155, 263], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.1690254509449005
bi 1 loss 0.3007802665233612
bi 2 loss 0.08498146384954453
bi 3 loss 0.22152748703956604
Layer  6  loss:  0.24169424176216125 0.0 18.696155548095703
logits torch.Size([643, 4, 1024]) labels torch.Size([643, 4]) 0 1022
Curr loss timestep torch.Size([643, 4]) tensor([259, 368, 227, 263], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.3018181324005127
bi 1 loss 0.33100712299346924
bi 2 loss 0.03740447387099266
bi 3 loss 0.30501946806907654
Epoch 0: :   3%|▎         | 15837/600000 [05:49<3:34:57, v_num=12, reduced_train_loss=1.650, global_step=15835.0, consumed_samples=63344.0, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15837/600000 [05:49<3:34:57, v_num=12, reduced_train_loss=1.790, global_step=15836.0, consumed_samples=63348.0, train_step_timing in s=0.441]loss mask original None

First layer loss:  0.13120393455028534 torch.Size([558, 4]) 6.754866600036621 0.0
Max loss timestep torch.Size([558, 4]) tensor([218, 260, 444, 283], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.13065463304519653
speech mask sum tensor(288, device='cuda:0') loss mask sum tensor(288, device='cuda:0')
bi 1 loss 0.06315053999423981
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
bi 2 loss 0.06809163093566895
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 3 loss 0.22197800874710083
speech mask sum tensor(363, device='cuda:0') loss mask sum tensor(363, device='cuda:0')
logits torch.Size([558, 4, 257024]) labels torch.Size([558, 4]) 0 257022
Layer  0  loss:  0.15135343372821808 0.0 11.922249794006348
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([399, 277, 298, 283], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.11704102903604507
bi 1 loss 0.044898368418216705
bi 2 loss 0.06712395697832108
bi 3 loss 0.303318589925766
Layer  1  loss:  0.17052887380123138 0.0 13.283549308776855
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([403, 277, 370, 283], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.12824544310569763
bi 1 loss 0.11333752423524857
bi 2 loss 0.09641309827566147
bi 3 loss 0.3040914535522461
Layer  2  loss:  0.14920319616794586 0.0 12.211813926696777
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([395, 277, 445, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.10041268914937973
bi 1 loss 0.0973631739616394
bi 2 loss 0.08341453969478607
bi 3 loss 0.2769784927368164
Layer  3  loss:  0.17649884521961212 0.0 11.349814414978027
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1019
Curr loss timestep torch.Size([558, 4]) tensor([395, 276, 286, 521], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.12939924001693726
bi 1 loss 0.12422773987054825
bi 2 loss 0.09291283786296844
bi 3 loss 0.32339465618133545
Layer  4  loss:  0.15731066465377808 0.0 10.845870018005371
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([395, 276, 445, 283], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.13207286596298218
bi 1 loss 0.1052498146891594
bi 2 loss 0.0927579328417778
bi 3 loss 0.26504552364349365
Layer  5  loss:  0.16791236400604248 0.0 11.613689422607422
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1023
Curr loss timestep torch.Size([558, 4]) tensor([395, 276, 444, 283], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.1160149872303009
bi 1 loss 0.14085674285888672
bi 2 loss 0.08571729809045792
bi 3 loss 0.31028643250465393
Layer  6  loss:  0.18741890788078308 0.0 18.78929328918457
logits torch.Size([558, 4, 1024]) labels torch.Size([558, 4]) 0 1022
Curr loss timestep torch.Size([558, 4]) tensor([395, 276, 445, 283], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.1647823005914688
bi 1 loss 0.16851191222667694
bi 2 loss 0.0812821015715599
bi 3 loss 0.3317717909812927
Epoch 0: :   3%|▎         | 15838/600000 [05:50<3:35:12, v_num=12, reduced_train_loss=1.790, global_step=15836.0, consumed_samples=63348.0, train_step_timing in s=0.441]Epoch 0: :   3%|▎         | 15838/600000 [05:50<3:35:12, v_num=12, reduced_train_loss=1.290, global_step=15837.0, consumed_samples=63352.0, train_step_timing in s=0.381]loss mask original None

First layer loss:  0.07666156440973282 torch.Size([425, 4]) 4.774382591247559 0.0
Max loss timestep torch.Size([425, 4]) tensor([214, 260, 400, 349], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.03877665102481842
speech mask sum tensor(138, device='cuda:0') loss mask sum tensor(138, device='cuda:0')
bi 1 loss 0.07524964213371277
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 2 loss 0.09660632908344269
speech mask sum tensor(197, device='cuda:0') loss mask sum tensor(197, device='cuda:0')
bi 3 loss 0.09128722548484802
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
logits torch.Size([425, 4, 257024]) labels torch.Size([425, 4]) 0 257022
Layer  0  loss:  0.09073159843683243 0.0 3.801392078399658
logits torch.Size([425, 4, 1024]) labels torch.Size([425, 4]) 0 1023
Curr loss timestep torch.Size([425, 4]) tensor([272, 261, 400, 297], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.04216548055410385
bi 1 loss 0.10283944010734558
bi 2 loss 0.07941374182701111
bi 3 loss 0.15466132760047913
Layer  1  loss:  0.10932392627000809 0.0 10.984622955322266
logits torch.Size([425, 4, 1024]) labels torch.Size([425, 4]) 0 1023
Curr loss timestep torch.Size([425, 4]) tensor([270, 261, 400, 312], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.06247476115822792
bi 1 loss 0.09965228289365768
bi 2 loss 0.11814272403717041
bi 3 loss 0.17016765475273132
Layer  2  loss:  0.06762910634279251 0.0 2.7269856929779053
logits torch.Size([425, 4, 1024]) labels torch.Size([425, 4]) 0 1023
Curr loss timestep torch.Size([425, 4]) tensor([280, 261, 400, 346], device='cuda:0') tensor(346, device='cuda:0')
bi 0 loss 0.037807125598192215
bi 1 loss 0.06178215146064758
bi 2 loss 0.06648664176464081
bi 3 loss 0.11839570105075836
Layer  3  loss:  0.11748291552066803 0.0 8.794149398803711
logits torch.Size([425, 4, 1024]) labels torch.Size([425, 4]) 0 1021
Curr loss timestep torch.Size([425, 4]) tensor([270, 261, 400, 313], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.05783045291900635
bi 1 loss 0.1056387647986412
bi 2 loss 0.1212618499994278
bi 3 loss 0.20800982415676117
Layer  4  loss:  0.09200312942266464 0.0 9.872532844543457
logits torch.Size([425, 4, 1024]) labels torch.Size([425, 4]) 0 1023
Curr loss timestep torch.Size([425, 4]) tensor([259, 261, 400, 346], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.03917696326971054
bi 1 loss 0.1281062364578247
bi 2 loss 0.06643916666507721
bi 3 loss 0.1476612687110901
Layer  5  loss:  0.08152477443218231 0.0 9.194926261901855
logits torch.Size([425, 4, 1024]) labels torch.Size([425, 4]) 0 1023
Curr loss timestep torch.Size([425, 4]) tensor([186, 261, 400, 312], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.052570901811122894
bi 1 loss 0.10183356702327728
bi 2 loss 0.05150288715958595
bi 3 loss 0.14091138541698456
Layer  6  loss:  0.08940518647432327 0.0 14.366707801818848
logits torch.Size([425, 4, 1024]) labels torch.Size([425, 4]) 0 1022
Curr loss timestep torch.Size([425, 4]) tensor([272, 261, 400, 313], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.05155680701136589
bi 1 loss 0.11616411060094833
bi 2 loss 0.06266237050294876
bi 3 loss 0.1434459388256073
Epoch 0: :   3%|▎         | 15839/600000 [05:50<3:35:24, v_num=12, reduced_train_loss=1.290, global_step=15837.0, consumed_samples=63352.0, train_step_timing in s=0.381]Epoch 0: :   3%|▎         | 15839/600000 [05:50<3:35:24, v_num=12, reduced_train_loss=0.725, global_step=15838.0, consumed_samples=63356.0, train_step_timing in s=0.326]loss mask original None

First layer loss:  0.29597923159599304 torch.Size([730, 4]) 9.597577095031738 0.0
Max loss timestep torch.Size([730, 4]) tensor([517, 309, 284, 526], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.2894896864891052
speech mask sum tensor(429, device='cuda:0') loss mask sum tensor(429, device='cuda:0')
bi 1 loss 0.3694280683994293
speech mask sum tensor(258, device='cuda:0') loss mask sum tensor(258, device='cuda:0')
bi 2 loss 0.08849430084228516
speech mask sum tensor(175, device='cuda:0') loss mask sum tensor(175, device='cuda:0')
bi 3 loss 0.3530445992946625
speech mask sum tensor(353, device='cuda:0') loss mask sum tensor(353, device='cuda:0')
logits torch.Size([730, 4, 257024]) labels torch.Size([730, 4]) 0 257022
Layer  0  loss:  0.3999713957309723 0.0 15.766507148742676
logits torch.Size([730, 4, 1024]) labels torch.Size([730, 4]) 0 1023
Curr loss timestep torch.Size([730, 4]) tensor([433, 288, 284, 702], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.44296854734420776
bi 1 loss 0.3871527314186096
bi 2 loss 0.12619084119796753
bi 3 loss 0.4928129017353058
Layer  1  loss:  0.3895550072193146 0.0 12.21893310546875
logits torch.Size([730, 4, 1024]) labels torch.Size([730, 4]) 0 1023
Curr loss timestep torch.Size([730, 4]) tensor([327, 462, 284, 404], device='cuda:0') tensor(327, device='cuda:0')
bi 0 loss 0.394196093082428
bi 1 loss 0.38832199573516846
bi 2 loss 0.12371654063463211
bi 3 loss 0.5166054368019104
Layer  2  loss:  0.4105968177318573 0.0 17.496313095092773
logits torch.Size([730, 4, 1024]) labels torch.Size([730, 4]) 0 1022
Curr loss timestep torch.Size([730, 4]) tensor([327, 452, 284, 705], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.44121086597442627
bi 1 loss 0.4405467212200165
bi 2 loss 0.18393763899803162
bi 3 loss 0.46386823058128357
Layer  3  loss:  0.41184815764427185 0.0 16.124011993408203
logits torch.Size([730, 4, 1024]) labels torch.Size([730, 4]) 0 1022
Curr loss timestep torch.Size([730, 4]) tensor([327, 452, 285, 702], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.3917023837566376
bi 1 loss 0.4240855574607849
bi 2 loss 0.13340312242507935
bi 3 loss 0.5654265880584717
Layer  4  loss:  0.4544009566307068 0.0 19.32061767578125
logits torch.Size([730, 4, 1024]) labels torch.Size([730, 4]) 0 1023
Curr loss timestep torch.Size([730, 4]) tensor([516, 453, 285, 403], device='cuda:0') tensor(403, device='cuda:0')
bi 0 loss 0.45715197920799255
bi 1 loss 0.3646785616874695
bi 2 loss 0.18402202427387238
bi 3 loss 0.6506744623184204
Layer  5  loss:  0.4512946903705597 0.0 18.1494197845459
logits torch.Size([730, 4, 1024]) labels torch.Size([730, 4]) 0 1022
Curr loss timestep torch.Size([730, 4]) tensor([327, 452, 284, 702], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.42732539772987366
bi 1 loss 0.4380898177623749
bi 2 loss 0.10654406994581223
bi 3 loss 0.6609860062599182
Layer  6  loss:  0.47496744990348816 0.0 18.93816566467285
logits torch.Size([730, 4, 1024]) labels torch.Size([730, 4]) 0 1022
Curr loss timestep torch.Size([730, 4]) tensor([517, 452, 284, 534], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.525450587272644
bi 1 loss 0.39503011107444763
bi 2 loss 0.1668713092803955
bi 3 loss 0.6247788071632385
Epoch 0: :   3%|▎         | 15840/600000 [05:50<3:35:43, v_num=12, reduced_train_loss=0.725, global_step=15838.0, consumed_samples=63356.0, train_step_timing in s=0.326]Epoch 0: :   3%|▎         | 15840/600000 [05:50<3:35:43, v_num=12, reduced_train_loss=3.290, global_step=15839.0, consumed_samples=63360.0, train_step_timing in s=0.499]loss mask original None

First layer loss:  0.25550708174705505 torch.Size([743, 4]) 14.203754425048828 0.0
Max loss timestep torch.Size([743, 4]) tensor([345, 647, 155,  46], device='cuda:0') tensor(647, device='cuda:0')
bi 0 loss 0.07918129116296768
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
bi 1 loss 0.45750728249549866
speech mask sum tensor(429, device='cuda:0') loss mask sum tensor(429, device='cuda:0')
bi 2 loss 0.031057823449373245
speech mask sum tensor(89, device='cuda:0') loss mask sum tensor(89, device='cuda:0')
bi 3 loss 0.020973796024918556
speech mask sum tensor(49, device='cuda:0') loss mask sum tensor(49, device='cuda:0')
logits torch.Size([743, 4, 257024]) labels torch.Size([743, 4]) 0 257023
Layer  0  loss:  0.2457437962293625 0.0 10.66084098815918
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([345, 601, 181,  42], device='cuda:0') tensor(601, device='cuda:0')
bi 0 loss 0.1247519701719284
bi 1 loss 0.40456637740135193
bi 2 loss 0.026761997491121292
bi 3 loss 0.025844652205705643
Layer  1  loss:  0.24184612929821014 0.0 10.891298294067383
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1022
Curr loss timestep torch.Size([743, 4]) tensor([344, 646, 182,  48], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.12991319596767426
bi 1 loss 0.3888458013534546
bi 2 loss 0.04226754978299141
bi 3 loss 0.03234946355223656
Layer  2  loss:  0.29526659846305847 0.0 14.152034759521484
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1022
Curr loss timestep torch.Size([743, 4]) tensor([345, 602, 166,  46], device='cuda:0') tensor(602, device='cuda:0')
bi 0 loss 0.130827397108078
bi 1 loss 0.5011953115463257
bi 2 loss 0.03030548430979252
bi 3 loss 0.023992599919438362
Layer  3  loss:  0.2918298840522766 0.0 14.18024730682373
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1021
Curr loss timestep torch.Size([743, 4]) tensor([345, 602, 171,  53], device='cuda:0') tensor(602, device='cuda:0')
bi 0 loss 0.1534702032804489
bi 1 loss 0.47850552201271057
bi 2 loss 0.02851036749780178
bi 3 loss 0.01954801008105278
Layer  4  loss:  0.3095218241214752 0.0 11.440495491027832
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([345, 646, 162,  39], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.14047843217849731
bi 1 loss 0.5201359391212463
bi 2 loss 0.05026060342788696
bi 3 loss 0.01628444902598858
Layer  5  loss:  0.3232935070991516 0.0 14.750264167785645
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1020
Curr loss timestep torch.Size([743, 4]) tensor([345, 602, 169,  56], device='cuda:0') tensor(602, device='cuda:0')
bi 0 loss 0.12354385852813721
bi 1 loss 0.5612974166870117
bi 2 loss 0.03411272168159485
bi 3 loss 0.040743388235569
Layer  6  loss:  0.3402330279350281 0.0 18.914112091064453
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1022
Curr loss timestep torch.Size([743, 4]) tensor([345, 602, 175,  45], device='cuda:0') tensor(602, device='cuda:0')
bi 0 loss 0.13186955451965332
bi 1 loss 0.590772807598114
bi 2 loss 0.045078109949827194
bi 3 loss 0.013804041780531406
Epoch 0: :   3%|▎         | 15841/600000 [05:51<3:36:02, v_num=12, reduced_train_loss=3.290, global_step=15839.0, consumed_samples=63360.0, train_step_timing in s=0.499]Epoch 0: :   3%|▎         | 15841/600000 [05:51<3:36:02, v_num=12, reduced_train_loss=2.300, global_step=15840.0, consumed_samples=63364.0, train_step_timing in s=0.506]loss mask original None

First layer loss:  3.7038183212280273 torch.Size([636, 4]) 10.959569931030273 0.0
Max loss timestep torch.Size([636, 4]) tensor([275, 171, 305, 485], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 3.66100811958313
speech mask sum tensor(501, device='cuda:0') loss mask sum tensor(501, device='cuda:0')
bi 1 loss 4.091919422149658
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 2 loss 3.381239891052246
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 3 loss 3.7082831859588623
speech mask sum tensor(479, device='cuda:0') loss mask sum tensor(479, device='cuda:0')
logits torch.Size([636, 4, 257024]) labels torch.Size([636, 4]) 0 257022
Layer  0  loss:  4.306998252868652 0.0 10.350345611572266
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([456, 258, 314, 409], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.131488800048828
bi 1 loss 4.686769485473633
bi 2 loss 4.131888389587402
bi 3 loss 4.371606826782227
Layer  1  loss:  4.4929914474487305 0.0 11.384276390075684
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([336, 307, 227, 191], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 4.248298168182373
bi 1 loss 5.0850090980529785
bi 2 loss 4.322816371917725
bi 3 loss 4.505317211151123
Layer  2  loss:  4.842937469482422 0.0 11.148255348205566
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([587, 114, 229, 229], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 4.71297550201416
bi 1 loss 5.213466644287109
bi 2 loss 4.6407647132873535
bi 3 loss 4.880524158477783
Layer  3  loss:  4.997053623199463 0.0 10.862313270568848
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([406, 141, 115, 463], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 4.7774176597595215
bi 1 loss 5.462189197540283
bi 2 loss 4.94012975692749
bi 3 loss 4.991943359375
Layer  4  loss:  5.174469470977783 0.0 11.011737823486328
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([470, 338, 173, 500], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 4.9956512451171875
bi 1 loss 5.556803226470947
bi 2 loss 5.12882137298584
bi 3 loss 5.16782283782959
Layer  5  loss:  5.230363368988037 0.0 12.834772109985352
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1023
Curr loss timestep torch.Size([636, 4]) tensor([374, 168, 298, 263], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 5.062842845916748
bi 1 loss 5.573346138000488
bi 2 loss 5.25057315826416
bi 3 loss 5.197233200073242
Layer  6  loss:  5.2368340492248535 0.0 10.900691986083984
logits torch.Size([636, 4, 1024]) labels torch.Size([636, 4]) 0 1022
Curr loss timestep torch.Size([636, 4]) tensor([275, 361, 291, 463], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 4.968386650085449
bi 1 loss 5.6782050132751465
bi 2 loss 5.218478679656982
bi 3 loss 5.274598598480225
Epoch 0: :   3%|▎         | 15842/600000 [05:51<3:36:17, v_num=12, reduced_train_loss=2.300, global_step=15840.0, consumed_samples=63364.0, train_step_timing in s=0.506]Epoch 0: :   3%|▎         | 15842/600000 [05:51<3:36:17, v_num=12, reduced_train_loss=38.00, global_step=15841.0, consumed_samples=63368.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  0.17113293707370758 torch.Size([657, 4]) 16.173982620239258 0.0
Max loss timestep torch.Size([657, 4]) tensor([273, 286, 522, 412], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.18862739205360413
speech mask sum tensor(222, device='cuda:0') loss mask sum tensor(222, device='cuda:0')
bi 1 loss 0.11161450296640396
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 2 loss 0.26654052734375
speech mask sum tensor(484, device='cuda:0') loss mask sum tensor(484, device='cuda:0')
bi 3 loss 0.07303042709827423
speech mask sum tensor(375, device='cuda:0') loss mask sum tensor(375, device='cuda:0')
logits torch.Size([657, 4, 257024]) labels torch.Size([657, 4]) 0 257023
Layer  0  loss:  0.21206389367580414 0.0 14.298304557800293
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([273, 289, 446, 353], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.19664613902568817
bi 1 loss 0.1362425982952118
bi 2 loss 0.32158976793289185
bi 3 loss 0.12491827458143234
Layer  1  loss:  0.20087511837482452 0.0 12.219545364379883
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1022
Curr loss timestep torch.Size([657, 4]) tensor([271, 289, 443, 400], device='cuda:0') tensor(443, device='cuda:0')
bi 0 loss 0.20536364614963531
bi 1 loss 0.15684425830841064
bi 2 loss 0.29270097613334656
bi 3 loss 0.10588500648736954
Layer  2  loss:  0.22552448511123657 0.0 12.610807418823242
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([273, 286, 629, 400], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.21687839925289154
bi 1 loss 0.18689216673374176
bi 2 loss 0.3378811776638031
bi 3 loss 0.10860127955675125
Layer  3  loss:  0.22501930594444275 0.0 14.836386680603027
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1021
Curr loss timestep torch.Size([657, 4]) tensor([271, 289, 442, 411], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 0.19916942715644836
bi 1 loss 0.18800269067287445
bi 2 loss 0.35166898369789124
bi 3 loss 0.09887244552373886
Layer  4  loss:  0.20640932023525238 0.0 12.957202911376953
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1022
Curr loss timestep torch.Size([657, 4]) tensor([271, 289, 522, 400], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.2206968367099762
bi 1 loss 0.16061918437480927
bi 2 loss 0.29675695300102234
bi 3 loss 0.10857229679822922
Layer  5  loss:  0.22974461317062378 0.0 12.468894004821777
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1022
Curr loss timestep torch.Size([657, 4]) tensor([271, 286, 449, 412], device='cuda:0') tensor(449, device='cuda:0')
bi 0 loss 0.23683561384677887
bi 1 loss 0.13787433505058289
bi 2 loss 0.3492029309272766
bi 3 loss 0.12599807977676392
Layer  6  loss:  0.1966986209154129 0.0 13.189416885375977
logits torch.Size([657, 4, 1024]) labels torch.Size([657, 4]) 0 1023
Curr loss timestep torch.Size([657, 4]) tensor([273, 286, 524, 412], device='cuda:0') tensor(524, device='cuda:0')
bi 0 loss 0.16615360975265503
bi 1 loss 0.12139621376991272
bi 2 loss 0.3199347257614136
bi 3 loss 0.10050441324710846
Epoch 0: :   3%|▎         | 15843/600000 [05:52<3:36:35, v_num=12, reduced_train_loss=38.00, global_step=15841.0, consumed_samples=63368.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15843/600000 [05:52<3:36:35, v_num=12, reduced_train_loss=1.670, global_step=15842.0, consumed_samples=63372.0, train_step_timing in s=0.465]loss mask original None

First layer loss:  3.753521680831909 torch.Size([568, 4]) 9.554523468017578 0.0
Max loss timestep torch.Size([568, 4]) tensor([283, 177, 168, 193], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 2.811206102371216
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 1 loss 4.275206565856934
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
bi 2 loss 4.18612813949585
speech mask sum tensor(147, device='cuda:0') loss mask sum tensor(147, device='cuda:0')
bi 3 loss 4.066422939300537
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
logits torch.Size([568, 4, 257024]) labels torch.Size([568, 4]) 0 257023
Layer  0  loss:  4.307586669921875 0.0 10.732278823852539
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([238, 281, 230, 481], device='cuda:0') tensor(238, device='cuda:0')
bi 0 loss 3.59509015083313
bi 1 loss 4.3008599281311035
bi 2 loss 4.208944797515869
bi 3 loss 4.861280918121338
Layer  1  loss:  4.537604331970215 0.0 9.924357414245605
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([296, 164, 253, 156], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 3.944655418395996
bi 1 loss 4.328262805938721
bi 2 loss 5.2101569175720215
bi 3 loss 4.834346771240234
Layer  2  loss:  4.783671855926514 0.0 10.515363693237305
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([164, 197, 272, 348], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.12713623046875
bi 1 loss 4.772853374481201
bi 2 loss 5.222837448120117
bi 3 loss 5.1183953285217285
Layer  3  loss:  4.92095422744751 0.0 9.597820281982422
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1021
Curr loss timestep torch.Size([568, 4]) tensor([311, 300, 177, 270], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.489641189575195
bi 1 loss 4.95390510559082
bi 2 loss 5.243737697601318
bi 3 loss 5.111947536468506
Layer  4  loss:  5.057971000671387 0.0 10.132720947265625
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1022
Curr loss timestep torch.Size([568, 4]) tensor([417, 301, 205, 308], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 4.678989410400391
bi 1 loss 5.038868427276611
bi 2 loss 5.414462566375732
bi 3 loss 5.2222981452941895
Layer  5  loss:  5.132903575897217 0.0 11.548203468322754
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([154, 310, 279, 139], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 4.7777791023254395
bi 1 loss 5.117485523223877
bi 2 loss 5.432863235473633
bi 3 loss 5.297221660614014
Layer  6  loss:  5.14652156829834 0.0 10.87746810913086
logits torch.Size([568, 4, 1024]) labels torch.Size([568, 4]) 0 1023
Curr loss timestep torch.Size([568, 4]) tensor([419, 296, 294, 338], device='cuda:0') tensor(241, device='cuda:0')
bi 0 loss 4.808416366577148
bi 1 loss 5.080366134643555
bi 2 loss 5.47698450088501
bi 3 loss 5.310333251953125
Epoch 0: :   3%|▎         | 15844/600000 [05:52<3:36:49, v_num=12, reduced_train_loss=1.670, global_step=15842.0, consumed_samples=63372.0, train_step_timing in s=0.465]Epoch 0: :   3%|▎         | 15844/600000 [05:52<3:36:49, v_num=12, reduced_train_loss=37.60, global_step=15843.0, consumed_samples=63376.0, train_step_timing in s=0.367]loss mask original None

First layer loss:  0.0037142843939363956 torch.Size([270, 4]) 0.03554319217801094 0.0
Max loss timestep torch.Size([270, 4]) tensor([231,  64, 128, 118], device='cuda:0') tensor(128, device='cuda:0')
bi 0 loss 0.0018668827833607793
speech mask sum tensor(57, device='cuda:0') loss mask sum tensor(57, device='cuda:0')
bi 1 loss 0.0039384691044688225
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 2 loss 0.004412609152495861
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 3 loss 0.0034549180418252945
speech mask sum tensor(74, device='cuda:0') loss mask sum tensor(74, device='cuda:0')
logits torch.Size([270, 4, 257024]) labels torch.Size([270, 4]) 0 257023
Layer  0  loss:  0.003434628713876009 0.0 0.03537141531705856
logits torch.Size([270, 4, 1024]) labels torch.Size([270, 4]) 0 1021
Curr loss timestep torch.Size([270, 4]) tensor([256,  90,  85, 103], device='cuda:0') tensor(85, device='cuda:0')
bi 0 loss 0.0019034009892493486
bi 1 loss 0.00413156021386385
bi 2 loss 0.004102921579033136
bi 3 loss 0.002267455216497183
Layer  1  loss:  0.0032187323085963726 0.0 0.045933306217193604
logits torch.Size([270, 4, 1024]) labels torch.Size([270, 4]) 0 1022
Curr loss timestep torch.Size([270, 4]) tensor([233, 133, 144, 113], device='cuda:0') tensor(133, device='cuda:0')
bi 0 loss 0.0016480357153341174
bi 1 loss 0.004317854531109333
bi 2 loss 0.003468433627858758
bi 3 loss 0.002271046629175544
Layer  2  loss:  0.003420508000999689 0.0 0.0303169135004282
logits torch.Size([270, 4, 1024]) labels torch.Size([270, 4]) 0 1023
Curr loss timestep torch.Size([270, 4]) tensor([230,  78, 119, 121], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 0.0014544142177328467
bi 1 loss 0.003776183584704995
bi 2 loss 0.003923378419131041
bi 3 loss 0.0034268361050635576
Layer  3  loss:  0.0033734722528606653 0.0 0.051349952816963196
logits torch.Size([270, 4, 1024]) labels torch.Size([270, 4]) 0 1021
Curr loss timestep torch.Size([270, 4]) tensor([231, 136, 193, 124], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 0.0014978155959397554
bi 1 loss 0.0038802146445959806
bi 2 loss 0.004142486024647951
bi 3 loss 0.00256875017657876
Layer  4  loss:  0.003133365884423256 0.0 0.03676964342594147
logits torch.Size([270, 4, 1024]) labels torch.Size([270, 4]) 0 1022
Curr loss timestep torch.Size([270, 4]) tensor([238, 142, 158, 136], device='cuda:0') tensor(142, device='cuda:0')
bi 0 loss 0.00131903903093189
bi 1 loss 0.0041521633975207806
bi 2 loss 0.0033954018726944923
bi 3 loss 0.0024723298847675323
Layer  5  loss:  0.004276381805539131 0.0 0.16330131888389587
logits torch.Size([270, 4, 1024]) labels torch.Size([270, 4]) 0 1022
Curr loss timestep torch.Size([270, 4]) tensor([259,  87, 199,  97], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.004817183129489422
bi 1 loss 0.004794279579073191
bi 2 loss 0.0038813482969999313
bi 3 loss 0.0038270121440291405
Layer  6  loss:  0.003256966359913349 0.0 0.049214981496334076
logits torch.Size([270, 4, 1024]) labels torch.Size([270, 4]) 0 1022
Curr loss timestep torch.Size([270, 4]) tensor([255, 106,  85, 129], device='cuda:0') tensor(129, device='cuda:0')
bi 0 loss 0.0012462972663342953
bi 1 loss 0.003478813450783491
bi 2 loss 0.003683873452246189
bi 3 loss 0.003647757926955819
Epoch 0: :   3%|▎         | 15845/600000 [05:53<3:36:58, v_num=12, reduced_train_loss=37.60, global_step=15843.0, consumed_samples=63376.0, train_step_timing in s=0.367]Epoch 0: :   3%|▎         | 15845/600000 [05:53<3:36:58, v_num=12, reduced_train_loss=0.0278, global_step=15844.0, consumed_samples=63380.0, train_step_timing in s=0.243]loss mask original None

First layer loss:  0.17158398032188416 torch.Size([554, 4]) 9.955366134643555 0.0
Max loss timestep torch.Size([554, 4]) tensor([123, 287, 288, 534], device='cuda:0') tensor(534, device='cuda:0')
bi 0 loss 0.04005541279911995
speech mask sum tensor(248, device='cuda:0') loss mask sum tensor(248, device='cuda:0')
bi 1 loss 0.04694603383541107
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 2 loss 0.40469685196876526
speech mask sum tensor(245, device='cuda:0') loss mask sum tensor(245, device='cuda:0')
bi 3 loss 0.19226673245429993
speech mask sum tensor(485, device='cuda:0') loss mask sum tensor(485, device='cuda:0')
logits torch.Size([554, 4, 257024]) labels torch.Size([554, 4]) 0 257023
Layer  0  loss:  0.13207097351551056 0.0 9.285035133361816
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([241, 210, 336, 536], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.04507101699709892
bi 1 loss 0.04232371225953102
bi 2 loss 0.2638223171234131
bi 3 loss 0.1612604558467865
Layer  1  loss:  0.14973671734333038 0.0 11.223682403564453
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1021
Curr loss timestep torch.Size([554, 4]) tensor([170, 205, 340, 541], device='cuda:0') tensor(541, device='cuda:0')
bi 0 loss 0.056100085377693176
bi 1 loss 0.042060185223817825
bi 2 loss 0.226491317152977
bi 3 loss 0.22034166753292084
Layer  2  loss:  0.1524752378463745 0.0 9.599132537841797
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([212, 287, 347, 482], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.06645607948303223
bi 1 loss 0.07568492740392685
bi 2 loss 0.23672828078269958
bi 3 loss 0.1977570354938507
Layer  3  loss:  0.1543293595314026 0.0 12.50416374206543
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([261, 289, 336, 482], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.05208325386047363
bi 1 loss 0.06598068028688431
bi 2 loss 0.22934243083000183
bi 3 loss 0.21917764842510223
Layer  4  loss:  0.14984874427318573 0.0 15.552422523498535
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([111, 287, 312, 482], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.0344754122197628
bi 1 loss 0.06249508261680603
bi 2 loss 0.23241572082042694
bi 3 loss 0.2170252799987793
Layer  5  loss:  0.15892434120178223 0.0 10.76577091217041
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([113, 292, 335, 482], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.05381301790475845
bi 1 loss 0.06677189469337463
bi 2 loss 0.262297660112381
bi 3 loss 0.21308386325836182
Layer  6  loss:  0.16510827839374542 0.0 8.057536125183105
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1021
Curr loss timestep torch.Size([554, 4]) tensor([158, 289, 312, 535], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.0625690296292305
bi 1 loss 0.07534250617027283
bi 2 loss 0.2662658393383026
bi 3 loss 0.21770882606506348
Epoch 0: :   3%|▎         | 15846/600000 [05:53<3:37:13, v_num=12, reduced_train_loss=0.0278, global_step=15844.0, consumed_samples=63380.0, train_step_timing in s=0.243]Epoch 0: :   3%|▎         | 15846/600000 [05:53<3:37:13, v_num=12, reduced_train_loss=1.230, global_step=15845.0, consumed_samples=63384.0, train_step_timing in s=0.378] loss mask original None

First layer loss:  3.597480535507202 torch.Size([716, 4]) 12.733726501464844 0.0
Max loss timestep torch.Size([716, 4]) tensor([568, 231,  89, 437], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 3.8651485443115234
speech mask sum tensor(487, device='cuda:0') loss mask sum tensor(487, device='cuda:0')
bi 1 loss 3.711451768875122
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
bi 2 loss 3.420623302459717
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
bi 3 loss 3.3310434818267822
speech mask sum tensor(395, device='cuda:0') loss mask sum tensor(395, device='cuda:0')
logits torch.Size([716, 4, 257024]) labels torch.Size([716, 4]) 0 257023
Layer  0  loss:  4.114665985107422 0.0 10.114013671875
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([298, 432, 469, 554], device='cuda:0') tensor(438, device='cuda:0')
bi 0 loss 4.55544376373291
bi 1 loss 4.183169841766357
bi 2 loss 3.957871913909912
bi 3 loss 3.665809154510498
Layer  1  loss:  4.412375450134277 0.0 10.590381622314453
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([476, 240, 408, 697], device='cuda:0') tensor(477, device='cuda:0')
bi 0 loss 4.705275058746338
bi 1 loss 4.475796222686768
bi 2 loss 4.232263088226318
bi 3 loss 4.177845001220703
Layer  2  loss:  4.651364326477051 0.0 10.896550178527832
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([602, 346, 132, 422], device='cuda:0') tensor(478, device='cuda:0')
bi 0 loss 4.879088878631592
bi 1 loss 4.781065464019775
bi 2 loss 4.48034143447876
bi 3 loss 4.409181594848633
Layer  3  loss:  4.766073703765869 0.0 11.150714874267578
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([434, 527, 261, 552], device='cuda:0') tensor(445, device='cuda:0')
bi 0 loss 4.9809794425964355
bi 1 loss 4.853597640991211
bi 2 loss 4.607508659362793
bi 3 loss 4.57533073425293
Layer  4  loss:  4.883944988250732 0.0 10.455618858337402
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([574, 617,  95, 551], device='cuda:0') tensor(447, device='cuda:0')
bi 0 loss 5.190552711486816
bi 1 loss 4.982173442840576
bi 2 loss 4.7374444007873535
bi 3 loss 4.554097652435303
Layer  5  loss:  4.907050132751465 0.0 9.635873794555664
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([626, 621, 157, 441], device='cuda:0') tensor(441, device='cuda:0')
bi 0 loss 5.145277500152588
bi 1 loss 5.080280303955078
bi 2 loss 4.705246448516846
bi 3 loss 4.635149955749512
Layer  6  loss:  4.993058681488037 0.0 11.600590705871582
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([216, 190, 105, 359], device='cuda:0') tensor(469, device='cuda:0')
bi 0 loss 5.315428733825684
bi 1 loss 5.065503120422363
bi 2 loss 4.749091625213623
bi 3 loss 4.782883644104004
Epoch 0: :   3%|▎         | 15847/600000 [05:54<3:37:29, v_num=12, reduced_train_loss=1.230, global_step=15845.0, consumed_samples=63384.0, train_step_timing in s=0.378]Epoch 0: :   3%|▎         | 15847/600000 [05:54<3:37:29, v_num=12, reduced_train_loss=36.30, global_step=15846.0, consumed_samples=63388.0, train_step_timing in s=0.426]loss mask original None

First layer loss:  3.2859742641448975 torch.Size([376, 4]) 10.06831169128418 0.0
Max loss timestep torch.Size([376, 4]) tensor([174, 154,  96, 279], device='cuda:0') tensor(96, device='cuda:0')
bi 0 loss 2.7972514629364014
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 1 loss 3.901344060897827
speech mask sum tensor(249, device='cuda:0') loss mask sum tensor(249, device='cuda:0')
bi 2 loss 2.5216517448425293
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 3 loss 2.929349899291992
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
logits torch.Size([376, 4, 257024]) labels torch.Size([376, 4]) 0 257023
Layer  0  loss:  3.7490158081054688 0.0 9.881819725036621
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1023
Curr loss timestep torch.Size([376, 4]) tensor([110, 194, 112, 277], device='cuda:0') tensor(111, device='cuda:0')
bi 0 loss 2.9777164459228516
bi 1 loss 4.319933891296387
bi 2 loss 3.381977081298828
bi 3 loss 3.4875826835632324
Layer  1  loss:  4.087039947509766 0.0 9.796073913574219
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([144, 229, 120, 355], device='cuda:0') tensor(144, device='cuda:0')
bi 0 loss 3.416250228881836
bi 1 loss 4.649676322937012
bi 2 loss 3.5086634159088135
bi 3 loss 3.918891191482544
Layer  2  loss:  4.343688011169434 0.0 10.317728042602539
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([171, 228, 135, 310], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 3.8546595573425293
bi 1 loss 4.975644588470459
bi 2 loss 3.6031758785247803
bi 3 loss 3.921959400177002
Layer  3  loss:  4.556960105895996 0.0 10.266355514526367
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1021
Curr loss timestep torch.Size([376, 4]) tensor([119, 305, 130, 303], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 3.7792887687683105
bi 1 loss 5.142279148101807
bi 2 loss 3.9677505493164062
bi 3 loss 4.465872287750244
Layer  4  loss:  4.631020545959473 0.0 9.325161933898926
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1022
Curr loss timestep torch.Size([376, 4]) tensor([118, 263, 132, 317], device='cuda:0') tensor(142, device='cuda:0')
bi 0 loss 3.946544647216797
bi 1 loss 5.236691474914551
bi 2 loss 3.854351758956909
bi 3 loss 4.544487953186035
Layer  5  loss:  4.697256565093994 0.0 9.439277648925781
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1023
Curr loss timestep torch.Size([376, 4]) tensor([174, 323,  93, 296], device='cuda:0') tensor(140, device='cuda:0')
bi 0 loss 3.883641481399536
bi 1 loss 5.3418073654174805
bi 2 loss 3.9577133655548096
bi 3 loss 4.62803316116333
Layer  6  loss:  4.766733646392822 0.0 10.506863594055176
logits torch.Size([376, 4, 1024]) labels torch.Size([376, 4]) 0 1021
Curr loss timestep torch.Size([376, 4]) tensor([ 99, 358, 138, 281], device='cuda:0') tensor(146, device='cuda:0')
bi 0 loss 4.055841445922852
bi 1 loss 5.242524147033691
bi 2 loss 4.316945552825928
bi 3 loss 4.7601399421691895
Epoch 0: :   3%|▎         | 15848/600000 [05:54<3:37:40, v_num=12, reduced_train_loss=36.30, global_step=15846.0, consumed_samples=63388.0, train_step_timing in s=0.426]Epoch 0: :   3%|▎         | 15848/600000 [05:54<3:37:40, v_num=12, reduced_train_loss=34.10, global_step=15847.0, consumed_samples=63392.0, train_step_timing in s=0.290]loss mask original None

First layer loss:  0.16788001358509064 torch.Size([675, 4]) 8.539838790893555 0.0
Max loss timestep torch.Size([675, 4]) tensor([279, 517, 211, 517], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.09967982769012451
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 1 loss 0.2281191051006317
speech mask sum tensor(379, device='cuda:0') loss mask sum tensor(379, device='cuda:0')
bi 2 loss 0.04202737286686897
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 3 loss 0.2227214127779007
speech mask sum tensor(485, device='cuda:0') loss mask sum tensor(485, device='cuda:0')
logits torch.Size([675, 4, 257024]) labels torch.Size([675, 4]) 0 257022
Layer  0  loss:  0.21045033633708954 0.0 14.56982421875
logits torch.Size([675, 4, 1024]) labels torch.Size([675, 4]) 0 1023
Curr loss timestep torch.Size([675, 4]) tensor([279, 520, 237, 517], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.12919369339942932
bi 1 loss 0.3026394546031952
bi 2 loss 0.038541022688150406
bi 3 loss 0.26898300647735596
Layer  1  loss:  0.20042014122009277 0.0 9.542491912841797
logits torch.Size([675, 4, 1024]) labels torch.Size([675, 4]) 0 1023
Curr loss timestep torch.Size([675, 4]) tensor([275, 522, 118, 550], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.10763020068407059
bi 1 loss 0.2994742691516876
bi 2 loss 0.041804660111665726
bi 3 loss 0.2564219832420349
Layer  2  loss:  0.1986430436372757 0.0 14.969974517822266
logits torch.Size([675, 4, 1024]) labels torch.Size([675, 4]) 0 1022
Curr loss timestep torch.Size([675, 4]) tensor([274, 520, 213, 614], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.12205111980438232
bi 1 loss 0.28437483310699463
bi 2 loss 0.058808207511901855
bi 3 loss 0.2454773634672165
Layer  3  loss:  0.2279529720544815 0.0 13.143209457397461
logits torch.Size([675, 4, 1024]) labels torch.Size([675, 4]) 0 1021
Curr loss timestep torch.Size([675, 4]) tensor([285, 517, 122, 550], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.11610302329063416
bi 1 loss 0.3265776038169861
bi 2 loss 0.0818476602435112
bi 3 loss 0.29291319847106934
Layer  4  loss:  0.19904786348342896 0.0 11.971908569335938
logits torch.Size([675, 4, 1024]) labels torch.Size([675, 4]) 0 1022
Curr loss timestep torch.Size([675, 4]) tensor([285, 520, 267, 517], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.13803933560848236
bi 1 loss 0.2574753165245056
bi 2 loss 0.04084659367799759
bi 3 loss 0.2635585367679596
Layer  5  loss:  0.21215525269508362 0.0 12.809320449829102
logits torch.Size([675, 4, 1024]) labels torch.Size([675, 4]) 0 1023
Curr loss timestep torch.Size([675, 4]) tensor([276, 522, 248, 517], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.10812009125947952
bi 1 loss 0.3423583507537842
bi 2 loss 0.051846493035554886
bi 3 loss 0.2526825964450836
Layer  6  loss:  0.20496416091918945 0.0 13.8191556930542
logits torch.Size([675, 4, 1024]) labels torch.Size([675, 4]) 0 1023
Curr loss timestep torch.Size([675, 4]) tensor([274, 517, 167, 550], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.11731939017772675
bi 1 loss 0.28079256415367126
bi 2 loss 0.07888495922088623
bi 3 loss 0.2618301510810852
Epoch 0: :   3%|▎         | 15849/600000 [05:54<3:37:58, v_num=12, reduced_train_loss=34.10, global_step=15847.0, consumed_samples=63392.0, train_step_timing in s=0.290]Epoch 0: :   3%|▎         | 15849/600000 [05:54<3:37:58, v_num=12, reduced_train_loss=1.620, global_step=15848.0, consumed_samples=63396.0, train_step_timing in s=0.462]loss mask original None

First layer loss:  3.7266652584075928 torch.Size([656, 4]) 11.664177894592285 0.0
Max loss timestep torch.Size([656, 4]) tensor([522, 393, 275, 373], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 3.5434727668762207
speech mask sum tensor(406, device='cuda:0') loss mask sum tensor(406, device='cuda:0')
bi 1 loss 4.1211018562316895
speech mask sum tensor(482, device='cuda:0') loss mask sum tensor(482, device='cuda:0')
bi 2 loss 3.476147174835205
speech mask sum tensor(401, device='cuda:0') loss mask sum tensor(401, device='cuda:0')
bi 3 loss 3.6860151290893555
speech mask sum tensor(376, device='cuda:0') loss mask sum tensor(376, device='cuda:0')
logits torch.Size([656, 4, 257024]) labels torch.Size([656, 4]) 0 257022
Layer  0  loss:  4.290904998779297 0.0 10.841846466064453
logits torch.Size([656, 4, 1024]) labels torch.Size([656, 4]) 0 1023
Curr loss timestep torch.Size([656, 4]) tensor([351, 545, 344, 472], device='cuda:0') tensor(442, device='cuda:0')
bi 0 loss 3.724653959274292
bi 1 loss 5.0090250968933105
bi 2 loss 4.041542053222656
bi 3 loss 4.247707843780518
Layer  1  loss:  4.568517208099365 0.0 10.51382827758789
logits torch.Size([656, 4, 1024]) labels torch.Size([656, 4]) 0 1022
Curr loss timestep torch.Size([656, 4]) tensor([284, 566, 340, 244], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 3.94140362739563
bi 1 loss 5.050472259521484
bi 2 loss 4.6803741455078125
bi 3 loss 4.508546829223633
Layer  2  loss:  4.81921911239624 0.0 11.002191543579102
logits torch.Size([656, 4, 1024]) labels torch.Size([656, 4]) 0 1022
Curr loss timestep torch.Size([656, 4]) tensor([328, 470, 340, 365], device='cuda:0') tensor(444, device='cuda:0')
bi 0 loss 4.288464546203613
bi 1 loss 5.389410972595215
bi 2 loss 4.785153388977051
bi 3 loss 4.697714328765869
Layer  3  loss:  4.937535285949707 0.0 10.370292663574219
logits torch.Size([656, 4, 1024]) labels torch.Size([656, 4]) 0 1023
Curr loss timestep torch.Size([656, 4]) tensor([322, 353, 390, 475], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 4.240415573120117
bi 1 loss 5.4691481590271
bi 2 loss 5.001040935516357
bi 3 loss 4.94106388092041
Layer  4  loss:  5.023486614227295 0.0 11.711675643920898
logits torch.Size([656, 4, 1024]) labels torch.Size([656, 4]) 0 1022
Curr loss timestep torch.Size([656, 4]) tensor([304, 432, 518, 304], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 4.354667663574219
bi 1 loss 5.416977882385254
bi 2 loss 5.160351753234863
bi 3 loss 5.095280647277832
Layer  5  loss:  5.153116226196289 0.0 11.907905578613281
logits torch.Size([656, 4, 1024]) labels torch.Size([656, 4]) 0 1023
Curr loss timestep torch.Size([656, 4]) tensor([423, 181, 454, 422], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 4.461847305297852
bi 1 loss 5.514743804931641
bi 2 loss 5.374621391296387
bi 3 loss 5.199728965759277
Layer  6  loss:  5.201715469360352 0.0 10.452333450317383
logits torch.Size([656, 4, 1024]) labels torch.Size([656, 4]) 0 1023
Curr loss timestep torch.Size([656, 4]) tensor([286, 294, 560, 369], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 4.51051139831543
bi 1 loss 5.657991409301758
bi 2 loss 5.295116901397705
bi 3 loss 5.263550281524658
Epoch 0: :   3%|▎         | 15850/600000 [05:55<3:38:13, v_num=12, reduced_train_loss=1.620, global_step=15848.0, consumed_samples=63396.0, train_step_timing in s=0.462]Epoch 0: :   3%|▎         | 15850/600000 [05:55<3:38:13, v_num=12, reduced_train_loss=37.70, global_step=15849.0, consumed_samples=63400.0, train_step_timing in s=0.401]loss mask original None

First layer loss:  0.11781539767980576 torch.Size([597, 4]) 10.323875427246094 0.0
Max loss timestep torch.Size([597, 4]) tensor([181, 560, 430, 288], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.06475644558668137
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
bi 1 loss 0.20679250359535217
speech mask sum tensor(451, device='cuda:0') loss mask sum tensor(451, device='cuda:0')
bi 2 loss 0.08891022205352783
speech mask sum tensor(218, device='cuda:0') loss mask sum tensor(218, device='cuda:0')
bi 3 loss 0.03556489571928978
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
logits torch.Size([597, 4, 257024]) labels torch.Size([597, 4]) 0 257022
Layer  0  loss:  0.13995756208896637 0.0 9.90795612335205
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([235, 560, 310, 166], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.07025639712810516
bi 1 loss 0.23076532781124115
bi 2 loss 0.11638797074556351
bi 3 loss 0.06639426946640015
Layer  1  loss:  0.1707511842250824 0.0 15.922035217285156
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([285, 308, 360,  95], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.08306196331977844
bi 1 loss 0.27497610449790955
bi 2 loss 0.19595025479793549
bi 3 loss 0.04844512417912483
Layer  2  loss:  0.16242752969264984 0.0 15.040785789489746
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([117, 560, 361, 198], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.06748451292514801
bi 1 loss 0.27861589193344116
bi 2 loss 0.1598869115114212
bi 3 loss 0.04998219385743141
Layer  3  loss:  0.1634513884782791 0.0 10.032931327819824
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1022
Curr loss timestep torch.Size([597, 4]) tensor([207, 560, 454, 287], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.07719884812831879
bi 1 loss 0.2764270007610321
bi 2 loss 0.14838922023773193
bi 3 loss 0.05903008580207825
Layer  4  loss:  0.15293247997760773 0.0 10.913637161254883
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([ 90, 526, 360, 267], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.04902295395731926
bi 1 loss 0.25959399342536926
bi 2 loss 0.14712776243686676
bi 3 loss 0.06948637962341309
Layer  5  loss:  0.14348095655441284 0.0 13.26502799987793
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1023
Curr loss timestep torch.Size([597, 4]) tensor([228, 527, 361, 204], device='cuda:0') tensor(527, device='cuda:0')
bi 0 loss 0.05754007399082184
bi 1 loss 0.22213532030582428
bi 2 loss 0.1712571233510971
bi 3 loss 0.06330849230289459
Layer  6  loss:  0.15234893560409546 0.0 12.8132963180542
logits torch.Size([597, 4, 1024]) labels torch.Size([597, 4]) 0 1021
Curr loss timestep torch.Size([597, 4]) tensor([234, 427, 360, 128], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.058568548411130905
bi 1 loss 0.271769255399704
bi 2 loss 0.13659338653087616
bi 3 loss 0.044433947652578354
Epoch 0: :   3%|▎         | 15851/600000 [05:55<3:38:29, v_num=12, reduced_train_loss=37.70, global_step=15849.0, consumed_samples=63400.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15851/600000 [05:55<3:38:29, v_num=12, reduced_train_loss=1.200, global_step=15850.0, consumed_samples=63404.0, train_step_timing in s=0.409]loss mask original None

First layer loss:  2.9262120723724365 torch.Size([240, 4]) 8.845314025878906 0.0
Max loss timestep torch.Size([240, 4]) tensor([83, 82, 91, 99], device='cuda:0') tensor(94, device='cuda:0')
bi 0 loss 2.6638615131378174
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 1 loss 2.744734048843384
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 2 loss 3.185149908065796
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 2.974395513534546
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
logits torch.Size([240, 4, 257024]) labels torch.Size([240, 4]) 0 257023
Layer  0  loss:  3.460763692855835 0.0 8.969457626342773
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1023
Curr loss timestep torch.Size([240, 4]) tensor([ 85, 161, 216,  62], device='cuda:0') tensor(109, device='cuda:0')
bi 0 loss 3.5320820808410645
bi 1 loss 3.4350485801696777
bi 2 loss 3.5735840797424316
bi 3 loss 3.2607204914093018
Layer  1  loss:  4.067347049713135 0.0 10.541021347045898
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([109, 179, 170,  67], device='cuda:0') tensor(109, device='cuda:0')
bi 0 loss 3.8459079265594482
bi 1 loss 3.852001428604126
bi 2 loss 4.296862602233887
bi 3 loss 4.1723551750183105
Layer  2  loss:  4.154893398284912 0.0 9.839977264404297
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([109, 174, 150, 118], device='cuda:0') tensor(109, device='cuda:0')
bi 0 loss 3.7099578380584717
bi 1 loss 4.0863471031188965
bi 2 loss 4.410416603088379
bi 3 loss 4.2092366218566895
Layer  3  loss:  4.4154767990112305 0.0 10.120210647583008
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([ 90, 169, 174, 112], device='cuda:0') tensor(107, device='cuda:0')
bi 0 loss 4.1820831298828125
bi 1 loss 4.35774564743042
bi 2 loss 4.611621379852295
bi 3 loss 4.37580680847168
Layer  4  loss:  4.57355260848999 0.0 9.307479858398438
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([ 94, 179, 135, 118], device='cuda:0') tensor(112, device='cuda:0')
bi 0 loss 4.556855201721191
bi 1 loss 4.543833255767822
bi 2 loss 4.630500316619873
bi 3 loss 4.537411212921143
Layer  5  loss:  4.611444473266602 0.0 9.797362327575684
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1017
Curr loss timestep torch.Size([240, 4]) tensor([ 84,  95, 168,  93], device='cuda:0') tensor(108, device='cuda:0')
bi 0 loss 4.383049488067627
bi 1 loss 4.4653000831604
bi 2 loss 4.835437297821045
bi 3 loss 4.640110969543457
Layer  6  loss:  4.682546615600586 0.0 11.27320384979248
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1023
Curr loss timestep torch.Size([240, 4]) tensor([114, 112, 205,  92], device='cuda:0') tensor(112, device='cuda:0')
bi 0 loss 4.50719690322876
bi 1 loss 4.654862880706787
bi 2 loss 4.754401206970215
bi 3 loss 4.7497477531433105
Epoch 0: :   3%|▎         | 15852/600000 [05:55<3:38:37, v_num=12, reduced_train_loss=1.200, global_step=15850.0, consumed_samples=63404.0, train_step_timing in s=0.409]Epoch 0: :   3%|▎         | 15852/600000 [05:55<3:38:37, v_num=12, reduced_train_loss=32.90, global_step=15851.0, consumed_samples=63408.0, train_step_timing in s=0.224]loss mask original None

First layer loss:  0.01525075826793909 torch.Size([323, 4]) 0.8070404529571533 0.0
Max loss timestep torch.Size([323, 4]) tensor([298, 116, 183, 255], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.018265897408127785
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 1 loss 0.012401609681546688
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
bi 2 loss 0.013469587080180645
speech mask sum tensor(188, device='cuda:0') loss mask sum tensor(188, device='cuda:0')
bi 3 loss 0.02052583172917366
speech mask sum tensor(62, device='cuda:0') loss mask sum tensor(62, device='cuda:0')
logits torch.Size([323, 4, 257024]) labels torch.Size([323, 4]) 0 257023
Layer  0  loss:  0.019051875919103622 0.0 4.337465286254883
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1023
Curr loss timestep torch.Size([323, 4]) tensor([299, 290, 170, 244], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.03260759636759758
bi 1 loss 0.013779792934656143
bi 2 loss 0.010715088807046413
bi 3 loss 0.01154897827655077
Layer  1  loss:  0.014081001281738281 0.0 0.7560868263244629
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1023
Curr loss timestep torch.Size([323, 4]) tensor([299, 215, 135, 232], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.01864410936832428
bi 1 loss 0.012613789178431034
bi 2 loss 0.011274403892457485
bi 3 loss 0.010242068208754063
Layer  2  loss:  0.013377594761550426 0.0 0.7407070994377136
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([299, 163, 158, 262], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.016104672104120255
bi 1 loss 0.012229597195982933
bi 2 loss 0.011210734955966473
bi 3 loss 0.0137266144156456
Layer  3  loss:  0.020662665367126465 0.0 2.8203535079956055
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([299, 290, 223, 263], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.038974836468696594
bi 1 loss 0.011536827310919762
bi 2 loss 0.012023041024804115
bi 3 loss 0.01114034652709961
Layer  4  loss:  0.015511792153120041 0.0 1.8738577365875244
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1023
Curr loss timestep torch.Size([323, 4]) tensor([299, 105, 224, 259], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.02718445658683777
bi 1 loss 0.009402759373188019
bi 2 loss 0.01093337219208479
bi 3 loss 0.007873930037021637
Layer  5  loss:  0.02623824216425419 0.0 7.637337684631348
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([299, 283, 227, 254], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.05641593411564827
bi 1 loss 0.01256890781223774
bi 2 loss 0.00983167253434658
bi 3 loss 0.011268123053014278
Layer  6  loss:  0.016766102984547615 0.0 2.8501574993133545
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([299, 211, 230, 230], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.027265382930636406
bi 1 loss 0.011463924311101437
bi 2 loss 0.011382418684661388
bi 3 loss 0.012909533455967903
Epoch 0: :   3%|▎         | 15853/600000 [05:56<3:38:48, v_num=12, reduced_train_loss=32.90, global_step=15851.0, consumed_samples=63408.0, train_step_timing in s=0.224]Epoch 0: :   3%|▎         | 15853/600000 [05:56<3:38:48, v_num=12, reduced_train_loss=0.141, global_step=15852.0, consumed_samples=63412.0, train_step_timing in s=0.266]loss mask original None

First layer loss:  3.5269012451171875 torch.Size([456, 4]) 9.919744491577148 0.0
Max loss timestep torch.Size([456, 4]) tensor([181, 177, 353, 198], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 3.325772523880005
speech mask sum tensor(297, device='cuda:0') loss mask sum tensor(297, device='cuda:0')
bi 1 loss 3.163050651550293
speech mask sum tensor(103, device='cuda:0') loss mask sum tensor(103, device='cuda:0')
bi 2 loss 3.6390128135681152
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 3 loss 3.7155096530914307
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
logits torch.Size([456, 4, 257024]) labels torch.Size([456, 4]) 0 257023
Layer  0  loss:  4.0531744956970215 0.0 11.388370513916016
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([334, 213, 199, 153], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 3.888380765914917
bi 1 loss 3.764887809753418
bi 2 loss 4.086172103881836
bi 3 loss 4.285455226898193
Layer  1  loss:  4.346811294555664 0.0 11.536445617675781
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([ 89, 227, 253, 404], device='cuda:0') tensor(176, device='cuda:0')
bi 0 loss 4.288531303405762
bi 1 loss 3.9317445755004883
bi 2 loss 4.47036075592041
bi 3 loss 4.388341903686523
Layer  2  loss:  4.670535564422607 0.0 9.932229995727539
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([ 82, 224, 268, 246], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.397496223449707
bi 1 loss 4.397768974304199
bi 2 loss 4.896580219268799
bi 3 loss 4.744048118591309
Layer  3  loss:  4.798490047454834 0.0 10.010744094848633
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([185, 177, 246, 419], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.723440647125244
bi 1 loss 4.232082366943359
bi 2 loss 4.979530334472656
bi 3 loss 4.8332695960998535
Layer  4  loss:  4.951896667480469 0.0 10.241693496704102
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1022
Curr loss timestep torch.Size([456, 4]) tensor([153, 195, 164, 245], device='cuda:0') tensor(179, device='cuda:0')
bi 0 loss 4.9078264236450195
bi 1 loss 4.251219749450684
bi 2 loss 5.110234260559082
bi 3 loss 5.034398078918457
Layer  5  loss:  5.06308650970459 0.0 10.265105247497559
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([320, 201, 176, 379], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 5.0214080810546875
bi 1 loss 4.4749274253845215
bi 2 loss 5.162957191467285
bi 3 loss 5.182907581329346
Layer  6  loss:  5.069063663482666 0.0 10.973750114440918
logits torch.Size([456, 4, 1024]) labels torch.Size([456, 4]) 0 1023
Curr loss timestep torch.Size([456, 4]) tensor([263, 248, 176, 410], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 5.108311176300049
bi 1 loss 4.381618976593018
bi 2 loss 5.195399761199951
bi 3 loss 5.103524684906006
Epoch 0: :   3%|▎         | 15854/600000 [05:56<3:39:00, v_num=12, reduced_train_loss=0.141, global_step=15852.0, consumed_samples=63412.0, train_step_timing in s=0.266]Epoch 0: :   3%|▎         | 15854/600000 [05:56<3:39:00, v_num=12, reduced_train_loss=36.50, global_step=15853.0, consumed_samples=63416.0, train_step_timing in s=0.322]loss mask original None

First layer loss:  0.11659150570631027 torch.Size([490, 4]) 10.266778945922852 0.0
Max loss timestep torch.Size([490, 4]) tensor([322, 359, 399, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.11156853288412094
speech mask sum tensor(386, device='cuda:0') loss mask sum tensor(386, device='cuda:0')
bi 1 loss 0.060378480702638626
speech mask sum tensor(379, device='cuda:0') loss mask sum tensor(379, device='cuda:0')
bi 2 loss 0.17048455774784088
speech mask sum tensor(237, device='cuda:0') loss mask sum tensor(237, device='cuda:0')
bi 3 loss 0.17288696765899658
speech mask sum tensor(186, device='cuda:0') loss mask sum tensor(186, device='cuda:0')
logits torch.Size([490, 4, 257024]) labels torch.Size([490, 4]) 0 257022
Layer  0  loss:  0.14056396484375 0.0 11.375446319580078
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([322, 360, 308, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.15070228278636932
bi 1 loss 0.04984872415661812
bi 2 loss 0.1797046959400177
bi 3 loss 0.25449588894844055
Layer  1  loss:  0.15179021656513214 0.0 10.875408172607422
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([322, 359, 308, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.14548327028751373
bi 1 loss 0.0963834673166275
bi 2 loss 0.20120854675769806
bi 3 loss 0.21480894088745117
Layer  2  loss:  0.13921137154102325 0.0 10.739030838012695
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([326, 359, 399, 353], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 0.13203220069408417
bi 1 loss 0.10038362443447113
bi 2 loss 0.19337591528892517
bi 3 loss 0.1642107367515564
Layer  3  loss:  0.1670372188091278 0.0 11.792454719543457
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([322, 340, 308, 352], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.13299918174743652
bi 1 loss 0.1421719789505005
bi 2 loss 0.24896997213363647
bi 3 loss 0.18394343554973602
Layer  4  loss:  0.1540803462266922 0.0 15.482213973999023
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1022
Curr loss timestep torch.Size([490, 4]) tensor([322, 340, 399, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.14828243851661682
bi 1 loss 0.10037802159786224
bi 2 loss 0.20709224045276642
bi 3 loss 0.207990825176239
Layer  5  loss:  0.1588382124900818 0.0 12.463129997253418
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([322, 359, 308, 353], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.11673703044652939
bi 1 loss 0.10860732942819595
bi 2 loss 0.2450580894947052
bi 3 loss 0.23870088160037994
Layer  6  loss:  0.16350261867046356 0.0 10.889945030212402
logits torch.Size([490, 4, 1024]) labels torch.Size([490, 4]) 0 1023
Curr loss timestep torch.Size([490, 4]) tensor([481, 359, 399, 353], device='cuda:0') tensor(399, device='cuda:0')
bi 0 loss 0.14366590976715088
bi 1 loss 0.11039048433303833
bi 2 loss 0.2510245740413666
bi 3 loss 0.20137231051921844
Epoch 0: :   3%|▎         | 15855/600000 [05:57<3:39:13, v_num=12, reduced_train_loss=36.50, global_step=15853.0, consumed_samples=63416.0, train_step_timing in s=0.322]Epoch 0: :   3%|▎         | 15855/600000 [05:57<3:39:13, v_num=12, reduced_train_loss=1.190, global_step=15854.0, consumed_samples=63420.0, train_step_timing in s=0.344]loss mask original None

First layer loss:  0.08010154962539673 torch.Size([567, 4]) 5.552151679992676 0.0
Max loss timestep torch.Size([567, 4]) tensor([478, 187, 173, 331], device='cuda:0') tensor(478, device='cuda:0')
bi 0 loss 0.11018097400665283
speech mask sum tensor(292, device='cuda:0') loss mask sum tensor(292, device='cuda:0')
bi 1 loss 0.035841625183820724
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 2 loss 0.01263432763516903
speech mask sum tensor(99, device='cuda:0') loss mask sum tensor(99, device='cuda:0')
bi 3 loss 0.09328419715166092
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
logits torch.Size([567, 4, 257024]) labels torch.Size([567, 4]) 0 257023
Layer  0  loss:  0.09013567864894867 0.0 7.918392658233643
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([546, 152, 168, 301], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.13675256073474884
bi 1 loss 0.03779102489352226
bi 2 loss 0.026838727295398712
bi 3 loss 0.07458869367837906
Layer  1  loss:  0.08454948663711548 0.0 3.425332546234131
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1022
Curr loss timestep torch.Size([567, 4]) tensor([546, 168, 180, 299], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.12615159153938293
bi 1 loss 0.015689069405198097
bi 2 loss 0.030091216787695885
bi 3 loss 0.08273176103830338
Layer  2  loss:  0.09837347269058228 0.0 10.28999137878418
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1022
Curr loss timestep torch.Size([567, 4]) tensor([546, 130, 133, 406], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.15828871726989746
bi 1 loss 0.03836078941822052
bi 2 loss 0.022005543112754822
bi 3 loss 0.07085021585226059
Layer  3  loss:  0.11723042279481888 0.0 7.0023884773254395
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1022
Curr loss timestep torch.Size([567, 4]) tensor([368, 151, 133, 308], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.179498091340065
bi 1 loss 0.03917362913489342
bi 2 loss 0.02518579736351967
bi 3 loss 0.10612527281045914
Layer  4  loss:  0.09239650517702103 0.0 7.838422775268555
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([546, 128, 140, 301], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.110868901014328
bi 1 loss 0.04091055318713188
bi 2 loss 0.02858711965382099
bi 3 loss 0.12933796644210815
Layer  5  loss:  0.12908293306827545 0.0 11.154263496398926
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1023
Curr loss timestep torch.Size([567, 4]) tensor([546, 126, 193, 301], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.18293914198875427
bi 1 loss 0.047653742134571075
bi 2 loss 0.03978044167160988
bi 3 loss 0.13401417434215546
Layer  6  loss:  0.08766940981149673 0.0 5.343920707702637
logits torch.Size([567, 4, 1024]) labels torch.Size([567, 4]) 0 1022
Curr loss timestep torch.Size([567, 4]) tensor([546, 191, 195, 301], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.13044960796833038
bi 1 loss 0.029408158734440804
bi 2 loss 0.016226891428232193
bi 3 loss 0.08803831040859222
Epoch 0: :   3%|▎         | 15856/600000 [05:57<3:39:28, v_num=12, reduced_train_loss=1.190, global_step=15854.0, consumed_samples=63420.0, train_step_timing in s=0.344]Epoch 0: :   3%|▎         | 15856/600000 [05:57<3:39:28, v_num=12, reduced_train_loss=0.780, global_step=15855.0, consumed_samples=63424.0, train_step_timing in s=0.391]loss mask original None

First layer loss:  0.13973821699619293 torch.Size([599, 4]) 12.890002250671387 0.0
Max loss timestep torch.Size([599, 4]) tensor([307,  85, 331, 486], device='cuda:0') tensor(486, device='cuda:0')
bi 0 loss 0.16597510874271393
speech mask sum tensor(243, device='cuda:0') loss mask sum tensor(243, device='cuda:0')
bi 1 loss 0.11060589551925659
speech mask sum tensor(433, device='cuda:0') loss mask sum tensor(433, device='cuda:0')
bi 2 loss 0.06628307700157166
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
bi 3 loss 0.20795972645282745
speech mask sum tensor(422, device='cuda:0') loss mask sum tensor(422, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257022
Layer  0  loss:  0.14867541193962097 0.0 14.879587173461914
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([411, 284, 361, 576], device='cuda:0') tensor(576, device='cuda:0')
bi 0 loss 0.11650802195072174
bi 1 loss 0.11290348321199417
bi 2 loss 0.13181759417057037
bi 3 loss 0.21616658568382263
Layer  1  loss:  0.15870888531208038 0.0 11.44088363647461
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([404, 420, 353, 509], device='cuda:0') tensor(509, device='cuda:0')
bi 0 loss 0.1256239414215088
bi 1 loss 0.12229570746421814
bi 2 loss 0.12940633296966553
bi 3 loss 0.23643973469734192
Layer  2  loss:  0.16499687731266022 0.0 11.855106353759766
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([306, 304, 360, 576], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.1274525374174118
bi 1 loss 0.14563393592834473
bi 2 loss 0.15387354791164398
bi 3 loss 0.21457578241825104
Layer  3  loss:  0.17323942482471466 0.0 11.465960502624512
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1021
Curr loss timestep torch.Size([599, 4]) tensor([411, 292, 361, 509], device='cuda:0') tensor(509, device='cuda:0')
bi 0 loss 0.12347453087568283
bi 1 loss 0.12574559450149536
bi 2 loss 0.16723133623600006
bi 3 loss 0.25499817728996277
Layer  4  loss:  0.17690080404281616 0.0 9.86143970489502
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([367, 370, 361, 509], device='cuda:0') tensor(509, device='cuda:0')
bi 0 loss 0.1755688488483429
bi 1 loss 0.14734531939029694
bi 2 loss 0.1396172046661377
bi 3 loss 0.2351170778274536
Layer  5  loss:  0.1807301789522171 0.0 10.501220703125
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([307, 371, 353, 509], device='cuda:0') tensor(509, device='cuda:0')
bi 0 loss 0.18693988025188446
bi 1 loss 0.13221028447151184
bi 2 loss 0.158046692609787
bi 3 loss 0.24344103038311005
Layer  6  loss:  0.1582215428352356 0.0 9.324341773986816
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([303, 370, 353, 572], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.14402957260608673
bi 1 loss 0.11912909895181656
bi 2 loss 0.15340334177017212
bi 3 loss 0.2100103348493576
Epoch 0: :   3%|▎         | 15857/600000 [05:57<3:39:44, v_num=12, reduced_train_loss=0.780, global_step=15855.0, consumed_samples=63424.0, train_step_timing in s=0.391]Epoch 0: :   3%|▎         | 15857/600000 [05:57<3:39:44, v_num=12, reduced_train_loss=1.300, global_step=15856.0, consumed_samples=63428.0, train_step_timing in s=0.412]loss mask original None

First layer loss:  0.16141881048679352 torch.Size([758, 4]) 6.838990688323975 0.0
Max loss timestep torch.Size([758, 4]) tensor([320, 583, 324, 124], device='cuda:0') tensor(583, device='cuda:0')
bi 0 loss 0.08224373310804367
speech mask sum tensor(264, device='cuda:0') loss mask sum tensor(264, device='cuda:0')
bi 1 loss 0.23914262652397156
speech mask sum tensor(477, device='cuda:0') loss mask sum tensor(477, device='cuda:0')
bi 2 loss 0.11123199760913849
speech mask sum tensor(250, device='cuda:0') loss mask sum tensor(250, device='cuda:0')
bi 3 loss 0.02198299951851368
speech mask sum tensor(26, device='cuda:0') loss mask sum tensor(26, device='cuda:0')
logits torch.Size([758, 4, 257024]) labels torch.Size([758, 4]) 0 257022
Layer  0  loss:  0.18808047473430634 0.0 16.328235626220703
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1023
Curr loss timestep torch.Size([758, 4]) tensor([315, 573, 324, 127], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.06639250367879868
bi 1 loss 0.2508435547351837
bi 2 loss 0.21524052321910858
bi 3 loss 0.011066094972193241
Layer  1  loss:  0.20428888499736786 0.0 10.641704559326172
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1022
Curr loss timestep torch.Size([758, 4]) tensor([317, 386, 314, 128], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.06444386392831802
bi 1 loss 0.3146577477455139
bi 2 loss 0.15933410823345184
bi 3 loss 0.03166661411523819
Layer  2  loss:  0.253471702337265 0.0 12.836181640625
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1022
Curr loss timestep torch.Size([758, 4]) tensor([320, 566, 324, 140], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.07275039702653885
bi 1 loss 0.37569743394851685
bi 2 loss 0.23187871277332306
bi 3 loss 0.05374179035425186
Layer  3  loss:  0.23213595151901245 0.0 13.121908187866211
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1022
Curr loss timestep torch.Size([758, 4]) tensor([354, 386, 324, 137], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.053142648190259933
bi 1 loss 0.3724345266819
bi 2 loss 0.17058315873146057
bi 3 loss 0.06752120703458786
Layer  4  loss:  0.21263420581817627 0.0 10.42829704284668
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1023
Curr loss timestep torch.Size([758, 4]) tensor([320, 390, 314, 128], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.08131061494350433
bi 1 loss 0.3088350296020508
bi 2 loss 0.18744492530822754
bi 3 loss 0.023363618180155754
Layer  5  loss:  0.3246038854122162 0.0 9.603838920593262
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1021
Curr loss timestep torch.Size([758, 4]) tensor([320, 719, 314, 128], device='cuda:0') tensor(386, device='cuda:0')
bi 0 loss 0.12973175942897797
bi 1 loss 0.517815887928009
bi 2 loss 0.19413809478282928
bi 3 loss 0.01308776531368494
Layer  6  loss:  0.25441330671310425 0.0 11.158044815063477
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1023
Curr loss timestep torch.Size([758, 4]) tensor([389, 386, 314, 137], device='cuda:0') tensor(314, device='cuda:0')
bi 0 loss 0.15895719826221466
bi 1 loss 0.33483752608299255
bi 2 loss 0.225997194647789
bi 3 loss 0.021416116505861282
Epoch 0: :   3%|▎         | 15858/600000 [05:58<3:40:03, v_num=12, reduced_train_loss=1.300, global_step=15856.0, consumed_samples=63428.0, train_step_timing in s=0.412]Epoch 0: :   3%|▎         | 15858/600000 [05:58<3:40:03, v_num=12, reduced_train_loss=1.830, global_step=15857.0, consumed_samples=63432.0, train_step_timing in s=0.519]loss mask original None

First layer loss:  0.1005471795797348 torch.Size([489, 4]) 18.283161163330078 0.0
Max loss timestep torch.Size([489, 4]) tensor([288, 452, 274, 463], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.09102044999599457
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 1 loss 0.17263124883174896
speech mask sum tensor(380, device='cuda:0') loss mask sum tensor(380, device='cuda:0')
bi 2 loss 0.038675468415021896
speech mask sum tensor(240, device='cuda:0') loss mask sum tensor(240, device='cuda:0')
bi 3 loss 0.06656800955533981
speech mask sum tensor(331, device='cuda:0') loss mask sum tensor(331, device='cuda:0')
logits torch.Size([489, 4, 257024]) labels torch.Size([489, 4]) 0 257022
Layer  0  loss:  0.0778268426656723 0.0 8.912911415100098
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1023
Curr loss timestep torch.Size([489, 4]) tensor([248, 450, 274, 434], device='cuda:0') tensor(450, device='cuda:0')
bi 0 loss 0.049881462007761
bi 1 loss 0.09447889029979706
bi 2 loss 0.058981753885746
bi 3 loss 0.08385588228702545
Layer  1  loss:  0.08096779882907867 0.0 7.255520820617676
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([288, 452, 274, 437], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.08793965727090836
bi 1 loss 0.0978778526186943
bi 2 loss 0.06424252688884735
bi 3 loss 0.07081693410873413
Layer  2  loss:  0.10131179541349411 0.0 12.094338417053223
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([315, 452, 274, 434], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.057778436690568924
bi 1 loss 0.164649099111557
bi 2 loss 0.06345701217651367
bi 3 loss 0.07393266260623932
Layer  3  loss:  0.08377369493246078 0.0 12.814391136169434
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1023
Curr loss timestep torch.Size([489, 4]) tensor([239, 452, 274, 169], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.05336543545126915
bi 1 loss 0.14613161981105804
bi 2 loss 0.042985644191503525
bi 3 loss 0.05425295978784561
Layer  4  loss:  0.0794462338089943 0.0 12.79768180847168
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([288, 451, 291, 434], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.07945574820041656
bi 1 loss 0.11649998277425766
bi 2 loss 0.03390425816178322
bi 3 loss 0.06992463767528534
Layer  5  loss:  0.09396490454673767 0.0 8.752948760986328
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1017
Curr loss timestep torch.Size([489, 4]) tensor([289, 451, 291, 434], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.0419364869594574
bi 1 loss 0.15068313479423523
bi 2 loss 0.05091448500752449
bi 3 loss 0.08144237846136093
Layer  6  loss:  0.0785110592842102 0.0 7.421256065368652
logits torch.Size([489, 4, 1024]) labels torch.Size([489, 4]) 0 1022
Curr loss timestep torch.Size([489, 4]) tensor([286, 369, 274, 434], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 0.07655583322048187
bi 1 loss 0.11262305080890656
bi 2 loss 0.04892091080546379
bi 3 loss 0.06160770729184151
Epoch 0: :   3%|▎         | 15859/600000 [05:58<3:40:16, v_num=12, reduced_train_loss=1.830, global_step=15857.0, consumed_samples=63432.0, train_step_timing in s=0.519]Epoch 0: :   3%|▎         | 15859/600000 [05:58<3:40:16, v_num=12, reduced_train_loss=0.696, global_step=15858.0, consumed_samples=63436.0, train_step_timing in s=0.342]loss mask original None

First layer loss:  0.10218982398509979 torch.Size([649, 4]) 11.458965301513672 0.0
Max loss timestep torch.Size([649, 4]) tensor([ 88, 307, 452, 181], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.0139034204185009
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 1 loss 0.2029387652873993
speech mask sum tensor(309, device='cuda:0') loss mask sum tensor(309, device='cuda:0')
bi 2 loss 0.0913841500878334
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
bi 3 loss 0.039905235171318054
speech mask sum tensor(340, device='cuda:0') loss mask sum tensor(340, device='cuda:0')
logits torch.Size([649, 4, 257024]) labels torch.Size([649, 4]) 0 257022
Layer  0  loss:  0.13825400173664093 0.0 11.525444030761719
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1023
Curr loss timestep torch.Size([649, 4]) tensor([ 73, 307, 424, 183], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.02438976615667343
bi 1 loss 0.13971051573753357
bi 2 loss 0.24766093492507935
bi 3 loss 0.036111488938331604
Layer  1  loss:  0.1613917350769043 0.0 14.05557918548584
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([ 96, 307, 594, 358], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.019207598641514778
bi 1 loss 0.18565425276756287
bi 2 loss 0.2862054109573364
bi 3 loss 0.026710033416748047
Layer  2  loss:  0.15725204348564148 0.0 14.989641189575195
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([ 92, 307, 594, 356], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.018739650025963783
bi 1 loss 0.19637709856033325
bi 2 loss 0.2447068840265274
bi 3 loss 0.05032387375831604
Layer  3  loss:  0.16006793081760406 0.0 12.25049114227295
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1021
Curr loss timestep torch.Size([649, 4]) tensor([ 87, 307, 319, 180], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.03829313814640045
bi 1 loss 0.16729530692100525
bi 2 loss 0.289015531539917
bi 3 loss 0.03226170688867569
Layer  4  loss:  0.15212243795394897 0.0 14.048700332641602
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1022
Curr loss timestep torch.Size([649, 4]) tensor([ 89, 309, 319, 335], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.019554346799850464
bi 1 loss 0.19898398220539093
bi 2 loss 0.2295713573694229
bi 3 loss 0.04825123772025108
Layer  5  loss:  0.16900698840618134 0.0 16.271516799926758
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1019
Curr loss timestep torch.Size([649, 4]) tensor([ 94, 307, 319, 156], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 0.01820414699614048
bi 1 loss 0.19860990345478058
bi 2 loss 0.29165834188461304
bi 3 loss 0.03357426077127457
Layer  6  loss:  0.17395256459712982 0.0 15.322970390319824
logits torch.Size([649, 4, 1024]) labels torch.Size([649, 4]) 0 1019
Curr loss timestep torch.Size([649, 4]) tensor([ 92, 307, 319, 294], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.02072867564857006
bi 1 loss 0.17677807807922363
bi 2 loss 0.3140246570110321
bi 3 loss 0.0437530018389225
Epoch 0: :   3%|▎         | 15860/600000 [05:59<3:40:33, v_num=12, reduced_train_loss=0.696, global_step=15858.0, consumed_samples=63436.0, train_step_timing in s=0.342]Epoch 0: :   3%|▎         | 15860/600000 [05:59<3:40:33, v_num=12, reduced_train_loss=1.210, global_step=15859.0, consumed_samples=63440.0, train_step_timing in s=0.443]loss mask original None

First layer loss:  0.12785343825817108 torch.Size([599, 4]) 10.774759292602539 0.0
Max loss timestep torch.Size([599, 4]) tensor([460, 485, 293, 290], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.10874087363481522
speech mask sum tensor(379, device='cuda:0') loss mask sum tensor(379, device='cuda:0')
bi 1 loss 0.17841149866580963
speech mask sum tensor(394, device='cuda:0') loss mask sum tensor(394, device='cuda:0')
bi 2 loss 0.13855618238449097
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 3 loss 0.06147162243723869
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
logits torch.Size([599, 4, 257024]) labels torch.Size([599, 4]) 0 257022
Layer  0  loss:  0.16366760432720184 0.0 7.022723197937012
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([344, 581, 349, 134], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 0.1543813794851303
bi 1 loss 0.20789596438407898
bi 2 loss 0.16595135629177094
bi 3 loss 0.10540208965539932
Layer  1  loss:  0.1616843044757843 0.0 10.665213584899902
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1023
Curr loss timestep torch.Size([599, 4]) tensor([397, 484, 349, 112], device='cuda:0') tensor(484, device='cuda:0')
bi 0 loss 0.17408724129199982
bi 1 loss 0.21296605467796326
bi 2 loss 0.16148439049720764
bi 3 loss 0.06393805146217346
Layer  2  loss:  0.18734732270240784 0.0 9.011466979980469
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([344, 570, 293, 300], device='cuda:0') tensor(344, device='cuda:0')
bi 0 loss 0.17893953621387482
bi 1 loss 0.25338825583457947
bi 2 loss 0.20959480106830597
bi 3 loss 0.06320429593324661
Layer  3  loss:  0.21402773261070251 0.0 11.314303398132324
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1021
Curr loss timestep torch.Size([599, 4]) tensor([397, 484, 286, 286], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.19867345690727234
bi 1 loss 0.31768691539764404
bi 2 loss 0.21320514380931854
bi 3 loss 0.07741036266088486
Layer  4  loss:  0.2083689421415329 0.0 17.750043869018555
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([504, 484, 349, 302], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.17918750643730164
bi 1 loss 0.26872509717941284
bi 2 loss 0.2631876766681671
bi 3 loss 0.07390158623456955
Layer  5  loss:  0.18731361627578735 0.0 9.509727478027344
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([397, 586, 286,  86], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.19386319816112518
bi 1 loss 0.25463438034057617
bi 2 loss 0.20704251527786255
bi 3 loss 0.042744092643260956
Layer  6  loss:  0.2180265486240387 0.0 11.871111869812012
logits torch.Size([599, 4, 1024]) labels torch.Size([599, 4]) 0 1022
Curr loss timestep torch.Size([599, 4]) tensor([460, 581, 445, 144], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.20347155630588531
bi 1 loss 0.29464688897132874
bi 2 loss 0.23127761483192444
bi 3 loss 0.10049416124820709
Epoch 0: :   3%|▎         | 15861/600000 [05:59<3:40:49, v_num=12, reduced_train_loss=1.210, global_step=15859.0, consumed_samples=63440.0, train_step_timing in s=0.443]Epoch 0: :   3%|▎         | 15861/600000 [05:59<3:40:49, v_num=12, reduced_train_loss=1.470, global_step=15860.0, consumed_samples=63444.0, train_step_timing in s=0.413]loss mask original None

First layer loss:  0.0169486403465271 torch.Size([429, 4]) 0.2607429623603821 0.0
Max loss timestep torch.Size([429, 4]) tensor([175, 137, 206, 237], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 0.015587876550853252
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 1 loss 0.016129612922668457
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 2 loss 0.014934878796339035
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 3 loss 0.01862505078315735
speech mask sum tensor(342, device='cuda:0') loss mask sum tensor(342, device='cuda:0')
logits torch.Size([429, 4, 257024]) labels torch.Size([429, 4]) 0 257023
Layer  0  loss:  0.0213147085160017 0.0 1.1159087419509888
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1023
Curr loss timestep torch.Size([429, 4]) tensor([161,  92, 281, 281], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.019475551322102547
bi 1 loss 0.013929836452007294
bi 2 loss 0.01721654087305069
bi 3 loss 0.02598763071000576
Layer  1  loss:  0.01957097463309765 0.0 1.1917588710784912
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([158,  85, 269, 281], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.016725527122616768
bi 1 loss 0.015935471281409264
bi 2 loss 0.013209098018705845
bi 3 loss 0.02453179471194744
Layer  2  loss:  0.018326101824641228 0.0 0.36675944924354553
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([212, 117, 207, 336], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.017086025327444077
bi 1 loss 0.019059646874666214
bi 2 loss 0.011707840487360954
bi 3 loss 0.02140706405043602
Layer  3  loss:  0.021895188838243484 0.0 2.806183338165283
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1021
Curr loss timestep torch.Size([429, 4]) tensor([209, 123, 172, 281], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.015458757057785988
bi 1 loss 0.014940086752176285
bi 2 loss 0.014734701253473759
bi 3 loss 0.029743729159235954
Layer  4  loss:  0.018725303933024406 0.0 0.5179063081741333
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([161, 142, 268, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.020604291930794716
bi 1 loss 0.016590911895036697
bi 2 loss 0.013792365789413452
bi 3 loss 0.020567957311868668
Layer  5  loss:  0.02691357582807541 0.0 4.872409343719482
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1023
Curr loss timestep torch.Size([429, 4]) tensor([114, 138, 272, 281], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.01927085965871811
bi 1 loss 0.01719760335981846
bi 2 loss 0.017174063250422478
bi 3 loss 0.03717280924320221
Layer  6  loss:  0.020494453608989716 0.0 1.5768730640411377
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1023
Curr loss timestep torch.Size([429, 4]) tensor([210,  70, 194, 281], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.013852274045348167
bi 1 loss 0.017760848626494408
bi 2 loss 0.014877264387905598
bi 3 loss 0.026558691635727882
Epoch 0: :   3%|▎         | 15862/600000 [06:00<3:41:02, v_num=12, reduced_train_loss=1.470, global_step=15860.0, consumed_samples=63444.0, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15862/600000 [06:00<3:41:02, v_num=12, reduced_train_loss=0.164, global_step=15861.0, consumed_samples=63448.0, train_step_timing in s=0.332]loss mask original None

First layer loss:  3.3146016597747803 torch.Size([508, 4]) 13.082605361938477 0.0
Max loss timestep torch.Size([508, 4]) tensor([391, 458, 233,  77], device='cuda:0') tensor(197, device='cuda:0')
bi 0 loss 3.9862875938415527
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
bi 1 loss 2.538444757461548
speech mask sum tensor(333, device='cuda:0') loss mask sum tensor(333, device='cuda:0')
bi 2 loss 3.4072906970977783
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
bi 3 loss 3.1823315620422363
speech mask sum tensor(150, device='cuda:0') loss mask sum tensor(150, device='cuda:0')
logits torch.Size([508, 4, 257024]) labels torch.Size([508, 4]) 0 257022
Layer  0  loss:  3.8120923042297363 0.0 10.326627731323242
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([192, 429, 323,  77], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 4.3840107917785645
bi 1 loss 3.18957781791687
bi 2 loss 3.659132719039917
bi 3 loss 4.144549369812012
Layer  1  loss:  4.098163604736328 0.0 10.956315994262695
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([226, 202, 412, 147], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.605730056762695
bi 1 loss 3.400881767272949
bi 2 loss 4.1822991371154785
bi 3 loss 4.211895942687988
Layer  2  loss:  4.305354595184326 0.0 11.262170791625977
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([313, 426, 454, 113], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 4.82462739944458
bi 1 loss 3.472233533859253
bi 2 loss 4.355093479156494
bi 3 loss 4.770660400390625
Layer  3  loss:  4.472822189331055 0.0 12.792160034179688
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([245, 207, 250,  71], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.912660121917725
bi 1 loss 3.5598647594451904
bi 2 loss 4.578490734100342
bi 3 loss 5.181822776794434
Layer  4  loss:  4.5946364402771 0.0 10.427013397216797
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([188, 430, 423, 128], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 5.225483417510986
bi 1 loss 3.677690267562866
bi 2 loss 4.532498359680176
bi 3 loss 5.228874683380127
Layer  5  loss:  4.691948890686035 0.0 10.793265342712402
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1022
Curr loss timestep torch.Size([508, 4]) tensor([123, 203, 281,  70], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 5.234550476074219
bi 1 loss 3.9194650650024414
bi 2 loss 4.580233097076416
bi 3 loss 5.334752559661865
Layer  6  loss:  4.681868553161621 0.0 12.112142562866211
logits torch.Size([508, 4, 1024]) labels torch.Size([508, 4]) 0 1023
Curr loss timestep torch.Size([508, 4]) tensor([290, 471, 426, 199], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 5.216555595397949
bi 1 loss 3.7907297611236572
bi 2 loss 4.675694942474365
bi 3 loss 5.366114139556885
Epoch 0: :   3%|▎         | 15863/600000 [06:00<3:41:15, v_num=12, reduced_train_loss=0.164, global_step=15861.0, consumed_samples=63448.0, train_step_timing in s=0.332]Epoch 0: :   3%|▎         | 15863/600000 [06:00<3:41:15, v_num=12, reduced_train_loss=34.00, global_step=15862.0, consumed_samples=63452.0, train_step_timing in s=0.339]loss mask original None

First layer loss:  0.04856158420443535 torch.Size([543, 4]) 5.724391460418701 0.0
Max loss timestep torch.Size([543, 4]) tensor([270,  64, 154, 393], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.06546993553638458
speech mask sum tensor(438, device='cuda:0') loss mask sum tensor(438, device='cuda:0')
bi 1 loss 0.030181117355823517
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 2 loss 0.027934186160564423
speech mask sum tensor(213, device='cuda:0') loss mask sum tensor(213, device='cuda:0')
bi 3 loss 0.05544624477624893
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
logits torch.Size([543, 4, 257024]) labels torch.Size([543, 4]) 0 257023
Layer  0  loss:  0.056430116295814514 0.0 7.314245700836182
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([276, 166, 179, 200], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.08464205265045166
bi 1 loss 0.03952886909246445
bi 2 loss 0.03330574557185173
bi 3 loss 0.04732520133256912
Layer  1  loss:  0.06564246118068695 0.0 4.938899993896484
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1022
Curr loss timestep torch.Size([543, 4]) tensor([509, 257,  58, 453], device='cuda:0') tensor(509, device='cuda:0')
bi 0 loss 0.10104861110448837
bi 1 loss 0.03418884798884392
bi 2 loss 0.037063512951135635
bi 3 loss 0.06329832971096039
Layer  2  loss:  0.06873419135808945 0.0 6.6860857009887695
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([275, 157, 211, 439], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.09753032773733139
bi 1 loss 0.06132369488477707
bi 2 loss 0.0528041236102581
bi 3 loss 0.045002736151218414
Layer  3  loss:  0.07184873521327972 0.0 7.503559112548828
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1022
Curr loss timestep torch.Size([543, 4]) tensor([509, 296, 113, 357], device='cuda:0') tensor(509, device='cuda:0')
bi 0 loss 0.11630924046039581
bi 1 loss 0.036566220223903656
bi 2 loss 0.028635092079639435
bi 3 loss 0.07020657509565353
Layer  4  loss:  0.0785726010799408 0.0 5.384612083435059
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1023
Curr loss timestep torch.Size([543, 4]) tensor([428, 167, 109, 341], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.1316342055797577
bi 1 loss 0.05039779841899872
bi 2 loss 0.02635418437421322
bi 3 loss 0.0642877072095871
Layer  5  loss:  0.08401976525783539 0.0 7.439408302307129
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1022
Curr loss timestep torch.Size([543, 4]) tensor([276,  82, 108, 283], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.16726054251194
bi 1 loss 0.03645167872309685
bi 2 loss 0.026146065443754196
bi 3 loss 0.04774162545800209
Layer  6  loss:  0.08082378655672073 0.0 8.127686500549316
logits torch.Size([543, 4, 1024]) labels torch.Size([543, 4]) 0 1021
Curr loss timestep torch.Size([543, 4]) tensor([276, 304,  62, 300], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.13494247198104858
bi 1 loss 0.0470128059387207
bi 2 loss 0.030955815687775612
bi 3 loss 0.06851764768362045
Epoch 0: :   3%|▎         | 15864/600000 [06:00<3:41:30, v_num=12, reduced_train_loss=34.00, global_step=15862.0, consumed_samples=63452.0, train_step_timing in s=0.339]Epoch 0: :   3%|▎         | 15864/600000 [06:00<3:41:30, v_num=12, reduced_train_loss=0.555, global_step=15863.0, consumed_samples=63456.0, train_step_timing in s=0.390]loss mask original None

First layer loss:  0.11921266466379166 torch.Size([538, 4]) 14.876715660095215 0.0
Max loss timestep torch.Size([538, 4]) tensor([211, 271, 510, 216], device='cuda:0') tensor(510, device='cuda:0')
bi 0 loss 0.035225268453359604
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 1 loss 0.07109582424163818
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 2 loss 0.2050532102584839
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
bi 3 loss 0.02922959439456463
speech mask sum tensor(61, device='cuda:0') loss mask sum tensor(61, device='cuda:0')
logits torch.Size([538, 4, 257024]) labels torch.Size([538, 4]) 0 257022
Layer  0  loss:  0.12848128378391266 0.0 11.657262802124023
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([255, 411, 510, 207], device='cuda:0') tensor(510, device='cuda:0')
bi 0 loss 0.05215127021074295
bi 1 loss 0.12088963389396667
bi 2 loss 0.18489393591880798
bi 3 loss 0.035674095153808594
Layer  1  loss:  0.12048441171646118 0.0 16.354629516601562
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([148, 271, 515, 223], device='cuda:0') tensor(515, device='cuda:0')
bi 0 loss 0.04244000464677811
bi 1 loss 0.08822130411863327
bi 2 loss 0.19134089350700378
bi 3 loss 0.0417851060628891
Layer  2  loss:  0.1237792819738388 0.0 15.072294235229492
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1022
Curr loss timestep torch.Size([538, 4]) tensor([161, 266, 515, 223], device='cuda:0') tensor(515, device='cuda:0')
bi 0 loss 0.031809139996767044
bi 1 loss 0.13107749819755554
bi 2 loss 0.1779855191707611
bi 3 loss 0.030290527269244194
Layer  3  loss:  0.13134247064590454 0.0 14.982494354248047
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1021
Curr loss timestep torch.Size([538, 4]) tensor([222, 266, 514, 203], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.02863030508160591
bi 1 loss 0.11146846413612366
bi 2 loss 0.20941099524497986
bi 3 loss 0.03086153417825699
Layer  4  loss:  0.12487538903951645 0.0 10.725749969482422
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1022
Curr loss timestep torch.Size([538, 4]) tensor([299, 433, 515, 240], device='cuda:0') tensor(515, device='cuda:0')
bi 0 loss 0.05420249328017235
bi 1 loss 0.10132480412721634
bi 2 loss 0.19032835960388184
bi 3 loss 0.024134647101163864
Layer  5  loss:  0.15116074681282043 0.0 16.337446212768555
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1022
Curr loss timestep torch.Size([538, 4]) tensor([298, 266, 510, 226], device='cuda:0') tensor(510, device='cuda:0')
bi 0 loss 0.04653546214103699
bi 1 loss 0.11347252875566483
bi 2 loss 0.24468277394771576
bi 3 loss 0.03293211758136749
Layer  6  loss:  0.13917073607444763 0.0 15.134488105773926
logits torch.Size([538, 4, 1024]) labels torch.Size([538, 4]) 0 1023
Curr loss timestep torch.Size([538, 4]) tensor([299, 267, 515, 231], device='cuda:0') tensor(515, device='cuda:0')
bi 0 loss 0.04794720560312271
bi 1 loss 0.10743936896324158
bi 2 loss 0.21995408833026886
bi 3 loss 0.036241091787815094
Epoch 0: :   3%|▎         | 15865/600000 [06:01<3:41:44, v_num=12, reduced_train_loss=0.555, global_step=15863.0, consumed_samples=63456.0, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15865/600000 [06:01<3:41:44, v_num=12, reduced_train_loss=1.040, global_step=15864.0, consumed_samples=63460.0, train_step_timing in s=0.387]loss mask original None

First layer loss:  0.044025324285030365 torch.Size([429, 4]) 6.207449436187744 0.0
Max loss timestep torch.Size([429, 4]) tensor([242, 329, 242, 258], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.028363851830363274
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
bi 1 loss 0.05254726856946945
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
bi 2 loss 0.0388387106359005
speech mask sum tensor(245, device='cuda:0') loss mask sum tensor(245, device='cuda:0')
bi 3 loss 0.0857997015118599
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
logits torch.Size([429, 4, 257024]) labels torch.Size([429, 4]) 0 257022
Layer  0  loss:  0.04494930058717728 0.0 1.641087532043457
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1023
Curr loss timestep torch.Size([429, 4]) tensor([168, 329, 192, 294], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 0.03488049656152725
bi 1 loss 0.051691945642232895
bi 2 loss 0.03928034380078316
bi 3 loss 0.07522503286600113
Layer  1  loss:  0.045954037457704544 0.0 3.0146706104278564
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([175, 329,  76, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.03301369398832321
bi 1 loss 0.038327496498823166
bi 2 loss 0.04611153155565262
bi 3 loss 0.124871164560318
Layer  2  loss:  0.051357418298721313 0.0 2.704313039779663
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([ 66, 254, 116, 283], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 0.03069012425839901
bi 1 loss 0.07789163291454315
bi 2 loss 0.03947969526052475
bi 3 loss 0.06169812008738518
Layer  3  loss:  0.04974907264113426 0.0 3.0627994537353516
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1021
Curr loss timestep torch.Size([429, 4]) tensor([130, 280, 191, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.04034135118126869
bi 1 loss 0.049241773784160614
bi 2 loss 0.038176801055669785
bi 3 loss 0.1295928657054901
Layer  4  loss:  0.05269833654165268 0.0 2.2585668563842773
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([249, 329, 186, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.04791979864239693
bi 1 loss 0.06313685327768326
bi 2 loss 0.04138398543000221
bi 3 loss 0.06902900338172913
Layer  5  loss:  0.05053986608982086 0.0 3.5348520278930664
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1023
Curr loss timestep torch.Size([429, 4]) tensor([ 85, 323, 204, 273], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.027440153062343597
bi 1 loss 0.08076318353414536
bi 2 loss 0.030080920085310936
bi 3 loss 0.08641231060028076
Layer  6  loss:  0.060207802802324295 0.0 3.365027666091919
logits torch.Size([429, 4, 1024]) labels torch.Size([429, 4]) 0 1022
Curr loss timestep torch.Size([429, 4]) tensor([ 69, 326,  85, 264], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.03740239515900612
bi 1 loss 0.09101033955812454
bi 2 loss 0.0451556034386158
bi 3 loss 0.07251712679862976
Epoch 0: :   3%|▎         | 15866/600000 [06:01<3:41:56, v_num=12, reduced_train_loss=1.040, global_step=15864.0, consumed_samples=63460.0, train_step_timing in s=0.387]Epoch 0: :   3%|▎         | 15866/600000 [06:01<3:41:56, v_num=12, reduced_train_loss=0.399, global_step=15865.0, consumed_samples=63464.0, train_step_timing in s=0.315]loss mask original None

First layer loss:  0.13789156079292297 torch.Size([606, 4]) 9.825010299682617 0.0
Max loss timestep torch.Size([606, 4]) tensor([163, 280, 349, 479], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.019820567220449448
speech mask sum tensor(111, device='cuda:0') loss mask sum tensor(111, device='cuda:0')
bi 1 loss 0.1323847472667694
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 2 loss 0.21731024980545044
speech mask sum tensor(495, device='cuda:0') loss mask sum tensor(495, device='cuda:0')
bi 3 loss 0.07256881892681122
speech mask sum tensor(378, device='cuda:0') loss mask sum tensor(378, device='cuda:0')
logits torch.Size([606, 4, 257024]) labels torch.Size([606, 4]) 0 257022
Layer  0  loss:  0.18304353952407837 0.0 10.813103675842285
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([218, 367, 335, 480], device='cuda:0') tensor(480, device='cuda:0')
bi 0 loss 0.03201419115066528
bi 1 loss 0.1739201694726944
bi 2 loss 0.2432331144809723
bi 3 loss 0.15521110594272614
Layer  1  loss:  0.17183952033519745 0.0 11.939005851745605
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([231, 297, 349, 480], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.03419185057282448
bi 1 loss 0.11160730570554733
bi 2 loss 0.28032147884368896
bi 3 loss 0.11401987075805664
Layer  2  loss:  0.2135932743549347 0.0 14.985379219055176
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([162, 297, 584, 480], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 0.049226123839616776
bi 1 loss 0.24438221752643585
bi 2 loss 0.30933719873428345
bi 3 loss 0.11408150941133499
Layer  3  loss:  0.20230427384376526 0.0 13.98444938659668
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([224, 297, 349, 480], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.03852098435163498
bi 1 loss 0.18255789577960968
bi 2 loss 0.2906395494937897
bi 3 loss 0.14908798038959503
Layer  4  loss:  0.21009083092212677 0.0 11.537568092346191
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1021
Curr loss timestep torch.Size([606, 4]) tensor([159, 297, 335, 479], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.04793049395084381
bi 1 loss 0.16551680862903595
bi 2 loss 0.3230322003364563
bi 3 loss 0.14223812520503998
Layer  5  loss:  0.22845357656478882 0.0 12.522533416748047
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([169, 280, 335, 480], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.039519887417554855
bi 1 loss 0.23209428787231445
bi 2 loss 0.33997642993927
bi 3 loss 0.13524366915225983
Layer  6  loss:  0.21606916189193726 0.0 16.288360595703125
logits torch.Size([606, 4, 1024]) labels torch.Size([606, 4]) 0 1023
Curr loss timestep torch.Size([606, 4]) tensor([226, 297, 335, 480], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.033858973532915115
bi 1 loss 0.1645103245973587
bi 2 loss 0.32663270831108093
bi 3 loss 0.16229940950870514
Epoch 0: :   3%|▎         | 15867/600000 [06:02<3:42:12, v_num=12, reduced_train_loss=0.399, global_step=15865.0, consumed_samples=63464.0, train_step_timing in s=0.315]Epoch 0: :   3%|▎         | 15867/600000 [06:02<3:42:12, v_num=12, reduced_train_loss=1.560, global_step=15866.0, consumed_samples=63468.0, train_step_timing in s=0.415]loss mask original None

First layer loss:  0.14532411098480225 torch.Size([575, 4]) 11.687053680419922 0.0
Max loss timestep torch.Size([575, 4]) tensor([549, 231, 317, 489], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.1918753832578659
speech mask sum tensor(312, device='cuda:0') loss mask sum tensor(312, device='cuda:0')
bi 1 loss 0.028982529416680336
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 2 loss 0.2546598017215729
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 3 loss 0.09584478288888931
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
logits torch.Size([575, 4, 257024]) labels torch.Size([575, 4]) 0 257022
Layer  0  loss:  0.16519346833229065 0.0 13.962931632995605
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([549, 166, 316, 284], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.2419615536928177
bi 1 loss 0.05888218432664871
bi 2 loss 0.27511101961135864
bi 3 loss 0.08426908403635025
Layer  1  loss:  0.1702110320329666 0.0 19.366851806640625
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([549, 118, 317, 267], device='cuda:0') tensor(549, device='cuda:0')
bi 0 loss 0.2591571509838104
bi 1 loss 0.0367206446826458
bi 2 loss 0.3126264214515686
bi 3 loss 0.07234343886375427
Layer  2  loss:  0.19069591164588928 0.0 10.174262046813965
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([549, 223, 317, 423], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.2723546028137207
bi 1 loss 0.035026565194129944
bi 2 loss 0.349000483751297
bi 3 loss 0.1003967672586441
Layer  3  loss:  0.16935484111309052 0.0 17.921937942504883
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1021
Curr loss timestep torch.Size([575, 4]) tensor([556,  92, 317, 424], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.2597227096557617
bi 1 loss 0.036542657762765884
bi 2 loss 0.3056595027446747
bi 3 loss 0.07366308569908142
Layer  4  loss:  0.18021762371063232 0.0 16.742687225341797
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1022
Curr loss timestep torch.Size([575, 4]) tensor([523, 199, 323, 284], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.24183204770088196
bi 1 loss 0.051789700984954834
bi 2 loss 0.3470762372016907
bi 3 loss 0.08849779516458511
Layer  5  loss:  0.17027230560779572 0.0 14.627132415771484
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([523, 110, 317, 284], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.2684710621833801
bi 1 loss 0.02953510731458664
bi 2 loss 0.25884371995925903
bi 3 loss 0.10096387565135956
Layer  6  loss:  0.19987235963344574 0.0 14.612332344055176
logits torch.Size([575, 4, 1024]) labels torch.Size([575, 4]) 0 1023
Curr loss timestep torch.Size([575, 4]) tensor([556, 106, 317, 283], device='cuda:0') tensor(317, device='cuda:0')
bi 0 loss 0.2814410328865051
bi 1 loss 0.042609959840774536
bi 2 loss 0.3475903272628784
bi 3 loss 0.11692188680171967
Epoch 0: :   3%|▎         | 15868/600000 [06:02<3:42:27, v_num=12, reduced_train_loss=1.560, global_step=15866.0, consumed_samples=63468.0, train_step_timing in s=0.415]Epoch 0: :   3%|▎         | 15868/600000 [06:02<3:42:27, v_num=12, reduced_train_loss=1.390, global_step=15867.0, consumed_samples=63472.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  0.06213940680027008 torch.Size([439, 4]) 5.8655524253845215 0.0
Max loss timestep torch.Size([439, 4]) tensor([285, 368, 326, 407], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.044538747519254684
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 1 loss 0.07029557973146439
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
bi 2 loss 0.04541432484984398
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
bi 3 loss 0.08588577061891556
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
logits torch.Size([439, 4, 257024]) labels torch.Size([439, 4]) 0 257023
Layer  0  loss:  0.08433263748884201 0.0 10.792330741882324
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([311, 368, 261, 257], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.09712111949920654
bi 1 loss 0.07762975990772247
bi 2 loss 0.09719131141901016
bi 3 loss 0.06760195642709732
Layer  1  loss:  0.09643708169460297 0.0 8.152165412902832
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1022
Curr loss timestep torch.Size([439, 4]) tensor([280, 367, 270, 369], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.08847322314977646
bi 1 loss 0.10951387882232666
bi 2 loss 0.08688764274120331
bi 3 loss 0.09411176294088364
Layer  2  loss:  0.09315817803144455 0.0 6.88306999206543
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([357, 367, 256, 332], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.07721645385026932
bi 1 loss 0.09356492757797241
bi 2 loss 0.09263380616903305
bi 3 loss 0.11085119843482971
Layer  3  loss:  0.107816681265831 0.0 7.229279041290283
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1022
Curr loss timestep torch.Size([439, 4]) tensor([351, 332, 272, 332], device='cuda:0') tensor(332, device='cuda:0')
bi 0 loss 0.10214339941740036
bi 1 loss 0.1283968985080719
bi 2 loss 0.07917466014623642
bi 3 loss 0.1105053573846817
Layer  4  loss:  0.109549880027771 0.0 12.656494140625
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([353, 368, 338, 416], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.09709473699331284
bi 1 loss 0.14300373196601868
bi 2 loss 0.07099206745624542
bi 3 loss 0.10929697751998901
Layer  5  loss:  0.1141132190823555 0.0 11.986736297607422
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1021
Curr loss timestep torch.Size([439, 4]) tensor([280, 368, 281, 332], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.12441211938858032
bi 1 loss 0.11548817902803421
bi 2 loss 0.09743546694517136
bi 3 loss 0.11756112426519394
Layer  6  loss:  0.11211013048887253 0.0 8.057989120483398
logits torch.Size([439, 4, 1024]) labels torch.Size([439, 4]) 0 1023
Curr loss timestep torch.Size([439, 4]) tensor([307, 368, 256, 399], device='cuda:0') tensor(368, device='cuda:0')
bi 0 loss 0.12405207008123398
bi 1 loss 0.10514836013317108
bi 2 loss 0.10278286039829254
bi 3 loss 0.11957711726427078
Epoch 0: :   3%|▎         | 15869/600000 [06:02<3:42:40, v_num=12, reduced_train_loss=1.390, global_step=15867.0, consumed_samples=63472.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15869/600000 [06:02<3:42:40, v_num=12, reduced_train_loss=0.780, global_step=15868.0, consumed_samples=63476.0, train_step_timing in s=0.318]loss mask original None

First layer loss:  0.012972754426300526 torch.Size([295, 4]) 0.4524076282978058 0.0
Max loss timestep torch.Size([295, 4]) tensor([160, 218,  97, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.010251830331981182
speech mask sum tensor(204, device='cuda:0') loss mask sum tensor(204, device='cuda:0')
bi 1 loss 0.009251688607037067
speech mask sum tensor(125, device='cuda:0') loss mask sum tensor(125, device='cuda:0')
bi 2 loss 0.012879363261163235
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 3 loss 0.019412662833929062
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
logits torch.Size([295, 4, 257024]) labels torch.Size([295, 4]) 0 257023
Layer  0  loss:  0.009833768010139465 0.0 0.13946467638015747
logits torch.Size([295, 4, 1024]) labels torch.Size([295, 4]) 0 1023
Curr loss timestep torch.Size([295, 4]) tensor([121, 249, 110, 136], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 0.00895177572965622
bi 1 loss 0.008038295432925224
bi 2 loss 0.010845470242202282
bi 3 loss 0.011226799339056015
Layer  1  loss:  0.010124754160642624 0.0 0.14725711941719055
logits torch.Size([295, 4, 1024]) labels torch.Size([295, 4]) 0 1023
Curr loss timestep torch.Size([295, 4]) tensor([247, 209,  76, 136], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 0.010553124360740185
bi 1 loss 0.009119865484535694
bi 2 loss 0.010422119870781898
bi 3 loss 0.01003340445458889
Layer  2  loss:  0.010854716412723064 0.0 0.4880099296569824
logits torch.Size([295, 4, 1024]) labels torch.Size([295, 4]) 0 1022
Curr loss timestep torch.Size([295, 4]) tensor([224, 234, 152, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.009764858521521091
bi 1 loss 0.00843658298254013
bi 2 loss 0.011577282100915909
bi 3 loss 0.013314226642251015
Layer  3  loss:  0.010080666281282902 0.0 0.19397547841072083
logits torch.Size([295, 4, 1024]) labels torch.Size([295, 4]) 0 1019
Curr loss timestep torch.Size([295, 4]) tensor([117, 219, 170, 135], device='cuda:0') tensor(219, device='cuda:0')
bi 0 loss 0.008784889243543148
bi 1 loss 0.009263862855732441
bi 2 loss 0.011670197360217571
bi 3 loss 0.010599314235150814
Layer  4  loss:  0.00957013014703989 0.0 0.10858944803476334
logits torch.Size([295, 4, 1024]) labels torch.Size([295, 4]) 0 1022
Curr loss timestep torch.Size([295, 4]) tensor([183, 209,  97, 147], device='cuda:0') tensor(183, device='cuda:0')
bi 0 loss 0.009798574261367321
bi 1 loss 0.007815525867044926
bi 2 loss 0.00995954591780901
bi 3 loss 0.010212412104010582
Layer  5  loss:  0.010429209098219872 0.0 0.21425944566726685
logits torch.Size([295, 4, 1024]) labels torch.Size([295, 4]) 0 1021
Curr loss timestep torch.Size([295, 4]) tensor([223, 245,  66, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.008919979445636272
bi 1 loss 0.008556322194635868
bi 2 loss 0.011820964515209198
bi 3 loss 0.012256921268999577
Layer  6  loss:  0.010211162269115448 0.0 0.20772598683834076
logits torch.Size([295, 4, 1024]) labels torch.Size([295, 4]) 0 1021
Curr loss timestep torch.Size([295, 4]) tensor([170, 176, 131, 167], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 0.01113651879131794
bi 1 loss 0.008386370725929737
bi 2 loss 0.01084393635392189
bi 3 loss 0.009755835868418217
Epoch 0: :   3%|▎         | 15870/600000 [06:03<3:42:50, v_num=12, reduced_train_loss=0.780, global_step=15868.0, consumed_samples=63476.0, train_step_timing in s=0.318]Epoch 0: :   3%|▎         | 15870/600000 [06:03<3:42:50, v_num=12, reduced_train_loss=0.0841, global_step=15869.0, consumed_samples=63480.0, train_step_timing in s=0.265]loss mask original None

First layer loss:  0.22412866353988647 torch.Size([758, 4]) 13.81562328338623 0.0
Max loss timestep torch.Size([758, 4]) tensor([308, 303, 653, 499], device='cuda:0') tensor(653, device='cuda:0')
bi 0 loss 0.1654801368713379
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 1 loss 0.17634959518909454
speech mask sum tensor(306, device='cuda:0') loss mask sum tensor(306, device='cuda:0')
bi 2 loss 0.3709648549556732
speech mask sum tensor(475, device='cuda:0') loss mask sum tensor(475, device='cuda:0')
bi 3 loss 0.08836370706558228
speech mask sum tensor(346, device='cuda:0') loss mask sum tensor(346, device='cuda:0')
logits torch.Size([758, 4, 257024]) labels torch.Size([758, 4]) 0 257022
Layer  0  loss:  0.22248755395412445 0.0 10.771574974060059
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1023
Curr loss timestep torch.Size([758, 4]) tensor([308, 343, 737, 499], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.1681850105524063
bi 1 loss 0.186762273311615
bi 2 loss 0.34869441390037537
bi 3 loss 0.10263711214065552
Layer  1  loss:  0.26887446641921997 0.0 12.696037292480469
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1023
Curr loss timestep torch.Size([758, 4]) tensor([308, 342, 562, 325], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 0.07752929627895355
bi 1 loss 0.22452956438064575
bi 2 loss 0.46379348635673523
bi 3 loss 0.11737146228551865
Layer  2  loss:  0.2665919363498688 0.0 11.587037086486816
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1023
Curr loss timestep torch.Size([758, 4]) tensor([272, 355, 737, 394], device='cuda:0') tensor(737, device='cuda:0')
bi 0 loss 0.0577528215944767
bi 1 loss 0.15193365514278412
bi 2 loss 0.5275760889053345
bi 3 loss 0.09360526502132416
Layer  3  loss:  0.32114851474761963 0.0 13.608905792236328
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1023
Curr loss timestep torch.Size([758, 4]) tensor([308, 303, 562, 344], device='cuda:0') tensor(562, device='cuda:0')
bi 0 loss 0.13639982044696808
bi 1 loss 0.22542627155780792
bi 2 loss 0.5957866311073303
bi 3 loss 0.102992482483387
Layer  4  loss:  0.2851227819919586 0.0 13.048572540283203
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1022
Curr loss timestep torch.Size([758, 4]) tensor([308, 343, 653, 325], device='cuda:0') tensor(653, device='cuda:0')
bi 0 loss 0.10471461713314056
bi 1 loss 0.16674503684043884
bi 2 loss 0.5386000871658325
bi 3 loss 0.11430957913398743
Layer  5  loss:  0.26967644691467285 0.0 20.945392608642578
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1022
Curr loss timestep torch.Size([758, 4]) tensor([307, 342, 737, 499], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 0.11376766860485077
bi 1 loss 0.26577234268188477
bi 2 loss 0.44788506627082825
bi 3 loss 0.0911126360297203
Layer  6  loss:  0.31314799189567566 0.0 15.1580228805542
logits torch.Size([758, 4, 1024]) labels torch.Size([758, 4]) 0 1022
Curr loss timestep torch.Size([758, 4]) tensor([308, 343, 677, 499], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.15847232937812805
bi 1 loss 0.2906946539878845
bi 2 loss 0.5164722204208374
bi 3 loss 0.11601393669843674
Epoch 0: :   3%|▎         | 15871/600000 [06:03<3:43:09, v_num=12, reduced_train_loss=0.0841, global_step=15869.0, consumed_samples=63480.0, train_step_timing in s=0.265]Epoch 0: :   3%|▎         | 15871/600000 [06:03<3:43:09, v_num=12, reduced_train_loss=2.170, global_step=15870.0, consumed_samples=63484.0, train_step_timing in s=0.519] loss mask original None

First layer loss:  0.009803756140172482 torch.Size([405, 4]) 0.13337036967277527 0.0
Max loss timestep torch.Size([405, 4]) tensor([167, 180, 283, 269], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 0.008250908926129341
speech mask sum tensor(173, device='cuda:0') loss mask sum tensor(173, device='cuda:0')
bi 1 loss 0.006902292370796204
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 2 loss 0.011423302814364433
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 3 loss 0.012239756993949413
speech mask sum tensor(126, device='cuda:0') loss mask sum tensor(126, device='cuda:0')
logits torch.Size([405, 4, 257024]) labels torch.Size([405, 4]) 0 257022
Layer  0  loss:  0.009861474856734276 0.0 0.17590628564357758
logits torch.Size([405, 4, 1024]) labels torch.Size([405, 4]) 0 1023
Curr loss timestep torch.Size([405, 4]) tensor([265, 158, 243, 282], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.008445858024060726
bi 1 loss 0.0077535780146718025
bi 2 loss 0.012389992363750935
bi 3 loss 0.009204051457345486
Layer  1  loss:  0.009459313005208969 0.0 0.48066043853759766
logits torch.Size([405, 4, 1024]) labels torch.Size([405, 4]) 0 1023
Curr loss timestep torch.Size([405, 4]) tensor([194, 188, 283, 213], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.007356640882790089
bi 1 loss 0.006732357200235128
bi 2 loss 0.011432907544076443
bi 3 loss 0.011689627543091774
Layer  2  loss:  0.008628685027360916 0.0 0.14598587155342102
logits torch.Size([405, 4, 1024]) labels torch.Size([405, 4]) 0 1022
Curr loss timestep torch.Size([405, 4]) tensor([167, 157, 362, 280], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 0.008021382614970207
bi 1 loss 0.007208929397165775
bi 2 loss 0.00947349052876234
bi 3 loss 0.009502025321125984
Layer  3  loss:  0.009868670254945755 0.0 0.1751498430967331
logits torch.Size([405, 4, 1024]) labels torch.Size([405, 4]) 0 1021
Curr loss timestep torch.Size([405, 4]) tensor([248, 156, 327, 257], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 0.00825132429599762
bi 1 loss 0.008112607523798943
bi 2 loss 0.009830344468355179
bi 3 loss 0.014399231411516666
Layer  4  loss:  0.010389317758381367 0.0 0.28170493245124817
logits torch.Size([405, 4, 1024]) labels torch.Size([405, 4]) 0 1023
Curr loss timestep torch.Size([405, 4]) tensor([256, 207, 283, 273], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.006970965303480625
bi 1 loss 0.007644988596439362
bi 2 loss 0.01290062628686428
bi 3 loss 0.013325774110853672
Layer  5  loss:  0.01010209135711193 0.0 0.27832573652267456
logits torch.Size([405, 4, 1024]) labels torch.Size([405, 4]) 0 1022
Curr loss timestep torch.Size([405, 4]) tensor([164, 114, 275, 269], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.010123378597199917
bi 1 loss 0.008924409747123718
bi 2 loss 0.011040179058909416
bi 3 loss 0.009610258974134922
Layer  6  loss:  0.009374771267175674 0.0 0.19098563492298126
logits torch.Size([405, 4, 1024]) labels torch.Size([405, 4]) 0 1023
Curr loss timestep torch.Size([405, 4]) tensor([284, 236, 234, 199], device='cuda:0') tensor(234, device='cuda:0')
bi 0 loss 0.006952251307666302
bi 1 loss 0.010384146124124527
bi 2 loss 0.011101717129349709
bi 3 loss 0.007814528420567513
Epoch 0: :   3%|▎         | 15872/600000 [06:04<3:43:22, v_num=12, reduced_train_loss=2.170, global_step=15870.0, consumed_samples=63484.0, train_step_timing in s=0.519]Epoch 0: :   3%|▎         | 15872/600000 [06:04<3:43:22, v_num=12, reduced_train_loss=0.0775, global_step=15871.0, consumed_samples=63488.0, train_step_timing in s=0.318]loss mask original None

First layer loss:  3.7364437580108643 torch.Size([440, 4]) 10.947321891784668 0.0
Max loss timestep torch.Size([440, 4]) tensor([284, 165, 302, 118], device='cuda:0') tensor(165, device='cuda:0')
bi 0 loss 3.4241960048675537
speech mask sum tensor(223, device='cuda:0') loss mask sum tensor(223, device='cuda:0')
bi 1 loss 3.345646858215332
speech mask sum tensor(84, device='cuda:0') loss mask sum tensor(84, device='cuda:0')
bi 2 loss 3.937983274459839
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 3 loss 3.926405429840088
speech mask sum tensor(359, device='cuda:0') loss mask sum tensor(359, device='cuda:0')
logits torch.Size([440, 4, 257024]) labels torch.Size([440, 4]) 0 257022
Layer  0  loss:  4.266375541687012 0.0 11.374967575073242
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([138, 175, 310, 230], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 4.098363876342773
bi 1 loss 4.23935604095459
bi 2 loss 4.9324846267700195
bi 3 loss 4.061634063720703
Layer  1  loss:  4.4678635597229 0.0 10.146343231201172
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([291, 216, 274, 327], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.51474142074585
bi 1 loss 3.9089138507843018
bi 2 loss 4.629016876220703
bi 3 loss 4.4932169914245605
Layer  2  loss:  4.766385078430176 0.0 11.047231674194336
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([165, 173, 312, 375], device='cuda:0') tensor(173, device='cuda:0')
bi 0 loss 4.549576282501221
bi 1 loss 4.171944618225098
bi 2 loss 4.960379600524902
bi 3 loss 4.948286533355713
Layer  3  loss:  4.9135613441467285 0.0 9.628623962402344
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([253, 208, 252, 415], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 4.906434535980225
bi 1 loss 4.100588321685791
bi 2 loss 5.123635768890381
bi 3 loss 5.008732318878174
Layer  4  loss:  5.035951614379883 0.0 9.831892013549805
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([273, 224, 245, 272], device='cuda:0') tensor(168, device='cuda:0')
bi 0 loss 5.101533889770508
bi 1 loss 4.365354537963867
bi 2 loss 5.2281107902526855
bi 3 loss 5.06112813949585
Layer  5  loss:  5.065461158752441 0.0 11.702948570251465
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1022
Curr loss timestep torch.Size([440, 4]) tensor([178, 189, 265, 378], device='cuda:0') tensor(175, device='cuda:0')
bi 0 loss 4.932723045349121
bi 1 loss 4.074151515960693
bi 2 loss 5.349407196044922
bi 3 loss 5.245404243469238
Layer  6  loss:  5.082958221435547 0.0 10.06411075592041
logits torch.Size([440, 4, 1024]) labels torch.Size([440, 4]) 0 1023
Curr loss timestep torch.Size([440, 4]) tensor([275, 201, 200, 319], device='cuda:0') tensor(174, device='cuda:0')
bi 0 loss 5.072365760803223
bi 1 loss 4.171120643615723
bi 2 loss 5.28170108795166
bi 3 loss 5.208779811859131
Epoch 0: :   3%|▎         | 15873/600000 [06:04<3:43:33, v_num=12, reduced_train_loss=0.0775, global_step=15871.0, consumed_samples=63488.0, train_step_timing in s=0.318]Epoch 0: :   3%|▎         | 15873/600000 [06:04<3:43:33, v_num=12, reduced_train_loss=37.30, global_step=15872.0, consumed_samples=63492.0, train_step_timing in s=0.309] loss mask original None

First layer loss:  0.0390237458050251 torch.Size([402, 4]) 6.088768482208252 0.0
Max loss timestep torch.Size([402, 4]) tensor([256, 241, 285, 183], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.029878372326493263
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 1 loss 0.027098583057522774
speech mask sum tensor(215, device='cuda:0') loss mask sum tensor(215, device='cuda:0')
bi 2 loss 0.06188901513814926
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 3 loss 0.01983116939663887
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
logits torch.Size([402, 4, 257024]) labels torch.Size([402, 4]) 0 257022
Layer  0  loss:  0.03976597636938095 0.0 7.201273441314697
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1023
Curr loss timestep torch.Size([402, 4]) tensor([162, 236, 283, 124], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.015269984491169453
bi 1 loss 0.01740766130387783
bi 2 loss 0.07252489775419235
bi 3 loss 0.03214665874838829
Layer  1  loss:  0.03631475940346718 0.0 8.263172149658203
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1022
Curr loss timestep torch.Size([402, 4]) tensor([260, 282, 285, 126], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.018139684572815895
bi 1 loss 0.02281053178012371
bi 2 loss 0.061112675815820694
bi 3 loss 0.024877626448869705
Layer  2  loss:  0.031214654445648193 0.0 6.288914203643799
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1023
Curr loss timestep torch.Size([402, 4]) tensor([257, 104, 283, 146], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.019011327996850014
bi 1 loss 0.017859235405921936
bi 2 loss 0.05237382650375366
bi 3 loss 0.02089068852365017
Layer  3  loss:  0.03762539103627205 0.0 7.259279727935791
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1023
Curr loss timestep torch.Size([402, 4]) tensor([166, 275, 285,  75], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.02326642908155918
bi 1 loss 0.021989552304148674
bi 2 loss 0.06405216455459595
bi 3 loss 0.02220798470079899
Layer  4  loss:  0.031052028760313988 0.0 4.530119895935059
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1022
Curr loss timestep torch.Size([402, 4]) tensor([256, 260, 285,  89], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.020747682079672813
bi 1 loss 0.02505391649901867
bi 2 loss 0.047598399221897125
bi 3 loss 0.016885491088032722
Layer  5  loss:  0.0380290187895298 0.0 5.7781662940979
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1023
Curr loss timestep torch.Size([402, 4]) tensor([257, 274, 283, 151], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.025276128202676773
bi 1 loss 0.024874823167920113
bi 2 loss 0.06035361811518669
bi 3 loss 0.025561243295669556
Layer  6  loss:  0.042118798941373825 0.0 11.67793083190918
logits torch.Size([402, 4, 1024]) labels torch.Size([402, 4]) 0 1022
Curr loss timestep torch.Size([402, 4]) tensor([159, 226, 283, 161], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.015698103234171867
bi 1 loss 0.018878180533647537
bi 2 loss 0.08004244416952133
bi 3 loss 0.027217572554945946
Epoch 0: :   3%|▎         | 15874/600000 [06:04<3:43:46, v_num=12, reduced_train_loss=37.30, global_step=15872.0, consumed_samples=63492.0, train_step_timing in s=0.309]Epoch 0: :   3%|▎         | 15874/600000 [06:04<3:43:46, v_num=12, reduced_train_loss=0.295, global_step=15873.0, consumed_samples=63496.0, train_step_timing in s=0.314]loss mask original None

First layer loss:  0.05876056104898453 torch.Size([415, 4]) 9.269633293151855 0.0
Max loss timestep torch.Size([415, 4]) tensor([380, 286, 111,  45], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.06118965893983841
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
bi 1 loss 0.07276638597249985
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 2 loss 0.031505241990089417
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 3 loss 0.01880737394094467
speech mask sum tensor(39, device='cuda:0') loss mask sum tensor(39, device='cuda:0')
logits torch.Size([415, 4, 257024]) labels torch.Size([415, 4]) 0 257023
Layer  0  loss:  0.04939465597271919 0.0 1.7701736688613892
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1023
Curr loss timestep torch.Size([415, 4]) tensor([264, 287, 148,  45], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.050669800490140915
bi 1 loss 0.0588780902326107
bi 2 loss 0.028655629605054855
bi 3 loss 0.03175467252731323
Layer  1  loss:  0.06132020056247711 0.0 3.958186626434326
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1023
Curr loss timestep torch.Size([415, 4]) tensor([380, 287, 124,  41], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.06294943392276764
bi 1 loss 0.0718664899468422
bi 2 loss 0.03277384117245674
bi 3 loss 0.05581941828131676
Layer  2  loss:  0.05404946580529213 0.0 4.598667621612549
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([380, 286, 130,  64], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.05452512949705124
bi 1 loss 0.06492219865322113
bi 2 loss 0.04047375172376633
bi 3 loss 0.012140721082687378
Layer  3  loss:  0.04543818160891533 0.0 1.915541410446167
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1023
Curr loss timestep torch.Size([415, 4]) tensor([144, 288,  99,  57], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.04678060859441757
bi 1 loss 0.05510445684194565
bi 2 loss 0.027418779209256172
bi 3 loss 0.018170105293393135
Layer  4  loss:  0.054332051426172256 0.0 4.76930046081543
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([169, 286, 114,  48], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.06740245968103409
bi 1 loss 0.05966402590274811
bi 2 loss 0.020982680842280388
bi 3 loss 0.011357180774211884
Layer  5  loss:  0.04110952839255333 0.0 2.832911968231201
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1022
Curr loss timestep torch.Size([415, 4]) tensor([241, 286, 130,  47], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.04434800148010254
bi 1 loss 0.045495010912418365
bi 2 loss 0.03230021148920059
bi 3 loss 0.010265550576150417
Layer  6  loss:  0.05893760174512863 0.0 3.8505258560180664
logits torch.Size([415, 4, 1024]) labels torch.Size([415, 4]) 0 1019
Curr loss timestep torch.Size([415, 4]) tensor([379, 287, 134,  50], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.042374905198812485
bi 1 loss 0.0838080570101738
bi 2 loss 0.05757817625999451
bi 3 loss 0.014027618803083897
Epoch 0: :   3%|▎         | 15875/600000 [06:05<3:43:57, v_num=12, reduced_train_loss=0.295, global_step=15873.0, consumed_samples=63496.0, train_step_timing in s=0.314]Epoch 0: :   3%|▎         | 15875/600000 [06:05<3:43:57, v_num=12, reduced_train_loss=0.423, global_step=15874.0, consumed_samples=63500.0, train_step_timing in s=0.308]loss mask original None

First layer loss:  3.411653518676758 torch.Size([716, 4]) 13.256851196289062 0.0
Max loss timestep torch.Size([716, 4]) tensor([209, 274, 382, 259], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 2.714179277420044
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 1 loss 3.3334310054779053
speech mask sum tensor(319, device='cuda:0') loss mask sum tensor(319, device='cuda:0')
bi 2 loss 3.999807834625244
speech mask sum tensor(484, device='cuda:0') loss mask sum tensor(484, device='cuda:0')
bi 3 loss 3.0491340160369873
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
logits torch.Size([716, 4, 257024]) labels torch.Size([716, 4]) 0 257023
Layer  0  loss:  3.954820394515991 0.0 10.898354530334473
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([190, 465, 473, 134], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 3.1041507720947266
bi 1 loss 4.318827152252197
bi 2 loss 4.310724258422852
bi 3 loss 3.6008176803588867
Layer  1  loss:  4.372213363647461 0.0 11.135154724121094
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([ 56, 469, 437, 150], device='cuda:0') tensor(301, device='cuda:0')
bi 0 loss 3.708014726638794
bi 1 loss 4.604997634887695
bi 2 loss 4.813348293304443
bi 3 loss 3.9013843536376953
Layer  2  loss:  4.668785572052002 0.0 10.769694328308105
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([ 93, 452, 251, 357], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 3.853912115097046
bi 1 loss 4.900773525238037
bi 2 loss 5.148940086364746
bi 3 loss 4.236023902893066
Layer  3  loss:  4.7994279861450195 0.0 10.171316146850586
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1021
Curr loss timestep torch.Size([716, 4]) tensor([ 62, 243, 390, 379], device='cuda:0') tensor(309, device='cuda:0')
bi 0 loss 3.874837636947632
bi 1 loss 4.99512243270874
bi 2 loss 5.350009918212891
bi 3 loss 4.366611480712891
Layer  4  loss:  4.905797481536865 0.0 11.432548522949219
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1021
Curr loss timestep torch.Size([716, 4]) tensor([210, 208, 459, 207], device='cuda:0') tensor(210, device='cuda:0')
bi 0 loss 4.0512518882751465
bi 1 loss 5.215992450714111
bi 2 loss 5.324477672576904
bi 3 loss 4.5132155418396
Layer  5  loss:  5.05924129486084 0.0 11.349568367004395
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([204, 387, 314, 368], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 4.085756301879883
bi 1 loss 5.326067924499512
bi 2 loss 5.4988789558410645
bi 3 loss 4.753844738006592
Layer  6  loss:  5.060960292816162 0.0 10.081348419189453
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([179, 476, 281, 228], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 4.132302761077881
bi 1 loss 5.315998554229736
bi 2 loss 5.539231300354004
bi 3 loss 4.680630683898926
Epoch 0: :   3%|▎         | 15876/600000 [06:05<3:44:14, v_num=12, reduced_train_loss=0.423, global_step=15874.0, consumed_samples=63500.0, train_step_timing in s=0.308]Epoch 0: :   3%|▎         | 15876/600000 [06:05<3:44:14, v_num=12, reduced_train_loss=36.20, global_step=15875.0, consumed_samples=63504.0, train_step_timing in s=0.430]loss mask original None

First layer loss:  0.11120815575122833 torch.Size([499, 4]) 17.187833786010742 0.0
Max loss timestep torch.Size([499, 4]) tensor([367, 381, 417, 304], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.20049810409545898
speech mask sum tensor(305, device='cuda:0') loss mask sum tensor(305, device='cuda:0')
bi 1 loss 0.06336630880832672
speech mask sum tensor(284, device='cuda:0') loss mask sum tensor(284, device='cuda:0')
bi 2 loss 0.10532031208276749
speech mask sum tensor(344, device='cuda:0') loss mask sum tensor(344, device='cuda:0')
bi 3 loss 0.06879596412181854
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
logits torch.Size([499, 4, 257024]) labels torch.Size([499, 4]) 0 257023
Layer  0  loss:  0.11603124439716339 0.0 12.38335132598877
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([273, 151, 417, 303], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.1855398714542389
bi 1 loss 0.07701832056045532
bi 2 loss 0.11343397200107574
bi 3 loss 0.08235607296228409
Layer  1  loss:  0.11943977326154709 0.0 9.825077056884766
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([369, 300, 417, 303], device='cuda:0') tensor(417, device='cuda:0')
bi 0 loss 0.17180387675762177
bi 1 loss 0.05898161232471466
bi 2 loss 0.09956304728984833
bi 3 loss 0.14877066016197205
Layer  2  loss:  0.1465943157672882 0.0 12.431167602539062
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([367, 337, 417, 303], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.25935056805610657
bi 1 loss 0.07627645134925842
bi 2 loss 0.10940143465995789
bi 3 loss 0.1406598687171936
Layer  3  loss:  0.13624237477779388 0.0 12.09715747833252
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([367, 205, 415, 302], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.24011459946632385
bi 1 loss 0.0707055926322937
bi 2 loss 0.10773565620183945
bi 3 loss 0.12433619052171707
Layer  4  loss:  0.13683821260929108 0.0 15.47761058807373
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1022
Curr loss timestep torch.Size([499, 4]) tensor([367, 224, 417, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.20989680290222168
bi 1 loss 0.059731777757406235
bi 2 loss 0.10233699530363083
bi 3 loss 0.17874988913536072
Layer  5  loss:  0.16101519763469696 0.0 19.032682418823242
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([367, 260, 417, 303], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.3213661015033722
bi 1 loss 0.05205694958567619
bi 2 loss 0.1294548064470291
bi 3 loss 0.135080486536026
Layer  6  loss:  0.15072426199913025 0.0 15.045024871826172
logits torch.Size([499, 4, 1024]) labels torch.Size([499, 4]) 0 1023
Curr loss timestep torch.Size([499, 4]) tensor([367, 352, 417, 303], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.2561904788017273
bi 1 loss 0.05291850119829178
bi 2 loss 0.12611356377601624
bi 3 loss 0.16559915244579315
Epoch 0: :   3%|▎         | 15877/600000 [06:06<3:44:27, v_num=12, reduced_train_loss=36.20, global_step=15875.0, consumed_samples=63504.0, train_step_timing in s=0.430]Epoch 0: :   3%|▎         | 15877/600000 [06:06<3:44:27, v_num=12, reduced_train_loss=1.080, global_step=15876.0, consumed_samples=63508.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  0.06967657804489136 torch.Size([446, 4]) 5.790971755981445 0.0
Max loss timestep torch.Size([446, 4]) tensor([317, 413, 395,  99], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.038491010665893555
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
bi 1 loss 0.06914094090461731
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
bi 2 loss 0.10289235413074493
speech mask sum tensor(212, device='cuda:0') loss mask sum tensor(212, device='cuda:0')
bi 3 loss 0.03872918337583542
speech mask sum tensor(59, device='cuda:0') loss mask sum tensor(59, device='cuda:0')
logits torch.Size([446, 4, 257024]) labels torch.Size([446, 4]) 0 257023
Layer  0  loss:  0.07120435684919357 0.0 5.524903774261475
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1023
Curr loss timestep torch.Size([446, 4]) tensor([212, 387, 321,  91], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.06110098958015442
bi 1 loss 0.06300917267799377
bi 2 loss 0.10602137446403503
bi 3 loss 0.024229424074292183
Layer  1  loss:  0.09815075248479843 0.0 6.825263977050781
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1022
Curr loss timestep torch.Size([446, 4]) tensor([229, 377, 321, 103], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.06419110298156738
bi 1 loss 0.08354534208774567
bi 2 loss 0.1671910136938095
bi 3 loss 0.03285137936472893
Layer  2  loss:  0.07283363491296768 0.0 2.833648920059204
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1023
Curr loss timestep torch.Size([446, 4]) tensor([256, 292, 395,  74], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.044891878962516785
bi 1 loss 0.08222705870866776
bi 2 loss 0.09433821588754654
bi 3 loss 0.013858144171535969
Layer  3  loss:  0.07700834423303604 0.0 9.483428955078125
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1021
Curr loss timestep torch.Size([446, 4]) tensor([295, 413, 395,  93], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.03618329390883446
bi 1 loss 0.05227689817547798
bi 2 loss 0.16819025576114655
bi 3 loss 0.013356020674109459
Layer  4  loss:  0.0942494347691536 0.0 8.376138687133789
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1022
Curr loss timestep torch.Size([446, 4]) tensor([241, 413, 321,  94], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.04818348214030266
bi 1 loss 0.07450784742832184
bi 2 loss 0.16129091382026672
bi 3 loss 0.10085552930831909
Layer  5  loss:  0.08276388049125671 0.0 5.395803928375244
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1023
Curr loss timestep torch.Size([446, 4]) tensor([201, 413, 321, 105], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.059968557208776474
bi 1 loss 0.07276245206594467
bi 2 loss 0.13034053146839142
bi 3 loss 0.035718366503715515
Layer  6  loss:  0.09257110208272934 0.0 8.814777374267578
logits torch.Size([446, 4, 1024]) labels torch.Size([446, 4]) 0 1022
Curr loss timestep torch.Size([446, 4]) tensor([256, 340, 321,  97], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.04138991981744766
bi 1 loss 0.09084997326135635
bi 2 loss 0.13897526264190674
bi 3 loss 0.07611310482025146
Epoch 0: :   3%|▎         | 15878/600000 [06:06<3:44:40, v_num=12, reduced_train_loss=1.080, global_step=15876.0, consumed_samples=63508.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15878/600000 [06:06<3:44:40, v_num=12, reduced_train_loss=0.658, global_step=15877.0, consumed_samples=63512.0, train_step_timing in s=0.331]loss mask original None

First layer loss:  3.579784631729126 torch.Size([548, 4]) 12.610661506652832 0.0
Max loss timestep torch.Size([548, 4]) tensor([114, 493, 136, 335], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 4.289132595062256
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 1 loss 3.4285237789154053
speech mask sum tensor(338, device='cuda:0') loss mask sum tensor(338, device='cuda:0')
bi 2 loss 3.1654460430145264
speech mask sum tensor(294, device='cuda:0') loss mask sum tensor(294, device='cuda:0')
bi 3 loss 3.920549154281616
speech mask sum tensor(316, device='cuda:0') loss mask sum tensor(316, device='cuda:0')
logits torch.Size([548, 4, 257024]) labels torch.Size([548, 4]) 0 257019
Layer  0  loss:  4.122381210327148 0.0 10.771601676940918
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([125, 274, 338, 259], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 4.354870319366455
bi 1 loss 4.014662742614746
bi 2 loss 3.836803674697876
bi 3 loss 4.435606479644775
Layer  1  loss:  4.282159805297852 0.0 11.641510009765625
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([104, 337, 295, 457], device='cuda:0') tensor(338, device='cuda:0')
bi 0 loss 4.836296558380127
bi 1 loss 4.033878803253174
bi 2 loss 3.9913861751556396
bi 3 loss 4.656924247741699
Layer  2  loss:  4.547850608825684 0.0 9.591583251953125
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 97, 239, 223, 274], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 4.993589878082275
bi 1 loss 4.508901596069336
bi 2 loss 4.114805221557617
bi 3 loss 4.862635135650635
Layer  3  loss:  4.677824974060059 0.0 10.151724815368652
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([110, 318, 309, 336], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 5.173605918884277
bi 1 loss 4.557714462280273
bi 2 loss 4.3582587242126465
bi 3 loss 4.9592742919921875
Layer  4  loss:  4.816630840301514 0.0 10.278766632080078
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([153, 276, 304, 444], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 5.157483100891113
bi 1 loss 4.785614490509033
bi 2 loss 4.505814552307129
bi 3 loss 5.03974723815918
Layer  5  loss:  4.965994358062744 0.0 10.209650039672852
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1022
Curr loss timestep torch.Size([548, 4]) tensor([ 97, 449, 216, 355], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 5.450654983520508
bi 1 loss 4.935252666473389
bi 2 loss 4.599087715148926
bi 3 loss 5.199134349822998
Layer  6  loss:  4.991424083709717 0.0 10.248123168945312
logits torch.Size([548, 4, 1024]) labels torch.Size([548, 4]) 0 1023
Curr loss timestep torch.Size([548, 4]) tensor([142, 272, 343, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 5.3533711433410645
bi 1 loss 4.958308219909668
bi 2 loss 4.650550842285156
bi 3 loss 5.238611221313477
Epoch 0: :   3%|▎         | 15879/600000 [06:06<3:44:53, v_num=12, reduced_train_loss=0.658, global_step=15877.0, consumed_samples=63512.0, train_step_timing in s=0.331]Epoch 0: :   3%|▎         | 15879/600000 [06:06<3:44:53, v_num=12, reduced_train_loss=36.00, global_step=15878.0, consumed_samples=63516.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  0.08455177396535873 torch.Size([491, 4]) 11.285966873168945 0.0
Max loss timestep torch.Size([491, 4]) tensor([177, 391, 169, 225], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 0.03204091638326645
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
bi 1 loss 0.06465955823659897
speech mask sum tensor(431, device='cuda:0') loss mask sum tensor(431, device='cuda:0')
bi 2 loss 0.18445414304733276
speech mask sum tensor(195, device='cuda:0') loss mask sum tensor(195, device='cuda:0')
bi 3 loss 0.03916603699326515
speech mask sum tensor(120, device='cuda:0') loss mask sum tensor(120, device='cuda:0')
logits torch.Size([491, 4, 257024]) labels torch.Size([491, 4]) 0 257022
Layer  0  loss:  0.08924456685781479 0.0 7.201028823852539
logits torch.Size([491, 4, 1024]) labels torch.Size([491, 4]) 0 1023
Curr loss timestep torch.Size([491, 4]) tensor([149, 391, 345, 222], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.03108764812350273
bi 1 loss 0.08620192855596542
bi 2 loss 0.16414278745651245
bi 3 loss 0.02886578068137169
Layer  1  loss:  0.11619914323091507 0.0 11.285341262817383
logits torch.Size([491, 4, 1024]) labels torch.Size([491, 4]) 0 1022
Curr loss timestep torch.Size([491, 4]) tensor([172, 390, 342, 221], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 0.05578388646245003
bi 1 loss 0.12528473138809204
bi 2 loss 0.17408506572246552
bi 3 loss 0.04186208173632622
Layer  2  loss:  0.0960768386721611 0.0 10.821646690368652
logits torch.Size([491, 4, 1024]) labels torch.Size([491, 4]) 0 1023
Curr loss timestep torch.Size([491, 4]) tensor([108, 390, 345, 179], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.050165507942438126
bi 1 loss 0.09704503417015076
bi 2 loss 0.1625346690416336
bi 3 loss 0.024395247921347618
Layer  3  loss:  0.09283336997032166 0.0 8.036382675170898
logits torch.Size([491, 4, 1024]) labels torch.Size([491, 4]) 0 1023
Curr loss timestep torch.Size([491, 4]) tensor([106, 390, 345, 203], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.024988749995827675
bi 1 loss 0.08559244871139526
bi 2 loss 0.1826038658618927
bi 3 loss 0.031761929392814636
Layer  4  loss:  0.09121055901050568 0.0 9.191679000854492
logits torch.Size([491, 4, 1024]) labels torch.Size([491, 4]) 0 1022
Curr loss timestep torch.Size([491, 4]) tensor([159, 391, 345, 224], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.027174992486834526
bi 1 loss 0.08293750137090683
bi 2 loss 0.17177200317382812
bi 3 loss 0.04550979286432266
Layer  5  loss:  0.09875768423080444 0.0 10.094961166381836
logits torch.Size([491, 4, 1024]) labels torch.Size([491, 4]) 0 1020
Curr loss timestep torch.Size([491, 4]) tensor([157, 391, 345, 209], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.012277716770768166
bi 1 loss 0.09923186153173447
bi 2 loss 0.18024839460849762
bi 3 loss 0.039581459015607834
Layer  6  loss:  0.10896529257297516 0.0 14.801373481750488
logits torch.Size([491, 4, 1024]) labels torch.Size([491, 4]) 0 1022
Curr loss timestep torch.Size([491, 4]) tensor([167, 391, 345, 262], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.02503807283937931
bi 1 loss 0.08592686802148819
bi 2 loss 0.24612003564834595
bi 3 loss 0.04157207906246185
Epoch 0: :   3%|▎         | 15880/600000 [06:07<3:45:06, v_num=12, reduced_train_loss=36.00, global_step=15878.0, consumed_samples=63516.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15880/600000 [06:07<3:45:06, v_num=12, reduced_train_loss=0.778, global_step=15879.0, consumed_samples=63520.0, train_step_timing in s=0.346]loss mask original None

First layer loss:  0.1590512990951538 torch.Size([647, 4]) 17.723575592041016 0.0
Max loss timestep torch.Size([647, 4]) tensor([573, 271, 298, 341], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.2837538719177246
speech mask sum tensor(494, device='cuda:0') loss mask sum tensor(494, device='cuda:0')
bi 1 loss 0.16420264542102814
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 2 loss 0.07645797729492188
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 3 loss 0.06404563784599304
speech mask sum tensor(331, device='cuda:0') loss mask sum tensor(331, device='cuda:0')
logits torch.Size([647, 4, 257024]) labels torch.Size([647, 4]) 0 257023
Layer  0  loss:  0.16359570622444153 0.0 10.697640419006348
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([573, 289, 353, 338], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.2510033845901489
bi 1 loss 0.12683527171611786
bi 2 loss 0.13101641833782196
bi 3 loss 0.11771860718727112
Layer  1  loss:  0.18296846747398376 0.0 12.712352752685547
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([605, 271, 304, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.3180416524410248
bi 1 loss 0.09216099977493286
bi 2 loss 0.2099522352218628
bi 3 loss 0.06335613131523132
Layer  2  loss:  0.19405639171600342 0.0 13.000507354736328
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([605, 271, 352,  58], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.2944372594356537
bi 1 loss 0.1905268281698227
bi 2 loss 0.16677899658679962
bi 3 loss 0.0808904692530632
Layer  3  loss:  0.1710539609193802 0.0 10.159576416015625
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([449, 376, 352, 260], device='cuda:0') tensor(298, device='cuda:0')
bi 0 loss 0.26795920729637146
bi 1 loss 0.11308898031711578
bi 2 loss 0.18709178268909454
bi 3 loss 0.08015821129083633
Layer  4  loss:  0.21748283505439758 0.0 18.607118606567383
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([605, 271, 352, 338], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.37300053238868713
bi 1 loss 0.155081108212471
bi 2 loss 0.1870625913143158
bi 3 loss 0.099553182721138
Layer  5  loss:  0.19161824882030487 0.0 12.283432960510254
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([573, 343, 353, 261], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.2903503477573395
bi 1 loss 0.14874912798404694
bi 2 loss 0.19892461597919464
bi 3 loss 0.08938335627317429
Layer  6  loss:  0.20314054191112518 0.0 13.991186141967773
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1019
Curr loss timestep torch.Size([647, 4]) tensor([573, 271, 353, 261], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.322084903717041
bi 1 loss 0.15143200755119324
bi 2 loss 0.19418315589427948
bi 3 loss 0.10103446990251541
Epoch 0: :   3%|▎         | 15881/600000 [06:07<3:45:23, v_num=12, reduced_train_loss=0.778, global_step=15879.0, consumed_samples=63520.0, train_step_timing in s=0.346]Epoch 0: :   3%|▎         | 15881/600000 [06:07<3:45:23, v_num=12, reduced_train_loss=1.480, global_step=15880.0, consumed_samples=63524.0, train_step_timing in s=0.444]loss mask original None

First layer loss:  0.06149894371628761 torch.Size([513, 4]) 8.501516342163086 0.0
Max loss timestep torch.Size([513, 4]) tensor([361,  91, 262, 221], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.08736032247543335
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 1 loss 0.0457635372877121
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 2 loss 0.060652513056993484
speech mask sum tensor(227, device='cuda:0') loss mask sum tensor(227, device='cuda:0')
bi 3 loss 0.03864060714840889
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
logits torch.Size([513, 4, 257024]) labels torch.Size([513, 4]) 0 257023
Layer  0  loss:  0.03637700155377388 0.0 2.062983512878418
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([360, 133, 216, 188], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.050064340233802795
bi 1 loss 0.026195168495178223
bi 2 loss 0.02998782880604267
bi 3 loss 0.03265998885035515
Layer  1  loss:  0.05592728778719902 0.0 5.519474506378174
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([360, 129, 274, 168], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.08625882118940353
bi 1 loss 0.02970224991440773
bi 2 loss 0.05964121222496033
bi 3 loss 0.02905646711587906
Layer  2  loss:  0.06323672086000443 0.0 10.192861557006836
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([361, 100, 324, 107], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.09624604880809784
bi 1 loss 0.03505362197756767
bi 2 loss 0.059296123683452606
bi 3 loss 0.04322623834013939
Layer  3  loss:  0.05533866211771965 0.0 6.5741753578186035
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([360,  87, 262, 111], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.07550036162137985
bi 1 loss 0.03769325464963913
bi 2 loss 0.06470712274312973
bi 3 loss 0.029429031535983086
Layer  4  loss:  0.06448253244161606 0.0 7.152052402496338
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([361, 130, 376, 102], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.12049625813961029
bi 1 loss 0.03902163356542587
bi 2 loss 0.043445467948913574
bi 3 loss 0.03165813535451889
Layer  5  loss:  0.07002411037683487 0.0 15.4391508102417
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1023
Curr loss timestep torch.Size([513, 4]) tensor([361, 126, 262,  85], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.12693281471729279
bi 1 loss 0.03872435912489891
bi 2 loss 0.05546782910823822
bi 3 loss 0.032441362738609314
Layer  6  loss:  0.06547486037015915 0.0 11.60165023803711
logits torch.Size([513, 4, 1024]) labels torch.Size([513, 4]) 0 1022
Curr loss timestep torch.Size([513, 4]) tensor([361,  71, 262, 176], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.106288380920887
bi 1 loss 0.04188356176018715
bi 2 loss 0.06628397107124329
bi 3 loss 0.025967270135879517
Epoch 0: :   3%|▎         | 15882/600000 [06:08<3:45:37, v_num=12, reduced_train_loss=1.480, global_step=15880.0, consumed_samples=63524.0, train_step_timing in s=0.444]Epoch 0: :   3%|▎         | 15882/600000 [06:08<3:45:37, v_num=12, reduced_train_loss=0.472, global_step=15881.0, consumed_samples=63528.0, train_step_timing in s=0.359]loss mask original None

First layer loss:  0.038858942687511444 torch.Size([462, 4]) 2.554290533065796 0.0
Max loss timestep torch.Size([462, 4]) tensor([ 59, 263, 213, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.01593177765607834
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 1 loss 0.025795629248023033
speech mask sum tensor(189, device='cuda:0') loss mask sum tensor(189, device='cuda:0')
bi 2 loss 0.03814154118299484
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 3 loss 0.05306115001440048
speech mask sum tensor(309, device='cuda:0') loss mask sum tensor(309, device='cuda:0')
logits torch.Size([462, 4, 257024]) labels torch.Size([462, 4]) 0 257023
Layer  0  loss:  0.04550918936729431 0.0 1.7267717123031616
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1023
Curr loss timestep torch.Size([462, 4]) tensor([ 61, 119, 259, 377], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.04232382774353027
bi 1 loss 0.029314769431948662
bi 2 loss 0.058281052857637405
bi 3 loss 0.05265354365110397
Layer  1  loss:  0.04014456272125244 0.0 2.5774495601654053
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1023
Curr loss timestep torch.Size([462, 4]) tensor([ 76, 263, 225, 382], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 0.029204348102211952
bi 1 loss 0.03709300979971886
bi 2 loss 0.026714807376265526
bi 3 loss 0.04866006225347519
Layer  2  loss:  0.03500775620341301 0.0 0.7348605990409851
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([ 75, 214, 245, 371], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 0.040345821529626846
bi 1 loss 0.024719465523958206
bi 2 loss 0.033312998712062836
bi 3 loss 0.04037845879793167
Layer  3  loss:  0.041975151747465134 0.0 2.6351797580718994
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1017
Curr loss timestep torch.Size([462, 4]) tensor([ 88, 206, 261, 296], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.02989923767745495
bi 1 loss 0.03319977968931198
bi 2 loss 0.038294754922389984
bi 3 loss 0.05154437944293022
Layer  4  loss:  0.04915567487478256 0.0 4.624141693115234
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1021
Curr loss timestep torch.Size([462, 4]) tensor([ 67, 270, 260, 383], device='cuda:0') tensor(383, device='cuda:0')
bi 0 loss 0.018785690888762474
bi 1 loss 0.0557515025138855
bi 2 loss 0.0295742005109787
bi 3 loss 0.058595627546310425
Layer  5  loss:  0.046283405274152756 0.0 2.2469592094421387
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([ 56, 225, 257, 201], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 0.021822771057486534
bi 1 loss 0.04111611470580101
bi 2 loss 0.023859260603785515
bi 3 loss 0.06216958537697792
Layer  6  loss:  0.03618050739169121 0.0 0.80247962474823
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1019
Curr loss timestep torch.Size([462, 4]) tensor([ 57, 263, 262, 178], device='cuda:0') tensor(178, device='cuda:0')
bi 0 loss 0.011014610528945923
bi 1 loss 0.0307085569947958
bi 2 loss 0.05082254484295845
bi 3 loss 0.04200180247426033
Epoch 0: :   3%|▎         | 15883/600000 [06:08<3:45:49, v_num=12, reduced_train_loss=0.472, global_step=15881.0, consumed_samples=63528.0, train_step_timing in s=0.359]Epoch 0: :   3%|▎         | 15883/600000 [06:08<3:45:49, v_num=12, reduced_train_loss=0.333, global_step=15882.0, consumed_samples=63532.0, train_step_timing in s=0.330]loss mask original None

First layer loss:  0.23580153286457062 torch.Size([601, 4]) 18.312543869018555 0.0
Max loss timestep torch.Size([601, 4]) tensor([463, 567, 289, 323], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.3171592950820923
speech mask sum tensor(296, device='cuda:0') loss mask sum tensor(296, device='cuda:0')
bi 1 loss 0.24326838552951813
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 2 loss 0.058950282633304596
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
bi 3 loss 0.23451438546180725
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
logits torch.Size([601, 4, 257024]) labels torch.Size([601, 4]) 0 257022
Layer  0  loss:  0.2790108025074005 0.0 12.8755521774292
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([410, 577, 289, 323], device='cuda:0') tensor(410, device='cuda:0')
bi 0 loss 0.3306422829627991
bi 1 loss 0.3725770115852356
bi 2 loss 0.06912222504615784
bi 3 loss 0.22274768352508545
Layer  1  loss:  0.2717163562774658 0.0 14.621170997619629
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([446, 481, 294, 322], device='cuda:0') tensor(446, device='cuda:0')
bi 0 loss 0.33345475792884827
bi 1 loss 0.3483712673187256
bi 2 loss 0.08141009509563446
bi 3 loss 0.21393904089927673
Layer  2  loss:  0.30879244208335876 0.0 17.40627670288086
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([446, 481, 289, 323], device='cuda:0') tensor(481, device='cuda:0')
bi 0 loss 0.39377155900001526
bi 1 loss 0.39778926968574524
bi 2 loss 0.10805928707122803
bi 3 loss 0.21506452560424805
Layer  3  loss:  0.29349109530448914 0.0 14.730653762817383
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([413, 480, 289, 323], device='cuda:0') tensor(413, device='cuda:0')
bi 0 loss 0.4129300117492676
bi 1 loss 0.2999832332134247
bi 2 loss 0.16677604615688324
bi 3 loss 0.22152942419052124
Layer  4  loss:  0.2954333424568176 0.0 16.898109436035156
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([462, 347, 288, 322], device='cuda:0') tensor(462, device='cuda:0')
bi 0 loss 0.3899824917316437
bi 1 loss 0.34606048464775085
bi 2 loss 0.11571520566940308
bi 3 loss 0.2268100380897522
Layer  5  loss:  0.3520902395248413 0.0 15.828390121459961
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1022
Curr loss timestep torch.Size([601, 4]) tensor([463, 481, 270, 323], device='cuda:0') tensor(463, device='cuda:0')
bi 0 loss 0.46968820691108704
bi 1 loss 0.43262478709220886
bi 2 loss 0.1503455489873886
bi 3 loss 0.2323804348707199
Layer  6  loss:  0.3300708830356598 0.0 20.406259536743164
logits torch.Size([601, 4, 1024]) labels torch.Size([601, 4]) 0 1023
Curr loss timestep torch.Size([601, 4]) tensor([462, 472, 266, 341], device='cuda:0') tensor(462, device='cuda:0')
bi 0 loss 0.49571165442466736
bi 1 loss 0.37123408913612366
bi 2 loss 0.1245381087064743
bi 3 loss 0.20703688263893127
Epoch 0: :   3%|▎         | 15884/600000 [06:08<3:46:05, v_num=12, reduced_train_loss=0.333, global_step=15882.0, consumed_samples=63532.0, train_step_timing in s=0.330]Epoch 0: :   3%|▎         | 15884/600000 [06:08<3:46:05, v_num=12, reduced_train_loss=2.370, global_step=15883.0, consumed_samples=63536.0, train_step_timing in s=0.410]loss mask original None

First layer loss:  0.16756291687488556 torch.Size([653, 4]) 12.41322135925293 0.0
Max loss timestep torch.Size([653, 4]) tensor([280, 267, 295,  67], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.2017538994550705
speech mask sum tensor(500, device='cuda:0') loss mask sum tensor(500, device='cuda:0')
bi 1 loss 0.13831160962581635
speech mask sum tensor(236, device='cuda:0') loss mask sum tensor(236, device='cuda:0')
bi 2 loss 0.17662489414215088
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 3 loss 0.016634417697787285
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
logits torch.Size([653, 4, 257024]) labels torch.Size([653, 4]) 0 257023
Layer  0  loss:  0.191020205616951 0.0 13.82633113861084
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([551, 267, 295, 100], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.23798440396785736
bi 1 loss 0.17908471822738647
bi 2 loss 0.16141018271446228
bi 3 loss 0.026028912514448166
Layer  1  loss:  0.20928245782852173 0.0 11.875523567199707
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([477, 267, 296,  62], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.24965225160121918
bi 1 loss 0.2142280638217926
bi 2 loss 0.17802457511425018
bi 3 loss 0.040759190917015076
Layer  2  loss:  0.22480911016464233 0.0 11.89834213256836
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([278, 266, 295,  62], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.2716052234172821
bi 1 loss 0.222882479429245
bi 2 loss 0.18918150663375854
bi 3 loss 0.049722280353307724
Layer  3  loss:  0.21573702991008759 0.0 10.060979843139648
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([551, 266, 296,  65], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.284422367811203
bi 1 loss 0.19065727293491364
bi 2 loss 0.15617553889751434
bi 3 loss 0.04415729641914368
Layer  4  loss:  0.25072595477104187 0.0 13.266011238098145
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([279, 266, 296,  84], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.30108609795570374
bi 1 loss 0.1775965541601181
bi 2 loss 0.2778884768486023
bi 3 loss 0.07429078221321106
Layer  5  loss:  0.2541583776473999 0.0 12.978520393371582
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([278, 266, 295,  96], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 0.3188382089138031
bi 1 loss 0.23705236613750458
bi 2 loss 0.21408312022686005
bi 3 loss 0.026783397421240807
Layer  6  loss:  0.2662140727043152 0.0 15.152694702148438
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([280, 267, 295,  90], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.34704113006591797
bi 1 loss 0.23379775881767273
bi 2 loss 0.2091692090034485
bi 3 loss 0.03431859612464905
Epoch 0: :   3%|▎         | 15885/600000 [06:09<3:46:23, v_num=12, reduced_train_loss=2.370, global_step=15883.0, consumed_samples=63536.0, train_step_timing in s=0.410]Epoch 0: :   3%|▎         | 15885/600000 [06:09<3:46:23, v_num=12, reduced_train_loss=1.780, global_step=15884.0, consumed_samples=63540.0, train_step_timing in s=0.469]loss mask original None

First layer loss:  3.6515777111053467 torch.Size([744, 4]) 11.90241813659668 0.0
Max loss timestep torch.Size([744, 4]) tensor([334, 139, 666, 143], device='cuda:0') tensor(373, device='cuda:0')
bi 0 loss 3.365976095199585
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 1 loss 3.778244972229004
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
bi 2 loss 3.7191545963287354
speech mask sum tensor(400, device='cuda:0') loss mask sum tensor(400, device='cuda:0')
bi 3 loss 3.7330269813537598
speech mask sum tensor(164, device='cuda:0') loss mask sum tensor(164, device='cuda:0')
logits torch.Size([744, 4, 257024]) labels torch.Size([744, 4]) 0 257022
Layer  0  loss:  4.14275598526001 0.0 10.801682472229004
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([160, 153, 579,  89], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 3.699265241622925
bi 1 loss 4.291684627532959
bi 2 loss 4.374482154846191
bi 3 loss 4.054931163787842
Layer  1  loss:  4.395299434661865 0.0 10.907207489013672
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([356, 139, 522, 128], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 4.132212162017822
bi 1 loss 4.625053405761719
bi 2 loss 4.4992899894714355
bi 3 loss 4.143758296966553
Layer  2  loss:  4.7544145584106445 0.0 9.734739303588867
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([274, 271, 361,  66], device='cuda:0') tensor(161, device='cuda:0')
bi 0 loss 4.518998622894287
bi 1 loss 4.934049129486084
bi 2 loss 4.802753448486328
bi 3 loss 4.689975738525391
Layer  3  loss:  4.838101387023926 0.0 9.850356101989746
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([192, 141, 677,  60], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 4.545924663543701
bi 1 loss 5.031161785125732
bi 2 loss 4.965964317321777
bi 3 loss 4.652002334594727
Layer  4  loss:  4.994379997253418 0.0 10.439716339111328
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([313, 398, 696,  91], device='cuda:0') tensor(398, device='cuda:0')
bi 0 loss 4.605584621429443
bi 1 loss 5.182093620300293
bi 2 loss 5.122178554534912
bi 3 loss 4.987562656402588
Layer  5  loss:  5.016557693481445 0.0 10.650019645690918
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([199, 280, 630, 135], device='cuda:0') tensor(369, device='cuda:0')
bi 0 loss 4.739992141723633
bi 1 loss 5.068653106689453
bi 2 loss 5.170334339141846
bi 3 loss 5.020238399505615
Layer  6  loss:  5.030301570892334 0.0 11.798107147216797
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([316, 276, 680, 105], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 4.703670978546143
bi 1 loss 5.117988109588623
bi 2 loss 5.168888092041016
bi 3 loss 5.087594032287598
Epoch 0: :   3%|▎         | 15886/600000 [06:09<3:46:40, v_num=12, reduced_train_loss=1.780, global_step=15884.0, consumed_samples=63540.0, train_step_timing in s=0.469]Epoch 0: :   3%|▎         | 15886/600000 [06:09<3:46:40, v_num=12, reduced_train_loss=36.80, global_step=15885.0, consumed_samples=63544.0, train_step_timing in s=0.444]loss mask original None

First layer loss:  0.06024067848920822 torch.Size([530, 4]) 6.533270359039307 0.0
Max loss timestep torch.Size([530, 4]) tensor([189, 190, 521, 331], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.028828365728259087
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 1 loss 0.032762520015239716
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 2 loss 0.09969057142734528
speech mask sum tensor(353, device='cuda:0') loss mask sum tensor(353, device='cuda:0')
bi 3 loss 0.04729229956865311
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
logits torch.Size([530, 4, 257024]) labels torch.Size([530, 4]) 0 257022
Layer  0  loss:  0.07729621976613998 0.0 7.303966522216797
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([195, 128, 407, 440], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.03764979541301727
bi 1 loss 0.02536439709365368
bi 2 loss 0.11953594535589218
bi 3 loss 0.08084208518266678
Layer  1  loss:  0.09636805206537247 0.0 11.643842697143555
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([240, 229, 407, 259], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.042372267693281174
bi 1 loss 0.04869546368718147
bi 2 loss 0.17237426340579987
bi 3 loss 0.06344546377658844
Layer  2  loss:  0.10314510017633438 0.0 11.068256378173828
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([ 99, 243, 407, 259], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.03492997586727142
bi 1 loss 0.0366450697183609
bi 2 loss 0.18567994236946106
bi 3 loss 0.08309287577867508
Layer  3  loss:  0.09945898503065109 0.0 8.128623962402344
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1021
Curr loss timestep torch.Size([530, 4]) tensor([235, 163, 288, 259], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.03843721002340317
bi 1 loss 0.04521115869283676
bi 2 loss 0.1584727019071579
bi 3 loss 0.09827399998903275
Layer  4  loss:  0.10100825130939484 0.0 11.532001495361328
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1023
Curr loss timestep torch.Size([530, 4]) tensor([245, 207, 506, 440], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.039260827004909515
bi 1 loss 0.03454509377479553
bi 2 loss 0.1801740676164627
bi 3 loss 0.08049272000789642
Layer  5  loss:  0.11869385093450546 0.0 16.781810760498047
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([106, 222, 407, 329], device='cuda:0') tensor(407, device='cuda:0')
bi 0 loss 0.044513389468193054
bi 1 loss 0.05753616988658905
bi 2 loss 0.20616254210472107
bi 3 loss 0.09357240796089172
Layer  6  loss:  0.09304475039243698 0.0 11.371217727661133
logits torch.Size([530, 4, 1024]) labels torch.Size([530, 4]) 0 1022
Curr loss timestep torch.Size([530, 4]) tensor([197, 149, 506, 398], device='cuda:0') tensor(506, device='cuda:0')
bi 0 loss 0.04533030092716217
bi 1 loss 0.04870811849832535
bi 2 loss 0.14858528971672058
bi 3 loss 0.08069510012865067
Epoch 0: :   3%|▎         | 15887/600000 [06:10<3:46:54, v_num=12, reduced_train_loss=36.80, global_step=15885.0, consumed_samples=63544.0, train_step_timing in s=0.444]Epoch 0: :   3%|▎         | 15887/600000 [06:10<3:46:54, v_num=12, reduced_train_loss=0.749, global_step=15886.0, consumed_samples=63548.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  0.13550013303756714 torch.Size([659, 4]) 11.921479225158691 0.0
Max loss timestep torch.Size([659, 4]) tensor([187, 191, 164, 597], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.03282877802848816
speech mask sum tensor(184, device='cuda:0') loss mask sum tensor(184, device='cuda:0')
bi 1 loss 0.025509675964713097
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
bi 2 loss 0.03832903504371643
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 3 loss 0.2696230411529541
speech mask sum tensor(356, device='cuda:0') loss mask sum tensor(356, device='cuda:0')
logits torch.Size([659, 4, 257024]) labels torch.Size([659, 4]) 0 257022
Layer  0  loss:  0.19225572049617767 0.0 11.805912017822266
logits torch.Size([659, 4, 1024]) labels torch.Size([659, 4]) 0 1023
Curr loss timestep torch.Size([659, 4]) tensor([159, 198, 167, 594], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.04191131889820099
bi 1 loss 0.016673613339662552
bi 2 loss 0.03739146143198013
bi 3 loss 0.39924192428588867
Layer  1  loss:  0.19853749871253967 0.0 15.458261489868164
logits torch.Size([659, 4, 1024]) labels torch.Size([659, 4]) 0 1022
Curr loss timestep torch.Size([659, 4]) tensor([156, 122, 116, 597], device='cuda:0') tensor(597, device='cuda:0')
bi 0 loss 0.05187740921974182
bi 1 loss 0.020444931462407112
bi 2 loss 0.04017673805356026
bi 3 loss 0.4060441851615906
Layer  2  loss:  0.1947522908449173 0.0 12.845368385314941
logits torch.Size([659, 4, 1024]) labels torch.Size([659, 4]) 0 1022
Curr loss timestep torch.Size([659, 4]) tensor([110, 195, 125, 594], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.04372897371649742
bi 1 loss 0.0410924032330513
bi 2 loss 0.04481245577335358
bi 3 loss 0.3924251198768616
Layer  3  loss:  0.24373608827590942 0.0 16.381397247314453
logits torch.Size([659, 4, 1024]) labels torch.Size([659, 4]) 0 1017
Curr loss timestep torch.Size([659, 4]) tensor([187, 170, 167, 514], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.0633280947804451
bi 1 loss 0.04839376360177994
bi 2 loss 0.05233605578541756
bi 3 loss 0.4893976151943207
Layer  4  loss:  0.23274876177310944 0.0 11.785709381103516
logits torch.Size([659, 4, 1024]) labels torch.Size([659, 4]) 0 1022
Curr loss timestep torch.Size([659, 4]) tensor([190, 193, 152, 551], device='cuda:0') tensor(551, device='cuda:0')
bi 0 loss 0.03741692379117012
bi 1 loss 0.03501439839601517
bi 2 loss 0.048233117908239365
bi 3 loss 0.4838426113128662
Layer  5  loss:  0.20985302329063416 0.0 13.398106575012207
logits torch.Size([659, 4, 1024]) labels torch.Size([659, 4]) 0 1022
Curr loss timestep torch.Size([659, 4]) tensor([131, 129, 178, 360], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.04263985529541969
bi 1 loss 0.03571037948131561
bi 2 loss 0.044141411781311035
bi 3 loss 0.42994388937950134
Layer  6  loss:  0.22936108708381653 0.0 12.917496681213379
logits torch.Size([659, 4, 1024]) labels torch.Size([659, 4]) 0 1021
Curr loss timestep torch.Size([659, 4]) tensor([ 86, 189, 180, 594], device='cuda:0') tensor(594, device='cuda:0')
bi 0 loss 0.0448622927069664
bi 1 loss 0.03770142421126366
bi 2 loss 0.04904277250170708
bi 3 loss 0.47090470790863037
Epoch 0: :   3%|▎         | 15888/600000 [06:10<3:47:11, v_num=12, reduced_train_loss=0.749, global_step=15886.0, consumed_samples=63548.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15888/600000 [06:10<3:47:11, v_num=12, reduced_train_loss=1.640, global_step=15887.0, consumed_samples=63552.0, train_step_timing in s=0.472]loss mask original None

First layer loss:  0.26506343483924866 torch.Size([751, 4]) 13.365874290466309 0.0
Max loss timestep torch.Size([751, 4]) tensor([392, 497, 217, 717], device='cuda:0') tensor(497, device='cuda:0')
bi 0 loss 0.23479218780994415
speech mask sum tensor(248, device='cuda:0') loss mask sum tensor(248, device='cuda:0')
bi 1 loss 0.27453774213790894
speech mask sum tensor(459, device='cuda:0') loss mask sum tensor(459, device='cuda:0')
bi 2 loss 0.035671673715114594
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 3 loss 0.3682488799095154
speech mask sum tensor(453, device='cuda:0') loss mask sum tensor(453, device='cuda:0')
logits torch.Size([751, 4, 257024]) labels torch.Size([751, 4]) 0 257023
Layer  0  loss:  0.24020268023014069 0.0 9.765137672424316
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1023
Curr loss timestep torch.Size([751, 4]) tensor([385, 496, 111, 416], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.24016155302524567
bi 1 loss 0.20006147027015686
bi 2 loss 0.046737365424633026
bi 3 loss 0.36204245686531067
Layer  1  loss:  0.34908655285835266 0.0 22.06308364868164
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1022
Curr loss timestep torch.Size([751, 4]) tensor([385, 260, 216, 717], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.3740617334842682
bi 1 loss 0.24697567522525787
bi 2 loss 0.029372621327638626
bi 3 loss 0.5729732513427734
Layer  2  loss:  0.372267484664917 0.0 17.657093048095703
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1022
Curr loss timestep torch.Size([751, 4]) tensor([385, 260, 113, 717], device='cuda:0') tensor(717, device='cuda:0')
bi 0 loss 0.40602633357048035
bi 1 loss 0.2729145884513855
bi 2 loss 0.07098004966974258
bi 3 loss 0.5808224678039551
Layer  3  loss:  0.3829779624938965 0.0 16.339962005615234
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1022
Curr loss timestep torch.Size([751, 4]) tensor([456, 495, 154, 717], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.31016603112220764
bi 1 loss 0.30796071887016296
bi 2 loss 0.05671045929193497
bi 3 loss 0.6356956362724304
Layer  4  loss:  0.34045490622520447 0.0 14.12544059753418
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1023
Curr loss timestep torch.Size([751, 4]) tensor([385, 260, 190, 380], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.4382782578468323
bi 1 loss 0.23438876867294312
bi 2 loss 0.04022509604692459
bi 3 loss 0.5202955603599548
Layer  5  loss:  0.3918135166168213 0.0 18.187503814697266
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1022
Curr loss timestep torch.Size([751, 4]) tensor([385, 260, 231, 446], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.3612319827079773
bi 1 loss 0.2959307134151459
bi 2 loss 0.04621659219264984
bi 3 loss 0.6506609916687012
Layer  6  loss:  0.4125800132751465 0.0 18.032346725463867
logits torch.Size([751, 4, 1024]) labels torch.Size([751, 4]) 0 1021
Curr loss timestep torch.Size([751, 4]) tensor([385, 495,  87, 416], device='cuda:0') tensor(385, device='cuda:0')
bi 0 loss 0.4487651288509369
bi 1 loss 0.2880566418170929
bi 2 loss 0.04023657739162445
bi 3 loss 0.6751133799552917
Epoch 0: :   3%|▎         | 15889/600000 [06:11<3:47:30, v_num=12, reduced_train_loss=1.640, global_step=15887.0, consumed_samples=63552.0, train_step_timing in s=0.472]Epoch 0: :   3%|▎         | 15889/600000 [06:11<3:47:30, v_num=12, reduced_train_loss=2.750, global_step=15888.0, consumed_samples=63556.0, train_step_timing in s=0.510]loss mask original None

First layer loss:  0.12254653871059418 torch.Size([610, 4]) 11.595931053161621 0.0
Max loss timestep torch.Size([610, 4]) tensor([519, 259, 355,  92], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.18974639475345612
speech mask sum tensor(502, device='cuda:0') loss mask sum tensor(502, device='cuda:0')
bi 1 loss 0.11026796698570251
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 2 loss 0.06458201259374619
speech mask sum tensor(263, device='cuda:0') loss mask sum tensor(263, device='cuda:0')
bi 3 loss 0.04122652858495712
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
logits torch.Size([610, 4, 257024]) labels torch.Size([610, 4]) 0 257023
Layer  0  loss:  0.15631641447544098 0.0 11.721172332763672
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([520, 259, 261, 197], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.22723571956157684
bi 1 loss 0.09892887622117996
bi 2 loss 0.15957148373126984
bi 3 loss 0.033765245229005814
Layer  1  loss:  0.1694570928812027 0.0 14.094170570373535
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1022
Curr loss timestep torch.Size([610, 4]) tensor([520, 260, 311,  78], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.29243072867393494
bi 1 loss 0.06024450436234474
bi 2 loss 0.11393380165100098
bi 3 loss 0.050930455327034
Layer  2  loss:  0.15643300116062164 0.0 15.822713851928711
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1022
Curr loss timestep torch.Size([610, 4]) tensor([520, 259, 273,  89], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.25177818536758423
bi 1 loss 0.11820987612009048
bi 2 loss 0.09664767980575562
bi 3 loss 0.034307047724723816
Layer  3  loss:  0.1760977804660797 0.0 12.156895637512207
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1021
Curr loss timestep torch.Size([610, 4]) tensor([390, 259, 261, 193], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.2882969379425049
bi 1 loss 0.15723268687725067
bi 2 loss 0.08127658069133759
bi 3 loss 0.035804904997348785
Layer  4  loss:  0.16115014255046844 0.0 16.176979064941406
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([517, 259, 356, 108], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.2671371400356293
bi 1 loss 0.10518742352724075
bi 2 loss 0.10218500345945358
bi 3 loss 0.030583679676055908
Layer  5  loss:  0.19038449227809906 0.0 16.80373764038086
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([517, 259, 350, 166], device='cuda:0') tensor(517, device='cuda:0')
bi 0 loss 0.3077535331249237
bi 1 loss 0.13449549674987793
bi 2 loss 0.12273003906011581
bi 3 loss 0.04206139221787453
Layer  6  loss:  0.18929921090602875 0.0 17.47348403930664
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1022
Curr loss timestep torch.Size([610, 4]) tensor([520, 259, 265,  92], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.30005714297294617
bi 1 loss 0.12081288546323776
bi 2 loss 0.13873787224292755
bi 3 loss 0.0492611825466156
Epoch 0: :   3%|▎         | 15890/600000 [06:11<3:47:46, v_num=12, reduced_train_loss=2.750, global_step=15888.0, consumed_samples=63556.0, train_step_timing in s=0.510]Epoch 0: :   3%|▎         | 15890/600000 [06:11<3:47:46, v_num=12, reduced_train_loss=1.320, global_step=15889.0, consumed_samples=63560.0, train_step_timing in s=0.416]loss mask original None

First layer loss:  0.19048772752285004 torch.Size([623, 4]) 11.943574905395508 0.0
Max loss timestep torch.Size([623, 4]) tensor([601, 442, 358, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.16479727625846863
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
bi 1 loss 0.2301657348871231
speech mask sum tensor(439, device='cuda:0') loss mask sum tensor(439, device='cuda:0')
bi 2 loss 0.14623595774173737
speech mask sum tensor(289, device='cuda:0') loss mask sum tensor(289, device='cuda:0')
bi 3 loss 0.20902787148952484
speech mask sum tensor(396, device='cuda:0') loss mask sum tensor(396, device='cuda:0')
logits torch.Size([623, 4, 257024]) labels torch.Size([623, 4]) 0 257022
Layer  0  loss:  0.22101502120494843 0.0 15.345831871032715
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([602, 322, 358, 277], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 0.21820533275604248
bi 1 loss 0.2839016318321228
bi 2 loss 0.15823861956596375
bi 3 loss 0.2004203051328659
Layer  1  loss:  0.24285075068473816 0.0 11.408318519592285
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([469, 443, 273, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.29263943433761597
bi 1 loss 0.2850959897041321
bi 2 loss 0.15111567080020905
bi 3 loss 0.20437654852867126
Layer  2  loss:  0.2625269591808319 0.0 14.3777437210083
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([610, 419, 273, 276], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 0.27170825004577637
bi 1 loss 0.32940176129341125
bi 2 loss 0.21177253127098083
bi 3 loss 0.2146267294883728
Layer  3  loss:  0.2395305186510086 0.0 21.195337295532227
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1021
Curr loss timestep torch.Size([623, 4]) tensor([469, 443, 273, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.22498707473278046
bi 1 loss 0.29787033796310425
bi 2 loss 0.15463651716709137
bi 3 loss 0.2539255619049072
Layer  4  loss:  0.25947561860084534 0.0 15.538291931152344
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1023
Curr loss timestep torch.Size([623, 4]) tensor([602, 442, 273, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.3191015124320984
bi 1 loss 0.3167922794818878
bi 2 loss 0.1670629382133484
bi 3 loss 0.1932118535041809
Layer  5  loss:  0.2711851894855499 0.0 18.4071102142334
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1022
Curr loss timestep torch.Size([623, 4]) tensor([602, 442, 273, 276], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.2627251148223877
bi 1 loss 0.36748090386390686
bi 2 loss 0.16248221695423126
bi 3 loss 0.25371986627578735
Layer  6  loss:  0.26797062158584595 0.0 17.621545791625977
logits torch.Size([623, 4, 1024]) labels torch.Size([623, 4]) 0 1020
Curr loss timestep torch.Size([623, 4]) tensor([602, 443, 352, 277], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.28832411766052246
bi 1 loss 0.37479549646377563
bi 2 loss 0.14737975597381592
bi 3 loss 0.21360167860984802
Epoch 0: :   3%|▎         | 15891/600000 [06:12<3:48:02, v_num=12, reduced_train_loss=1.320, global_step=15889.0, consumed_samples=63560.0, train_step_timing in s=0.416]Epoch 0: :   3%|▎         | 15891/600000 [06:12<3:48:02, v_num=12, reduced_train_loss=1.960, global_step=15890.0, consumed_samples=63564.0, train_step_timing in s=0.426]loss mask original None

First layer loss:  0.004567257594317198 torch.Size([273, 4]) 0.06168398633599281 0.0
Max loss timestep torch.Size([273, 4]) tensor([164, 171,  96,  60], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 0.0050195688381791115
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 1 loss 0.004316838923841715
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 2 loss 0.0049807545728981495
speech mask sum tensor(78, device='cuda:0') loss mask sum tensor(78, device='cuda:0')
bi 3 loss 0.0034707204904407263
speech mask sum tensor(76, device='cuda:0') loss mask sum tensor(76, device='cuda:0')
logits torch.Size([273, 4, 257024]) labels torch.Size([273, 4]) 0 257022
Layer  0  loss:  0.0041417572647333145 0.0 0.037715330719947815
logits torch.Size([273, 4, 1024]) labels torch.Size([273, 4]) 0 1023
Curr loss timestep torch.Size([273, 4]) tensor([260, 164,  80,  42], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.004208204336464405
bi 1 loss 0.004100089427083731
bi 2 loss 0.0043522268533706665
bi 3 loss 0.0038324641063809395
Layer  1  loss:  0.004405423067510128 0.0 0.06506023555994034
logits torch.Size([273, 4, 1024]) labels torch.Size([273, 4]) 0 1022
Curr loss timestep torch.Size([273, 4]) tensor([250, 136, 118,  56], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 0.00531954038888216
bi 1 loss 0.0031377123668789864
bi 2 loss 0.004626404028385878
bi 3 loss 0.003672004444524646
Layer  2  loss:  0.004121729638427496 0.0 0.03520098701119423
logits torch.Size([273, 4, 1024]) labels torch.Size([273, 4]) 0 1022
Curr loss timestep torch.Size([273, 4]) tensor([135, 174,  79,  56], device='cuda:0') tensor(135, device='cuda:0')
bi 0 loss 0.004661303944885731
bi 1 loss 0.003733511548489332
bi 2 loss 0.004135201219469309
bi 3 loss 0.0034061470068991184
Layer  3  loss:  0.004115734715014696 0.0 0.04251699149608612
logits torch.Size([273, 4, 1024]) labels torch.Size([273, 4]) 0 1016
Curr loss timestep torch.Size([273, 4]) tensor([174, 156, 102,  82], device='cuda:0') tensor(102, device='cuda:0')
bi 0 loss 0.004158439114689827
bi 1 loss 0.004078694619238377
bi 2 loss 0.004243677016347647
bi 3 loss 0.003935948014259338
Layer  4  loss:  0.004728586412966251 0.0 0.04950670525431633
logits torch.Size([273, 4, 1024]) labels torch.Size([273, 4]) 0 1022
Curr loss timestep torch.Size([273, 4]) tensor([135, 134, 115,  44], device='cuda:0') tensor(134, device='cuda:0')
bi 0 loss 0.004500365350395441
bi 1 loss 0.005555465817451477
bi 2 loss 0.004780320916324854
bi 3 loss 0.0042311581782996655
Layer  5  loss:  0.004149368964135647 0.0 0.06688543409109116
logits torch.Size([273, 4, 1024]) labels torch.Size([273, 4]) 0 1022
Curr loss timestep torch.Size([273, 4]) tensor([255, 171, 124,  93], device='cuda:0') tensor(171, device='cuda:0')
bi 0 loss 0.004317124839872122
bi 1 loss 0.004576570820063353
bi 2 loss 0.004231160972267389
bi 3 loss 0.0032344614155590534
Layer  6  loss:  0.0048381974920630455 0.0 0.04603805020451546
logits torch.Size([273, 4, 1024]) labels torch.Size([273, 4]) 0 1022
Curr loss timestep torch.Size([273, 4]) tensor([247, 170,  87,  38], device='cuda:0') tensor(181, device='cuda:0')
bi 0 loss 0.006005039904266596
bi 1 loss 0.004519054666161537
bi 2 loss 0.0036142028402537107
bi 3 loss 0.0039948285557329655
Epoch 0: :   3%|▎         | 15892/600000 [06:12<3:48:12, v_num=12, reduced_train_loss=1.960, global_step=15890.0, consumed_samples=63564.0, train_step_timing in s=0.426]Epoch 0: :   3%|▎         | 15892/600000 [06:12<3:48:12, v_num=12, reduced_train_loss=0.0351, global_step=15891.0, consumed_samples=63568.0, train_step_timing in s=0.247]loss mask original None

First layer loss:  0.11125975102186203 torch.Size([493, 4]) 13.576988220214844 0.0
Max loss timestep torch.Size([493, 4]) tensor([340, 285, 433, 348], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.09414225816726685
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 1 loss 0.04864608123898506
speech mask sum tensor(280, device='cuda:0') loss mask sum tensor(280, device='cuda:0')
bi 2 loss 0.195896178483963
speech mask sum tensor(312, device='cuda:0') loss mask sum tensor(312, device='cuda:0')
bi 3 loss 0.08868358284235
speech mask sum tensor(199, device='cuda:0') loss mask sum tensor(199, device='cuda:0')
logits torch.Size([493, 4, 257024]) labels torch.Size([493, 4]) 0 257023
Layer  0  loss:  0.12368952482938766 0.0 9.754627227783203
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1023
Curr loss timestep torch.Size([493, 4]) tensor([303, 305, 433, 280], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.08512358367443085
bi 1 loss 0.07118972390890121
bi 2 loss 0.20160003006458282
bi 3 loss 0.12501995265483856
Layer  1  loss:  0.12068349123001099 0.0 15.314847946166992
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1022
Curr loss timestep torch.Size([493, 4]) tensor([447, 312, 433, 242], device='cuda:0') tensor(433, device='cuda:0')
bi 0 loss 0.1095464900135994
bi 1 loss 0.04785733297467232
bi 2 loss 0.18493063747882843
bi 3 loss 0.13675028085708618
Layer  2  loss:  0.12986062467098236 0.0 9.937650680541992
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1022
Curr loss timestep torch.Size([493, 4]) tensor([261, 256, 419, 328], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.14853818714618683
bi 1 loss 0.05378168821334839
bi 2 loss 0.17547346651554108
bi 3 loss 0.14136531949043274
Layer  3  loss:  0.1401565670967102 0.0 11.91964340209961
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1021
Curr loss timestep torch.Size([493, 4]) tensor([261, 279, 378, 348], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 0.16637687385082245
bi 1 loss 0.06941506266593933
bi 2 loss 0.2052161693572998
bi 3 loss 0.10395879298448563
Layer  4  loss:  0.14551013708114624 0.0 13.883061408996582
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1022
Curr loss timestep torch.Size([493, 4]) tensor([261, 275, 381, 348], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.15867561101913452
bi 1 loss 0.06653765588998795
bi 2 loss 0.20962540805339813
bi 3 loss 0.13916833698749542
Layer  5  loss:  0.1312345564365387 0.0 14.718767166137695
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1023
Curr loss timestep torch.Size([493, 4]) tensor([261, 240, 381, 348], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.1624678373336792
bi 1 loss 0.034096475690603256
bi 2 loss 0.19725115597248077
bi 3 loss 0.12422837316989899
Layer  6  loss:  0.14533692598342896 0.0 11.737603187561035
logits torch.Size([493, 4, 1024]) labels torch.Size([493, 4]) 0 1023
Curr loss timestep torch.Size([493, 4]) tensor([261, 309, 381, 348], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 0.1469743847846985
bi 1 loss 0.06569360941648483
bi 2 loss 0.21258419752120972
bi 3 loss 0.1498585194349289
Epoch 0: :   3%|▎         | 15893/600000 [06:12<3:48:25, v_num=12, reduced_train_loss=0.0351, global_step=15891.0, consumed_samples=63568.0, train_step_timing in s=0.247]Epoch 0: :   3%|▎         | 15893/600000 [06:12<3:48:25, v_num=12, reduced_train_loss=1.050, global_step=15892.0, consumed_samples=63572.0, train_step_timing in s=0.355] loss mask original None

First layer loss:  0.10425520688295364 torch.Size([743, 4]) 9.199929237365723 0.0
Max loss timestep torch.Size([743, 4]) tensor([ 54, 372, 261, 648], device='cuda:0') tensor(648, device='cuda:0')
bi 0 loss 0.056472115218639374
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 1 loss 0.060484569519758224
speech mask sum tensor(345, device='cuda:0') loss mask sum tensor(345, device='cuda:0')
bi 2 loss 0.01762251742184162
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 3 loss 0.18567994236946106
speech mask sum tensor(501, device='cuda:0') loss mask sum tensor(501, device='cuda:0')
logits torch.Size([743, 4, 257024]) labels torch.Size([743, 4]) 0 257022
Layer  0  loss:  0.15627214312553406 0.0 12.688606262207031
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([ 51, 415, 239, 613], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.06795115768909454
bi 1 loss 0.1581050008535385
bi 2 loss 0.03309514746069908
bi 3 loss 0.23114001750946045
Layer  1  loss:  0.1667763888835907 0.0 11.627093315124512
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([ 82, 416, 261, 560], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.06203026697039604
bi 1 loss 0.13102228939533234
bi 2 loss 0.03511694446206093
bi 3 loss 0.2744010388851166
Layer  2  loss:  0.21407346427440643 0.0 17.582780838012695
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([ 55, 415, 264, 592], device='cuda:0') tensor(415, device='cuda:0')
bi 0 loss 0.045945655554533005
bi 1 loss 0.16729624569416046
bi 2 loss 0.044105831533670425
bi 3 loss 0.3586284816265106
Layer  3  loss:  0.1883680373430252 0.0 12.695296287536621
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([ 53, 414, 265, 648], device='cuda:0') tensor(648, device='cuda:0')
bi 0 loss 0.05299190431833267
bi 1 loss 0.16146953403949738
bi 2 loss 0.05168946459889412
bi 3 loss 0.29725906252861023
Layer  4  loss:  0.21070066094398499 0.0 13.670258522033691
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([ 63, 414,  85, 556], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.03887047618627548
bi 1 loss 0.1903449445962906
bi 2 loss 0.046978019177913666
bi 3 loss 0.3344913423061371
Layer  5  loss:  0.22104057669639587 0.0 14.004968643188477
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([ 80, 416, 262, 647], device='cuda:0') tensor(647, device='cuda:0')
bi 0 loss 0.05622522160410881
bi 1 loss 0.17954660952091217
bi 2 loss 0.03322317823767662
bi 3 loss 0.3704490065574646
Layer  6  loss:  0.19682897627353668 0.0 12.395228385925293
logits torch.Size([743, 4, 1024]) labels torch.Size([743, 4]) 0 1023
Curr loss timestep torch.Size([743, 4]) tensor([ 71, 416, 100, 725], device='cuda:0') tensor(416, device='cuda:0')
bi 0 loss 0.06655657291412354
bi 1 loss 0.16437466442584991
bi 2 loss 0.02164878323674202
bi 3 loss 0.32818397879600525
Epoch 0: :   3%|▎         | 15894/600000 [06:13<3:48:44, v_num=12, reduced_train_loss=1.050, global_step=15892.0, consumed_samples=63572.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15894/600000 [06:13<3:48:44, v_num=12, reduced_train_loss=1.460, global_step=15893.0, consumed_samples=63576.0, train_step_timing in s=0.506]loss mask original None

First layer loss:  0.0938805565237999 torch.Size([554, 4]) 12.093875885009766 0.0
Max loss timestep torch.Size([554, 4]) tensor([336, 313, 289, 273], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.11661934107542038
speech mask sum tensor(362, device='cuda:0') loss mask sum tensor(362, device='cuda:0')
bi 1 loss 0.0528651662170887
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 2 loss 0.02818927727639675
speech mask sum tensor(209, device='cuda:0') loss mask sum tensor(209, device='cuda:0')
bi 3 loss 0.1233140304684639
speech mask sum tensor(400, device='cuda:0') loss mask sum tensor(400, device='cuda:0')
logits torch.Size([554, 4, 257024]) labels torch.Size([554, 4]) 0 257022
Layer  0  loss:  0.0994216799736023 0.0 10.68829345703125
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([335, 313, 129, 396], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.11646349728107452
bi 1 loss 0.09288642555475235
bi 2 loss 0.03403647989034653
bi 3 loss 0.12066234648227692
Layer  1  loss:  0.10653503984212875 0.0 12.612065315246582
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([336, 313, 276, 526], device='cuda:0') tensor(336, device='cuda:0')
bi 0 loss 0.1331908255815506
bi 1 loss 0.090501569211483
bi 2 loss 0.05660891532897949
bi 3 loss 0.11463077366352081
Layer  2  loss:  0.11116301268339157 0.0 10.443187713623047
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([335, 313, 279, 396], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.12217952311038971
bi 1 loss 0.09494821727275848
bi 2 loss 0.0587942935526371
bi 3 loss 0.1347578912973404
Layer  3  loss:  0.10018501430749893 0.0 10.012506484985352
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([335, 312, 129, 526], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.12762631475925446
bi 1 loss 0.03795100376009941
bi 2 loss 0.04142921790480614
bi 3 loss 0.12985505163669586
Layer  4  loss:  0.11705129593610764 0.0 19.953353881835938
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1022
Curr loss timestep torch.Size([554, 4]) tensor([335, 313, 297, 526], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.1425127536058426
bi 1 loss 0.05797475948929787
bi 2 loss 0.058533426374197006
bi 3 loss 0.14718103408813477
Layer  5  loss:  0.10962269455194473 0.0 13.482762336730957
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1023
Curr loss timestep torch.Size([554, 4]) tensor([335, 313, 243, 396], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.1311185657978058
bi 1 loss 0.08763305842876434
bi 2 loss 0.04249570518732071
bi 3 loss 0.13365383446216583
Layer  6  loss:  0.09899884462356567 0.0 11.916108131408691
logits torch.Size([554, 4, 1024]) labels torch.Size([554, 4]) 0 1021
Curr loss timestep torch.Size([554, 4]) tensor([335, 313, 137, 526], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.0971953496336937
bi 1 loss 0.07018663734197617
bi 2 loss 0.03875727578997612
bi 3 loss 0.1431279182434082
Epoch 0: :   3%|▎         | 15895/600000 [06:13<3:48:59, v_num=12, reduced_train_loss=1.460, global_step=15893.0, consumed_samples=63576.0, train_step_timing in s=0.506]Epoch 0: :   3%|▎         | 15895/600000 [06:13<3:48:59, v_num=12, reduced_train_loss=0.837, global_step=15894.0, consumed_samples=63580.0, train_step_timing in s=0.377]loss mask original None

First layer loss:  3.8682188987731934 torch.Size([716, 4]) 12.06881332397461 0.0
Max loss timestep torch.Size([716, 4]) tensor([258, 186, 213, 304], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 3.713789939880371
speech mask sum tensor(324, device='cuda:0') loss mask sum tensor(324, device='cuda:0')
bi 1 loss 3.807685136795044
speech mask sum tensor(244, device='cuda:0') loss mask sum tensor(244, device='cuda:0')
bi 2 loss 4.157106876373291
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 3 loss 3.87249493598938
speech mask sum tensor(495, device='cuda:0') loss mask sum tensor(495, device='cuda:0')
logits torch.Size([716, 4, 257024]) labels torch.Size([716, 4]) 0 257023
Layer  0  loss:  4.286135673522949 0.0 10.336197853088379
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([383, 274, 133, 307], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 4.178526878356934
bi 1 loss 4.459360599517822
bi 2 loss 4.536761283874512
bi 3 loss 4.161312580108643
Layer  1  loss:  4.670716285705566 0.0 10.164162635803223
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([378, 277, 172, 339], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.693869590759277
bi 1 loss 4.6144819259643555
bi 2 loss 4.83443546295166
bi 3 loss 4.611508369445801
Layer  2  loss:  4.87454080581665 0.0 11.108541488647461
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([357, 202, 149, 415], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 4.874731540679932
bi 1 loss 5.010617256164551
bi 2 loss 5.0287251472473145
bi 3 loss 4.739747524261475
Layer  3  loss:  4.984152793884277 0.0 10.705790519714355
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1020
Curr loss timestep torch.Size([716, 4]) tensor([396, 327, 101, 351], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 4.92154598236084
bi 1 loss 5.119050979614258
bi 2 loss 5.252624034881592
bi 3 loss 4.840942859649658
Layer  4  loss:  5.055880069732666 0.0 10.176294326782227
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([487, 197, 126, 481], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.917850494384766
bi 1 loss 5.354782581329346
bi 2 loss 5.193158149719238
bi 3 loss 4.93870735168457
Layer  5  loss:  5.142256736755371 0.0 10.453200340270996
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1022
Curr loss timestep torch.Size([716, 4]) tensor([334, 125, 191, 635], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 4.927343845367432
bi 1 loss 5.27547025680542
bi 2 loss 5.234471321105957
bi 3 loss 5.176837921142578
Layer  6  loss:  5.1803507804870605 0.0 10.649884223937988
logits torch.Size([716, 4, 1024]) labels torch.Size([716, 4]) 0 1023
Curr loss timestep torch.Size([716, 4]) tensor([357, 119, 183, 247], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 4.877126693725586
bi 1 loss 5.5009660720825195
bi 2 loss 5.349551200866699
bi 3 loss 5.146608829498291
Epoch 0: :   3%|▎         | 15896/600000 [06:14<3:49:15, v_num=12, reduced_train_loss=0.837, global_step=15894.0, consumed_samples=63580.0, train_step_timing in s=0.377]Epoch 0: :   3%|▎         | 15896/600000 [06:14<3:49:15, v_num=12, reduced_train_loss=38.10, global_step=15895.0, consumed_samples=63584.0, train_step_timing in s=0.431]loss mask original None

First layer loss:  3.7550301551818848 torch.Size([652, 4]) 17.023990631103516 0.0
Max loss timestep torch.Size([652, 4]) tensor([327, 444, 334,  84], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 3.2687151432037354
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 1 loss 4.2268195152282715
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
bi 2 loss 4.080815315246582
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
bi 3 loss 2.910191535949707
speech mask sum tensor(116, device='cuda:0') loss mask sum tensor(116, device='cuda:0')
logits torch.Size([652, 4, 257024]) labels torch.Size([652, 4]) 0 257022
Layer  0  loss:  4.32305908203125 0.0 9.859210014343262
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1023
Curr loss timestep torch.Size([652, 4]) tensor([494, 394, 636,  72], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 3.8662121295928955
bi 1 loss 4.824845790863037
bi 2 loss 4.59025764465332
bi 3 loss 3.565213918685913
Layer  1  loss:  4.562831878662109 0.0 10.263472557067871
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1022
Curr loss timestep torch.Size([652, 4]) tensor([324, 428, 382, 107], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 4.239736080169678
bi 1 loss 4.936605930328369
bi 2 loss 4.843503475189209
bi 3 loss 3.5900330543518066
Layer  2  loss:  4.785221099853516 0.0 10.210480690002441
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1022
Curr loss timestep torch.Size([652, 4]) tensor([519, 381, 415,  67], device='cuda:0') tensor(381, device='cuda:0')
bi 0 loss 4.5185322761535645
bi 1 loss 5.410210609436035
bi 2 loss 4.912405967712402
bi 3 loss 3.7223968505859375
Layer  3  loss:  4.8821258544921875 0.0 10.892158508300781
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1021
Curr loss timestep torch.Size([652, 4]) tensor([220, 351, 483, 137], device='cuda:0') tensor(430, device='cuda:0')
bi 0 loss 4.822988986968994
bi 1 loss 5.264316082000732
bi 2 loss 4.995949745178223
bi 3 loss 3.732126474380493
Layer  4  loss:  4.995487213134766 0.0 9.8643798828125
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1018
Curr loss timestep torch.Size([652, 4]) tensor([519, 351, 295,  92], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 4.818719863891602
bi 1 loss 5.511178493499756
bi 2 loss 5.11554479598999
bi 3 loss 3.909858465194702
Layer  5  loss:  5.076127052307129 0.0 9.966645240783691
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1022
Curr loss timestep torch.Size([652, 4]) tensor([465, 379, 429, 109], device='cuda:0') tensor(429, device='cuda:0')
bi 0 loss 4.920814514160156
bi 1 loss 5.6511993408203125
bi 2 loss 5.13467264175415
bi 3 loss 4.050799369812012
Layer  6  loss:  5.071105480194092 0.0 10.814173698425293
logits torch.Size([652, 4, 1024]) labels torch.Size([652, 4]) 0 1023
Curr loss timestep torch.Size([652, 4]) tensor([398, 470, 350, 114], device='cuda:0') tensor(470, device='cuda:0')
bi 0 loss 4.999495506286621
bi 1 loss 5.669111251831055
bi 2 loss 5.0728559494018555
bi 3 loss 3.9608898162841797
Epoch 0: :   3%|▎         | 15897/600000 [06:14<3:49:30, v_num=12, reduced_train_loss=38.10, global_step=15895.0, consumed_samples=63584.0, train_step_timing in s=0.431]Epoch 0: :   3%|▎         | 15897/600000 [06:14<3:49:30, v_num=12, reduced_train_loss=37.50, global_step=15896.0, consumed_samples=63588.0, train_step_timing in s=0.403]loss mask original None

First layer loss:  3.0603365898132324 torch.Size([400, 4]) 10.833982467651367 0.0
Max loss timestep torch.Size([400, 4]) tensor([216, 186, 359, 279], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 2.8512375354766846
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 1 loss 2.760706663131714
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 2 loss 3.260775566101074
speech mask sum tensor(248, device='cuda:0') loss mask sum tensor(248, device='cuda:0')
bi 3 loss 3.14737868309021
speech mask sum tensor(156, device='cuda:0') loss mask sum tensor(156, device='cuda:0')
logits torch.Size([400, 4, 257024]) labels torch.Size([400, 4]) 0 257022
Layer  0  loss:  3.6286303997039795 0.0 10.439247131347656
logits torch.Size([400, 4, 1024]) labels torch.Size([400, 4]) 0 1023
Curr loss timestep torch.Size([400, 4]) tensor([146, 175, 242, 250], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 3.509960412979126
bi 1 loss 3.0139176845550537
bi 2 loss 3.969632148742676
bi 3 loss 3.564751148223877
Layer  1  loss:  3.957753896713257 0.0 9.493207931518555
logits torch.Size([400, 4, 1024]) labels torch.Size([400, 4]) 0 1022
Curr loss timestep torch.Size([400, 4]) tensor([246, 195, 375, 365], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 3.92734956741333
bi 1 loss 3.768629789352417
bi 2 loss 4.230124473571777
bi 3 loss 3.664919376373291
Layer  2  loss:  4.260245323181152 0.0 9.81590461730957
logits torch.Size([400, 4, 1024]) labels torch.Size([400, 4]) 0 1022
Curr loss timestep torch.Size([400, 4]) tensor([242, 203, 358, 316], device='cuda:0') tensor(166, device='cuda:0')
bi 0 loss 4.0387187004089355
bi 1 loss 4.425203800201416
bi 2 loss 4.587381839752197
bi 3 loss 3.9009525775909424
Layer  3  loss:  4.379179000854492 0.0 12.244161605834961
logits torch.Size([400, 4, 1024]) labels torch.Size([400, 4]) 0 1023
Curr loss timestep torch.Size([400, 4]) tensor([190, 153, 271, 313], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 4.162638187408447
bi 1 loss 4.279959201812744
bi 2 loss 4.655497074127197
bi 3 loss 4.24231481552124
Layer  4  loss:  4.5640387535095215 0.0 9.626243591308594
logits torch.Size([400, 4, 1024]) labels torch.Size([400, 4]) 0 1022
Curr loss timestep torch.Size([400, 4]) tensor([ 93, 176, 347, 294], device='cuda:0') tensor(165, device='cuda:0')
bi 0 loss 4.285739898681641
bi 1 loss 4.798099994659424
bi 2 loss 4.681713104248047
bi 3 loss 4.563979625701904
Layer  5  loss:  4.645132064819336 0.0 10.289315223693848
logits torch.Size([400, 4, 1024]) labels torch.Size([400, 4]) 0 1019
Curr loss timestep torch.Size([400, 4]) tensor([244, 207, 254, 358], device='cuda:0') tensor(207, device='cuda:0')
bi 0 loss 4.3319549560546875
bi 1 loss 5.011286735534668
bi 2 loss 4.810025215148926
bi 3 loss 4.536136150360107
Layer  6  loss:  4.731471061706543 0.0 10.233856201171875
logits torch.Size([400, 4, 1024]) labels torch.Size([400, 4]) 0 1022
Curr loss timestep torch.Size([400, 4]) tensor([172, 206, 362, 339], device='cuda:0') tensor(170, device='cuda:0')
bi 0 loss 4.524087429046631
bi 1 loss 4.820446968078613
bi 2 loss 4.930465221405029
bi 3 loss 4.602128028869629
Epoch 0: :   3%|▎         | 15898/600000 [06:15<3:49:42, v_num=12, reduced_train_loss=37.50, global_step=15896.0, consumed_samples=63588.0, train_step_timing in s=0.403]Epoch 0: :   3%|▎         | 15898/600000 [06:15<3:49:42, v_num=12, reduced_train_loss=33.20, global_step=15897.0, consumed_samples=63592.0, train_step_timing in s=0.305]loss mask original None

First layer loss:  0.0492364726960659 torch.Size([478, 4]) 5.786105632781982 0.0
Max loss timestep torch.Size([478, 4]) tensor([357, 181, 276, 357], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.06976132839918137
speech mask sum tensor(348, device='cuda:0') loss mask sum tensor(348, device='cuda:0')
bi 1 loss 0.04051258787512779
speech mask sum tensor(190, device='cuda:0') loss mask sum tensor(190, device='cuda:0')
bi 2 loss 0.03272683545947075
speech mask sum tensor(251, device='cuda:0') loss mask sum tensor(251, device='cuda:0')
bi 3 loss 0.045018892735242844
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
logits torch.Size([478, 4, 257024]) labels torch.Size([478, 4]) 0 257022
Layer  0  loss:  0.05832869932055473 0.0 5.141462326049805
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1023
Curr loss timestep torch.Size([478, 4]) tensor([357, 185, 275, 318], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.07587491720914841
bi 1 loss 0.03169628977775574
bi 2 loss 0.06266491115093231
bi 3 loss 0.05161702260375023
Layer  1  loss:  0.04623118415474892 0.0 6.060551643371582
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1021
Curr loss timestep torch.Size([478, 4]) tensor([371, 221, 275, 357], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.0467853769659996
bi 1 loss 0.021404597908258438
bi 2 loss 0.039418842643499374
bi 3 loss 0.06583525240421295
Layer  2  loss:  0.05853671953082085 0.0 7.319851875305176
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([452, 176, 288, 321], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.08504370599985123
bi 1 loss 0.03803930804133415
bi 2 loss 0.040225621312856674
bi 3 loss 0.05622904375195503
Layer  3  loss:  0.052088186144828796 0.0 2.600951671600342
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1023
Curr loss timestep torch.Size([478, 4]) tensor([420, 229, 145, 357], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.06160646304488182
bi 1 loss 0.03260135278105736
bi 2 loss 0.05190316215157509
bi 3 loss 0.05346108600497246
Layer  4  loss:  0.05834687873721123 0.0 4.402723789215088
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([357, 233, 288, 281], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 0.06224402040243149
bi 1 loss 0.047876257449388504
bi 2 loss 0.047122225165367126
bi 3 loss 0.06919782608747482
Layer  5  loss:  0.05631011351943016 0.0 6.127296447753906
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1023
Curr loss timestep torch.Size([478, 4]) tensor([274, 190, 275, 357], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.052884090691804886
bi 1 loss 0.037276096642017365
bi 2 loss 0.04825523495674133
bi 3 loss 0.07778965681791306
Layer  6  loss:  0.06375054270029068 0.0 4.121645450592041
logits torch.Size([478, 4, 1024]) labels torch.Size([478, 4]) 0 1022
Curr loss timestep torch.Size([478, 4]) tensor([354, 129, 276, 357], device='cuda:0') tensor(357, device='cuda:0')
bi 0 loss 0.06554382294416428
bi 1 loss 0.05023176968097687
bi 2 loss 0.05951972305774689
bi 3 loss 0.07320476323366165
Epoch 0: :   3%|▎         | 15899/600000 [06:15<3:49:55, v_num=12, reduced_train_loss=33.20, global_step=15897.0, consumed_samples=63592.0, train_step_timing in s=0.305]Epoch 0: :   3%|▎         | 15899/600000 [06:15<3:49:55, v_num=12, reduced_train_loss=0.443, global_step=15898.0, consumed_samples=63596.0, train_step_timing in s=0.349]loss mask original None

First layer loss:  0.10167591273784637 torch.Size([557, 4]) 14.156898498535156 0.0
Max loss timestep torch.Size([557, 4]) tensor([147, 479, 106, 451], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.025441598147153854
speech mask sum tensor(189, device='cuda:0') loss mask sum tensor(189, device='cuda:0')
bi 1 loss 0.08333459496498108
speech mask sum tensor(318, device='cuda:0') loss mask sum tensor(318, device='cuda:0')
bi 2 loss 0.04176900163292885
speech mask sum tensor(120, device='cuda:0') loss mask sum tensor(120, device='cuda:0')
bi 3 loss 0.16957107186317444
speech mask sum tensor(404, device='cuda:0') loss mask sum tensor(404, device='cuda:0')
logits torch.Size([557, 4, 257024]) labels torch.Size([557, 4]) 0 257022
Layer  0  loss:  0.11343378573656082 0.0 10.59558391571045
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1023
Curr loss timestep torch.Size([557, 4]) tensor([137, 392,  99, 453], device='cuda:0') tensor(453, device='cuda:0')
bi 0 loss 0.019511975347995758
bi 1 loss 0.10197915136814117
bi 2 loss 0.06266526132822037
bi 3 loss 0.18146847188472748
Layer  1  loss:  0.11645195633172989 0.0 12.523107528686523
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1022
Curr loss timestep torch.Size([557, 4]) tensor([206, 301,  74, 452], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.03511248156428337
bi 1 loss 0.0657426044344902
bi 2 loss 0.0763448029756546
bi 3 loss 0.20633211731910706
Layer  2  loss:  0.15735051035881042 0.0 12.372722625732422
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1022
Curr loss timestep torch.Size([557, 4]) tensor([205, 413, 139, 520], device='cuda:0') tensor(453, device='cuda:0')
bi 0 loss 0.030556166544556618
bi 1 loss 0.09576797485351562
bi 2 loss 0.04075991362333298
bi 3 loss 0.2997719347476959
Layer  3  loss:  0.12382543087005615 0.0 12.687568664550781
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1021
Curr loss timestep torch.Size([557, 4]) tensor([ 77, 479,  93, 453], device='cuda:0') tensor(453, device='cuda:0')
bi 0 loss 0.029206832870841026
bi 1 loss 0.07106223702430725
bi 2 loss 0.052178237587213516
bi 3 loss 0.23090283572673798
Layer  4  loss:  0.13343966007232666 0.0 12.663496017456055
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1022
Curr loss timestep torch.Size([557, 4]) tensor([ 82, 298,  75, 451], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.03749898448586464
bi 1 loss 0.0819137766957283
bi 2 loss 0.05706166848540306
bi 3 loss 0.24156680703163147
Layer  5  loss:  0.1308765411376953 0.0 9.688871383666992
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1017
Curr loss timestep torch.Size([557, 4]) tensor([ 79, 413, 138, 520], device='cuda:0') tensor(520, device='cuda:0')
bi 0 loss 0.038632288575172424
bi 1 loss 0.11463727802038193
bi 2 loss 0.04388563707470894
bi 3 loss 0.21265169978141785
Layer  6  loss:  0.12628065049648285 0.0 13.187243461608887
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1023
Curr loss timestep torch.Size([557, 4]) tensor([ 86, 301,  82, 453], device='cuda:0') tensor(453, device='cuda:0')
bi 0 loss 0.027193857356905937
bi 1 loss 0.08148439228534698
bi 2 loss 0.028938548639416695
bi 3 loss 0.23680956661701202
Epoch 0: :   3%|▎         | 15900/600000 [06:15<3:50:09, v_num=12, reduced_train_loss=0.443, global_step=15898.0, consumed_samples=63596.0, train_step_timing in s=0.349]Epoch 0: :   3%|▎         | 15900/600000 [06:15<3:50:09, v_num=12, reduced_train_loss=1.000, global_step=15899.0, consumed_samples=63600.0, train_step_timing in s=0.380]loss mask original None

First layer loss:  0.10515250265598297 torch.Size([527, 4]) 11.407157897949219 0.0
Max loss timestep torch.Size([527, 4]) tensor([352, 154, 153, 329], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.14138521254062653
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 1 loss 0.0462101474404335
speech mask sum tensor(141, device='cuda:0') loss mask sum tensor(141, device='cuda:0')
bi 2 loss 0.0326138436794281
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
bi 3 loss 0.1391354352235794
speech mask sum tensor(358, device='cuda:0') loss mask sum tensor(358, device='cuda:0')
logits torch.Size([527, 4, 257024]) labels torch.Size([527, 4]) 0 257022
Layer  0  loss:  0.1320599615573883 0.0 10.849203109741211
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1023
Curr loss timestep torch.Size([527, 4]) tensor([352, 122, 159, 411], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.2238643616437912
bi 1 loss 0.038773417472839355
bi 2 loss 0.06927361339330673
bi 3 loss 0.12983503937721252
Layer  1  loss:  0.1550815999507904 0.0 15.253096580505371
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1022
Curr loss timestep torch.Size([527, 4]) tensor([388,  60, 158, 411], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.2276087999343872
bi 1 loss 0.057436272501945496
bi 2 loss 0.045235905796289444
bi 3 loss 0.19573795795440674
Layer  2  loss:  0.14736145734786987 0.0 13.032051086425781
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1023
Curr loss timestep torch.Size([527, 4]) tensor([351, 126, 139, 411], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.22808118164539337
bi 1 loss 0.041757192462682724
bi 2 loss 0.040603719651699066
bi 3 loss 0.18291695415973663
Layer  3  loss:  0.14991305768489838 0.0 13.004862785339355
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1022
Curr loss timestep torch.Size([527, 4]) tensor([351, 145,  98, 411], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.1744227111339569
bi 1 loss 0.042929138988256454
bi 2 loss 0.07012376189231873
bi 3 loss 0.2161523848772049
Layer  4  loss:  0.15497981011867523 0.0 13.045907020568848
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1023
Curr loss timestep torch.Size([527, 4]) tensor([351,  66, 140, 411], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.2060340940952301
bi 1 loss 0.05731884390115738
bi 2 loss 0.044347796589136124
bi 3 loss 0.21322712302207947
Layer  5  loss:  0.1505660116672516 0.0 12.481958389282227
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1023
Curr loss timestep torch.Size([527, 4]) tensor([352, 110, 194, 298], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.21514545381069183
bi 1 loss 0.04959248751401901
bi 2 loss 0.049877673387527466
bi 3 loss 0.19386900961399078
Layer  6  loss:  0.1347581297159195 0.0 15.009398460388184
logits torch.Size([527, 4, 1024]) labels torch.Size([527, 4]) 0 1022
Curr loss timestep torch.Size([527, 4]) tensor([352,  79, 103, 410], device='cuda:0') tensor(352, device='cuda:0')
bi 0 loss 0.20000316202640533
bi 1 loss 0.05444332957267761
bi 2 loss 0.03494011610746384
bi 3 loss 0.16891629993915558
Epoch 0: :   3%|▎         | 15901/600000 [06:16<3:50:23, v_num=12, reduced_train_loss=1.000, global_step=15899.0, consumed_samples=63600.0, train_step_timing in s=0.380]Epoch 0: :   3%|▎         | 15901/600000 [06:16<3:50:23, v_num=12, reduced_train_loss=1.130, global_step=15900.0, consumed_samples=63604.0, train_step_timing in s=0.364]loss mask original None

First layer loss:  0.17120327055454254 torch.Size([665, 4]) 10.08259391784668 0.0
Max loss timestep torch.Size([665, 4]) tensor([ 92, 602, 332, 175], device='cuda:0') tensor(602, device='cuda:0')
bi 0 loss 0.08748272806406021
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 1 loss 0.2865610122680664
speech mask sum tensor(437, device='cuda:0') loss mask sum tensor(437, device='cuda:0')
bi 2 loss 0.07421579957008362
speech mask sum tensor(277, device='cuda:0') loss mask sum tensor(277, device='cuda:0')
bi 3 loss 0.0397920235991478
speech mask sum tensor(104, device='cuda:0') loss mask sum tensor(104, device='cuda:0')
logits torch.Size([665, 4, 257024]) labels torch.Size([665, 4]) 0 257022
Layer  0  loss:  0.18647916615009308 0.0 14.219236373901367
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1023
Curr loss timestep torch.Size([665, 4]) tensor([131, 554, 331, 173], device='cuda:0') tensor(554, device='cuda:0')
bi 0 loss 0.05855493247509003
bi 1 loss 0.33336544036865234
bi 2 loss 0.06430687010288239
bi 3 loss 0.039820533245801926
Layer  1  loss:  0.21680907905101776 0.0 15.728660583496094
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1023
Curr loss timestep torch.Size([665, 4]) tensor([126, 538, 331, 151], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.08920207619667053
bi 1 loss 0.3801705539226532
bi 2 loss 0.08673901110887527
bi 3 loss 0.021598251536488533
Layer  2  loss:  0.22390300035476685 0.0 13.42371654510498
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1022
Curr loss timestep torch.Size([665, 4]) tensor([107, 538, 332, 176], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.05428578332066536
bi 1 loss 0.4134550094604492
bi 2 loss 0.07221460342407227
bi 3 loss 0.02388647012412548
Layer  3  loss:  0.2386951595544815 0.0 15.91073989868164
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1022
Curr loss timestep torch.Size([665, 4]) tensor([ 93, 283, 411, 135], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.052235640585422516
bi 1 loss 0.4401151239871979
bi 2 loss 0.07644642144441605
bi 3 loss 0.03604705259203911
Layer  4  loss:  0.2435387223958969 0.0 15.53217887878418
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1023
Curr loss timestep torch.Size([665, 4]) tensor([109, 602, 331, 142], device='cuda:0') tensor(602, device='cuda:0')
bi 0 loss 0.031110096722841263
bi 1 loss 0.4216535687446594
bi 2 loss 0.1327911764383316
bi 3 loss 0.03111029975116253
Layer  5  loss:  0.2468373328447342 0.0 10.569562911987305
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1023
Curr loss timestep torch.Size([665, 4]) tensor([ 88, 539, 331, 154], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.042131029069423676
bi 1 loss 0.41154730319976807
bi 2 loss 0.1416502445936203
bi 3 loss 0.06716343760490417
Layer  6  loss:  0.26919516921043396 0.0 15.188488960266113
logits torch.Size([665, 4, 1024]) labels torch.Size([665, 4]) 0 1019
Curr loss timestep torch.Size([665, 4]) tensor([ 54, 538, 411, 176], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.0350848063826561
bi 1 loss 0.4598543047904968
bi 2 loss 0.14463157951831818
bi 3 loss 0.06545580923557281
Epoch 0: :   3%|▎         | 15902/600000 [06:16<3:50:41, v_num=12, reduced_train_loss=1.130, global_step=15900.0, consumed_samples=63604.0, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15902/600000 [06:16<3:50:41, v_num=12, reduced_train_loss=1.800, global_step=15901.0, consumed_samples=63608.0, train_step_timing in s=0.476]loss mask original None

First layer loss:  0.055966831743717194 torch.Size([610, 4]) 4.665690898895264 0.0
Max loss timestep torch.Size([610, 4]) tensor([179, 543, 264, 269], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.03641051426529884
speech mask sum tensor(163, device='cuda:0') loss mask sum tensor(163, device='cuda:0')
bi 1 loss 0.05735525116324425
speech mask sum tensor(489, device='cuda:0') loss mask sum tensor(489, device='cuda:0')
bi 2 loss 0.04420030117034912
speech mask sum tensor(189, device='cuda:0') loss mask sum tensor(189, device='cuda:0')
bi 3 loss 0.07143288105726242
speech mask sum tensor(306, device='cuda:0') loss mask sum tensor(306, device='cuda:0')
logits torch.Size([610, 4, 257024]) labels torch.Size([610, 4]) 0 257023
Layer  0  loss:  0.06900124251842499 0.0 12.837668418884277
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([233, 602, 325, 266], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.03483627364039421
bi 1 loss 0.06838728487491608
bi 2 loss 0.034348320215940475
bi 3 loss 0.10958465933799744
Layer  1  loss:  0.07272211462259293 0.0 6.262344837188721
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([263, 599, 321, 269], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.05267733708024025
bi 1 loss 0.09191732108592987
bi 2 loss 0.03485492616891861
bi 3 loss 0.07611344009637833
Layer  2  loss:  0.06598059833049774 0.0 7.565269470214844
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1022
Curr loss timestep torch.Size([610, 4]) tensor([152, 545, 186, 269], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.03418702259659767
bi 1 loss 0.06756928563117981
bi 2 loss 0.03462715074419975
bi 3 loss 0.09974296391010284
Layer  3  loss:  0.06100082769989967 0.0 6.639170169830322
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1021
Curr loss timestep torch.Size([610, 4]) tensor([178, 544, 288, 266], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.02258707396686077
bi 1 loss 0.07623270153999329
bi 2 loss 0.02600000984966755
bi 3 loss 0.07874007523059845
Layer  4  loss:  0.06786224246025085 0.0 7.54938268661499
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1022
Curr loss timestep torch.Size([610, 4]) tensor([161, 544, 329, 266], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.02847704477608204
bi 1 loss 0.07198728621006012
bi 2 loss 0.06604057550430298
bi 3 loss 0.08337509632110596
Layer  5  loss:  0.07439766824245453 0.0 4.918646812438965
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1023
Curr loss timestep torch.Size([610, 4]) tensor([265, 544, 184, 269], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.03556229546666145
bi 1 loss 0.08942916244268417
bi 2 loss 0.04452074319124222
bi 3 loss 0.08951696753501892
Layer  6  loss:  0.06876871734857559 0.0 4.02126407623291
logits torch.Size([610, 4, 1024]) labels torch.Size([610, 4]) 0 1022
Curr loss timestep torch.Size([610, 4]) tensor([158, 599, 262, 269], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.023611649870872498
bi 1 loss 0.07595673948526382
bi 2 loss 0.08483846485614777
bi 3 loss 0.07141079008579254
Epoch 0: :   3%|▎         | 15903/600000 [06:17<3:50:57, v_num=12, reduced_train_loss=1.800, global_step=15901.0, consumed_samples=63608.0, train_step_timing in s=0.476]Epoch 0: :   3%|▎         | 15903/600000 [06:17<3:50:57, v_num=12, reduced_train_loss=0.536, global_step=15902.0, consumed_samples=63612.0, train_step_timing in s=0.411]loss mask original None

First layer loss:  0.10604296624660492 torch.Size([557, 4]) 8.646612167358398 0.0
Max loss timestep torch.Size([557, 4]) tensor([534, 260, 310, 431], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.11820519715547562
speech mask sum tensor(478, device='cuda:0') loss mask sum tensor(478, device='cuda:0')
bi 1 loss 0.16746577620506287
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
bi 2 loss 0.0503019355237484
speech mask sum tensor(198, device='cuda:0') loss mask sum tensor(198, device='cuda:0')
bi 3 loss 0.06909286230802536
speech mask sum tensor(359, device='cuda:0') loss mask sum tensor(359, device='cuda:0')
logits torch.Size([557, 4, 257024]) labels torch.Size([557, 4]) 0 257023
Layer  0  loss:  0.12273424118757248 0.0 12.511679649353027
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1023
Curr loss timestep torch.Size([557, 4]) tensor([490, 304, 332, 320], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.1460835188627243
bi 1 loss 0.19928990304470062
bi 2 loss 0.07559533417224884
bi 3 loss 0.05345651134848595
Layer  1  loss:  0.10918351262807846 0.0 14.987829208374023
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1023
Curr loss timestep torch.Size([557, 4]) tensor([537, 287, 332, 259], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.09448456764221191
bi 1 loss 0.21409642696380615
bi 2 loss 0.07903025299310684
bi 3 loss 0.057422101497650146
Layer  2  loss:  0.1521710902452469 0.0 19.40963363647461
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1022
Curr loss timestep torch.Size([557, 4]) tensor([534, 286, 332, 268], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.18155747652053833
bi 1 loss 0.24282020330429077
bi 2 loss 0.0917799174785614
bi 3 loss 0.07034756243228912
Layer  3  loss:  0.13965283334255219 0.0 16.563600540161133
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1023
Curr loss timestep torch.Size([557, 4]) tensor([402, 286, 268, 328], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.1400650590658188
bi 1 loss 0.2685125470161438
bi 2 loss 0.1071123480796814
bi 3 loss 0.049009956419467926
Layer  4  loss:  0.13349975645542145 0.0 15.911089897155762
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1023
Curr loss timestep torch.Size([557, 4]) tensor([403, 286, 332, 181], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.1625957041978836
bi 1 loss 0.20203666388988495
bi 2 loss 0.1290130317211151
bi 3 loss 0.039769649505615234
Layer  5  loss:  0.1527286022901535 0.0 14.001664161682129
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1023
Curr loss timestep torch.Size([557, 4]) tensor([403, 286, 331, 115], device='cuda:0') tensor(286, device='cuda:0')
bi 0 loss 0.19694164395332336
bi 1 loss 0.22748808562755585
bi 2 loss 0.08972522616386414
bi 3 loss 0.06592697650194168
Layer  6  loss:  0.13633593916893005 0.0 9.192333221435547
logits torch.Size([557, 4, 1024]) labels torch.Size([557, 4]) 0 1021
Curr loss timestep torch.Size([557, 4]) tensor([359, 287, 332, 179], device='cuda:0') tensor(287, device='cuda:0')
bi 0 loss 0.1623331606388092
bi 1 loss 0.18879052996635437
bi 2 loss 0.12357472628355026
bi 3 loss 0.06477939337491989
Epoch 0: :   3%|▎         | 15904/600000 [06:17<3:51:12, v_num=12, reduced_train_loss=0.536, global_step=15902.0, consumed_samples=63612.0, train_step_timing in s=0.411]Epoch 0: :   3%|▎         | 15904/600000 [06:17<3:51:12, v_num=12, reduced_train_loss=1.050, global_step=15903.0, consumed_samples=63616.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  3.312282085418701 torch.Size([240, 4]) 10.94542407989502 0.0
Max loss timestep torch.Size([240, 4]) tensor([108, 137, 180, 159], device='cuda:0') tensor(151, device='cuda:0')
bi 0 loss 3.0218310356140137
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 1 loss 3.4613475799560547
speech mask sum tensor(92, device='cuda:0') loss mask sum tensor(92, device='cuda:0')
bi 2 loss 3.5212788581848145
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 3 loss 2.9368481636047363
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
logits torch.Size([240, 4, 257024]) labels torch.Size([240, 4]) 0 257023
Layer  0  loss:  3.6619603633880615 0.0 10.009628295898438
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1023
Curr loss timestep torch.Size([240, 4]) tensor([136, 102,  76, 181], device='cuda:0') tensor(154, device='cuda:0')
bi 0 loss 3.196594476699829
bi 1 loss 3.9152798652648926
bi 2 loss 3.913645029067993
bi 3 loss 3.3060288429260254
Layer  1  loss:  3.987555503845215 0.0 10.176624298095703
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([118, 153,  96, 186], device='cuda:0') tensor(155, device='cuda:0')
bi 0 loss 3.762720823287964
bi 1 loss 4.147025108337402
bi 2 loss 4.2913665771484375
bi 3 loss 3.1786327362060547
Layer  2  loss:  4.329738140106201 0.0 9.608773231506348
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([137, 120, 189, 187], device='cuda:0') tensor(160, device='cuda:0')
bi 0 loss 3.9981677532196045
bi 1 loss 4.21336555480957
bi 2 loss 4.641776084899902
bi 3 loss 4.077776908874512
Layer  3  loss:  4.424147129058838 0.0 10.05984115600586
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1023
Curr loss timestep torch.Size([240, 4]) tensor([131, 107, 157, 178], device='cuda:0') tensor(157, device='cuda:0')
bi 0 loss 4.001029014587402
bi 1 loss 4.214599609375
bi 2 loss 4.8374247550964355
bi 3 loss 4.142046928405762
Layer  4  loss:  4.430655002593994 0.0 9.672256469726562
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1022
Curr loss timestep torch.Size([240, 4]) tensor([155, 106, 210, 185], device='cuda:0') tensor(162, device='cuda:0')
bi 0 loss 3.9556586742401123
bi 1 loss 4.363556861877441
bi 2 loss 4.812568187713623
bi 3 loss 4.135032653808594
Layer  5  loss:  4.647731304168701 0.0 9.498374938964844
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1020
Curr loss timestep torch.Size([240, 4]) tensor([124, 166, 180, 204], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 4.0719218254089355
bi 1 loss 4.533721446990967
bi 2 loss 5.05038595199585
bi 3 loss 4.529537677764893
Layer  6  loss:  4.767446994781494 0.0 9.372285842895508
logits torch.Size([240, 4, 1024]) labels torch.Size([240, 4]) 0 1019
Curr loss timestep torch.Size([240, 4]) tensor([136, 149, 210, 170], device='cuda:0') tensor(164, device='cuda:0')
bi 0 loss 4.271210670471191
bi 1 loss 4.493008136749268
bi 2 loss 5.251437664031982
bi 3 loss 4.480083465576172
Epoch 0: :   3%|▎         | 15905/600000 [06:17<3:51:21, v_num=12, reduced_train_loss=1.050, global_step=15903.0, consumed_samples=63616.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15905/600000 [06:17<3:51:21, v_num=12, reduced_train_loss=33.60, global_step=15904.0, consumed_samples=63620.0, train_step_timing in s=0.227]loss mask original None

First layer loss:  0.1609494537115097 torch.Size([671, 4]) 15.750021934509277 0.0
Max loss timestep torch.Size([671, 4]) tensor([310, 499, 243, 391], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.16944122314453125
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
bi 1 loss 0.19665215909481049
speech mask sum tensor(482, device='cuda:0') loss mask sum tensor(482, device='cuda:0')
bi 2 loss 0.03081660531461239
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
bi 3 loss 0.16268672049045563
speech mask sum tensor(496, device='cuda:0') loss mask sum tensor(496, device='cuda:0')
logits torch.Size([671, 4, 257024]) labels torch.Size([671, 4]) 0 257022
Layer  0  loss:  0.17895860970020294 0.0 17.14825439453125
logits torch.Size([671, 4, 1024]) labels torch.Size([671, 4]) 0 1023
Curr loss timestep torch.Size([671, 4]) tensor([311, 498, 280, 390], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.164114847779274
bi 1 loss 0.22710387408733368
bi 2 loss 0.061587557196617126
bi 3 loss 0.17555716633796692
Layer  1  loss:  0.1847100406885147 0.0 14.81263256072998
logits torch.Size([671, 4, 1024]) labels torch.Size([671, 4]) 0 1022
Curr loss timestep torch.Size([671, 4]) tensor([310, 498, 232, 390], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.18385948240756989
bi 1 loss 0.22210028767585754
bi 2 loss 0.033292144536972046
bi 3 loss 0.19578580558300018
Layer  2  loss:  0.2126377373933792 0.0 11.910354614257812
logits torch.Size([671, 4, 1024]) labels torch.Size([671, 4]) 0 1022
Curr loss timestep torch.Size([671, 4]) tensor([310, 498, 170, 391], device='cuda:0') tensor(310, device='cuda:0')
bi 0 loss 0.2538054287433624
bi 1 loss 0.2924743890762329
bi 2 loss 0.053529027849435806
bi 3 loss 0.1651993691921234
Layer  3  loss:  0.21404503285884857 0.0 17.169816970825195
logits torch.Size([671, 4, 1024]) labels torch.Size([671, 4]) 0 1023
Curr loss timestep torch.Size([671, 4]) tensor([311, 498, 206, 391], device='cuda:0') tensor(311, device='cuda:0')
bi 0 loss 0.3102324903011322
bi 1 loss 0.2808210253715515
bi 2 loss 0.057196881622076035
bi 3 loss 0.1528617888689041
Layer  4  loss:  0.2116570770740509 0.0 13.637078285217285
logits torch.Size([671, 4, 1024]) labels torch.Size([671, 4]) 0 1022
Curr loss timestep torch.Size([671, 4]) tensor([398, 607, 242, 390], device='cuda:0') tensor(607, device='cuda:0')
bi 0 loss 0.2672981023788452
bi 1 loss 0.2619969844818115
bi 2 loss 0.0321396142244339
bi 3 loss 0.19244970381259918
Layer  5  loss:  0.23457345366477966 0.0 16.112817764282227
logits torch.Size([671, 4, 1024]) labels torch.Size([671, 4]) 0 1023
Curr loss timestep torch.Size([671, 4]) tensor([310, 498, 173, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.266051322221756
bi 1 loss 0.28220656514167786
bi 2 loss 0.06900027394294739
bi 3 loss 0.22496916353702545
Layer  6  loss:  0.22673021256923676 0.0 18.323564529418945
logits torch.Size([671, 4, 1024]) labels torch.Size([671, 4]) 0 1023
Curr loss timestep torch.Size([671, 4]) tensor([310, 498, 278, 390], device='cuda:0') tensor(390, device='cuda:0')
bi 0 loss 0.33365270495414734
bi 1 loss 0.24276787042617798
bi 2 loss 0.036113057285547256
bi 3 loss 0.22031670808792114
Epoch 0: :   3%|▎         | 15906/600000 [06:18<3:51:38, v_num=12, reduced_train_loss=33.60, global_step=15904.0, consumed_samples=63620.0, train_step_timing in s=0.227]Epoch 0: :   3%|▎         | 15906/600000 [06:18<3:51:38, v_num=12, reduced_train_loss=1.620, global_step=15905.0, consumed_samples=63624.0, train_step_timing in s=0.461]loss mask original None

First layer loss:  0.12993040680885315 torch.Size([591, 4]) 12.931760787963867 0.0
Max loss timestep torch.Size([591, 4]) tensor([304, 308, 154, 198], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.14615759253501892
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
bi 1 loss 0.17866258323192596
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 2 loss 0.030999762937426567
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 3 loss 0.05408609285950661
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
logits torch.Size([591, 4, 257024]) labels torch.Size([591, 4]) 0 257023
Layer  0  loss:  0.13131698966026306 0.0 15.607492446899414
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1023
Curr loss timestep torch.Size([591, 4]) tensor([305, 307, 154, 209], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.13307501375675201
bi 1 loss 0.21801099181175232
bi 2 loss 0.019524509087204933
bi 3 loss 0.03638962656259537
Layer  1  loss:  0.14632557332515717 0.0 16.316205978393555
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([305, 306, 210, 183], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.16857442259788513
bi 1 loss 0.19831247627735138
bi 2 loss 0.04223927855491638
bi 3 loss 0.0426180362701416
Layer  2  loss:  0.13302233815193176 0.0 11.575630187988281
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([305, 307, 208, 203], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.15003643929958344
bi 1 loss 0.18945322930812836
bi 2 loss 0.032511286437511444
bi 3 loss 0.036204930394887924
Layer  3  loss:  0.1420130580663681 0.0 17.48699378967285
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([305, 306, 230, 207], device='cuda:0') tensor(305, device='cuda:0')
bi 0 loss 0.16484780609607697
bi 1 loss 0.19116836786270142
bi 2 loss 0.039799463003873825
bi 3 loss 0.040757808834314346
Layer  4  loss:  0.15177704393863678 0.0 24.843870162963867
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1021
Curr loss timestep torch.Size([591, 4]) tensor([305, 307, 148, 232], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.1342727243900299
bi 1 loss 0.2849346101284027
bi 2 loss 0.031118106096982956
bi 3 loss 0.03200952708721161
Layer  5  loss:  0.1748265027999878 0.0 16.503360748291016
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([304, 308, 230, 223], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.2029954046010971
bi 1 loss 0.25034791231155396
bi 2 loss 0.032694678753614426
bi 3 loss 0.031191665679216385
Layer  6  loss:  0.17607785761356354 0.0 17.470584869384766
logits torch.Size([591, 4, 1024]) labels torch.Size([591, 4]) 0 1022
Curr loss timestep torch.Size([591, 4]) tensor([304, 308, 215, 218], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.173778235912323
bi 1 loss 0.29948562383651733
bi 2 loss 0.03548254445195198
bi 3 loss 0.03957810997962952
Epoch 0: :   3%|▎         | 15907/600000 [06:18<3:51:53, v_num=12, reduced_train_loss=1.620, global_step=15905.0, consumed_samples=63624.0, train_step_timing in s=0.461]Epoch 0: :   3%|▎         | 15907/600000 [06:18<3:51:53, v_num=12, reduced_train_loss=1.190, global_step=15906.0, consumed_samples=63628.0, train_step_timing in s=0.404]loss mask original None

First layer loss:  3.3000621795654297 torch.Size([744, 4]) 13.350360870361328 0.0
Max loss timestep torch.Size([744, 4]) tensor([135, 315, 461,  97], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 3.911503791809082
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 1 loss 3.0323126316070557
speech mask sum tensor(458, device='cuda:0') loss mask sum tensor(458, device='cuda:0')
bi 2 loss 3.190042495727539
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
bi 3 loss 3.7616076469421387
speech mask sum tensor(84, device='cuda:0') loss mask sum tensor(84, device='cuda:0')
logits torch.Size([744, 4, 257024]) labels torch.Size([744, 4]) 0 257023
Layer  0  loss:  3.954237461090088 0.0 10.50908374786377
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([197, 681, 659,  82], device='cuda:0') tensor(602, device='cuda:0')
bi 0 loss 4.150759220123291
bi 1 loss 3.672114372253418
bi 2 loss 4.087926387786865
bi 3 loss 4.233786582946777
Layer  1  loss:  4.307004451751709 0.0 9.882524490356445
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([136, 304, 274,  86], device='cuda:0') tensor(625, device='cuda:0')
bi 0 loss 4.777292251586914
bi 1 loss 3.8694422245025635
bi 2 loss 4.477766513824463
bi 3 loss 4.508131980895996
Layer  2  loss:  4.645276069641113 0.0 10.092608451843262
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([103, 296, 514, 122], device='cuda:0') tensor(103, device='cuda:0')
bi 0 loss 4.913992881774902
bi 1 loss 4.203251838684082
bi 2 loss 4.9200005531311035
bi 3 loss 4.824314117431641
Layer  3  loss:  4.6898393630981445 0.0 11.067288398742676
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([220, 600, 536,  72], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 5.27067756652832
bi 1 loss 4.091139316558838
bi 2 loss 4.926487445831299
bi 3 loss 5.113193511962891
Layer  4  loss:  4.854305267333984 0.0 10.081928253173828
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1022
Curr loss timestep torch.Size([744, 4]) tensor([ 97, 330, 456, 121], device='cuda:0') tensor(509, device='cuda:0')
bi 0 loss 5.4654998779296875
bi 1 loss 4.245164394378662
bi 2 loss 5.122208595275879
bi 3 loss 5.081328392028809
Layer  5  loss:  4.9881391525268555 0.0 10.161226272583008
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1023
Curr loss timestep torch.Size([744, 4]) tensor([255, 699, 625, 110], device='cuda:0') tensor(77, device='cuda:0')
bi 0 loss 5.564520359039307
bi 1 loss 4.422049522399902
bi 2 loss 5.195303440093994
bi 3 loss 5.408967018127441
Layer  6  loss:  4.98583459854126 0.0 11.077408790588379
logits torch.Size([744, 4, 1024]) labels torch.Size([744, 4]) 0 1020
Curr loss timestep torch.Size([744, 4]) tensor([ 99, 320, 242,  81], device='cuda:0') tensor(479, device='cuda:0')
bi 0 loss 5.45712423324585
bi 1 loss 4.427056789398193
bi 2 loss 5.2473530769348145
bi 3 loss 5.34175443649292
Epoch 0: :   3%|▎         | 15908/600000 [06:19<3:52:10, v_num=12, reduced_train_loss=1.190, global_step=15906.0, consumed_samples=63628.0, train_step_timing in s=0.404]Epoch 0: :   3%|▎         | 15908/600000 [06:19<3:52:10, v_num=12, reduced_train_loss=35.70, global_step=15907.0, consumed_samples=63632.0, train_step_timing in s=0.438]loss mask original None

First layer loss:  3.4614837169647217 torch.Size([524, 4]) 10.822731018066406 0.0
Max loss timestep torch.Size([524, 4]) tensor([167, 278, 216, 121], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 3.823697805404663
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
bi 1 loss 3.811943769454956
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 2 loss 3.1459457874298096
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
bi 3 loss 3.5674493312835693
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
logits torch.Size([524, 4, 257024]) labels torch.Size([524, 4]) 0 257023
Layer  0  loss:  3.8720483779907227 0.0 11.290928840637207
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([159, 263, 423, 122], device='cuda:0') tensor(251, device='cuda:0')
bi 0 loss 3.979313850402832
bi 1 loss 4.287306785583496
bi 2 loss 3.633545398712158
bi 3 loss 4.100120544433594
Layer  1  loss:  4.168514728546143 0.0 10.529767990112305
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1022
Curr loss timestep torch.Size([524, 4]) tensor([244, 321, 289, 161], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 4.31846284866333
bi 1 loss 4.502869606018066
bi 2 loss 3.9239046573638916
bi 3 loss 4.407959938049316
Layer  2  loss:  4.61070442199707 0.0 10.766530990600586
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1022
Curr loss timestep torch.Size([524, 4]) tensor([221, 239, 163, 239], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 4.595145225524902
bi 1 loss 4.613772869110107
bi 2 loss 4.564021587371826
bi 3 loss 4.7700700759887695
Layer  3  loss:  4.701079368591309 0.0 12.003217697143555
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([258, 240, 498, 225], device='cuda:0') tensor(130, device='cuda:0')
bi 0 loss 4.7816362380981445
bi 1 loss 4.752070903778076
bi 2 loss 4.651832580566406
bi 3 loss 4.682966232299805
Layer  4  loss:  4.85661506652832 0.0 12.020200729370117
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1022
Curr loss timestep torch.Size([524, 4]) tensor([282, 311, 390, 229], device='cuda:0') tensor(239, device='cuda:0')
bi 0 loss 4.85426664352417
bi 1 loss 4.897421836853027
bi 2 loss 4.804628849029541
bi 3 loss 4.983126163482666
Layer  5  loss:  4.922088623046875 0.0 10.424905776977539
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([100, 279, 248, 157], device='cuda:0') tensor(256, device='cuda:0')
bi 0 loss 4.969991207122803
bi 1 loss 5.040068626403809
bi 2 loss 4.864315509796143
bi 3 loss 4.930365562438965
Layer  6  loss:  5.042989730834961 0.0 10.614330291748047
logits torch.Size([524, 4, 1024]) labels torch.Size([524, 4]) 0 1023
Curr loss timestep torch.Size([524, 4]) tensor([189, 315, 450, 156], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 4.974874019622803
bi 1 loss 5.234675407409668
bi 2 loss 5.0246124267578125
bi 3 loss 5.061360836029053
Epoch 0: :   3%|▎         | 15909/600000 [06:19<3:52:23, v_num=12, reduced_train_loss=35.70, global_step=15907.0, consumed_samples=63632.0, train_step_timing in s=0.438]Epoch 0: :   3%|▎         | 15909/600000 [06:19<3:52:23, v_num=12, reduced_train_loss=35.60, global_step=15908.0, consumed_samples=63636.0, train_step_timing in s=0.342]loss mask original None

First layer loss:  0.16780410706996918 torch.Size([653, 4]) 9.375091552734375 0.0
Max loss timestep torch.Size([653, 4]) tensor([389, 347, 276, 141], device='cuda:0') tensor(389, device='cuda:0')
bi 0 loss 0.2540566027164459
speech mask sum tensor(441, device='cuda:0') loss mask sum tensor(441, device='cuda:0')
bi 1 loss 0.06672783195972443
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
bi 2 loss 0.20605716109275818
speech mask sum tensor(433, device='cuda:0') loss mask sum tensor(433, device='cuda:0')
bi 3 loss 0.02885926514863968
speech mask sum tensor(158, device='cuda:0') loss mask sum tensor(158, device='cuda:0')
logits torch.Size([653, 4, 257024]) labels torch.Size([653, 4]) 0 257023
Layer  0  loss:  0.1913101077079773 0.0 13.165252685546875
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([275, 342, 572, 151], device='cuda:0') tensor(572, device='cuda:0')
bi 0 loss 0.24334093928337097
bi 1 loss 0.07162946462631226
bi 2 loss 0.2869740128517151
bi 3 loss 0.028580835089087486
Layer  1  loss:  0.2329738885164261 0.0 15.255024909973145
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([367, 201, 572, 185], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.3673942983150482
bi 1 loss 0.06248356029391289
bi 2 loss 0.2947843074798584
bi 3 loss 0.03692977502942085
Layer  2  loss:  0.24746346473693848 0.0 14.183574676513672
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([591, 261, 546, 120], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.29427850246429443
bi 1 loss 0.1413555145263672
bi 2 loss 0.34881412982940674
bi 3 loss 0.05596079304814339
Layer  3  loss:  0.25282391905784607 0.0 15.153936386108398
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1021
Curr loss timestep torch.Size([653, 4]) tensor([264, 261, 572, 204], device='cuda:0') tensor(572, device='cuda:0')
bi 0 loss 0.374767929315567
bi 1 loss 0.1196298897266388
bi 2 loss 0.301979124546051
bi 3 loss 0.050040144473314285
Layer  4  loss:  0.229819655418396 0.0 13.170501708984375
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([264, 261, 573, 187], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.3585605025291443
bi 1 loss 0.09817854315042496
bi 2 loss 0.2685995399951935
bi 3 loss 0.03332395479083061
Layer  5  loss:  0.258964478969574 0.0 12.58073616027832
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([591, 303, 572, 133], device='cuda:0') tensor(572, device='cuda:0')
bi 0 loss 0.39699235558509827
bi 1 loss 0.0991879478096962
bi 2 loss 0.3138574957847595
bi 3 loss 0.049906518310308456
Layer  6  loss:  0.26313021779060364 0.0 13.145256996154785
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([591, 303, 542, 204], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.34972456097602844
bi 1 loss 0.09376901388168335
bi 2 loss 0.3818424344062805
bi 3 loss 0.04232770949602127
Epoch 0: :   3%|▎         | 15910/600000 [06:20<3:52:40, v_num=12, reduced_train_loss=35.60, global_step=15908.0, consumed_samples=63636.0, train_step_timing in s=0.342]Epoch 0: :   3%|▎         | 15910/600000 [06:20<3:52:40, v_num=12, reduced_train_loss=1.840, global_step=15909.0, consumed_samples=63640.0, train_step_timing in s=0.445]loss mask original None

First layer loss:  0.18619821965694427 torch.Size([714, 4]) 12.188126564025879 0.0
Max loss timestep torch.Size([714, 4]) tensor([680, 372, 220, 367], device='cuda:0') tensor(367, device='cuda:0')
bi 0 loss 0.16144061088562012
speech mask sum tensor(431, device='cuda:0') loss mask sum tensor(431, device='cuda:0')
bi 1 loss 0.33001041412353516
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 2 loss 0.04711944982409477
speech mask sum tensor(248, device='cuda:0') loss mask sum tensor(248, device='cuda:0')
bi 3 loss 0.15014450252056122
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
logits torch.Size([714, 4, 257024]) labels torch.Size([714, 4]) 0 257022
Layer  0  loss:  0.20470009744167328 0.0 11.530165672302246
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([664, 537, 260, 460], device='cuda:0') tensor(537, device='cuda:0')
bi 0 loss 0.14712579548358917
bi 1 loss 0.4307594299316406
bi 2 loss 0.04952705278992653
bi 3 loss 0.12296801805496216
Layer  1  loss:  0.24743284285068512 0.0 12.386765480041504
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1022
Curr loss timestep torch.Size([714, 4]) tensor([647, 514, 270, 366], device='cuda:0') tensor(514, device='cuda:0')
bi 0 loss 0.17976924777030945
bi 1 loss 0.4946361780166626
bi 2 loss 0.08553583174943924
bi 3 loss 0.15836751461029053
Layer  2  loss:  0.3074507415294647 0.0 17.173316955566406
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([664, 541, 270, 366], device='cuda:0') tensor(664, device='cuda:0')
bi 0 loss 0.23266875743865967
bi 1 loss 0.6048547625541687
bi 2 loss 0.10307182371616364
bi 3 loss 0.19876040518283844
Layer  3  loss:  0.2848662734031677 0.0 13.400933265686035
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([678, 546, 270, 366], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.2557604908943176
bi 1 loss 0.5403989553451538
bi 2 loss 0.09440062195062637
bi 3 loss 0.1541391909122467
Layer  4  loss:  0.2927663326263428 0.0 16.878477096557617
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([664, 551, 270, 366], device='cuda:0') tensor(366, device='cuda:0')
bi 0 loss 0.20229943096637726
bi 1 loss 0.5393149852752686
bi 2 loss 0.11837723106145859
bi 3 loss 0.24663998186588287
Layer  5  loss:  0.32482221722602844 0.0 17.488101959228516
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([664, 546, 270, 366], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.21483640372753143
bi 1 loss 0.6704722046852112
bi 2 loss 0.11268242448568344
bi 3 loss 0.21037745475769043
Layer  6  loss:  0.31801822781562805 0.0 21.001239776611328
logits torch.Size([714, 4, 1024]) labels torch.Size([714, 4]) 0 1023
Curr loss timestep torch.Size([714, 4]) tensor([678, 546, 271, 366], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.24453502893447876
bi 1 loss 0.671431839466095
bi 2 loss 0.06423603743314743
bi 3 loss 0.1760786771774292
Epoch 0: :   3%|▎         | 15911/600000 [06:20<3:52:58, v_num=12, reduced_train_loss=1.840, global_step=15909.0, consumed_samples=63640.0, train_step_timing in s=0.445]Epoch 0: :   3%|▎         | 15911/600000 [06:20<3:52:58, v_num=12, reduced_train_loss=2.170, global_step=15910.0, consumed_samples=63644.0, train_step_timing in s=0.481]loss mask original None

First layer loss:  3.437066078186035 torch.Size([404, 4]) 9.719634056091309 0.0
Max loss timestep torch.Size([404, 4]) tensor([142, 367, 270, 102], device='cuda:0') tensor(278, device='cuda:0')
bi 0 loss 3.689451217651367
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 1 loss 3.36299204826355
speech mask sum tensor(168, device='cuda:0') loss mask sum tensor(168, device='cuda:0')
bi 2 loss 1.855782151222229
speech mask sum tensor(59, device='cuda:0') loss mask sum tensor(59, device='cuda:0')
bi 3 loss 3.8293752670288086
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
logits torch.Size([404, 4, 257024]) labels torch.Size([404, 4]) 0 257022
Layer  0  loss:  3.818608283996582 0.0 10.835100173950195
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([112, 292, 265, 158], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 4.0911688804626465
bi 1 loss 3.744961738586426
bi 2 loss 1.9421013593673706
bi 3 loss 4.311758518218994
Layer  1  loss:  4.141463756561279 0.0 10.893665313720703
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([170, 371, 257, 182], device='cuda:0') tensor(257, device='cuda:0')
bi 0 loss 4.7004008293151855
bi 1 loss 3.9924559593200684
bi 2 loss 1.7482553720474243
bi 3 loss 4.479484558105469
Layer  2  loss:  4.420799732208252 0.0 10.5995454788208
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([149, 353, 264, 195], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 4.947173595428467
bi 1 loss 4.365278720855713
bi 2 loss 2.1385719776153564
bi 3 loss 4.640931129455566
Layer  3  loss:  4.553755283355713 0.0 9.357648849487305
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1021
Curr loss timestep torch.Size([404, 4]) tensor([159, 377, 282, 146], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 5.0843892097473145
bi 1 loss 4.404361724853516
bi 2 loss 2.2444489002227783
bi 3 loss 4.902251720428467
Layer  4  loss:  4.725122928619385 0.0 11.88632869720459
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1022
Curr loss timestep torch.Size([404, 4]) tensor([242, 267, 267, 190], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 5.418647289276123
bi 1 loss 4.472756385803223
bi 2 loss 2.5356285572052
bi 3 loss 4.873578071594238
Layer  5  loss:  4.645904064178467 0.0 10.164680480957031
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1019
Curr loss timestep torch.Size([404, 4]) tensor([254, 266, 275, 120], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 5.1623921394348145
bi 1 loss 4.628795623779297
bi 2 loss 2.5891873836517334
bi 3 loss 4.728662490844727
Layer  6  loss:  4.6424102783203125 0.0 10.998014450073242
logits torch.Size([404, 4, 1024]) labels torch.Size([404, 4]) 0 1023
Curr loss timestep torch.Size([404, 4]) tensor([300, 359, 267, 152], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 5.154219150543213
bi 1 loss 4.461009979248047
bi 2 loss 2.269632577896118
bi 3 loss 5.094529628753662
Epoch 0: :   3%|▎         | 15912/600000 [06:21<3:53:09, v_num=12, reduced_train_loss=2.170, global_step=15910.0, consumed_samples=63644.0, train_step_timing in s=0.481]Epoch 0: :   3%|▎         | 15912/600000 [06:21<3:53:09, v_num=12, reduced_train_loss=34.40, global_step=15911.0, consumed_samples=63648.0, train_step_timing in s=0.294]loss mask original None

First layer loss:  0.08402270823717117 torch.Size([565, 4]) 5.341988563537598 0.0
Max loss timestep torch.Size([565, 4]) tensor([276, 539, 381,  56], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.05643119290471077
speech mask sum tensor(293, device='cuda:0') loss mask sum tensor(293, device='cuda:0')
bi 1 loss 0.1320079267024994
speech mask sum tensor(455, device='cuda:0') loss mask sum tensor(455, device='cuda:0')
bi 2 loss 0.06967589259147644
speech mask sum tensor(325, device='cuda:0') loss mask sum tensor(325, device='cuda:0')
bi 3 loss 0.024244798347353935
speech mask sum tensor(152, device='cuda:0') loss mask sum tensor(152, device='cuda:0')
logits torch.Size([565, 4, 257024]) labels torch.Size([565, 4]) 0 257022
Layer  0  loss:  0.11457367241382599 0.0 8.688430786132812
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([268, 546, 379, 155], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.09286683052778244
bi 1 loss 0.138464093208313
bi 2 loss 0.13549800217151642
bi 3 loss 0.04016287252306938
Layer  1  loss:  0.12921947240829468 0.0 11.539590835571289
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([351, 360, 330,  96], device='cuda:0') tensor(360, device='cuda:0')
bi 0 loss 0.11306177824735641
bi 1 loss 0.188235342502594
bi 2 loss 0.09934018552303314
bi 3 loss 0.04759284853935242
Layer  2  loss:  0.1216791421175003 0.0 8.476600646972656
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([419, 535, 380,  88], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.07226865738630295
bi 1 loss 0.19646696746349335
bi 2 loss 0.09918853640556335
bi 3 loss 0.04114122688770294
Layer  3  loss:  0.1262008100748062 0.0 11.185185432434082
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([351, 361, 379, 106], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.0885014683008194
bi 1 loss 0.17600634694099426
bi 2 loss 0.12635524570941925
bi 3 loss 0.04945211112499237
Layer  4  loss:  0.1385226547718048 0.0 10.99563980102539
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([301, 539, 330,  93], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.08428530395030975
bi 1 loss 0.2332988977432251
bi 2 loss 0.1094169020652771
bi 3 loss 0.02159973420202732
Layer  5  loss:  0.13917423784732819 0.0 10.091197967529297
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1023
Curr loss timestep torch.Size([565, 4]) tensor([389, 539, 330, 104], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.09587522596120834
bi 1 loss 0.21120189130306244
bi 2 loss 0.1319098323583603
bi 3 loss 0.022562099620699883
Layer  6  loss:  0.15723556280136108 0.0 14.516379356384277
logits torch.Size([565, 4, 1024]) labels torch.Size([565, 4]) 0 1022
Curr loss timestep torch.Size([565, 4]) tensor([363, 539, 379, 118], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.09960463643074036
bi 1 loss 0.26803624629974365
bi 2 loss 0.11528447270393372
bi 3 loss 0.026351699605584145
Epoch 0: :   3%|▎         | 15913/600000 [06:21<3:53:24, v_num=12, reduced_train_loss=34.40, global_step=15911.0, consumed_samples=63648.0, train_step_timing in s=0.294]Epoch 0: :   3%|▎         | 15913/600000 [06:21<3:53:24, v_num=12, reduced_train_loss=1.010, global_step=15912.0, consumed_samples=63652.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  3.8127527236938477 torch.Size([696, 4]) 12.505412101745605 0.0
Max loss timestep torch.Size([696, 4]) tensor([217, 346, 673, 146], device='cuda:0') tensor(241, device='cuda:0')
bi 0 loss 3.8142178058624268
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
bi 1 loss 3.544274091720581
speech mask sum tensor(482, device='cuda:0') loss mask sum tensor(482, device='cuda:0')
bi 2 loss 4.273146152496338
speech mask sum tensor(466, device='cuda:0') loss mask sum tensor(466, device='cuda:0')
bi 3 loss 3.28255295753479
speech mask sum tensor(161, device='cuda:0') loss mask sum tensor(161, device='cuda:0')
logits torch.Size([696, 4, 257024]) labels torch.Size([696, 4]) 0 257023
Layer  0  loss:  4.202967166900635 0.0 12.922781944274902
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([169, 290, 353, 182], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 4.298523902893066
bi 1 loss 3.88454270362854
bi 2 loss 4.529250621795654
bi 3 loss 4.120463848114014
Layer  1  loss:  4.577188491821289 0.0 10.871101379394531
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1022
Curr loss timestep torch.Size([696, 4]) tensor([127, 572, 529, 253], device='cuda:0') tensor(244, device='cuda:0')
bi 0 loss 4.659787654876709
bi 1 loss 4.254204750061035
bi 2 loss 4.8785080909729
bi 3 loss 4.592986583709717
Layer  2  loss:  4.818179130554199 0.0 10.907694816589355
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([229, 289, 313, 133], device='cuda:0') tensor(249, device='cuda:0')
bi 0 loss 4.980006217956543
bi 1 loss 4.545926570892334
bi 2 loss 4.937887191772461
bi 3 loss 5.131969928741455
Layer  3  loss:  4.970545291900635 0.0 10.364269256591797
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([110, 270, 569, 144], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 5.077421188354492
bi 1 loss 4.694725036621094
bi 2 loss 5.200329303741455
bi 3 loss 5.028972148895264
Layer  4  loss:  5.08396053314209 0.0 11.122553825378418
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([215, 413, 594, 211], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 5.262501239776611
bi 1 loss 4.735880374908447
bi 2 loss 5.3564019203186035
bi 3 loss 5.166704177856445
Layer  5  loss:  5.174733638763428 0.0 11.033110618591309
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([202, 352, 245, 134], device='cuda:0') tensor(238, device='cuda:0')
bi 0 loss 5.380878448486328
bi 1 loss 4.882972240447998
bi 2 loss 5.37987756729126
bi 3 loss 5.257251262664795
Layer  6  loss:  5.275706768035889 0.0 10.829792022705078
logits torch.Size([696, 4, 1024]) labels torch.Size([696, 4]) 0 1023
Curr loss timestep torch.Size([696, 4]) tensor([244, 659, 330, 131], device='cuda:0') tensor(244, device='cuda:0')
bi 0 loss 5.455384254455566
bi 1 loss 4.997751235961914
bi 2 loss 5.472254276275635
bi 3 loss 5.367092132568359
Epoch 0: :   3%|▎         | 15914/600000 [06:21<3:53:40, v_num=12, reduced_train_loss=1.010, global_step=15912.0, consumed_samples=63652.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15914/600000 [06:21<3:53:40, v_num=12, reduced_train_loss=37.90, global_step=15913.0, consumed_samples=63656.0, train_step_timing in s=0.421]loss mask original None

First layer loss:  0.06564073264598846 torch.Size([519, 4]) 4.112096309661865 0.0
Max loss timestep torch.Size([519, 4]) tensor([340, 260, 152, 374], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.1113327145576477
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 1 loss 0.04872889071702957
speech mask sum tensor(119, device='cuda:0') loss mask sum tensor(119, device='cuda:0')
bi 2 loss 0.0410410538315773
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 3 loss 0.060453567653894424
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
logits torch.Size([519, 4, 257024]) labels torch.Size([519, 4]) 0 257022
Layer  0  loss:  0.0767490342259407 0.0 3.682244062423706
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([340, 268, 236, 365], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.08739887923002243
bi 1 loss 0.05620603263378143
bi 2 loss 0.0310708936303854
bi 3 loss 0.0937737450003624
Layer  1  loss:  0.08750659972429276 0.0 7.340325355529785
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([323, 261, 227, 365], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.11134297400712967
bi 1 loss 0.032570984214544296
bi 2 loss 0.05487767234444618
bi 3 loss 0.10338865965604782
Layer  2  loss:  0.08098497986793518 0.0 5.500053405761719
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([343, 257, 280, 365], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.06491786241531372
bi 1 loss 0.04672858864068985
bi 2 loss 0.05961974337697029
bi 3 loss 0.10350126773118973
Layer  3  loss:  0.11121498048305511 0.0 11.100367546081543
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([323, 220, 268, 365], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.10374719649553299
bi 1 loss 0.08437265455722809
bi 2 loss 0.04935330152511597
bi 3 loss 0.1426975131034851
Layer  4  loss:  0.08321624994277954 0.0 8.376818656921387
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([340, 188, 204, 306], device='cuda:0') tensor(306, device='cuda:0')
bi 0 loss 0.06282375007867813
bi 1 loss 0.061465904116630554
bi 2 loss 0.05034434050321579
bi 3 loss 0.10834001004695892
Layer  5  loss:  0.10642950236797333 0.0 7.00309419631958
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1022
Curr loss timestep torch.Size([519, 4]) tensor([323, 239, 233, 295], device='cuda:0') tensor(323, device='cuda:0')
bi 0 loss 0.12995773553848267
bi 1 loss 0.06447289884090424
bi 2 loss 0.05941392108798027
bi 3 loss 0.12422110885381699
Layer  6  loss:  0.09573576599359512 0.0 8.598357200622559
logits torch.Size([519, 4, 1024]) labels torch.Size([519, 4]) 0 1023
Curr loss timestep torch.Size([519, 4]) tensor([323, 256, 287, 365], device='cuda:0') tensor(365, device='cuda:0')
bi 0 loss 0.10434786230325699
bi 1 loss 0.0674343854188919
bi 2 loss 0.05868781730532646
bi 3 loss 0.11248864978551865
Epoch 0: :   3%|▎         | 15915/600000 [06:22<3:53:54, v_num=12, reduced_train_loss=37.90, global_step=15913.0, consumed_samples=63656.0, train_step_timing in s=0.421]Epoch 0: :   3%|▎         | 15915/600000 [06:22<3:53:54, v_num=12, reduced_train_loss=0.707, global_step=15914.0, consumed_samples=63660.0, train_step_timing in s=0.374]loss mask original None

First layer loss:  3.5301175117492676 torch.Size([536, 4]) 10.15073299407959 0.0
Max loss timestep torch.Size([536, 4]) tensor([140, 192, 280,  36], device='cuda:0') tensor(253, device='cuda:0')
bi 0 loss 3.791048526763916
speech mask sum tensor(445, device='cuda:0') loss mask sum tensor(445, device='cuda:0')
bi 1 loss 3.082399845123291
speech mask sum tensor(130, device='cuda:0') loss mask sum tensor(130, device='cuda:0')
bi 2 loss 3.4574103355407715
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 3 loss 2.954659938812256
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
logits torch.Size([536, 4, 257024]) labels torch.Size([536, 4]) 0 257022
Layer  0  loss:  4.270415782928467 0.0 10.39936637878418
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1023
Curr loss timestep torch.Size([536, 4]) tensor([440, 236, 252,  61], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 4.4697418212890625
bi 1 loss 3.77286434173584
bi 2 loss 4.346529006958008
bi 3 loss 3.9109885692596436
Layer  1  loss:  4.5340070724487305 0.0 10.800928115844727
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1022
Curr loss timestep torch.Size([536, 4]) tensor([201, 160, 288,  63], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 4.854891777038574
bi 1 loss 3.95599365234375
bi 2 loss 4.444965839385986
bi 3 loss 3.8664169311523438
Layer  2  loss:  4.732573509216309 0.0 10.046161651611328
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1023
Curr loss timestep torch.Size([536, 4]) tensor([132, 165, 237,  58], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 5.003871917724609
bi 1 loss 4.224335193634033
bi 2 loss 4.708696365356445
bi 3 loss 4.138607501983643
Layer  3  loss:  4.816599369049072 0.0 9.762895584106445
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1020
Curr loss timestep torch.Size([536, 4]) tensor([192, 224, 260,  35], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 5.065420150756836
bi 1 loss 4.160235404968262
bi 2 loss 4.665189743041992
bi 3 loss 4.7000412940979
Layer  4  loss:  4.944456100463867 0.0 9.9840087890625
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1022
Curr loss timestep torch.Size([536, 4]) tensor([128, 200, 238,  66], device='cuda:0') tensor(238, device='cuda:0')
bi 0 loss 5.251986980438232
bi 1 loss 4.299113750457764
bi 2 loss 4.754594326019287
bi 3 loss 4.558429718017578
Layer  5  loss:  5.03026008605957 0.0 10.014782905578613
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1017
Curr loss timestep torch.Size([536, 4]) tensor([168, 176, 224,  78], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 5.315870761871338
bi 1 loss 4.596813201904297
bi 2 loss 4.8153910636901855
bi 3 loss 4.470470905303955
Layer  6  loss:  5.058960437774658 0.0 9.74282455444336
logits torch.Size([536, 4, 1024]) labels torch.Size([536, 4]) 0 1022
Curr loss timestep torch.Size([536, 4]) tensor([483, 216, 296,  84], device='cuda:0') tensor(231, device='cuda:0')
bi 0 loss 5.331238269805908
bi 1 loss 4.431904315948486
bi 2 loss 4.915811538696289
bi 3 loss 4.7711029052734375
Epoch 0: :   3%|▎         | 15916/600000 [06:22<3:54:07, v_num=12, reduced_train_loss=0.707, global_step=15914.0, consumed_samples=63660.0, train_step_timing in s=0.374]Epoch 0: :   3%|▎         | 15916/600000 [06:22<3:54:07, v_num=12, reduced_train_loss=36.90, global_step=15915.0, consumed_samples=63664.0, train_step_timing in s=0.350]loss mask original None

First layer loss:  3.205869197845459 torch.Size([484, 4]) 12.516878128051758 0.0
Max loss timestep torch.Size([484, 4]) tensor([230, 180, 299, 238], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 3.1845154762268066
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 1 loss 3.580636978149414
speech mask sum tensor(113, device='cuda:0') loss mask sum tensor(113, device='cuda:0')
bi 2 loss 2.671548366546631
speech mask sum tensor(286, device='cuda:0') loss mask sum tensor(286, device='cuda:0')
bi 3 loss 3.7990007400512695
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
logits torch.Size([484, 4, 257024]) labels torch.Size([484, 4]) 0 257022
Layer  0  loss:  3.6726086139678955 0.0 11.068748474121094
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1023
Curr loss timestep torch.Size([484, 4]) tensor([304, 175, 333, 166], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 3.8176896572113037
bi 1 loss 4.047952651977539
bi 2 loss 3.141443967819214
bi 3 loss 4.030681610107422
Layer  1  loss:  3.8830437660217285 0.0 10.136245727539062
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1023
Curr loss timestep torch.Size([484, 4]) tensor([268, 193, 324, 254], device='cuda:0') tensor(214, device='cuda:0')
bi 0 loss 4.131124973297119
bi 1 loss 3.9830591678619385
bi 2 loss 3.253727912902832
bi 3 loss 4.400657653808594
Layer  2  loss:  4.181276321411133 0.0 9.753121376037598
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1022
Curr loss timestep torch.Size([484, 4]) tensor([312, 147, 431, 226], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.305305004119873
bi 1 loss 4.418067932128906
bi 2 loss 3.645078420639038
bi 3 loss 4.65568208694458
Layer  3  loss:  4.3198723793029785 0.0 9.723546981811523
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1021
Curr loss timestep torch.Size([484, 4]) tensor([273, 159, 354, 202], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.505935192108154
bi 1 loss 4.7997894287109375
bi 2 loss 3.597069025039673
bi 3 loss 4.840627670288086
Layer  4  loss:  4.4841108322143555 0.0 9.484857559204102
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1023
Curr loss timestep torch.Size([484, 4]) tensor([294, 143, 288, 208], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 4.606365203857422
bi 1 loss 4.845891952514648
bi 2 loss 3.7088327407836914
bi 3 loss 5.2377705574035645
Layer  5  loss:  4.575971603393555 0.0 10.27115249633789
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1023
Curr loss timestep torch.Size([484, 4]) tensor([136, 226, 234, 244], device='cuda:0') tensor(220, device='cuda:0')
bi 0 loss 4.761786937713623
bi 1 loss 5.135434627532959
bi 2 loss 3.8292086124420166
bi 3 loss 5.086169242858887
Layer  6  loss:  4.572250843048096 0.0 9.329054832458496
logits torch.Size([484, 4, 1024]) labels torch.Size([484, 4]) 0 1023
Curr loss timestep torch.Size([484, 4]) tensor([157, 173, 245, 167], device='cuda:0') tensor(245, device='cuda:0')
bi 0 loss 4.670243263244629
bi 1 loss 4.842914581298828
bi 2 loss 3.8327832221984863
bi 3 loss 5.359735488891602
Epoch 0: :   3%|▎         | 15917/600000 [06:23<3:54:20, v_num=12, reduced_train_loss=36.90, global_step=15915.0, consumed_samples=63664.0, train_step_timing in s=0.350]Epoch 0: :   3%|▎         | 15917/600000 [06:23<3:54:20, v_num=12, reduced_train_loss=32.90, global_step=15916.0, consumed_samples=63668.0, train_step_timing in s=0.325]loss mask original None

First layer loss:  0.09328488260507584 torch.Size([585, 4]) 9.316450119018555 0.0
Max loss timestep torch.Size([585, 4]) tensor([285, 161, 305, 218], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.10604354739189148
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 1 loss 0.02925746887922287
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 2 loss 0.10842100530862808
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
bi 3 loss 0.08722759783267975
speech mask sum tensor(215, device='cuda:0') loss mask sum tensor(215, device='cuda:0')
logits torch.Size([585, 4, 257024]) labels torch.Size([585, 4]) 0 257023
Layer  0  loss:  0.10901003330945969 0.0 14.021122932434082
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([285, 117, 530, 136], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.07686038315296173
bi 1 loss 0.033607568591833115
bi 2 loss 0.1652749478816986
bi 3 loss 0.08653197437524796
Layer  1  loss:  0.09663158655166626 0.0 9.856103897094727
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([284, 204, 562, 280], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.09647729247808456
bi 1 loss 0.02960163727402687
bi 2 loss 0.1283683329820633
bi 3 loss 0.07620078325271606
Layer  2  loss:  0.09675056487321854 0.0 7.637495040893555
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1023
Curr loss timestep torch.Size([585, 4]) tensor([285, 114, 545, 166], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.07934451848268509
bi 1 loss 0.027957415208220482
bi 2 loss 0.14072905480861664
bi 3 loss 0.07542929798364639
Layer  3  loss:  0.12086419016122818 0.0 14.397163391113281
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([284, 105, 530, 265], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.16852855682373047
bi 1 loss 0.027742497622966766
bi 2 loss 0.14649371802806854
bi 3 loss 0.0672365203499794
Layer  4  loss:  0.10725073516368866 0.0 11.720704078674316
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([285, 220, 546, 253], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.09074635058641434
bi 1 loss 0.04503843933343887
bi 2 loss 0.15432871878147125
bi 3 loss 0.07444511353969574
Layer  5  loss:  0.1106279194355011 0.0 9.016622543334961
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1020
Curr loss timestep torch.Size([585, 4]) tensor([285, 107, 546, 269], device='cuda:0') tensor(546, device='cuda:0')
bi 0 loss 0.12066016346216202
bi 1 loss 0.021881012246012688
bi 2 loss 0.1548801064491272
bi 3 loss 0.06590670347213745
Layer  6  loss:  0.12651784718036652 0.0 14.312785148620605
logits torch.Size([585, 4, 1024]) labels torch.Size([585, 4]) 0 1022
Curr loss timestep torch.Size([585, 4]) tensor([284, 209, 546, 108], device='cuda:0') tensor(284, device='cuda:0')
bi 0 loss 0.10861998796463013
bi 1 loss 0.028360538184642792
bi 2 loss 0.183068186044693
bi 3 loss 0.09943880140781403
Epoch 0: :   3%|▎         | 15918/600000 [06:23<3:54:35, v_num=12, reduced_train_loss=32.90, global_step=15916.0, consumed_samples=63668.0, train_step_timing in s=0.325]Epoch 0: :   3%|▎         | 15918/600000 [06:23<3:54:35, v_num=12, reduced_train_loss=0.861, global_step=15917.0, consumed_samples=63672.0, train_step_timing in s=0.401]loss mask original None

First layer loss:  0.06486997753381729 torch.Size([437, 4]) 9.13252067565918 0.0
Max loss timestep torch.Size([437, 4]) tensor([129, 269, 298, 257], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.10187573730945587
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 1 loss 0.06507252901792526
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 2 loss 0.04632832854986191
speech mask sum tensor(249, device='cuda:0') loss mask sum tensor(249, device='cuda:0')
bi 3 loss 0.06875857710838318
speech mask sum tensor(339, device='cuda:0') loss mask sum tensor(339, device='cuda:0')
logits torch.Size([437, 4, 257024]) labels torch.Size([437, 4]) 0 257022
Layer  0  loss:  0.07836068421602249 0.0 10.063628196716309
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([143, 269, 298, 258], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.02287864126265049
bi 1 loss 0.09481585770845413
bi 2 loss 0.06690523028373718
bi 3 loss 0.09108089655637741
Layer  1  loss:  0.07747147232294083 0.0 5.908517360687256
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([183, 267, 299, 323], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.04576103389263153
bi 1 loss 0.13721616566181183
bi 2 loss 0.047478869557380676
bi 3 loss 0.07107554376125336
Layer  2  loss:  0.0756995677947998 0.0 7.380624771118164
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([134, 269, 298, 257], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.060203567147254944
bi 1 loss 0.11025963723659515
bi 2 loss 0.08087115734815598
bi 3 loss 0.05471854656934738
Layer  3  loss:  0.07767924666404724 0.0 7.193635940551758
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([148, 269, 301, 331], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.04194042459130287
bi 1 loss 0.10105125606060028
bi 2 loss 0.09028416126966476
bi 3 loss 0.06335774064064026
Layer  4  loss:  0.06831974536180496 0.0 3.756695508956909
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([132, 269, 170, 257], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.06956759095191956
bi 1 loss 0.07109913975000381
bi 2 loss 0.061572056263685226
bi 3 loss 0.07124674320220947
Layer  5  loss:  0.08458016067743301 0.0 12.199385643005371
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1022
Curr loss timestep torch.Size([437, 4]) tensor([188, 269, 309, 333], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.09097304195165634
bi 1 loss 0.13721516728401184
bi 2 loss 0.07251713424921036
bi 3 loss 0.059485893696546555
Layer  6  loss:  0.08767083287239075 0.0 12.8759765625
logits torch.Size([437, 4, 1024]) labels torch.Size([437, 4]) 0 1023
Curr loss timestep torch.Size([437, 4]) tensor([137, 269, 188, 257], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.07506510615348816
bi 1 loss 0.13457101583480835
bi 2 loss 0.057031210511922836
bi 3 loss 0.08467182517051697
Epoch 0: :   3%|▎         | 15919/600000 [06:23<3:54:47, v_num=12, reduced_train_loss=0.861, global_step=15917.0, consumed_samples=63672.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15919/600000 [06:23<3:54:47, v_num=12, reduced_train_loss=0.615, global_step=15918.0, consumed_samples=63676.0, train_step_timing in s=0.318]loss mask original None

First layer loss:  0.10231125354766846 torch.Size([581, 4]) 14.684835433959961 0.0
Max loss timestep torch.Size([581, 4]) tensor([395, 144, 196, 496], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.20625342428684235
speech mask sum tensor(229, device='cuda:0') loss mask sum tensor(229, device='cuda:0')
bi 1 loss 0.04608679935336113
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
bi 2 loss 0.018557073548436165
speech mask sum tensor(139, device='cuda:0') loss mask sum tensor(139, device='cuda:0')
bi 3 loss 0.10739464312791824
speech mask sum tensor(406, device='cuda:0') loss mask sum tensor(406, device='cuda:0')
logits torch.Size([581, 4, 257024]) labels torch.Size([581, 4]) 0 257022
Layer  0  loss:  0.12313990294933319 0.0 12.8753023147583
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([394, 123, 186, 533], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.2968286871910095
bi 1 loss 0.03827032446861267
bi 2 loss 0.0184645876288414
bi 3 loss 0.11389642208814621
Layer  1  loss:  0.11067353934049606 0.0 11.906573295593262
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1023
Curr loss timestep torch.Size([581, 4]) tensor([400, 105, 261, 496], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.27634769678115845
bi 1 loss 0.038004133850336075
bi 2 loss 0.03557620942592621
bi 3 loss 0.08822160214185715
Layer  2  loss:  0.13409534096717834 0.0 17.660354614257812
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([395, 263, 243, 533], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.30099523067474365
bi 1 loss 0.03190425783395767
bi 2 loss 0.050840288400650024
bi 3 loss 0.13214142620563507
Layer  3  loss:  0.12788210809230804 0.0 13.250049591064453
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1020
Curr loss timestep torch.Size([581, 4]) tensor([395, 219, 178, 517], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.2752315104007721
bi 1 loss 0.04812358692288399
bi 2 loss 0.02853674441576004
bi 3 loss 0.12848535180091858
Layer  4  loss:  0.1459175944328308 0.0 14.016042709350586
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([395, 211, 209, 496], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.23883166909217834
bi 1 loss 0.05628073960542679
bi 2 loss 0.019155846908688545
bi 3 loss 0.19276657700538635
Layer  5  loss:  0.14496925473213196 0.0 15.35249137878418
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1017
Curr loss timestep torch.Size([581, 4]) tensor([394, 127, 197, 522], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.32235661149024963
bi 1 loss 0.05833008885383606
bi 2 loss 0.028170892968773842
bi 3 loss 0.13889284431934357
Layer  6  loss:  0.1284465342760086 0.0 10.81316089630127
logits torch.Size([581, 4, 1024]) labels torch.Size([581, 4]) 0 1022
Curr loss timestep torch.Size([581, 4]) tensor([395, 262, 201, 522], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.2914208471775055
bi 1 loss 0.03084319643676281
bi 2 loss 0.028600303456187248
bi 3 loss 0.13152819871902466
Epoch 0: :   3%|▎         | 15920/600000 [06:24<3:55:02, v_num=12, reduced_train_loss=0.615, global_step=15918.0, consumed_samples=63676.0, train_step_timing in s=0.318]Epoch 0: :   3%|▎         | 15920/600000 [06:24<3:55:02, v_num=12, reduced_train_loss=1.020, global_step=15919.0, consumed_samples=63680.0, train_step_timing in s=0.398]loss mask original None

First layer loss:  3.4015121459960938 torch.Size([488, 4]) 10.039924621582031 0.0
Max loss timestep torch.Size([488, 4]) tensor([187, 164, 113, 349], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 3.2547712326049805
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 1 loss 3.595787525177002
speech mask sum tensor(125, device='cuda:0') loss mask sum tensor(125, device='cuda:0')
bi 2 loss 3.303459405899048
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 3 loss 3.47701358795166
speech mask sum tensor(341, device='cuda:0') loss mask sum tensor(341, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257023
Layer  0  loss:  4.2731099128723145 0.0 11.581096649169922
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([367, 136, 112, 224], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 4.122849464416504
bi 1 loss 4.0893874168396
bi 2 loss 4.389252662658691
bi 3 loss 4.375751972198486
Layer  1  loss:  4.556274890899658 0.0 9.683605194091797
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([320, 162, 121, 302], device='cuda:0') tensor(218, device='cuda:0')
bi 0 loss 4.624064922332764
bi 1 loss 4.420898914337158
bi 2 loss 4.549161911010742
bi 3 loss 4.565938949584961
Layer  2  loss:  4.920882701873779 0.0 10.521133422851562
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([382, 163,  97, 335], device='cuda:0') tensor(213, device='cuda:0')
bi 0 loss 4.847743988037109
bi 1 loss 4.719758033752441
bi 2 loss 5.270429611206055
bi 3 loss 4.85625696182251
Layer  3  loss:  4.959392070770264 0.0 12.504624366760254
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([228, 167, 217, 438], device='cuda:0') tensor(217, device='cuda:0')
bi 0 loss 4.8166069984436035
bi 1 loss 5.015529155731201
bi 2 loss 5.03208065032959
bi 3 loss 4.99235200881958
Layer  4  loss:  5.197171688079834 0.0 10.995619773864746
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([239, 187, 232, 242], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 5.302715301513672
bi 1 loss 5.211336612701416
bi 2 loss 5.096879482269287
bi 3 loss 5.177120208740234
Layer  5  loss:  5.207273960113525 0.0 9.663284301757812
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([371, 138, 165, 430], device='cuda:0') tensor(201, device='cuda:0')
bi 0 loss 5.239994049072266
bi 1 loss 5.378173351287842
bi 2 loss 5.374907493591309
bi 3 loss 5.034539222717285
Layer  6  loss:  5.299295425415039 0.0 9.749288558959961
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([370, 221, 129, 241], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 5.387650012969971
bi 1 loss 5.38252592086792
bi 2 loss 5.4110307693481445
bi 3 loss 5.152474403381348
Epoch 0: :   3%|▎         | 15921/600000 [06:24<3:55:14, v_num=12, reduced_train_loss=1.020, global_step=15919.0, consumed_samples=63680.0, train_step_timing in s=0.398]Epoch 0: :   3%|▎         | 15921/600000 [06:24<3:55:14, v_num=12, reduced_train_loss=37.80, global_step=15920.0, consumed_samples=63684.0, train_step_timing in s=0.324]loss mask original None

First layer loss:  0.05492253601551056 torch.Size([566, 4]) 1.680668592453003 0.0
Max loss timestep torch.Size([566, 4]) tensor([194, 133, 271, 411], device='cuda:0') tensor(411, device='cuda:0')
bi 0 loss 0.025425201281905174
speech mask sum tensor(112, device='cuda:0') loss mask sum tensor(112, device='cuda:0')
bi 1 loss 0.021305175498127937
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 2 loss 0.02034323289990425
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
bi 3 loss 0.08298439532518387
speech mask sum tensor(374, device='cuda:0') loss mask sum tensor(374, device='cuda:0')
logits torch.Size([566, 4, 257024]) labels torch.Size([566, 4]) 0 257022
Layer  0  loss:  0.06177789345383644 0.0 6.073965072631836
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([196, 147, 258, 472], device='cuda:0') tensor(472, device='cuda:0')
bi 0 loss 0.020201612263917923
bi 1 loss 0.011707165278494358
bi 2 loss 0.016238225623965263
bi 3 loss 0.10068334639072418
Layer  1  loss:  0.07638310641050339 0.0 9.833683013916016
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([177, 127, 272, 544], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.051533568650484085
bi 1 loss 0.012374652549624443
bi 2 loss 0.04778117686510086
bi 3 loss 0.10679548978805542
Layer  2  loss:  0.07214964926242828 0.0 8.134138107299805
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([246, 115, 164, 544], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.03537391871213913
bi 1 loss 0.0069136833772063255
bi 2 loss 0.03500094637274742
bi 3 loss 0.1095038652420044
Layer  3  loss:  0.06436722725629807 0.0 3.863973617553711
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1019
Curr loss timestep torch.Size([566, 4]) tensor([238, 127, 186, 544], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.04206794127821922
bi 1 loss 0.019431984052062035
bi 2 loss 0.03826829418540001
bi 3 loss 0.08937617391347885
Layer  4  loss:  0.06004839763045311 0.0 3.5397942066192627
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1022
Curr loss timestep torch.Size([566, 4]) tensor([218, 126, 208, 544], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.032018452882766724
bi 1 loss 0.0322224460542202
bi 2 loss 0.032931651920080185
bi 3 loss 0.08380680531263351
Layer  5  loss:  0.07658190280199051 0.0 5.009792327880859
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([191, 130, 178, 395], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.025446007028222084
bi 1 loss 0.026613987982273102
bi 2 loss 0.03828422725200653
bi 3 loss 0.11567723006010056
Layer  6  loss:  0.07092659175395966 0.0 4.380991458892822
logits torch.Size([566, 4, 1024]) labels torch.Size([566, 4]) 0 1023
Curr loss timestep torch.Size([566, 4]) tensor([196, 125, 272, 295], device='cuda:0') tensor(295, device='cuda:0')
bi 0 loss 0.044316597282886505
bi 1 loss 0.01951460726559162
bi 2 loss 0.04347776249051094
bi 3 loss 0.09898509830236435
Epoch 0: :   3%|▎         | 15922/600000 [06:25<3:55:29, v_num=12, reduced_train_loss=37.80, global_step=15920.0, consumed_samples=63684.0, train_step_timing in s=0.324]Epoch 0: :   3%|▎         | 15922/600000 [06:25<3:55:29, v_num=12, reduced_train_loss=0.537, global_step=15921.0, consumed_samples=63688.0, train_step_timing in s=0.393]loss mask original None

First layer loss:  0.14603763818740845 torch.Size([525, 4]) 9.815644264221191 0.0
Max loss timestep torch.Size([525, 4]) tensor([428, 189, 260, 363], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.10406265407800674
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
bi 1 loss 0.0805414468050003
speech mask sum tensor(243, device='cuda:0') loss mask sum tensor(243, device='cuda:0')
bi 2 loss 0.18587087094783783
speech mask sum tensor(367, device='cuda:0') loss mask sum tensor(367, device='cuda:0')
bi 3 loss 0.1874839961528778
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
logits torch.Size([525, 4, 257024]) labels torch.Size([525, 4]) 0 257023
Layer  0  loss:  0.17905540764331818 0.0 10.698533058166504
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([428, 304, 260, 348], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.1189221665263176
bi 1 loss 0.1069662794470787
bi 2 loss 0.23534952104091644
bi 3 loss 0.22309376299381256
Layer  1  loss:  0.17692825198173523 0.0 12.794711112976074
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([428, 280, 358, 363], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.17355984449386597
bi 1 loss 0.08319725841283798
bi 2 loss 0.19389891624450684
bi 3 loss 0.23069697618484497
Layer  2  loss:  0.18819110095500946 0.0 12.18917179107666
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([441, 237, 359, 348], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.13764338195323944
bi 1 loss 0.09825456142425537
bi 2 loss 0.1948891580104828
bi 3 loss 0.2928100824356079
Layer  3  loss:  0.21106794476509094 0.0 17.598960876464844
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1021
Curr loss timestep torch.Size([525, 4]) tensor([427, 172, 260, 348], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.13780826330184937
bi 1 loss 0.0982208400964737
bi 2 loss 0.273690402507782
bi 3 loss 0.29008015990257263
Layer  4  loss:  0.19656790792942047 0.0 12.912094116210938
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1022
Curr loss timestep torch.Size([525, 4]) tensor([277, 278, 363, 363], device='cuda:0') tensor(363, device='cuda:0')
bi 0 loss 0.14098992943763733
bi 1 loss 0.08675088733434677
bi 2 loss 0.28634682297706604
bi 3 loss 0.22696629166603088
Layer  5  loss:  0.18867550790309906 0.0 12.887264251708984
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([428, 280, 358, 404], device='cuda:0') tensor(358, device='cuda:0')
bi 0 loss 0.1021466851234436
bi 1 loss 0.07974687218666077
bi 2 loss 0.24503526091575623
bi 3 loss 0.28366178274154663
Layer  6  loss:  0.19232314825057983 0.0 18.828744888305664
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1022
Curr loss timestep torch.Size([525, 4]) tensor([441, 274, 365, 348], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.1344188004732132
bi 1 loss 0.08558402955532074
bi 2 loss 0.23416215181350708
bi 3 loss 0.27647295594215393
Epoch 0: :   3%|▎         | 15923/600000 [06:25<3:55:43, v_num=12, reduced_train_loss=0.537, global_step=15921.0, consumed_samples=63688.0, train_step_timing in s=0.393]Epoch 0: :   3%|▎         | 15923/600000 [06:25<3:55:43, v_num=12, reduced_train_loss=1.480, global_step=15922.0, consumed_samples=63692.0, train_step_timing in s=0.361]loss mask original None

First layer loss:  3.491877555847168 torch.Size([488, 4]) 12.479129791259766 0.0
Max loss timestep torch.Size([488, 4]) tensor([220, 132, 200, 216], device='cuda:0') tensor(216, device='cuda:0')
bi 0 loss 3.476238250732422
speech mask sum tensor(384, device='cuda:0') loss mask sum tensor(384, device='cuda:0')
bi 1 loss 3.2650516033172607
speech mask sum tensor(169, device='cuda:0') loss mask sum tensor(169, device='cuda:0')
bi 2 loss 3.786180019378662
speech mask sum tensor(84, device='cuda:0') loss mask sum tensor(84, device='cuda:0')
bi 3 loss 3.67185640335083
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
logits torch.Size([488, 4, 257024]) labels torch.Size([488, 4]) 0 257022
Layer  0  loss:  4.271589756011963 0.0 9.922173500061035
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([291, 228, 195, 245], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.41260290145874
bi 1 loss 4.012678623199463
bi 2 loss 4.522793769836426
bi 3 loss 3.9826526641845703
Layer  1  loss:  4.6291375160217285 0.0 10.005563735961914
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([325, 139, 184, 284], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.810152053833008
bi 1 loss 4.552644729614258
bi 2 loss 4.6478142738342285
bi 3 loss 4.095637798309326
Layer  2  loss:  4.955434799194336 0.0 10.626703262329102
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([344, 154, 176, 249], device='cuda:0') tensor(225, device='cuda:0')
bi 0 loss 5.03973913192749
bi 1 loss 4.8999834060668945
bi 2 loss 5.1470723152160645
bi 3 loss 4.5967278480529785
Layer  3  loss:  5.059447765350342 0.0 10.30799388885498
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([235, 232, 175, 237], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 5.324353218078613
bi 1 loss 4.75877046585083
bi 2 loss 5.0067138671875
bi 3 loss 4.633027076721191
Layer  4  loss:  5.22516393661499 0.0 10.194581031799316
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([239, 172, 217, 305], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 5.381399154663086
bi 1 loss 5.004022598266602
bi 2 loss 5.33663272857666
bi 3 loss 4.931723594665527
Layer  5  loss:  5.335010051727295 0.0 9.588388442993164
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1022
Curr loss timestep torch.Size([488, 4]) tensor([323, 129, 175, 310], device='cuda:0') tensor(233, device='cuda:0')
bi 0 loss 5.489990711212158
bi 1 loss 5.114243030548096
bi 2 loss 5.1582465171813965
bi 3 loss 5.26753568649292
Layer  6  loss:  5.370566368103027 0.0 9.134657859802246
logits torch.Size([488, 4, 1024]) labels torch.Size([488, 4]) 0 1023
Curr loss timestep torch.Size([488, 4]) tensor([334, 253, 175, 251], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 5.54128885269165
bi 1 loss 5.291371822357178
bi 2 loss 5.28143835067749
bi 3 loss 4.960590362548828
Epoch 0: :   3%|▎         | 15924/600000 [06:25<3:55:55, v_num=12, reduced_train_loss=1.480, global_step=15922.0, consumed_samples=63692.0, train_step_timing in s=0.361]Epoch 0: :   3%|▎         | 15924/600000 [06:25<3:55:55, v_num=12, reduced_train_loss=38.30, global_step=15923.0, consumed_samples=63696.0, train_step_timing in s=0.327]loss mask original None

First layer loss:  0.12521688640117645 torch.Size([465, 4]) 13.311287879943848 0.0
Max loss timestep torch.Size([465, 4]) tensor([320, 321, 254, 268], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.04889998212456703
speech mask sum tensor(187, device='cuda:0') loss mask sum tensor(187, device='cuda:0')
bi 1 loss 0.2757149338722229
speech mask sum tensor(271, device='cuda:0') loss mask sum tensor(271, device='cuda:0')
bi 2 loss 0.05146089196205139
speech mask sum tensor(238, device='cuda:0') loss mask sum tensor(238, device='cuda:0')
bi 3 loss 0.08485747128725052
speech mask sum tensor(222, device='cuda:0') loss mask sum tensor(222, device='cuda:0')
logits torch.Size([465, 4, 257024]) labels torch.Size([465, 4]) 0 257022
Layer  0  loss:  0.1303727924823761 0.0 13.297998428344727
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([272, 318, 383, 268], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.05716778710484505
bi 1 loss 0.23728303611278534
bi 2 loss 0.10721942037343979
bi 3 loss 0.08635101467370987
Layer  1  loss:  0.15815339982509613 0.0 20.718814849853516
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([272, 318, 390, 269], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.05417932569980621
bi 1 loss 0.32689327001571655
bi 2 loss 0.09245391935110092
bi 3 loss 0.1101853996515274
Layer  2  loss:  0.19091884791851044 0.0 16.64537239074707
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([276, 318, 385, 268], device='cuda:0') tensor(318, device='cuda:0')
bi 0 loss 0.07272256165742874
bi 1 loss 0.37649834156036377
bi 2 loss 0.12554000318050385
bi 3 loss 0.13403066992759705
Layer  3  loss:  0.1918288767337799 0.0 16.95964241027832
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1023
Curr loss timestep torch.Size([465, 4]) tensor([277, 320, 390, 267], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 0.10693641006946564
bi 1 loss 0.33437228202819824
bi 2 loss 0.16386961936950684
bi 3 loss 0.11930598318576813
Layer  4  loss:  0.19106490910053253 0.0 15.221186637878418
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([317, 321, 390, 268], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.0812491625547409
bi 1 loss 0.3687904477119446
bi 2 loss 0.10213314741849899
bi 3 loss 0.1619553565979004
Layer  5  loss:  0.16474153101444244 0.0 14.67529010772705
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1019
Curr loss timestep torch.Size([465, 4]) tensor([209, 321, 388, 268], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.04944917559623718
bi 1 loss 0.3116254508495331
bi 2 loss 0.08702296763658524
bi 3 loss 0.16587276756763458
Layer  6  loss:  0.17491132020950317 0.0 16.028553009033203
logits torch.Size([465, 4, 1024]) labels torch.Size([465, 4]) 0 1022
Curr loss timestep torch.Size([465, 4]) tensor([318, 315, 382, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.08364884555339813
bi 1 loss 0.28408077359199524
bi 2 loss 0.10626909881830215
bi 3 loss 0.19210956990718842
Epoch 0: :   3%|▎         | 15925/600000 [06:26<3:56:09, v_num=12, reduced_train_loss=38.30, global_step=15923.0, consumed_samples=63696.0, train_step_timing in s=0.327]Epoch 0: :   3%|▎         | 15925/600000 [06:26<3:56:09, v_num=12, reduced_train_loss=1.330, global_step=15924.0, consumed_samples=63700.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  0.0382012277841568 torch.Size([358, 4]) 6.449624538421631 0.0
Max loss timestep torch.Size([358, 4]) tensor([226, 175, 267, 200], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.019660577178001404
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
bi 1 loss 0.019106075167655945
speech mask sum tensor(136, device='cuda:0') loss mask sum tensor(136, device='cuda:0')
bi 2 loss 0.11496029049158096
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 3 loss 0.027723141014575958
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
logits torch.Size([358, 4, 257024]) labels torch.Size([358, 4]) 0 257022
Layer  0  loss:  0.054998211562633514 0.0 11.566140174865723
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1023
Curr loss timestep torch.Size([358, 4]) tensor([217, 279, 269, 123], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.01498194970190525
bi 1 loss 0.01752028800547123
bi 2 loss 0.23291422426700592
bi 3 loss 0.02571922168135643
Layer  1  loss:  0.08599267899990082 0.0 18.407310485839844
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([200, 174, 267, 291], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.010774939320981503
bi 1 loss 0.02250693179666996
bi 2 loss 0.44562697410583496
bi 3 loss 0.017620688304305077
Layer  2  loss:  0.057480935007333755 0.0 11.401620864868164
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([227, 190, 269, 315], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.009750058874487877
bi 1 loss 0.02055736817419529
bi 2 loss 0.27117642760276794
bi 3 loss 0.017918916419148445
Layer  3  loss:  0.07050387561321259 0.0 13.023554801940918
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([171, 198, 269, 219], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.013938529416918755
bi 1 loss 0.018070831894874573
bi 2 loss 0.3298676311969757
bi 3 loss 0.025805087760090828
Layer  4  loss:  0.07622315734624863 0.0 16.54678726196289
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([145, 214, 269, 349], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.019373223185539246
bi 1 loss 0.02586299180984497
bi 2 loss 0.36153537034988403
bi 3 loss 0.020598948001861572
Layer  5  loss:  0.06813333928585052 0.0 18.31487274169922
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1023
Curr loss timestep torch.Size([358, 4]) tensor([195, 246, 269, 307], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.01730780303478241
bi 1 loss 0.021130485460162163
bi 2 loss 0.3219848871231079
bi 3 loss 0.019910577684640884
Layer  6  loss:  0.08388418704271317 0.0 19.796899795532227
logits torch.Size([358, 4, 1024]) labels torch.Size([358, 4]) 0 1022
Curr loss timestep torch.Size([358, 4]) tensor([164, 212, 269, 130], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.009365096688270569
bi 1 loss 0.02390618808567524
bi 2 loss 0.41488292813301086
bi 3 loss 0.02434978447854519
Epoch 0: :   3%|▎         | 15926/600000 [06:26<3:56:19, v_num=12, reduced_train_loss=1.330, global_step=15924.0, consumed_samples=63700.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15926/600000 [06:26<3:56:19, v_num=12, reduced_train_loss=0.535, global_step=15925.0, consumed_samples=63704.0, train_step_timing in s=0.277]loss mask original None

First layer loss:  3.8968403339385986 torch.Size([476, 4]) 10.550180435180664 0.0
Max loss timestep torch.Size([476, 4]) tensor([ 74, 259, 299, 201], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 3.327178478240967
speech mask sum tensor(58, device='cuda:0') loss mask sum tensor(58, device='cuda:0')
bi 1 loss 3.907820224761963
speech mask sum tensor(422, device='cuda:0') loss mask sum tensor(422, device='cuda:0')
bi 2 loss 3.9891889095306396
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 3 loss 3.935922861099243
speech mask sum tensor(207, device='cuda:0') loss mask sum tensor(207, device='cuda:0')
logits torch.Size([476, 4, 257024]) labels torch.Size([476, 4]) 0 257022
Layer  0  loss:  4.295905113220215 0.0 10.183639526367188
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1023
Curr loss timestep torch.Size([476, 4]) tensor([ 71, 247, 351, 266], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 3.9247241020202637
bi 1 loss 4.360236644744873
bi 2 loss 4.317789077758789
bi 3 loss 4.245500087738037
Layer  1  loss:  4.703758239746094 0.0 10.04927921295166
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1022
Curr loss timestep torch.Size([476, 4]) tensor([ 83, 220, 272, 164], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 4.1714630126953125
bi 1 loss 4.859261512756348
bi 2 loss 4.487298488616943
bi 3 loss 4.765942096710205
Layer  2  loss:  5.000889778137207 0.0 10.102425575256348
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1023
Curr loss timestep torch.Size([476, 4]) tensor([ 69, 226, 238, 175], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 3.9470138549804688
bi 1 loss 5.163356304168701
bi 2 loss 5.052272796630859
bi 3 loss 4.910356521606445
Layer  3  loss:  5.030428409576416 0.0 10.050734519958496
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1022
Curr loss timestep torch.Size([476, 4]) tensor([ 78, 103, 273, 288], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 3.9967293739318848
bi 1 loss 5.168589115142822
bi 2 loss 5.067790985107422
bi 3 loss 4.998692989349365
Layer  4  loss:  5.183873176574707 0.0 11.189872741699219
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1023
Curr loss timestep torch.Size([476, 4]) tensor([ 87, 377, 275, 257], device='cuda:0') tensor(228, device='cuda:0')
bi 0 loss 4.345804691314697
bi 1 loss 5.387520790100098
bi 2 loss 5.174759864807129
bi 3 loss 5.013211727142334
Layer  5  loss:  5.320428848266602 0.0 10.349130630493164
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1023
Curr loss timestep torch.Size([476, 4]) tensor([ 82, 455, 215, 333], device='cuda:0') tensor(262, device='cuda:0')
bi 0 loss 4.204263210296631
bi 1 loss 5.533194541931152
bi 2 loss 5.382761001586914
bi 3 loss 5.133168697357178
Layer  6  loss:  5.289312362670898 0.0 9.530464172363281
logits torch.Size([476, 4, 1024]) labels torch.Size([476, 4]) 0 1023
Curr loss timestep torch.Size([476, 4]) tensor([ 68, 442, 341, 242], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 4.375921726226807
bi 1 loss 5.557023525238037
bi 2 loss 5.228264808654785
bi 3 loss 5.064350605010986
Epoch 0: :   3%|▎         | 15927/600000 [06:27<3:56:32, v_num=12, reduced_train_loss=0.535, global_step=15925.0, consumed_samples=63704.0, train_step_timing in s=0.277]Epoch 0: :   3%|▎         | 15927/600000 [06:27<3:56:32, v_num=12, reduced_train_loss=38.70, global_step=15926.0, consumed_samples=63708.0, train_step_timing in s=0.326]loss mask original None

First layer loss:  3.9621615409851074 torch.Size([584, 4]) 11.207027435302734 0.0
Max loss timestep torch.Size([584, 4]) tensor([462, 293, 313, 247], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 4.1861491203308105
speech mask sum tensor(492, device='cuda:0') loss mask sum tensor(492, device='cuda:0')
bi 1 loss 4.221280574798584
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 2 loss 3.713613748550415
speech mask sum tensor(438, device='cuda:0') loss mask sum tensor(438, device='cuda:0')
bi 3 loss 3.2645046710968018
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
logits torch.Size([584, 4, 257024]) labels torch.Size([584, 4]) 0 257022
Layer  0  loss:  4.1663312911987305 0.0 11.686640739440918
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([308, 205,  69, 225], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 4.312393665313721
bi 1 loss 4.216030120849609
bi 2 loss 4.041224002838135
bi 3 loss 3.8592381477355957
Layer  1  loss:  4.628929138183594 0.0 10.371768951416016
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([457, 342, 133, 277], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 4.807154655456543
bi 1 loss 4.620946884155273
bi 2 loss 4.491140365600586
bi 3 loss 4.368187427520752
Layer  2  loss:  4.837968349456787 0.0 9.995737075805664
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([193, 248, 164, 248], device='cuda:0') tensor(248, device='cuda:0')
bi 0 loss 4.9810662269592285
bi 1 loss 4.902768611907959
bi 2 loss 4.745842933654785
bi 3 loss 4.357118606567383
Layer  3  loss:  4.96279239654541 0.0 10.45538330078125
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1023
Curr loss timestep torch.Size([584, 4]) tensor([130, 401, 187, 251], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 4.99418306350708
bi 1 loss 4.999310493469238
bi 2 loss 5.048459053039551
bi 3 loss 4.320376396179199
Layer  4  loss:  5.098789691925049 0.0 10.082880973815918
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([481, 226, 129, 266], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 5.195605278015137
bi 1 loss 5.073455810546875
bi 2 loss 5.177496910095215
bi 3 loss 4.319183826446533
Layer  5  loss:  5.198157787322998 0.0 10.904213905334473
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([229, 402, 385, 281], device='cuda:0') tensor(229, device='cuda:0')
bi 0 loss 5.230384349822998
bi 1 loss 5.191932201385498
bi 2 loss 5.308177947998047
bi 3 loss 4.554340362548828
Layer  6  loss:  5.212697505950928 0.0 9.801092147827148
logits torch.Size([584, 4, 1024]) labels torch.Size([584, 4]) 0 1022
Curr loss timestep torch.Size([584, 4]) tensor([224, 213,  70, 280], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 5.259459495544434
bi 1 loss 5.23687744140625
bi 2 loss 5.301109790802002
bi 3 loss 4.512474060058594
Epoch 0: :   3%|▎         | 15928/600000 [06:27<3:56:46, v_num=12, reduced_train_loss=38.70, global_step=15926.0, consumed_samples=63708.0, train_step_timing in s=0.326]Epoch 0: :   3%|▎         | 15928/600000 [06:27<3:56:46, v_num=12, reduced_train_loss=38.10, global_step=15927.0, consumed_samples=63712.0, train_step_timing in s=0.374]loss mask original None

First layer loss:  0.1678975522518158 torch.Size([462, 4]) 8.945216178894043 0.0
Max loss timestep torch.Size([462, 4]) tensor([372, 223, 273, 268], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.20319916307926178
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 1 loss 0.06157199665904045
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 2 loss 0.24726873636245728
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 3 loss 0.11134335398674011
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
logits torch.Size([462, 4, 257024]) labels torch.Size([462, 4]) 0 257023
Layer  0  loss:  0.18739964067935944 0.0 13.1984281539917
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1023
Curr loss timestep torch.Size([462, 4]) tensor([373, 202, 273, 268], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.20698508620262146
bi 1 loss 0.06608889251947403
bi 2 loss 0.2612747848033905
bi 3 loss 0.15507358312606812
Layer  1  loss:  0.2007848620414734 0.0 16.369354248046875
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1023
Curr loss timestep torch.Size([462, 4]) tensor([326, 172, 271, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.19705913960933685
bi 1 loss 0.03631831333041191
bi 2 loss 0.32636427879333496
bi 3 loss 0.1533782035112381
Layer  2  loss:  0.20309214293956757 0.0 12.478059768676758
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([346, 196, 270, 269], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.2890471816062927
bi 1 loss 0.06971384584903717
bi 2 loss 0.2703620195388794
bi 3 loss 0.13433651626110077
Layer  3  loss:  0.21862131357192993 0.0 16.3011474609375
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([373, 216, 270, 268], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.25738364458084106
bi 1 loss 0.0629533901810646
bi 2 loss 0.3567640483379364
bi 3 loss 0.12301374971866608
Layer  4  loss:  0.22472576797008514 0.0 9.603272438049316
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1022
Curr loss timestep torch.Size([462, 4]) tensor([373, 179, 273, 268], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.281732976436615
bi 1 loss 0.08342380821704865
bi 2 loss 0.3200155794620514
bi 3 loss 0.15250752866268158
Layer  5  loss:  0.23793761432170868 0.0 13.757257461547852
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1023
Curr loss timestep torch.Size([462, 4]) tensor([373, 194, 270, 268], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.36360323429107666
bi 1 loss 0.05714356154203415
bi 2 loss 0.3000965118408203
bi 3 loss 0.16753090918064117
Layer  6  loss:  0.18517695367336273 0.0 10.631476402282715
logits torch.Size([462, 4, 1024]) labels torch.Size([462, 4]) 0 1023
Curr loss timestep torch.Size([462, 4]) tensor([372, 220, 273, 269], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.258639395236969
bi 1 loss 0.05933111533522606
bi 2 loss 0.24886402487754822
bi 3 loss 0.12570565938949585
Epoch 0: :   3%|▎         | 15929/600000 [06:27<3:56:58, v_num=12, reduced_train_loss=38.10, global_step=15927.0, consumed_samples=63712.0, train_step_timing in s=0.374]Epoch 0: :   3%|▎         | 15929/600000 [06:27<3:56:58, v_num=12, reduced_train_loss=1.630, global_step=15928.0, consumed_samples=63716.0, train_step_timing in s=0.326]loss mask original None

First layer loss:  0.17497770488262177 torch.Size([650, 4]) 10.370895385742188 0.0
Max loss timestep torch.Size([650, 4]) tensor([343, 275, 270, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.19086261093616486
speech mask sum tensor(298, device='cuda:0') loss mask sum tensor(298, device='cuda:0')
bi 1 loss 0.09126833826303482
speech mask sum tensor(226, device='cuda:0') loss mask sum tensor(226, device='cuda:0')
bi 2 loss 0.1255970448255539
speech mask sum tensor(285, device='cuda:0') loss mask sum tensor(285, device='cuda:0')
bi 3 loss 0.23206478357315063
speech mask sum tensor(495, device='cuda:0') loss mask sum tensor(495, device='cuda:0')
logits torch.Size([650, 4, 257024]) labels torch.Size([650, 4]) 0 257023
Layer  0  loss:  0.21296699345111847 0.0 13.191854476928711
logits torch.Size([650, 4, 1024]) labels torch.Size([650, 4]) 0 1023
Curr loss timestep torch.Size([650, 4]) tensor([528, 275, 270, 292], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.27631044387817383
bi 1 loss 0.17177051305770874
bi 2 loss 0.10795661807060242
bi 3 loss 0.25410234928131104
Layer  1  loss:  0.19098272919654846 0.0 14.875574111938477
logits torch.Size([650, 4, 1024]) labels torch.Size([650, 4]) 0 1023
Curr loss timestep torch.Size([650, 4]) tensor([528, 275, 272, 307], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.1833675503730774
bi 1 loss 0.11784928292036057
bi 2 loss 0.16278916597366333
bi 3 loss 0.2451900690793991
Layer  2  loss:  0.22580143809318542 0.0 14.531258583068848
logits torch.Size([650, 4, 1024]) labels torch.Size([650, 4]) 0 1022
Curr loss timestep torch.Size([650, 4]) tensor([351, 275, 271, 334], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 0.2973844110965729
bi 1 loss 0.12454096227884293
bi 2 loss 0.11272240430116653
bi 3 loss 0.2940451204776764
Layer  3  loss:  0.22225645184516907 0.0 16.0310001373291
logits torch.Size([650, 4, 1024]) labels torch.Size([650, 4]) 0 1021
Curr loss timestep torch.Size([650, 4]) tensor([528, 275, 272, 335], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.15984803438186646
bi 1 loss 0.16252826154232025
bi 2 loss 0.15426261723041534
bi 3 loss 0.32624539732933044
Layer  4  loss:  0.22507210075855255 0.0 12.783414840698242
logits torch.Size([650, 4, 1024]) labels torch.Size([650, 4]) 0 1022
Curr loss timestep torch.Size([650, 4]) tensor([442, 275, 272, 334], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.22891783714294434
bi 1 loss 0.12839439511299133
bi 2 loss 0.1736016571521759
bi 3 loss 0.29653117060661316
Layer  5  loss:  0.22212104499340057 0.0 20.000892639160156
logits torch.Size([650, 4, 1024]) labels torch.Size([650, 4]) 0 1023
Curr loss timestep torch.Size([650, 4]) tensor([527, 275, 269, 425], device='cuda:0') tensor(425, device='cuda:0')
bi 0 loss 0.24855926632881165
bi 1 loss 0.12183435261249542
bi 2 loss 0.14440518617630005
bi 3 loss 0.2967376410961151
Layer  6  loss:  0.23119813203811646 0.0 11.075933456420898
logits torch.Size([650, 4, 1024]) labels torch.Size([650, 4]) 0 1022
Curr loss timestep torch.Size([650, 4]) tensor([528, 275, 270, 307], device='cuda:0') tensor(307, device='cuda:0')
bi 0 loss 0.26795488595962524
bi 1 loss 0.12712140381336212
bi 2 loss 0.15924881398677826
bi 3 loss 0.2980130612850189
Epoch 0: :   3%|▎         | 15930/600000 [06:28<3:57:15, v_num=12, reduced_train_loss=1.630, global_step=15928.0, consumed_samples=63716.0, train_step_timing in s=0.326]Epoch 0: :   3%|▎         | 15930/600000 [06:28<3:57:15, v_num=12, reduced_train_loss=1.710, global_step=15929.0, consumed_samples=63720.0, train_step_timing in s=0.441]loss mask original None

First layer loss:  0.0784294605255127 torch.Size([529, 4]) 3.6652426719665527 0.0
Max loss timestep torch.Size([529, 4]) tensor([371, 367, 253, 213], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.1056932881474495
speech mask sum tensor(279, device='cuda:0') loss mask sum tensor(279, device='cuda:0')
bi 1 loss 0.07953029870986938
speech mask sum tensor(196, device='cuda:0') loss mask sum tensor(196, device='cuda:0')
bi 2 loss 0.06883891671895981
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 3 loss 0.02195441909134388
speech mask sum tensor(120, device='cuda:0') loss mask sum tensor(120, device='cuda:0')
logits torch.Size([529, 4, 257024]) labels torch.Size([529, 4]) 0 257022
Layer  0  loss:  0.08618529886007309 0.0 3.5722761154174805
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([436, 309, 254, 273], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.12029366195201874
bi 1 loss 0.06501135230064392
bi 2 loss 0.09363806247711182
bi 3 loss 0.03469785675406456
Layer  1  loss:  0.09423158317804337 0.0 6.469817161560059
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([371, 307, 264, 191], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.16228409111499786
bi 1 loss 0.05881873890757561
bi 2 loss 0.061358511447906494
bi 3 loss 0.023710159584879875
Layer  2  loss:  0.09780433028936386 0.0 4.412495136260986
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([371, 388, 243, 258], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.13720588386058807
bi 1 loss 0.10770774632692337
bi 2 loss 0.036656055599451065
bi 3 loss 0.04556310921907425
Layer  3  loss:  0.10242057591676712 0.0 3.8284220695495605
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1023
Curr loss timestep torch.Size([529, 4]) tensor([384, 386, 231, 277], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.1315038651227951
bi 1 loss 0.11832138895988464
bi 2 loss 0.06038936227560043
bi 3 loss 0.047008976340293884
Layer  4  loss:  0.08979170769453049 0.0 5.5568084716796875
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1021
Curr loss timestep torch.Size([529, 4]) tensor([467, 223, 201, 261], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.12539342045783997
bi 1 loss 0.08181918412446976
bi 2 loss 0.06485483795404434
bi 3 loss 0.04269052669405937
Layer  5  loss:  0.09884237498044968 0.0 4.023840427398682
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([370, 270, 270, 219], device='cuda:0') tensor(370, device='cuda:0')
bi 0 loss 0.16696757078170776
bi 1 loss 0.07789593189954758
bi 2 loss 0.04222678393125534
bi 3 loss 0.02608964592218399
Layer  6  loss:  0.09000781178474426 0.0 2.863178014755249
logits torch.Size([529, 4, 1024]) labels torch.Size([529, 4]) 0 1022
Curr loss timestep torch.Size([529, 4]) tensor([512, 307, 273, 208], device='cuda:0') tensor(512, device='cuda:0')
bi 0 loss 0.1324097067117691
bi 1 loss 0.08076368272304535
bi 2 loss 0.06459448486566544
bi 3 loss 0.029605934396386147
Epoch 0: :   3%|▎         | 15931/600000 [06:28<3:57:29, v_num=12, reduced_train_loss=1.710, global_step=15929.0, consumed_samples=63720.0, train_step_timing in s=0.441]Epoch 0: :   3%|▎         | 15931/600000 [06:28<3:57:29, v_num=12, reduced_train_loss=0.738, global_step=15930.0, consumed_samples=63724.0, train_step_timing in s=0.367]loss mask original None

First layer loss:  0.022708922624588013 torch.Size([323, 4]) 0.5049822926521301 0.0
Max loss timestep torch.Size([323, 4]) tensor([195, 126, 210, 112], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 0.02564339153468609
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 1 loss 0.0285909716039896
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 2 loss 0.022424884140491486
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 3 loss 0.017868105322122574
speech mask sum tensor(201, device='cuda:0') loss mask sum tensor(201, device='cuda:0')
logits torch.Size([323, 4, 257024]) labels torch.Size([323, 4]) 0 257023
Layer  0  loss:  0.02546343393623829 0.0 0.7322361469268799
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1023
Curr loss timestep torch.Size([323, 4]) tensor([191, 164, 272, 142], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.018552614375948906
bi 1 loss 0.02311628684401512
bi 2 loss 0.03473374620079994
bi 3 loss 0.025391023606061935
Layer  1  loss:  0.025590529665350914 0.0 0.9148475527763367
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([304, 175, 209, 213], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.033863604068756104
bi 1 loss 0.025312140583992004
bi 2 loss 0.020146241411566734
bi 3 loss 0.023488201200962067
Layer  2  loss:  0.022762689739465714 0.0 0.4191041886806488
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([227, 169, 234, 164], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 0.025652766227722168
bi 1 loss 0.021796075627207756
bi 2 loss 0.024461597204208374
bi 3 loss 0.02008250169456005
Layer  3  loss:  0.029986388981342316 0.0 0.8546543717384338
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1022
Curr loss timestep torch.Size([323, 4]) tensor([304, 168, 301, 116], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.03376571089029312
bi 1 loss 0.02589602954685688
bi 2 loss 0.03310919553041458
bi 3 loss 0.02730543725192547
Layer  4  loss:  0.028102438896894455 0.0 2.586693286895752
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1021
Curr loss timestep torch.Size([323, 4]) tensor([304, 124, 222, 168], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.039950236678123474
bi 1 loss 0.02476559951901436
bi 2 loss 0.024176830425858498
bi 3 loss 0.024006608873605728
Layer  5  loss:  0.02215549349784851 0.0 0.8986191749572754
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1018
Curr loss timestep torch.Size([323, 4]) tensor([250, 186, 308,  97], device='cuda:0') tensor(250, device='cuda:0')
bi 0 loss 0.03165310621261597
bi 1 loss 0.02152586169540882
bi 2 loss 0.017817597836256027
bi 3 loss 0.018632471561431885
Layer  6  loss:  0.024770494550466537 0.0 2.4426214694976807
logits torch.Size([323, 4, 1024]) labels torch.Size([323, 4]) 0 1023
Curr loss timestep torch.Size([323, 4]) tensor([304, 139, 259, 184], device='cuda:0') tensor(304, device='cuda:0')
bi 0 loss 0.03845739737153053
bi 1 loss 0.014264586381614208
bi 2 loss 0.019086210057139397
bi 3 loss 0.024141477420926094
Epoch 0: :   3%|▎         | 15932/600000 [06:28<3:57:39, v_num=12, reduced_train_loss=0.738, global_step=15930.0, consumed_samples=63724.0, train_step_timing in s=0.367]Epoch 0: :   3%|▎         | 15932/600000 [06:28<3:57:39, v_num=12, reduced_train_loss=0.202, global_step=15931.0, consumed_samples=63728.0, train_step_timing in s=0.264]loss mask original None

First layer loss:  0.036540817469358444 torch.Size([371, 4]) 1.3769152164459229 0.0
Max loss timestep torch.Size([371, 4]) tensor([205,  75, 266,  71], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.031021658331155777
speech mask sum tensor(245, device='cuda:0') loss mask sum tensor(245, device='cuda:0')
bi 1 loss 0.032908517867326736
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 2 loss 0.044762950390577316
speech mask sum tensor(129, device='cuda:0') loss mask sum tensor(129, device='cuda:0')
bi 3 loss 0.046956904232501984
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
logits torch.Size([371, 4, 257024]) labels torch.Size([371, 4]) 0 257023
Layer  0  loss:  0.035461701452732086 0.0 1.199326992034912
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([343, 101, 208, 110], device='cuda:0') tensor(110, device='cuda:0')
bi 0 loss 0.04730670154094696
bi 1 loss 0.02661251462996006
bi 2 loss 0.034142035990953445
bi 3 loss 0.03515098989009857
Layer  1  loss:  0.04356157407164574 0.0 3.5229289531707764
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([163, 356, 177, 111], device='cuda:0') tensor(111, device='cuda:0')
bi 0 loss 0.04131107032299042
bi 1 loss 0.030157433822751045
bi 2 loss 0.05896718427538872
bi 3 loss 0.06325490772724152
Layer  2  loss:  0.0380883514881134 0.0 1.7929368019104004
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([172, 279, 218, 162], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.03254168853163719
bi 1 loss 0.039001815021038055
bi 2 loss 0.05387108400464058
bi 3 loss 0.030963487923145294
Layer  3  loss:  0.04634598270058632 0.0 3.5139122009277344
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1017
Curr loss timestep torch.Size([371, 4]) tensor([343, 279, 236,  93], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 0.046207547187805176
bi 1 loss 0.0442328006029129
bi 2 loss 0.07126960158348083
bi 3 loss 0.02739953249692917
Layer  4  loss:  0.037868328392505646 0.0 1.3017945289611816
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1021
Curr loss timestep torch.Size([371, 4]) tensor([263, 163, 266, 158], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.03832940012216568
bi 1 loss 0.037235986441373825
bi 2 loss 0.0464969277381897
bi 3 loss 0.030153263360261917
Layer  5  loss:  0.038524143397808075 0.0 2.4398765563964844
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([304, 342, 280, 163], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 0.03515096753835678
bi 1 loss 0.04142520949244499
bi 2 loss 0.04005463421344757
bi 3 loss 0.03663662075996399
Layer  6  loss:  0.04396704211831093 0.0 2.9520721435546875
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([250, 279, 271, 138], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 0.03901807218790054
bi 1 loss 0.04798520356416702
bi 2 loss 0.05639071762561798
bi 3 loss 0.031939588487148285
Epoch 0: :   3%|▎         | 15933/600000 [06:29<3:57:50, v_num=12, reduced_train_loss=0.202, global_step=15931.0, consumed_samples=63728.0, train_step_timing in s=0.264]Epoch 0: :   3%|▎         | 15933/600000 [06:29<3:57:50, v_num=12, reduced_train_loss=0.320, global_step=15932.0, consumed_samples=63732.0, train_step_timing in s=0.297]loss mask original None

First layer loss:  0.018521854653954506 torch.Size([403, 4]) 0.46665793657302856 0.0
Max loss timestep torch.Size([403, 4]) tensor([158, 120,  85, 351], device='cuda:0') tensor(351, device='cuda:0')
bi 0 loss 0.00975534413009882
speech mask sum tensor(73, device='cuda:0') loss mask sum tensor(73, device='cuda:0')
bi 1 loss 0.017085468396544456
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 2 loss 0.012071454897522926
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 3 loss 0.02455531433224678
speech mask sum tensor(221, device='cuda:0') loss mask sum tensor(221, device='cuda:0')
logits torch.Size([403, 4, 257024]) labels torch.Size([403, 4]) 0 257022
Layer  0  loss:  0.017409536987543106 0.0 0.24513721466064453
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1023
Curr loss timestep torch.Size([403, 4]) tensor([163,  82, 115, 353], device='cuda:0') tensor(163, device='cuda:0')
bi 0 loss 0.014152121730148792
bi 1 loss 0.018682260066270828
bi 2 loss 0.015376821160316467
bi 3 loss 0.0184750035405159
Layer  1  loss:  0.015384282916784286 0.0 0.22430692613124847
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1022
Curr loss timestep torch.Size([403, 4]) tensor([191, 159, 127, 331], device='cuda:0') tensor(131, device='cuda:0')
bi 0 loss 0.009562430903315544
bi 1 loss 0.014199692755937576
bi 2 loss 0.018625833094120026
bi 3 loss 0.016834691166877747
Layer  2  loss:  0.014101101085543633 0.0 0.24912507832050323
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1022
Curr loss timestep torch.Size([403, 4]) tensor([156, 152, 129, 342], device='cuda:0') tensor(342, device='cuda:0')
bi 0 loss 0.007461302913725376
bi 1 loss 0.013970017433166504
bi 2 loss 0.010298139415681362
bi 3 loss 0.017729690298438072
Layer  3  loss:  0.014772271737456322 0.0 0.1878497153520584
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1023
Curr loss timestep torch.Size([403, 4]) tensor([161, 107,  97, 378], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 0.0069081601686775684
bi 1 loss 0.013762786984443665
bi 2 loss 0.013574943877756596
bi 3 loss 0.01838260143995285
Layer  4  loss:  0.01442237664014101 0.0 0.176298126578331
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1017
Curr loss timestep torch.Size([403, 4]) tensor([175, 153,  80, 243], device='cuda:0') tensor(153, device='cuda:0')
bi 0 loss 0.00893197301775217
bi 1 loss 0.01523544080555439
bi 2 loss 0.013426382094621658
bi 3 loss 0.016121068969368935
Layer  5  loss:  0.015577281825244427 0.0 0.2326723337173462
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1023
Curr loss timestep torch.Size([403, 4]) tensor([162, 126, 111, 194], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 0.009710980579257011
bi 1 loss 0.015609782189130783
bi 2 loss 0.009210924617946148
bi 3 loss 0.019771955907344818
Layer  6  loss:  0.01533690094947815 0.0 0.1848033368587494
logits torch.Size([403, 4, 1024]) labels torch.Size([403, 4]) 0 1023
Curr loss timestep torch.Size([403, 4]) tensor([180, 148,  95, 356], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.008502010256052017
bi 1 loss 0.014043438248336315
bi 2 loss 0.012517707422375679
bi 3 loss 0.019351499155163765
Epoch 0: :   3%|▎         | 15934/600000 [06:29<3:58:02, v_num=12, reduced_train_loss=0.320, global_step=15932.0, consumed_samples=63732.0, train_step_timing in s=0.297]Epoch 0: :   3%|▎         | 15934/600000 [06:29<3:58:02, v_num=12, reduced_train_loss=0.126, global_step=15933.0, consumed_samples=63736.0, train_step_timing in s=0.301]loss mask original None

First layer loss:  0.21455469727516174 torch.Size([785, 4]) 9.814827919006348 0.0
Max loss timestep torch.Size([785, 4]) tensor([193, 371, 415, 384], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.020435558632016182
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 1 loss 0.10452757030725479
speech mask sum tensor(435, device='cuda:0') loss mask sum tensor(435, device='cuda:0')
bi 2 loss 0.1787046641111374
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 3 loss 0.3723668158054352
speech mask sum tensor(468, device='cuda:0') loss mask sum tensor(468, device='cuda:0')
logits torch.Size([785, 4, 257024]) labels torch.Size([785, 4]) 0 257023
Layer  0  loss:  0.22774046659469604 0.0 11.51763916015625
logits torch.Size([785, 4, 1024]) labels torch.Size([785, 4]) 0 1023
Curr loss timestep torch.Size([785, 4]) tensor([214, 498, 409, 535], device='cuda:0') tensor(409, device='cuda:0')
bi 0 loss 0.01009421143680811
bi 1 loss 0.10192205756902695
bi 2 loss 0.20809270441532135
bi 3 loss 0.3958105146884918
Layer  1  loss:  0.23702889680862427 0.0 10.001595497131348
logits torch.Size([785, 4, 1024]) labels torch.Size([785, 4]) 0 1023
Curr loss timestep torch.Size([785, 4]) tensor([191, 371, 303, 729], device='cuda:0') tensor(729, device='cuda:0')
bi 0 loss 0.006341974716633558
bi 1 loss 0.09362713992595673
bi 2 loss 0.21090872585773468
bi 3 loss 0.4273794889450073
Layer  2  loss:  0.3001711964607239 0.0 13.282320976257324
logits torch.Size([785, 4, 1024]) labels torch.Size([785, 4]) 0 1023
Curr loss timestep torch.Size([785, 4]) tensor([188, 371, 415, 751], device='cuda:0') tensor(751, device='cuda:0')
bi 0 loss 0.022219333797693253
bi 1 loss 0.11962416768074036
bi 2 loss 0.2431819885969162
bi 3 loss 0.5505878329277039
Layer  3  loss:  0.28772521018981934 0.0 10.537805557250977
logits torch.Size([785, 4, 1024]) labels torch.Size([785, 4]) 0 1023
Curr loss timestep torch.Size([785, 4]) tensor([215, 371, 415, 384], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.018019938841462135
bi 1 loss 0.13553033769130707
bi 2 loss 0.25380051136016846
bi 3 loss 0.4977380335330963
Layer  4  loss:  0.3038804531097412 0.0 11.501110076904297
logits torch.Size([785, 4, 1024]) labels torch.Size([785, 4]) 0 1022
Curr loss timestep torch.Size([785, 4]) tensor([221, 371, 409, 737], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.019076421856880188
bi 1 loss 0.15313352644443512
bi 2 loss 0.19187095761299133
bi 3 loss 0.5577336549758911
Layer  5  loss:  0.29967182874679565 0.0 15.453485488891602
logits torch.Size([785, 4, 1024]) labels torch.Size([785, 4]) 0 1023
Curr loss timestep torch.Size([785, 4]) tensor([187, 483, 409, 384], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.008388360030949116
bi 1 loss 0.13089880347251892
bi 2 loss 0.3013562858104706
bi 3 loss 0.5097787976264954
Layer  6  loss:  0.30411869287490845 0.0 13.04716968536377
logits torch.Size([785, 4, 1024]) labels torch.Size([785, 4]) 0 1023
Curr loss timestep torch.Size([785, 4]) tensor([193, 371, 409, 757], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.013379239477217197
bi 1 loss 0.12755492329597473
bi 2 loss 0.19435495138168335
bi 3 loss 0.5818528532981873
Epoch 0: :   3%|▎         | 15935/600000 [06:30<3:58:22, v_num=12, reduced_train_loss=0.126, global_step=15933.0, consumed_samples=63736.0, train_step_timing in s=0.301]Epoch 0: :   3%|▎         | 15935/600000 [06:30<3:58:22, v_num=12, reduced_train_loss=2.170, global_step=15934.0, consumed_samples=63740.0, train_step_timing in s=0.544]loss mask original None

First layer loss:  0.028374778106808662 torch.Size([507, 4]) 0.7764871120452881 0.0
Max loss timestep torch.Size([507, 4]) tensor([201,  31, 335, 117], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.017879171296954155
speech mask sum tensor(212, device='cuda:0') loss mask sum tensor(212, device='cuda:0')
bi 1 loss 0.024097634479403496
speech mask sum tensor(47, device='cuda:0') loss mask sum tensor(47, device='cuda:0')
bi 2 loss 0.040569305419921875
speech mask sum tensor(275, device='cuda:0') loss mask sum tensor(275, device='cuda:0')
bi 3 loss 0.024061286821961403
speech mask sum tensor(215, device='cuda:0') loss mask sum tensor(215, device='cuda:0')
logits torch.Size([507, 4, 257024]) labels torch.Size([507, 4]) 0 257022
Layer  0  loss:  0.05530950799584389 0.0 9.438512802124023
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([229,  38, 348, 170], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.019804583862423897
bi 1 loss 0.03639794886112213
bi 2 loss 0.10640827566385269
bi 3 loss 0.02909427508711815
Layer  1  loss:  0.052284542471170425 0.0 8.863876342773438
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([214,  27, 347, 201], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.017032016068696976
bi 1 loss 0.01933722011744976
bi 2 loss 0.10751297324895859
bi 3 loss 0.023606592789292336
Layer  2  loss:  0.05203063040971756 0.0 9.252479553222656
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1022
Curr loss timestep torch.Size([507, 4]) tensor([152,  33, 348,  97], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.020247522741556168
bi 1 loss 0.010180533863604069
bi 2 loss 0.10654646903276443
bi 3 loss 0.022789334878325462
Layer  3  loss:  0.06631643325090408 0.0 12.203168869018555
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1021
Curr loss timestep torch.Size([507, 4]) tensor([194,  29, 347, 236], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.010527980513870716
bi 1 loss 0.016492385417222977
bi 2 loss 0.15643034875392914
bi 3 loss 0.01695624552667141
Layer  4  loss:  0.04778539016842842 0.0 5.80282735824585
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1021
Curr loss timestep torch.Size([507, 4]) tensor([255,  36, 348, 116], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.01657220721244812
bi 1 loss 0.009977606125175953
bi 2 loss 0.09626130759716034
bi 3 loss 0.02482392080128193
Layer  5  loss:  0.06678945571184158 0.0 11.317660331726074
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1022
Curr loss timestep torch.Size([507, 4]) tensor([202,  30, 347, 257], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 0.01802697405219078
bi 1 loss 0.006930990610271692
bi 2 loss 0.14755766093730927
bi 3 loss 0.024648698046803474
Layer  6  loss:  0.06497753411531448 0.0 11.363118171691895
logits torch.Size([507, 4, 1024]) labels torch.Size([507, 4]) 0 1023
Curr loss timestep torch.Size([507, 4]) tensor([252,  38, 348, 157], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.01895431987941265
bi 1 loss 0.009605331346392632
bi 2 loss 0.13906918466091156
bi 3 loss 0.02769477665424347
Epoch 0: :   3%|▎         | 15936/600000 [06:30<3:58:35, v_num=12, reduced_train_loss=2.170, global_step=15934.0, consumed_samples=63740.0, train_step_timing in s=0.544]Epoch 0: :   3%|▎         | 15936/600000 [06:30<3:58:35, v_num=12, reduced_train_loss=0.434, global_step=15935.0, consumed_samples=63744.0, train_step_timing in s=0.355]loss mask original None

First layer loss:  3.7710301876068115 torch.Size([672, 4]) 12.195135116577148 0.0
Max loss timestep torch.Size([672, 4]) tensor([371, 417, 587, 360], device='cuda:0') tensor(362, device='cuda:0')
bi 0 loss 3.5788896083831787
speech mask sum tensor(395, device='cuda:0') loss mask sum tensor(395, device='cuda:0')
bi 1 loss 4.076711177825928
speech mask sum tensor(364, device='cuda:0') loss mask sum tensor(364, device='cuda:0')
bi 2 loss 2.9550607204437256
speech mask sum tensor(449, device='cuda:0') loss mask sum tensor(449, device='cuda:0')
bi 3 loss 4.530200958251953
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
logits torch.Size([672, 4, 257024]) labels torch.Size([672, 4]) 0 257022
Layer  0  loss:  4.217557907104492 0.0 12.926678657531738
logits torch.Size([672, 4, 1024]) labels torch.Size([672, 4]) 0 1023
Curr loss timestep torch.Size([672, 4]) tensor([365, 244, 338, 490], device='cuda:0') tensor(378, device='cuda:0')
bi 0 loss 4.151854991912842
bi 1 loss 4.357566833496094
bi 2 loss 3.7384531497955322
bi 3 loss 4.653585910797119
Layer  1  loss:  4.55147647857666 0.0 13.386575698852539
logits torch.Size([672, 4, 1024]) labels torch.Size([672, 4]) 0 1022
Curr loss timestep torch.Size([672, 4]) tensor([261, 445, 576, 244], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 4.460220813751221
bi 1 loss 4.741332054138184
bi 2 loss 4.028104305267334
bi 3 loss 5.01462459564209
Layer  2  loss:  4.83384370803833 0.0 11.053970336914062
logits torch.Size([672, 4, 1024]) labels torch.Size([672, 4]) 0 1022
Curr loss timestep torch.Size([672, 4]) tensor([445, 327, 276, 326], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 4.8718719482421875
bi 1 loss 4.9127020835876465
bi 2 loss 4.308124542236328
bi 3 loss 5.274947643280029
Layer  3  loss:  4.933712482452393 0.0 11.191215515136719
logits torch.Size([672, 4, 1024]) labels torch.Size([672, 4]) 0 1023
Curr loss timestep torch.Size([672, 4]) tensor([254, 528, 601, 446], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 4.996145248413086
bi 1 loss 5.039555072784424
bi 2 loss 4.447268009185791
bi 3 loss 5.289735794067383
Layer  4  loss:  5.048330307006836 0.0 10.338714599609375
logits torch.Size([672, 4, 1024]) labels torch.Size([672, 4]) 0 1022
Curr loss timestep torch.Size([672, 4]) tensor([311, 320, 439, 146], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 5.230592250823975
bi 1 loss 5.103628158569336
bi 2 loss 4.512555122375488
bi 3 loss 5.388792037963867
Layer  5  loss:  5.154790878295898 0.0 11.93671989440918
logits torch.Size([672, 4, 1024]) labels torch.Size([672, 4]) 0 1023
Curr loss timestep torch.Size([672, 4]) tensor([483, 368, 608, 220], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 5.309786796569824
bi 1 loss 5.130424976348877
bi 2 loss 4.712857246398926
bi 3 loss 5.489822864532471
Layer  6  loss:  5.0825653076171875 0.0 12.183096885681152
logits torch.Size([672, 4, 1024]) labels torch.Size([672, 4]) 0 1023
Curr loss timestep torch.Size([672, 4]) tensor([527, 353, 416, 298], device='cuda:0') tensor(322, device='cuda:0')
bi 0 loss 5.287708759307861
bi 1 loss 5.087759494781494
bi 2 loss 4.630684852600098
bi 3 loss 5.357728958129883
Epoch 0: :   3%|▎         | 15937/600000 [06:31<3:58:51, v_num=12, reduced_train_loss=0.434, global_step=15935.0, consumed_samples=63744.0, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15937/600000 [06:31<3:58:51, v_num=12, reduced_train_loss=37.60, global_step=15936.0, consumed_samples=63748.0, train_step_timing in s=0.414]loss mask original None

First layer loss:  0.07738453894853592 torch.Size([569, 4]) 5.65974235534668 0.0
Max loss timestep torch.Size([569, 4]) tensor([168, 201,  57, 392], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.02760235220193863
speech mask sum tensor(146, device='cuda:0') loss mask sum tensor(146, device='cuda:0')
bi 1 loss 0.026580076664686203
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 0.03308195620775223
speech mask sum tensor(79, device='cuda:0') loss mask sum tensor(79, device='cuda:0')
bi 3 loss 0.1466536670923233
speech mask sum tensor(253, device='cuda:0') loss mask sum tensor(253, device='cuda:0')
logits torch.Size([569, 4, 257024]) labels torch.Size([569, 4]) 0 257022
Layer  0  loss:  0.07669448107481003 0.0 6.974308967590332
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([ 60, 189,  65, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.034595098346471786
bi 1 loss 0.02436468005180359
bi 2 loss 0.0165113415569067
bi 3 loss 0.1472906917333603
Layer  1  loss:  0.058064188808202744 0.0 6.519851207733154
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([152, 227,  69, 391], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.042017512023448944
bi 1 loss 0.017300035804510117
bi 2 loss 0.017163388431072235
bi 3 loss 0.10152509808540344
Layer  2  loss:  0.07959794998168945 0.0 7.976151466369629
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([123, 164,  91, 523], device='cuda:0') tensor(523, device='cuda:0')
bi 0 loss 0.045594148337841034
bi 1 loss 0.02615549974143505
bi 2 loss 0.024353625252842903
bi 3 loss 0.1445651650428772
Layer  3  loss:  0.08897841721773148 0.0 7.640021800994873
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1023
Curr loss timestep torch.Size([569, 4]) tensor([139, 182,  61, 525], device='cuda:0') tensor(525, device='cuda:0')
bi 0 loss 0.026611506938934326
bi 1 loss 0.06313709169626236
bi 2 loss 0.026430513709783554
bi 3 loss 0.15808415412902832
Layer  4  loss:  0.0864362046122551 0.0 7.652548313140869
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([151, 213,  86, 511], device='cuda:0') tensor(511, device='cuda:0')
bi 0 loss 0.028566742315888405
bi 1 loss 0.02921559475362301
bi 2 loss 0.02645963989198208
bi 3 loss 0.16863948106765747
Layer  5  loss:  0.07748719304800034 0.0 5.6038103103637695
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1019
Curr loss timestep torch.Size([569, 4]) tensor([ 86, 256,  82, 523], device='cuda:0') tensor(523, device='cuda:0')
bi 0 loss 0.03159043565392494
bi 1 loss 0.03264501690864563
bi 2 loss 0.038606636226177216
bi 3 loss 0.13968679308891296
Layer  6  loss:  0.09283854067325592 0.0 8.344897270202637
logits torch.Size([569, 4, 1024]) labels torch.Size([569, 4]) 0 1022
Curr loss timestep torch.Size([569, 4]) tensor([114, 202,  95, 392], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.030547108501195908
bi 1 loss 0.02519281953573227
bi 2 loss 0.04682926833629608
bi 3 loss 0.17871271073818207
Epoch 0: :   3%|▎         | 15938/600000 [06:31<3:59:06, v_num=12, reduced_train_loss=37.60, global_step=15936.0, consumed_samples=63748.0, train_step_timing in s=0.414]Epoch 0: :   3%|▎         | 15938/600000 [06:31<3:59:06, v_num=12, reduced_train_loss=0.637, global_step=15937.0, consumed_samples=63752.0, train_step_timing in s=0.395]loss mask original None

First layer loss:  0.07688681036233902 torch.Size([505, 4]) 11.222256660461426 0.0
Max loss timestep torch.Size([505, 4]) tensor([375, 335, 130, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.06803873181343079
speech mask sum tensor(352, device='cuda:0') loss mask sum tensor(352, device='cuda:0')
bi 1 loss 0.07369296252727509
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
bi 2 loss 0.05600139498710632
speech mask sum tensor(413, device='cuda:0') loss mask sum tensor(413, device='cuda:0')
bi 3 loss 0.11835354566574097
speech mask sum tensor(307, device='cuda:0') loss mask sum tensor(307, device='cuda:0')
logits torch.Size([505, 4, 257024]) labels torch.Size([505, 4]) 0 257023
Layer  0  loss:  0.0854872465133667 0.0 19.61818504333496
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1023
Curr loss timestep torch.Size([505, 4]) tensor([262, 155, 301, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.09509825706481934
bi 1 loss 0.049973901361227036
bi 2 loss 0.050193242728710175
bi 3 loss 0.1578080654144287
Layer  1  loss:  0.09603579342365265 0.0 17.164722442626953
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1023
Curr loss timestep torch.Size([505, 4]) tensor([263, 335, 284, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.09334471076726913
bi 1 loss 0.07586513459682465
bi 2 loss 0.073456309735775
bi 3 loss 0.14986471831798553
Layer  2  loss:  0.07558450102806091 0.0 11.335416793823242
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1022
Curr loss timestep torch.Size([505, 4]) tensor([333, 104, 397, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.08116345852613449
bi 1 loss 0.06301126629114151
bi 2 loss 0.06226951256394386
bi 3 loss 0.09979619830846786
Layer  3  loss:  0.09502754360437393 0.0 16.32822036743164
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1023
Curr loss timestep torch.Size([505, 4]) tensor([287, 379, 176, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.0808141827583313
bi 1 loss 0.11389487236738205
bi 2 loss 0.06943196058273315
bi 3 loss 0.12670576572418213
Layer  4  loss:  0.09268089383840561 0.0 9.881896018981934
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1019
Curr loss timestep torch.Size([505, 4]) tensor([315, 335, 476, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.12259352952241898
bi 1 loss 0.07181349396705627
bi 2 loss 0.07522516697645187
bi 3 loss 0.1029377430677414
Layer  5  loss:  0.09577146917581558 0.0 14.954032897949219
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1022
Curr loss timestep torch.Size([505, 4]) tensor([333, 234, 483, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.10565685480833054
bi 1 loss 0.0448903851211071
bi 2 loss 0.08636043965816498
bi 3 loss 0.14847582578659058
Layer  6  loss:  0.08836855739355087 0.0 11.44852352142334
logits torch.Size([505, 4, 1024]) labels torch.Size([505, 4]) 0 1023
Curr loss timestep torch.Size([505, 4]) tensor([266, 174, 316, 273], device='cuda:0') tensor(273, device='cuda:0')
bi 0 loss 0.09098978340625763
bi 1 loss 0.06927143037319183
bi 2 loss 0.07162108272314072
bi 3 loss 0.12717683613300323
Epoch 0: :   3%|▎         | 15939/600000 [06:31<3:59:19, v_num=12, reduced_train_loss=0.637, global_step=15937.0, consumed_samples=63752.0, train_step_timing in s=0.395]Epoch 0: :   3%|▎         | 15939/600000 [06:31<3:59:19, v_num=12, reduced_train_loss=0.706, global_step=15938.0, consumed_samples=63756.0, train_step_timing in s=0.356]loss mask original None

First layer loss:  3.724626302719116 torch.Size([704, 4]) 13.519063949584961 0.0
Max loss timestep torch.Size([704, 4]) tensor([396, 254, 108, 222], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 3.9758284091949463
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
bi 1 loss 3.551957607269287
speech mask sum tensor(193, device='cuda:0') loss mask sum tensor(193, device='cuda:0')
bi 2 loss 2.795131206512451
speech mask sum tensor(93, device='cuda:0') loss mask sum tensor(93, device='cuda:0')
bi 3 loss 3.728499412536621
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
logits torch.Size([704, 4, 257024]) labels torch.Size([704, 4]) 0 257022
Layer  0  loss:  4.318645477294922 0.0 10.696244239807129
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1023
Curr loss timestep torch.Size([704, 4]) tensor([261, 291,  91, 435], device='cuda:0') tensor(401, device='cuda:0')
bi 0 loss 4.460343837738037
bi 1 loss 4.44305944442749
bi 2 loss 3.6660759449005127
bi 3 loss 4.221212863922119
Layer  1  loss:  4.600697040557861 0.0 9.969944953918457
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1022
Curr loss timestep torch.Size([704, 4]) tensor([465, 377, 102, 192], device='cuda:0') tensor(289, device='cuda:0')
bi 0 loss 4.610881328582764
bi 1 loss 4.595689296722412
bi 2 loss 3.8953943252563477
bi 3 loss 4.799899578094482
Layer  2  loss:  4.90511417388916 0.0 10.175101280212402
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1022
Curr loss timestep torch.Size([704, 4]) tensor([580, 292, 114, 412], device='cuda:0') tensor(382, device='cuda:0')
bi 0 loss 5.006664276123047
bi 1 loss 4.941933631896973
bi 2 loss 4.043700218200684
bi 3 loss 4.985995769500732
Layer  3  loss:  5.106812000274658 0.0 10.660994529724121
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1023
Curr loss timestep torch.Size([704, 4]) tensor([525, 369, 100, 443], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 5.276115894317627
bi 1 loss 5.0943732261657715
bi 2 loss 4.22851037979126
bi 3 loss 5.120266437530518
Layer  4  loss:  5.291853904724121 0.0 10.748393058776855
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1022
Curr loss timestep torch.Size([704, 4]) tensor([636, 271,  78, 402], device='cuda:0') tensor(240, device='cuda:0')
bi 0 loss 5.3714494705200195
bi 1 loss 5.2564616203308105
bi 2 loss 4.299563884735107
bi 3 loss 5.490384578704834
Layer  5  loss:  5.277489185333252 0.0 10.823465347290039
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1023
Curr loss timestep torch.Size([704, 4]) tensor([499, 301, 136, 428], device='cuda:0') tensor(393, device='cuda:0')
bi 0 loss 5.397712230682373
bi 1 loss 5.330502510070801
bi 2 loss 4.160896301269531
bi 3 loss 5.396411895751953
Layer  6  loss:  5.363137722015381 0.0 11.514994621276855
logits torch.Size([704, 4, 1024]) labels torch.Size([704, 4]) 0 1023
Curr loss timestep torch.Size([704, 4]) tensor([429, 355, 103, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 5.475592613220215
bi 1 loss 5.41741418838501
bi 2 loss 4.376562595367432
bi 3 loss 5.454095363616943
Epoch 0: :   3%|▎         | 15940/600000 [06:32<3:59:36, v_num=12, reduced_train_loss=0.706, global_step=15938.0, consumed_samples=63756.0, train_step_timing in s=0.356]Epoch 0: :   3%|▎         | 15940/600000 [06:32<3:59:36, v_num=12, reduced_train_loss=38.60, global_step=15939.0, consumed_samples=63760.0, train_step_timing in s=0.438]loss mask original None

First layer loss:  0.03605804592370987 torch.Size([553, 4]) 2.6139609813690186 0.0
Max loss timestep torch.Size([553, 4]) tensor([273, 304, 394,  58], device='cuda:0') tensor(58, device='cuda:0')
bi 0 loss 0.029316211119294167
speech mask sum tensor(219, device='cuda:0') loss mask sum tensor(219, device='cuda:0')
bi 1 loss 0.03927669674158096
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 2 loss 0.0314742848277092
speech mask sum tensor(481, device='cuda:0') loss mask sum tensor(481, device='cuda:0')
bi 3 loss 0.05844928324222565
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
logits torch.Size([553, 4, 257024]) labels torch.Size([553, 4]) 0 257022
Layer  0  loss:  0.02929885871708393 0.0 1.9370421171188354
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([171, 296, 394,  62], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.023101847618818283
bi 1 loss 0.025032369419932365
bi 2 loss 0.03517535701394081
bi 3 loss 0.02313697151839733
Layer  1  loss:  0.03626213222742081 0.0 3.971120595932007
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([264, 304, 394, 138], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.04143216833472252
bi 1 loss 0.01872001588344574
bi 2 loss 0.0408080592751503
bi 3 loss 0.029705941677093506
Layer  2  loss:  0.032803550362586975 0.0 0.9071840643882751
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([202, 291, 254,  58], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 0.025715941563248634
bi 1 loss 0.03578667715191841
bi 2 loss 0.03459339588880539
bi 3 loss 0.03479352965950966
Layer  3  loss:  0.02926415205001831 0.0 0.8325923681259155
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1021
Curr loss timestep torch.Size([553, 4]) tensor([197, 296, 544, 140], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.02515467256307602
bi 1 loss 0.03029528632760048
bi 2 loss 0.031183846294879913
bi 3 loss 0.02814277820289135
Layer  4  loss:  0.0332612618803978 0.0 1.183158040046692
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([106, 278, 543,  94], device='cuda:0') tensor(106, device='cuda:0')
bi 0 loss 0.028317712247371674
bi 1 loss 0.03333596885204315
bi 2 loss 0.03551739454269409
bi 3 loss 0.033174049109220505
Layer  5  loss:  0.028690412640571594 0.0 1.5505276918411255
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1023
Curr loss timestep torch.Size([553, 4]) tensor([256, 292, 126,  40], device='cuda:0') tensor(126, device='cuda:0')
bi 0 loss 0.022400664165616035
bi 1 loss 0.016663314774632454
bi 2 loss 0.037623871117830276
bi 3 loss 0.019753308966755867
Layer  6  loss:  0.033956095576286316 0.0 2.6750895977020264
logits torch.Size([553, 4, 1024]) labels torch.Size([553, 4]) 0 1022
Curr loss timestep torch.Size([553, 4]) tensor([148, 310, 544, 121], device='cuda:0') tensor(544, device='cuda:0')
bi 0 loss 0.028538944199681282
bi 1 loss 0.0313243567943573
bi 2 loss 0.039130788296461105
bi 3 loss 0.02742241881787777
Epoch 0: :   3%|▎         | 15941/600000 [06:32<3:59:50, v_num=12, reduced_train_loss=38.60, global_step=15939.0, consumed_samples=63760.0, train_step_timing in s=0.438]Epoch 0: :   3%|▎         | 15941/600000 [06:32<3:59:50, v_num=12, reduced_train_loss=0.260, global_step=15940.0, consumed_samples=63764.0, train_step_timing in s=0.380]loss mask original None

First layer loss:  0.12840571999549866 torch.Size([663, 4]) 11.682755470275879 0.0
Max loss timestep torch.Size([663, 4]) tensor([225, 625, 377, 300], device='cuda:0') tensor(625, device='cuda:0')
bi 0 loss 0.06786315888166428
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
bi 1 loss 0.187281534075737
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
bi 2 loss 0.12790894508361816
speech mask sum tensor(339, device='cuda:0') loss mask sum tensor(339, device='cuda:0')
bi 3 loss 0.034784261137247086
speech mask sum tensor(145, device='cuda:0') loss mask sum tensor(145, device='cuda:0')
logits torch.Size([663, 4, 257024]) labels torch.Size([663, 4]) 0 257022
Layer  0  loss:  0.17196087539196014 0.0 11.255674362182617
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1023
Curr loss timestep torch.Size([663, 4]) tensor([316, 626, 316, 321], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.06531081348657608
bi 1 loss 0.21538391709327698
bi 2 loss 0.21276943385601044
bi 3 loss 0.10584386438131332
Layer  1  loss:  0.1790417730808258 0.0 13.923425674438477
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1022
Curr loss timestep torch.Size([663, 4]) tensor([160, 519, 375, 312], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.07653646916151047
bi 1 loss 0.2661832571029663
bi 2 loss 0.1828850656747818
bi 3 loss 0.05040428042411804
Layer  2  loss:  0.17232787609100342 0.0 13.173076629638672
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1022
Curr loss timestep torch.Size([663, 4]) tensor([317, 626, 376, 300], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.07577202469110489
bi 1 loss 0.22733204066753387
bi 2 loss 0.21020445227622986
bi 3 loss 0.05921619012951851
Layer  3  loss:  0.20199145376682281 0.0 13.140693664550781
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1023
Curr loss timestep torch.Size([663, 4]) tensor([311, 626, 316, 310], device='cuda:0') tensor(626, device='cuda:0')
bi 0 loss 0.0581304095685482
bi 1 loss 0.3134300112724304
bi 2 loss 0.1864423155784607
bi 3 loss 0.10577025264501572
Layer  4  loss:  0.18634214997291565 0.0 12.250712394714355
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1022
Curr loss timestep torch.Size([663, 4]) tensor([155, 625, 316, 321], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.0638250783085823
bi 1 loss 0.27080368995666504
bi 2 loss 0.19256281852722168
bi 3 loss 0.0928891971707344
Layer  5  loss:  0.19837316870689392 0.0 11.428375244140625
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1023
Curr loss timestep torch.Size([663, 4]) tensor([316, 512, 377, 321], device='cuda:0') tensor(316, device='cuda:0')
bi 0 loss 0.07478558272123337
bi 1 loss 0.25897446274757385
bi 2 loss 0.23309457302093506
bi 3 loss 0.11766938865184784
Layer  6  loss:  0.2091573029756546 0.0 15.069228172302246
logits torch.Size([663, 4, 1024]) labels torch.Size([663, 4]) 0 1023
Curr loss timestep torch.Size([663, 4]) tensor([311, 538, 314, 300], device='cuda:0') tensor(538, device='cuda:0')
bi 0 loss 0.08218394964933395
bi 1 loss 0.2936927080154419
bi 2 loss 0.2360876053571701
bi 3 loss 0.07417621463537216
Epoch 0: :   3%|▎         | 15942/600000 [06:33<4:00:07, v_num=12, reduced_train_loss=0.260, global_step=15940.0, consumed_samples=63764.0, train_step_timing in s=0.380]Epoch 0: :   3%|▎         | 15942/600000 [06:33<4:00:07, v_num=12, reduced_train_loss=1.450, global_step=15941.0, consumed_samples=63768.0, train_step_timing in s=0.455]loss mask original None

First layer loss:  0.1694985032081604 torch.Size([561, 4]) 14.983329772949219 0.0
Max loss timestep torch.Size([561, 4]) tensor([269,  74, 331, 301], device='cuda:0') tensor(331, device='cuda:0')
bi 0 loss 0.14404140412807465
speech mask sum tensor(268, device='cuda:0') loss mask sum tensor(268, device='cuda:0')
bi 1 loss 0.03082096204161644
speech mask sum tensor(70, device='cuda:0') loss mask sum tensor(70, device='cuda:0')
bi 2 loss 0.2693326473236084
speech mask sum tensor(251, device='cuda:0') loss mask sum tensor(251, device='cuda:0')
bi 3 loss 0.14404048025608063
speech mask sum tensor(335, device='cuda:0') loss mask sum tensor(335, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257023
Layer  0  loss:  0.20035339891910553 0.0 11.286837577819824
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([268,  53, 330, 267], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.18340417742729187
bi 1 loss 0.06749042868614197
bi 2 loss 0.27935007214546204
bi 3 loss 0.1824866384267807
Layer  1  loss:  0.2284068912267685 0.0 19.181852340698242
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([268,  50, 332, 349], device='cuda:0') tensor(332, device='cuda:0')
bi 0 loss 0.20846563577651978
bi 1 loss 0.02745833620429039
bi 2 loss 0.34150123596191406
bi 3 loss 0.20161283016204834
Layer  2  loss:  0.2216041088104248 0.0 13.345303535461426
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([269,  36, 332, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.13381178677082062
bi 1 loss 0.043933458626270294
bi 2 loss 0.34751832485198975
bi 3 loss 0.23462146520614624
Layer  3  loss:  0.22819934785366058 0.0 16.670520782470703
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([269,  69, 332, 349], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.16372798383235931
bi 1 loss 0.035434674471616745
bi 2 loss 0.37282782793045044
bi 3 loss 0.21169210970401764
Layer  4  loss:  0.2596651315689087 0.0 21.015657424926758
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([269,  50, 330, 349], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.20765197277069092
bi 1 loss 0.09311149269342422
bi 2 loss 0.39988991618156433
bi 3 loss 0.23101389408111572
Layer  5  loss:  0.2143906205892563 0.0 13.866739273071289
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([269,  65, 330, 349], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 0.19574731588363647
bi 1 loss 0.06914321333169937
bi 2 loss 0.31223323941230774
bi 3 loss 0.18634654581546783
Layer  6  loss:  0.22750280797481537 0.0 14.0980863571167
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1021
Curr loss timestep torch.Size([561, 4]) tensor([268,  57, 332, 301], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.21342390775680542
bi 1 loss 0.07391656935214996
bi 2 loss 0.34008175134658813
bi 3 loss 0.1865084022283554
Epoch 0: :   3%|▎         | 15943/600000 [06:33<4:00:22, v_num=12, reduced_train_loss=1.450, global_step=15941.0, consumed_samples=63768.0, train_step_timing in s=0.455]Epoch 0: :   3%|▎         | 15943/600000 [06:33<4:00:22, v_num=12, reduced_train_loss=1.750, global_step=15942.0, consumed_samples=63772.0, train_step_timing in s=0.391]loss mask original None

First layer loss:  0.08443423360586166 torch.Size([539, 4]) 7.377352714538574 0.0
Max loss timestep torch.Size([539, 4]) tensor([427, 302, 119, 369], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.13582032918930054
speech mask sum tensor(349, device='cuda:0') loss mask sum tensor(349, device='cuda:0')
bi 1 loss 0.07999671250581741
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 2 loss 0.06202534958720207
speech mask sum tensor(72, device='cuda:0') loss mask sum tensor(72, device='cuda:0')
bi 3 loss 0.03511592373251915
speech mask sum tensor(323, device='cuda:0') loss mask sum tensor(323, device='cuda:0')
logits torch.Size([539, 4, 257024]) labels torch.Size([539, 4]) 0 257022
Layer  0  loss:  0.10631818324327469 0.0 12.761280059814453
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([427, 302, 124, 374], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.1569463461637497
bi 1 loss 0.19864468276500702
bi 2 loss 0.03671665117144585
bi 3 loss 0.041975609958171844
Layer  1  loss:  0.08601929247379303 0.0 12.313246726989746
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([427, 302, 114, 203], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.11316367983818054
bi 1 loss 0.18259014189243317
bi 2 loss 0.03523498773574829
bi 3 loss 0.041699934750795364
Layer  2  loss:  0.104227215051651 0.0 10.24340534210205
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([427, 302, 102, 111], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.16050927340984344
bi 1 loss 0.15892305970191956
bi 2 loss 0.05159847438335419
bi 3 loss 0.040244512259960175
Layer  3  loss:  0.10151099413633347 0.0 5.708649635314941
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1021
Curr loss timestep torch.Size([539, 4]) tensor([429, 302, 109, 268], device='cuda:0') tensor(302, device='cuda:0')
bi 0 loss 0.140194371342659
bi 1 loss 0.23131513595581055
bi 2 loss 0.030044760555028915
bi 3 loss 0.040279749780893326
Layer  4  loss:  0.09080011397600174 0.0 11.368626594543457
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([427, 302, 108, 359], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.13941015303134918
bi 1 loss 0.14600849151611328
bi 2 loss 0.016581539064645767
bi 3 loss 0.039779968559741974
Layer  5  loss:  0.10995259881019592 0.0 17.739595413208008
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1023
Curr loss timestep torch.Size([539, 4]) tensor([427, 302, 129, 146], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.16689305007457733
bi 1 loss 0.168898805975914
bi 2 loss 0.036762785166502
bi 3 loss 0.048683810979127884
Layer  6  loss:  0.10919202119112015 0.0 16.968780517578125
logits torch.Size([539, 4, 1024]) labels torch.Size([539, 4]) 0 1022
Curr loss timestep torch.Size([539, 4]) tensor([427, 302, 124, 338], device='cuda:0') tensor(427, device='cuda:0')
bi 0 loss 0.14934368431568146
bi 1 loss 0.21383939683437347
bi 2 loss 0.03172416239976883
bi 3 loss 0.05456600338220596
Epoch 0: :   3%|▎         | 15944/600000 [06:34<4:00:36, v_num=12, reduced_train_loss=1.750, global_step=15942.0, consumed_samples=63772.0, train_step_timing in s=0.391]Epoch 0: :   3%|▎         | 15944/600000 [06:34<4:00:36, v_num=12, reduced_train_loss=0.792, global_step=15943.0, consumed_samples=63776.0, train_step_timing in s=0.374]loss mask original None

First layer loss:  3.9273502826690674 torch.Size([520, 4]) 10.487847328186035 0.0
Max loss timestep torch.Size([520, 4]) tensor([343, 121, 166, 188], device='cuda:0') tensor(184, device='cuda:0')
bi 0 loss 4.149014949798584
speech mask sum tensor(347, device='cuda:0') loss mask sum tensor(347, device='cuda:0')
bi 1 loss 3.5784122943878174
speech mask sum tensor(170, device='cuda:0') loss mask sum tensor(170, device='cuda:0')
bi 2 loss 3.796881675720215
speech mask sum tensor(222, device='cuda:0') loss mask sum tensor(222, device='cuda:0')
bi 3 loss 3.97470760345459
speech mask sum tensor(240, device='cuda:0') loss mask sum tensor(240, device='cuda:0')
logits torch.Size([520, 4, 257024]) labels torch.Size([520, 4]) 0 257021
Layer  0  loss:  4.384643077850342 0.0 11.41646957397461
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([285, 134, 267, 227], device='cuda:0') tensor(185, device='cuda:0')
bi 0 loss 4.4699859619140625
bi 1 loss 3.9919021129608154
bi 2 loss 4.648615837097168
bi 3 loss 4.295266151428223
Layer  1  loss:  4.699704170227051 0.0 10.201631546020508
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1022
Curr loss timestep torch.Size([520, 4]) tensor([479,  84, 208, 275], device='cuda:0') tensor(194, device='cuda:0')
bi 0 loss 4.751221179962158
bi 1 loss 4.752305507659912
bi 2 loss 4.737951278686523
bi 3 loss 4.552579879760742
Layer  2  loss:  5.113107204437256 0.0 10.84827709197998
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([500, 196, 186, 201], device='cuda:0') tensor(191, device='cuda:0')
bi 0 loss 5.415415287017822
bi 1 loss 4.885499000549316
bi 2 loss 5.092623710632324
bi 3 loss 4.8561882972717285
Layer  3  loss:  5.167959690093994 0.0 10.008919715881348
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1019
Curr loss timestep torch.Size([520, 4]) tensor([380,  92, 275, 263], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 5.561212062835693
bi 1 loss 4.867342472076416
bi 2 loss 4.9821977615356445
bi 3 loss 4.984152317047119
Layer  4  loss:  5.344945907592773 0.0 10.364699363708496
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([426,  87, 240, 258], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 5.684420585632324
bi 1 loss 4.983019828796387
bi 2 loss 5.2644429206848145
bi 3 loss 5.184950828552246
Layer  5  loss:  5.315208435058594 0.0 10.108318328857422
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1023
Curr loss timestep torch.Size([520, 4]) tensor([313, 100, 166, 373], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 5.633823394775391
bi 1 loss 4.850762367248535
bi 2 loss 5.273110389709473
bi 3 loss 5.222465991973877
Layer  6  loss:  5.425878524780273 0.0 9.978318214416504
logits torch.Size([520, 4, 1024]) labels torch.Size([520, 4]) 0 1021
Curr loss timestep torch.Size([520, 4]) tensor([450, 209, 191, 278], device='cuda:0') tensor(188, device='cuda:0')
bi 0 loss 5.7410888671875
bi 1 loss 5.047712326049805
bi 2 loss 5.258432388305664
bi 3 loss 5.3928914070129395
Epoch 0: :   3%|▎         | 15945/600000 [06:34<4:00:49, v_num=12, reduced_train_loss=0.792, global_step=15943.0, consumed_samples=63776.0, train_step_timing in s=0.374]Epoch 0: :   3%|▎         | 15945/600000 [06:34<4:00:49, v_num=12, reduced_train_loss=39.40, global_step=15944.0, consumed_samples=63780.0, train_step_timing in s=0.339]loss mask original None

First layer loss:  0.1961054801940918 torch.Size([561, 4]) 9.443851470947266 0.0
Max loss timestep torch.Size([561, 4]) tensor([329, 281, 481, 543], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.18907342851161957
speech mask sum tensor(179, device='cuda:0') loss mask sum tensor(179, device='cuda:0')
bi 1 loss 0.12911206483840942
speech mask sum tensor(478, device='cuda:0') loss mask sum tensor(478, device='cuda:0')
bi 2 loss 0.29548782110214233
speech mask sum tensor(281, device='cuda:0') loss mask sum tensor(281, device='cuda:0')
bi 3 loss 0.20945996046066284
speech mask sum tensor(401, device='cuda:0') loss mask sum tensor(401, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257022
Layer  0  loss:  0.2058376520872116 0.0 10.137735366821289
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([263, 277, 418, 533], device='cuda:0') tensor(533, device='cuda:0')
bi 0 loss 0.2248024046421051
bi 1 loss 0.1581883430480957
bi 2 loss 0.28048762679100037
bi 3 loss 0.20186011493206024
Layer  1  loss:  0.23115910589694977 0.0 12.846109390258789
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([326, 276, 481, 543], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.32479944825172424
bi 1 loss 0.2008405327796936
bi 2 loss 0.23873716592788696
bi 3 loss 0.22018955647945404
Layer  2  loss:  0.2762661278247833 0.0 15.296499252319336
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([326, 276, 415, 533], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.24758969247341156
bi 1 loss 0.21242201328277588
bi 2 loss 0.32100602984428406
bi 3 loss 0.33381885290145874
Layer  3  loss:  0.2254999876022339 0.0 12.562664985656738
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1021
Curr loss timestep torch.Size([561, 4]) tensor([326, 276, 369, 543], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.21223296225070953
bi 1 loss 0.16332663595676422
bi 2 loss 0.20337942242622375
bi 3 loss 0.3210350275039673
Layer  4  loss:  0.21890561282634735 0.0 14.250195503234863
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([329, 275, 481, 326], device='cuda:0') tensor(329, device='cuda:0')
bi 0 loss 0.25990819931030273
bi 1 loss 0.1762334108352661
bi 2 loss 0.26577621698379517
bi 3 loss 0.21862435340881348
Layer  5  loss:  0.23696087300777435 0.0 12.177877426147461
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([329, 527, 481, 533], device='cuda:0') tensor(326, device='cuda:0')
bi 0 loss 0.24335739016532898
bi 1 loss 0.17537400126457214
bi 2 loss 0.2623700201511383
bi 3 loss 0.2897129952907562
Layer  6  loss:  0.2438122034072876 0.0 15.822694778442383
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([278, 276, 320, 329], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.24752335250377655
bi 1 loss 0.18503519892692566
bi 2 loss 0.2951463460922241
bi 3 loss 0.27624666690826416
Epoch 0: :   3%|▎         | 15946/600000 [06:34<4:01:03, v_num=12, reduced_train_loss=39.40, global_step=15944.0, consumed_samples=63780.0, train_step_timing in s=0.339]Epoch 0: :   3%|▎         | 15946/600000 [06:34<4:01:03, v_num=12, reduced_train_loss=1.830, global_step=15945.0, consumed_samples=63784.0, train_step_timing in s=0.388]loss mask original None

First layer loss:  0.11913429200649261 torch.Size([522, 4]) 11.70606803894043 0.0
Max loss timestep torch.Size([522, 4]) tensor([283, 198, 397, 299], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.33708104491233826
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
bi 1 loss 0.04030067101120949
speech mask sum tensor(133, device='cuda:0') loss mask sum tensor(133, device='cuda:0')
bi 2 loss 0.10667489469051361
speech mask sum tensor(450, device='cuda:0') loss mask sum tensor(450, device='cuda:0')
bi 3 loss 0.08380797505378723
speech mask sum tensor(291, device='cuda:0') loss mask sum tensor(291, device='cuda:0')
logits torch.Size([522, 4, 257024]) labels torch.Size([522, 4]) 0 257023
Layer  0  loss:  0.1164516732096672 0.0 12.48659610748291
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([285, 168, 397, 303], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.24868342280387878
bi 1 loss 0.06866775453090668
bi 2 loss 0.1186814233660698
bi 3 loss 0.07986004650592804
Layer  1  loss:  0.12488952279090881 0.0 12.97661018371582
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1021
Curr loss timestep torch.Size([522, 4]) tensor([282, 207, 397, 309], device='cuda:0') tensor(282, device='cuda:0')
bi 0 loss 0.32412952184677124
bi 1 loss 0.05269039422273636
bi 2 loss 0.112035371363163
bi 3 loss 0.09491978585720062
Layer  2  loss:  0.13847164809703827 0.0 11.858295440673828
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1022
Curr loss timestep torch.Size([522, 4]) tensor([283, 255, 319, 370], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.29707181453704834
bi 1 loss 0.05640502646565437
bi 2 loss 0.1545674353837967
bi 3 loss 0.08514223247766495
Layer  3  loss:  0.1188826933503151 0.0 12.362252235412598
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1021
Curr loss timestep torch.Size([522, 4]) tensor([285, 250, 397, 179], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.24221767485141754
bi 1 loss 0.047710198909044266
bi 2 loss 0.10413631051778793
bi 3 loss 0.12293176352977753
Layer  4  loss:  0.15364374220371246 0.0 18.329021453857422
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1022
Curr loss timestep torch.Size([522, 4]) tensor([283, 251, 319, 303], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.4599776864051819
bi 1 loss 0.0459328219294548
bi 2 loss 0.11977361887693405
bi 3 loss 0.12787295877933502
Layer  5  loss:  0.11365749686956406 0.0 15.511520385742188
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1022
Curr loss timestep torch.Size([522, 4]) tensor([285, 184, 397, 281], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 0.3640226125717163
bi 1 loss 0.05605186149477959
bi 2 loss 0.08560784161090851
bi 3 loss 0.07925786077976227
Layer  6  loss:  0.1543850153684616 0.0 12.778042793273926
logits torch.Size([522, 4, 1024]) labels torch.Size([522, 4]) 0 1023
Curr loss timestep torch.Size([522, 4]) tensor([283, 218, 397, 278], device='cuda:0') tensor(397, device='cuda:0')
bi 0 loss 0.3571089804172516
bi 1 loss 0.04812496900558472
bi 2 loss 0.14493119716644287
bi 3 loss 0.13327568769454956
Epoch 0: :   3%|▎         | 15947/600000 [06:35<4:01:17, v_num=12, reduced_train_loss=1.830, global_step=15945.0, consumed_samples=63784.0, train_step_timing in s=0.388]Epoch 0: :   3%|▎         | 15947/600000 [06:35<4:01:17, v_num=12, reduced_train_loss=1.040, global_step=15946.0, consumed_samples=63788.0, train_step_timing in s=0.361]loss mask original None

First layer loss:  3.4354329109191895 torch.Size([624, 4]) 11.39579963684082 0.0
Max loss timestep torch.Size([624, 4]) tensor([275,  67, 161, 435], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 3.0762457847595215
speech mask sum tensor(345, device='cuda:0') loss mask sum tensor(345, device='cuda:0')
bi 1 loss 3.814434766769409
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 2 loss 3.7728962898254395
speech mask sum tensor(392, device='cuda:0') loss mask sum tensor(392, device='cuda:0')
bi 3 loss 3.2535948753356934
speech mask sum tensor(392, device='cuda:0') loss mask sum tensor(392, device='cuda:0')
logits torch.Size([624, 4, 257024]) labels torch.Size([624, 4]) 0 257022
Layer  0  loss:  4.0458984375 0.0 10.025162696838379
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1023
Curr loss timestep torch.Size([624, 4]) tensor([246, 127, 392, 294], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 3.6783995628356934
bi 1 loss 4.685207366943359
bi 2 loss 4.157191753387451
bi 3 loss 3.987313985824585
Layer  1  loss:  4.382474899291992 0.0 10.319648742675781
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1022
Curr loss timestep torch.Size([624, 4]) tensor([324, 163, 511, 246], device='cuda:0') tensor(246, device='cuda:0')
bi 0 loss 3.8780643939971924
bi 1 loss 4.632993698120117
bi 2 loss 4.521960258483887
bi 3 loss 4.58083438873291
Layer  2  loss:  4.636409759521484 0.0 11.527029037475586
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1023
Curr loss timestep torch.Size([624, 4]) tensor([383, 108, 387, 239], device='cuda:0') tensor(359, device='cuda:0')
bi 0 loss 4.016870975494385
bi 1 loss 4.812618732452393
bi 2 loss 4.9690399169921875
bi 3 loss 4.774418354034424
Layer  3  loss:  4.7697343826293945 0.0 11.647177696228027
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1021
Curr loss timestep torch.Size([624, 4]) tensor([225,  55, 426, 510], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 4.120604515075684
bi 1 loss 4.877248764038086
bi 2 loss 5.243342876434326
bi 3 loss 4.821897506713867
Layer  4  loss:  4.97335147857666 0.0 10.347664833068848
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1022
Curr loss timestep torch.Size([624, 4]) tensor([203, 185, 355, 243], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 4.318848133087158
bi 1 loss 5.225067615509033
bi 2 loss 5.275926113128662
bi 3 loss 5.140212535858154
Layer  5  loss:  5.106627941131592 0.0 11.35952377319336
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1023
Curr loss timestep torch.Size([624, 4]) tensor([391, 104, 399, 379], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 4.494452476501465
bi 1 loss 5.260363578796387
bi 2 loss 5.420286655426025
bi 3 loss 5.26664400100708
Layer  6  loss:  5.176489353179932 0.0 10.019342422485352
logits torch.Size([624, 4, 1024]) labels torch.Size([624, 4]) 0 1022
Curr loss timestep torch.Size([624, 4]) tensor([ 68,  74, 408, 577], device='cuda:0') tensor(247, device='cuda:0')
bi 0 loss 4.538247108459473
bi 1 loss 5.172596454620361
bi 2 loss 5.449673175811768
bi 3 loss 5.466672897338867
Epoch 0: :   3%|▎         | 15948/600000 [06:35<4:01:31, v_num=12, reduced_train_loss=1.040, global_step=15946.0, consumed_samples=63788.0, train_step_timing in s=0.361]Epoch 0: :   3%|▎         | 15948/600000 [06:35<4:01:31, v_num=12, reduced_train_loss=36.50, global_step=15947.0, consumed_samples=63792.0, train_step_timing in s=0.382]loss mask original None

First layer loss:  0.0732755959033966 torch.Size([458, 4]) 10.351414680480957 0.0
Max loss timestep torch.Size([458, 4]) tensor([ 75, 428, 325,  60], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.0346439965069294
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 1 loss 0.10097851604223251
speech mask sum tensor(304, device='cuda:0') loss mask sum tensor(304, device='cuda:0')
bi 2 loss 0.08653350174427032
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
bi 3 loss 0.06957203149795532
speech mask sum tensor(396, device='cuda:0') loss mask sum tensor(396, device='cuda:0')
logits torch.Size([458, 4, 257024]) labels torch.Size([458, 4]) 0 257023
Layer  0  loss:  0.07111110538244247 0.0 6.0363311767578125
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([186, 428, 331, 293], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.034320954233407974
bi 1 loss 0.08055966347455978
bi 2 loss 0.10764635354280472
bi 3 loss 0.07671968638896942
Layer  1  loss:  0.07331761717796326 0.0 10.294898986816406
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([163, 429, 333, 291], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 0.03850322589278221
bi 1 loss 0.0935908779501915
bi 2 loss 0.13105270266532898
bi 3 loss 0.06618224084377289
Layer  2  loss:  0.0799003317952156 0.0 8.754929542541504
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([115, 428, 332, 293], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.03422758728265762
bi 1 loss 0.1266985684633255
bi 2 loss 0.10746246576309204
bi 3 loss 0.06281765550374985
Layer  3  loss:  0.08652696758508682 0.0 7.937041282653809
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([203, 428, 322, 291], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.022226816043257713
bi 1 loss 0.1152215376496315
bi 2 loss 0.09383393824100494
bi 3 loss 0.09611745923757553
Layer  4  loss:  0.09100613743066788 0.0 15.486139297485352
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1022
Curr loss timestep torch.Size([458, 4]) tensor([204, 428, 327, 293], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.033856745809316635
bi 1 loss 0.1415901631116867
bi 2 loss 0.08739577233791351
bi 3 loss 0.0819094106554985
Layer  5  loss:  0.10316512733697891 0.0 15.884288787841797
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([163, 428, 319, 293], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.04947194084525108
bi 1 loss 0.1273404359817505
bi 2 loss 0.10850977897644043
bi 3 loss 0.1111314669251442
Layer  6  loss:  0.08283759653568268 0.0 9.357989311218262
logits torch.Size([458, 4, 1024]) labels torch.Size([458, 4]) 0 1023
Curr loss timestep torch.Size([458, 4]) tensor([141, 428, 338, 293], device='cuda:0') tensor(428, device='cuda:0')
bi 0 loss 0.024442601948976517
bi 1 loss 0.1296101063489914
bi 2 loss 0.10021046549081802
bi 3 loss 0.07391104847192764
Epoch 0: :   3%|▎         | 15949/600000 [06:36<4:01:44, v_num=12, reduced_train_loss=36.50, global_step=15947.0, consumed_samples=63792.0, train_step_timing in s=0.382]Epoch 0: :   3%|▎         | 15949/600000 [06:36<4:01:44, v_num=12, reduced_train_loss=0.661, global_step=15948.0, consumed_samples=63796.0, train_step_timing in s=0.328]loss mask original None

First layer loss:  3.222968816757202 torch.Size([472, 4]) 9.93592357635498 0.0
Max loss timestep torch.Size([472, 4]) tensor([201, 351, 314, 248], device='cuda:0') tensor(264, device='cuda:0')
bi 0 loss 3.196835994720459
speech mask sum tensor(35, device='cuda:0') loss mask sum tensor(35, device='cuda:0')
bi 1 loss 3.6559438705444336
speech mask sum tensor(278, device='cuda:0') loss mask sum tensor(278, device='cuda:0')
bi 2 loss 2.6968994140625
speech mask sum tensor(206, device='cuda:0') loss mask sum tensor(206, device='cuda:0')
bi 3 loss 3.1532704830169678
speech mask sum tensor(159, device='cuda:0') loss mask sum tensor(159, device='cuda:0')
logits torch.Size([472, 4, 257024]) labels torch.Size([472, 4]) 0 257023
Layer  0  loss:  3.935835361480713 0.0 9.217244148254395
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([182, 312, 374, 232], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 3.6994528770446777
bi 1 loss 4.341573715209961
bi 2 loss 3.4082190990448
bi 3 loss 3.962043523788452
Layer  1  loss:  4.4175920486450195 0.0 9.212055206298828
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([195, 348, 387, 303], device='cuda:0') tensor(196, device='cuda:0')
bi 0 loss 3.504197120666504
bi 1 loss 4.7331342697143555
bi 2 loss 4.21832799911499
bi 3 loss 4.325118541717529
Layer  2  loss:  4.498699188232422 0.0 10.536172866821289
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([186, 256, 378, 210], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 3.7950451374053955
bi 1 loss 4.6891255378723145
bi 2 loss 4.3014607429504395
bi 3 loss 4.576188564300537
Layer  3  loss:  4.705137729644775 0.0 9.479909896850586
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([187, 209, 249, 270], device='cuda:0') tensor(285, device='cuda:0')
bi 0 loss 3.644268751144409
bi 1 loss 5.065536975860596
bi 2 loss 4.478799343109131
bi 3 loss 4.601773262023926
Layer  4  loss:  4.823391437530518 0.0 8.70054817199707
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([189, 212, 229, 333], device='cuda:0') tensor(274, device='cuda:0')
bi 0 loss 3.6584582328796387
bi 1 loss 5.265778064727783
bi 2 loss 4.537679195404053
bi 3 loss 4.676509380340576
Layer  5  loss:  5.0184831619262695 0.0 9.521575927734375
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([195, 369, 389, 213], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 3.84454345703125
bi 1 loss 5.428548336029053
bi 2 loss 4.832162857055664
bi 3 loss 4.801323890686035
Layer  6  loss:  5.106327533721924 0.0 9.893409729003906
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([196, 463, 345, 262], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 3.9737234115600586
bi 1 loss 5.564161777496338
bi 2 loss 4.899051666259766
bi 3 loss 4.823698043823242
Epoch 0: :   3%|▎         | 15950/600000 [06:36<4:01:56, v_num=12, reduced_train_loss=0.661, global_step=15948.0, consumed_samples=63796.0, train_step_timing in s=0.328]Epoch 0: :   3%|▎         | 15950/600000 [06:36<4:01:56, v_num=12, reduced_train_loss=35.70, global_step=15949.0, consumed_samples=63800.0, train_step_timing in s=0.329]loss mask original None

First layer loss:  0.03072093240916729 torch.Size([322, 4]) 2.211442708969116 0.0
Max loss timestep torch.Size([322, 4]) tensor([198, 137,  94, 215], device='cuda:0') tensor(198, device='cuda:0')
bi 0 loss 0.04550367221236229
speech mask sum tensor(232, device='cuda:0') loss mask sum tensor(232, device='cuda:0')
bi 1 loss 0.013211586512625217
speech mask sum tensor(102, device='cuda:0') loss mask sum tensor(102, device='cuda:0')
bi 2 loss 0.01832515373826027
speech mask sum tensor(61, device='cuda:0') loss mask sum tensor(61, device='cuda:0')
bi 3 loss 0.017858613282442093
speech mask sum tensor(69, device='cuda:0') loss mask sum tensor(69, device='cuda:0')
logits torch.Size([322, 4, 257024]) labels torch.Size([322, 4]) 0 257020
Layer  0  loss:  0.020779041573405266 0.0 0.4793364405632019
logits torch.Size([322, 4, 1024]) labels torch.Size([322, 4]) 0 1023
Curr loss timestep torch.Size([322, 4]) tensor([105, 174,  59, 257], device='cuda:0') tensor(105, device='cuda:0')
bi 0 loss 0.024967946112155914
bi 1 loss 0.01635376177728176
bi 2 loss 0.01208412740379572
bi 3 loss 0.02092314325273037
Layer  1  loss:  0.017577212303876877 0.0 0.3053628206253052
logits torch.Size([322, 4, 1024]) labels torch.Size([322, 4]) 0 1022
Curr loss timestep torch.Size([322, 4]) tensor([ 96, 149,  72, 215], device='cuda:0') tensor(96, device='cuda:0')
bi 0 loss 0.020297156646847725
bi 1 loss 0.013405148871243
bi 2 loss 0.024800973013043404
bi 3 loss 0.008213071152567863
Layer  2  loss:  0.018874233588576317 0.0 0.6781951785087585
logits torch.Size([322, 4, 1024]) labels torch.Size([322, 4]) 0 1022
Curr loss timestep torch.Size([322, 4]) tensor([157, 136,  86, 226], device='cuda:0') tensor(157, device='cuda:0')
bi 0 loss 0.02370949275791645
bi 1 loss 0.012637433595955372
bi 2 loss 0.010546080768108368
bi 3 loss 0.01919875666499138
Layer  3  loss:  0.019040895625948906 0.0 0.4148297607898712
logits torch.Size([322, 4, 1024]) labels torch.Size([322, 4]) 0 1021
Curr loss timestep torch.Size([322, 4]) tensor([278, 177,  54, 213], device='cuda:0') tensor(54, device='cuda:0')
bi 0 loss 0.021675849333405495
bi 1 loss 0.015733327716588974
bi 2 loss 0.019804667681455612
bi 3 loss 0.01439556386321783
Layer  4  loss:  0.022806547582149506 0.0 0.6955822706222534
logits torch.Size([322, 4, 1024]) labels torch.Size([322, 4]) 0 1023
Curr loss timestep torch.Size([322, 4]) tensor([293, 134,  68, 223], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 0.02679227478802204
bi 1 loss 0.011641787365078926
bi 2 loss 0.028135115280747414
bi 3 loss 0.02119891531765461
Layer  5  loss:  0.02014530450105667 0.0 0.39206916093826294
logits torch.Size([322, 4, 1024]) labels torch.Size([322, 4]) 0 1022
Curr loss timestep torch.Size([322, 4]) tensor([221, 153,  69, 208], device='cuda:0') tensor(221, device='cuda:0')
bi 0 loss 0.02302892506122589
bi 1 loss 0.014675762504339218
bi 2 loss 0.02050897665321827
bi 3 loss 0.018213553354144096
Layer  6  loss:  0.016629649326205254 0.0 0.23527459800243378
logits torch.Size([322, 4, 1024]) labels torch.Size([322, 4]) 0 1019
Curr loss timestep torch.Size([322, 4]) tensor([101, 156,  60, 221], device='cuda:0') tensor(101, device='cuda:0')
bi 0 loss 0.019414646551012993
bi 1 loss 0.008587700314819813
bi 2 loss 0.015761077404022217
bi 3 loss 0.01992155611515045
Epoch 0: :   3%|▎         | 15951/600000 [06:36<4:02:06, v_num=12, reduced_train_loss=35.70, global_step=15949.0, consumed_samples=63800.0, train_step_timing in s=0.329]Epoch 0: :   3%|▎         | 15951/600000 [06:36<4:02:06, v_num=12, reduced_train_loss=0.167, global_step=1.6e+4, consumed_samples=63804.0, train_step_timing in s=0.264] loss mask original None

First layer loss:  0.06890435516834259 torch.Size([633, 4]) 7.515374183654785 0.0
Max loss timestep torch.Size([633, 4]) tensor([176, 232, 495, 159], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.033332984894514084
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
bi 1 loss 0.03011697717010975
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
bi 2 loss 0.10641223937273026
speech mask sum tensor(478, device='cuda:0') loss mask sum tensor(478, device='cuda:0')
bi 3 loss 0.04712830111384392
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
logits torch.Size([633, 4, 257024]) labels torch.Size([633, 4]) 0 257022
Layer  0  loss:  0.06716424226760864 0.0 10.112048149108887
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([221, 273, 496, 193], device='cuda:0') tensor(496, device='cuda:0')
bi 0 loss 0.028413821011781693
bi 1 loss 0.03158875182271004
bi 2 loss 0.10974234342575073
bi 3 loss 0.029260942712426186
Layer  1  loss:  0.07273019105195999 0.0 15.343792915344238
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([177, 273, 496, 115], device='cuda:0') tensor(496, device='cuda:0')
bi 0 loss 0.04539560526609421
bi 1 loss 0.056223828345537186
bi 2 loss 0.10398007929325104
bi 3 loss 0.030425837263464928
Layer  2  loss:  0.08536439388990402 0.0 13.845439910888672
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([172, 271, 497, 211], device='cuda:0') tensor(497, device='cuda:0')
bi 0 loss 0.02747228369116783
bi 1 loss 0.0452837198972702
bi 2 loss 0.1380680352449417
bi 3 loss 0.03930599242448807
Layer  3  loss:  0.08444227278232574 0.0 9.032828330993652
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([215, 273, 495, 144], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.0462215431034565
bi 1 loss 0.059239234775304794
bi 2 loss 0.11741089820861816
bi 3 loss 0.0571366548538208
Layer  4  loss:  0.07824261486530304 0.0 13.361642837524414
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1017
Curr loss timestep torch.Size([633, 4]) tensor([158, 117, 495, 209], device='cuda:0') tensor(495, device='cuda:0')
bi 0 loss 0.03802300617098808
bi 1 loss 0.02666759118437767
bi 2 loss 0.12737037241458893
bi 3 loss 0.046637341380119324
Layer  5  loss:  0.07606597244739532 0.0 13.062911987304688
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1022
Curr loss timestep torch.Size([633, 4]) tensor([149, 273, 496, 137], device='cuda:0') tensor(496, device='cuda:0')
bi 0 loss 0.023543577641248703
bi 1 loss 0.0347258560359478
bi 2 loss 0.12502163648605347
bi 3 loss 0.03834705799818039
Layer  6  loss:  0.08919967710971832 0.0 15.495589256286621
logits torch.Size([633, 4, 1024]) labels torch.Size([633, 4]) 0 1023
Curr loss timestep torch.Size([633, 4]) tensor([220, 273, 497, 157], device='cuda:0') tensor(497, device='cuda:0')
bi 0 loss 0.03985344246029854
bi 1 loss 0.05786191299557686
bi 2 loss 0.14143608510494232
bi 3 loss 0.02625381015241146
Epoch 0: :   3%|▎         | 15952/600000 [06:37<4:02:23, v_num=12, reduced_train_loss=0.167, global_step=1.6e+4, consumed_samples=63804.0, train_step_timing in s=0.264]Epoch 0: :   3%|▎         | 15952/600000 [06:37<4:02:23, v_num=12, reduced_train_loss=0.622, global_step=1.6e+4, consumed_samples=63808.0, train_step_timing in s=0.432]loss mask original None

First layer loss:  0.10791659355163574 torch.Size([471, 4]) 11.22307300567627 0.0
Max loss timestep torch.Size([471, 4]) tensor([206, 436, 224, 268], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.03433848172426224
speech mask sum tensor(115, device='cuda:0') loss mask sum tensor(115, device='cuda:0')
bi 1 loss 0.10577866435050964
speech mask sum tensor(356, device='cuda:0') loss mask sum tensor(356, device='cuda:0')
bi 2 loss 0.16995498538017273
speech mask sum tensor(194, device='cuda:0') loss mask sum tensor(194, device='cuda:0')
bi 3 loss 0.057686805725097656
speech mask sum tensor(56, device='cuda:0') loss mask sum tensor(56, device='cuda:0')
logits torch.Size([471, 4, 257024]) labels torch.Size([471, 4]) 0 257022
Layer  0  loss:  0.0763106718659401 0.0 4.805861473083496
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([177, 437, 180, 291], device='cuda:0') tensor(180, device='cuda:0')
bi 0 loss 0.03315078467130661
bi 1 loss 0.07640320807695389
bi 2 loss 0.09964773803949356
bi 3 loss 0.08350799232721329
Layer  1  loss:  0.09369885176420212 0.0 12.818598747253418
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([186, 436, 319, 264], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.040183112025260925
bi 1 loss 0.11654812842607498
bi 2 loss 0.08900181949138641
bi 3 loss 0.0746130421757698
Layer  2  loss:  0.08337269723415375 0.0 8.546568870544434
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1022
Curr loss timestep torch.Size([471, 4]) tensor([200, 436, 258, 294], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.027645990252494812
bi 1 loss 0.09755457937717438
bi 2 loss 0.08627352863550186
bi 3 loss 0.09760605543851852
Layer  3  loss:  0.10862674564123154 0.0 10.410787582397461
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([183, 436, 190, 292], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.055483803153038025
bi 1 loss 0.11749985814094543
bi 2 loss 0.09866905212402344
bi 3 loss 0.19584833085536957
Layer  4  loss:  0.07646294683218002 0.0 7.420255661010742
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([170, 437, 343, 294], device='cuda:0') tensor(437, device='cuda:0')
bi 0 loss 0.02997821569442749
bi 1 loss 0.098752461373806
bi 2 loss 0.05920422822237015
bi 3 loss 0.09001410007476807
Layer  5  loss:  0.0953594297170639 0.0 13.937562942504883
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([222, 436, 343, 292], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.05718468129634857
bi 1 loss 0.12569907307624817
bi 2 loss 0.06052706390619278
bi 3 loss 0.1015499085187912
Layer  6  loss:  0.09259364753961563 0.0 12.626246452331543
logits torch.Size([471, 4, 1024]) labels torch.Size([471, 4]) 0 1023
Curr loss timestep torch.Size([471, 4]) tensor([213, 353, 209, 292], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.028076360002160072
bi 1 loss 0.14582884311676025
bi 2 loss 0.04056479409337044
bi 3 loss 0.06690351665019989
Epoch 0: :   3%|▎         | 15953/600000 [06:37<4:02:35, v_num=12, reduced_train_loss=0.622, global_step=1.6e+4, consumed_samples=63808.0, train_step_timing in s=0.432]Epoch 0: :   3%|▎         | 15953/600000 [06:37<4:02:35, v_num=12, reduced_train_loss=0.734, global_step=1.6e+4, consumed_samples=63812.0, train_step_timing in s=0.335]loss mask original None

First layer loss:  0.05767405405640602 torch.Size([563, 4]) 8.171470642089844 0.0
Max loss timestep torch.Size([563, 4]) tensor([107,  73, 390, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.039265427738428116
speech mask sum tensor(143, device='cuda:0') loss mask sum tensor(143, device='cuda:0')
bi 1 loss 0.031220417469739914
speech mask sum tensor(67, device='cuda:0') loss mask sum tensor(67, device='cuda:0')
bi 2 loss 0.032877735793590546
speech mask sum tensor(241, device='cuda:0') loss mask sum tensor(241, device='cuda:0')
bi 3 loss 0.08293133974075317
speech mask sum tensor(411, device='cuda:0') loss mask sum tensor(411, device='cuda:0')
logits torch.Size([563, 4, 257024]) labels torch.Size([563, 4]) 0 257022
Layer  0  loss:  0.060082677751779556 0.0 6.845517158508301
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([ 86,  84, 312, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.042844586074352264
bi 1 loss 0.02133891172707081
bi 2 loss 0.0347861684858799
bi 3 loss 0.08722947537899017
Layer  1  loss:  0.059846311807632446 0.0 5.2242279052734375
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([ 99,  82, 188, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.03306632116436958
bi 1 loss 0.028375782072544098
bi 2 loss 0.038332149386405945
bi 3 loss 0.08690951764583588
Layer  2  loss:  0.08260573446750641 0.0 17.936668395996094
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([ 94,  81, 299, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.04082983359694481
bi 1 loss 0.029041485860943794
bi 2 loss 0.05260617285966873
bi 3 loss 0.12346377968788147
Layer  3  loss:  0.0662248432636261 0.0 14.139750480651855
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1020
Curr loss timestep torch.Size([563, 4]) tensor([140,  54, 269, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.035614434629678726
bi 1 loss 0.025374671444296837
bi 2 loss 0.04075532406568527
bi 3 loss 0.09846914559602737
Layer  4  loss:  0.06492257863283157 0.0 7.008526802062988
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([ 74,  47, 375, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.03936818987131119
bi 1 loss 0.010960130952298641
bi 2 loss 0.026646489277482033
bi 3 loss 0.10505469143390656
Layer  5  loss:  0.055024415254592896 0.0 7.832489013671875
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1022
Curr loss timestep torch.Size([563, 4]) tensor([133,  79, 297, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.031352605670690536
bi 1 loss 0.016453105956315994
bi 2 loss 0.03658153861761093
bi 3 loss 0.08036280423402786
Layer  6  loss:  0.06295141577720642 0.0 12.594133377075195
logits torch.Size([563, 4, 1024]) labels torch.Size([563, 4]) 0 1023
Curr loss timestep torch.Size([563, 4]) tensor([ 89,  52, 187, 519], device='cuda:0') tensor(519, device='cuda:0')
bi 0 loss 0.0421740785241127
bi 1 loss 0.024832285940647125
bi 2 loss 0.04012400284409523
bi 3 loss 0.08978000283241272
Epoch 0: :   3%|▎         | 15954/600000 [06:38<4:02:50, v_num=12, reduced_train_loss=0.734, global_step=1.6e+4, consumed_samples=63812.0, train_step_timing in s=0.335]Epoch 0: :   3%|▎         | 15954/600000 [06:38<4:02:50, v_num=12, reduced_train_loss=0.509, global_step=1.6e+4, consumed_samples=63816.0, train_step_timing in s=0.390]loss mask original None

First layer loss:  0.12288818508386612 torch.Size([603, 4]) 14.170661926269531 0.0
Max loss timestep torch.Size([603, 4]) tensor([ 91, 122, 542, 230], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.10354290157556534
speech mask sum tensor(88, device='cuda:0') loss mask sum tensor(88, device='cuda:0')
bi 1 loss 0.06449835002422333
speech mask sum tensor(208, device='cuda:0') loss mask sum tensor(208, device='cuda:0')
bi 2 loss 0.2566382884979248
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 3 loss 0.03208150714635849
speech mask sum tensor(310, device='cuda:0') loss mask sum tensor(310, device='cuda:0')
logits torch.Size([603, 4, 257024]) labels torch.Size([603, 4]) 0 257022
Layer  0  loss:  0.13408778607845306 0.0 12.564003944396973
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([ 79, 177, 396, 230], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.054687533527612686
bi 1 loss 0.056899409741163254
bi 2 loss 0.2894808053970337
bi 3 loss 0.051020026206970215
Layer  1  loss:  0.13737833499908447 0.0 10.943282127380371
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([100, 132, 542, 225], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.04937253147363663
bi 1 loss 0.05023077502846718
bi 2 loss 0.3039122521877289
bi 3 loss 0.05215107649564743
Layer  2  loss:  0.14605818688869476 0.0 14.875033378601074
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([ 82, 122, 396, 129], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.03249072656035423
bi 1 loss 0.06458263099193573
bi 2 loss 0.3368576765060425
bi 3 loss 0.03970276564359665
Layer  3  loss:  0.13588865101337433 0.0 14.138287544250488
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([120, 296, 395, 141], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.03014490194618702
bi 1 loss 0.08945126086473465
bi 2 loss 0.2716887295246124
bi 3 loss 0.059511903673410416
Layer  4  loss:  0.13614223897457123 0.0 13.660501480102539
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1023
Curr loss timestep torch.Size([603, 4]) tensor([113, 157, 395, 287], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.06482405215501785
bi 1 loss 0.06276506185531616
bi 2 loss 0.2975735366344452
bi 3 loss 0.04210682213306427
Layer  5  loss:  0.16741429269313812 0.0 18.118621826171875
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([109, 259, 395, 255], device='cuda:0') tensor(395, device='cuda:0')
bi 0 loss 0.05839842930436134
bi 1 loss 0.05043013393878937
bi 2 loss 0.4017026126384735
bi 3 loss 0.039541907608509064
Layer  6  loss:  0.15814372897148132 0.0 14.656675338745117
logits torch.Size([603, 4, 1024]) labels torch.Size([603, 4]) 0 1022
Curr loss timestep torch.Size([603, 4]) tensor([119, 296, 396,  82], device='cuda:0') tensor(396, device='cuda:0')
bi 0 loss 0.043094512075185776
bi 1 loss 0.05948076397180557
bi 2 loss 0.3542727828025818
bi 3 loss 0.0583428293466568
Epoch 0: :   3%|▎         | 15955/600000 [06:38<4:03:06, v_num=12, reduced_train_loss=0.509, global_step=1.6e+4, consumed_samples=63816.0, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15955/600000 [06:38<4:03:06, v_num=12, reduced_train_loss=1.140, global_step=1.6e+4, consumed_samples=63820.0, train_step_timing in s=0.413]loss mask original None

First layer loss:  0.12138468772172928 torch.Size([725, 4]) 8.909449577331543 0.0
Max loss timestep torch.Size([725, 4]) tensor([140, 302, 645, 279], device='cuda:0') tensor(645, device='cuda:0')
bi 0 loss 0.021536318585276604
speech mask sum tensor(100, device='cuda:0') loss mask sum tensor(100, device='cuda:0')
bi 1 loss 0.04511091113090515
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 2 loss 0.169974684715271
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
bi 3 loss 0.125220388174057
speech mask sum tensor(322, device='cuda:0') loss mask sum tensor(322, device='cuda:0')
logits torch.Size([725, 4, 257024]) labels torch.Size([725, 4]) 0 257023
Layer  0  loss:  0.22498531639575958 0.0 15.920660972595215
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1023
Curr loss timestep torch.Size([725, 4]) tensor([161, 303, 646, 273], device='cuda:0') tensor(646, device='cuda:0')
bi 0 loss 0.033085837960243225
bi 1 loss 0.07723744213581085
bi 2 loss 0.36447909474372864
bi 3 loss 0.17826028168201447
Layer  1  loss:  0.1885836124420166 0.0 14.000250816345215
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1023
Curr loss timestep torch.Size([725, 4]) tensor([135, 260, 632, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.027344074100255966
bi 1 loss 0.06256340444087982
bi 2 loss 0.293378621339798
bi 3 loss 0.1647564321756363
Layer  2  loss:  0.22677956521511078 0.0 16.79555892944336
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1022
Curr loss timestep torch.Size([725, 4]) tensor([172, 259, 646, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.02145930379629135
bi 1 loss 0.06353916972875595
bi 2 loss 0.39705920219421387
bi 3 loss 0.15395426750183105
Layer  3  loss:  0.22745564579963684 0.0 14.938824653625488
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1022
Curr loss timestep torch.Size([725, 4]) tensor([167, 228, 645, 272], device='cuda:0') tensor(645, device='cuda:0')
bi 0 loss 0.029196610674262047
bi 1 loss 0.05759967863559723
bi 2 loss 0.4099171459674835
bi 3 loss 0.14065325260162354
Layer  4  loss:  0.20628663897514343 0.0 17.902185440063477
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1023
Curr loss timestep torch.Size([725, 4]) tensor([165, 276, 639, 272], device='cuda:0') tensor(639, device='cuda:0')
bi 0 loss 0.01218055933713913
bi 1 loss 0.05217471718788147
bi 2 loss 0.3640262186527252
bi 3 loss 0.14118775725364685
Layer  5  loss:  0.25265705585479736 0.0 14.5741548538208
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1023
Curr loss timestep torch.Size([725, 4]) tensor([168, 295, 645, 272], device='cuda:0') tensor(645, device='cuda:0')
bi 0 loss 0.019258815795183182
bi 1 loss 0.06913759559392929
bi 2 loss 0.43297094106674194
bi 3 loss 0.18474005162715912
Layer  6  loss:  0.19621337950229645 0.0 10.415061950683594
logits torch.Size([725, 4, 1024]) labels torch.Size([725, 4]) 0 1019
Curr loss timestep torch.Size([725, 4]) tensor([187, 278, 637, 272], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.03459913656115532
bi 1 loss 0.07642911374568939
bi 2 loss 0.3132041096687317
bi 3 loss 0.15559333562850952
Epoch 0: :   3%|▎         | 15956/600000 [06:38<4:03:24, v_num=12, reduced_train_loss=1.140, global_step=1.6e+4, consumed_samples=63820.0, train_step_timing in s=0.413]Epoch 0: :   3%|▎         | 15956/600000 [06:39<4:03:24, v_num=12, reduced_train_loss=1.640, global_step=1.6e+4, consumed_samples=63824.0, train_step_timing in s=0.500]loss mask original None

First layer loss:  0.039890967309474945 torch.Size([395, 4]) 3.3290822505950928 0.0
Max loss timestep torch.Size([395, 4]) tensor([116,  67,  71, 117], device='cuda:0') tensor(71, device='cuda:0')
bi 0 loss 0.01998584158718586
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 1 loss 0.017225231975317
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
bi 2 loss 0.05365607887506485
speech mask sum tensor(344, device='cuda:0') loss mask sum tensor(344, device='cuda:0')
bi 3 loss 0.021222157403826714
speech mask sum tensor(32, device='cuda:0') loss mask sum tensor(32, device='cuda:0')
logits torch.Size([395, 4, 257024]) labels torch.Size([395, 4]) 0 257022
Layer  0  loss:  0.04911331087350845 0.0 4.7375288009643555
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1023
Curr loss timestep torch.Size([395, 4]) tensor([181,  52,  72, 120], device='cuda:0') tensor(72, device='cuda:0')
bi 0 loss 0.03204357624053955
bi 1 loss 0.02979492023587227
bi 2 loss 0.06087670102715492
bi 3 loss 0.03330657631158829
Layer  1  loss:  0.03057939000427723 0.0 1.2436398267745972
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1022
Curr loss timestep torch.Size([395, 4]) tensor([195,  65, 313, 123], device='cuda:0') tensor(313, device='cuda:0')
bi 0 loss 0.021000893786549568
bi 1 loss 0.026581931859254837
bi 2 loss 0.03512357175350189
bi 3 loss 0.030133578926324844
Layer  2  loss:  0.028174011036753654 0.0 0.5877262353897095
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1022
Curr loss timestep torch.Size([395, 4]) tensor([186,  46, 259, 111], device='cuda:0') tensor(186, device='cuda:0')
bi 0 loss 0.034302860498428345
bi 1 loss 0.02357475645840168
bi 2 loss 0.026717066764831543
bi 3 loss 0.027178578078746796
Layer  3  loss:  0.0322556234896183 0.0 0.7486112713813782
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1022
Curr loss timestep torch.Size([395, 4]) tensor([198,  47, 232, 117], device='cuda:0') tensor(232, device='cuda:0')
bi 0 loss 0.021709470078349113
bi 1 loss 0.015082994475960732
bi 2 loss 0.03937624767422676
bi 3 loss 0.03454577177762985
Layer  4  loss:  0.03443051874637604 0.0 1.2655770778656006
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1022
Curr loss timestep torch.Size([395, 4]) tensor([127,  45, 192, 109], device='cuda:0') tensor(192, device='cuda:0')
bi 0 loss 0.024936359375715256
bi 1 loss 0.017606649547815323
bi 2 loss 0.04186548292636871
bi 3 loss 0.02820581942796707
Layer  5  loss:  0.03413901850581169 0.0 1.8518755435943604
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1017
Curr loss timestep torch.Size([395, 4]) tensor([206,  44,  76, 113], device='cuda:0') tensor(76, device='cuda:0')
bi 0 loss 0.024933338165283203
bi 1 loss 0.020931439474225044
bi 2 loss 0.03878677636384964
bi 3 loss 0.04942725598812103
Layer  6  loss:  0.02876441366970539 0.0 1.0425255298614502
logits torch.Size([395, 4, 1024]) labels torch.Size([395, 4]) 0 1019
Curr loss timestep torch.Size([395, 4]) tensor([185,  47,  75, 116], device='cuda:0') tensor(75, device='cuda:0')
bi 0 loss 0.016453323885798454
bi 1 loss 0.01696566492319107
bi 2 loss 0.036640483886003494
bi 3 loss 0.019631586968898773
Epoch 0: :   3%|▎         | 15957/600000 [06:39<4:03:36, v_num=12, reduced_train_loss=1.640, global_step=1.6e+4, consumed_samples=63824.0, train_step_timing in s=0.500]Epoch 0: :   3%|▎         | 15957/600000 [06:39<4:03:36, v_num=12, reduced_train_loss=0.277, global_step=1.6e+4, consumed_samples=63828.0, train_step_timing in s=0.298]loss mask original None

First layer loss:  0.09184359014034271 torch.Size([594, 4]) 8.034504890441895 0.0
Max loss timestep torch.Size([594, 4]) tensor([188, 115,  58, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.009922252036631107
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 1 loss 0.03469553962349892
speech mask sum tensor(131, device='cuda:0') loss mask sum tensor(131, device='cuda:0')
bi 2 loss 0.0966334193944931
speech mask sum tensor(105, device='cuda:0') loss mask sum tensor(105, device='cuda:0')
bi 3 loss 0.12399082630872726
speech mask sum tensor(495, device='cuda:0') loss mask sum tensor(495, device='cuda:0')
logits torch.Size([594, 4, 257024]) labels torch.Size([594, 4]) 0 257023
Layer  0  loss:  0.08190003037452698 0.0 13.003398895263672
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([175,  92, 120, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.02174570970237255
bi 1 loss 0.02414584346115589
bi 2 loss 0.058983031660318375
bi 3 loss 0.11529175937175751
Layer  1  loss:  0.08325453847646713 0.0 16.392574310302734
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([245,  40, 132, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.006858016364276409
bi 1 loss 0.03126692771911621
bi 2 loss 0.022109631448984146
bi 3 loss 0.12680567800998688
Layer  2  loss:  0.08450397849082947 0.0 8.317301750183105
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1022
Curr loss timestep torch.Size([594, 4]) tensor([177, 117, 100, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.005335458554327488
bi 1 loss 0.054530851542949677
bi 2 loss 0.034727778285741806
bi 3 loss 0.1204279288649559
Layer  3  loss:  0.09664073586463928 0.0 11.260820388793945
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1019
Curr loss timestep torch.Size([594, 4]) tensor([232,  62, 102, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.01940843090415001
bi 1 loss 0.031319133937358856
bi 2 loss 0.03857681155204773
bi 3 loss 0.14325116574764252
Layer  4  loss:  0.07942522317171097 0.0 9.125819206237793
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([178,  74,  68, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.013854194432497025
bi 1 loss 0.0340605303645134
bi 2 loss 0.04259482026100159
bi 3 loss 0.11368221044540405
Layer  5  loss:  0.0936400443315506 0.0 16.70643424987793
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1022
Curr loss timestep torch.Size([594, 4]) tensor([237,  70,  69, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.03428487479686737
bi 1 loss 0.03606359288096428
bi 2 loss 0.03498391807079315
bi 3 loss 0.13438980281352997
Layer  6  loss:  0.08969252556562424 0.0 11.396580696105957
logits torch.Size([594, 4, 1024]) labels torch.Size([594, 4]) 0 1023
Curr loss timestep torch.Size([594, 4]) tensor([237, 111, 117, 531], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.018885528668761253
bi 1 loss 0.026258759200572968
bi 2 loss 0.04980979114770889
bi 3 loss 0.13053186237812042
Epoch 0: :   3%|▎         | 15958/600000 [06:39<4:03:51, v_num=12, reduced_train_loss=0.277, global_step=1.6e+4, consumed_samples=63828.0, train_step_timing in s=0.298]Epoch 0: :   3%|▎         | 15958/600000 [06:39<4:03:51, v_num=12, reduced_train_loss=0.701, global_step=1.6e+4, consumed_samples=63832.0, train_step_timing in s=0.412]loss mask original None

First layer loss:  0.07752175629138947 torch.Size([511, 4]) 14.01306438446045 0.0
Max loss timestep torch.Size([511, 4]) tensor([325, 178, 142, 143], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.15064874291419983
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 1 loss 0.030152682214975357
speech mask sum tensor(128, device='cuda:0') loss mask sum tensor(128, device='cuda:0')
bi 2 loss 0.03239358961582184
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 3 loss 0.02402508817613125
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
logits torch.Size([511, 4, 257024]) labels torch.Size([511, 4]) 0 257022
Layer  0  loss:  0.052342042326927185 0.0 10.503966331481934
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1023
Curr loss timestep torch.Size([511, 4]) tensor([324, 110, 171, 221], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.09233534336090088
bi 1 loss 0.022669099271297455
bi 2 loss 0.03090662509202957
bi 3 loss 0.02330256626009941
Layer  1  loss:  0.08649086952209473 0.0 13.472289085388184
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1023
Curr loss timestep torch.Size([511, 4]) tensor([325, 106, 161, 107], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.16838666796684265
bi 1 loss 0.03947359323501587
bi 2 loss 0.03011331893503666
bi 3 loss 0.026658708229660988
Layer  2  loss:  0.06493233889341354 0.0 8.361170768737793
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1022
Curr loss timestep torch.Size([511, 4]) tensor([325, 174,  98, 124], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.11561771482229233
bi 1 loss 0.03952080011367798
bi 2 loss 0.030872270464897156
bi 3 loss 0.025009436532855034
Layer  3  loss:  0.0862714871764183 0.0 18.200336456298828
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1022
Curr loss timestep torch.Size([511, 4]) tensor([325, 163, 151, 249], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.1691172868013382
bi 1 loss 0.02518141083419323
bi 2 loss 0.029000066220760345
bi 3 loss 0.034477364271879196
Layer  4  loss:  0.07124549895524979 0.0 10.785229682922363
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1022
Curr loss timestep torch.Size([511, 4]) tensor([324, 139, 144, 248], device='cuda:0') tensor(324, device='cuda:0')
bi 0 loss 0.1396542489528656
bi 1 loss 0.025493986904621124
bi 2 loss 0.02079154923558235
bi 3 loss 0.027617421001195908
Layer  5  loss:  0.08149503916501999 0.0 17.482372283935547
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1023
Curr loss timestep torch.Size([511, 4]) tensor([325, 141, 155, 173], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.1593099981546402
bi 1 loss 0.028150510042905807
bi 2 loss 0.026206811890006065
bi 3 loss 0.03128770366311073
Layer  6  loss:  0.06930830329656601 0.0 18.088911056518555
logits torch.Size([511, 4, 1024]) labels torch.Size([511, 4]) 0 1019
Curr loss timestep torch.Size([511, 4]) tensor([325, 143, 158, 121], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.13618387281894684
bi 1 loss 0.0216873399913311
bi 2 loss 0.0209202878177166
bi 3 loss 0.02786739356815815
Epoch 0: :   3%|▎         | 15959/600000 [06:40<4:04:05, v_num=12, reduced_train_loss=0.701, global_step=1.6e+4, consumed_samples=63832.0, train_step_timing in s=0.412]Epoch 0: :   3%|▎         | 15959/600000 [06:40<4:04:05, v_num=12, reduced_train_loss=0.590, global_step=1.6e+4, consumed_samples=63836.0, train_step_timing in s=0.357]loss mask original None

First layer loss:  3.578702688217163 torch.Size([448, 4]) 9.130752563476562 0.0
Max loss timestep torch.Size([448, 4]) tensor([291, 116, 303, 187], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 3.711122751235962
speech mask sum tensor(303, device='cuda:0') loss mask sum tensor(303, device='cuda:0')
bi 1 loss 3.032728672027588
speech mask sum tensor(99, device='cuda:0') loss mask sum tensor(99, device='cuda:0')
bi 2 loss 3.797872304916382
speech mask sum tensor(283, device='cuda:0') loss mask sum tensor(283, device='cuda:0')
bi 3 loss 2.6537630558013916
speech mask sum tensor(52, device='cuda:0') loss mask sum tensor(52, device='cuda:0')
logits torch.Size([448, 4, 257024]) labels torch.Size([448, 4]) 0 257023
Layer  0  loss:  3.912132501602173 0.0 10.030405044555664
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([303, 114, 338, 194], device='cuda:0') tensor(199, device='cuda:0')
bi 0 loss 3.9491608142852783
bi 1 loss 3.8055944442749023
bi 2 loss 4.103044509887695
bi 3 loss 2.860201597213745
Layer  1  loss:  4.272708415985107 0.0 9.437618255615234
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1022
Curr loss timestep torch.Size([448, 4]) tensor([228, 141, 399, 188], device='cuda:0') tensor(195, device='cuda:0')
bi 0 loss 4.407900810241699
bi 1 loss 4.0946149826049805
bi 2 loss 4.4759907722473145
bi 3 loss 2.7176928520202637
Layer  2  loss:  4.518651962280273 0.0 11.122404098510742
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1022
Curr loss timestep torch.Size([448, 4]) tensor([236, 105, 404, 204], device='cuda:0') tensor(177, device='cuda:0')
bi 0 loss 4.653678894042969
bi 1 loss 4.436127662658691
bi 2 loss 4.722428798675537
bi 3 loss 2.779954671859741
Layer  3  loss:  4.6850481033325195 0.0 10.398987770080566
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1022
Curr loss timestep torch.Size([448, 4]) tensor([167, 171, 253, 209], device='cuda:0') tensor(200, device='cuda:0')
bi 0 loss 4.875030040740967
bi 1 loss 4.533153057098389
bi 2 loss 4.8650617599487305
bi 3 loss 2.887535572052002
Layer  4  loss:  4.751697540283203 0.0 9.965394020080566
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1022
Curr loss timestep torch.Size([448, 4]) tensor([153, 169, 216, 206], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 4.8012261390686035
bi 1 loss 4.579117774963379
bi 2 loss 5.114736080169678
bi 3 loss 2.81589412689209
Layer  5  loss:  4.8757853507995605 0.0 10.738407135009766
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([290, 147, 213, 217], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 5.149044990539551
bi 1 loss 4.55325174331665
bi 2 loss 4.991277694702148
bi 3 loss 3.2690329551696777
Layer  6  loss:  4.936548709869385 0.0 10.976971626281738
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1021
Curr loss timestep torch.Size([448, 4]) tensor([323, 151, 359, 200], device='cuda:0') tensor(205, device='cuda:0')
bi 0 loss 5.123993873596191
bi 1 loss 4.932772159576416
bi 2 loss 5.075196266174316
bi 3 loss 3.0969510078430176
Epoch 0: :   3%|▎         | 15960/600000 [06:40<4:04:17, v_num=12, reduced_train_loss=0.590, global_step=1.6e+4, consumed_samples=63836.0, train_step_timing in s=0.357]Epoch 0: :   3%|▎         | 15960/600000 [06:40<4:04:17, v_num=12, reduced_train_loss=35.50, global_step=1.6e+4, consumed_samples=63840.0, train_step_timing in s=0.320]loss mask original None

First layer loss:  0.11142955720424652 torch.Size([622, 4]) 10.29976749420166 0.0
Max loss timestep torch.Size([622, 4]) tensor([116, 179, 578, 135], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.03672856464982033
speech mask sum tensor(181, device='cuda:0') loss mask sum tensor(181, device='cuda:0')
bi 1 loss 0.02477964200079441
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 2 loss 0.2032448649406433
speech mask sum tensor(371, device='cuda:0') loss mask sum tensor(371, device='cuda:0')
bi 3 loss 0.02649841085076332
speech mask sum tensor(97, device='cuda:0') loss mask sum tensor(97, device='cuda:0')
logits torch.Size([622, 4, 257024]) labels torch.Size([622, 4]) 0 257023
Layer  0  loss:  0.12137498706579208 0.0 10.706486701965332
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([165, 166, 586, 122], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.07730972021818161
bi 1 loss 0.0342409573495388
bi 2 loss 0.20171479880809784
bi 3 loss 0.023877860978245735
Layer  1  loss:  0.1295839101076126 0.0 8.538080215454102
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([114, 196, 578, 129], device='cuda:0') tensor(578, device='cuda:0')
bi 0 loss 0.036703236401081085
bi 1 loss 0.0470079705119133
bi 2 loss 0.23445647954940796
bi 3 loss 0.022670989856123924
Layer  2  loss:  0.12148131430149078 0.0 11.906542778015137
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([215, 202, 590, 122], device='cuda:0') tensor(590, device='cuda:0')
bi 0 loss 0.03331722691655159
bi 1 loss 0.042668793350458145
bi 2 loss 0.21421945095062256
bi 3 loss 0.04666930437088013
Layer  3  loss:  0.11202730983495712 0.0 9.553572654724121
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([163, 145, 590, 131], device='cuda:0') tensor(590, device='cuda:0')
bi 0 loss 0.043189529329538345
bi 1 loss 0.03983300179243088
bi 2 loss 0.1959015429019928
bi 3 loss 0.02536633610725403
Layer  4  loss:  0.1267261803150177 0.0 12.759909629821777
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([169, 172, 590, 102], device='cuda:0') tensor(590, device='cuda:0')
bi 0 loss 0.032051391899585724
bi 1 loss 0.028205353766679764
bi 2 loss 0.23552705347537994
bi 3 loss 0.03147846460342407
Layer  5  loss:  0.1547018438577652 0.0 15.460325241088867
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1023
Curr loss timestep torch.Size([622, 4]) tensor([175, 171, 590, 133], device='cuda:0') tensor(590, device='cuda:0')
bi 0 loss 0.038947831839323044
bi 1 loss 0.03661096468567848
bi 2 loss 0.2790117561817169
bi 3 loss 0.06811836361885071
Layer  6  loss:  0.11510175466537476 0.0 8.662505149841309
logits torch.Size([622, 4, 1024]) labels torch.Size([622, 4]) 0 1022
Curr loss timestep torch.Size([622, 4]) tensor([207, 151, 586, 101], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.02570534311234951
bi 1 loss 0.026764241978526115
bi 2 loss 0.21422739326953888
bi 3 loss 0.032102297991514206
Epoch 0: :   3%|▎         | 15961/600000 [06:40<4:04:32, v_num=12, reduced_train_loss=35.50, global_step=1.6e+4, consumed_samples=63840.0, train_step_timing in s=0.320]Epoch 0: :   3%|▎         | 15961/600000 [06:40<4:04:32, v_num=12, reduced_train_loss=0.992, global_step=1.6e+4, consumed_samples=63844.0, train_step_timing in s=0.421]loss mask original None

First layer loss:  3.768179416656494 torch.Size([564, 4]) 14.1135892868042 0.0
Max loss timestep torch.Size([564, 4]) tensor([183,  60, 457, 342], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 3.5912415981292725
speech mask sum tensor(326, device='cuda:0') loss mask sum tensor(326, device='cuda:0')
bi 1 loss 4.093061447143555
speech mask sum tensor(313, device='cuda:0') loss mask sum tensor(313, device='cuda:0')
bi 2 loss 4.202849864959717
speech mask sum tensor(331, device='cuda:0') loss mask sum tensor(331, device='cuda:0')
bi 3 loss 3.370124578475952
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
logits torch.Size([564, 4, 257024]) labels torch.Size([564, 4]) 0 257022
Layer  0  loss:  4.424070358276367 0.0 13.129499435424805
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([332, 232, 474, 321], device='cuda:0') tensor(334, device='cuda:0')
bi 0 loss 4.518738269805908
bi 1 loss 4.663066387176514
bi 2 loss 4.726410388946533
bi 3 loss 3.9881772994995117
Layer  1  loss:  4.74050760269165 0.0 12.9115571975708
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([227, 236, 423, 278], device='cuda:0') tensor(294, device='cuda:0')
bi 0 loss 4.651782989501953
bi 1 loss 5.005275726318359
bi 2 loss 5.135241985321045
bi 3 loss 4.34939432144165
Layer  2  loss:  4.9483795166015625 0.0 11.400802612304688
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([222, 111, 265, 148], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 4.891244888305664
bi 1 loss 5.133492469787598
bi 2 loss 5.375554084777832
bi 3 loss 4.56552267074585
Layer  3  loss:  5.086878776550293 0.0 10.659858703613281
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1022
Curr loss timestep torch.Size([564, 4]) tensor([112, 111, 284, 324], device='cuda:0') tensor(291, device='cuda:0')
bi 0 loss 5.232558727264404
bi 1 loss 5.378929138183594
bi 2 loss 5.292952537536621
bi 3 loss 4.6480793952941895
Layer  4  loss:  5.174627304077148 0.0 10.808760643005371
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([330, 252, 409, 295], device='cuda:0') tensor(347, device='cuda:0')
bi 0 loss 5.3160881996154785
bi 1 loss 5.398970603942871
bi 2 loss 5.423861980438232
bi 3 loss 4.753371715545654
Layer  5  loss:  5.297041416168213 0.0 10.35638427734375
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1023
Curr loss timestep torch.Size([564, 4]) tensor([114,  76, 457, 268], device='cuda:0') tensor(320, device='cuda:0')
bi 0 loss 5.461925029754639
bi 1 loss 5.530297756195068
bi 2 loss 5.478459358215332
bi 3 loss 4.9012556076049805
Layer  6  loss:  5.338064193725586 0.0 10.32105541229248
logits torch.Size([564, 4, 1024]) labels torch.Size([564, 4]) 0 1020
Curr loss timestep torch.Size([564, 4]) tensor([ 74, 318, 513, 100], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 5.58946418762207
bi 1 loss 5.470038414001465
bi 2 loss 5.604928970336914
bi 3 loss 4.889767169952393
Epoch 0: :   3%|▎         | 15962/600000 [06:41<4:04:46, v_num=12, reduced_train_loss=0.992, global_step=1.6e+4, consumed_samples=63844.0, train_step_timing in s=0.421]Epoch 0: :   3%|▎         | 15962/600000 [06:41<4:04:46, v_num=12, reduced_train_loss=38.80, global_step=1.6e+4, consumed_samples=63848.0, train_step_timing in s=0.364]loss mask original None

First layer loss:  0.01903531700372696 torch.Size([335, 4]) 0.3720552623271942 0.0
Max loss timestep torch.Size([335, 4]) tensor([ 95, 128, 127, 260], device='cuda:0') tensor(260, device='cuda:0')
bi 0 loss 0.022212093695998192
speech mask sum tensor(87, device='cuda:0') loss mask sum tensor(87, device='cuda:0')
bi 1 loss 0.017797080799937248
speech mask sum tensor(89, device='cuda:0') loss mask sum tensor(89, device='cuda:0')
bi 2 loss 0.016763264313340187
speech mask sum tensor(254, device='cuda:0') loss mask sum tensor(254, device='cuda:0')
bi 3 loss 0.021811839193105698
speech mask sum tensor(148, device='cuda:0') loss mask sum tensor(148, device='cuda:0')
logits torch.Size([335, 4, 257024]) labels torch.Size([335, 4]) 0 257021
Layer  0  loss:  0.02018030732870102 0.0 0.4939362108707428
logits torch.Size([335, 4, 1024]) labels torch.Size([335, 4]) 0 1023
Curr loss timestep torch.Size([335, 4]) tensor([ 55, 140, 268, 225], device='cuda:0') tensor(268, device='cuda:0')
bi 0 loss 0.01852545514702797
bi 1 loss 0.02168775349855423
bi 2 loss 0.021015603095293045
bi 3 loss 0.018813038244843483
Layer  1  loss:  0.020107900723814964 0.0 0.4219008982181549
logits torch.Size([335, 4, 1024]) labels torch.Size([335, 4]) 0 1022
Curr loss timestep torch.Size([335, 4]) tensor([ 70, 159, 236, 192], device='cuda:0') tensor(236, device='cuda:0')
bi 0 loss 0.016117479652166367
bi 1 loss 0.0154918497428298
bi 2 loss 0.019821563735604286
bi 3 loss 0.025720909237861633
Layer  2  loss:  0.02057839184999466 0.0 0.6211132407188416
logits torch.Size([335, 4, 1024]) labels torch.Size([335, 4]) 0 1022
Curr loss timestep torch.Size([335, 4]) tensor([ 83, 155, 259, 259], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.00981676485389471
bi 1 loss 0.019182460382580757
bi 2 loss 0.024639446288347244
bi 3 loss 0.020774276927113533
Layer  3  loss:  0.01965014636516571 0.0 0.6226929426193237
logits torch.Size([335, 4, 1024]) labels torch.Size([335, 4]) 0 1023
Curr loss timestep torch.Size([335, 4]) tensor([ 70, 187, 148, 288], device='cuda:0') tensor(288, device='cuda:0')
bi 0 loss 0.01636301726102829
bi 1 loss 0.02171315625309944
bi 2 loss 0.017804119735956192
bi 3 loss 0.023510023951530457
Layer  4  loss:  0.020412106066942215 0.0 0.4426981210708618
logits torch.Size([335, 4, 1024]) labels torch.Size([335, 4]) 0 1022
Curr loss timestep torch.Size([335, 4]) tensor([ 59, 164,  92, 242], device='cuda:0') tensor(242, device='cuda:0')
bi 0 loss 0.015118267387151718
bi 1 loss 0.01291495468467474
bi 2 loss 0.021707940846681595
bi 3 loss 0.025808513164520264
Layer  5  loss:  0.01763126067817211 0.0 0.40929099917411804
logits torch.Size([335, 4, 1024]) labels torch.Size([335, 4]) 0 1021
Curr loss timestep torch.Size([335, 4]) tensor([ 98, 127, 241, 225], device='cuda:0') tensor(98, device='cuda:0')
bi 0 loss 0.020735349506139755
bi 1 loss 0.017218926921486855
bi 2 loss 0.015788305550813675
bi 3 loss 0.019217420369386673
Layer  6  loss:  0.01848728023469448 0.0 0.28216785192489624
logits torch.Size([335, 4, 1024]) labels torch.Size([335, 4]) 0 1020
Curr loss timestep torch.Size([335, 4]) tensor([ 79, 185, 280, 269], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.019504912197589874
bi 1 loss 0.01457291655242443
bi 2 loss 0.018843932077288628
bi 3 loss 0.019630882889032364
Epoch 0: :   3%|▎         | 15963/600000 [06:41<4:04:57, v_num=12, reduced_train_loss=38.80, global_step=1.6e+4, consumed_samples=63848.0, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15963/600000 [06:41<4:04:57, v_num=12, reduced_train_loss=0.156, global_step=1.6e+4, consumed_samples=63852.0, train_step_timing in s=0.274]loss mask original None

First layer loss:  3.6187002658843994 torch.Size([472, 4]) 13.192362785339355 0.0
Max loss timestep torch.Size([472, 4]) tensor([244, 324, 195, 185], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 3.208383798599243
speech mask sum tensor(47, device='cuda:0') loss mask sum tensor(47, device='cuda:0')
bi 1 loss 3.6621105670928955
speech mask sum tensor(255, device='cuda:0') loss mask sum tensor(255, device='cuda:0')
bi 2 loss 3.267651081085205
speech mask sum tensor(285, device='cuda:0') loss mask sum tensor(285, device='cuda:0')
bi 3 loss 4.027244567871094
speech mask sum tensor(265, device='cuda:0') loss mask sum tensor(265, device='cuda:0')
logits torch.Size([472, 4, 257024]) labels torch.Size([472, 4]) 0 257022
Layer  0  loss:  4.203458309173584 0.0 10.299251556396484
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([254, 434, 308, 157], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 3.6480712890625
bi 1 loss 4.024416923522949
bi 2 loss 4.317663669586182
bi 3 loss 4.351421356201172
Layer  1  loss:  4.613065719604492 0.0 11.773630142211914
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([250, 359, 306, 261], device='cuda:0') tensor(261, device='cuda:0')
bi 0 loss 4.2757110595703125
bi 1 loss 4.414496421813965
bi 2 loss 4.739767551422119
bi 3 loss 4.727711200714111
Layer  2  loss:  4.935421943664551 0.0 11.007326126098633
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1023
Curr loss timestep torch.Size([472, 4]) tensor([251, 464, 197, 193], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 4.9361162185668945
bi 1 loss 4.900189399719238
bi 2 loss 4.883670806884766
bi 3 loss 5.0248589515686035
Layer  3  loss:  4.971465110778809 0.0 10.525663375854492
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([253, 410, 338, 220], device='cuda:0') tensor(254, device='cuda:0')
bi 0 loss 4.573184013366699
bi 1 loss 4.886019706726074
bi 2 loss 5.029926300048828
bi 3 loss 5.061451435089111
Layer  4  loss:  5.099353790283203 0.0 11.094831466674805
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1022
Curr loss timestep torch.Size([472, 4]) tensor([266, 329, 334, 334], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 4.6077094078063965
bi 1 loss 5.083625316619873
bi 2 loss 5.151962757110596
bi 3 loss 5.145106315612793
Layer  5  loss:  5.210058212280273 0.0 10.744503021240234
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1020
Curr loss timestep torch.Size([472, 4]) tensor([269, 415, 212, 228], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 4.619665145874023
bi 1 loss 5.278324127197266
bi 2 loss 5.203827381134033
bi 3 loss 5.255781173706055
Layer  6  loss:  5.23374080657959 0.0 9.806611061096191
logits torch.Size([472, 4, 1024]) labels torch.Size([472, 4]) 0 1021
Curr loss timestep torch.Size([472, 4]) tensor([256, 356, 415, 343], device='cuda:0') tensor(279, device='cuda:0')
bi 0 loss 4.564390182495117
bi 1 loss 5.279381275177002
bi 2 loss 5.286718845367432
bi 3 loss 5.251560688018799
Epoch 0: :   3%|▎         | 15964/600000 [06:42<4:05:09, v_num=12, reduced_train_loss=0.156, global_step=1.6e+4, consumed_samples=63852.0, train_step_timing in s=0.274]Epoch 0: :   3%|▎         | 15964/600000 [06:42<4:05:09, v_num=12, reduced_train_loss=37.90, global_step=1.6e+4, consumed_samples=63856.0, train_step_timing in s=0.323]loss mask original None

First layer loss:  0.15864473581314087 torch.Size([719, 4]) 11.360629081726074 0.0
Max loss timestep torch.Size([719, 4]) tensor([371, 333, 295,  99], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.03520141541957855
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 1 loss 0.2394411712884903
speech mask sum tensor(493, device='cuda:0') loss mask sum tensor(493, device='cuda:0')
bi 2 loss 0.1330944150686264
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 3 loss 0.02270282804965973
speech mask sum tensor(121, device='cuda:0') loss mask sum tensor(121, device='cuda:0')
logits torch.Size([719, 4, 257024]) labels torch.Size([719, 4]) 0 257023
Layer  0  loss:  0.18057246506214142 0.0 8.914584159851074
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([384, 549, 294, 112], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.15128016471862793
bi 1 loss 0.2577294707298279
bi 2 loss 0.08911004662513733
bi 3 loss 0.03628068044781685
Layer  1  loss:  0.20148950815200806 0.0 12.330409049987793
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([415, 477, 294,  61], device='cuda:0') tensor(477, device='cuda:0')
bi 0 loss 0.11282911896705627
bi 1 loss 0.29628488421440125
bi 2 loss 0.13468396663665771
bi 3 loss 0.024536600336432457
Layer  2  loss:  0.267611563205719 0.0 8.939173698425293
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1022
Curr loss timestep torch.Size([719, 4]) tensor([383, 321, 294, 119], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.13425326347351074
bi 1 loss 0.4214402139186859
bi 2 loss 0.09267901629209518
bi 3 loss 0.06392916291952133
Layer  3  loss:  0.23207689821720123 0.0 11.585392951965332
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([384, 477, 294,  96], device='cuda:0') tensor(477, device='cuda:0')
bi 0 loss 0.11974763870239258
bi 1 loss 0.36082035303115845
bi 2 loss 0.11023228615522385
bi 3 loss 0.026791900396347046
Layer  4  loss:  0.2147635519504547 0.0 7.690122127532959
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1023
Curr loss timestep torch.Size([719, 4]) tensor([384, 706, 294,  40], device='cuda:0') tensor(384, device='cuda:0')
bi 0 loss 0.17589594423770905
bi 1 loss 0.29497814178466797
bi 2 loss 0.15078496932983398
bi 3 loss 0.0301453098654747
Layer  5  loss:  0.25169533491134644 0.0 9.408428192138672
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1019
Curr loss timestep torch.Size([719, 4]) tensor([384, 372, 294,  41], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.16481098532676697
bi 1 loss 0.3849867284297943
bi 2 loss 0.10679668933153152
bi 3 loss 0.02923920936882496
Layer  6  loss:  0.25726211071014404 0.0 10.93843936920166
logits torch.Size([719, 4, 1024]) labels torch.Size([719, 4]) 0 1022
Curr loss timestep torch.Size([719, 4]) tensor([384, 321, 294,  40], device='cuda:0') tensor(321, device='cuda:0')
bi 0 loss 0.10331469029188156
bi 1 loss 0.4073295593261719
bi 2 loss 0.11319572478532791
bi 3 loss 0.05004214495420456
Epoch 0: :   3%|▎         | 15965/600000 [06:42<4:05:27, v_num=12, reduced_train_loss=37.90, global_step=1.6e+4, consumed_samples=63856.0, train_step_timing in s=0.323]Epoch 0: :   3%|▎         | 15965/600000 [06:42<4:05:27, v_num=12, reduced_train_loss=1.760, global_step=1.6e+4, consumed_samples=63860.0, train_step_timing in s=0.488]loss mask original None

First layer loss:  3.7487168312072754 torch.Size([628, 4]) 11.462132453918457 0.0
Max loss timestep torch.Size([628, 4]) tensor([185,  93,  79,  75], device='cuda:0') tensor(252, device='cuda:0')
bi 0 loss 3.9795548915863037
speech mask sum tensor(472, device='cuda:0') loss mask sum tensor(472, device='cuda:0')
bi 1 loss 3.4779772758483887
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 2 loss 3.758476972579956
speech mask sum tensor(217, device='cuda:0') loss mask sum tensor(217, device='cuda:0')
bi 3 loss 2.9660136699676514
speech mask sum tensor(71, device='cuda:0') loss mask sum tensor(71, device='cuda:0')
logits torch.Size([628, 4, 257024]) labels torch.Size([628, 4]) 0 257022
Layer  0  loss:  4.424940586090088 0.0 9.752559661865234
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([253, 111, 122,  79], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 4.944207668304443
bi 1 loss 4.24097204208374
bi 2 loss 3.841796398162842
bi 3 loss 3.2863752841949463
Layer  1  loss:  4.5985636711120605 0.0 10.122292518615723
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1022
Curr loss timestep torch.Size([628, 4]) tensor([445, 124, 245,  80], device='cuda:0') tensor(244, device='cuda:0')
bi 0 loss 4.911588191986084
bi 1 loss 4.468117713928223
bi 2 loss 4.3160481452941895
bi 3 loss 3.7577149868011475
Layer  2  loss:  4.902143478393555 0.0 10.95649528503418
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1022
Curr loss timestep torch.Size([628, 4]) tensor([320, 119,  89,  93], device='cuda:0') tensor(202, device='cuda:0')
bi 0 loss 5.097019195556641
bi 1 loss 4.878480911254883
bi 2 loss 4.776845932006836
bi 3 loss 4.057903289794922
Layer  3  loss:  5.069950103759766 0.0 10.887306213378906
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1019
Curr loss timestep torch.Size([628, 4]) tensor([379, 187, 115, 110], device='cuda:0') tensor(169, device='cuda:0')
bi 0 loss 5.281087875366211
bi 1 loss 5.179356575012207
bi 2 loss 4.830986499786377
bi 3 loss 4.08079195022583
Layer  4  loss:  5.219932556152344 0.0 11.090761184692383
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([220, 217, 143,  76], device='cuda:0') tensor(167, device='cuda:0')
bi 0 loss 5.501832962036133
bi 1 loss 5.194051265716553
bi 2 loss 4.967623710632324
bi 3 loss 4.191757678985596
Layer  5  loss:  5.2359232902526855 0.0 9.70914077758789
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([534, 258, 158,  72], device='cuda:0') tensor(190, device='cuda:0')
bi 0 loss 5.5044450759887695
bi 1 loss 5.210139751434326
bi 2 loss 4.974800109863281
bi 3 loss 4.323347091674805
Layer  6  loss:  5.281482696533203 0.0 10.92285442352295
logits torch.Size([628, 4, 1024]) labels torch.Size([628, 4]) 0 1023
Curr loss timestep torch.Size([628, 4]) tensor([439, 157, 156,  96], device='cuda:0') tensor(267, device='cuda:0')
bi 0 loss 5.5063796043396
bi 1 loss 5.24865198135376
bi 2 loss 5.074725151062012
bi 3 loss 4.513114929199219
Epoch 0: :   3%|▎         | 15966/600000 [06:43<4:05:42, v_num=12, reduced_train_loss=1.760, global_step=1.6e+4, consumed_samples=63860.0, train_step_timing in s=0.488]Epoch 0: :   3%|▎         | 15966/600000 [06:43<4:05:42, v_num=12, reduced_train_loss=38.50, global_step=1.6e+4, consumed_samples=63864.0, train_step_timing in s=0.388]loss mask original None

First layer loss:  0.03500697389245033 torch.Size([423, 4]) 0.7988284230232239 0.0
Max loss timestep torch.Size([423, 4]) tensor([308, 261, 120, 175], device='cuda:0') tensor(266, device='cuda:0')
bi 0 loss 0.05283057317137718
speech mask sum tensor(176, device='cuda:0') loss mask sum tensor(176, device='cuda:0')
bi 1 loss 0.03213999420404434
speech mask sum tensor(373, device='cuda:0') loss mask sum tensor(373, device='cuda:0')
bi 2 loss 0.024717848747968674
speech mask sum tensor(153, device='cuda:0') loss mask sum tensor(153, device='cuda:0')
bi 3 loss 0.022673601284623146
speech mask sum tensor(40, device='cuda:0') loss mask sum tensor(40, device='cuda:0')
logits torch.Size([423, 4, 257024]) labels torch.Size([423, 4]) 0 257023
Layer  0  loss:  0.041070252656936646 0.0 2.734769821166992
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([355, 285, 146, 168], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.066838338971138
bi 1 loss 0.03508869186043739
bi 2 loss 0.02771245501935482
bi 3 loss 0.03456234186887741
Layer  1  loss:  0.054344240576028824 0.0 7.655948638916016
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1019
Curr loss timestep torch.Size([423, 4]) tensor([296, 375, 151, 180], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.1363716572523117
bi 1 loss 0.02946583367884159
bi 2 loss 0.027512753382325172
bi 3 loss 0.028045201674103737
Layer  2  loss:  0.05088646709918976 0.0 6.301342010498047
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([296, 179, 105, 172], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.0858444944024086
bi 1 loss 0.04722991958260536
bi 2 loss 0.0218929685652256
bi 3 loss 0.042068541049957275
Layer  3  loss:  0.04956585168838501 0.0 10.143503189086914
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1017
Curr loss timestep torch.Size([423, 4]) tensor([296, 213, 160, 164], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.11470088362693787
bi 1 loss 0.034381866455078125
bi 2 loss 0.01962871477007866
bi 3 loss 0.019071973860263824
Layer  4  loss:  0.04392130300402641 0.0 5.820648670196533
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1023
Curr loss timestep torch.Size([423, 4]) tensor([296, 413,  37, 170], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.07859739661216736
bi 1 loss 0.03776910901069641
bi 2 loss 0.017841048538684845
bi 3 loss 0.04847271740436554
Layer  5  loss:  0.05082428455352783 0.0 7.488706588745117
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1018
Curr loss timestep torch.Size([423, 4]) tensor([296,  99, 113, 165], device='cuda:0') tensor(296, device='cuda:0')
bi 0 loss 0.11042806506156921
bi 1 loss 0.03203338384628296
bi 2 loss 0.03264850378036499
bi 3 loss 0.03331518918275833
Layer  6  loss:  0.04010256007313728 0.0 2.7943789958953857
logits torch.Size([423, 4, 1024]) labels torch.Size([423, 4]) 0 1022
Curr loss timestep torch.Size([423, 4]) tensor([308, 280, 139, 170], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 0.07006465643644333
bi 1 loss 0.03708692267537117
bi 2 loss 0.017985345795750618
bi 3 loss 0.02098848484456539
Epoch 0: :   3%|▎         | 15967/600000 [06:43<4:05:53, v_num=12, reduced_train_loss=38.50, global_step=1.6e+4, consumed_samples=63864.0, train_step_timing in s=0.388]Epoch 0: :   3%|▎         | 15967/600000 [06:43<4:05:53, v_num=12, reduced_train_loss=0.366, global_step=1.6e+4, consumed_samples=63868.0, train_step_timing in s=0.310]loss mask original None

First layer loss:  0.12789155542850494 torch.Size([647, 4]) 11.759369850158691 0.0
Max loss timestep torch.Size([647, 4]) tensor([205, 143, 535, 156], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.07925114780664444
speech mask sum tensor(134, device='cuda:0') loss mask sum tensor(134, device='cuda:0')
bi 1 loss 0.03912833705544472
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 2 loss 0.2182469367980957
speech mask sum tensor(421, device='cuda:0') loss mask sum tensor(421, device='cuda:0')
bi 3 loss 0.039078958332538605
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
logits torch.Size([647, 4, 257024]) labels torch.Size([647, 4]) 0 257023
Layer  0  loss:  0.13584096729755402 0.0 12.37663745880127
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([261, 175, 535, 260], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.051091015338897705
bi 1 loss 0.04058577120304108
bi 2 loss 0.24336941540241241
bi 3 loss 0.040143098682165146
Layer  1  loss:  0.16972246766090393 0.0 11.883734703063965
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([255, 220, 418, 196], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.08653800189495087
bi 1 loss 0.03295278549194336
bi 2 loss 0.29963645339012146
bi 3 loss 0.055708158761262894
Layer  2  loss:  0.16820977628231049 0.0 14.562711715698242
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([268, 174, 535,  96], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.0956452339887619
bi 1 loss 0.03669331222772598
bi 2 loss 0.2971719801425934
bi 3 loss 0.04632469639182091
Layer  3  loss:  0.16375331580638885 0.0 15.500044822692871
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([268, 199, 535, 135], device='cuda:0') tensor(535, device='cuda:0')
bi 0 loss 0.055369120091199875
bi 1 loss 0.08522605895996094
bi 2 loss 0.28658273816108704
bi 3 loss 0.04290546104311943
Layer  4  loss:  0.1605384647846222 0.0 13.270124435424805
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([269, 216, 420, 137], device='cuda:0') tensor(420, device='cuda:0')
bi 0 loss 0.044302087277173996
bi 1 loss 0.06232729181647301
bi 2 loss 0.27534613013267517
bi 3 loss 0.07190274447202682
Layer  5  loss:  0.15045616030693054 0.0 18.398483276367188
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([268, 148, 418, 260], device='cuda:0') tensor(418, device='cuda:0')
bi 0 loss 0.08117561042308807
bi 1 loss 0.02713499590754509
bi 2 loss 0.2461826503276825
bi 3 loss 0.08514291793107986
Layer  6  loss:  0.1492684781551361 0.0 10.158209800720215
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([268, 230, 581, 260], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.11301318556070328
bi 1 loss 0.04904256761074066
bi 2 loss 0.24779628217220306
bi 3 loss 0.044307149946689606
Epoch 0: :   3%|▎         | 15968/600000 [06:43<4:06:10, v_num=12, reduced_train_loss=0.366, global_step=1.6e+4, consumed_samples=63868.0, train_step_timing in s=0.310]Epoch 0: :   3%|▎         | 15968/600000 [06:43<4:06:10, v_num=12, reduced_train_loss=1.230, global_step=1.6e+4, consumed_samples=63872.0, train_step_timing in s=0.451]loss mask original None

First layer loss:  3.453913927078247 torch.Size([452, 4]) 12.577674865722656 0.0
Max loss timestep torch.Size([452, 4]) tensor([308, 334, 346, 294], device='cuda:0') tensor(308, device='cuda:0')
bi 0 loss 3.173328161239624
speech mask sum tensor(189, device='cuda:0') loss mask sum tensor(189, device='cuda:0')
bi 1 loss 3.149050712585449
speech mask sum tensor(166, device='cuda:0') loss mask sum tensor(166, device='cuda:0')
bi 2 loss 3.595004081726074
speech mask sum tensor(315, device='cuda:0') loss mask sum tensor(315, device='cuda:0')
bi 3 loss 3.7331337928771973
speech mask sum tensor(212, device='cuda:0') loss mask sum tensor(212, device='cuda:0')
logits torch.Size([452, 4, 257024]) labels torch.Size([452, 4]) 0 257023
Layer  0  loss:  3.9313666820526123 0.0 11.036003112792969
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1023
Curr loss timestep torch.Size([452, 4]) tensor([253, 278, 165, 242], device='cuda:0') tensor(297, device='cuda:0')
bi 0 loss 3.6335201263427734
bi 1 loss 4.1562886238098145
bi 2 loss 4.0583062171936035
bi 3 loss 3.8321683406829834
Layer  1  loss:  4.3400702476501465 0.0 12.12464427947998
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1022
Curr loss timestep torch.Size([452, 4]) tensor([195, 327, 396, 224], device='cuda:0') tensor(293, device='cuda:0')
bi 0 loss 3.965360403060913
bi 1 loss 4.187735080718994
bi 2 loss 4.488645553588867
bi 3 loss 4.572647571563721
Layer  2  loss:  4.670042514801025 0.0 10.903050422668457
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1022
Curr loss timestep torch.Size([452, 4]) tensor([207, 317, 217, 290], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 4.520269393920898
bi 1 loss 4.6470537185668945
bi 2 loss 4.704733848571777
bi 3 loss 4.770022869110107
Layer  3  loss:  4.81108283996582 0.0 11.319327354431152
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1021
Curr loss timestep torch.Size([452, 4]) tensor([293, 203, 242, 148], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 4.498441219329834
bi 1 loss 4.772764205932617
bi 2 loss 4.874208450317383
bi 3 loss 5.026014804840088
Layer  4  loss:  5.005608558654785 0.0 9.365945816040039
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1023
Curr loss timestep torch.Size([452, 4]) tensor([176, 335, 365, 287], device='cuda:0') tensor(281, device='cuda:0')
bi 0 loss 4.728614330291748
bi 1 loss 4.817473411560059
bi 2 loss 5.09261417388916
bi 3 loss 5.270588397979736
Layer  5  loss:  5.117222309112549 0.0 10.818532943725586
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1023
Curr loss timestep torch.Size([452, 4]) tensor([182, 337, 313, 312], device='cuda:0') tensor(235, device='cuda:0')
bi 0 loss 4.75653600692749
bi 1 loss 5.050330638885498
bi 2 loss 5.253167629241943
bi 3 loss 5.289161682128906
Layer  6  loss:  5.096001148223877 0.0 10.214527130126953
logits torch.Size([452, 4, 1024]) labels torch.Size([452, 4]) 0 1023
Curr loss timestep torch.Size([452, 4]) tensor([206, 257, 253, 301], device='cuda:0') tensor(215, device='cuda:0')
bi 0 loss 4.732854843139648
bi 1 loss 4.996157646179199
bi 2 loss 5.266048908233643
bi 3 loss 5.245261192321777
Epoch 0: :   3%|▎         | 15969/600000 [06:44<4:06:23, v_num=12, reduced_train_loss=1.230, global_step=1.6e+4, consumed_samples=63872.0, train_step_timing in s=0.451]Epoch 0: :   3%|▎         | 15969/600000 [06:44<4:06:23, v_num=12, reduced_train_loss=36.40, global_step=1.6e+4, consumed_samples=63876.0, train_step_timing in s=0.327]loss mask original None

First layer loss:  0.04448996111750603 torch.Size([443, 4]) 1.39262855052948 0.0
Max loss timestep torch.Size([443, 4]) tensor([280, 392, 193, 264], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 0.025511357933282852
speech mask sum tensor(315, device='cuda:0') loss mask sum tensor(315, device='cuda:0')
bi 1 loss 0.057915471494197845
speech mask sum tensor(385, device='cuda:0') loss mask sum tensor(385, device='cuda:0')
bi 2 loss 0.03424349054694176
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 3 loss 0.06209632754325867
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
logits torch.Size([443, 4, 257024]) labels torch.Size([443, 4]) 0 257023
Layer  0  loss:  0.06529209762811661 0.0 5.4915080070495605
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1023
Curr loss timestep torch.Size([443, 4]) tensor([280, 391, 236, 268], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.038968682289123535
bi 1 loss 0.09136370569467545
bi 2 loss 0.05442442372441292
bi 3 loss 0.06562641263008118
Layer  1  loss:  0.061329908668994904 0.0 6.532623767852783
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([351, 391, 196, 300], device='cuda:0') tensor(391, device='cuda:0')
bi 0 loss 0.03887639194726944
bi 1 loss 0.08975108712911606
bi 2 loss 0.05563846975564957
bi 3 loss 0.040694620460271835
Layer  2  loss:  0.06215151026844978 0.0 4.292595863342285
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([351,  73, 114, 263], device='cuda:0') tensor(263, device='cuda:0')
bi 0 loss 0.04081786051392555
bi 1 loss 0.08002619445323944
bi 2 loss 0.041441742330789566
bi 3 loss 0.08507724851369858
Layer  3  loss:  0.052748195827007294 0.0 4.419855117797852
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1021
Curr loss timestep torch.Size([443, 4]) tensor([275, 380, 126, 265], device='cuda:0') tensor(380, device='cuda:0')
bi 0 loss 0.024402601644396782
bi 1 loss 0.07658939808607101
bi 2 loss 0.03763171285390854
bi 3 loss 0.06855251640081406
Layer  4  loss:  0.05120743811130524 0.0 4.317234992980957
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1023
Curr loss timestep torch.Size([443, 4]) tensor([339, 391, 157, 264], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.03923717141151428
bi 1 loss 0.06114944815635681
bi 2 loss 0.03586898744106293
bi 3 loss 0.06862861663103104
Layer  5  loss:  0.06189373880624771 0.0 5.882096767425537
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([275, 261, 205, 237], device='cuda:0') tensor(275, device='cuda:0')
bi 0 loss 0.04754197597503662
bi 1 loss 0.0841660350561142
bi 2 loss 0.043330077081918716
bi 3 loss 0.05491470918059349
Layer  6  loss:  0.04490724951028824 0.0 1.9566938877105713
logits torch.Size([443, 4, 1024]) labels torch.Size([443, 4]) 0 1022
Curr loss timestep torch.Size([443, 4]) tensor([267, 391, 136, 265], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.016154667362570763
bi 1 loss 0.0666828528046608
bi 2 loss 0.05320218950510025
bi 3 loss 0.04001140967011452
Epoch 0: :   3%|▎         | 15970/600000 [06:44<4:06:35, v_num=12, reduced_train_loss=36.40, global_step=1.6e+4, consumed_samples=63876.0, train_step_timing in s=0.327]Epoch 0: :   3%|▎         | 15970/600000 [06:44<4:06:35, v_num=12, reduced_train_loss=0.444, global_step=1.6e+4, consumed_samples=63880.0, train_step_timing in s=0.319]loss mask original None

First layer loss:  0.20519664883613586 torch.Size([634, 4]) 11.469243049621582 0.0
Max loss timestep torch.Size([634, 4]) tensor([526, 399, 320, 363], device='cuda:0') tensor(526, device='cuda:0')
bi 0 loss 0.28222915530204773
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
bi 1 loss 0.23877876996994019
speech mask sum tensor(436, device='cuda:0') loss mask sum tensor(436, device='cuda:0')
bi 2 loss 0.105866439640522
speech mask sum tensor(135, device='cuda:0') loss mask sum tensor(135, device='cuda:0')
bi 3 loss 0.12088456749916077
speech mask sum tensor(328, device='cuda:0') loss mask sum tensor(328, device='cuda:0')
logits torch.Size([634, 4, 257024]) labels torch.Size([634, 4]) 0 257022
Layer  0  loss:  0.2419252246618271 0.0 17.245954513549805
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([536, 530, 377, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.26375478506088257
bi 1 loss 0.2566293776035309
bi 2 loss 0.16107991337776184
bi 3 loss 0.23282639682292938
Layer  1  loss:  0.25485238432884216 0.0 12.330398559570312
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([388, 527, 321, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.31580737233161926
bi 1 loss 0.2796359360218048
bi 2 loss 0.10474441200494766
bi 3 loss 0.21994806826114655
Layer  2  loss:  0.28657203912734985 0.0 13.503897666931152
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([536, 572, 320, 303], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.31878334283828735
bi 1 loss 0.31383392214775085
bi 2 loss 0.13163535296916962
bi 3 loss 0.2804189920425415
Layer  3  loss:  0.29133176803588867 0.0 9.313288688659668
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1021
Curr loss timestep torch.Size([634, 4]) tensor([388, 573, 319, 265], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.4265638589859009
bi 1 loss 0.2435103803873062
bi 2 loss 0.13483431935310364
bi 3 loss 0.2778947651386261
Layer  4  loss:  0.2666396200656891 0.0 16.47231674194336
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([535, 284, 316, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.3748810887336731
bi 1 loss 0.24674563109874725
bi 2 loss 0.1326071321964264
bi 3 loss 0.23505832254886627
Layer  5  loss:  0.30084386467933655 0.0 11.627102851867676
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([536, 572, 375, 363], device='cuda:0') tensor(265, device='cuda:0')
bi 0 loss 0.45755255222320557
bi 1 loss 0.28883567452430725
bi 2 loss 0.09880605340003967
bi 3 loss 0.23608651757240295
Layer  6  loss:  0.28465238213539124 0.0 17.6879940032959
logits torch.Size([634, 4, 1024]) labels torch.Size([634, 4]) 0 1023
Curr loss timestep torch.Size([634, 4]) tensor([536, 527, 349, 363], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.3960113823413849
bi 1 loss 0.25761616230010986
bi 2 loss 0.14483407139778137
bi 3 loss 0.2616863250732422
Epoch 0: :   3%|▎         | 15971/600000 [06:45<4:06:51, v_num=12, reduced_train_loss=0.444, global_step=1.6e+4, consumed_samples=63880.0, train_step_timing in s=0.319]Epoch 0: :   3%|▎         | 15971/600000 [06:45<4:06:51, v_num=12, reduced_train_loss=2.130, global_step=1.6e+4, consumed_samples=63884.0, train_step_timing in s=0.433]loss mask original None

First layer loss:  3.5494093894958496 torch.Size([248, 4]) 11.009994506835938 0.0
Max loss timestep torch.Size([248, 4]) tensor([ 34, 112,  94, 102], device='cuda:0') tensor(109, device='cuda:0')
bi 0 loss 3.7819037437438965
speech mask sum tensor(202, device='cuda:0') loss mask sum tensor(202, device='cuda:0')
bi 1 loss 3.3445518016815186
speech mask sum tensor(191, device='cuda:0') loss mask sum tensor(191, device='cuda:0')
bi 2 loss 3.144118309020996
speech mask sum tensor(89, device='cuda:0') loss mask sum tensor(89, device='cuda:0')
bi 3 loss 3.7907304763793945
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
logits torch.Size([248, 4, 257024]) labels torch.Size([248, 4]) 0 257023
Layer  0  loss:  3.940847396850586 0.0 9.504636764526367
logits torch.Size([248, 4, 1024]) labels torch.Size([248, 4]) 0 1023
Curr loss timestep torch.Size([248, 4]) tensor([ 68, 150, 156, 116], device='cuda:0') tensor(125, device='cuda:0')
bi 0 loss 4.225823879241943
bi 1 loss 3.7784340381622314
bi 2 loss 3.6219968795776367
bi 3 loss 3.9565162658691406
Layer  1  loss:  4.404871463775635 0.0 9.371296882629395
logits torch.Size([248, 4, 1024]) labels torch.Size([248, 4]) 0 1020
Curr loss timestep torch.Size([248, 4]) tensor([ 94, 218,  96,  82], device='cuda:0') tensor(140, device='cuda:0')
bi 0 loss 4.515866279602051
bi 1 loss 4.387669086456299
bi 2 loss 4.4298858642578125
bi 3 loss 4.222294330596924
Layer  2  loss:  4.717306137084961 0.0 11.187612533569336
logits torch.Size([248, 4, 1024]) labels torch.Size([248, 4]) 0 1022
Curr loss timestep torch.Size([248, 4]) tensor([155, 188, 124, 130], device='cuda:0') tensor(118, device='cuda:0')
bi 0 loss 4.922791957855225
bi 1 loss 4.555979251861572
bi 2 loss 4.655808925628662
bi 3 loss 4.6726789474487305
Layer  3  loss:  4.749240875244141 0.0 10.359018325805664
logits torch.Size([248, 4, 1024]) labels torch.Size([248, 4]) 0 1021
Curr loss timestep torch.Size([248, 4]) tensor([211, 124, 122,  75], device='cuda:0') tensor(105, device='cuda:0')
bi 0 loss 4.987568378448486
bi 1 loss 4.701395034790039
bi 2 loss 4.600070953369141
bi 3 loss 4.529348850250244
Layer  4  loss:  5.040286540985107 0.0 10.861763954162598
logits torch.Size([248, 4, 1024]) labels torch.Size([248, 4]) 0 1022
Curr loss timestep torch.Size([248, 4]) tensor([125,  78, 158, 132], device='cuda:0') tensor(159, device='cuda:0')
bi 0 loss 5.165129661560059
bi 1 loss 4.92159366607666
bi 2 loss 4.899085998535156
bi 3 loss 5.125916957855225
Layer  5  loss:  4.977261066436768 0.0 9.53731918334961
logits torch.Size([248, 4, 1024]) labels torch.Size([248, 4]) 0 1018
Curr loss timestep torch.Size([248, 4]) tensor([114, 160, 150,  94], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 5.151159763336182
bi 1 loss 4.93480920791626
bi 2 loss 4.68582820892334
bi 3 loss 4.968015670776367
Layer  6  loss:  5.197317123413086 0.0 12.8457670211792
logits torch.Size([248, 4, 1024]) labels torch.Size([248, 4]) 0 1022
Curr loss timestep torch.Size([248, 4]) tensor([183,  83, 160, 107], device='cuda:0') tensor(145, device='cuda:0')
bi 0 loss 5.2206315994262695
bi 1 loss 5.326761722564697
bi 2 loss 4.826304912567139
bi 3 loss 5.227972030639648
Epoch 0: :   3%|▎         | 15972/600000 [06:45<4:07:00, v_num=12, reduced_train_loss=2.130, global_step=1.6e+4, consumed_samples=63884.0, train_step_timing in s=0.433]Epoch 0: :   3%|▎         | 15972/600000 [06:45<4:07:00, v_num=12, reduced_train_loss=36.60, global_step=1.6e+4, consumed_samples=63888.0, train_step_timing in s=0.232]loss mask original None

First layer loss:  3.9823238849639893 torch.Size([736, 4]) 10.929340362548828 0.0
Max loss timestep torch.Size([736, 4]) tensor([634, 504, 142, 207], device='cuda:0') tensor(193, device='cuda:0')
bi 0 loss 4.040345668792725
speech mask sum tensor(415, device='cuda:0') loss mask sum tensor(415, device='cuda:0')
bi 1 loss 4.025656223297119
speech mask sum tensor(469, device='cuda:0') loss mask sum tensor(469, device='cuda:0')
bi 2 loss 3.9670205116271973
speech mask sum tensor(203, device='cuda:0') loss mask sum tensor(203, device='cuda:0')
bi 3 loss 3.874220848083496
speech mask sum tensor(382, device='cuda:0') loss mask sum tensor(382, device='cuda:0')
logits torch.Size([736, 4, 257024]) labels torch.Size([736, 4]) 0 257023
Layer  0  loss:  4.588465213775635 0.0 11.540885925292969
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([615, 374,  71, 235], device='cuda:0') tensor(211, device='cuda:0')
bi 0 loss 4.508889198303223
bi 1 loss 4.554265975952148
bi 2 loss 4.941244602203369
bi 3 loss 4.529430866241455
Layer  1  loss:  4.825058460235596 0.0 11.494742393493652
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([438, 577, 211, 260], device='cuda:0') tensor(438, device='cuda:0')
bi 0 loss 4.865593910217285
bi 1 loss 4.701569080352783
bi 2 loss 5.159869194030762
bi 3 loss 4.7547125816345215
Layer  2  loss:  5.072646617889404 0.0 11.309152603149414
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1022
Curr loss timestep torch.Size([736, 4]) tensor([545, 231, 180, 312], device='cuda:0') tensor(473, device='cuda:0')
bi 0 loss 5.064817905426025
bi 1 loss 4.999511241912842
bi 2 loss 5.28487491607666
bi 3 loss 5.058162212371826
Layer  3  loss:  5.2081074714660645 0.0 10.846343994140625
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1022
Curr loss timestep torch.Size([736, 4]) tensor([563, 325, 195, 238], device='cuda:0') tensor(450, device='cuda:0')
bi 0 loss 5.200459957122803
bi 1 loss 5.037223815917969
bi 2 loss 5.625227451324463
bi 3 loss 5.204554557800293
Layer  4  loss:  5.400082111358643 0.0 11.06318473815918
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([403, 439,  62, 316], device='cuda:0') tensor(421, device='cuda:0')
bi 0 loss 5.386882305145264
bi 1 loss 5.276666164398193
bi 2 loss 5.600076198577881
bi 3 loss 5.459666728973389
Layer  5  loss:  5.429271697998047 0.0 10.981016159057617
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([709, 218, 190, 335], device='cuda:0') tensor(491, device='cuda:0')
bi 0 loss 5.426877021789551
bi 1 loss 5.206557750701904
bi 2 loss 5.828853607177734
bi 3 loss 5.492966175079346
Layer  6  loss:  5.496765613555908 0.0 10.016008377075195
logits torch.Size([736, 4, 1024]) labels torch.Size([736, 4]) 0 1023
Curr loss timestep torch.Size([736, 4]) tensor([570, 583,  71, 350], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 5.471011161804199
bi 1 loss 5.461679935455322
bi 2 loss 5.699478626251221
bi 3 loss 5.460099220275879
High loss detected
Logging training audio
Epoch 0: :   3%|▎         | 15973/600000 [06:46<4:07:30, v_num=12, reduced_train_loss=36.60, global_step=1.6e+4, consumed_samples=63888.0, train_step_timing in s=0.232]Epoch 0: :   3%|▎         | 15973/600000 [06:46<4:07:30, v_num=12, reduced_train_loss=40.00, global_step=1.6e+4, consumed_samples=63892.0, train_step_timing in s=0.815]loss mask original None

First layer loss:  0.1932234764099121 torch.Size([627, 4]) 15.270880699157715 0.0
Max loss timestep torch.Size([627, 4]) tensor([296, 263, 101, 372], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.13007062673568726
speech mask sum tensor(381, device='cuda:0') loss mask sum tensor(381, device='cuda:0')
bi 1 loss 0.1444796770811081
speech mask sum tensor(155, device='cuda:0') loss mask sum tensor(155, device='cuda:0')
bi 2 loss 0.021703539416193962
speech mask sum tensor(89, device='cuda:0') loss mask sum tensor(89, device='cuda:0')
bi 3 loss 0.3484612703323364
speech mask sum tensor(302, device='cuda:0') loss mask sum tensor(302, device='cuda:0')
logits torch.Size([627, 4, 257024]) labels torch.Size([627, 4]) 0 257023
Layer  0  loss:  0.22331909835338593 0.0 14.89162540435791
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1023
Curr loss timestep torch.Size([627, 4]) tensor([296, 259, 102, 371], device='cuda:0') tensor(372, device='cuda:0')
bi 0 loss 0.10341528058052063
bi 1 loss 0.08868440240621567
bi 2 loss 0.03747763857245445
bi 3 loss 0.4984568953514099
Layer  1  loss:  0.23338556289672852 0.0 12.78796100616455
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([450, 293, 100, 576], device='cuda:0') tensor(576, device='cuda:0')
bi 0 loss 0.10010196268558502
bi 1 loss 0.08923515677452087
bi 2 loss 0.01577628403902054
bi 3 loss 0.5396490693092346
Layer  2  loss:  0.21894153952598572 0.0 12.18973159790039
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([296, 293, 127, 370], device='cuda:0') tensor(370, device='cuda:0')
bi 0 loss 0.10369498282670975
bi 1 loss 0.11172162741422653
bi 2 loss 0.02264796942472458
bi 3 loss 0.4772135317325592
Layer  3  loss:  0.27030646800994873 0.0 18.668060302734375
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([296, 293, 131, 345], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.11272482573986053
bi 1 loss 0.08752340823411942
bi 2 loss 0.024866769090294838
bi 3 loss 0.63525390625
Layer  4  loss:  0.23567889630794525 0.0 11.783761978149414
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([451, 293, 110, 459], device='cuda:0') tensor(459, device='cuda:0')
bi 0 loss 0.09089811146259308
bi 1 loss 0.060324281454086304
bi 2 loss 0.04005147144198418
bi 3 loss 0.5659844875335693
Layer  5  loss:  0.2684174180030823 0.0 12.498211860656738
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([451, 293, 111, 459], device='cuda:0') tensor(459, device='cuda:0')
bi 0 loss 0.1271084100008011
bi 1 loss 0.11972349882125854
bi 2 loss 0.025841401889920235
bi 3 loss 0.5944953560829163
Layer  6  loss:  0.26909902691841125 0.0 14.474440574645996
logits torch.Size([627, 4, 1024]) labels torch.Size([627, 4]) 0 1022
Curr loss timestep torch.Size([627, 4]) tensor([451, 341,  78, 371], device='cuda:0') tensor(371, device='cuda:0')
bi 0 loss 0.14879253506660461
bi 1 loss 0.14049242436885834
bi 2 loss 0.033536821603775024
bi 3 loss 0.5563037991523743
Epoch 0: :   3%|▎         | 15974/600000 [06:46<4:07:46, v_num=12, reduced_train_loss=40.00, global_step=1.6e+4, consumed_samples=63892.0, train_step_timing in s=0.815]Epoch 0: :   3%|▎         | 15974/600000 [06:46<4:07:46, v_num=12, reduced_train_loss=1.910, global_step=1.6e+4, consumed_samples=63896.0, train_step_timing in s=0.427]loss mask original None

First layer loss:  0.08867605775594711 torch.Size([561, 4]) 10.129006385803223 0.0
Max loss timestep torch.Size([561, 4]) tensor([260, 408,  92, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.06349997967481613
speech mask sum tensor(150, device='cuda:0') loss mask sum tensor(150, device='cuda:0')
bi 1 loss 0.07414441555738449
speech mask sum tensor(427, device='cuda:0') loss mask sum tensor(427, device='cuda:0')
bi 2 loss 0.01479219552129507
speech mask sum tensor(64, device='cuda:0') loss mask sum tensor(64, device='cuda:0')
bi 3 loss 0.11821417510509491
speech mask sum tensor(498, device='cuda:0') loss mask sum tensor(498, device='cuda:0')
logits torch.Size([561, 4, 257024]) labels torch.Size([561, 4]) 0 257023
Layer  0  loss:  0.13091830909252167 0.0 12.72184944152832
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([290, 343,  86, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.09978852421045303
bi 1 loss 0.10804484039545059
bi 2 loss 0.012258464470505714
bi 3 loss 0.1751565933227539
Layer  1  loss:  0.11271277815103531 0.0 9.157856941223145
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1022
Curr loss timestep torch.Size([561, 4]) tensor([264, 429, 113, 542], device='cuda:0') tensor(542, device='cuda:0')
bi 0 loss 0.05162467435002327
bi 1 loss 0.12648263573646545
bi 2 loss 0.009300039149820805
bi 3 loss 0.13259612023830414
Layer  2  loss:  0.13028286397457123 0.0 10.944976806640625
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([286, 439,  92, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.07191760092973709
bi 1 loss 0.12069588154554367
bi 2 loss 0.03737655282020569
bi 3 loss 0.16802267730236053
Layer  3  loss:  0.1290232092142105 0.0 11.469614028930664
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1021
Curr loss timestep torch.Size([561, 4]) tensor([257, 440,  91, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.07190001755952835
bi 1 loss 0.08361564576625824
bi 2 loss 0.013747666031122208
bi 3 loss 0.19997727870941162
Layer  4  loss:  0.11540094763040543 0.0 12.576638221740723
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([286, 429,  96, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.08817167580127716
bi 1 loss 0.08819122612476349
bi 2 loss 0.029351856559515
bi 3 loss 0.15799149870872498
Layer  5  loss:  0.13621559739112854 0.0 12.39478874206543
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([186, 287, 120, 522], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.07725248485803604
bi 1 loss 0.1497078686952591
bi 2 loss 0.013695811852812767
bi 3 loss 0.15815237164497375
Layer  6  loss:  0.13931025564670563 0.0 11.72968864440918
logits torch.Size([561, 4, 1024]) labels torch.Size([561, 4]) 0 1023
Curr loss timestep torch.Size([561, 4]) tensor([283, 429, 126, 521], device='cuda:0') tensor(521, device='cuda:0')
bi 0 loss 0.08563254028558731
bi 1 loss 0.14658509194850922
bi 2 loss 0.008160997182130814
bi 3 loss 0.16609512269496918
Epoch 0: :   3%|▎         | 15975/600000 [06:47<4:08:01, v_num=12, reduced_train_loss=1.910, global_step=1.6e+4, consumed_samples=63896.0, train_step_timing in s=0.427]Epoch 0: :   3%|▎         | 15975/600000 [06:47<4:08:01, v_num=12, reduced_train_loss=0.983, global_step=1.6e+4, consumed_samples=63900.0, train_step_timing in s=0.390]loss mask original None

First layer loss:  3.635345220565796 torch.Size([448, 4]) 11.64084529876709 0.0
Max loss timestep torch.Size([448, 4]) tensor([ 62, 364,  63, 384], device='cuda:0') tensor(116, device='cuda:0')
bi 0 loss 3.405048370361328
speech mask sum tensor(106, device='cuda:0') loss mask sum tensor(106, device='cuda:0')
bi 1 loss 4.269414901733398
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 2 loss 2.801088333129883
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 3 loss 3.5371549129486084
speech mask sum tensor(353, device='cuda:0') loss mask sum tensor(353, device='cuda:0')
logits torch.Size([448, 4, 257024]) labels torch.Size([448, 4]) 0 257023
Layer  0  loss:  3.9818060398101807 0.0 9.548688888549805
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([ 58, 372, 129, 148], device='cuda:0') tensor(97, device='cuda:0')
bi 0 loss 3.7347147464752197
bi 1 loss 4.476126194000244
bi 2 loss 3.262357711791992
bi 3 loss 3.942171812057495
Layer  1  loss:  4.419206619262695 0.0 9.356620788574219
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1021
Curr loss timestep torch.Size([448, 4]) tensor([ 57, 414,  81, 259], device='cuda:0') tensor(127, device='cuda:0')
bi 0 loss 4.1190185546875
bi 1 loss 4.839332103729248
bi 2 loss 4.159070014953613
bi 3 loss 4.328005313873291
Layer  2  loss:  4.665933609008789 0.0 10.13792896270752
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([104, 336,  69,  87], device='cuda:0') tensor(87, device='cuda:0')
bi 0 loss 4.6031084060668945
bi 1 loss 5.198460102081299
bi 2 loss 4.133510589599609
bi 3 loss 4.503745079040527
Layer  3  loss:  4.803897857666016 0.0 9.368682861328125
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1021
Curr loss timestep torch.Size([448, 4]) tensor([102, 442,  67, 404], device='cuda:0') tensor(88, device='cuda:0')
bi 0 loss 4.778994083404541
bi 1 loss 5.293715476989746
bi 2 loss 4.261370658874512
bi 3 loss 4.657557964324951
Layer  4  loss:  4.971207141876221 0.0 10.271315574645996
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([ 84, 367,  96, 265], device='cuda:0') tensor(119, device='cuda:0')
bi 0 loss 4.883285045623779
bi 1 loss 5.524318695068359
bi 2 loss 4.532200813293457
bi 3 loss 4.782105445861816
Layer  5  loss:  5.050200462341309 0.0 9.963796615600586
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1021
Curr loss timestep torch.Size([448, 4]) tensor([ 65, 396,  85, 361], device='cuda:0') tensor(85, device='cuda:0')
bi 0 loss 4.921977519989014
bi 1 loss 5.635555267333984
bi 2 loss 4.65331506729126
bi 3 loss 4.844333171844482
Layer  6  loss:  5.121178150177002 0.0 11.58359432220459
logits torch.Size([448, 4, 1024]) labels torch.Size([448, 4]) 0 1023
Curr loss timestep torch.Size([448, 4]) tensor([ 99, 429,  92, 111], device='cuda:0') tensor(121, device='cuda:0')
bi 0 loss 4.868862628936768
bi 1 loss 5.7064313888549805
bi 2 loss 4.712098121643066
bi 3 loss 4.955570220947266
Epoch 0: :   3%|▎         | 15976/600000 [06:47<4:08:13, v_num=12, reduced_train_loss=0.983, global_step=1.6e+4, consumed_samples=63900.0, train_step_timing in s=0.390]Epoch 0: :   3%|▎         | 15976/600000 [06:47<4:08:13, v_num=12, reduced_train_loss=36.60, global_step=1.6e+4, consumed_samples=63904.0, train_step_timing in s=0.313]loss mask original None

First layer loss:  0.2656758427619934 torch.Size([647, 4]) 12.343256950378418 0.0
Max loss timestep torch.Size([647, 4]) tensor([297,  62, 434, 286], device='cuda:0') tensor(434, device='cuda:0')
bi 0 loss 0.17067058384418488
speech mask sum tensor(444, device='cuda:0') loss mask sum tensor(444, device='cuda:0')
bi 1 loss 0.046479012817144394
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
bi 2 loss 0.41456127166748047
speech mask sum tensor(462, device='cuda:0') loss mask sum tensor(462, device='cuda:0')
bi 3 loss 0.2593723237514496
speech mask sum tensor(117, device='cuda:0') loss mask sum tensor(117, device='cuda:0')
logits torch.Size([647, 4, 257024]) labels torch.Size([647, 4]) 0 257022
Layer  0  loss:  0.2912370264530182 0.0 14.337626457214355
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([562,  72, 435, 316], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.19419629871845245
bi 1 loss 0.039908118546009064
bi 2 loss 0.4729234576225281
bi 3 loss 0.19554279744625092
Layer  1  loss:  0.34804636240005493 0.0 19.74245262145996
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([297, 105, 436, 286], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.24151143431663513
bi 1 loss 0.053231384605169296
bi 2 loss 0.5260190963745117
bi 3 loss 0.3469030261039734
Layer  2  loss:  0.3546349108219147 0.0 14.125311851501465
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([515, 119, 435, 286], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.23105618357658386
bi 1 loss 0.05008290335536003
bi 2 loss 0.5586701035499573
bi 3 loss 0.32507801055908203
Layer  3  loss:  0.3323010802268982 0.0 17.326560974121094
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([515, 104, 435, 317], device='cuda:0') tensor(435, device='cuda:0')
bi 0 loss 0.21283455193042755
bi 1 loss 0.043604955077171326
bi 2 loss 0.5252141952514648
bi 3 loss 0.31506550312042236
Layer  4  loss:  0.329679012298584 0.0 14.174174308776855
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1023
Curr loss timestep torch.Size([647, 4]) tensor([297,  45, 436, 317], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.20630459487438202
bi 1 loss 0.05651022121310234
bi 2 loss 0.5229606628417969
bi 3 loss 0.3101578950881958
Layer  5  loss:  0.33510392904281616 0.0 17.592653274536133
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([304, 120, 436, 286], device='cuda:0') tensor(436, device='cuda:0')
bi 0 loss 0.23897045850753784
bi 1 loss 0.05255758389830589
bi 2 loss 0.5294334292411804
bi 3 loss 0.21752718091011047
Layer  6  loss:  0.35354551672935486 0.0 20.282697677612305
logits torch.Size([647, 4, 1024]) labels torch.Size([647, 4]) 0 1022
Curr loss timestep torch.Size([647, 4]) tensor([515, 114, 545, 317], device='cuda:0') tensor(545, device='cuda:0')
bi 0 loss 0.244339257478714
bi 1 loss 0.04822539538145065
bi 2 loss 0.5456675887107849
bi 3 loss 0.31726327538490295
Epoch 0: :   3%|▎         | 15977/600000 [06:47<4:08:29, v_num=12, reduced_train_loss=36.60, global_step=1.6e+4, consumed_samples=63904.0, train_step_timing in s=0.313]Epoch 0: :   3%|▎         | 15977/600000 [06:47<4:08:29, v_num=12, reduced_train_loss=2.610, global_step=1.6e+4, consumed_samples=63908.0, train_step_timing in s=0.442]loss mask original None

First layer loss:  0.1776529997587204 torch.Size([707, 4]) 9.916875839233398 0.0
Max loss timestep torch.Size([707, 4]) tensor([503, 319, 261, 646], device='cuda:0') tensor(335, device='cuda:0')
bi 0 loss 0.17802344262599945
speech mask sum tensor(321, device='cuda:0') loss mask sum tensor(321, device='cuda:0')
bi 1 loss 0.10471541434526443
speech mask sum tensor(243, device='cuda:0') loss mask sum tensor(243, device='cuda:0')
bi 2 loss 0.10428215563297272
speech mask sum tensor(361, device='cuda:0') loss mask sum tensor(361, device='cuda:0')
bi 3 loss 0.2663688659667969
speech mask sum tensor(497, device='cuda:0') loss mask sum tensor(497, device='cuda:0')
logits torch.Size([707, 4, 257024]) labels torch.Size([707, 4]) 0 257023
Layer  0  loss:  0.24008360505104065 0.0 9.451786041259766
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([503, 319, 451, 605], device='cuda:0') tensor(451, device='cuda:0')
bi 0 loss 0.19925691187381744
bi 1 loss 0.18804052472114563
bi 2 loss 0.22719906270503998
bi 3 loss 0.3012569844722748
Layer  1  loss:  0.23324230313301086 0.0 8.72792911529541
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([502, 319, 451, 661], device='cuda:0') tensor(661, device='cuda:0')
bi 0 loss 0.23275673389434814
bi 1 loss 0.16883358359336853
bi 2 loss 0.1823032796382904
bi 3 loss 0.302047461271286
Layer  2  loss:  0.2731076776981354 0.0 14.602968215942383
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([309, 319, 274, 661], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.22079399228096008
bi 1 loss 0.2246052771806717
bi 2 loss 0.19557519257068634
bi 3 loss 0.3869265913963318
Layer  3  loss:  0.26965704560279846 0.0 16.406293869018555
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([477, 319, 342, 661], device='cuda:0') tensor(477, device='cuda:0')
bi 0 loss 0.19710880517959595
bi 1 loss 0.18392537534236908
bi 2 loss 0.2796160876750946
bi 3 loss 0.3511974513530731
Layer  4  loss:  0.2700735330581665 0.0 14.138824462890625
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([431, 319, 296, 517], device='cuda:0') tensor(319, device='cuda:0')
bi 0 loss 0.23447762429714203
bi 1 loss 0.1978280395269394
bi 2 loss 0.24440978467464447
bi 3 loss 0.34702834486961365
Layer  5  loss:  0.27168595790863037 0.0 15.436286926269531
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1022
Curr loss timestep torch.Size([707, 4]) tensor([502, 319, 451, 661], device='cuda:0') tensor(661, device='cuda:0')
bi 0 loss 0.252155065536499
bi 1 loss 0.1750859022140503
bi 2 loss 0.20407691597938538
bi 3 loss 0.3806398808956146
Layer  6  loss:  0.2850344479084015 0.0 14.187664985656738
logits torch.Size([707, 4, 1024]) labels torch.Size([707, 4]) 0 1023
Curr loss timestep torch.Size([707, 4]) tensor([503, 361, 394, 661], device='cuda:0') tensor(394, device='cuda:0')
bi 0 loss 0.2338734269142151
bi 1 loss 0.18882550299167633
bi 2 loss 0.2763313353061676
bi 3 loss 0.37143945693969727
Epoch 0: :   3%|▎         | 15978/600000 [06:48<4:08:47, v_num=12, reduced_train_loss=2.610, global_step=1.6e+4, consumed_samples=63908.0, train_step_timing in s=0.442]Epoch 0: :   3%|▎         | 15978/600000 [06:48<4:08:47, v_num=12, reduced_train_loss=2.020, global_step=1.6e+4, consumed_samples=63912.0, train_step_timing in s=0.481]loss mask original None

First layer loss:  0.14394046366214752 torch.Size([533, 4]) 12.065434455871582 0.0
Max loss timestep torch.Size([533, 4]) tensor([440, 180, 293, 490], device='cuda:0') tensor(490, device='cuda:0')
bi 0 loss 0.11650579422712326
speech mask sum tensor(306, device='cuda:0') loss mask sum tensor(306, device='cuda:0')
bi 1 loss 0.04662013798952103
speech mask sum tensor(205, device='cuda:0') loss mask sum tensor(205, device='cuda:0')
bi 2 loss 0.17265230417251587
speech mask sum tensor(71, device='cuda:0') loss mask sum tensor(71, device='cuda:0')
bi 3 loss 0.2102052867412567
speech mask sum tensor(397, device='cuda:0') loss mask sum tensor(397, device='cuda:0')
logits torch.Size([533, 4, 257024]) labels torch.Size([533, 4]) 0 257022
Layer  0  loss:  0.16657747328281403 0.0 9.66557788848877
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1023
Curr loss timestep torch.Size([533, 4]) tensor([389, 162, 247, 458], device='cuda:0') tensor(458, device='cuda:0')
bi 0 loss 0.12392782419919968
bi 1 loss 0.049795325845479965
bi 2 loss 0.05326571315526962
bi 3 loss 0.2800188958644867
Layer  1  loss:  0.17023952305316925 0.0 15.875055313110352
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([382, 183, 261, 464], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.1466086208820343
bi 1 loss 0.048293378204107285
bi 2 loss 0.10278424620628357
bi 3 loss 0.26348721981048584
Layer  2  loss:  0.18237930536270142 0.0 11.442296028137207
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([440, 146, 293, 464], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.14412593841552734
bi 1 loss 0.04970354214310646
bi 2 loss 0.22903265058994293
bi 3 loss 0.27203088998794556
Layer  3  loss:  0.19832445681095123 0.0 13.850643157958984
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1020
Curr loss timestep torch.Size([533, 4]) tensor([440, 234, 293, 458], device='cuda:0') tensor(458, device='cuda:0')
bi 0 loss 0.12203338742256165
bi 1 loss 0.0383017361164093
bi 2 loss 0.0982772558927536
bi 3 loss 0.35765206813812256
Layer  4  loss:  0.19662976264953613 0.0 15.311009407043457
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([443, 243, 293, 490], device='cuda:0') tensor(490, device='cuda:0')
bi 0 loss 0.0893254354596138
bi 1 loss 0.06996604800224304
bi 2 loss 0.2578924596309662
bi 3 loss 0.33378729224205017
Layer  5  loss:  0.19369876384735107 0.0 13.01931095123291
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1022
Curr loss timestep torch.Size([533, 4]) tensor([266, 179, 293, 312], device='cuda:0') tensor(312, device='cuda:0')
bi 0 loss 0.13104984164237976
bi 1 loss 0.03929775953292847
bi 2 loss 0.18457676470279694
bi 3 loss 0.3233472406864166
Layer  6  loss:  0.1790522038936615 0.0 10.484187126159668
logits torch.Size([533, 4, 1024]) labels torch.Size([533, 4]) 0 1020
Curr loss timestep torch.Size([533, 4]) tensor([383, 149, 261, 464], device='cuda:0') tensor(464, device='cuda:0')
bi 0 loss 0.1391957551240921
bi 1 loss 0.03487345948815346
bi 2 loss 0.23979592323303223
bi 3 loss 0.2733592987060547
Epoch 0: :   3%|▎         | 15979/600000 [06:48<4:09:01, v_num=12, reduced_train_loss=2.020, global_step=1.6e+4, consumed_samples=63912.0, train_step_timing in s=0.481]Epoch 0: :   3%|▎         | 15979/600000 [06:48<4:09:01, v_num=12, reduced_train_loss=1.430, global_step=1.6e+4, consumed_samples=63916.0, train_step_timing in s=0.369]loss mask original None

First layer loss:  3.460308790206909 torch.Size([348, 4]) 9.870379447937012 0.0
Max loss timestep torch.Size([348, 4]) tensor([102, 147, 279, 145], device='cuda:0') tensor(147, device='cuda:0')
bi 0 loss 3.4203574657440186
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 1 loss 3.5011863708496094
speech mask sum tensor(101, device='cuda:0') loss mask sum tensor(101, device='cuda:0')
bi 2 loss 3.209892511367798
speech mask sum tensor(234, device='cuda:0') loss mask sum tensor(234, device='cuda:0')
bi 3 loss 3.8745572566986084
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
logits torch.Size([348, 4, 257024]) labels torch.Size([348, 4]) 0 257023
Layer  0  loss:  4.109624862670898 0.0 9.885738372802734
logits torch.Size([348, 4, 1024]) labels torch.Size([348, 4]) 0 1023
Curr loss timestep torch.Size([348, 4]) tensor([ 66, 153, 163, 161], device='cuda:0') tensor(131, device='cuda:0')
bi 0 loss 3.8247451782226562
bi 1 loss 3.9058845043182373
bi 2 loss 4.068271636962891
bi 3 loss 4.541360378265381
Layer  1  loss:  4.368277549743652 0.0 9.442893981933594
logits torch.Size([348, 4, 1024]) labels torch.Size([348, 4]) 0 1022
Curr loss timestep torch.Size([348, 4]) tensor([ 89,  99, 250, 148], device='cuda:0') tensor(132, device='cuda:0')
bi 0 loss 3.906743288040161
bi 1 loss 4.289438247680664
bi 2 loss 4.487674236297607
bi 3 loss 4.581876277923584
Layer  2  loss:  4.696587562561035 0.0 9.285079002380371
logits torch.Size([348, 4, 1024]) labels torch.Size([348, 4]) 0 1023
Curr loss timestep torch.Size([348, 4]) tensor([ 93, 121, 252, 105], device='cuda:0') tensor(133, device='cuda:0')
bi 0 loss 4.316843509674072
bi 1 loss 4.69153356552124
bi 2 loss 4.770314693450928
bi 3 loss 4.87018346786499
Layer  3  loss:  4.802802562713623 0.0 10.312748908996582
logits torch.Size([348, 4, 1024]) labels torch.Size([348, 4]) 0 1021
Curr loss timestep torch.Size([348, 4]) tensor([116, 124, 129, 163], device='cuda:0') tensor(148, device='cuda:0')
bi 0 loss 4.436365604400635
bi 1 loss 4.87318229675293
bi 2 loss 4.759871959686279
bi 3 loss 5.104769229888916
Layer  4  loss:  5.048267364501953 0.0 9.370024681091309
logits torch.Size([348, 4, 1024]) labels torch.Size([348, 4]) 0 1020
Curr loss timestep torch.Size([348, 4]) tensor([110,  87, 163, 110], device='cuda:0') tensor(131, device='cuda:0')
bi 0 loss 4.594959735870361
bi 1 loss 4.978109836578369
bi 2 loss 5.127182483673096
bi 3 loss 5.3160858154296875
Layer  5  loss:  5.005453586578369 0.0 9.837682723999023
logits torch.Size([348, 4, 1024]) labels torch.Size([348, 4]) 0 1023
Curr loss timestep torch.Size([348, 4]) tensor([136, 146, 166, 107], device='cuda:0') tensor(136, device='cuda:0')
bi 0 loss 4.492364883422852
bi 1 loss 4.857734680175781
bi 2 loss 5.168201923370361
bi 3 loss 5.236180305480957
Layer  6  loss:  5.0501508712768555 0.0 9.919761657714844
logits torch.Size([348, 4, 1024]) labels torch.Size([348, 4]) 0 1019
Curr loss timestep torch.Size([348, 4]) tensor([144, 149, 181, 136], device='cuda:0') tensor(137, device='cuda:0')
bi 0 loss 4.596486568450928
bi 1 loss 5.091917514801025
bi 2 loss 5.1029815673828125
bi 3 loss 5.281619548797607
Epoch 0: :   3%|▎         | 15980/600000 [06:49<4:09:11, v_num=12, reduced_train_loss=1.430, global_step=1.6e+4, consumed_samples=63916.0, train_step_timing in s=0.369]Epoch 0: :   3%|▎         | 15980/600000 [06:49<4:09:11, v_num=12, reduced_train_loss=36.50, global_step=1.6e+4, consumed_samples=63920.0, train_step_timing in s=0.271]loss mask original None

First layer loss:  0.10027536004781723 torch.Size([607, 4]) 6.729946136474609 0.0
Max loss timestep torch.Size([607, 4]) tensor([176, 112, 560, 109], device='cuda:0') tensor(560, device='cuda:0')
bi 0 loss 0.03443760797381401
speech mask sum tensor(109, device='cuda:0') loss mask sum tensor(109, device='cuda:0')
bi 1 loss 0.03408806398510933
speech mask sum tensor(85, device='cuda:0') loss mask sum tensor(85, device='cuda:0')
bi 2 loss 0.1540028154850006
speech mask sum tensor(461, device='cuda:0') loss mask sum tensor(461, device='cuda:0')
bi 3 loss 0.012931336648762226
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
logits torch.Size([607, 4, 257024]) labels torch.Size([607, 4]) 0 257023
Layer  0  loss:  0.09833607822656631 0.0 7.04114294052124
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([147,  83, 552, 110], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.047695182263851166
bi 1 loss 0.050252415239810944
bi 2 loss 0.14481715857982635
bi 3 loss 0.012052788399159908
Layer  1  loss:  0.11998704820871353 0.0 11.878104209899902
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([175,  64, 581,  57], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.025699719786643982
bi 1 loss 0.041245631873607635
bi 2 loss 0.1914021074771881
bi 3 loss 0.0035490200389176607
Layer  2  loss:  0.13801667094230652 0.0 12.577343940734863
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1022
Curr loss timestep torch.Size([607, 4]) tensor([210,  63, 581, 166], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.05382750928401947
bi 1 loss 0.04503714293241501
bi 2 loss 0.2145642191171646
bi 3 loss 0.005107617937028408
Layer  3  loss:  0.10690402239561081 0.0 10.409414291381836
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([157, 115, 552, 106], device='cuda:0') tensor(552, device='cuda:0')
bi 0 loss 0.022185541689395905
bi 1 loss 0.03456955403089523
bi 2 loss 0.17010249197483063
bi 3 loss 0.006526234094053507
Layer  4  loss:  0.13605660200119019 0.0 9.595307350158691
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([154,  83, 530, 107], device='cuda:0') tensor(530, device='cuda:0')
bi 0 loss 0.04205264523625374
bi 1 loss 0.024923985823988914
bi 2 loss 0.21662156283855438
bi 3 loss 0.008700820617377758
Layer  5  loss:  0.11697294563055038 0.0 8.350726127624512
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1023
Curr loss timestep torch.Size([607, 4]) tensor([208,  82, 581, 126], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.03129788860678673
bi 1 loss 0.08026183396577835
bi 2 loss 0.1752045601606369
bi 3 loss 0.011967449449002743
Layer  6  loss:  0.12319110333919525 0.0 10.067729949951172
logits torch.Size([607, 4, 1024]) labels torch.Size([607, 4]) 0 1020
Curr loss timestep torch.Size([607, 4]) tensor([151, 106, 516, 151], device='cuda:0') tensor(516, device='cuda:0')
bi 0 loss 0.03247203305363655
bi 1 loss 0.031170634552836418
bi 2 loss 0.19222459197044373
bi 3 loss 0.020166940987110138
Epoch 0: :   3%|▎         | 15981/600000 [06:49<4:09:27, v_num=12, reduced_train_loss=36.50, global_step=1.6e+4, consumed_samples=63920.0, train_step_timing in s=0.271]Epoch 0: :   3%|▎         | 15981/600000 [06:49<4:09:27, v_num=12, reduced_train_loss=0.940, global_step=1.6e+4, consumed_samples=63924.0, train_step_timing in s=0.419]loss mask original None

First layer loss:  3.3001506328582764 torch.Size([528, 4]) 11.05966567993164 0.0
Max loss timestep torch.Size([528, 4]) tensor([267, 266,  89, 227], device='cuda:0') tensor(206, device='cuda:0')
bi 0 loss 2.630095958709717
speech mask sum tensor(343, device='cuda:0') loss mask sum tensor(343, device='cuda:0')
bi 1 loss 3.798502206802368
speech mask sum tensor(432, device='cuda:0') loss mask sum tensor(432, device='cuda:0')
bi 2 loss 3.304156541824341
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 3 loss 3.329589366912842
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
logits torch.Size([528, 4, 257024]) labels torch.Size([528, 4]) 0 257022
Layer  0  loss:  3.815382242202759 0.0 11.96087646484375
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([338, 420, 163, 481], device='cuda:0') tensor(208, device='cuda:0')
bi 0 loss 2.942514419555664
bi 1 loss 4.3379597663879395
bi 2 loss 3.8255703449249268
bi 3 loss 3.9692587852478027
Layer  1  loss:  4.194576740264893 0.0 9.741571426391602
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([219, 419,  94, 295], device='cuda:0') tensor(209, device='cuda:0')
bi 0 loss 3.333775043487549
bi 1 loss 4.521017074584961
bi 2 loss 4.394195079803467
bi 3 loss 4.432328701019287
Layer  2  loss:  4.4592509269714355 0.0 10.708456993103027
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([343, 393, 156, 439], device='cuda:0') tensor(224, device='cuda:0')
bi 0 loss 3.6552107334136963
bi 1 loss 4.890634059906006
bi 2 loss 4.704224586486816
bi 3 loss 4.535831928253174
Layer  3  loss:  4.640313625335693 0.0 10.737481117248535
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([282, 265, 233, 241], device='cuda:0') tensor(223, device='cuda:0')
bi 0 loss 4.0476975440979
bi 1 loss 5.0200114250183105
bi 2 loss 4.937774181365967
bi 3 loss 4.583838939666748
Layer  4  loss:  4.76828145980835 0.0 10.407076835632324
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([230, 279, 130, 127], device='cuda:0') tensor(212, device='cuda:0')
bi 0 loss 4.147825241088867
bi 1 loss 5.143484115600586
bi 2 loss 4.97064208984375
bi 3 loss 4.781663417816162
Layer  5  loss:  4.826086521148682 0.0 10.034627914428711
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1022
Curr loss timestep torch.Size([528, 4]) tensor([242, 455,  66, 511], device='cuda:0') tensor(227, device='cuda:0')
bi 0 loss 4.118432998657227
bi 1 loss 5.302226543426514
bi 2 loss 5.154971599578857
bi 3 loss 4.749962329864502
Layer  6  loss:  4.900571346282959 0.0 10.595959663391113
logits torch.Size([528, 4, 1024]) labels torch.Size([528, 4]) 0 1023
Curr loss timestep torch.Size([528, 4]) tensor([508, 463, 224, 168], device='cuda:0') tensor(226, device='cuda:0')
bi 0 loss 4.203102111816406
bi 1 loss 5.33425235748291
bi 2 loss 5.187178611755371
bi 3 loss 4.876493453979492
Epoch 0: :   3%|▎         | 15982/600000 [06:49<4:09:40, v_num=12, reduced_train_loss=0.940, global_step=1.6e+4, consumed_samples=63924.0, train_step_timing in s=0.419]Epoch 0: :   3%|▎         | 15982/600000 [06:49<4:09:40, v_num=12, reduced_train_loss=34.90, global_step=1.6e+4, consumed_samples=63928.0, train_step_timing in s=0.352]loss mask original None

First layer loss:  0.07233129441738129 torch.Size([570, 4]) 8.604683876037598 0.0
Max loss timestep torch.Size([570, 4]) tensor([255, 365, 400, 186], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.031015664339065552
speech mask sum tensor(142, device='cuda:0') loss mask sum tensor(142, device='cuda:0')
bi 1 loss 0.08701570332050323
speech mask sum tensor(228, device='cuda:0') loss mask sum tensor(228, device='cuda:0')
bi 2 loss 0.09523234516382217
speech mask sum tensor(391, device='cuda:0') loss mask sum tensor(391, device='cuda:0')
bi 3 loss 0.030542125925421715
speech mask sum tensor(154, device='cuda:0') loss mask sum tensor(154, device='cuda:0')
logits torch.Size([570, 4, 257024]) labels torch.Size([570, 4]) 0 257023
Layer  0  loss:  0.0792277380824089 0.0 7.702186107635498
logits torch.Size([570, 4, 1024]) labels torch.Size([570, 4]) 0 1023
Curr loss timestep torch.Size([570, 4]) tensor([259, 293, 400, 144], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.016709983348846436
bi 1 loss 0.09962490200996399
bi 2 loss 0.11549124866724014
bi 3 loss 0.014603974297642708
Layer  1  loss:  0.10164092481136322 0.0 10.783987045288086
logits torch.Size([570, 4, 1024]) labels torch.Size([570, 4]) 0 1023
Curr loss timestep torch.Size([570, 4]) tensor([273, 398, 400, 151], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.018664054572582245
bi 1 loss 0.12064724415540695
bi 2 loss 0.15458276867866516
bi 3 loss 0.015595562756061554
Layer  2  loss:  0.10239586979150772 0.0 9.629227638244629
logits torch.Size([570, 4, 1024]) labels torch.Size([570, 4]) 0 1023
Curr loss timestep torch.Size([570, 4]) tensor([198, 342, 539, 198], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.028843853622674942
bi 1 loss 0.10184332728385925
bi 2 loss 0.16116991639137268
bi 3 loss 0.021809590980410576
Layer  3  loss:  0.1022677794098854 0.0 7.790461540222168
logits torch.Size([570, 4, 1024]) labels torch.Size([570, 4]) 0 1023
Curr loss timestep torch.Size([570, 4]) tensor([198, 346, 400, 182], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.023707440122961998
bi 1 loss 0.10508986562490463
bi 2 loss 0.15934306383132935
bi 3 loss 0.025616435334086418
Layer  4  loss:  0.09374719858169556 0.0 9.934033393859863
logits torch.Size([570, 4, 1024]) labels torch.Size([570, 4]) 0 1022
Curr loss timestep torch.Size([570, 4]) tensor([152, 357, 536, 131], device='cuda:0') tensor(536, device='cuda:0')
bi 0 loss 0.04035354405641556
bi 1 loss 0.0930476114153862
bi 2 loss 0.14020270109176636
bi 3 loss 0.026067368686199188
Layer  5  loss:  0.10509980469942093 0.0 8.710283279418945
logits torch.Size([570, 4, 1024]) labels torch.Size([570, 4]) 0 1020
Curr loss timestep torch.Size([570, 4]) tensor([160, 319, 539, 223], device='cuda:0') tensor(539, device='cuda:0')
bi 0 loss 0.027944467961788177
bi 1 loss 0.09455044567584991
bi 2 loss 0.16420507431030273
bi 3 loss 0.041795581579208374
Layer  6  loss:  0.10987984389066696 0.0 7.323263168334961
logits torch.Size([570, 4, 1024]) labels torch.Size([570, 4]) 0 1022
Curr loss timestep torch.Size([570, 4]) tensor([152, 367, 400, 110], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.039314787834882736
bi 1 loss 0.12184152752161026
bi 2 loss 0.15666501224040985
bi 3 loss 0.03845107927918434
Epoch 0: :   3%|▎         | 15983/600000 [06:50<4:09:55, v_num=12, reduced_train_loss=34.90, global_step=1.6e+4, consumed_samples=63928.0, train_step_timing in s=0.352]Epoch 0: :   3%|▎         | 15983/600000 [06:50<4:09:55, v_num=12, reduced_train_loss=0.767, global_step=1.6e+4, consumed_samples=63932.0, train_step_timing in s=0.397]loss mask original None

First layer loss:  0.09728433936834335 torch.Size([587, 4]) 14.672022819519043 0.0
Max loss timestep torch.Size([587, 4]) tensor([271, 355, 340, 174], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.08708912134170532
speech mask sum tensor(204, device='cuda:0') loss mask sum tensor(204, device='cuda:0')
bi 1 loss 0.12702620029449463
speech mask sum tensor(332, device='cuda:0') loss mask sum tensor(332, device='cuda:0')
bi 2 loss 0.09967482089996338
speech mask sum tensor(398, device='cuda:0') loss mask sum tensor(398, device='cuda:0')
bi 3 loss 0.02316661924123764
speech mask sum tensor(118, device='cuda:0') loss mask sum tensor(118, device='cuda:0')
logits torch.Size([587, 4, 257024]) labels torch.Size([587, 4]) 0 257023
Layer  0  loss:  0.1257629096508026 0.0 12.626489639282227
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([228, 464, 341, 263], device='cuda:0') tensor(341, device='cuda:0')
bi 0 loss 0.10142531991004944
bi 1 loss 0.1393248736858368
bi 2 loss 0.15726302564144135
bi 3 loss 0.02343451790511608
Layer  1  loss:  0.13963355123996735 0.0 12.314401626586914
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([348, 355, 341, 210], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.13074105978012085
bi 1 loss 0.1877945065498352
bi 2 loss 0.13764329254627228
bi 3 loss 0.026216236874461174
Layer  2  loss:  0.15545280277729034 0.0 12.485481262207031
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1022
Curr loss timestep torch.Size([587, 4]) tensor([348, 282, 340, 223], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.1926521211862564
bi 1 loss 0.13895092904567719
bi 2 loss 0.18893110752105713
bi 3 loss 0.024652758613228798
Layer  3  loss:  0.162246435880661 0.0 13.31589126586914
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([292, 356, 340, 229], device='cuda:0') tensor(356, device='cuda:0')
bi 0 loss 0.1632160097360611
bi 1 loss 0.17246997356414795
bi 2 loss 0.1929510086774826
bi 3 loss 0.02824275940656662
Layer  4  loss:  0.16807341575622559 0.0 8.817907333374023
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([348, 430, 339, 224], device='cuda:0') tensor(430, device='cuda:0')
bi 0 loss 0.13439081609249115
bi 1 loss 0.18974055349826813
bi 2 loss 0.20530351996421814
bi 3 loss 0.03976970538496971
Layer  5  loss:  0.16186903417110443 0.0 10.805261611938477
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1016
Curr loss timestep torch.Size([587, 4]) tensor([348, 356, 340, 222], device='cuda:0') tensor(340, device='cuda:0')
bi 0 loss 0.17223797738552094
bi 1 loss 0.1467972993850708
bi 2 loss 0.20848175883293152
bi 3 loss 0.0291290283203125
Layer  6  loss:  0.17051933705806732 0.0 9.607969284057617
logits torch.Size([587, 4, 1024]) labels torch.Size([587, 4]) 0 1023
Curr loss timestep torch.Size([587, 4]) tensor([388, 355, 341, 170], device='cuda:0') tensor(355, device='cuda:0')
bi 0 loss 0.18697305023670197
bi 1 loss 0.20700833201408386
bi 2 loss 0.1640671044588089
bi 3 loss 0.061172567307949066
Epoch 0: :   3%|▎         | 15984/600000 [06:50<4:10:10, v_num=12, reduced_train_loss=0.767, global_step=1.6e+4, consumed_samples=63932.0, train_step_timing in s=0.397]Epoch 0: :   3%|▎         | 15984/600000 [06:50<4:10:10, v_num=12, reduced_train_loss=1.180, global_step=1.6e+4, consumed_samples=63936.0, train_step_timing in s=0.401]loss mask original None

First layer loss:  0.10574447363615036 torch.Size([618, 4]) 4.823156833648682 0.0
Max loss timestep torch.Size([618, 4]) tensor([345, 397, 579,  62], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.09831438958644867
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
bi 1 loss 0.04562468081712723
speech mask sum tensor(220, device='cuda:0') loss mask sum tensor(220, device='cuda:0')
bi 2 loss 0.16275982558727264
speech mask sum tensor(500, device='cuda:0') loss mask sum tensor(500, device='cuda:0')
bi 3 loss 0.05023449659347534
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
logits torch.Size([618, 4, 257024]) labels torch.Size([618, 4]) 0 257023
Layer  0  loss:  0.11653066426515579 0.0 7.867752552032471
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([426, 323, 580, 110], device='cuda:0') tensor(580, device='cuda:0')
bi 0 loss 0.12008228152990341
bi 1 loss 0.05533617362380028
bi 2 loss 0.17677029967308044
bi 3 loss 0.04110058397054672
Layer  1  loss:  0.12042039632797241 0.0 6.942911148071289
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([427, 319, 467,  59], device='cuda:0') tensor(467, device='cuda:0')
bi 0 loss 0.13587675988674164
bi 1 loss 0.058815423399209976
bi 2 loss 0.1732300966978073
bi 3 loss 0.04593471810221672
Layer  2  loss:  0.10514632612466812 0.0 10.197285652160645
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([345, 383, 491,  89], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.13043451309204102
bi 1 loss 0.0729108452796936
bi 2 loss 0.13824692368507385
bi 3 loss 0.03250698372721672
Layer  3  loss:  0.13127002120018005 0.0 12.609088897705078
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([345, 286, 578, 178], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.14830508828163147
bi 1 loss 0.06065952032804489
bi 2 loss 0.1802619993686676
bi 3 loss 0.07131575047969818
Layer  4  loss:  0.1435031145811081 0.0 11.610114097595215
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1022
Curr loss timestep torch.Size([618, 4]) tensor([345, 289, 578, 109], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.12728025019168854
bi 1 loss 0.06395217031240463
bi 2 loss 0.21909116208553314
bi 3 loss 0.07792976498603821
Layer  5  loss:  0.1457841992378235 0.0 9.095702171325684
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([345, 346, 579,  98], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.15088996291160583
bi 1 loss 0.0476577989757061
bi 2 loss 0.23128603398799896
bi 3 loss 0.04918871819972992
Layer  6  loss:  0.1424102485179901 0.0 12.65418815612793
logits torch.Size([618, 4, 1024]) labels torch.Size([618, 4]) 0 1023
Curr loss timestep torch.Size([618, 4]) tensor([345, 243, 578, 173], device='cuda:0') tensor(345, device='cuda:0')
bi 0 loss 0.2153717279434204
bi 1 loss 0.04399600625038147
bi 2 loss 0.1910637766122818
bi 3 loss 0.037571776658296585
Epoch 0: :   3%|▎         | 15985/600000 [06:51<4:10:26, v_num=12, reduced_train_loss=1.180, global_step=1.6e+4, consumed_samples=63936.0, train_step_timing in s=0.401]Epoch 0: :   3%|▎         | 15985/600000 [06:51<4:10:26, v_num=12, reduced_train_loss=1.010, global_step=1.6e+4, consumed_samples=63940.0, train_step_timing in s=0.415]loss mask original None

First layer loss:  0.16245914995670319 torch.Size([619, 4]) 14.140982627868652 0.0
Max loss timestep torch.Size([619, 4]) tensor([297, 361, 581, 405], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.03837180510163307
speech mask sum tensor(235, device='cuda:0') loss mask sum tensor(235, device='cuda:0')
bi 1 loss 0.0767589583992958
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
bi 2 loss 0.16700027883052826
speech mask sum tensor(452, device='cuda:0') loss mask sum tensor(452, device='cuda:0')
bi 3 loss 0.2607501149177551
speech mask sum tensor(499, device='cuda:0') loss mask sum tensor(499, device='cuda:0')
logits torch.Size([619, 4, 257024]) labels torch.Size([619, 4]) 0 257022
Layer  0  loss:  0.16732051968574524 0.0 12.531537055969238
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([331, 361, 581, 396], device='cuda:0') tensor(361, device='cuda:0')
bi 0 loss 0.05321108549833298
bi 1 loss 0.12205739319324493
bi 2 loss 0.16501405835151672
bi 3 loss 0.24636980891227722
Layer  1  loss:  0.18584994971752167 0.0 10.865525245666504
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([331, 317, 586, 553], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.090956911444664
bi 1 loss 0.11986568570137024
bi 2 loss 0.19435212016105652
bi 3 loss 0.2566893398761749
Layer  2  loss:  0.23166900873184204 0.0 12.79935073852539
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([328, 361, 578, 333], device='cuda:0') tensor(333, device='cuda:0')
bi 0 loss 0.1100020557641983
bi 1 loss 0.15897369384765625
bi 2 loss 0.22869481146335602
bi 3 loss 0.328955739736557
Layer  3  loss:  0.22470863163471222 0.0 13.563284873962402
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([328, 361, 581, 553], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.12193583697080612
bi 1 loss 0.1327797919511795
bi 2 loss 0.24108944833278656
bi 3 loss 0.30543258786201477
Layer  4  loss:  0.216223806142807 0.0 13.94998550415039
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1022
Curr loss timestep torch.Size([619, 4]) tensor([328, 361, 578, 550], device='cuda:0') tensor(343, device='cuda:0')
bi 0 loss 0.1433228850364685
bi 1 loss 0.13744227588176727
bi 2 loss 0.25432896614074707
bi 3 loss 0.25645676255226135
Layer  5  loss:  0.23438477516174316 0.0 15.227313995361328
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1023
Curr loss timestep torch.Size([619, 4]) tensor([328, 361, 581, 405], device='cuda:0') tensor(581, device='cuda:0')
bi 0 loss 0.135975182056427
bi 1 loss 0.09190261363983154
bi 2 loss 0.26213860511779785
bi 3 loss 0.32868725061416626
Layer  6  loss:  0.2243974804878235 0.0 14.038122177124023
logits torch.Size([619, 4, 1024]) labels torch.Size([619, 4]) 0 1020
Curr loss timestep torch.Size([619, 4]) tensor([328, 361, 586, 550], device='cuda:0') tensor(586, device='cuda:0')
bi 0 loss 0.1717725545167923
bi 1 loss 0.1342417299747467
bi 2 loss 0.2394620180130005
bi 3 loss 0.2817873954772949
Epoch 0: :   3%|▎         | 15986/600000 [06:51<4:10:41, v_num=12, reduced_train_loss=1.010, global_step=1.6e+4, consumed_samples=63940.0, train_step_timing in s=0.415]Epoch 0: :   3%|▎         | 15986/600000 [06:51<4:10:41, v_num=12, reduced_train_loss=1.650, global_step=1.6e+4, consumed_samples=63944.0, train_step_timing in s=0.433]loss mask original None

First layer loss:  0.02246999740600586 torch.Size([526, 4]) 1.098395824432373 0.0
Max loss timestep torch.Size([526, 4]) tensor([133, 283, 202, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.008596064522862434
speech mask sum tensor(81, device='cuda:0') loss mask sum tensor(81, device='cuda:0')
bi 1 loss 0.019191117957234383
speech mask sum tensor(292, device='cuda:0') loss mask sum tensor(292, device='cuda:0')
bi 2 loss 0.020065052434802055
speech mask sum tensor(82, device='cuda:0') loss mask sum tensor(82, device='cuda:0')
bi 3 loss 0.031233178451657295
speech mask sum tensor(260, device='cuda:0') loss mask sum tensor(260, device='cuda:0')
logits torch.Size([526, 4, 257024]) labels torch.Size([526, 4]) 0 257022
Layer  0  loss:  0.02155347354710102 0.0 1.343550205230713
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1023
Curr loss timestep torch.Size([526, 4]) tensor([114, 290, 206, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.010377478785812855
bi 1 loss 0.021032845601439476
bi 2 loss 0.0170251727104187
bi 3 loss 0.02704809047281742
Layer  1  loss:  0.02127186395227909 0.0 1.4630268812179565
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([114, 345, 192, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.009725994430482388
bi 1 loss 0.022539343684911728
bi 2 loss 0.0179384034126997
bi 3 loss 0.024496695026755333
Layer  2  loss:  0.022402869537472725 0.0 0.6890289783477783
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([ 97, 422, 181, 280], device='cuda:0') tensor(422, device='cuda:0')
bi 0 loss 0.016169480979442596
bi 1 loss 0.027110092341899872
bi 2 loss 0.01600603573024273
bi 3 loss 0.021075692027807236
Layer  3  loss:  0.018807344138622284 0.0 0.5626555681228638
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1018
Curr loss timestep torch.Size([526, 4]) tensor([109, 259, 204, 308], device='cuda:0') tensor(259, device='cuda:0')
bi 0 loss 0.013716906309127808
bi 1 loss 0.022244449704885483
bi 2 loss 0.012896665371954441
bi 3 loss 0.018397217616438866
Layer  4  loss:  0.022632258012890816 0.0 0.6061338782310486
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1021
Curr loss timestep torch.Size([526, 4]) tensor([145, 269, 201,  99], device='cuda:0') tensor(269, device='cuda:0')
bi 0 loss 0.010387979447841644
bi 1 loss 0.024227324873209
bi 2 loss 0.027102423831820488
bi 3 loss 0.023245614022016525
Layer  5  loss:  0.02613109163939953 0.0 2.435739040374756
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1023
Curr loss timestep torch.Size([526, 4]) tensor([137, 423, 206, 280], device='cuda:0') tensor(280, device='cuda:0')
bi 0 loss 0.012634754180908203
bi 1 loss 0.02517329901456833
bi 2 loss 0.019914137199521065
bi 3 loss 0.03337213024497032
Layer  6  loss:  0.021211212500929832 0.0 0.421718031167984
logits torch.Size([526, 4, 1024]) labels torch.Size([526, 4]) 0 1022
Curr loss timestep torch.Size([526, 4]) tensor([ 90, 472, 180, 337], device='cuda:0') tensor(90, device='cuda:0')
bi 0 loss 0.020107539370656013
bi 1 loss 0.022144468501210213
bi 2 loss 0.02190360613167286
bi 3 loss 0.020288560539484024
Epoch 0: :   3%|▎         | 15987/600000 [06:52<4:10:55, v_num=12, reduced_train_loss=1.650, global_step=1.6e+4, consumed_samples=63944.0, train_step_timing in s=0.433]Epoch 0: :   3%|▎         | 15987/600000 [06:52<4:10:55, v_num=12, reduced_train_loss=0.176, global_step=1.6e+4, consumed_samples=63948.0, train_step_timing in s=0.361]loss mask original None

First layer loss:  0.04939154535531998 torch.Size([506, 4]) 5.013277053833008 0.0
Max loss timestep torch.Size([506, 4]) tensor([201, 289, 272, 487], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.023794550448656082
speech mask sum tensor(185, device='cuda:0') loss mask sum tensor(185, device='cuda:0')
bi 1 loss 0.043644312769174576
speech mask sum tensor(162, device='cuda:0') loss mask sum tensor(162, device='cuda:0')
bi 2 loss 0.0680595263838768
speech mask sum tensor(165, device='cuda:0') loss mask sum tensor(165, device='cuda:0')
bi 3 loss 0.05623355880379677
speech mask sum tensor(378, device='cuda:0') loss mask sum tensor(378, device='cuda:0')
logits torch.Size([506, 4, 257024]) labels torch.Size([506, 4]) 0 257022
Layer  0  loss:  0.05999017879366875 0.0 5.691175937652588
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([ 90, 283, 270, 425], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.03267204761505127
bi 1 loss 0.029625294730067253
bi 2 loss 0.07792546600103378
bi 3 loss 0.07854478061199188
Layer  1  loss:  0.046115584671497345 0.0 5.828117847442627
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([155, 227, 270, 485], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.034044042229652405
bi 1 loss 0.04039262235164642
bi 2 loss 0.06882668286561966
bi 3 loss 0.04456274211406708
Layer  2  loss:  0.054715756326913834 0.0 5.011773109436035
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([122, 288, 271, 422], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.03381936252117157
bi 1 loss 0.03382781893014908
bi 2 loss 0.1130971759557724
bi 3 loss 0.048410844057798386
Layer  3  loss:  0.07105264067649841 0.0 8.618855476379395
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1021
Curr loss timestep torch.Size([506, 4]) tensor([154, 289, 270, 485], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.018807915970683098
bi 1 loss 0.0323181077837944
bi 2 loss 0.12876078486442566
bi 3 loss 0.08803259581327438
Layer  4  loss:  0.05318080261349678 0.0 8.695976257324219
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([161, 286, 270, 422], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.02633499540388584
bi 1 loss 0.0190757904201746
bi 2 loss 0.12318650633096695
bi 3 loss 0.05037801340222359
Layer  5  loss:  0.04272829368710518 0.0 6.293044090270996
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1022
Curr loss timestep torch.Size([506, 4]) tensor([ 94, 283, 271, 485], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.02280276268720627
bi 1 loss 0.04060444235801697
bi 2 loss 0.07342628389596939
bi 3 loss 0.039990514516830444
Layer  6  loss:  0.05557550489902496 0.0 8.033782005310059
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([126, 294, 270, 484], device='cuda:0') tensor(270, device='cuda:0')
bi 0 loss 0.021988214924931526
bi 1 loss 0.0305558480322361
bi 2 loss 0.13942182064056396
bi 3 loss 0.04613684490323067
Epoch 0: :   3%|▎         | 15988/600000 [06:52<4:11:08, v_num=12, reduced_train_loss=0.176, global_step=1.6e+4, consumed_samples=63948.0, train_step_timing in s=0.361]Epoch 0: :   3%|▎         | 15988/600000 [06:52<4:11:08, v_num=12, reduced_train_loss=0.433, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.355] loss mask original None

First layer loss:  0.07749932259321213 torch.Size([574, 4]) 8.11135196685791 0.0
Max loss timestep torch.Size([574, 4]) tensor([500,  96, 297, 217], device='cuda:0') tensor(500, device='cuda:0')
bi 0 loss 0.1289113163948059
speech mask sum tensor(418, device='cuda:0') loss mask sum tensor(418, device='cuda:0')
bi 1 loss 0.03266948461532593
speech mask sum tensor(210, device='cuda:0') loss mask sum tensor(210, device='cuda:0')
bi 2 loss 0.05501968041062355
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 3 loss 0.028726743534207344
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
logits torch.Size([574, 4, 257024]) labels torch.Size([574, 4]) 0 257022
Layer  0  loss:  0.08600842952728271 0.0 10.645821571350098
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1023
Curr loss timestep torch.Size([574, 4]) tensor([450, 149, 275, 102], device='cuda:0') tensor(450, device='cuda:0')
bi 0 loss 0.1408674269914627
bi 1 loss 0.04644738882780075
bi 2 loss 0.036188412457704544
bi 3 loss 0.046118415892124176
Layer  1  loss:  0.1008586585521698 0.0 13.251322746276855
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1023
Curr loss timestep torch.Size([574, 4]) tensor([452, 120, 266,  80], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.18956027925014496
bi 1 loss 0.03741028532385826
bi 2 loss 0.022464778274297714
bi 3 loss 0.03391685336828232
Layer  2  loss:  0.11364004760980606 0.0 13.188830375671387
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1022
Curr loss timestep torch.Size([574, 4]) tensor([450, 145, 297, 146], device='cuda:0') tensor(450, device='cuda:0')
bi 0 loss 0.20050789415836334
bi 1 loss 0.038698915392160416
bi 2 loss 0.07872174680233002
bi 3 loss 0.027682341635227203
Layer  3  loss:  0.11075932532548904 0.0 13.456402778625488
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1023
Curr loss timestep torch.Size([574, 4]) tensor([452, 241, 282, 209], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.18608374893665314
bi 1 loss 0.04361647367477417
bi 2 loss 0.07177817821502686
bi 3 loss 0.0461556576192379
Layer  4  loss:  0.10613943636417389 0.0 11.608297348022461
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1022
Curr loss timestep torch.Size([574, 4]) tensor([452, 183, 280, 136], device='cuda:0') tensor(452, device='cuda:0')
bi 0 loss 0.17065146565437317
bi 1 loss 0.06756244599819183
bi 2 loss 0.05118399113416672
bi 3 loss 0.04677658528089523
Layer  5  loss:  0.11529987305402756 0.0 11.537144660949707
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1022
Curr loss timestep torch.Size([574, 4]) tensor([450, 231, 210,  93], device='cuda:0') tensor(450, device='cuda:0')
bi 0 loss 0.2162552922964096
bi 1 loss 0.03346143290400505
bi 2 loss 0.0432431623339653
bi 3 loss 0.03590244799852371
Layer  6  loss:  0.08110711723566055 0.0 6.055359363555908
logits torch.Size([574, 4, 1024]) labels torch.Size([574, 4]) 0 1022
Curr loss timestep torch.Size([574, 4]) tensor([450, 137, 224, 184], device='cuda:0') tensor(450, device='cuda:0')
bi 0 loss 0.1180107593536377
bi 1 loss 0.058868158608675
bi 2 loss 0.05568074807524681
bi 3 loss 0.04225233569741249
Epoch 0: :   3%|▎         | 15989/600000 [06:52<4:11:23, v_num=12, reduced_train_loss=0.433, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.355]Epoch 0: :   3%|▎         | 15989/600000 [06:52<4:11:23, v_num=12, reduced_train_loss=0.791, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.400]loss mask original None

First layer loss:  0.1355363130569458 torch.Size([582, 4]) 12.804621696472168 0.0
Max loss timestep torch.Size([582, 4]) tensor([518, 461, 446, 218], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.1907709240913391
speech mask sum tensor(378, device='cuda:0') loss mask sum tensor(378, device='cuda:0')
bi 1 loss 0.13609890639781952
speech mask sum tensor(420, device='cuda:0') loss mask sum tensor(420, device='cuda:0')
bi 2 loss 0.13187645375728607
speech mask sum tensor(358, device='cuda:0') loss mask sum tensor(358, device='cuda:0')
bi 3 loss 0.0416749082505703
speech mask sum tensor(211, device='cuda:0') loss mask sum tensor(211, device='cuda:0')
logits torch.Size([582, 4, 257024]) labels torch.Size([582, 4]) 0 257022
Layer  0  loss:  0.15322476625442505 0.0 12.523299217224121
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([518, 461, 403, 199], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.2158927321434021
bi 1 loss 0.1647423356771469
bi 2 loss 0.1373535394668579
bi 3 loss 0.04495943710207939
Layer  1  loss:  0.1804875135421753 0.0 18.75147819519043
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([552, 461, 404,  81], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.2146735042333603
bi 1 loss 0.1795150339603424
bi 2 loss 0.23561443388462067
bi 3 loss 0.0276472344994545
Layer  2  loss:  0.17405250668525696 0.0 11.100399017333984
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([331, 461, 403, 138], device='cuda:0') tensor(461, device='cuda:0')
bi 0 loss 0.22742198407649994
bi 1 loss 0.15001176297664642
bi 2 loss 0.21289493143558502
bi 3 loss 0.060393158346414566
Layer  3  loss:  0.1795758605003357 0.0 13.406508445739746
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1021
Curr loss timestep torch.Size([582, 4]) tensor([327, 461, 405, 226], device='cuda:0') tensor(405, device='cuda:0')
bi 0 loss 0.2693541646003723
bi 1 loss 0.13465754687786102
bi 2 loss 0.22315581142902374
bi 3 loss 0.03421015664935112
Layer  4  loss:  0.16410945355892181 0.0 14.313831329345703
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1023
Curr loss timestep torch.Size([582, 4]) tensor([553, 461, 404, 154], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.22049470245838165
bi 1 loss 0.1485513597726822
bi 2 loss 0.19076448678970337
bi 3 loss 0.048840563744306564
Layer  5  loss:  0.18128174543380737 0.0 12.129242897033691
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([370, 461, 404, 126], device='cuda:0') tensor(404, device='cuda:0')
bi 0 loss 0.2730557918548584
bi 1 loss 0.14929133653640747
bi 2 loss 0.20915310084819794
bi 3 loss 0.03326010704040527
Layer  6  loss:  0.18548737466335297 0.0 14.358868598937988
logits torch.Size([582, 4, 1024]) labels torch.Size([582, 4]) 0 1022
Curr loss timestep torch.Size([582, 4]) tensor([335, 461, 405, 221], device='cuda:0') tensor(405, device='cuda:0')
bi 0 loss 0.23623226583003998
bi 1 loss 0.14486530423164368
bi 2 loss 0.2703102231025696
bi 3 loss 0.03152121230959892
Epoch 0: :   3%|▎         | 15990/600000 [06:53<4:11:38, v_num=12, reduced_train_loss=0.791, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.400]Epoch 0: :   3%|▎         | 15990/600000 [06:53<4:11:38, v_num=12, reduced_train_loss=1.350, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.399]loss mask original None

First layer loss:  0.08598954975605011 torch.Size([653, 4]) 11.51348876953125 0.0
Max loss timestep torch.Size([653, 4]) tensor([196, 606, 361,  63], device='cuda:0') tensor(606, device='cuda:0')
bi 0 loss 0.03836978226900101
speech mask sum tensor(160, device='cuda:0') loss mask sum tensor(160, device='cuda:0')
bi 1 loss 0.1405370533466339
speech mask sum tensor(469, device='cuda:0') loss mask sum tensor(469, device='cuda:0')
bi 2 loss 0.06861746311187744
speech mask sum tensor(330, device='cuda:0') loss mask sum tensor(330, device='cuda:0')
bi 3 loss 0.028836112469434738
speech mask sum tensor(214, device='cuda:0') loss mask sum tensor(214, device='cuda:0')
logits torch.Size([653, 4, 257024]) labels torch.Size([653, 4]) 0 257023
Layer  0  loss:  0.10098988562822342 0.0 13.892699241638184
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([178, 605, 307, 162], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.02702568843960762
bi 1 loss 0.1731165647506714
bi 2 loss 0.07988836616277695
bi 3 loss 0.030757946893572807
Layer  1  loss:  0.09629270434379578 0.0 11.430482864379883
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([182, 606, 336, 173], device='cuda:0') tensor(606, device='cuda:0')
bi 0 loss 0.0404595322906971
bi 1 loss 0.16628490388393402
bi 2 loss 0.06570706516504288
bi 3 loss 0.03180782496929169
Layer  2  loss:  0.0909346267580986 0.0 14.33655834197998
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([ 74, 606, 307,  75], device='cuda:0') tensor(606, device='cuda:0')
bi 0 loss 0.03786391392350197
bi 1 loss 0.1493670791387558
bi 2 loss 0.06153647601604462
bi 3 loss 0.047887373715639114
Layer  3  loss:  0.10433437675237656 0.0 23.96892547607422
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1020
Curr loss timestep torch.Size([653, 4]) tensor([163, 606, 347, 208], device='cuda:0') tensor(606, device='cuda:0')
bi 0 loss 0.04291124269366264
bi 1 loss 0.17792080342769623
bi 2 loss 0.07723703235387802
bi 3 loss 0.030772652477025986
Layer  4  loss:  0.09040763229131699 0.0 10.338604927062988
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1023
Curr loss timestep torch.Size([653, 4]) tensor([ 91, 605, 307,  63], device='cuda:0') tensor(605, device='cuda:0')
bi 0 loss 0.02898954227566719
bi 1 loss 0.13520346581935883
bi 2 loss 0.09631647914648056
bi 3 loss 0.02904186025261879
Layer  5  loss:  0.1000717282295227 0.0 11.469823837280273
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1022
Curr loss timestep torch.Size([653, 4]) tensor([127, 606, 307, 174], device='cuda:0') tensor(606, device='cuda:0')
bi 0 loss 0.03331577405333519
bi 1 loss 0.18096677958965302
bi 2 loss 0.061925750225782394
bi 3 loss 0.03151731193065643
Layer  6  loss:  0.11582313477993011 0.0 16.781925201416016
logits torch.Size([653, 4, 1024]) labels torch.Size([653, 4]) 0 1021
Curr loss timestep torch.Size([653, 4]) tensor([ 83, 606, 306, 111], device='cuda:0') tensor(606, device='cuda:0')
bi 0 loss 0.05446796864271164
bi 1 loss 0.1869000792503357
bi 2 loss 0.10027699172496796
bi 3 loss 0.029897794127464294
Epoch 0: :   3%|▎         | 15991/600000 [06:53<4:11:55, v_num=12, reduced_train_loss=1.350, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.399]Epoch 0: :   3%|▎         | 15991/600000 [06:53<4:11:55, v_num=12, reduced_train_loss=0.785, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.449]loss mask original None

First layer loss:  0.07527001202106476 torch.Size([506, 4]) 9.382356643676758 0.0
Max loss timestep torch.Size([506, 4]) tensor([100, 376, 129, 381], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.049353793263435364
speech mask sum tensor(94, device='cuda:0') loss mask sum tensor(94, device='cuda:0')
bi 1 loss 0.11726224422454834
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
bi 2 loss 0.03039800375699997
speech mask sum tensor(178, device='cuda:0') loss mask sum tensor(178, device='cuda:0')
bi 3 loss 0.06780765950679779
speech mask sum tensor(297, device='cuda:0') loss mask sum tensor(297, device='cuda:0')
logits torch.Size([506, 4, 257024]) labels torch.Size([506, 4]) 0 257023
Layer  0  loss:  0.0813523381948471 0.0 12.095174789428711
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([120, 377, 213, 381], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.023716308176517487
bi 1 loss 0.14810700714588165
bi 2 loss 0.021194545552134514
bi 3 loss 0.06799449026584625
Layer  1  loss:  0.07710608094930649 0.0 13.81391716003418
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([143, 377, 229, 374], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.029573963955044746
bi 1 loss 0.1544833928346634
bi 2 loss 0.038584236055612564
bi 3 loss 0.03681764379143715
Layer  2  loss:  0.09261679649353027 0.0 13.187801361083984
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([142, 377, 131, 381], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.0428449846804142
bi 1 loss 0.1387491077184677
bi 2 loss 0.0515655092895031
bi 3 loss 0.08621902018785477
Layer  3  loss:  0.08549627661705017 0.0 12.125658988952637
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1021
Curr loss timestep torch.Size([506, 4]) tensor([113, 374, 122, 381], device='cuda:0') tensor(374, device='cuda:0')
bi 0 loss 0.033641982823610306
bi 1 loss 0.16168242692947388
bi 2 loss 0.04676990956068039
bi 3 loss 0.047905564308166504
Layer  4  loss:  0.08860712498426437 0.0 11.307802200317383
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([100, 377, 137, 381], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.04715112969279289
bi 1 loss 0.17420944571495056
bi 2 loss 0.03537457808852196
bi 3 loss 0.04687635600566864
Layer  5  loss:  0.09666483104228973 0.0 12.089438438415527
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([ 69, 377, 163, 381], device='cuda:0') tensor(377, device='cuda:0')
bi 0 loss 0.03050142712891102
bi 1 loss 0.1420961618423462
bi 2 loss 0.051596201956272125
bi 3 loss 0.09857308864593506
Layer  6  loss:  0.09732881933450699 0.0 14.268329620361328
logits torch.Size([506, 4, 1024]) labels torch.Size([506, 4]) 0 1023
Curr loss timestep torch.Size([506, 4]) tensor([136, 376, 212, 381], device='cuda:0') tensor(376, device='cuda:0')
bi 0 loss 0.03978555649518967
bi 1 loss 0.179623082280159
bi 2 loss 0.04378346726298332
bi 3 loss 0.06422972679138184
Epoch 0: :   3%|▎         | 15992/600000 [06:54<4:12:08, v_num=12, reduced_train_loss=0.785, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.449]Epoch 0: :   3%|▎         | 15992/600000 [06:54<4:12:08, v_num=12, reduced_train_loss=0.694, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.354]loss mask original None

First layer loss:  0.20856714248657227 torch.Size([525, 4]) 16.235862731933594 0.0
Max loss timestep torch.Size([525, 4]) tensor([276, 275, 271, 349], device='cuda:0') tensor(271, device='cuda:0')
bi 0 loss 0.22791688144207
speech mask sum tensor(455, device='cuda:0') loss mask sum tensor(455, device='cuda:0')
bi 1 loss 0.052251849323511124
speech mask sum tensor(259, device='cuda:0') loss mask sum tensor(259, device='cuda:0')
bi 2 loss 0.2475503832101822
speech mask sum tensor(301, device='cuda:0') loss mask sum tensor(301, device='cuda:0')
bi 3 loss 0.2984210252761841
speech mask sum tensor(222, device='cuda:0') loss mask sum tensor(222, device='cuda:0')
logits torch.Size([525, 4, 257024]) labels torch.Size([525, 4]) 0 257022
Layer  0  loss:  0.22656042873859406 0.0 18.564895629882812
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([276, 277, 271, 347], device='cuda:0') tensor(276, device='cuda:0')
bi 0 loss 0.2692767381668091
bi 1 loss 0.07148221135139465
bi 2 loss 0.3117218017578125
bi 3 loss 0.20446927845478058
Layer  1  loss:  0.2485082596540451 0.0 18.42706298828125
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([277, 275, 271, 348], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.260680228471756
bi 1 loss 0.09722229838371277
bi 2 loss 0.3039622902870178
bi 3 loss 0.3248738944530487
Layer  2  loss:  0.25633102655410767 0.0 20.05487823486328
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1022
Curr loss timestep torch.Size([525, 4]) tensor([276, 284, 270, 349], device='cuda:0') tensor(349, device='cuda:0')
bi 0 loss 0.2613547444343567
bi 1 loss 0.08035773038864136
bi 2 loss 0.34368982911109924
bi 3 loss 0.33289095759391785
Layer  3  loss:  0.2403900921344757 0.0 20.300981521606445
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([275, 223, 371, 348], device='cuda:0') tensor(348, device='cuda:0')
bi 0 loss 0.2758702039718628
bi 1 loss 0.1007208377122879
bi 2 loss 0.289386123418808
bi 3 loss 0.26418766379356384
Layer  4  loss:  0.27487480640411377 0.0 18.497867584228516
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1022
Curr loss timestep torch.Size([525, 4]) tensor([277, 284, 272, 349], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.3318258821964264
bi 1 loss 0.09552903473377228
bi 2 loss 0.3297313153743744
bi 3 loss 0.29301002621650696
Layer  5  loss:  0.25976666808128357 0.0 19.515701293945312
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1023
Curr loss timestep torch.Size([525, 4]) tensor([277, 277, 270, 348], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.29179754853248596
bi 1 loss 0.06271062046289444
bi 2 loss 0.35539504885673523
bi 3 loss 0.2943582534790039
Layer  6  loss:  0.24572965502738953 0.0 20.376296997070312
logits torch.Size([525, 4, 1024]) labels torch.Size([525, 4]) 0 1021
Curr loss timestep torch.Size([525, 4]) tensor([277,  69, 272, 348], device='cuda:0') tensor(277, device='cuda:0')
bi 0 loss 0.2599306106567383
bi 1 loss 0.05507935211062431
bi 2 loss 0.33037689328193665
bi 3 loss 0.3242800235748291
Epoch 0: :   3%|▎         | 15993/600000 [06:54<4:12:22, v_num=12, reduced_train_loss=0.694, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.354]Epoch 0: :   3%|▎         | 15993/600000 [06:54<4:12:22, v_num=12, reduced_train_loss=1.960, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.364]loss mask original None

First layer loss:  0.056055452674627304 torch.Size([521, 4]) 3.864853620529175 0.0
Max loss timestep torch.Size([521, 4]) tensor([114, 284, 414, 303], device='cuda:0') tensor(414, device='cuda:0')
bi 0 loss 0.020122986286878586
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 1 loss 0.04484008625149727
speech mask sum tensor(151, device='cuda:0') loss mask sum tensor(151, device='cuda:0')
bi 2 loss 0.05929607152938843
speech mask sum tensor(403, device='cuda:0') loss mask sum tensor(403, device='cuda:0')
bi 3 loss 0.09848873317241669
speech mask sum tensor(137, device='cuda:0') loss mask sum tensor(137, device='cuda:0')
logits torch.Size([521, 4, 257024]) labels torch.Size([521, 4]) 0 257023
Layer  0  loss:  0.06490028649568558 0.0 6.751999855041504
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1023
Curr loss timestep torch.Size([521, 4]) tensor([199, 260, 498, 303], device='cuda:0') tensor(498, device='cuda:0')
bi 0 loss 0.031322382390499115
bi 1 loss 0.04848819226026535
bi 2 loss 0.07611885666847229
bi 3 loss 0.08699813485145569
Layer  1  loss:  0.06666085124015808 0.0 10.428206443786621
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([199, 184, 498, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.03573980554938316
bi 1 loss 0.036402296274900436
bi 2 loss 0.06957055628299713
bi 3 loss 0.12553317844867706
Layer  2  loss:  0.0626218169927597 0.0 8.164515495300293
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([145, 217, 447, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.03769718110561371
bi 1 loss 0.03270746022462845
bi 2 loss 0.06418262422084808
bi 3 loss 0.11847350001335144
Layer  3  loss:  0.06096065789461136 0.0 2.6543378829956055
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1017
Curr loss timestep torch.Size([521, 4]) tensor([144, 205, 151, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.04608269780874252
bi 1 loss 0.028803572058677673
bi 2 loss 0.06488170474767685
bi 3 loss 0.10126801580190659
Layer  4  loss:  0.06605065613985062 0.0 9.688630104064941
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([206, 259, 499, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.040989700704813004
bi 1 loss 0.06166410818696022
bi 2 loss 0.06137329339981079
bi 3 loss 0.11226637661457062
Layer  5  loss:  0.08427398651838303 0.0 11.93961238861084
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1022
Curr loss timestep torch.Size([521, 4]) tensor([119, 247, 499, 303], device='cuda:0') tensor(303, device='cuda:0')
bi 0 loss 0.03347163274884224
bi 1 loss 0.042228735983371735
bi 2 loss 0.08763319253921509
bi 3 loss 0.17672815918922424
Layer  6  loss:  0.07654216140508652 0.0 8.286885261535645
logits torch.Size([521, 4, 1024]) labels torch.Size([521, 4]) 0 1023
Curr loss timestep torch.Size([521, 4]) tensor([121, 300, 499, 303], device='cuda:0') tensor(499, device='cuda:0')
bi 0 loss 0.037054695188999176
bi 1 loss 0.0379197858273983
bi 2 loss 0.10081581026315689
bi 3 loss 0.09123052656650543
Epoch 0: :   3%|▎         | 15994/600000 [06:55<4:12:36, v_num=12, reduced_train_loss=1.960, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.364]Epoch 0: :   3%|▎         | 15994/600000 [06:55<4:12:36, v_num=12, reduced_train_loss=0.538, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.365]loss mask original None

First layer loss:  0.20957285165786743 torch.Size([775, 4]) 12.415512084960938 0.0
Max loss timestep torch.Size([775, 4]) tensor([ 51, 164, 615, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.021601855754852295
speech mask sum tensor(65, device='cuda:0') loss mask sum tensor(65, device='cuda:0')
bi 1 loss 0.028241369873285294
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 2 loss 0.17239227890968323
speech mask sum tensor(406, device='cuda:0') loss mask sum tensor(406, device='cuda:0')
bi 3 loss 0.3039990961551666
speech mask sum tensor(416, device='cuda:0') loss mask sum tensor(416, device='cuda:0')
logits torch.Size([775, 4, 257024]) labels torch.Size([775, 4]) 0 257023
Layer  0  loss:  0.29111912846565247 0.0 9.594738960266113
logits torch.Size([775, 4, 1024]) labels torch.Size([775, 4]) 0 1023
Curr loss timestep torch.Size([775, 4]) tensor([ 75, 161, 450, 650], device='cuda:0') tensor(672, device='cuda:0')
bi 0 loss 0.03569526597857475
bi 1 loss 0.06278791278600693
bi 2 loss 0.25401410460472107
bi 3 loss 0.4034677743911743
Layer  1  loss:  0.28679555654525757 0.0 9.777042388916016
logits torch.Size([775, 4, 1024]) labels torch.Size([775, 4]) 0 1023
Curr loss timestep torch.Size([775, 4]) tensor([ 66, 154, 615, 570], device='cuda:0') tensor(671, device='cuda:0')
bi 0 loss 0.02482197806239128
bi 1 loss 0.07666361331939697
bi 2 loss 0.3269464373588562
bi 3 loss 0.3218814432621002
Layer  2  loss:  0.32986801862716675 0.0 17.484481811523438
logits torch.Size([775, 4, 1024]) labels torch.Size([775, 4]) 0 1022
Curr loss timestep torch.Size([775, 4]) tensor([ 59, 170, 672, 582], device='cuda:0') tensor(582, device='cuda:0')
bi 0 loss 0.054421719163656235
bi 1 loss 0.07498274743556976
bi 2 loss 0.314177006483078
bi 3 loss 0.4286589026451111
Layer  3  loss:  0.3607391119003296 0.0 14.539849281311035
logits torch.Size([775, 4, 1024]) labels torch.Size([775, 4]) 0 1022
Curr loss timestep torch.Size([775, 4]) tensor([ 81, 145, 404, 570], device='cuda:0') tensor(570, device='cuda:0')
bi 0 loss 0.060654427856206894
bi 1 loss 0.07556922733783722
bi 2 loss 0.30855944752693176
bi 3 loss 0.5037959218025208
Layer  4  loss:  0.3555618226528168 0.0 12.308805465698242
logits torch.Size([775, 4, 1024]) labels torch.Size([775, 4]) 0 1023
Curr loss timestep torch.Size([775, 4]) tensor([ 90, 144, 672, 582], device='cuda:0') tensor(672, device='cuda:0')
bi 0 loss 0.042790401726961136
bi 1 loss 0.05663745105266571
bi 2 loss 0.3397332429885864
bi 3 loss 0.46730583906173706
Layer  5  loss:  0.3355420231819153 0.0 14.67475414276123
logits torch.Size([775, 4, 1024]) labels torch.Size([775, 4]) 0 1023
Curr loss timestep torch.Size([775, 4]) tensor([ 75, 165, 615, 569], device='cuda:0') tensor(615, device='cuda:0')
bi 0 loss 0.05131973326206207
bi 1 loss 0.06975468248128891
bi 2 loss 0.2638152241706848
bi 3 loss 0.4921225309371948
Layer  6  loss:  0.3639398217201233 0.0 11.990297317504883
logits torch.Size([775, 4, 1024]) labels torch.Size([775, 4]) 0 1023
Curr loss timestep torch.Size([775, 4]) tensor([ 71, 143, 679, 585], device='cuda:0') tensor(672, device='cuda:0')
bi 0 loss 0.02244381606578827
bi 1 loss 0.07769395411014557
bi 2 loss 0.28743988275527954
bi 3 loss 0.5373736023902893
Epoch 0: :   3%|▎         | 15995/600000 [06:55<4:12:55, v_num=12, reduced_train_loss=0.538, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.365]Epoch 0: :   3%|▎         | 15995/600000 [06:55<4:12:55, v_num=12, reduced_train_loss=2.530, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.527]loss mask original None

First layer loss:  0.2824268639087677 torch.Size([666, 4]) 11.362767219543457 0.0
Max loss timestep torch.Size([666, 4]) tensor([405, 122, 521, 589], device='cuda:0') tensor(405, device='cuda:0')
bi 0 loss 0.23421159386634827
speech mask sum tensor(464, device='cuda:0') loss mask sum tensor(464, device='cuda:0')
bi 1 loss 0.021249443292617798
speech mask sum tensor(66, device='cuda:0') loss mask sum tensor(66, device='cuda:0')
bi 2 loss 0.1893986314535141
speech mask sum tensor(273, device='cuda:0') loss mask sum tensor(273, device='cuda:0')
bi 3 loss 0.4132242798805237
speech mask sum tensor(497, device='cuda:0') loss mask sum tensor(497, device='cuda:0')
logits torch.Size([666, 4, 257024]) labels torch.Size([666, 4]) 0 257023
Layer  0  loss:  0.40514084696769714 0.0 17.598630905151367
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([393, 107, 521, 325], device='cuda:0') tensor(325, device='cuda:0')
bi 0 loss 0.2932947874069214
bi 1 loss 0.04922192543745041
bi 2 loss 0.3018817603588104
bi 3 loss 0.6135451793670654
Layer  1  loss:  0.3986181616783142 0.0 20.594762802124023
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([392, 111, 522, 586], device='cuda:0') tensor(392, device='cuda:0')
bi 0 loss 0.3782322406768799
bi 1 loss 0.03633912652730942
bi 2 loss 0.21302935481071472
bi 3 loss 0.5677030682563782
Layer  2  loss:  0.43644315004348755 0.0 18.330480575561523
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1022
Curr loss timestep torch.Size([666, 4]) tensor([392, 118, 522, 591], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.3709529638290405
bi 1 loss 0.015250494703650475
bi 2 loss 0.3224148750305176
bi 3 loss 0.6161531805992126
Layer  3  loss:  0.461124986410141 0.0 16.434280395507812
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([393, 120, 522, 449], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.4369114637374878
bi 1 loss 0.03023645654320717
bi 2 loss 0.3196779787540436
bi 3 loss 0.618647575378418
Layer  4  loss:  0.4619106352329254 0.0 17.301607131958008
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1022
Curr loss timestep torch.Size([666, 4]) tensor([393, 134, 522, 591], device='cuda:0') tensor(518, device='cuda:0')
bi 0 loss 0.4056015610694885
bi 1 loss 0.04697562754154205
bi 2 loss 0.33024710416793823
bi 3 loss 0.6419051289558411
Layer  5  loss:  0.48158878087997437 0.0 16.390716552734375
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([393, 112, 522, 324], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.4488270878791809
bi 1 loss 0.03456636518239975
bi 2 loss 0.36066892743110657
bi 3 loss 0.6379592418670654
Layer  6  loss:  0.48582497239112854 0.0 17.200645446777344
logits torch.Size([666, 4, 1024]) labels torch.Size([666, 4]) 0 1023
Curr loss timestep torch.Size([666, 4]) tensor([392, 116, 307, 449], device='cuda:0') tensor(522, device='cuda:0')
bi 0 loss 0.44199055433273315
bi 1 loss 0.062222857028245926
bi 2 loss 0.27929988503456116
bi 3 loss 0.6964451670646667
Epoch 0: :   3%|▎         | 15996/600000 [06:56<4:13:12, v_num=12, reduced_train_loss=2.530, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.527]Epoch 0: :   3%|▎         | 15996/600000 [06:56<4:13:12, v_num=12, reduced_train_loss=3.410, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.454]loss mask original None

First layer loss:  0.016214987263083458 torch.Size([371, 4]) 0.7354860305786133 0.0
Max loss timestep torch.Size([371, 4]) tensor([272, 163, 138, 152], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.020110415294766426
speech mask sum tensor(297, device='cuda:0') loss mask sum tensor(297, device='cuda:0')
bi 1 loss 0.013793185353279114
speech mask sum tensor(172, device='cuda:0') loss mask sum tensor(172, device='cuda:0')
bi 2 loss 0.012098134495317936
speech mask sum tensor(177, device='cuda:0') loss mask sum tensor(177, device='cuda:0')
bi 3 loss 0.016122786328196526
speech mask sum tensor(127, device='cuda:0') loss mask sum tensor(127, device='cuda:0')
logits torch.Size([371, 4, 257024]) labels torch.Size([371, 4]) 0 257023
Layer  0  loss:  0.020071981474757195 0.0 2.542513608932495
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([232, 119,  89, 101], device='cuda:0') tensor(89, device='cuda:0')
bi 0 loss 0.021675297990441322
bi 1 loss 0.016195176169276237
bi 2 loss 0.023971889168024063
bi 3 loss 0.01613767258822918
Layer  1  loss:  0.017082344740629196 0.0 0.9043516516685486
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([272, 217, 149,  72], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.021073216572403908
bi 1 loss 0.017210472375154495
bi 2 loss 0.012002733536064625
bi 3 loss 0.014655292965471745
Layer  2  loss:  0.02327668108046055 0.0 3.859905481338501
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([272, 180, 186, 124], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.03076111152768135
bi 1 loss 0.01719333603978157
bi 2 loss 0.013376785442233086
bi 3 loss 0.027810074388980865
Layer  3  loss:  0.01869186945259571 0.0 1.7203631401062012
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1022
Curr loss timestep torch.Size([371, 4]) tensor([272, 193, 186,  98], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.02429165504872799
bi 1 loss 0.01760280504822731
bi 2 loss 0.012500499375164509
bi 3 loss 0.015700167044997215
Layer  4  loss:  0.020865194499492645 0.0 3.662564754486084
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1023
Curr loss timestep torch.Size([371, 4]) tensor([272, 255,  96,  75], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.029791854321956635
bi 1 loss 0.016386352479457855
bi 2 loss 0.01212084386497736
bi 3 loss 0.01824232004582882
Layer  5  loss:  0.016317754983901978 0.0 0.6711675524711609
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1020
Curr loss timestep torch.Size([371, 4]) tensor([272, 239, 151,  91], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.017118379473686218
bi 1 loss 0.01583455130457878
bi 2 loss 0.01326410286128521
bi 3 loss 0.01935572177171707
Layer  6  loss:  0.020546481013298035 0.0 3.626967668533325
logits torch.Size([371, 4, 1024]) labels torch.Size([371, 4]) 0 1020
Curr loss timestep torch.Size([371, 4]) tensor([272, 181,  90, 123], device='cuda:0') tensor(272, device='cuda:0')
bi 0 loss 0.027504300698637962
bi 1 loss 0.020131124183535576
bi 2 loss 0.01353234238922596
bi 3 loss 0.014613175764679909
Epoch 0: :   3%|▎         | 15997/600000 [06:56<4:13:23, v_num=12, reduced_train_loss=3.410, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.454]Epoch 0: :   3%|▎         | 15997/600000 [06:56<4:13:23, v_num=12, reduced_train_loss=0.153, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.288]loss mask original None

First layer loss:  0.04763233661651611 torch.Size([413, 4]) 7.12734317779541 0.0
Max loss timestep torch.Size([413, 4]) tensor([322, 181, 299, 371], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.03811677172780037
speech mask sum tensor(218, device='cuda:0') loss mask sum tensor(218, device='cuda:0')
bi 1 loss 0.040254730731248856
speech mask sum tensor(274, device='cuda:0') loss mask sum tensor(274, device='cuda:0')
bi 2 loss 0.06272897124290466
speech mask sum tensor(231, device='cuda:0') loss mask sum tensor(231, device='cuda:0')
bi 3 loss 0.05000942945480347
speech mask sum tensor(256, device='cuda:0') loss mask sum tensor(256, device='cuda:0')
logits torch.Size([413, 4, 257024]) labels torch.Size([413, 4]) 0 257022
Layer  0  loss:  0.06161431968212128 0.0 9.362807273864746
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1023
Curr loss timestep torch.Size([413, 4]) tensor([322, 144, 299, 387], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.04250452667474747
bi 1 loss 0.0351259671151638
bi 2 loss 0.08082009851932526
bi 3 loss 0.08890809863805771
Layer  1  loss:  0.07141578942537308 0.0 7.096764087677002
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1023
Curr loss timestep torch.Size([413, 4]) tensor([322, 310, 299, 384], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.05841179937124252
bi 1 loss 0.06433649361133575
bi 2 loss 0.07944029569625854
bi 3 loss 0.08282570540904999
Layer  2  loss:  0.06548434495925903 0.0 10.316237449645996
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([321, 136, 299, 387], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.044888414442539215
bi 1 loss 0.04206825792789459
bi 2 loss 0.09003027528524399
bi 3 loss 0.08593674004077911
Layer  3  loss:  0.05482550710439682 0.0 10.831427574157715
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1022
Curr loss timestep torch.Size([413, 4]) tensor([322, 193, 299, 402], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.04793574661016464
bi 1 loss 0.03397621959447861
bi 2 loss 0.09336481243371964
bi 3 loss 0.04823211580514908
Layer  4  loss:  0.05864550545811653 0.0 9.434768676757812
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1023
Curr loss timestep torch.Size([413, 4]) tensor([306, 274, 299, 327], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.038407281041145325
bi 1 loss 0.048800621181726456
bi 2 loss 0.09582970291376114
bi 3 loss 0.05286378785967827
Layer  5  loss:  0.06393152475357056 0.0 6.985554218292236
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1019
Curr loss timestep torch.Size([413, 4]) tensor([322, 304, 299, 387], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.0613432414829731
bi 1 loss 0.0449436753988266
bi 2 loss 0.06871070712804794
bi 3 loss 0.08214609324932098
Layer  6  loss:  0.09169135242700577 0.0 11.778410911560059
logits torch.Size([413, 4, 1024]) labels torch.Size([413, 4]) 0 1020
Curr loss timestep torch.Size([413, 4]) tensor([321, 110, 299, 348], device='cuda:0') tensor(299, device='cuda:0')
bi 0 loss 0.07395263016223907
bi 1 loss 0.029518375173211098
bi 2 loss 0.10365641117095947
bi 3 loss 0.16254490613937378
Epoch 0: :   3%|▎         | 15998/600000 [06:56<4:13:36, v_num=12, reduced_train_loss=0.153, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.288]Epoch 0: :   3%|▎         | 15998/600000 [06:56<4:13:36, v_num=12, reduced_train_loss=0.515, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.332]loss mask original None

First layer loss:  0.03040999546647072 torch.Size([410, 4]) 1.9462432861328125 0.0
Max loss timestep torch.Size([410, 4]) tensor([383, 299, 283, 100], device='cuda:0') tensor(283, device='cuda:0')
bi 0 loss 0.04149849712848663
speech mask sum tensor(314, device='cuda:0') loss mask sum tensor(314, device='cuda:0')
bi 1 loss 0.0200507752597332
speech mask sum tensor(340, device='cuda:0') loss mask sum tensor(340, device='cuda:0')
bi 2 loss 0.033548980951309204
speech mask sum tensor(239, device='cuda:0') loss mask sum tensor(239, device='cuda:0')
bi 3 loss 0.01877276971936226
speech mask sum tensor(61, device='cuda:0') loss mask sum tensor(61, device='cuda:0')
logits torch.Size([410, 4, 257024]) labels torch.Size([410, 4]) 0 257022
Layer  0  loss:  0.028192205354571342 0.0 1.0091650485992432
logits torch.Size([410, 4, 1024]) labels torch.Size([410, 4]) 0 1023
Curr loss timestep torch.Size([410, 4]) tensor([365, 187, 299,  82], device='cuda:0') tensor(187, device='cuda:0')
bi 0 loss 0.0390072800219059
bi 1 loss 0.02039797231554985
bi 2 loss 0.026870515197515488
bi 3 loss 0.021142857149243355
Layer  1  loss:  0.0311964750289917 0.0 1.5755997896194458
logits torch.Size([410, 4, 1024]) labels torch.Size([410, 4]) 0 1022
Curr loss timestep torch.Size([410, 4]) tensor([379, 260, 168,  80], device='cuda:0') tensor(379, device='cuda:0')
bi 0 loss 0.0446229912340641
bi 1 loss 0.021053936332464218
bi 2 loss 0.031024474650621414
bi 3 loss 0.01928899437189102
Layer  2  loss:  0.03717827424407005 0.0 3.61569881439209
logits torch.Size([410, 4, 1024]) labels torch.Size([410, 4]) 0 1022
Curr loss timestep torch.Size([410, 4]) tensor([339, 258, 283,  76], device='cuda:0') tensor(339, device='cuda:0')
bi 0 loss 0.05433104559779167
bi 1 loss 0.025709325447678566
bi 2 loss 0.03309075906872749
bi 3 loss 0.028824016451835632
Layer  3  loss:  0.034841254353523254 0.0 4.394737243652344
logits torch.Size([410, 4, 1024]) labels torch.Size([410, 4]) 0 1020
Curr loss timestep torch.Size([410, 4]) tensor([400, 164, 283, 104], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.0525873564183712
bi 1 loss 0.017829369753599167
bi 2 loss 0.04141436517238617
bi 3 loss 0.012559138238430023
Layer  4  loss:  0.03747272118926048 0.0 4.644314289093018
logits torch.Size([410, 4, 1024]) labels torch.Size([410, 4]) 0 1022
Curr loss timestep torch.Size([410, 4]) tensor([400, 332, 101,  99], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.06972058862447739
bi 1 loss 0.022884652018547058
bi 2 loss 0.02254113368690014
bi 3 loss 0.01128854788839817
Layer  5  loss:  0.032051701098680496 0.0 6.759914875030518
logits torch.Size([410, 4, 1024]) labels torch.Size([410, 4]) 0 1023
Curr loss timestep torch.Size([410, 4]) tensor([400, 276, 211, 105], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.05699847266077995
bi 1 loss 0.021609485149383545
bi 2 loss 0.019252609461545944
bi 3 loss 0.011986947618424892
Layer  6  loss:  0.035302240401506424 0.0 4.4538469314575195
logits torch.Size([410, 4, 1024]) labels torch.Size([410, 4]) 0 1023
Curr loss timestep torch.Size([410, 4]) tensor([400,  95, 172,  77], device='cuda:0') tensor(400, device='cuda:0')
bi 0 loss 0.057235658168792725
bi 1 loss 0.017668236047029495
bi 2 loss 0.03445131704211235
bi 3 loss 0.02402089536190033
Epoch 0: :   3%|▎         | 15999/600000 [06:57<4:13:47, v_num=12, reduced_train_loss=0.515, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.332]Epoch 0: :   3%|▎         | 15999/600000 [06:57<4:13:47, v_num=12, reduced_train_loss=0.267, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.307]loss mask original None

First layer loss:  0.11492523550987244 torch.Size([638, 4]) 9.029711723327637 0.0
Max loss timestep torch.Size([638, 4]) tensor([353, 221,  69, 345], device='cuda:0') tensor(353, device='cuda:0')
bi 0 loss 0.1745348572731018
speech mask sum tensor(450, device='cuda:0') loss mask sum tensor(450, device='cuda:0')
bi 1 loss 0.060079425573349
speech mask sum tensor(96, device='cuda:0') loss mask sum tensor(96, device='cuda:0')
bi 2 loss 0.030421718955039978
speech mask sum tensor(77, device='cuda:0') loss mask sum tensor(77, device='cuda:0')
bi 3 loss 0.05917570739984512
speech mask sum tensor(270, device='cuda:0') loss mask sum tensor(270, device='cuda:0')
logits torch.Size([638, 4, 257024]) labels torch.Size([638, 4]) 0 257023
Layer  0  loss:  0.131322979927063 0.0 7.873395919799805
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1023
Curr loss timestep torch.Size([638, 4]) tensor([573, 215,  66, 366], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.16864173114299774
bi 1 loss 0.062402427196502686
bi 2 loss 0.04428062587976456
bi 3 loss 0.11845336854457855
Layer  1  loss:  0.11739030480384827 0.0 13.198172569274902
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([615, 227,  73, 369], device='cuda:0') tensor(615, device='cuda:0')
bi 0 loss 0.17594270408153534
bi 1 loss 0.03208792954683304
bi 2 loss 0.04304976761341095
bi 3 loss 0.07133349776268005
Layer  2  loss:  0.1225137859582901 0.0 7.872600078582764
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([573, 173,  40, 277], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.16517865657806396
bi 1 loss 0.031216122210025787
bi 2 loss 0.052923791110515594
bi 3 loss 0.10371307283639908
Layer  3  loss:  0.12272797524929047 0.0 8.288349151611328
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([615, 194,  77, 366], device='cuda:0') tensor(615, device='cuda:0')
bi 0 loss 0.1849624663591385
bi 1 loss 0.05230516195297241
bi 2 loss 0.026736067607998848
bi 3 loss 0.07141853123903275
Layer  4  loss:  0.13022145628929138 0.0 8.778898239135742
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1018
Curr loss timestep torch.Size([638, 4]) tensor([531, 214,  42, 277], device='cuda:0') tensor(531, device='cuda:0')
bi 0 loss 0.1873132288455963
bi 1 loss 0.05504116788506508
bi 2 loss 0.05296147242188454
bi 3 loss 0.08383266627788544
Layer  5  loss:  0.16748365759849548 0.0 11.177762031555176
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([449, 222,  46, 366], device='cuda:0') tensor(449, device='cuda:0')
bi 0 loss 0.2371007651090622
bi 1 loss 0.040765974670648575
bi 2 loss 0.039862532168626785
bi 3 loss 0.1329060047864914
Layer  6  loss:  0.13799749314785004 0.0 10.291253089904785
logits torch.Size([638, 4, 1024]) labels torch.Size([638, 4]) 0 1022
Curr loss timestep torch.Size([638, 4]) tensor([573, 188,  76, 367], device='cuda:0') tensor(573, device='cuda:0')
bi 0 loss 0.18623144924640656
bi 1 loss 0.04703785106539726
bi 2 loss 0.07003599405288696
bi 3 loss 0.10933040827512741
Epoch 0: :   3%|▎         | 16000/600000 [06:57<4:14:03, v_num=12, reduced_train_loss=0.267, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.307]Epoch 0: :   3%|▎         | 16000/600000 [06:57<4:14:03, v_num=12, reduced_train_loss=1.040, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.435]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/50 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/50 [00:00<?, ?it/s][Aloss mask original None
Epoch 0: :   3%|▎         | 16000/600000 [07:21<4:28:41, v_num=12, reduced_train_loss=1.040, global_step=1.6e+4, consumed_samples=6.4e+4, train_step_timing in s=0.435]

                                                               [A