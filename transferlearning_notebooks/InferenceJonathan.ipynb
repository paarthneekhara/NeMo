{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a325d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from nemo.collections.tts.models import FastPitchModel\n",
    "from nemo.collections.tts.modules.hifigan_modules import Generator as Hifigan_generator\n",
    "from nemo.collections.asr.modules import AudioToMelSpectrogramPreprocessor\n",
    "from nemo.collections.asr.parts.preprocessing.features import WaveformFeaturizer\n",
    "from nemo.collections.tts.models import HifiGanModel\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(spec_gen_model, vocoder_model, str_input, speaker=None):\n",
    "    parser_model = spec_gen_model\n",
    "    with torch.no_grad():\n",
    "        parsed = parser_model.parse(str_input)\n",
    "        if speaker is not None:\n",
    "            speaker = torch.tensor([speaker]).long().cuda()\n",
    "        spectrogram = spec_gen_model.generate_spectrogram(tokens=parsed, speaker = speaker)\n",
    "        if isinstance(vocoder_model, Hifigan_generator):\n",
    "            audio = vocoder_model(x=spectrogram.half()).squeeze(1)\n",
    "        else:\n",
    "            audio = vocoder_model.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "        \n",
    "    if spectrogram is not None:\n",
    "        if isinstance(spectrogram, torch.Tensor):\n",
    "            spectrogram = spectrogram.to('cpu').numpy()\n",
    "        if len(spectrogram.shape) == 3:\n",
    "            spectrogram = spectrogram[0]\n",
    "    if isinstance(audio, torch.Tensor):\n",
    "        audio = audio.to('cpu').numpy()\n",
    "    return spectrogram, audio\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_best_ckpt_from_experiment(exp_dir):\n",
    "    ckpt_candidates = []\n",
    "    last_ckpt = None\n",
    "    for root, dirs, files in os.walk(exp_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ckpt\"):\n",
    "                try:\n",
    "                    val_error = float(file.split(\"v_loss=\")[1].split(\"-epoch\")[0])\n",
    "                except:\n",
    "                    val_error = 0.0\n",
    "                if \"last\" in file:\n",
    "                    last_ckpt = os.path.join(root, file)\n",
    "                ckpt_candidates.append( (val_error, os.path.join(root, file)))\n",
    "    ckpt_candidates.sort()\n",
    "    \n",
    "#     return ckpt_candidates, last_ckpt\n",
    "    return ckpt_candidates, ckpt_candidates[0][1]\n",
    "\n",
    "wav_featurizer = WaveformFeaturizer(sample_rate=44100, int_values=False, augmentor=None)\n",
    "mel_processor = AudioToMelSpectrogramPreprocessor(\n",
    "        window_size = None,\n",
    "        window_stride = None,\n",
    "        sample_rate=44100,\n",
    "        n_window_size=2048,\n",
    "        n_window_stride=512,\n",
    "        window=\"hann\",\n",
    "        normalize=None,\n",
    "        n_fft=None,\n",
    "        preemph=None,\n",
    "        features=80,\n",
    "        lowfreq=0,\n",
    "        highfreq=None,\n",
    "        log=True,\n",
    "        log_zero_guard_type=\"add\",\n",
    "        log_zero_guard_value=1e-05,\n",
    "        dither=0.0,\n",
    "        pad_to=1,\n",
    "        frame_splicing=1,\n",
    "        exact_pad=False,\n",
    "        stft_exact_pad=False,\n",
    "        stft_conv=False,\n",
    "        pad_value=0,\n",
    "        mag_power=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa26a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthesis_models(fastpitch_model_path, hifigan_model_path):\n",
    "    print (fastpitch_model_path)\n",
    "    print (hifigan_model_path)\n",
    "    spec_model = FastPitchModel.load_from_checkpoint(fastpitch_model_path)\n",
    "    spec_model.cuda().eval()\n",
    "    vocoder = HifiGanModel.load_from_checkpoint(hifigan_model_path)\n",
    "    vocoder.cuda().eval()\n",
    "    \n",
    "    return spec_model, vocoder\n",
    "\n",
    "def play_validation_samples(spec_model, vocoder):\n",
    "    val_manifest_file = \"/home/pneekhara/JonData/val_list.json\"\n",
    "    with open(val_manifest_file) as f:\n",
    "        all_lines = f.read().split(\"\\n\")\n",
    "        for lidx, line in enumerate(all_lines):\n",
    "            if len(line) > 0:\n",
    "                record = json.loads(line)\n",
    "                text_to_generate = record['text']\n",
    "                #print (text_to_generate)\n",
    "                print(\"Jon's actual voice\")\n",
    "                ipd.display(ipd.Audio(record['audio_filepath']))\n",
    "\n",
    "                real_wav = wav_featurizer.process(record['audio_filepath'])\n",
    "                real_mel, _ = mel_processor.get_features(real_wav[None], torch.tensor([[real_wav.shape[0]]]).long() )\n",
    "                real_mel = real_mel[0]\n",
    "                real_mel = real_mel.cuda()\n",
    "                with torch.no_grad():\n",
    "                    vocoded_audio_real = vocoder.convert_spectrogram_to_audio(spec=real_mel).cpu().numpy()\n",
    "                    print(\"Ground truh spectrogram vocoded (HiFiGAN):\")\n",
    "                    ipd.display(ipd.Audio(vocoded_audio_real, rate=44100))\n",
    "                \n",
    "                spec, audio = infer(spec_model, vocoder, text_to_generate, speaker=0)\n",
    "                print(\"Synthetic audio\")\n",
    "                ipd.display(ipd.Audio(audio, rate=44100))\n",
    "                \n",
    "                if lidx >= 2:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166573fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fastpitch_8051_ckpt = \"/home/pneekhara/PreTrainedModels/FastPitch.nemo\"\n",
    "fastpitch_nomix_finetuned_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsMainBranch/JonFinetuningv2\")[1]\n",
    "fastpitch_mix_finetuned_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsMainBranch/JonFinetuningMixed\")[1]\n",
    "hifigan_universal_ckpt = \"/home/pneekhara/PreTrainedModels/HifiGan--val_loss=0.08-epoch=899.ckpt\"\n",
    "hifigan_nomix_finetuned_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsHiFiJon/JonFinetuning\")[1]\n",
    "hifigan_mix_finetuned_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsHiFiJon/JonFinetuningMixing\")[1]\n",
    "print(fastpitch_8051_ckpt)\n",
    "print(fastpitch_nomix_finetuned_ckpt)\n",
    "print(fastpitch_mix_finetuned_ckpt)\n",
    "print(hifigan_universal_ckpt)\n",
    "print(hifigan_nomix_finetuned_ckpt)\n",
    "print(hifigan_mix_finetuned_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastpitch_8051_ckpt = \"/home/pneekhara/PreTrainedModels/FastPitch.nemo\"\n",
    "fastpitch_nomix_finetuned_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsMainBranch/JonFinetuningv2\")[1]\n",
    "fastpitch_mix_finetuned_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsMainBranch/JonFinetuningMixed\")[1]\n",
    "hifigan_universal_ckpt = \"/home/pneekhara/PreTrainedModels/HifiGan--val_loss=0.08-epoch=899.ckpt\"\n",
    "# hifigan_universal_ckpt = \"/home/pneekhara/PreTrainedModels/HifiGan--val_loss=0.09-epoch=202-last.ckpt\"\n",
    "hifigan_nomix_finetuned_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsHiFiJon/JonFinetuning\")[1]\n",
    "hifigan_mix_finetuned_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsHiFiJon/JonFinetuningMixing\")[1]\n",
    "\n",
    "spec_model, vocoder = get_synthesis_models(fastpitch_nomix_finetuned_ckpt, hifigan_mix_finetuned_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_generate = \"Oh! This is a really good text to speech synthesis model.\"\n",
    "spec, audio = infer(spec_model, vocoder, text_to_generate, speaker = 1)\n",
    "ipd.display(ipd.Audio(audio, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_generate = \"Oh! This is a really good text to speech synthesis model.\"\n",
    "spec, audio = infer(spec_model, vocoder, text_to_generate, speaker = 1)\n",
    "ipd.display(ipd.Audio(audio, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_validation_samples(spec_model, vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58044d3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dur_loss in [0.1]:\n",
    "    print(\"dur_loss coeffecient\", dur_loss)\n",
    "    _fastpitch_ckpt = _get_best_ckpt_from_experiment(\"/home/pneekhara/ExperimentsMainBranch/JonFinetuningDurLoss_{}\".format(dur_loss))[1]\n",
    "    spec_model, vocoder = get_synthesis_models(_fastpitch_ckpt, hifigan_mix_finetuned_ckpt)\n",
    "    play_validation_samples(spec_model, vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae62774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_speaking_rate(mainfest_fp):\n",
    "    \n",
    "    chars_per_second_list = []\n",
    "    with open(mainfest_fp) as f:\n",
    "        all_lines = f.read().split(\"\\n\")\n",
    "        for line in all_lines:\n",
    "            if len(line) > 0:\n",
    "                record = json.loads(line)\n",
    "                chars_per_second = len(record['text'])/record['duration']\n",
    "                chars_per_second_list.append(chars_per_second)\n",
    "    \n",
    "    return np.mean(chars_per_second_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_speaking_rate(\"/home/pneekhara/JonData/train_list.json\"))\n",
    "print(calculate_speaking_rate(\"/home/pneekhara/JonData/val_list.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394722f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_speaking_rate(\"/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/8051_manifest_clean_train.json\"))\n",
    "# print(calculate_speaking_rate(\"/home/pneekhara/JonData/val_list.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.data import audio_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbce564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "conf = OmegaConf.load('/home/pneekhara/NeMo/examples/tts/conf/fastpitch_align_44100.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460383b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.validation_datasets = \"/home/pneekhara/JonData/val_list.json\"\n",
    "conf.prior_folder = \"/home/pneekhara/dump\"\n",
    "print (conf.model.validation_ds.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc232a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import instantiate\n",
    "\n",
    "val_dataset = instantiate(conf.model.validation_ds.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf.model.validation_ds.dataloader_params.batch_size = 1\n",
    "conf.model.validation_ds.dataloader_params.num_workers = 1\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, collate_fn=val_dataset.collate_fn, **conf.model.validation_ds.dataloader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loader.cuda()\n",
    "for batch in val_loader:\n",
    "    with torch.no_grad():\n",
    "        audio, audio_lens, text, text_lens, attn_prior, pitch, speakers = batch\n",
    "        for item in [audio, audio_lens, text, text_lens, attn_prior, pitch, speakers]:\n",
    "            if item is not None:\n",
    "                item = item.cuda()\n",
    "        print(audio)\n",
    "        \n",
    "        \n",
    "                    \n",
    "                    \n",
    "        mels, spec_len = spec_model.preprocessor(input_signal=audio.cuda(), length=audio_lens.cuda())\n",
    "        \n",
    "        real_mel = mels\n",
    "        real_mel = real_mel.cuda()\n",
    "        with torch.no_grad():\n",
    "            vocoded_audio_real = vocoder.convert_spectrogram_to_audio(spec=real_mel).cpu().numpy()\n",
    "            print(\"Ground truh spectrogram vocoded (HiFiGAN):\")\n",
    "            ipd.display(ipd.Audio(vocoded_audio_real, rate=44100))\n",
    "            \n",
    "        mels_pred, _, _, log_durs_pred, pitch_pred, attn_soft, attn_logprob, attn_hard, attn_hard_dur, pitch = spec_model(\n",
    "                text=text.cuda(),\n",
    "                durs=None,\n",
    "                pitch=pitch.cuda(),\n",
    "                speaker=speakers,\n",
    "                pace=1.0,\n",
    "                spec=mels.cuda(),\n",
    "                attn_prior=attn_prior.cuda(),\n",
    "                mel_lens=spec_len.cuda(),\n",
    "                input_lens=text_lens.cuda())\n",
    "        synthesized_audio = vocoder.convert_spectrogram_to_audio(spec=mels_pred)\n",
    "        synthesized_audio = synthesized_audio.to('cpu').numpy()\n",
    "        ipd.display(ipd.Audio(synthesized_audio, rate=44100))\n",
    "        print (mels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesized_audio = vocoder.convert_spectrogram_to_audio(spec=mels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc83721",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_model.learn_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf78d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in val_loader:\n",
    "    print(record)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccfe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in val_loader:\n",
    "    print(record)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab972a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in val_loader:\n",
    "    print(record)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dcb4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemoenv",
   "language": "python",
   "name": "nemoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
