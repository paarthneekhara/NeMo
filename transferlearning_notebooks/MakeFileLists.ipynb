{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "048d0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup\"\n",
    "target_dir = \"/home/pneekhara/filelists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebb080ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def make_universal_hifigan_filelist(speaker_id_mapping, split):\n",
    "    \n",
    "    all_records = []\n",
    "    for speaker_id in speaker_id_mapping:\n",
    "        clean_other = speaker_id_mapping[speaker_id]\n",
    "        file_list_name = \"{}_manifest_{}_{}.json\".format(speaker_id, clean_other, split)\n",
    "        with open(os.path.join(data_dir, file_list_name), 'r') as f:\n",
    "            speaker_records = [json.loads(l) for l in f.read().split(\"\\n\") if len(l) > 0]\n",
    "            print (\"Num Records : {} for speaker {}\".format(len(speaker_records), speaker_id))\n",
    "        \n",
    "        for row in speaker_records:\n",
    "            all_records.append(row)\n",
    "    random.seed(0)\n",
    "    random.shuffle(all_records)\n",
    "    if split == \"dev\":\n",
    "        all_records = all_records[:150]\n",
    "    else:\n",
    "        all_records = all_records[:150000]\n",
    "        \n",
    "    target_fp = os.path.join(target_dir, \"hifigan_mixed_{}.json\".format(split))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for record in json.loads(json.dumps(all_records)):\n",
    "            record['audio_filepath'] = record['audio_filepath'][record['audio_filepath'].find(\"wav/\"):]\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "    \n",
    "    target_fp = os.path.join(target_dir, \"hifigan_mixed_{}_ngc.json\".format(split))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for record in json.loads(json.dumps(all_records)):\n",
    "            record['audio_filepath'] = record['audio_filepath'][record['audio_filepath'].find(\"wav/\"):]\n",
    "            record['audio_filepath'] = \"/raid/HiFiDataset/Hi_Fi_TTS_v_0/\" + record['audio_filepath']\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "    \n",
    "    target_fp = os.path.join(target_dir, \"hifigan_mixed_{}_local.json\".format(split))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for record in json.loads(json.dumps(all_records)):\n",
    "            record['audio_filepath'] = record['audio_filepath'][record['audio_filepath'].find(\"wav/\"):]\n",
    "            record['audio_filepath'] = \"/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/\" + record['audio_filepath']\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "    \n",
    "def make_sub_file_list(speaker_id, clean_other, split, num_samples, total_duration, seed=42):\n",
    "    file_list_name = \"{}_manifest_{}_{}.json\".format(speaker_id, clean_other, split)\n",
    "    with open(os.path.join(data_dir, file_list_name), 'r') as f:\n",
    "        all_records = [json.loads(l) for l in f.read().split(\"\\n\") if len(l) > 0]\n",
    "    for r in all_records:\n",
    "        r['audio_filepath'] = r['audio_filepath'][r['audio_filepath'].find(\"wav/\"):]\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_records)\n",
    "    \n",
    "    if num_samples is not None and total_duration is None:\n",
    "        sub_records = all_records[:num_samples]\n",
    "        fname_extension = \"ns_{}\".format(num_samples)\n",
    "    elif num_samples is None and total_duration is not None:\n",
    "        sub_record_duration = 0.0\n",
    "        sub_records = []\n",
    "        for r in all_records:\n",
    "            sub_record_duration += r['duration']\n",
    "            if sub_record_duration > total_duration:\n",
    "                print (\"Sub record duration reached {}\".format(total_duration), len(sub_records))\n",
    "                break\n",
    "            sub_records.append(r)\n",
    "        fname_extension = \"dur_{}_mins\".format( int(round(total_duration/60.0 )))\n",
    "    elif num_samples is None and total_duration is None:\n",
    "        sub_records = all_records\n",
    "        fname_extension = \"ns_all\"\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    print (\"num subrecs\", len(sub_records))\n",
    "    target_fp = os.path.join(target_dir, \"{}_mainifest_{}_{}.json\".format(speaker_id, split, fname_extension))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for record in json.loads(json.dumps(sub_records)):\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "    \n",
    "    target_fp = os.path.join(target_dir, \"{}_mainifest_{}_{}_ngc.json\".format(speaker_id, split, fname_extension))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for record in json.loads(json.dumps(sub_records)):\n",
    "            record['audio_filepath'] = record['audio_filepath'][record['audio_filepath'].find(\"wav/\"):]\n",
    "            record['audio_filepath'] = \"/raid/HiFiDataset/Hi_Fi_TTS_v_0/\" + record['audio_filepath']\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "    \n",
    "    target_fp = os.path.join(target_dir, \"{}_mainifest_{}_{}_local.json\".format(speaker_id, split,  fname_extension))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for record in json.loads(json.dumps(sub_records)):\n",
    "            record['audio_filepath'] = record['audio_filepath'][record['audio_filepath'].find(\"wav/\"):]\n",
    "            record['audio_filepath'] = \"/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/\" + record['audio_filepath']\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "def mix_file_list(speaker_id, clean_other, split, num_samples, total_duration, original_speaker_id, original_clean_other, n_orig=None, seed=42):\n",
    "    file_list_name = \"{}_manifest_{}_{}.json\".format(speaker_id, clean_other, split)\n",
    "    with open(os.path.join(data_dir, file_list_name), 'r') as f:\n",
    "        all_records = [json.loads(l) for l in f.read().split(\"\\n\") if len(l) > 0]\n",
    "    for r in all_records:\n",
    "        r['audio_filepath'] = r['audio_filepath'][r['audio_filepath'].find(\"wav/\"):]\n",
    "    \n",
    "    original_file_list_name = \"{}_manifest_{}_{}.json\".format(original_speaker_id, original_clean_other, \"train\")\n",
    "    with open(os.path.join(data_dir, original_file_list_name), 'r') as f:\n",
    "        original_all_records = [json.loads(l) for l in f.read().split(\"\\n\") if len(l) > 0]\n",
    "    for r in original_all_records:\n",
    "        r['audio_filepath'] = r['audio_filepath'][r['audio_filepath'].find(\"wav/\"):]\n",
    "    \n",
    "    random.seed(seed)\n",
    "    if n_orig is not None:\n",
    "        random.shuffle(original_all_records)\n",
    "        original_all_records = original_all_records[:n_orig]\n",
    "        \n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_records)\n",
    "    \n",
    "    if num_samples is not None and total_duration is None:\n",
    "        sub_records = all_records[:num_samples]\n",
    "        fname_extension = \"ns_{}\".format(num_samples)\n",
    "    elif num_samples is None and total_duration is not None:\n",
    "        sub_record_duration = 0.0\n",
    "        sub_records = []\n",
    "        for r in all_records:\n",
    "            sub_record_duration += r['duration']\n",
    "            if sub_record_duration > total_duration:\n",
    "                print (\"Sub record duration reached {}\".format(total_duration), len(sub_records))\n",
    "                break\n",
    "            sub_records.append(r)\n",
    "        fname_extension = \"dur_{}_mins\".format( int(round(total_duration/60.0 )))\n",
    "    elif num_samples is None and total_duration is None:\n",
    "        sub_records = all_records\n",
    "        fname_extension = \"ns_all\"\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    print(len(original_all_records))\n",
    "    sub_records1 = json.loads(json.dumps(sub_records))\n",
    "    sub_records2 = json.loads(json.dumps(sub_records))\n",
    "    sub_records3 = json.loads(json.dumps(sub_records))\n",
    "    target_fp = os.path.join(target_dir, \"{}_mainifest_{}_{}_mix_{}.json\".format(speaker_id, split, fname_extension, original_speaker_id))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for ridx, original_record in enumerate(original_all_records):\n",
    "            new_speaker_record = sub_records1[ridx % len(sub_records1)]\n",
    "            new_speaker_record['speaker'] = 1\n",
    "            original_record['speaker'] = 0\n",
    "            f.write(json.dumps(original_record) + \"\\n\")\n",
    "            f.write(json.dumps(new_speaker_record) + \"\\n\")\n",
    "    \n",
    "    target_fp = os.path.join(target_dir, \"{}_mainifest_{}_{}_ngc_mix_{}.json\".format(speaker_id, split, fname_extension, original_speaker_id))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for ridx, original_record in enumerate(original_all_records):\n",
    "            original_record['audio_filepath'] = original_record['audio_filepath'][original_record['audio_filepath'].find(\"wav/\"):]\n",
    "            original_record['audio_filepath'] = \"/raid/HiFiDataset/Hi_Fi_TTS_v_0/\" + original_record['audio_filepath']\n",
    "            \n",
    "            new_speaker_record = sub_records2[ridx % len(sub_records2)]\n",
    "            new_speaker_record['audio_filepath'] = new_speaker_record['audio_filepath'][new_speaker_record['audio_filepath'].find(\"wav/\"):]\n",
    "            new_speaker_record['audio_filepath'] = \"/raid/HiFiDataset/Hi_Fi_TTS_v_0/\" + new_speaker_record['audio_filepath']\n",
    "            \n",
    "            new_speaker_record['speaker'] = 1\n",
    "            original_record['speaker'] = 0\n",
    "            f.write(json.dumps(original_record) + \"\\n\")\n",
    "            f.write(json.dumps(new_speaker_record) + \"\\n\")\n",
    "    \n",
    "    target_fp = os.path.join(target_dir, \"{}_mainifest_{}_{}_local_mix_{}.json\".format(speaker_id, split,  fname_extension, original_speaker_id))\n",
    "    with open(target_fp, 'w') as f:\n",
    "        for ridx, original_record in enumerate(original_all_records):\n",
    "            original_record['audio_filepath'] = original_record['audio_filepath'][original_record['audio_filepath'].find(\"wav/\"):]\n",
    "            original_record['audio_filepath'] = \"/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/\" + original_record['audio_filepath']\n",
    "            \n",
    "            new_speaker_record = sub_records3[ridx % len(sub_records3)]\n",
    "            new_speaker_record['audio_filepath'] = new_speaker_record['audio_filepath'][new_speaker_record['audio_filepath'].find(\"wav/\"):]\n",
    "            new_speaker_record['audio_filepath'] = \"/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/\" + new_speaker_record['audio_filepath']\n",
    "            \n",
    "            new_speaker_record['speaker'] = 1\n",
    "            original_record['speaker'] = 0\n",
    "            f.write(json.dumps(original_record) + \"\\n\")\n",
    "            f.write(json.dumps(new_speaker_record) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6079771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id_mapping = {\n",
    "#     92 : 'clean',\n",
    "#     6097 : 'clean',\n",
    "    8051 : 'clean',\n",
    "    11697 : 'other',\n",
    "    6670 : 'other',\n",
    "    6671 : 'other',\n",
    "    9017 : 'clean',\n",
    "    11614 : 'other',\n",
    "    9136 : 'other',\n",
    "    12787 : 'other'\n",
    "}\n",
    "# make_universal_hifigan_filelist(speaker_id_mapping, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b0c3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num subrecs 50\n",
      "num subrecs 50\n",
      "num subrecs 50\n",
      "num subrecs 50\n",
      "num subrecs 50\n",
      "num subrecs 50\n",
      "num subrecs 50\n",
      "num subrecs 50\n"
     ]
    }
   ],
   "source": [
    "# make_sub_file_list(6097, \"clean\", \"train\", None, 1*60)\n",
    "# make_sub_file_list(6097, \"clean\", \"train\", None, 5*60)\n",
    "# make_sub_file_list(6097, \"clean\", \"train\", None, 30*60)\n",
    "# make_sub_file_list(6097, \"clean\", \"train\", None, 60*60)\n",
    "for speaker in speaker_id_mapping:\n",
    "    make_sub_file_list(speaker, speaker_id_mapping[speaker], \"dev\", None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b58497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub record duration reached 60 17\n",
      "5000\n",
      "Sub record duration reached 300 108\n",
      "5000\n",
      "Sub record duration reached 1800 656\n",
      "5000\n",
      "Sub record duration reached 3600 1319\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "mix_file_list(6097, \"clean\", \"train\", None, 1*60, 8051, \"clean\", n_orig=5000)\n",
    "mix_file_list(6097, \"clean\", \"train\", None, 5*60, 8051, \"clean\", n_orig=5000)\n",
    "mix_file_list(6097, \"clean\", \"train\", None, 30*60, 8051, \"clean\", n_orig=5000)\n",
    "mix_file_list(6097, \"clean\", \"train\", None, 60*60, 8051, \"clean\", n_orig=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5276e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_ckpt(new_speaker_id, duration_mins, mixing_enabled, original_speaker_id):\n",
    "    if not mixing_enabled:\n",
    "        exp_dir = \"/home/pneekhara/ExperimentsAutomated/{}_to_{}_no_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "    else:\n",
    "        exp_dir = \"/home/pneekhara/ExperimentsAutomated/{}_to_{}_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "    \n",
    "    ckpt_candidates = []\n",
    "    for root, dirs, files in os.walk(exp_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ckpt\"):\n",
    "                val_error = float(file.split(\"v_loss=\")[1].split(\"-epoch\")[0])\n",
    "                ckpt_candidates.append( (val_error, os.path.join(root, file)))\n",
    "    ckpt_candidates.sort()\n",
    "    \n",
    "    return ckpt_candidates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efdd9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_stats = {\n",
    "    92 : {\n",
    "        'mean' : 214.5,\n",
    "        'std' : 30.9,\n",
    "        'fmin' : 80,\n",
    "        'fmax' : 512\n",
    "    },\n",
    "    6097 : {\n",
    "        'mean' : 121.9 ,\n",
    "        'std' : 23.1,\n",
    "        'fmin' : 30,\n",
    "        'fmax' : 512\n",
    "    }\n",
    "}\n",
    "def generate_training_command_old(new_speaker_id, duration_mins, mixing_enabled, original_speaker_id, use_new_pitch_stats=False,\n",
    "                             ckpt = \"/home/pneekhara/PreTrainedModels/FastPitch.nemo\"):\n",
    "    \n",
    "    def _find_epochs(duration_mins, mixing_enabled, n_orig=None):\n",
    "        epochs = 200 # default.\n",
    "        if duration_mins == 5:\n",
    "            epochs = 1000\n",
    "        elif duration_mins == 30:\n",
    "            epochs = 300\n",
    "        elif duration_mins == 60:\n",
    "            epochs = 150\n",
    "        \n",
    "        if mixing_enabled:\n",
    "            if duration_mins == 5:\n",
    "                epochs = epochs/50 + 1\n",
    "            elif duration_mins == 30:\n",
    "                epochs = epochs/10 + 1\n",
    "            elif duration_mins == 60:\n",
    "                epochs = epochs/5 + 1\n",
    "        \n",
    "        return int(epochs)\n",
    "            \n",
    "            \n",
    "    if ckpt.endswith(\".nemo\"):\n",
    "        ckpt_arg_name = \"init_from_nemo_model\"\n",
    "    else:\n",
    "        ckpt_arg_name = \"init_from_ptl_ckpt\"\n",
    "    if not mixing_enabled:\n",
    "        config_name = \"fastpitch_align_finetuningnomixing\"\n",
    "        train_dataset = \"../filelists/{}_mainifest_train_dur_{}_mins_local.json\".format(new_speaker_id, duration_mins)\n",
    "        val_dataset = \"../filelists/{}_mainifest_dev_ns_all_local.json\".format(new_speaker_id)\n",
    "        prior_folder = \"/home/pneekhara/Datasets/Priors{}\".format(new_speaker_id)\n",
    "        exp_dir = \"/home/pneekhara/ExperimentsAutomatedResetPitch/{}_to_{}_no_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "    else:\n",
    "        config_name = \"fastpitch_align_finetuningmixing\"\n",
    "        train_dataset = \"../filelists/{}_mainifest_train_dur_{}_mins_local_mix_{}.json\".format(new_speaker_id, duration_mins, original_speaker_id)\n",
    "        val_dataset = \"../filelists/{}_mainifest_dev_ns_all_local.json\".format(new_speaker_id)\n",
    "        prior_folder = \"/home/pneekhara/Datasets/Priors_{}_mix_{}\".format(new_speaker_id, original_speaker_id)\n",
    "        exp_dir = \"/home/pneekhara/ExperimentsAutomatedResetPitch/{}_to_{}_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "    max_epochs = _find_epochs(duration_mins, mixing_enabled, n_orig=None)\n",
    "    \n",
    "    training_command = \"python examples/tts/fastpitch2_finetune.py --config-name={} train_dataset={} validation_datasets={} +{}={} trainer.max_epochs={} trainer.check_val_every_n_epoch=1 prior_folder={} model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir={}\".format(\n",
    "        config_name, train_dataset, val_dataset, ckpt_arg_name, ckpt, max_epochs, prior_folder, exp_dir)\n",
    "    if use_new_pitch_stats:\n",
    "        training_command += \" model.pitch_avg={} model.pitch_std={} model.pitch_fmin={} model.pitch_fmax={}\".format(\n",
    "            pitch_stats[new_speaker_id]['mean'], \n",
    "            pitch_stats[new_speaker_id]['std'],\n",
    "            pitch_stats[new_speaker_id]['fmin'],\n",
    "            pitch_stats[new_speaker_id]['fmax']\n",
    "        )\n",
    "        \n",
    "    return training_command\n",
    "\n",
    "\n",
    "data_dir = \"/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup\"\n",
    "filelist_dir = \"/home/pneekhara/filelists\"\n",
    "exp_base_dir = \"/home/pneekhara/ExperimentsAutomatedResetPitch\"\n",
    "exp_base_dir_hifi = \"/home/pneekhara/ExperimentsHiFiFinetuning\"\n",
    "\n",
    "def generate_training_command_new(new_speaker_id, duration_mins, mixing_enabled, original_speaker_id, ckpt=\"/home/pneekhara/PreTrainedModels/FastPitch.nemo\", use_new_pitch_stats=False):\n",
    "    \"\"\"\n",
    "    Generates the training command string to be run from the NeMo/ directory. Assumes we have created the finetuning filelists\n",
    "    using the instructions given above.\n",
    "    \n",
    "    Arguments:\n",
    "    new_speaker_id -- speaker id of the new HiFiTTS speaker\n",
    "    duration_mins -- total minutes of the new speaker data (same as that used for creating the filelists)\n",
    "    mixing_enabled -- True or False depending on whether we want to mix the original speaker data or not\n",
    "    original_speaker_id -- speaker id of the original HiFiTTS speaker\n",
    "    use_new_pitch_stats -- whether to use pitch_stats dictionary given above or not\n",
    "    ckpt: Path to pretrained FastPitch checkpoint\n",
    "    \n",
    "    Returns:\n",
    "    Training command string\n",
    "    \"\"\"\n",
    "    def _find_epochs(duration_mins, mixing_enabled, n_orig=None):\n",
    "        # estimated num of epochs \n",
    "        if duration_mins == 1:\n",
    "            epochs = 5000\n",
    "        elif duration_mins == 5:\n",
    "            epochs = 1000\n",
    "        elif duration_mins == 30:\n",
    "            epochs = 300\n",
    "        elif duration_mins == 60:\n",
    "            epochs = 150\n",
    "        \n",
    "        if mixing_enabled:\n",
    "            if duration_mins == 1:\n",
    "                epochs = epochs/70 + 1\n",
    "            elif duration_mins == 5:\n",
    "                epochs = epochs/50 + 1\n",
    "            elif duration_mins == 30:\n",
    "                epochs = epochs/10 + 1\n",
    "            elif duration_mins == 60:\n",
    "                epochs = epochs/5 + 1\n",
    "        \n",
    "        return int(epochs)\n",
    "            \n",
    "            \n",
    "    if ckpt.endswith(\".nemo\"):\n",
    "        ckpt_arg_name = \"init_from_nemo_model\"\n",
    "    else:\n",
    "        ckpt_arg_name = \"init_from_ptl_ckpt\"\n",
    "    if not mixing_enabled:\n",
    "        train_dataset = \"{}_mainifest_train_dur_{}_mins_local.json\".format(new_speaker_id, duration_mins)\n",
    "        val_dataset = \"{}_mainifest_dev_ns_all_local.json\".format(new_speaker_id)\n",
    "        prior_folder = os.path.join(data_dir, \"Priors{}\".format(new_speaker_id))\n",
    "        exp_dir = \"{}_to_{}_no_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "        n_speakers = 1\n",
    "    else:\n",
    "        train_dataset = \"{}_mainifest_train_dur_{}_mins_local_mix_{}.json\".format(new_speaker_id, duration_mins, original_speaker_id)\n",
    "        val_dataset = \"{}_mainifest_dev_ns_all_local.json\".format(new_speaker_id)\n",
    "        prior_folder = os.path.join(data_dir, \"Priors_{}_mix_{}\".format(new_speaker_id, original_speaker_id))\n",
    "        exp_dir = \"{}_to_{}_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "        n_speakers = 2\n",
    "    train_dataset = os.path.join(filelist_dir, train_dataset)\n",
    "    val_dataset = os.path.join(filelist_dir, val_dataset)\n",
    "    exp_dir = os.path.join(exp_base_dir, exp_dir)\n",
    "                                    \n",
    "    max_epochs = _find_epochs(duration_mins, mixing_enabled, n_orig=None)\n",
    "    config_name = \"fastpitch_align_44100.yaml\"\n",
    "    \n",
    "    training_command = \"python examples/tts/fastpitch2_finetune.py --config-name={} train_dataset={} validation_datasets={} +{}={} trainer.max_epochs={} trainer.check_val_every_n_epoch=1 prior_folder={} model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir={} model.n_speakers={}\".format(\n",
    "        config_name, train_dataset, val_dataset, ckpt_arg_name, ckpt, max_epochs, prior_folder, exp_dir, n_speakers)\n",
    "    if use_new_pitch_stats:\n",
    "        training_command += \" model.pitch_avg={} model.pitch_std={} model.pitch_fmin={} model.pitch_fmax={}\".format(\n",
    "            pitch_stats[new_speaker_id]['mean'], \n",
    "            pitch_stats[new_speaker_id]['std'],\n",
    "            pitch_stats[new_speaker_id]['fmin'],\n",
    "            pitch_stats[new_speaker_id]['fmax']\n",
    "        )\n",
    "    training_command += \" model.optim.lr=2e-4 ~model.optim.sched\"\n",
    "    return training_command\n",
    "\n",
    "def generate_hifigan_training_command(new_speaker_id, duration_mins, mixing, original_speaker_id=8051, hifipretrained_ckpt=\"/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt\"):\n",
    "    \n",
    "    \n",
    "    if not mixing:\n",
    "        exp_dir = \"{}_to_{}_no_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "        train_manifest_file = \"{}_mainifest_train_dur_{}_mins_local.json\".format(new_speaker_id, duration_mins)\n",
    "        trainer_max_steps = 2000\n",
    "    else:\n",
    "        exp_dir = \"{}_to_{}_mixing_{}_mins\".format(original_speaker_id, new_speaker_id, duration_mins)\n",
    "        train_manifest_file = \"{}_mainifest_train_dur_{}_mins_local_mix_{}.json\".format(new_speaker_id, duration_mins, original_speaker_id)\n",
    "        trainer_max_steps = 4000\n",
    "        \n",
    "    val_manifest_file = \"{}_mainifest_dev_ns_all_local.json\".format(new_speaker_id)\n",
    "    batch_size = 16\n",
    "    # exp_dir = \n",
    "    exp_dir = os.path.join(exp_base_dir_hifi, exp_dir)\n",
    "    train_manifest_file = os.path.join(filelist_dir, train_manifest_file)\n",
    "    val_manifest_file = os.path.join(filelist_dir, val_manifest_file)\n",
    "    \n",
    "    training_command = \"python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset={} validation_datasets={} +init_from_ptl_ckpt={} trainer.max_steps={}  model.train_ds.dataloader_params.batch_size={} model.validation_ds.dataloader_params.batch_size={} exp_manager.exp_dir={}  ~model.sched\".format(\n",
    "        train_manifest_file, val_manifest_file, hifipretrained_ckpt, trainer_max_steps, batch_size, batch_size, exp_dir)\n",
    "    return training_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24156ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_1_mins_local.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=2000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_6097_no_mixing_1_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_5_mins_local.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=2000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_6097_no_mixing_5_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_30_mins_local.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=2000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_6097_no_mixing_30_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_60_mins_local.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=2000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_6097_no_mixing_60_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_1_mins_local.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=2000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_92_no_mixing_1_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_5_mins_local.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=2000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_92_no_mixing_5_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_30_mins_local.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=2000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_92_no_mixing_30_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_60_mins_local.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=2000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_92_no_mixing_60_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_1_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=4000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_6097_mixing_1_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_5_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=4000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_6097_mixing_5_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_30_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=4000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_6097_mixing_30_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_60_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=4000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_6097_mixing_60_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_1_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=4000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_92_mixing_1_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_5_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=4000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_92_mixing_5_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_30_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=4000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_92_mixing_30_mins  ~model.sched;python examples/tts/hifigan_finetune.py --config-name=hifigan44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_60_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_ptl_ckpt=/home/pneekhara/PreTrainedModels/HiFiMix_No_92_6097.ckpt trainer.max_steps=4000  model.train_ds.dataloader_params.batch_size=16 model.validation_ds.dataloader_params.batch_size=16 exp_manager.exp_dir=/home/pneekhara/ExperimentsHiFiFinetuning/8051_to_92_mixing_60_mins  ~model.sched;\n"
     ]
    }
   ],
   "source": [
    "overall_command = \"\"\n",
    "for mixing in [False, True]:\n",
    "    for speaker in [6097, 92]:\n",
    "\n",
    "        for duration_mins in [1, 5, 30, 60]:\n",
    "            overall_command += generate_hifigan_training_command(speaker, duration_mins, mixing)\n",
    "            overall_command += \";\"\n",
    "print(overall_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ce9a2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python examples/tts/fastpitch2_finetune.py --config-name=fastpitch_align_44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_5_mins_local.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_nemo_model=/home/pneekhara/PreTrainedModels/FastPitch.nemo trainer.max_epochs=1000 trainer.check_val_every_n_epoch=1 prior_folder=/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/Priors92 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=/home/pneekhara/ExperimentsMainBranch/8051_to_92_no_mixing_5_mins model.n_speakers=1 model.pitch_avg=214.5 model.pitch_std=30.9 model.pitch_fmin=80 model.pitch_fmax=512 model.optim.lr=2e-4 ~model.optim.sched'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_training_command_new(92, 5, False, 8051, use_new_pitch_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beb582b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "overall_command = \"\"\n",
    "for mixing in [False, True]:\n",
    "    for speaker in [6097, 92]:\n",
    "    \n",
    "        for duration_mins in [1]:\n",
    "            overall_command += generate_training_command_new(speaker, duration_mins, mixing, 8051, use_new_pitch_stats=True)\n",
    "            overall_command += \";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a5b78d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python examples/tts/fastpitch2_finetune.py --config-name=fastpitch_align_44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_1_mins_local.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_nemo_model=/home/pneekhara/PreTrainedModels/FastPitch.nemo trainer.max_epochs=5000 trainer.check_val_every_n_epoch=1 prior_folder=/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/Priors6097 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=/home/pneekhara/ExperimentsAutomatedResetPitch/8051_to_6097_no_mixing_1_mins model.n_speakers=1 model.pitch_avg=121.9 model.pitch_std=23.1 model.pitch_fmin=30 model.pitch_fmax=512 model.optim.lr=2e-4 ~model.optim.sched;python examples/tts/fastpitch2_finetune.py --config-name=fastpitch_align_44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_1_mins_local.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_nemo_model=/home/pneekhara/PreTrainedModels/FastPitch.nemo trainer.max_epochs=5000 trainer.check_val_every_n_epoch=1 prior_folder=/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/Priors92 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=/home/pneekhara/ExperimentsAutomatedResetPitch/8051_to_92_no_mixing_1_mins model.n_speakers=1 model.pitch_avg=214.5 model.pitch_std=30.9 model.pitch_fmin=80 model.pitch_fmax=512 model.optim.lr=2e-4 ~model.optim.sched;python examples/tts/fastpitch2_finetune.py --config-name=fastpitch_align_44100.yaml train_dataset=/home/pneekhara/filelists/6097_mainifest_train_dur_1_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/6097_mainifest_dev_ns_all_local.json +init_from_nemo_model=/home/pneekhara/PreTrainedModels/FastPitch.nemo trainer.max_epochs=72 trainer.check_val_every_n_epoch=1 prior_folder=/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/Priors_6097_mix_8051 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=/home/pneekhara/ExperimentsAutomatedResetPitch/8051_to_6097_mixing_1_mins model.n_speakers=2 model.pitch_avg=121.9 model.pitch_std=23.1 model.pitch_fmin=30 model.pitch_fmax=512 model.optim.lr=2e-4 ~model.optim.sched;python examples/tts/fastpitch2_finetune.py --config-name=fastpitch_align_44100.yaml train_dataset=/home/pneekhara/filelists/92_mainifest_train_dur_1_mins_local_mix_8051.json validation_datasets=/home/pneekhara/filelists/92_mainifest_dev_ns_all_local.json +init_from_nemo_model=/home/pneekhara/PreTrainedModels/FastPitch.nemo trainer.max_epochs=72 trainer.check_val_every_n_epoch=1 prior_folder=/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup/Priors_92_mix_8051 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=/home/pneekhara/ExperimentsAutomatedResetPitch/8051_to_92_mixing_1_mins model.n_speakers=2 model.pitch_avg=214.5 model.pitch_std=30.9 model.pitch_fmin=80 model.pitch_fmax=512 model.optim.lr=2e-4 ~model.optim.sched;'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865322e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"FastPitch--v_loss=1.80-epoch=0.ckpt\".split(\"v_loss=\")[1].split(\"-epoch\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d50dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.16, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_5_mins/FastPitch/2021-07-20_17-57-18/checkpoints/FastPitch--v_loss=1.16-epoch=37.ckpt'), (1.19, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_5_mins/FastPitch/2021-07-20_17-57-18/checkpoints/FastPitch--v_loss=1.19-epoch=199-last.ckpt'), (1.19, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_5_mins/FastPitch/2021-07-20_17-57-18/checkpoints/FastPitch--v_loss=1.19-epoch=36.ckpt'), (1.19, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_5_mins/FastPitch/2021-07-20_17-57-18/checkpoints/FastPitch--v_loss=1.19-epoch=39.ckpt')]\n",
      "**\n",
      "[(2.32, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_5_mins/FastPitch/2021-07-20_18-12-56/checkpoints/FastPitch--v_loss=2.32-epoch=4-last.ckpt'), (2.34, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_5_mins/FastPitch/2021-07-20_18-12-56/checkpoints/FastPitch--v_loss=2.34-epoch=2.ckpt'), (2.44, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_5_mins/FastPitch/2021-07-20_18-12-56/checkpoints/FastPitch--v_loss=2.44-epoch=0.ckpt'), (2.45, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_5_mins/FastPitch/2021-07-20_18-12-56/checkpoints/FastPitch--v_loss=2.45-epoch=3.ckpt')]\n",
      "**\n",
      "[(0.96, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_30_mins/FastPitch/2021-07-20_18-24-39/checkpoints/FastPitch--v_loss=0.96-epoch=9.ckpt'), (0.97, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_30_mins/FastPitch/2021-07-20_18-24-39/checkpoints/FastPitch--v_loss=0.97-epoch=15.ckpt'), (0.98, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_30_mins/FastPitch/2021-07-20_18-24-39/checkpoints/FastPitch--v_loss=0.98-epoch=18.ckpt'), (1.06, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_30_mins/FastPitch/2021-07-20_18-24-39/checkpoints/FastPitch--v_loss=1.06-epoch=149-last.ckpt')]\n",
      "**\n",
      "[(2.1, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_30_mins/FastPitch/2021-07-20_18-43-25/checkpoints/FastPitch--v_loss=2.10-epoch=4.ckpt'), (2.12, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_30_mins/FastPitch/2021-07-20_18-43-25/checkpoints/FastPitch--v_loss=2.12-epoch=6.ckpt'), (2.13, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_30_mins/FastPitch/2021-07-20_18-43-25/checkpoints/FastPitch--v_loss=2.13-epoch=2.ckpt'), (2.26, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_30_mins/FastPitch/2021-07-20_18-43-25/checkpoints/FastPitch--v_loss=2.26-epoch=15-last.ckpt')]\n",
      "**\n",
      "[(0.79, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_60_mins/FastPitch/2021-07-20_19-01-14/checkpoints/FastPitch--v_loss=0.79-epoch=12.ckpt'), (0.82, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_60_mins/FastPitch/2021-07-20_19-01-14/checkpoints/FastPitch--v_loss=0.82-epoch=7.ckpt'), (0.84, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_60_mins/FastPitch/2021-07-20_19-01-14/checkpoints/FastPitch--v_loss=0.84-epoch=47.ckpt'), (0.96, '/home/pneekhara/ExperimentsAutomated/8051_to_92_no_mixing_60_mins/FastPitch/2021-07-20_19-01-14/checkpoints/FastPitch--v_loss=0.96-epoch=99-last.ckpt')]\n",
      "**\n",
      "[(1.98, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_60_mins/FastPitch/2021-07-20_19-19-33/checkpoints/FastPitch--v_loss=1.98-epoch=4.ckpt'), (2.06, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_60_mins/FastPitch/2021-07-20_19-19-33/checkpoints/FastPitch--v_loss=2.06-epoch=0.ckpt'), (2.09, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_60_mins/FastPitch/2021-07-20_19-19-33/checkpoints/FastPitch--v_loss=2.09-epoch=5.ckpt'), (2.2, '/home/pneekhara/ExperimentsAutomated/8051_to_92_mixing_60_mins/FastPitch/2021-07-20_19-19-33/checkpoints/FastPitch--v_loss=2.20-epoch=20-last.ckpt')]\n",
      "**\n",
      "[(1.05, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_5_mins/FastPitch/2021-07-20_19-42-40/checkpoints/FastPitch--v_loss=1.05-epoch=10.ckpt'), (1.05, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_5_mins/FastPitch/2021-07-20_19-42-40/checkpoints/FastPitch--v_loss=1.05-epoch=14.ckpt'), (1.06, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_5_mins/FastPitch/2021-07-20_19-42-40/checkpoints/FastPitch--v_loss=1.06-epoch=89.ckpt'), (1.08, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_5_mins/FastPitch/2021-07-20_19-42-40/checkpoints/FastPitch--v_loss=1.08-epoch=199-last.ckpt')]\n",
      "**\n",
      "[(1.75, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_5_mins/FastPitch/2021-07-20_19-57-53/checkpoints/FastPitch--v_loss=1.75-epoch=1.ckpt'), (1.8, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_5_mins/FastPitch/2021-07-20_19-57-53/checkpoints/FastPitch--v_loss=1.80-epoch=0.ckpt'), (1.81, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_5_mins/FastPitch/2021-07-20_19-57-53/checkpoints/FastPitch--v_loss=1.81-epoch=2.ckpt'), (1.94, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_5_mins/FastPitch/2021-07-20_19-57-53/checkpoints/FastPitch--v_loss=1.94-epoch=4-last.ckpt')]\n",
      "**\n",
      "[(0.88, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_30_mins/FastPitch/2021-07-20_20-10-53/checkpoints/FastPitch--v_loss=0.88-epoch=12.ckpt'), (0.89, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_30_mins/FastPitch/2021-07-20_20-10-53/checkpoints/FastPitch--v_loss=0.89-epoch=9.ckpt'), (0.9, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_30_mins/FastPitch/2021-07-20_20-10-53/checkpoints/FastPitch--v_loss=0.90-epoch=6.ckpt'), (0.97, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_30_mins/FastPitch/2021-07-20_20-10-53/checkpoints/FastPitch--v_loss=0.97-epoch=149-last.ckpt')]\n",
      "**\n",
      "[(1.48, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_30_mins/FastPitch/2021-07-20_20-29-27/checkpoints/FastPitch--v_loss=1.48-epoch=3.ckpt'), (1.58, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_30_mins/FastPitch/2021-07-20_20-29-27/checkpoints/FastPitch--v_loss=1.58-epoch=9.ckpt'), (1.59, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_30_mins/FastPitch/2021-07-20_20-29-27/checkpoints/FastPitch--v_loss=1.59-epoch=2.ckpt'), (1.68, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_30_mins/FastPitch/2021-07-20_20-29-27/checkpoints/FastPitch--v_loss=1.68-epoch=15-last.ckpt')]\n",
      "**\n",
      "[(0.8, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_60_mins/FastPitch/2021-07-20_20-47-17/checkpoints/FastPitch--v_loss=0.80-epoch=85.ckpt'), (0.81, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_60_mins/FastPitch/2021-07-20_20-47-17/checkpoints/FastPitch--v_loss=0.81-epoch=99-last.ckpt'), (0.82, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_60_mins/FastPitch/2021-07-20_20-47-17/checkpoints/FastPitch--v_loss=0.82-epoch=8.ckpt'), (0.82, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_no_mixing_60_mins/FastPitch/2021-07-20_20-47-17/checkpoints/FastPitch--v_loss=0.82-epoch=9.ckpt')]\n",
      "**\n",
      "[(1.58, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_60_mins/FastPitch/2021-07-20_21-05-51/checkpoints/FastPitch--v_loss=1.58-epoch=0.ckpt'), (1.59, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_60_mins/FastPitch/2021-07-20_21-05-51/checkpoints/FastPitch--v_loss=1.59-epoch=19.ckpt'), (1.6, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_60_mins/FastPitch/2021-07-20_21-05-51/checkpoints/FastPitch--v_loss=1.60-epoch=2.ckpt'), (1.69, '/home/pneekhara/ExperimentsAutomated/8051_to_6097_mixing_60_mins/FastPitch/2021-07-20_21-05-51/checkpoints/FastPitch--v_loss=1.69-epoch=20-last.ckpt')]\n",
      "**\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "overall_command = \"\"\n",
    "for speaker in [92, 6097]:\n",
    "    for duration_mins in [5, 30, 60]:\n",
    "        for mixing in [False, True]:\n",
    "            print(get_best_ckpt(speaker, duration_mins, mixing, 8051))\n",
    "            print(\"**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68dfb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "python examples/tts/fastpitch2_finetune.py --config-name=fastpitch_align_finetuningnomixing train_dataset=filelists/92_mainifest_train_dur_5_mins_local.json validation_datasets=filelists/92_mainifest_dev_ns_all_local.json +init_from_nemo_model=/home/pneekhara/PreTrainedModels/FastPitch.nemo trainer.max_epochs=1000 trainer.check_val_every_n_epoch=1 prior_folder=/home/pneekhara/Datasets/Priors92 model.train_ds.dataloader_params.batch_size=24 model.validation_ds.dataloader_params.batch_size=24 exp_manager.exp_dir=/home/pneekhara/ExperimentsAutomatedO/8051_to_92_no_mixing_5_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb90154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemoenv",
   "language": "python",
   "name": "nemoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
