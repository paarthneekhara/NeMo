{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a325d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from nemo.collections.tts.models import FastPitchModel\n",
    "from nemo.collections.tts.modules.hifigan_modules import Generator as Hifigan_generator\n",
    "from nemo.collections.asr.modules import AudioToMelSpectrogramPreprocessor\n",
    "from nemo.collections.asr.parts.preprocessing.features import WaveformFeaturizer\n",
    "from nemo.collections.tts.models import HifiGanModel\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(spec_gen_model, vocoder_model, str_input, speaker=None):\n",
    "    parser_model = spec_gen_model\n",
    "    with torch.no_grad():\n",
    "        parsed = parser_model.parse(str_input)\n",
    "        if speaker is not None:\n",
    "            speaker = torch.tensor([speaker]).long().cuda()\n",
    "        spectrogram = spec_gen_model.generate_spectrogram(tokens=parsed, speaker = speaker)\n",
    "        if isinstance(vocoder_model, Hifigan_generator):\n",
    "            audio = vocoder_model(x=spectrogram.half()).squeeze(1)\n",
    "        else:\n",
    "            audio = vocoder_model.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "        \n",
    "    if spectrogram is not None:\n",
    "        if isinstance(spectrogram, torch.Tensor):\n",
    "            spectrogram = spectrogram.to('cpu').numpy()\n",
    "        if len(spectrogram.shape) == 3:\n",
    "            spectrogram = spectrogram[0]\n",
    "    if isinstance(audio, torch.Tensor):\n",
    "        audio = audio.to('cpu').numpy()\n",
    "    return spectrogram, audio\n",
    "\n",
    "\n",
    "wav_featurizer = WaveformFeaturizer(sample_rate=44100, int_values=False, augmentor=None)\n",
    "mel_processor = AudioToMelSpectrogramPreprocessor(\n",
    "        window_size = None,\n",
    "        window_stride = None,\n",
    "        sample_rate=44100,\n",
    "        n_window_size=2048,\n",
    "        n_window_stride=512,\n",
    "        window=\"hann\",\n",
    "        normalize=None,\n",
    "        n_fft=None,\n",
    "        preemph=None,\n",
    "        features=80,\n",
    "        lowfreq=0,\n",
    "        highfreq=None,\n",
    "        log=True,\n",
    "        log_zero_guard_type=\"add\",\n",
    "        log_zero_guard_value=1e-05,\n",
    "        dither=0.0,\n",
    "        pad_to=1,\n",
    "        frame_splicing=1,\n",
    "        exact_pad=False,\n",
    "        stft_exact_pad=False,\n",
    "        stft_conv=False,\n",
    "        pad_value=0,\n",
    "        mag_power=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa26a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthesis_models(fastpitch_model_path, hifigan_model_path):\n",
    "    print (fastpitch_model_path)\n",
    "    print (hifigan_model_path)\n",
    "    spec_model = FastPitchModel.load_from_checkpoint(fastpitch_model_path)\n",
    "    spec_model.cuda().eval()\n",
    "    vocoder = HifiGanModel.load_from_checkpoint(hifigan_model_path)\n",
    "    vocoder.cuda().eval()\n",
    "    \n",
    "    return spec_model, vocoder\n",
    "\n",
    "def play_validation_samples(spec_model, vocoder):\n",
    "    val_manifest_file = \"/home/pneekhara/JonData/val_list.json\"\n",
    "    with open(val_manifest_file) as f:\n",
    "        all_lines = f.read().split(\"\\n\")\n",
    "        for line in all_lines:\n",
    "            if len(line) > 0:\n",
    "                record = json.loads(line)\n",
    "\n",
    "                print(\"Jon's actual voice\")\n",
    "                ipd.display(ipd.Audio(record['audio_filepath']))\n",
    "\n",
    "                real_wav = wav_featurizer.process(record['audio_filepath'])\n",
    "                real_mel, _ = mel_processor.get_features(real_wav[None], torch.tensor([[real_wav.shape[0]]]).long() )\n",
    "                real_mel = real_mel[0]\n",
    "                real_mel = real_mel.cuda()\n",
    "                with torch.no_grad():\n",
    "                    vocoded_audio_real = vocoder.convert_spectrogram_to_audio(spec=real_mel).cpu().numpy()\n",
    "                    print(\"Ground truth spectrogram vocoded (HiFiGAN):\")\n",
    "                    ipd.display(ipd.Audio(vocoded_audio_real, rate=44100))\n",
    "                text_to_generate = record['text']\n",
    "                spec, audio = infer(spec_model, vocoder, text_to_generate, speaker=0)\n",
    "                print(\"Synthetic audio\")\n",
    "                ipd.display(ipd.Audio(audio, rate=44100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastpitch_nomix_finetuned_ckpt = \"/home/pneekhara/JonCkpts/FastPitchNoMixJon.ckpt\"\n",
    "fastpitch_mix_finetuned_ckpt = \"/home/pneekhara/JonCkpts/FastPitchMixJon.ckpt\"\n",
    "hifigan_nomix_finetuned_ckpt = \"/home/pneekhara/JonCkpts/HifiGanNoMix.ckpt\"\n",
    "hifigan_mix_finetuned_ckpt = \"/home/pneekhara/JonCkpts/HifiGanMix.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_model, vocoder = get_synthesis_models(fastpitch_nomix_finetuned_ckpt, hifigan_mix_finetuned_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_generate = \"This is a synthetic voice of Jon generated by a model trained on just fifteen minutes of data.\"\n",
    "spec, audio = infer(spec_model, vocoder, text_to_generate, speaker = 1)\n",
    "ipd.display(ipd.Audio(audio, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_validation_samples(spec_model, vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae62774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemoenv",
   "language": "python",
   "name": "nemoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
