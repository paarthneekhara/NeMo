{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "from nemo.collections.tts.models.base import SpectrogramGenerator, Vocoder, TextToWaveform\n",
    "from nemo.collections.tts.models import FastPitchModel\n",
    "from nemo.collections.tts.modules.hifigan_modules import Generator as Hifigan_generator\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "import librosa\n",
    "import os\n",
    "from nemo.collections.tts.models import TwoStagesModel\n",
    "from nemo.collections.asr.modules import AudioToMelSpectrogramPreprocessor\n",
    "from nemo.collections.asr.parts.preprocessing.features import WaveformFeaturizer\n",
    "from nemo.collections.tts.models import HifiGanModel\n",
    "import torchaudio\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_featurizer = WaveformFeaturizer(sample_rate=44100, int_values=False, augmentor=None)\n",
    "mel_processor = AudioToMelSpectrogramPreprocessor(\n",
    "        window_size = None,\n",
    "        window_stride = None,\n",
    "        sample_rate=44100,\n",
    "        n_window_size=2048,\n",
    "        n_window_stride=512,\n",
    "        window=\"hann\",\n",
    "        normalize=None,\n",
    "        n_fft=None,\n",
    "        preemph=None,\n",
    "        features=80,\n",
    "        lowfreq=0,\n",
    "        highfreq=None,\n",
    "        log=True,\n",
    "        log_zero_guard_type=\"add\",\n",
    "        log_zero_guard_value=1e-05,\n",
    "        dither=0.0,\n",
    "        pad_to=1,\n",
    "        frame_splicing=1,\n",
    "        exact_pad=False,\n",
    "        stft_exact_pad=False,\n",
    "        stft_conv=False,\n",
    "        pad_value=0,\n",
    "        mag_power=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder = Hifigan_generator(\n",
    "    resblock=1,\n",
    "    upsample_rates=[8, 8, 4, 2],\n",
    "    upsample_kernel_sizes=[16, 16, 4, 4],\n",
    "    upsample_initial_channel=512,\n",
    "    resblock_kernel_sizes=[3, 7, 11],\n",
    "    resblock_dilation_sizes=[[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
    ")\n",
    "nemo_gen_keys = [k for k in vocoder.state_dict().keys()]\n",
    "adlr_gen_ckpt = torch.load(\"/home/pneekhara/Checkpoints/g_01224000\")['generator']\n",
    "adlr_gen_keys = adlr_gen_ckpt.keys()\n",
    "# print (adlr_gen_keys)\n",
    "new_nemo_ckpt = {nemo_key: adlr_gen_ckpt[adlr_key] for adlr_key, nemo_key in zip(adlr_gen_keys, nemo_gen_keys)}\n",
    "vocoder.load_state_dict(new_nemo_ckpt)\n",
    "vocoder = vocoder.cuda().eval().half()\n",
    "\n",
    "cfg = {'linvocoder':  {'_target_': 'nemo.collections.tts.models.two_stages.GriffinLimModel',\n",
    "                     'cfg': {'n_iters': 64, 'n_fft': 2048, 'l_hop': 512}},\n",
    "       'mel2spec': {'_target_': 'nemo.collections.tts.models.two_stages.MelPsuedoInverseModel',\n",
    "                   'cfg': {'sampling_rate': 44100, 'n_fft': 2048, \n",
    "                           'mel_fmin': 0, 'mel_fmax': None, 'mel_freq': 80}}}\n",
    "vocoder_gl = TwoStagesModel(cfg).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder_hifimixed = HifiGanModel.load_from_checkpoint(\"/home/pneekhara/PreTrainedModels/HifiGan--val_loss=0.09-epoch=499-last.ckpt\")\n",
    "vocoder_hifimixed.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abec0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/pneekhara/Datasets/78419/Hi_Fi_TTS_v_0_backup\"\n",
    "experiment_base_dir = \"/home/pneekhara/ExperimentsOverfitting/\"\n",
    "clean_other_mapping = {\n",
    "    92 : 'clean',\n",
    "    6097 : 'clean'\n",
    "}\n",
    "\n",
    "\n",
    "num_val = 3\n",
    "for speaker in [ 6097, 92 ]:\n",
    "    manifest_path = os.path.join(data_dir, \"{}_manifest_{}_{}.json\".format(speaker, clean_other_mapping[speaker], \"dev\"))\n",
    "    val_records = []\n",
    "    with open(manifest_path, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            val_records.append( json.loads(line) )\n",
    "            if len(val_records) >= num_val:\n",
    "                break\n",
    "    print (\"**** REAL VALIDATION *****\")\n",
    "    for vidx, val_record in enumerate(val_records):\n",
    "        print(\"Audio file:\", val_record['audio_filepath'].split(\"/\")[-1] )\n",
    "        audio_path = os.path.join( data_dir, val_record['audio_filepath'] )\n",
    "        real_wav = wav_featurizer.process(audio_path)\n",
    "        real_mel, _ = mel_processor.get_features(real_wav[None], torch.tensor([[real_wav.shape[0]]]).long() )\n",
    "        real_mel = real_mel[0].cuda()\n",
    "        with torch.no_grad():\n",
    "            vocoded_audio_real_hifi = vocoder(x=real_mel.half()).squeeze(1)\n",
    "            vocoded_audio_real_hifi = vocoded_audio_real_hifi.to('cpu').numpy()\n",
    "            vocoded_audio_real_gl = vocoder_gl.convert_spectrogram_to_audio(spec=real_mel)\n",
    "            vocoded_audio_real_hfimixed = vocoder_hifimixed.convert_spectrogram_to_audio(spec=real_mel).cpu().numpy()\n",
    "        \n",
    "        print (\"{}) {}\".format(vidx+1, val_record['text']))\n",
    "        print(\"Ground Truth Audio for speaker:\", speaker)\n",
    "        ipd.display(ipd.Audio(real_wav, rate=44100))\n",
    "        print(\"Vocoded (HiFiGAN) from real spectrogram for speaker:\", speaker)\n",
    "        ipd.display(ipd.Audio(vocoded_audio_real_hifi, rate=44100))\n",
    "        print(\"Vocoded (GL) from real spectrogram for speaker:\", speaker)\n",
    "        ipd.display(ipd.Audio(vocoded_audio_real_gl, rate=44100))\n",
    "        print(\"Vocoded (HiFiGAN Mixed) from real spectrogram for speaker:\", speaker)\n",
    "        ipd.display(ipd.Audio(vocoded_audio_real_hfimixed, rate=44100))\n",
    "    print (\"************************\")\n",
    "    continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aabebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder_hifimixed.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09233066",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\"sample.wav\", torch.tensor(vocoded_audio_real, dtype=torch.float), 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2239219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5c56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemoenv",
   "language": "python",
   "name": "nemoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
