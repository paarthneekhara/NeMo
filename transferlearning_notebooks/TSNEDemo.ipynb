{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
    "from nemo.collections.asr.modules import AudioToMelSpectrogramPreprocessor\n",
    "from nemo.collections.asr.parts.preprocessing.features import WaveformFeaturizer\n",
    "import librosa\n",
    "import torch\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing real and synthesized samples from various methods for different speakers.\n",
    "samples_dir = \"/home/pneekhara/synthesized_samples3/\"\n",
    "\n",
    "wav_paths = {}\n",
    "for fname in os.listdir(samples_dir):\n",
    "    if fname.endswith(\".wav\"):\n",
    "        wav_type, method_info, speaker, val_no = fname.split(\"_\")\n",
    "        val_no = val_no.split(\".\")[0]\n",
    "        key = \"{}_{}_{}\".format(wav_type, method_info, speaker)\n",
    "        if \"real_actual\" in key:\n",
    "            if key in wav_paths:\n",
    "                wav_paths[key].append( ( int(val_no), os.path.join(samples_dir, fname) ) )\n",
    "            else:\n",
    "                wav_paths[key] = [ (int(val_no), os.path.join(samples_dir, fname)) ]\n",
    "\n",
    "for key in wav_paths:\n",
    "    wav_paths[key].sort()\n",
    "    wav_paths[key] = [ t[1] for t in wav_paths[key] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ef5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in wav_paths:\n",
    "    print (key, len(wav_paths[key]), wav_paths[key][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb740c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_featurizer = WaveformFeaturizer(sample_rate=44100, int_values=False, augmentor=None)\n",
    "mel_processor = AudioToMelSpectrogramPreprocessor(\n",
    "        window_size = None,\n",
    "        window_stride = None,\n",
    "        sample_rate=44100,\n",
    "        n_window_size=2048,\n",
    "        n_window_stride=512,\n",
    "        window=\"hann\",\n",
    "        normalize=None,\n",
    "        n_fft=None,\n",
    "        preemph=None,\n",
    "        features=80,\n",
    "        lowfreq=0,\n",
    "        highfreq=None,\n",
    "        log=True,\n",
    "        log_zero_guard_type=\"add\",\n",
    "        log_zero_guard_value=1e-05,\n",
    "        dither=0.0,\n",
    "        pad_to=1,\n",
    "        frame_splicing=1,\n",
    "        exact_pad=False,\n",
    "        stft_exact_pad=False,\n",
    "        stft_conv=False,\n",
    "        pad_value=0,\n",
    "        mag_power=1.0\n",
    ")\n",
    "\n",
    "speaker_verification_model = EncDecSpeakerLabelModel.from_pretrained(\"speakerverification_speakernet\")\n",
    "speaker_verification_model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"/home/pneekhara/synthesized_audio_demo.pkl\"\n",
    "regenerate = False\n",
    "if os.path.exists(pickle_path) and not regenerate:\n",
    "    with open(pickle_path, \"rb\") as f:\n",
    "        meta_data = pickle.load(f)\n",
    "        embeddings = meta_data['embeddings']\n",
    "else:\n",
    "    embeddings = {}\n",
    "    for key in wav_paths:\n",
    "        print (\"Getting embeddings for:\", key, len(wav_paths[key]))\n",
    "        embeddings[key] = []\n",
    "        for path in wav_paths[key]:\n",
    "            embedding = speaker_verification_model.get_embedding(path)\n",
    "            embeddings[key].append(embedding.cpu().numpy().flatten())\n",
    "\n",
    "    with open(\"synthesized_audio_meta_data.pkl\", \"wb\") as f:\n",
    "        meta_data = {\n",
    "            'embeddings' : embeddings\n",
    "        }\n",
    "        pickle.dump(meta_data, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26974e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mscatter(x,y, ax=None, m=None, **kw):\n",
    "    import matplotlib.markers as mmarkers\n",
    "    #ax = ax or plt.gca()\n",
    "    sc = plt.scatter(x,y,**kw)\n",
    "    if (m is not None) and (len(m)==len(x)):\n",
    "        paths = []\n",
    "        for marker in m:\n",
    "            if isinstance(marker, mmarkers.MarkerStyle):\n",
    "                marker_obj = marker\n",
    "            else:\n",
    "                marker_obj = mmarkers.MarkerStyle(marker)\n",
    "            path = marker_obj.get_path().transformed(\n",
    "                        marker_obj.get_transform())\n",
    "            paths.append(path)\n",
    "        sc.set_paths(paths)\n",
    "    return sc\n",
    "\n",
    "def visualize_embeddings(embedding_dict_np, title = \"TSNE\"):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    embedding_dict_np : Dictionary with keys as speaker ids/labels and value as list of np arrays (embeddings).\n",
    "    \"\"\"\n",
    "    color = []\n",
    "    marker_shape = []\n",
    "    universal_embed_list=[]\n",
    "    handle_list=[]  \n",
    "    _unique_speakers = {}\n",
    "    \n",
    "    marker_list = ['<', '*', 'h', 'X', 's', 'H', 'D', 'd', 'P', 'v', '^', '>', '8', 'p']\n",
    "        \n",
    "    for kidx, key in enumerate(embedding_dict_np.keys()):\n",
    "        universal_embed_list += embedding_dict_np[key]\n",
    "        _num_samples = len(embedding_dict_np[key])\n",
    "        \n",
    "        id_color = plt.cm.tab20(kidx)\n",
    "        _color = [id_color] * _num_samples\n",
    "        color += _color\n",
    "        _marker_shape = [ marker_list[kidx % len(marker_list)] ] * _num_samples\n",
    "        marker_shape += _marker_shape\n",
    "        _label = key\n",
    "        handle_list.append(mpatches.Patch(color = id_color, label=_label))\n",
    "        \n",
    "   \n",
    "    \n",
    "    speaker_embeddings = TSNE(n_components=2, random_state=0).fit_transform(universal_embed_list)        \n",
    "    \n",
    "    mscatter(speaker_embeddings[:, 0], speaker_embeddings[:, 1], m = marker_shape,  c=color, s=60)\n",
    "   \n",
    "    plt.legend(handles=handle_list,title=\"Speaker_ID\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d310c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_real is a dictionary with keys as speaker ids, and values as list of 256 dimensional embeddings (np arrays)\n",
    "for key in embeddings:\n",
    "    print (key, len(embeddings[key]), len(embeddings[key][0]), type(embeddings[key][0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 12)\n",
    "visualize_embeddings(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f4cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemoenv",
   "language": "python",
   "name": "nemoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
